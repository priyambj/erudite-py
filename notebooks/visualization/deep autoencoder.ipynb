{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%run ../basics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/learning_resources.csv')\n",
    "display(df.head(2))\n",
    "tags = pd.read_csv('../data/tags.csv')\n",
    "display(tags.head(2))\n",
    "df['tags'] = df['id'].apply(lambda x: (' '.join(tags[tags['id'] == x]['concept_tag'].values.tolist())).strip())\n",
    "print(df.columns)\n",
    "print(df.count())\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Encoder(object):\n",
    "    def __init__(self, tfidf_max_df=None, tfidf_min_df=None, tag_vec_max_df=None, tag_vec_min_df=None, \n",
    "                 ngram_range=None, **kwargs):\n",
    "        self.vectorizer = CountVectorizer(stop_words='english',\n",
    "                                          max_df=0.6 if tfidf_max_df is None else tfidf_max_df,\n",
    "                                          min_df=5 if tfidf_min_df is None else tfidf_min_df,\n",
    "                                          ngram_range=(1 ,1) if ngram_range is None else ngram_range)\n",
    "        \n",
    "        self.nn = None\n",
    "        self.nn_encode = None\n",
    "        self.topic_dict = None\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    def create_autoencoder(self,X):\n",
    "        print('X shape:', X.shape)\n",
    "        input_vec = Input(shape=(X.shape[1], ))\n",
    "        encoded = Dense(256, activation='relu')(input_vec)\n",
    "        encoded = Dense(128, activation='relu')(encoded)\n",
    "        encoded = Dense(64, activation='relu')(encoded)\n",
    "\n",
    "        decoded = Dense(128, activation='relu')(decoded)\n",
    "        decoded = Dense(256, activation='relu')(decoded)\n",
    "        decoded = Dense(X.shape[1], activation='relu')(decoded)\n",
    "        \n",
    "        nn = Model(input=input_vec, output=decoded)\n",
    "        nn.compile(optimizer='adadelta', loss='mse')\n",
    "        self.nn = nn\n",
    "        print(nn.summary())\n",
    "        \n",
    "        nn = Model(input=input_vec, output=encoded)\n",
    "        nn.compile(optimizer='adam', loss='mse')\n",
    "        self.nn_encode = nn\n",
    "\n",
    "    def fit(self, X, viz=True, *args, **kwargs):            \n",
    "        orig_X = X.copy()\n",
    "        X = self.prepare_X(X)\n",
    "        X = self.vectorize_X(X, fit=True, viz=viz)\n",
    "        if viz:\n",
    "            try:\n",
    "                tsne_plot(X, orig_X[[orig_X.columns[0]]], fit=True)\n",
    "            except:\n",
    "                print(traceback.format_exc())\n",
    "        if self.nn is None:\n",
    "            self.create_autoencoder(X)\n",
    "        \n",
    "        flat_X = np.array(X).flatten()\n",
    "        print('baseline mean mse:', mean_squared_error(flat_X, np.array([flat_X.mean()]*len(flat_X))))\n",
    "        start = datetime.datetime.now()\n",
    "        hist = self.nn.fit(X, X,\n",
    "                            nb_epoch=30,\n",
    "                            batch_size=1,\n",
    "                            shuffle=True,\n",
    "                            validation_split=.05,\n",
    "                            verbose=2)\n",
    "        print('nn training:', datetime.datetime.now() - start)\n",
    "        if 'val_loss' in hist.history:\n",
    "            data = zip(hist.history['loss'], hist.history['val_loss'])\n",
    "            hist_df = pd.DataFrame(columns=['train', 'val'], data=data)\n",
    "            hist_df.plot(y=['train', 'val'], secondary_y=['val'])\n",
    "            plt.show()\n",
    "        else:\n",
    "            data = hist.history['loss']\n",
    "            hist_df = pd.DataFrame(columns=['train'], data=data)\n",
    "            hist_df.plot(y=['train'])\n",
    "            plt.show()\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = self.prepare_X(X)\n",
    "        X = self.vectorize_X(X, fit=False)\n",
    "        return self.nn_encode.predict(X)\n",
    "    \n",
    "    @staticmethod\n",
    "    def prepare_X(X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            concat_x = pd.Series(index=X.index, data='')\n",
    "            for i in X.columns:\n",
    "                concat_x += ' ' + X[i].apply(text_cleanup)\n",
    "            X = concat_x\n",
    "        else:\n",
    "            assert isinstance(X, pd.Series)\n",
    "        return X\n",
    "        \n",
    "    def vectorize_X(self, X, fit=False, viz=False):\n",
    "        if fit:\n",
    "            tfidf = self.vectorizer.fit_transform(X.values)\n",
    "        else:\n",
    "            tfidf = self.vectorizer.transform(X.values)\n",
    "        tfidf, words = filter_word_rep(tfidf, self.vectorizer.get_feature_names())\n",
    "        print('tfidf shape', tfidf.shape)\n",
    "        # tfidf = (tfidf > 0.).astype('float')\n",
    "        tfidf = normalize(tfidf, axis=1, norm='l1')\n",
    "        #print(tfidf.sum(axis=1))\n",
    "        #assert np.allclose(tfidf.sum(axis=1), 1.)\n",
    "        return tfidf.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "encoder.fit(df[['title', 'subtitle', 'description', 'syllabus']], viz=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoded = encoder.predict(df[['title', 'subtitle', 'description', 'syllabus']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(encoded[:, 0], encoded[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
