{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"ca9047c2-30a5-4c1c-bfa5-17ba8aafe26a\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\") {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  var js_urls = ['https://cdn.pydata.org/bokeh/release/bokeh-0.12.0.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.0.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-compiler-0.12.0.min.js'];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      Bokeh.$(\"#ca9047c2-30a5-4c1c-bfa5-17ba8aafe26a\").text(\"BokehJS successfully loaded\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.0.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i](window.Bokeh);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%run basics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('len:', 940)\n",
      "('tags count:', 940)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>course_shortname</th>\n",
       "      <th>url</th>\n",
       "      <th>concept_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ud257</td>\n",
       "      <td>ab-testing</td>\n",
       "      <td>https://www.udacity.com/course/ab-testing--ud2...</td>\n",
       "      <td>video_lecture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ud257</td>\n",
       "      <td>ab-testing</td>\n",
       "      <td>https://www.udacity.com/course/ab-testing--ud2...</td>\n",
       "      <td>in_depth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id course_shortname                                                url  \\\n",
       "0  ud257       ab-testing  https://www.udacity.com/course/ab-testing--ud2...   \n",
       "1  ud257       ab-testing  https://www.udacity.com/course/ab-testing--ud2...   \n",
       "\n",
       "     concept_tag  \n",
       "0  video_lecture  \n",
       "1       in_depth  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags = pd.read_csv('../coursera/data/ds_urls_shortnames_concepts_reviewed_2016_06_21.csv', encoding='utf-8')\n",
    "print('len:', len(df_tags))\n",
    "print('tags count:', df_tags['concept_tag'].count())\n",
    "df_tags.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv('../coursera/data/learning_resource_table_2016_07_05.csv')\n",
    "df = pd.read_csv('../coursera/data/learning_resource_w_slide_transcript_2016_07_07.csv')\n",
    "print('len:', len(df))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df_tags, df, on='id', how='outer').groupby(by='id', as_index=False)\n",
    "merged_df = pd.DataFrame(df.apply(lambda x: x.iloc[0]))\n",
    "merged_df['tags'] = df.apply(lambda x: map(str, list(x['concept_tag'].values)))\n",
    "print('len:', len(merged_df))\n",
    "print(merged_df.columns)\n",
    "merged_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['title', 'subtitle', 'description', 'slide_text']\n",
    "df['all-text'] = ''\n",
    "for i in cols:\n",
    "    df['all-text'] += df[i].astype('str')\n",
    "    df['all-text'] += ' '\n",
    "df['all-text'].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['all-text'].apply(len).plot(kind='hist')\n",
    "plt.xlabel('#char')\n",
    "plt.show()\n",
    "df['all-text'].apply(lambda x: len(x.split())).plot(kind='hist')\n",
    "plt.xlabel('#words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "import string\n",
    "allowed_chars = set(string.ascii_lowercase) | {' '}\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def text_cleanup(text):\n",
    "    text = text.lower()\n",
    "    #text = ' '.join((stemmer.stem(i.decode('utf-8')) for i in text.split()))\n",
    "    if text == 'nan':\n",
    "        text = ''\n",
    "    text = filter(lambda x: x in allowed_chars, text.lower())\n",
    "    text = ' '.join(filter(lambda x: len(x) > 4, text.split()))\n",
    "    return text\n",
    "    \n",
    "df['all-text'] = df['all-text'].apply(text_cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.1, min_df=5)\n",
    "vectorized_text = vectorizer.fit_transform(df['all-text'].values)\n",
    "print('tfidf shape:', vectorized_text.shape)\n",
    "\n",
    "if False:\n",
    "    from sklearn.decomposition import TruncatedSVD\n",
    "    explained_var = list()\n",
    "    comp_range = range(2, 3000, 300)\n",
    "    shapes = list()\n",
    "    for i in tqdm(comp_range):\n",
    "        svd = TruncatedSVD(n_components=i, n_iter=100)\n",
    "        tmp = svd.fit_transform(vectorized_text)\n",
    "        explained_var.append(svd.explained_variance_.sum())\n",
    "        shapes.append(tmp.shape[1])\n",
    "    pd.DataFrame(columns=['number of components', 'explained variance', 'true dim'], \n",
    "                 data=zip(comp_range, explained_var, shapes)).plot(x='number of components', secondary_y=['true dim'])\n",
    "    plt.show()\n",
    "    svd = TruncatedSVD(n_components=3000, n_iter=100)\n",
    "    vectorized_text = svd.fit_transform(vectorized_text)\n",
    "else:\n",
    "    vectorized_text = np.array(vectorized_text.todense())\n",
    "print(type(vectorized_text))\n",
    "print(vectorized_text.shape)\n",
    "print(len(vectorized_text.shape))\n",
    "tfidf_vals = pd.DataFrame(data=vectorized_text.copy().ravel())\n",
    "tfidf_vals = tfidf_vals[tfidf_vals[0] > 0]\n",
    "tfidf_vals.plot(kind='hist', bins=200)\n",
    "plt.show()\n",
    "tfidf_vals = pd.DataFrame(data=vectorized_text.max(axis=1).ravel())\n",
    "print(len(tfidf_vals))\n",
    "#tfidf_vals = tfidf_vals[tfidf_vals[0] > 0]\n",
    "tfidf_vals.plot(kind='hist', bins=200)\n",
    "plt.title('max tfidf vals')\n",
    "plt.show()\n",
    "tfidf_vals = pd.DataFrame(data=vectorized_text.min(axis=1).ravel())\n",
    "print(len(tfidf_vals))\n",
    "#tfidf_vals = tfidf_vals[tfidf_vals[0] > 0]\n",
    "tfidf_vals.plot(kind='hist', bins=200)\n",
    "plt.title('min tfidf vals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diffs = list()\n",
    "for idx in range(vectorized_text.shape[0]):\n",
    "    for jdx in range(vectorized_text.shape[0]):\n",
    "        v1 = vectorized_text[idx, :].copy()\n",
    "        v2 = vectorized_text[jdx, :].copy()\n",
    "        \n",
    "        sim = (v1 * v2).sum() / ( np.sqrt((v1**2).sum()) * np.sqrt((v2**2).sum()) )\n",
    "        euc_dist = np.sqrt(((v1-v2)**2).sum())\n",
    "        man_dist = np.abs(v1-v2).sum()\n",
    "        bin_diff = (v2 > v1).sum()\n",
    "        max_diff = (v2 - v1).max()\n",
    "        mean_diff = (v2 - v1).mean()\n",
    "        median_diff = np.median(v2 - v1)\n",
    "        v1_max = v1.max()\n",
    "        v2_max = v2.max()\n",
    "        v1_min = v1.min()\n",
    "        v2_min = v2.min()\n",
    "        v1_mean = v1.mean()\n",
    "        v2_mean = v2.mean()\n",
    "        v1_median = np.median(v1)\n",
    "        v2_median = np.median(v2)\n",
    "        v1_count = (v1 > 0).sum()\n",
    "        v2_count = (v2 > 0).sum()\n",
    "        \n",
    "        #cons_idx = (v2 > 0.) & (v1 > 0.) & (v2 - 0.4 > v1)\n",
    "        #v1 = v1[cons_idx]\n",
    "        #v2 = v2[cons_idx]\n",
    "        \n",
    "        diff = (v2 - v1).sum()\n",
    "        diffs.append((idx, jdx, diff, sim, euc_dist, man_dist, \n",
    "                      bin_diff, max_diff, mean_diff, median_diff, \n",
    "                      v1_max, v2_max, v1_min, v2_min, v1_mean, v2_mean, v1_median, v2_median, v1_count, v2_count, v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_df = pd.DataFrame(columns=['idx', 'jdx', \n",
    "                                'vec-diff', 'cos-sim', 'euc-dist', 'man-dist', 'bin_diff', \n",
    "                                'max_diff', 'mean_diff', 'median_diff',\n",
    "                                'v1_max', 'v2_max', 'v1_min', 'v2_min', \n",
    "                                'v1_mean', 'v2_mean', 'v1_median', 'v2_median', \n",
    "                                'v1_count', 'v2_count',\n",
    "                                'v1', 'v2'], data=diffs)\n",
    "diff_df['c1'] = map(lambda x: df.iloc[x]['title'], diff_df['idx'])\n",
    "diff_df['c2'] = map(lambda x: df.iloc[x]['title'], diff_df['jdx'])\n",
    "diff_df['c_id'] = map(lambda x: df.iloc[x]['id'], diff_df['idx'])\n",
    "diff_df['prereq_id'] = map(lambda x: df.iloc[x][0], diff_df['jdx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(diff_df['vec-diff'].min())\n",
    "print(diff_df['vec-diff'].max())\n",
    "diff_df.to_pickle('coursera_clf.df')\n",
    "diff_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff_df[diff_df['ground-truth']>0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff_df.groupby(by='ground-truth').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff_df[diff_df['diff']!=0]['diff'].plot(kind='hist', bins=200)\n",
    "plt.show()\n",
    "diff_df[diff_df['diff']>0]['diff'].plot(kind='hist', bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def filter_top_prereq(df):\n",
    "    s_df = df.sort_values(by='diff', ascending=True)\n",
    "    return s_df[s_df['diff']>0.5].copy()\n",
    "    #return s_df.iloc[-3:]\n",
    "\n",
    "prereq = pd.DataFrame(diff_df.groupby(by='c1').apply(filter_top_prereq))\n",
    "prereq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prereq.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_prereq.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_true_prereq_level((c_id, prereq_id), prereq_df):\n",
    "    try:\n",
    "        true_prereq = prereq_df.loc[c_id]\n",
    "    except KeyError:\n",
    "        return 0\n",
    "    prereq_level = 0\n",
    "    #print('---------')\n",
    "    #print(df[df['id'] == c_id]['title'].iloc[0])\n",
    "    #print(df[df['id'] == prereq_id]['title'].iloc[0])\n",
    "    for idx, ids in enumerate(true_prereq.values):\n",
    "        if isinstance(ids, float):\n",
    "            continue\n",
    "        #try:    \n",
    "            #print(map(lambda x: df[df['id'] == x]['title'].iloc[0], ids.split()))\n",
    "        #except:\n",
    "        #    pass\n",
    "        if prereq_id in ids.split():\n",
    "            prereq_level = idx + 1\n",
    "    #print(prereq_level)\n",
    "    return prereq_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#prereq[['c_id', 'prereq_id']].iloc[:100].apply(get_true_prereq_level, args=(df_prereq,), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prereq['prereq_level'] = prereq[['c_id', 'prereq_id']].apply(get_true_prereq_level, args=(df_prereq,), axis=1)\n",
    "prereq['prereq_level'].plot(kind='hist')\n",
    "plt.show()\n",
    "prereq[['prereq_level', 'diff']].groupby(by='prereq_level').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prereq[prereq['prereq_level'] == 0].sort_values(by='diff', ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prereq['rnd_prereq_id'] = np.random.choice(df['id'].values, size=len(prereq), replace=True)\n",
    "prereq['rnd_prereq_id'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prereq['rnd_prereq_level'] = prereq[['c_id', 'rnd_prereq_id']].apply(get_true_prereq_level, args=(df_prereq,), axis=1)\n",
    "prereq['rnd_prereq_level'].plot(kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prereq[prereq['prereq_level']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prereq[prereq['rnd_prereq_level']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = '2D Game Development with libGDX'\n",
    "b = 'Intro to Physics'\n",
    "a_idx = df[df['title'] == a].index[0]\n",
    "b_idx = df[df['title'] == b].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tfidf_df(vec, vectorizer):\n",
    "    df = pd.DataFrame(columns=['tfidf-val'], data=vec)\n",
    "    df['word'] = vectorizer.get_feature_names()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_df = get_tfidf_df(vectorized_text[a_idx, :], vectorizer)\n",
    "a_df.sort_values(by='tfidf-val', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_df[a_df['tfidf-val']>0].sort_values(by='tfidf-val').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b_df = get_tfidf_df(vectorized_text[b_idx, :], vectorizer)\n",
    "b_df.sort_values(by='tfidf-val').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filt = (a_df['tfidf-val'] > 0) & (b_df['tfidf-val'] > 0)\n",
    "a_df = a_df[filt]\n",
    "b_df = b_df[filt]\n",
    "a_df['diff'] = a_df['tfidf-val'] - b_df['tfidf-val']\n",
    "a_df.sort_values(by='diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
