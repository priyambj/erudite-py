{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"2aac18b6-5fc2-46ed-b1e5-d66a30835fb0\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\") {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  var js_urls = ['https://cdn.pydata.org/bokeh/release/bokeh-0.12.0.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.0.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-compiler-0.12.0.min.js'];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      Bokeh.$(\"#2aac18b6-5fc2-46ed-b1e5-d66a30835fb0\").text(\"BokehJS successfully loaded\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.0.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i](window.Bokeh);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "%run basics.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'id', u'title', u'homepage', u'subtitle', u'level', u'starter',\n",
      "       u'image', u'banner_image', u'teaser_video', u'summary',\n",
      "       u'short_summary', u'required_knowledge', u'expected_learning',\n",
      "       u'featured', u'syllabus', u'faq', u'full_course_available',\n",
      "       u'expected_duration', u'expected_duration_unit', u'new_release',\n",
      "       u'transcripts_url', u'transcripts_zip_fn', u'transcript'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>homepage</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>level</th>\n",
       "      <th>starter</th>\n",
       "      <th>image</th>\n",
       "      <th>banner_image</th>\n",
       "      <th>teaser_video</th>\n",
       "      <th>summary</th>\n",
       "      <th>...</th>\n",
       "      <th>featured</th>\n",
       "      <th>syllabus</th>\n",
       "      <th>faq</th>\n",
       "      <th>full_course_available</th>\n",
       "      <th>expected_duration</th>\n",
       "      <th>expected_duration_unit</th>\n",
       "      <th>new_release</th>\n",
       "      <th>transcripts_url</th>\n",
       "      <th>transcripts_zip_fn</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bio110</td>\n",
       "      <td>Tales from the Genome</td>\n",
       "      <td>https://www.udacity.com/course/tales-from-the-...</td>\n",
       "      <td>Introduction to Genetics for Beginners</td>\n",
       "      <td>beginner</td>\n",
       "      <td>False</td>\n",
       "      <td>https://lh5.ggpht.com/Fh07_XbT61CGDWsQoOMQaIeH...</td>\n",
       "      <td>https://lh4.ggpht.com/_AHqr0EXcLBzF0rrwtBagE0t...</td>\n",
       "      <td>https://www.youtube.com/watch?v=sEXrjh-tme8</td>\n",
       "      <td>This course is a journey into the biology of t...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>## Lesson 1: Introduction to traits and heredi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>months</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.udacity.com/course/progress#!/c-bi...</td>\n",
       "      <td>transcripts_zips/bio110.zip</td>\n",
       "      <td>In the same way that our genomes influence tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cs046</td>\n",
       "      <td>Intro to Java Programming</td>\n",
       "      <td>https://www.udacity.com/course/intro-to-java-p...</td>\n",
       "      <td>Building Programs with Classes &amp; Objects</td>\n",
       "      <td>beginner</td>\n",
       "      <td>False</td>\n",
       "      <td>https://lh4.ggpht.com/9ytiUdz0QYHwuMJFTXcNXZn4...</td>\n",
       "      <td>https://lh3.ggpht.com/AdAALPYhCsWuIvDl0ZY6zIW2...</td>\n",
       "      <td>https://www.youtube.com/watch?v=Wsp5Rrenoq4</td>\n",
       "      <td>In this introductory course, you'll learn and ...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>### Lesson 1: Introduction to Computers, Progr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>months</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.udacity.com/course/progress#!/c-cs046</td>\n",
       "      <td>transcripts_zips/cs046.zip</td>\n",
       "      <td>Hi, I'm Cay. I'm Sara. We'll be the instructo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                      title  \\\n",
       "0  bio110      Tales from the Genome   \n",
       "1   cs046  Intro to Java Programming   \n",
       "\n",
       "                                            homepage  \\\n",
       "0  https://www.udacity.com/course/tales-from-the-...   \n",
       "1  https://www.udacity.com/course/intro-to-java-p...   \n",
       "\n",
       "                                   subtitle     level starter  \\\n",
       "0    Introduction to Genetics for Beginners  beginner   False   \n",
       "1  Building Programs with Classes & Objects  beginner   False   \n",
       "\n",
       "                                               image  \\\n",
       "0  https://lh5.ggpht.com/Fh07_XbT61CGDWsQoOMQaIeH...   \n",
       "1  https://lh4.ggpht.com/9ytiUdz0QYHwuMJFTXcNXZn4...   \n",
       "\n",
       "                                        banner_image  \\\n",
       "0  https://lh4.ggpht.com/_AHqr0EXcLBzF0rrwtBagE0t...   \n",
       "1  https://lh3.ggpht.com/AdAALPYhCsWuIvDl0ZY6zIW2...   \n",
       "\n",
       "                                  teaser_video  \\\n",
       "0  https://www.youtube.com/watch?v=sEXrjh-tme8   \n",
       "1  https://www.youtube.com/watch?v=Wsp5Rrenoq4   \n",
       "\n",
       "                                             summary  \\\n",
       "0  This course is a journey into the biology of t...   \n",
       "1  In this introductory course, you'll learn and ...   \n",
       "\n",
       "                         ...                         featured  \\\n",
       "0                        ...                            False   \n",
       "1                        ...                            False   \n",
       "\n",
       "                                            syllabus  faq  \\\n",
       "0  ## Lesson 1: Introduction to traits and heredi...  NaN   \n",
       "1  ### Lesson 1: Introduction to Computers, Progr...  NaN   \n",
       "\n",
       "  full_course_available expected_duration expected_duration_unit new_release  \\\n",
       "0                 False                 3                 months       False   \n",
       "1                  True                 4                 months       False   \n",
       "\n",
       "                                     transcripts_url  \\\n",
       "0  https://www.udacity.com/course/progress#!/c-bi...   \n",
       "1  https://www.udacity.com/course/progress#!/c-cs046   \n",
       "\n",
       "            transcripts_zip_fn  \\\n",
       "0  transcripts_zips/bio110.zip   \n",
       "1   transcripts_zips/cs046.zip   \n",
       "\n",
       "                                          transcript  \n",
       "0   In the same way that our genomes influence tr...  \n",
       "1   Hi, I'm Cay. I'm Sara. We'll be the instructo...  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('udacity_courses.df')\n",
    "print(df.columns)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_id</th>\n",
       "      <th>u_pre_req_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cs222</td>\n",
       "      <td>cs101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cs222</td>\n",
       "      <td>ph100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    u_id u_pre_req_id\n",
       "0  cs222        cs101\n",
       "1  cs222        ph100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prereq = pd.read_csv('udacity_prereq_graph.csv')\n",
    "df_prereq.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_prereq(a, b, preq):\n",
    "    a_p = preq[preq['u_id'] == a]\n",
    "    if len(a_p) > 0:\n",
    "        if b in a_p['u_pre_req_id'].values.tolist():\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title         129\n",
      "subtitle      127\n",
      "summary       129\n",
      "syllabus      129\n",
      "transcript    129\n",
      "dtype: int64\n",
      "0    tales from the genome introduction to genetics...\n",
      "1    intro to java programming building programs wi...\n",
      "Name: title, dtype: object\n",
      "# distinct words: 9813\n",
      "# excluded words: 30619\n"
     ]
    }
   ],
   "source": [
    "fields = ['title', 'subtitle', 'summary', 'syllabus', 'transcript']\n",
    "print(df[fields].count())\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.5, min_df=5)\n",
    "all_text = df[fields[0]].copy()\n",
    "for c in fields[1:]:\n",
    "    all_text += ' ' + df[c]\n",
    "all_text = all_text.apply(text_cleanup)\n",
    "print(all_text.head(2))\n",
    "vectorizer.fit(all_text)\n",
    "filter_w = set(vectorizer.get_feature_names())\n",
    "print('# distinct words:', len(filter_w))\n",
    "print('# excluded words:', len(vectorizer.stop_words_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'id', u'title', u'homepage', u'subtitle', u'level', u'starter',\n",
       "       u'image', u'banner_image', u'teaser_video', u'summary',\n",
       "       u'short_summary', u'required_knowledge', u'expected_learning',\n",
       "       u'featured', u'syllabus', u'faq', u'full_course_available',\n",
       "       u'expected_duration', u'expected_duration_unit', u'new_release',\n",
       "       u'transcripts_url', u'transcripts_zip_fn', u'transcript'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title 4\n",
      "0        genome\n",
      "1    intro java\n",
      "Name: title, dtype: object\n",
      "0    [1, 0, 0, 0]\n",
      "1    [2, 3, 0, 0]\n",
      "Name: title, dtype: object\n",
      "subtitle 4\n",
      "0    genetics beginners\n",
      "1              programs\n",
      "Name: subtitle, dtype: object\n",
      "0    [121, 96, 0, 0]\n",
      "1       [4, 0, 0, 0]\n",
      "Name: subtitle, dtype: object\n",
      "summary 69\n",
      "0    journey biology genome highlight scientific so...\n",
      "1    introductory essential java oriented programme...\n",
      "Name: summary, dtype: object\n",
      "0    [234, 235, 1, 236, 237, 123, 238, 239, 240, 24...\n",
      "1    [242, 243, 3, 31, 244, 4, 3, 245, 246, 0, 0, 0...\n",
      "Name: summary, dtype: object\n",
      "syllabus 244\n",
      "0    traits trait variation categorization inherita...\n",
      "1    computers algorithms java graphics fundamental...\n",
      "Name: syllabus, dtype: object\n",
      "0    [241, 1219, 1220, 1221, 1222, 1223, 171, 1224,...\n",
      "1    [524, 5, 3, 13, 666, 1271, 1272, 5, 1088, 1222...\n",
      "Name: syllabus, dtype: object\n",
      "transcript 40593\n",
      "0    influence traits eye hair cancer influence dru...\n",
      "1    sara instructors processor buttons secret secr...\n",
      "Name: transcript, dtype: object\n",
      "0    [2652, 241, 1531, 2653, 334, 2652, 1255, 2654,...\n",
      "1    [4340, 577, 1683, 956, 1573, 1573, 3, 4, 271, ...\n",
      "Name: transcript, dtype: object\n"
     ]
    }
   ],
   "source": [
    "digiz = Digitizer()\n",
    "max_words = 1000\n",
    "text_series = list()\n",
    "for i in fields:\n",
    "    ser = df[i].copy()\n",
    "    ser = ser.apply(text_cleanup, args=(filter_w, ))\n",
    "    print(i, ser.apply(lambda x: len(x.split())).max())\n",
    "    print(ser.head(2))\n",
    "    dig_ser = digiz.series_digitizer(ser, max_len=max_words)\n",
    "    text_series.append(dig_ser)\n",
    "    print(dig_ser.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1, 0, 0, 0]\n",
       "1    [2, 3, 0, 0]\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_series[0].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [121, 96, 0, 0]\n",
       "1       [4, 0, 0, 0]\n",
       "Name: subtitle, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_series[1].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10321\n",
      "syllabus len: 244\n",
      "summary len: 69\n",
      "subtitle len: 4\n",
      "transcript len: 10000\n",
      "title len: 4\n"
     ]
    }
   ],
   "source": [
    "all_text = text_series[0].copy()\n",
    "text_block_len = dict()\n",
    "text_block_len[fields[0]] = len(text_series[0].iloc[0])\n",
    "for i, f in zip(text_series[1:], fields[1:]):\n",
    "    all_text += i\n",
    "    text_block_len[f] = len(i.iloc[0])\n",
    "df['digitized_text'] = all_text\n",
    "max_len = df['digitized_text'].apply(len).max()\n",
    "print(max_len)\n",
    "df['digitized_text'] = df['digitized_text'].apply(lambda x: np.array(x))\n",
    "df['digitized_text'].head(10)\n",
    "for f in fields:\n",
    "    print(f, 'len:', text_block_len[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#words: 9809\n",
      "seq len: 10321\n"
     ]
    }
   ],
   "source": [
    "n_words = digiz.num_words()\n",
    "print('#words:', n_words)\n",
    "print('seq len:', max_len)\n",
    "df['digitized_text'].head(2)\n",
    "assert all(df['digitized_text'].apply(lambda x: len(x) == max_len).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129/129 [00:14<00:00,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16512\n",
      "113\n",
      "118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_id</th>\n",
       "      <th>c_seq</th>\n",
       "      <th>p_id</th>\n",
       "      <th>p_seq</th>\n",
       "      <th>prereq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bio110</td>\n",
       "      <td>[1, 0, 0, 0, 121, 96, 0, 0, 234, 235, 1, 236, ...</td>\n",
       "      <td>cs046</td>\n",
       "      <td>[2, 3, 0, 0, 4, 0, 0, 0, 242, 243, 3, 31, 244,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bio110</td>\n",
       "      <td>[1, 0, 0, 0, 121, 96, 0, 0, 234, 235, 1, 236, ...</td>\n",
       "      <td>cs101</td>\n",
       "      <td>[2, 0, 0, 0, 122, 123, 0, 0, 36, 247, 122, 123...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     c_id                                              c_seq   p_id  \\\n",
       "0  bio110  [1, 0, 0, 0, 121, 96, 0, 0, 234, 235, 1, 236, ...  cs046   \n",
       "1  bio110  [1, 0, 0, 0, 121, 96, 0, 0, 234, 235, 1, 236, ...  cs101   \n",
       "\n",
       "                                               p_seq prereq  \n",
       "0  [2, 3, 0, 0, 4, 0, 0, 0, 242, 243, 3, 31, 244,...  False  \n",
       "1  [2, 0, 0, 0, 122, 123, 0, 0, 36, 247, 122, 123...  False  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = list()\n",
    "for idx, (c_id, c_seq) in tqdm(df[['id', 'digitized_text']].iterrows(), total=len(df)):\n",
    "    for jdx, (p_id, p_seq) in df[['id', 'digitized_text']].iterrows():\n",
    "        if idx != jdx:\n",
    "            d.append((c_id, c_seq, p_id, p_seq, is_prereq(c_id, p_id, df_prereq)))\n",
    "            \n",
    "X = pd.DataFrame(columns=['c_id', 'c_seq', 'p_id', 'p_seq', 'prereq'], data=d)\n",
    "print(len(X))\n",
    "n_pos = X['prereq'].sum()\n",
    "print(n_pos)\n",
    "print(len(df_prereq))\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10321\n",
      "1    10321\n",
      "Name: c_seq, dtype: int64\n",
      "0    10321\n",
      "1    10321\n",
      "Name: p_seq, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X['c_seq'].apply(len).head(2))\n",
    "print(X['p_seq'].apply(len).head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X['c_seq'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X['w'] = 0\n",
    "X[X['prereq'] == 1]['w'] = .5 / n_pos\n",
    "X[X['prereq'] == 0]['w'] = .5 / (len(X) - n_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_nn(n_words, input_len):   \n",
    "    dim = 10\n",
    "    emb = Embedding(input_dim=n_words, output_dim=dim, mask_zero=False)\n",
    "    c = Input(shape=(max_len,), dtype='int32', name='course')\n",
    "    p = Input(shape=(max_len,), dtype='int32', name='prereq')\n",
    "    \n",
    "    dropout = Dropout(0.5)\n",
    "    c_emb = emb(c)\n",
    "    p_emb = emb(p)\n",
    "    \n",
    "    adder = Lambda(lambda x: (x + 1.)/2., output_shape=(max_len, dim))\n",
    "    c_emb = adder(emb(c))\n",
    "    p_emb = adder(emb(p))\n",
    "    \n",
    "    #dropout = Dropout(0.1)\n",
    "    #reshape = Reshape((1, max_len, dim))\n",
    "    #c_do = reshape(c_emb)\n",
    "    #p_do = reshape(p_emb)\n",
    "    \n",
    "    #seq_reduction = 1\n",
    "    #maxpool = MaxPooling2D(pool_size=(seq_reduction, 1))\n",
    "    #c_max = maxpool(c_do)\n",
    "    #p_max = maxpool(p_do)\n",
    "    #c_ac = Activation('relu')(c_emb)\n",
    "    #p_ac = Activation('relu')(p_emb)\n",
    "    #print(Model([c, p], p_max).summary())\n",
    "    \n",
    "    #axis = lambda a: len(a._keras_shape) - 1\n",
    "    #dot = lambda a, b: K.batch_dot(a, b.T, axes=axis(a))\n",
    "    #merge_layer = merge([c_ac, p_ac], mode=lambda x: dot(x[0], x[1]) / K.sqrt(dot(x[0], x[0]) * dot(x[1], x[1])),\n",
    "                        #output_shape=lambda x: (x[0][0], x[1][0]))\n",
    "    merge_layer = merge([c_emb, p_emb], mode='cos', dot_axes=2)    \n",
    "    reshape_layer = Reshape((1, max_len, max_len))(merge_layer)\n",
    "    \n",
    "    pooling_layer = MaxPooling2D(pool_size=(40, 40))(reshape_layer)\n",
    "    \n",
    "    flatten_layer = Flatten()(pooling_layer)\n",
    "    dense_100 = Dense(100, activation='relu')(flatten_layer)\n",
    "    dense_1 = Dense(1, activation='sigmoid')(dense_100)\n",
    "    \n",
    "    model = Model([c, p], dense_1)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "course (InputLayer)              (None, 10321)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "prereq (InputLayer)              (None, 10321)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)          (None, 10321, 10)     98090       course[0][0]                     \n",
      "                                                                   prereq[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (None, 10321, 10)     0           embedding_8[2][0]                \n",
      "                                                                   embedding_8[3][0]                \n",
      "____________________________________________________________________________________________________\n",
      "merge_7 (Merge)                  (None, 10321, 10321)  0           lambda_2[0][0]                   \n",
      "                                                                   lambda_2[1][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)              (None, 1, 10321, 103210           merge_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 1, 258, 258)   0           reshape_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 66564)         0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 100)           6656500     flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             101         dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 6754691\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nn = get_nn(n_words, max_len)\n",
    "print(nn.summary())\n",
    "#embedded_text = nn.predict(df['digitized_text'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(embedded_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16512\n"
     ]
    }
   ],
   "source": [
    "# np.array([np.array(i) for i in X['c_seq'].values]).shape\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_gen():\n",
    "    idx = X.index\n",
    "    while True:\n",
    "        #sample_idx = np.random.choice(idx, replace=True, size=30000)\n",
    "        pos_idx = X[X['prereq']>0].index\n",
    "        neg_idx = X[X['prereq']==0].index\n",
    "        sample_idx = list()\n",
    "        sample_idx += list(pos_idx)\n",
    "        sample_idx += list(np.random.choice(neg_idx, replace=False, size=len(pos_idx)*3))\n",
    "        #sample_idx = list(idx)\n",
    "        random.shuffle(sample_idx)\n",
    "        samples = X.loc[sample_idx]\n",
    "        samples_y = samples['prereq'].values\n",
    "        w = np.zeros(len(samples_y))\n",
    "        pos_s = samples_y.sum()\n",
    "        neg_s = len(samples_y) - pos_s\n",
    "        weights = len(w)/2.\n",
    "        w[samples_y==1] = weights/pos_s\n",
    "        w[samples_y==0] = weights/neg_s\n",
    "        print('pos', samples['prereq'].values.sum())\n",
    "        print(samples.count())\n",
    "        for i in samples['p_seq'].values:\n",
    "            [int(j) for j in i]\n",
    "        #print('')\n",
    "        #print('')\n",
    "        yield [np.vstack(samples['c_seq'].values), np.vstack(samples['p_seq'].values)], samples_y, w, samples.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos 113\n",
      "c_id      452\n",
      "c_seq     452\n",
      "p_id      452\n",
      "p_seq     452\n",
      "prereq    452\n",
      "w         452\n",
      "dtype: int64\n",
      "(452, 10321)\n",
      "(452, 10321)\n",
      "(452,)\n",
      "bool\n",
      "(452,)\n",
      "Train on 406 samples, validate on 46 samples\n",
      "Epoch 1/10\n",
      "406/406 [==============================] - 328s - loss: 0.6996 - acc: 0.2562 - val_loss: 2.3809 - val_acc: 0.1957\n",
      "Epoch 2/10\n",
      "406/406 [==============================] - 333s - loss: 0.6988 - acc: 0.2562 - val_loss: 2.2924 - val_acc: 0.1957\n",
      "Epoch 3/10\n",
      "406/406 [==============================] - 325s - loss: 0.6988 - acc: 0.2562 - val_loss: 2.2383 - val_acc: 0.1957\n",
      "Epoch 4/10\n",
      "406/406 [==============================] - 332s - loss: 0.6989 - acc: 0.2562 - val_loss: 2.1219 - val_acc: 0.1957\n",
      "Epoch 5/10\n",
      "406/406 [==============================] - 338s - loss: 0.6988 - acc: 0.2562 - val_loss: 2.0689 - val_acc: 0.1957\n",
      "Epoch 6/10\n",
      "406/406 [==============================] - 324s - loss: 0.6988 - acc: 0.2562 - val_loss: 2.0600 - val_acc: 0.1957\n",
      "Epoch 7/10\n",
      "406/406 [==============================] - 325s - loss: 0.6988 - acc: 0.2562 - val_loss: 2.0045 - val_acc: 0.1957\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-1ae000e2a003>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m               \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m               verbose=1)\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1106\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1108\u001b[1;33m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[0;32m   1109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[0;32m    824\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 826\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    827\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    828\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_in, y_in, w_in, x_idx = next(data_gen())\n",
    "print(x_in[0].shape)\n",
    "print(x_in[1].shape)\n",
    "print(y_in.shape)\n",
    "print(y_in.dtype)\n",
    "print(w_in.shape)\n",
    "hist = nn.fit(x_in, y_in, sample_weight=w_in,\n",
    "              batch_size=32,\n",
    "              validation_split=.1,\n",
    "              shuffle=True,\n",
    "              nb_epoch=10, \n",
    "              verbose=1)\n",
    "\n",
    "data = zip(hist.history['loss'], hist.history['val_loss'])\n",
    "hist_df = pd.DataFrame(columns=['train', 'val'], data=data[1:])\n",
    "hist_df.plot(y=['train', 'val'], secondary_y=['val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = nn.predict(x_in)\n",
    "X['prediction'] = 0.\n",
    "X.loc[x_idx, 'prediction'] = y_pred\n",
    "sns.violinplot(x='prereq', y='prediction', data=X.loc[x_idx])\n",
    "plt.show()\n",
    "t = X.loc[x_idx][['c_id', 'p_id', 'prereq', 'prediction']]\n",
    "t[t['prereq'] == False].sort_values(by='prediction', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
