Welcome to CS256 mobile web development. We're here to teach you to apply your web development skills to this, and to this because as you're probably aware the mobile web is kind of a big deal. Most statistics project that mobile web usage will soon over take desktop web usage, so you might ask whats the difference between developing for the desktop web and developing for the mobile web. Well mobile web development is really just normal web development with some additional key considerations and a few additional API's. We're going to assume that you're familiar with the building block HTML, CSS and javascript. The mobile web is also built on these technologies, although we are going to cover some specific advanced features that apply to the mobile space. Of course, there are a lot of additional considerations for developing for mobile. Things like smaller screen sizes and limited network bandwidth and computing power. Well you might think these constraints are a bad thing. In fact, developing mobile first forces you to focus on the key points of your user experience. For example, the Google News experience on the desktop shows a lot of information, but the mobile experience focuses on just the news stories. Pushing all of the secondary information out of the way. You'll learn how to write code that adapts to different screen sizes and also how to make your code work offline. You'll learn how pointer input works on touch screens and how to unlock the camera GPS and accelerometers sensors on mobile devices. Now technically speaking you don't need a mobile device in order to take this course or even to test out most of what you'll learn. But you're missing a lot of the experience of mobile web development, without a device. Preferably at least one Android device. You can use Chrome's great mobile debugging tools. Which we'll be using in this course. But, the more devices you have, and the more variety, the better. Before we get started, I want to be clear about what we're not going to teach you in this course. We're not going to be teaching mobile frameworks like bootstrap, or native app wrappers like PhoneGap. These are great tools, but we want to teach the fundamentals that you as a mobile web developer need to know first. Many of our coding examples are centered around a single conference application, which we put in a GitHub repository. Not every concept fits well in that app, so we'll be using other examples too. We're going to begin with a lesson on mobile development tools, showing you how to hook up the DevTools to your mobile browser. If you already know how to do this, feel free to skip this section. Let's get started. One of the most amazing things about the mobile platform is the incredible array of sensors these devices typically have. This phone has a camera that can take stills and video, has audio input and output, it has a GPS, a compass, a tilt sensing accelerometer. Far more sensors than a desktop or laptop typically has. And all this, in a device that I'm typically holding in the palm of my hand. This enables the mobile platform to play host to incredibly engaging and interactive user experiences. Let's start by talking about the camera. Now the camera is not just for taking pictures of your kids. The camera can be a great way to get quick input into the mobile device. For example you can snap a new profile picture or capture a QR code to transfer a hyperlink, or capture a map or a business card. There is a simple way to get access to the camera and the audio input, the capture extension on the accept attribute on the file input element in HTML. This will give you a button that opens up the system camera or Audio recorder app on a mobile device. However there are some issues with this approach. Can you think of some problems with this approach to camera and audio input? Well the first problem is that this feature only works in mobile, not in desktop. On desktop, you only get the normal file open dialogue. Not access to the webcam. Secondly, the interface is a file open button, which is hard to style and make look the way you might want it to. And finally, taking you to a different application to take a picture or record some audio, makes it kind of hard to keep a consistent flow in your application. We can get Live Input, Audio and Video, directly under our App by using an API called getUserMedia. This is a simple example where we just call getUserMedia, passing some constraints that say we want video, and then we assign the resulting stream to a video element in the page. Of course, this just gives us a rectangle with live Video Input. We probably want to do something with it. If we want to grab Snapshots like if we want to implement a Camera Application, we can do this with a canvas context and DrawImage. Whenever we want to take a Snapshot, we simply grab the image from the video and we draw it to the camera with DrawImage. Of course a canvas in different than an image. You can't directly copy a canvas and paste it somewhere else, or download it your hard drive or post it to your social networks. Or any of the other typical User flows centred around images, but it turns out, canvas has a handy function to encode itself as an image. The canvas toDataURL method. Here, instead of displaying the canvas itself, we're copying the canvas contents as a data earl to the source of an image tag. And if you want to save these images to the Mobile's local storage, you can do that, too, by forcing a download of a link using the download attribute on an anchor element. This isn't really downloading the data per se, it's encoded in the link itself, so you're not really transferring things over the network. So let's use these features to implement a profile picture taker in our Conference app. I've included the framework for a camera control in the Conference app already. You'll need to fill in the interesting bits here. First, here's the code that gets called when the user starts up the camera. And right here, you need to fill in the code that asks for access to the webcam. Note that we've already set up constraints for you. And you have success and error callbacks defined down below. Fill out the code for this function right here, now. Great. We just need to call navigator.getUserMedia and pass at the constraints object and the success and error callbacks. And we're ready to go. Now let's move on to the success callback. We've already put in a call that creates a user interface for us, and it returns a video element which we can hook the webcam stream into. How do we associate the stream that were passed into that video element? All you have to do is set the video source attribute to an ObjectURL that you create, from the video stream. Now let's jump down to the snapshot function. This function is called, when the user clicks in the video to take a snapshot. We need to copy the current video image to the canvas context, which will be displayed to the user for us. What should you fill in here? That's right, all you need to do is [UNKNOWN] drawImage on the canvas's context, and give it the video element and then a zero zero offset. Okay, now, the last bit. The useThisImage method is called when the user has decided they want to, well, use the current image. So we need to call the callback that they provided. But we need to hand them back the image as a data URL. Let's presume that you want the image/png media type. What code should you fill in right here to get that data URL? Great. That's right. Canvas has a very handy, toDataURL method that essentially screencaps the canvas. Now you have the idea of how to easily incorporate live camera images into your applications. One final bit on camera access. Of course on a mobile device, that typically has a front-facing and a rear-facing camera, you're going to want to select which camera to use or let the user select it. There's a way to do this with get user media using the MediaStreamTrack getSources api. This api will return a list of IDs that you can then pass into get user media. And that lets you choose which camera to use. As you can tell on my phone, I have two cameras to choose from. Now you may have noticed, one of the annoying things about using input this way, is that it's distracting to have the address bar on the screen when I'm taking a picture. One thing you might want to do is take your app full screen. This is pretty simple to do. Just grab the dom element that you want to make full screen, that you want to be the root of the window and call its requestFullscreen method. Now, at the time of this recording, requestFullscreen is still vendor prefixed, so we'll have to use webkitRequestFullscreen and mozRequestFullScreen. One important thing to notice here is the difference in capitalization. Kind of annoying, but it'll get fixed sooner or later. One important thing to note is that you can only call this API in the handler for a user action. Like, clicking on a button. This is to avoid apps forcing users into full-screen mode. You can't just do this when you're loading the page. Now that our app is full-screen, what else might you find distracting about the input expereince from a user perspective? One of the most aggravating things about input on the mobile web platform is the security prompts. One of the early challenges of the sensors of the mobile web platform was the security sandbox that's inherent in the web. Most of the sensors do require permission, but you can frequently limit how many times the user is prompted by using https instead of http. Usually this means they'll only get prompted once and the system will remember it after that. Keep in mind, there's more that you can use the camera for than just profile pics or vintage camera effects. For example, here's an app that uses a JS library to do live QRcode reading, or here's another one that transcodes the live webcam image into ASCI art I also want to briefly talk about audio input. Now this subject is near and dear to my heart. I've spent a lot of time working with a web audio API, on desktop as well as mobile, and audio input is a killer feature. Git user media, is also a bridge to audio input. This means it's relatively straightforward to input a voice memo recorder, or voice processing, through the web Audio API. Now, the Web Audio API is a pretty huge subject, so we won't really be going into it in this course. For more on the Web Audio API, check out HTML5 rocks. Or webaudiodemos.outspot.com. I did briefly want to mention though while we're on the topic of audio, mobile devices typically prevent audio from auto playing. Audio elements need to start playing in response to user input, like the full screen call we talked about earlier. On Safari, web audio is also the same. You have to create the audio context in response to an input event. So let's talk about some other sensors. Obviously one of the most useful sensors on the phone is the GPS. I love never having to ask for directions. Let's take a look at how we integrated Geolocation into our Conference app. This is a simple example of the Geolocation API, you call getCurrentPosition and pass it a call back and the call back is called when it gets your location and gives you your latitude and longitude. There's also a very similar watch position call, which does the same thing except continually calls you every time the position is updated. Let's walk through how we use this API in our conference app. First, we added a button to the map page that triggers the Geolocation procedure. When this button is pressed, the triggerGeolocation method in our code is called. This code is the heavy lifting of the triggerGeolocation method. This uses the HTML5 Geolocation method API method, getCurrentPosition. And passes it a success call back and an error callback. It also enables high accuracy and sets a time out. In case of failure, we print a generic, Sorry, we couldn't find your location. On the other hand, if we succeed, we call a method called elaborateDistance. ElaborateDistance uses the root method from the Google Maps direction service to obtain an object containing information about the route between the user's position and the venue. It then displays some of this information and allows you to open up Google Maps with the route already set. Obviously, this is frequently the way that you'll use Geolocation data, that is, passing it off to another control. Most of us don't, write code that uses this latitude and longitude directly. It's important to note that geolocation isn't just about your position on a map, it's also incredibly useful for location aware presentation. For example, for a website for a chain of stores, right in the front page you can show what the closest store is to the user's current location. And what their current hours are. This is almost certainly exactly what the user was looking for when they navigated to your app. You don't have to bury it under a store locator link. You can certainly do lots of other things with geolocation, too. You could use geolocation to implement a geocaching game, for example, or to do augmented reality. But Geolocation has many uses that just make the user experience better by better integrating with the real world environment. Mobile devices typically have a high quality accelerometer. This sensor let's us determine which way the device is tilted, as well as its compass direction. There are two different APIs for this: device orientation and device motion, both of which are really interesting. Device orientation tells you which way the device is tilted and which way it's pointed. This can be useful for implementing a virtual joystick for example, or implementing a compass. Device motion gives you events and information about what forces are being applied to the device. Which makes it easy to tell if you're shaking the device but it also lets you include and exclude gravity. This means it can tell you how the device is oriented too. It's really a strict superset of device orientation but it's a bit more challenging to use in that way. So given these descriptions in which of these scenarios do you think you would use device orientation And in which would you use device motion? Or remembering, that I said that device motion, is, a strict super set of device orientation. Anything, you can do with device orientation, you could do, with device motion. However, it's going to be easier to implement things like a compass or a joystick, using device orientation rather than device motion. However, if you want to implement shake to send feedback, you really need the acceleration, sensing that device motion offers. And for a generic game controller, rather than just a joy stick, you might find device motion, is interesting. For example, the roll it game, that we demonstrated at IO used the acceleration rates, from device motion and that way you could tell what speed the device was moving and in which direction. So, it made it really easy to throw a ball, with pretty good precision. One major difference, between, these two APIs, is how often they're fired. Device orientation, is, only fired, when the device orientation changes. For device motion, it's fired whenever, the acceleration changes, on the device, which includes lateral movement. So, it fires pretty often. Let's take a quick look at how we would use Device Motion to implement another common mechanism, the shape to send feedback feature. Detecting a shape is actually pretty easy, we just register an event listener for device motion and inside are event handler. We calculate the squares of all of the accelarations in all three directions And then test to see how big that absolute sum is. If we get a large value here, we know we've hit a shake, so we can demonstrate that on the screen. If we wanted to be fancy, we might want to sum these values over an interval of time, so slower motion that goes on for longer would still trigger it, or we might want to add rotation into the sum. But in practice this will work pretty well. Let's take a look. There continue to be new APIs added to the web platform, as well. For example, there's an upcoming API that adds haptic feedback to the web, the vibration API. This API is currently available in Firefox and coming soon in Chrome for Android. This enables you to use the mobile device's shaker device. To buzz in the users hand, just like when you have your phone set to vibrate and you get a call, this can be really useful for letting the user know something is happening ,particularly for errors or notifications. With all of the sensors available it can be tempting to use all of them, all the time. This can be a bad idea. Geolocation in particular can be power hungry, so if you use it constantly you may drain the user's battery. I hope this lesson has opened your eyes to the possibilities of incorporating device access into your applications. To make truly compelling user experiences. On a mobile platform, you can't always assume that your users are going to have a good network connection. Or any network connection. It's important for your web app to still work even if the cell signal gets dropped. In this lesson we're going to take a look at how you can treat the network as a potential enhancement to your application, rather then a requirement. We want to take, an offline first approach to building web apps, where your app can work offline by default. Don't be fooled, into thinking offline, can be an afterthought, just because we left this lesson to the end. Offline support, in the web platform, is a very complex topic, which is why we saved to the last. But first, let's define, what offline really means. There are a number of different scenarios, that can cause someone to be offline. These typically boil down, to not having a radio or Wi-Fi connection. But, not all of these scenarios, can be detected, by making a connection attempt. It's good to keep this in mind and all the more reason, to build apps, that treat the network as an enhancement. For example, let's take a look at a hypothetical set of situations. Which of the following scenarios on a computer with only Wifi can you detect without trying to make a network connection? Can you detect if you have no connection to the router at all? Can you detect if the router has no internet connection? Or if the router has an internet connection but no DNS service? Can you test that the router has a connection, but a proxy server is blocking a particular site? And can you test whether the router has a connection but your web server is down? The correct answer here is, only the first scenario can be detected without making a network request. In fact, this is a really important point. The browser can't really tell that it's definitively online. It can't tell that it's definitively offline either, unless it really has no connection to another device at all. In fact there's an attribute, navigator.onLine, that supposedly tells you whether you're online or not. There's also a pair of events that fire up the body of the document when you go online or offline. However, I don't recommend relying on these, they really just tell you if there's a network connection or not, they don't tell you if that network connection is actually connected to anything. For example, my computer at home is occasionally fooled because my cable modem will go out, but my computer is still connected to the router. Sometimes, computers or applications will use pings to various servers to tell them if there's a connection to the internet. But fundamentally, as a developer the only offline status that matters to you is can you get to your own servers, and of course in the cellular radio case it can be even more complex we've all had the experience of having a one bar signal. And trying to use the network. In fact, this is a critical point to offline use, and why we say you need to build offline first. You might think the way to support offline is to use the network first and then if it fails you can rely on the cash, but that doesn't really work in the real world. Precisely because it can take a long time to determine, if you don't really have an internet connection. If you only offer cache data once a network request has difinitively failed, you leave users waiting while their device desperately tries, but fails to actually transfer data over the network. This is what we mean by offline first, not that you should code offline first, but to underscore that your app has to be able to use cache data first. And then update the cache contents when it's online, but continue to use old data from the cache when it's offline. So the first major component we're going to dive into to help, is the HTML5 Application Cache. This lets you provide a local cache of HTML files, CSF, JavaScript, images, any other resources your client webapp may use. And get the browser to use them even before it tries to hit the network. So let's take a look at how this works and how we can use it. The application cache is a manifest that you point to from inside your HTML element. Let's take a look at the cache manifest for our conference application. The manifest starts with a magic header, cache manifest Lines that start with a hash sign are actually comments. Typically, the second line is a comment with some kind of cache version string. More on that later. But this is followed by a cache section. Now what do you think goes in the cache section? Should it be every file that's on the servers file system? Every resource that can be statically served, or should it be a collection of cat videos? That's right. Only files that can be statically served can go in the CACHE section. If the file needs to be interpreted by the server, say, a Python script, it really can't go in the cache section. Now, if your application is a collection of funny cat videos, of course, you may have some of those in your application and in the cache. But keep in mind that some implementations have limits on the size of a single application cache. Sometimes that limit is as small as five megabytes. So, that might not do Fluffy justice. Now, the network section of the cash manifest contains files that explicitly needs a network connection. Foe example, we can't really cash the google-analytics page because the connection is important. If you have a image resource that's a live webcam image or some other kind of data that has to be loaded over the network, putting that resource in this section will bypass the out cash. And try loading the resource from the network, even while it's offline. And finally, the Fallback section is where you set up alt cache alternatives for resources that need to come from the network. For example that live webcam image. Maybe you want to cache an old version of it. The browser will use the rules in this section to load an alternative. But only after trying to load the resource from the network first. For that reason you should use the Fallback section sparingly because it will await for a network timeout. So let's take a look on how to implement app cache, in our conference application. First, we go into out HTML file, and we add the manifest. In our manifest file, we list in the cache section all of the static resources for our application. Our javascript files, our CSS, our favicon. All of the images we need to use. But, note one file that's missing. Our index.html. Any page that points to the manifest, that's, that has that magic manifest equal in the html element, is implicitly cached, which can very easily got out of control. It's kind of hard to get them out of the cache once they're in it. Which is why we're only using the manifest attribute, on this one page. Note though, in the NETWORK section, we put the google analytics javascript file and all the maps api serves. We can't really usefully cache these API servers. So, we'll have to be online for now. Now let's go back to our app, and with the Devtools console open, let's reload and see what happens. You can see in the console, a whole bunch of application cache messages. If we go up to the top of this, you can see it's creating an application cache based on this file. It checks that, and then it starts downloading all of the resources that are inside that manifest. When it completes, it sends us an event that says the application cache is cached. Now, if we reload the page again, we get a much shorter set. This time it says, the document was loaded from the application cache. It tells us where the manifest is. It checks the cache, but there's no update ready, so it doesn't bother doing anything. Now let's take a look at one of the hardest things to deal with, with working with the app cache. The fact that you have to remember to update the application cache. Let's say, we change something in our file, let's add a title. Now, let's save this and go back and try to reload again. Now, you'll notice that even though I saved the index.html file Nothing happened to the cashe. It's because the only thing that was checked was the cashe file, the manifest, and we didn't touch the manifest at all. So let's go back and do that now. So in the manifest, we need to do some actual change to the file. We can't just touch it with the command line utility touch. That actually won't trigger a reload. So let's just add a version number hit save and now let's go back and reload again. This time you'll see again we've downloaded the cache. But remember what we are seeing here, what the user is seeing here is not actually the new content. It loaded it from the cache. And then updated the cache, not in real time, that way the user gets the content immediately, while they still get updated content. Now we can listen for the event on cache updated, and the cache update event will tell us that the user really needs to pick a good time to reload. We could surface that by popping a dialog box that says, Hey, this application is updated. Do you want to reload now? But, that can also be postponed, and you can just presume that the user will get a new version, when they hit refresh again. If I hit refresh one more time, now it's pulling it from the cache again, and I have the updated content over here. So you might ask, how did I get this list of files that I used to my manifest? I could just list every file coming from a directory listing from my server. But I don't want to grab things like Python files. So, the easiest thing to do is to get files that you know you're going to need, like the images I knew were referenced. And the JavaScript files. And then walk through one at a time and see what happens when you try to run the app from the cache. Let's try this now. Let's take a couple of these files out and see what happens. Let's save the manifest file, and go back and reload. Now remember, even though we downloaded a new cache here, what we're looking at over here is not that uploaded content. We need to refresh one more time. And now you'll notice that when I try to get this file from my application, it just fails. Now, if I had put in my manifest file under the network section, star, that would mean anything could come from the network. I find it's a useful trick to not use network Star because then you can see what's failing. Another important distinction, is that any file you put in the cache, has to actually be downloadable. If I put something in here that doesn't actually exist, and then try to update the cache again, you'll notice that I get a resource fetch failed event. And the problem is, this means that the cache is not being updated. It doesn't just fail to cache that one file. It doesn't update the cache at all. This is to make sure that sets of resources can be managed together. But be sure to watch the console log and make sure that you're getting the right things. The important poitn here is that the app cached contents are used immediately, even when you're online. The design of Appcash is offline first. The user gets content immediatly, rather than having to wait for the network to respond. With all of this in mind, what do you think the biggest challenge of developing with the Appcache system is? Is it that you have to reload constantly? That you have to keep touching the manifest file? Or that you actually have to change the manifest file, with every resource update? Now, if you chose that you have to reload a lot, you must not be used to developing on the web, you always have to hit reload a lot. But if you chose the second option, you missed a subtlety of what I said, you can't just touch the manifest file, you actually have to change the bits in the manifest file, with every resource update. The challenge becomes, that every time you update any of the files in your system, you have to update the manifest file as well. So ,even if you're just tweaking a bit of CSS, you have to change the manifest file as well in order for it to reload. And that's why I said it's really common to have a version string in your manifest file, and you keep updating that version string. This can be quite a pain, but it isn't too hard. So once we have an app cache on the user's machine, on every subsequent load, the resources will be loaded from the app cache, even when you're online. If it's an HTML resource with the manifest For example, that master page we started with. Then we'll start an async update of that manifest file at the same time. And then continue loading the rest of the page. Now, if the manifest has been changed, the browser will update the files in a new application cache. But remember, it's already loaded the page. It may be done loading a page by this point since we do want to be offline first and we want to make sure that the page gets loaded as quickly as possible. By the time the manifest file has been downloaded in the background, the user is probably already off looking at cat videos out of the application cache. Now, you can detect when a new cache has been downloaded and there's new content available. You can listen for an update ready event on the window application cache object. The window application cache represents the application cache system. And you can get things like the status and progress and tell it specifically to do things like update the cache or swap the cache out. So you have a lot of control over the application cache. This code here checks for an update ready event, and if there is actually an update ready, then it'll actually ask the user, is it okay to reload this. And if so, it swaps the cache out and reloads. Now it's important to understand how the application cache works together with the http cache. When we say that the cache is downloaded or Appcache updates the files of the cache, those downloads are still following the rules of http caching. If those files are already in the http cache, they may come from that cache rather than over the network. You can still use far-future caching, for example, on files that you know won't change often, and when the Appcache update system needs a new copy of them, it'll pull them out of the http cache, not grab them over the network. This gives you a two-stage updating system, which can be pretty useful. However, there is one file that you should never far-future cache. What is it? The master HTML page? The manifest file? Or cat videos? That's right. You should never far-future cache the manifest file itself. Cat videos, of course, never go out of style, so that's fine, but if you far-future cache the manifest file, you're going to have a really hard time getting the user's system to update the cache. Your users will get locked into that set of cache files. Unless the user specifically goes in, clears out their cache, the manifest file will never be re-downloaded. So now we've talked about how the cache works for updating normal files from the cache. Now the whole app cache system is actually very complex. It's a very complex algorithm that the browser goes through to get files out of the cache, figure out whether it should update the cache, check the different sections in the file. We do want to talk briefly about the network section for files that always need to be loaded from the network, so let's go take a look at that. The network section was supposed to make it easier to build applications that were occasionally online, but it turns out that's pretty hard to do. As we talked about before, it's hard to answer the question definitively if you're online or offline. One common thing to do is in the network section at the bottom to put a star, or even just to only have a star here. This basically means anything that anything we haven't specified already further up in the application cache in the cache section, you should just go to the network for. This is actually isn't a great thing to do. If you have any blocking resources in your file, or in your application that haven't been listed in the cache file, it's going to sit there and wait until it times out. So what you should really do, is develop without that network star. Even if you add it later. That way, your cache updates in the console will actually show you if you're missing files. Now that our application logic and our resources are stored in the app cache, let's talk about how we store data locally. There are several different ways to store data locally, many of which have developed over time. So let's cover each of these briefly. Local storage is the oldest and most basic of the storage APIs. It lets you get and set key value pairs and iterate through all the keys. However, each value is just a string and each domain can only store a total between two and five megabytes in local storage, depending on the browser. There's no real searching capability. You can index through all the keys one at a time, or you can ask for the value associated with a particular key, but that's basically it. The local storage API is really simple to use, take a look at how you can store an item using setItem, retrieve the value for a particular item with getItem. You can remove one key value pair with removeItem, iterate through all the key values pairs with length key and getIitem or clear the entire local storage system. To see the key value pairs that are stored for a particular site or scheme host port combination, you can open up the chrome developer tool, go to the Resources tab and select Local storage. Note that there is Local storage which persists across reloads and sessions storage which has the same API but it's isolated by tab and it's cleared at the end of the session. So whenever the page is closed down, the Sessions Storage goes away. Now, remember, you can only store text in local storage, so if you wanted to store an image or some other binary data type, you'd have to first base64 and code it. And of course, you only get typically about 5MB per domain, so you're not going to be able to store very much. So now it's your turn. Use local storage to store the value "bar" for the key "foo" Great job. It really, is just that easy. Local storage is widely supported across browsers. But as we pointed out it does have some down sides. It's a great way to get simple storage for persistent data like user settings, or users profile strings. But, you really don't want to try to use it store complex data, like binary files or structured data. For that, you'll need a more complex storage system like WebSQL or IndexDB. WebSQL provides a sequel light based database directly in the browser. You can use sequel queries to access data and to find relationships. And ,you can have structured data in your value storage as well. Now, this is significantly more complex. Than the simple and limited key value storage and local store. However, there's two main problems with it. The first problem is, although this API is available in Chrome, Safari, and Opera and IOS Safari in the Android browser, even, it's not available on IE or Firefox. The second problem is clear from the specification, which is no longer being maintained. In short, web sequel is a dead end. It's out there in Chrome, the Android browsers, Safari and IOS Safari, and Opera. But, it's not available in IE or Firefox ,and it's likely that it never will be. So, what should you use if you need a complex data storage system? Well, there's one more system, the Indexed Database API, also called IndexedDB for short. Indexed Database was designed in response to Web SQL, and its SQLite variant. Indexed Database is not a SQL API, it's a simpler index storage system, on which you can build an optimized query implementation, like a, a SQL variant. This means it isn't optimized to a particular query system. Instead, when you create your database, you define what indexes you want to use. If you've never done database storage before, IndexDB may take a little bit of getting used to, but it's actually pretty straight forward. The spec itself has some really good examples in it. This code is based on the spec. FIrst, you need to open your database and you need to be prepared to initialize the database if it hasn't been opened before. When you initialize the database, you can define the indexes in the database, that is, what attributes are easily searchable. You can change this later too, you just have to upgrade the database. And of course you can inspect the databases in the developer tools to see what's going in to the IndexDB store. And check to make sure it's organized the way you want it. Just go into the Resources tab, select IndexDB, and there you go. You can see your objects right there. If you expand them, you can even see the values. So why should you use IndexedDB over Web Sequel? Well, the good side is that IndexedDB is supported in Chrome, including Chrome for Android, as well as Firefox, IE, and Opera. The downside is that, it's not supported in the old Android browser or in Safari. So, there are going to be a bunch of mobile users out there that don't have IDB support for a while. Of course, there are a bunch of mobile users out there that aren't going to have Web SQL support either. So what's a web developer to do? Well in general, I like to recommend trying to do the right thing, but pragmatically making it work in tough situations. The answer here is write to IndexedDB, but use a polyfill so it will work on Web SQL browsers. A good polyfill to use is the IndexedDB shim. There's a link down in the instructor notes. Writing your code this way, you can write good IndexedDB code, but it'll still work on Safari, or other browsers that don't yet support IndexedDB. But let's bump up a level, and talk about what you might want to use local storage to store. As I mentioned before, you probably want to use it to store user settings. But, any data that may be useful in a different session of your application, is probably useful to cache in Index DB or local storage. Finally, an important way to think of this, is any time you call a network API, you probably want to cache that response, in index DB or local storage, so you can get it back later. When you're offline, this can be particularly useful, because you already have the data from a previous session cached. In our conference app, for example. Each of the data models is being loaded from a JSON file on the server. In the original incarnation, these files are loaded every time they're needed, just relying on HTTP caching to minimize the network transfers. When I initially made an app cache for the conference app, I just app cached the JSON files, since of course they need to be there to run the application. However, it would make more sense to cache the data here in index database, for a couple of reasons, first, it can do index lookups so I can have a table for speakers a table for sessions have them easily cross reference items in each of them. And make it easier to search for an entry. Secondly, we can get the structured data directly out of the database rather than having to [INAUDIBLE] text file each time. We can then provide a synchronization system, that occasionally makes network requests, to refresh the data objects. Or updates on load or when an unrecognized speaker is found. One final reminder, though. Keep in mind as you design your application, that if the user clears their data from the machine, any data stored locally is going to be deleted. So, you shouldn't store the only copy of important data on the client. Local storage is really just intended to be used as a cache. As you can see, there are a lot of complexities in making offline capable web applications. The key thing to understand is that in a mobile World offline is not a feature it's an necessity, you need your applications to work seamlessly regardless of network conditions. Congratulations on completing the course. We've covered lots of material in this course and there's lots more that we couldn't get to. Mobile web development is a huge topic and you're probably wondering where to go from here. Now that you understand the basic concepts, you probably have questions about things like scaffolding and getting started, which libraries to use and how to deploy your applications, how to really incorporate this knowledge into your day to day work. To learn more, you can visit HTML5 Rocks, follow Chrome developers on Google Plus, and check out the chrome channel on Google developers live for more information on dev tools. There are many handy tools out there that can further streamline your development workflow. Yeoman and Grunt for example allow you to scaffold and easily build your projects. There are also many frameworks you can use to build your app, many of which are mobile-friendly if not mobile-focused. We've placed links to some of the more popular ones in the instructor notes here for you to check out. If you want to be able to place your app into one of the mobile OS-friendly app stores, you're going to need to use one of the app wrappers out there, like PhoneGap, which lets you take your HTML5 app and turn it into a native app, that can be deployed on many platforms. There are several app wrappers listed in the Instructor Notes here too. Thanks for taking our course. Now, go build, mobile web awesomeness. You're still here? It's over, go home. Go. In this lesson, we're going to be discussing the Chrome developer tools, which enable you to analyze and debug, your web applications. Peter's, going to tell you more about them. Now you may already, be familiar with the dev tools. But, what's really exciting, about them, is that you can now, easily ,use these tools, for your mobile debugging. Let's get started. On any given page, like this one, you can open the con developer tools by clicking on the shortcut listed in tools, developer tools. As you can see, Chrome def tools provides a series of tabs that allow you to debug and inspect your web apps. For example you can select any element on the page by right clicking the element and selecting inspect element or as I'll do here you can click on the magnifying glass and hover over the area that you would like to inspect. Let's take a look at the un-ordered list of floor selectors. Let's change the text in one of the floor selectors. We can do that by simply expanding the element that contains it and then editing it live on the page. You can also make live edits to the CSS. Let's take a look at changing the selected floor class. Here, I can set the background color to whatever I want. For example, blanched almond because who doesn't like blanched almonds. Because the background color is now pretty light, we may also want to change the text color. Chrome Depth Tools provides a handy color picker for that. We can pick any color we want. [SOUND] Shift + clicking the color picker, allows you to cycle through the different color schemes. RGB HSL, and so on. If we scroll a little bit further, so our floor selector class, we can play around with the different settings there. You can use the scroll wheel to cycle through the different sizes. And we can set the border width in a similar fashion. As you can see, Chrome Dev Tools provides with rich functionality to edit and inspect your pages. And than was just one tab. We'll be diving deeper into the Network, Timeline, and Profiles tabs with Colt McAnlis in the performance lesson, and we'll cover the Resources tab in more detail in the lesson about offline and storage. You also want to make sure you're set up correctly to debug and profile your web apps on mobile. We're going to show you how to do that with chrome dev tools and chrome for android. The set up is simple. All you need is an Android device, a USB cable, and your development machine. Let's take a look. Before you get started you need to turn on the Developer Mode in your Android device. This may be different on any given device and you can check your device's manual on how to do this. In many cases though, you need to go to your device's settings, click on About Device and then click on Build Number seven times. Seriously. Next you'll want to turn on USB debugging Again, this varies slightly on your given device, but this is usually located in the developer options. We also need to make sure we have the right tools [UNKNOWN]. On my laptop, I have Chrome Canary and on my mobile device, I have Chrome Beta installed. Now that we have everything set up the way we need, open Chrome on your development machine and go to Chrome inspect. Make sure the site you want to debug is open on your mobile device and then connect your laptop to your mobile device via USB. Then confirm that you want to allow USB debugging. Back in our development machine, we can see a list of the attached devices and the Chrome tabs that are open on the devices. You can even open other tabs. We can also focus on specific tabs, you can reload them And you can even close a tab. The best part of course is that you can inspect the pages that are running on your mobile device, from your development machine let's take a look. One of my favorite new features is the new screen cast mode. This allows you to drive the experience on your mobile device from your development machine. You can click on links, and see them update simultaneously on the device. As well as on your desktop. As you can see, you have all the familiar features from the development tools available for mobile now. Now all of these examples, we're accessing a live site. But you can also setup Port Forwarding to allow your mobile device to access a local server on your development machine over USB. Let's take a look. To do this, you want to make sure you have a server running on your local development machine. In this case, I'm going to use Python's simple HTTP server on Port 9999. Now to verify that it is actually working, I'm going to access that on the local machine and it's working fine. If I want to now access that same page on my mobile device, I need to set up Port Forwarding. I can go back to the Chrome Inspect page, click on Port Forwarding and set up a port forwarding rule. In this case, port 9999 on local host or IP address 127001. I enable Port Forwarding and click on Done. When I refresh this page, you'll see that Port Forwarding is now running on Port 80 80, and 99 99. At this point, we're all set up. So let's try it out. I'll open a new tab, navigate to localhost 9999 on the mobile device. And voila, the page is ready to go. Now, that was really easy and it's also possible to do this on mobile Safari with the web inspector using the iOS web kit debug proxy. Now, that's a little bit harder to set up, so check out the link below for more information. Now that you are equipped with the right tools we can get to work. In the next lesson, we're going to get started with a mobile user experience. This lesson and the following ones are designed to give you the tools that build designs that scale across multiple devices. And one of the first challenges with developing for the mobile web, is the display screen. The typically small display screen compared to your desktop or laptop device really forces you to focus on what's critical for your users, in fact this is what's led to the recent adoption of the mantra mobile first. Now, mobile first isn't about designing for the mobile web before you even think about the desktop experience. It's really a design philosophy of stripping down to your core user experience and then layering additional gravy on top if you have the appropriate space. For example you might put your company info links inside a menu rather then cluttering up your home screen with them. When creating a visual design layout, it's tempting to think of your design surface like a canvas, a fixed surface. Now web design used to be like this. You drew on this canvas, it was a fixed size and shape, just like an artist draws on a canvas. What do you think the problems with this will be, as you move to a mobile first design. Fundamentally, the problem is all of these. With a layout that's designed for a particular screen size and aspect ratio, the user is going to have to zoom and scroll around in order to see everything and there will frequently be blank space left on the screen When Mobile browers first came along the content on the Web wasn't designed for narrow small screen devices. It was designed for Windows that were around 1,000 pixels wide and wider than they were tall with easy scrolling. To Shoehorn this content into a tiny Mobile screen since rendering a Web Page designed for 1,000 pixels across and a 320 pixel wide screen would mean you'd be scrolling a lot. Mobile browsers basically lied about the Window width. They made the Window act as if it were 980 pixels wide, even though the original iPhone was only 320 pixels across. This enabled sites that were designed for a 1024 by 768 screen, that is, that were around 980 pixels wide to fit on the Mobile screen. Although you needed to a do a lot of Zooming to read the text sometimes. Unfortunately if your site did not happen to match that 980 pixel width you were either going to overflow or underflow the screen. Either wasting space or forcing the User to Zoom. In order to control this, Apple provided a viewport meta tag to be added to your HTML to control the default For how big should my screen act on this page? The default is 980. So, if you put 980 here, it would have no effect. The Mobile browser already defaults to 980. But setting a viewport tells the browser how wide the content is intended to be, and then the browser scales to make that size fit on the device's screen. There are two ways to use this tag. The first way lets us take a page that was designed to be precisely one size. This is an application I built that's using a fixed layout, and it's a bit smaller than default. It's 916 pixels wide. Notice that it's not using all the space on the screen because the browser by default is assuming the layout wants to be 980 pixels wide. So let's a viewport that tells the browser it was designed for 916 pixels across. What would you put in the viewport to tell the browser that this should be 916 pixels? Now the mobile browser will automatically scale that width to fit on the screen, no matter what size screen the user has, or whatever device width the user has. Let's take a look at this app across a few devices with different width screens, an iPhone at 640 pixels across and a nexus 7 tablet in landscape, at double that width 1280 and note that it rescales properly on both of these devices. Note this takes into account orientation as well. The default scaling is to available screen width, so it will properly adjust when you flip the screen. There's also a height property on viewport which you could use instead of width, to control the scaling based on the height, but of course, most designs are built as width primary. That is, they're designed to scroll up and down. Although typically View-port is only being set on Load, you can actually play around with the View-port settings in the development tools to tweak it, and get it just right. If I go into the page and set the Viewport meta element contents from the mobile dev tools It will change the page, as if it had been refreshed, however, and this is where it gets a bit confusing, the zoom level is maintained by the browser across pager refreshes, so when you change viewport settings in the source code, and you're reloading, be sure to actually close the tab first. Don't just hit reload or it won't necesarilly show the effects on the screen. For example, let's go back to our last bit of code. And change that width to something really different. Let's double the width to 1832. And now let's save that to the server and reload it on our mobile device. Our new View-port setting doesn't take effect. On the other hand, if we close the tab first and then reopen it, our new View-port setting now takes effect. So pro tip, always remember to close the tab. So a fixed width lets you tell the browser what width your webpage was designed for and the browser will automatically scale that width to fit to the screen no matter what size screen the user has or what device width the user has. Now what would be some of the downsides or side effects of using a fixed width view port? It is true, that using effects with viewport, means that your content, is almost always going to be scaled, and not match the native resolution. And definitely, in some cases, users are going to have to zoom, to be able to see or read anything, particularly text. Since, everything, all scaled depending on the size of the screen, fitting the current layout, precisely, into the users screen. Whether, it's a four inch phone or a 12 inch tablet, but actually, your text in UI will not change at all on the desktop. Because, currently, at least, none mobile browsers, don't respond to the view port at all. In some cases of course, it's the right thing to do, if you just want to get the UI to fit on the screen, to use, fix with view port, like in my sync app, but of course those dials are awfully small, which makes the UI very hard to use. So let's talk about how to make truly scalable pages. Now, HTML, by default, is supposed to reflow text anyway. And text sizes are supposed to be consistent. But the worst side effect of this viewport stuff, by default, is that, even with nothing set, the mobile browser is going to reflow text and render as if the window were 980 pixels wide. And then scale it to fit it on to the screen. This may mean that the text looks really small on my mobile browser by default. So, the second way to use viewport is if your page knows how to adapt to width. For example, if it knows how to wrap the contents based on the screen width. You can simply the width to device width which tells the browser, my website knows how to adapt to your width. This is really the best approach. To build applications that scale their own layout and make intelligent decisions about how to do so, rather than just trying to scale a fixed layout to fit the screen. So let's try this out on this page. Let's add a device with meta element to our Lorem Ipsum page, and refresh it on the mobile browser. This is what our page looked like before. Now with the meta tag in place. Let's try reloading it. And you can see, the page now chooses a better size because it's reflowing at the native size of the screen. I did want to mention at this point that there are other viewpoint controls. There's an initial scale property that lets you set what the browser's initial scaling factor will be. It defaults to one and usually, you don't really want to mess with it. If you change it to another number, this changes the initial zoom factor. And the user will probably have to pan or zoom. There is one very critical use to initial scale though. On iOS, if you only set width to device width and you don't set the initial scale, like in this page, when you rotate the screen the iOS web engine will keep the same view port width and rescale it to fit across the landscape screen. It's just stretching the portrait layout, to fit, across the landscape width. Even though I've set width to device width, IOS is still scaling the landscape width. In fact, the interesting bit. is that even if you load this page initially in landscape mode, it still thinks it's the portrait width, it just rescaling it to fit in the landscape screen. Now, if you have the same page, but you set the initial scale to 1 in the viewport meta-element along with setting device width, it'll change the viewport size when you rotate, instead of rescaling. You can see now the window size is 480 pixels across. It's the landscape width, not the portrait width. So, in short, this is what you really need to use as your default boiler plate viewport meta-element. You'll need the initial scale, so that IRS, when flipping from portrait to landscape mode will still scale correctly. An interesting side note I discovered is that on Iphones - Although they are changing the viewport size properly if an initial scale is that, they are also changing the default font size for the document and orientation change, effectively zooming up the text when you go to landscape mode. This means you should probably set a default font size on the page, not just use an percentages. You may want to use a reset style sheet to do this, if you aren't already. So really, fixed viewport wits are historical. Resizing by default was an attempt to shoe horn the desktop web into a mobile device. Fixed viewport sizes were a quick way to provide some minimal controls on that resizing, with device whip, gets us back to the same scalable sized canvas that the desktop web has, so the right way to do fluid flexible design, in the modern mobile web Starts with this tag. This marker let's the browser know your one of the cool kids and you know what your doing. There are also minimum scale and maximum scale properties too. Which is a way to limit the extents, that the system is allowed to scale the page on the device. That seems a little esoteric at first, but, there is one use that, I wanted to mention. I don't want, you to think, that I'm biased. So, after describing how you need to add initial scale, for iOS to work as expected. I wanted to give equal time, for, Android. If your page, with device width happens to forcibly, overflow the page, like this page, where I've added an element that's very wide, Android will actually, do some rescaling, when you change screen orientation, to, try to get the whole page to fit onto the screen. Now, unfortunately, it gets it wrong, and it tries to zoom it the wrong way. Now, the only way that I found, to get around this, other than not overflowing the screen to begin with, is to set the minimum scale and maximum scale properties, to one, which will prevent the user from zooming altogether. As well as, disabling automatic scaling. Let's do that in the dev tools now. Now let's try rotating again. We're back to normal here, and now, you see that even in landscape mode, we get the proper width. Now, the problem with this, of course, is i can't zoom anymore. We really don't want to disable zooming, for, your users; this is an accessibility problem. So, don't do this in production pages, but, it can help your testing, in, general just don't overflow the page and you'll be good. There is one more property you can set. You can disable users zooming entirely by setting user scalable to no. Fundamentally, you really shouldn't do this. It's bad for accessibility and you're more likely to just annoy your users by preventing them from zooming than to make their experience any better. There is one more thing, on viewports. You're naturally, going to want to lay out, elements on the page, relative to the size of the viewport. Particularly, when you're sizing columns on the page, for example. So, we have a new unit type, in, CSS called, viewport units. You can use these units, to size things, in percentage of width of viewport or percentage of height of viewport. Without having to push percentage sizing, everywhere, which makes things a little easier. The really exciting thing, is, these unit types even work in desktop browsers, as well as in mobile browsers. There are also vmin and vmax units, which let you size things based on the smallest or largest units of width and height. This helps make layouts that stay consistent across portrait and landscape mode. Using this feature, it's pretty easy to create a button that takes up 1 3rd of the biggest square that will fit in the screen. Now using these units, the button stays as large as it can be and still fit in a third of the space. So you've had about wraps it up, for how to design for a particular view port. With all of this complexity though, you might have noticed, some developers decide to build two separate applications, a desktop app. And a separate mobile web app, but there are some problems with doing this, which of these problems might you encounter with having separate mobile and desktop sites? Really, all of these problems apply. Let's go through them one at a time. First, you really need all your features to be available and fully usable on the mobile version. If you try to guess what content or features your users won't miss on the mobile, you'll probably get it wrong. It might seem logical, right up until the point where I try to browse store inventory for my mobile device, only to find that feature is not availbale. Secondly, with two apps or sites, there's a natural tendency to focus on one or the other and to get out of sync between them. Maintaining two separate applications and keeping them fundamentally the same is hard to do. And finally, there's the problem that it's difficult to identify when you really want the mobile version. My tablet for example has nearly as big a screen as my laptop, and it's actually higher resolution than my laptop. Mobile design is actually more of a spectrum that spans all the way from low-resolution devices up into desktop design. At the very least, there are three simple rules if you want to offer a mobile-only site. First, you want to make sure a user can still get to the full site from the mobile site if they want to, in case you forgot any features. Secondly, you should but canonical URL in meta-information. This is commonly done for search engine optimization, but it's also important to keep your mobile site and your desktop site together. Finally, if someone links to a specific page on your desktop site, you shouldn't transfer them to your top-level mobile page. You need to transfer them to that specific page or its equivalent, on the mobile site. It's really frustrating when you get redirected to the top-level page. I also want to mention one pet peeve, the door slam. It's great if you've sunk development money into developing a native mobile app, and it's fine if you want to make sure your users know it's available, but you shouldn't block access to your web application with a full page ad for your native mobile app. Make this offer unobtrusive, and make my decision to ignore it sticky. Now, you can use smart app banners, in iOS, to make this offer a little less intrusive, but if I open a URL in a browser, I probably want to stay in the browser. In this course, we want to focus on building one adaptive experience. Now that you understand some of the goals behind mobile user experience design. And you understand how to use Viewport, in the next lesson, we'll focus on building fluid designs that scale across devices. As we discussed in the last lesson, one of the first challenges of developing for mobile devices is the screen. As mobile developers, we need to design pages that can adapt across various screen sizes and scenarios. This lesson will prepare you for building fluid layouts, designs that can adapt across different screen sizes. And hopefully we'll break the bad habits of designing to the fixed page. As an example, here's my blog, circa an embarassingly short time ago. Now, if you resize this window, nothing really changes. Nothing adjusts other than the amount of margin space. It's really a fixed width layout. Now, let's take a look at this on the phone. Now here, I get a very different version of my blog. It fits well on the phone, but I'm only getting this because my blog is running on Wordpress. And, Wordpress is configured to give a totally different version to phones. But, that's not actually what I want. Because I really want to have a shared layout between the two. Let's take a look at this on a intermediate device. My seven inch Android tablet. Now here, what I'm getting is essentially the desktop version. I can still scroll through the site but you can tell all the text is pretty small. Although interestingly, if I rotate to landscape mode, it adapts. Now why does it do that? Well it turns out it's our old friend viewport. There's now viewport set in this page. So, what does that mean? Does layout happen if the device flipped? Or does layout happen at the magic 980 pixel width and then get rescaled to fit on the screen? Layout is happening at 980 pixels wide and then just getting rescaled to fit the screen. If we rotate the screen it's scaling it up to fit the width, so in short this isn't a fluid layout at all. It's a fixed width with the font size being set in pixels and then getting scaled along with everything else. The worst part of this, is that I'm going to have to zoom in to read this text. It's far too small for me to read. And in fact, when it's all the way across the screen, it's still a little small to read. So if we dig around the page with the developer tools, we'd see a lot of pixel widths. Including the main content of the page, which is inside this page element. And you'll notice it has a width set in pixels. If I turn it off, well, the page is still not working properly. But at least we've started. Instead of this fixed code let's use a different technique, Fluid Layout. Fluid Layout means I should stop fixing all those widths in absolute terms like pixels or points and start thinking in terms of areas of screen real estate. Percentages of the widths, for example, and sizes based on the initial font or Em units. With all this complexity, you might ask, why don't I just set the viewport width to 760 pixels? The width of that column of text I showed you in the dev tools, and call it a day. Is it because that would be too easy? Or because, then my site would scale the same layout across all devices? Or because the fonts would be wrong in some way? Well, the answer isn't because this would be too easy there really is a good reason for why you don't want to set viewport width to a fixed size. Namely that then your site would scale the same layout across all devices, you'd get the same layout of text and images on a four inch cell phone as you do on a ten inch tablet. And of course this means the fonts would be are consistent size with that layout. You'd get the same size fonts rescaled on to a four inch phone as you would on a ten inch tablet. And fundamentally this would result in a poor user experience across mobile devices. So lets go fix my page. Now the first thing we need to do in order to make a mobile friendly page, is to set the viewport. The mobile browser needs to know that this webpage knows how to format itself on devices with varying width. It doesnt need the mobile browser to pretend that its a desktop screen with a given width. Once you set the viewport correctly, it will be able to resize properly and lay out properly. So what should my viewport meta say? That's right, you need to set the width to device width, and optionally, you can set the initial scale to one if you want, to help avoid some iOS device formatting issues. So now that you know how to support the view port meta, lets poke around in the developer tools to see what we need to do to fix this page. Now, the biggest problem here is that the page has a fixed column width. If I resize the window, you'll notice the column of text doesn't actually change size, just margin position. As we mouse around the elements inside the dev tools, we can pretty quickly find, the first offending element. This page element here actually has a width set on it. Let's disable that and see what happens. Well, it certainly changed things, but I don't think that it actually improved things very much. Let's keep digging inside the content and see what we can find. This wrapper element has a width of 100% already. Which is good. It means that it's not preventing us from resizing. But this content element does have a width set in pixels. Let's disable that. Now as we resize the page our content is fine but the sidebar is appearing and disappearing. Sure enough, it has a width set. If we set its width as a percentage also, now we're resizing a little bit better. So now let's go back up to the page, and let's try giving it a width but let's give it a width in view port units instead, now our only remaining problem seems to be that the header is actually not resizing as we want it to let's go take a look at the header image again. The image has a max width set, but not just a width. So, let's set its width. And now, everything seems to be resizing well. Now, this isn't perfect, but all that I really wanted to get at was that as you try to transition pages from fixed layout to fluid layout, The core things to look for, are fixed pixel sizes and lack of percentage resize. So there's really two rules for building fluid layouts. Use percentages or viewport units, something that'll size as you resize the window. And then, test while you're resizing the window. Let's take a look at how this worked out on the mobile device. We went from this layout without any changes to my blog. To this layout, definitely an improvement. I don't have to scroll left or right to see everything on the screen. And, you may notice the font size is actually a bit larger now. The font size was always set in M units, although it's actually still a bit small for a mobile device. So, we should probably bump that up. Let's take a look on the tablet. In the tablet layout, we went from this layout to this, again, a definite improvement. This is actually a pretty readable experience. And, even when we rotate the screen, we end up with a nice reformatting. All this is really just a long winded way of saying, be sure to create fluid layouts. Be sure to reflow to use all the space on the screen and take advantage of every bit you can. And be sure you adapt to different screens as well. One tool that makes reflow a lot easier, particularly across very different screen sizes, is the new flex box layout in CSS. This new tool lets you stack elements in flexible rows or columns. FlexBox has been kicking around for a couple of years now, but it's gone through some pretty major revisions during that time. It's just recently shipped in iOS 7, and it's been shipping in Android for a little while, but you should test your FlexBox layouts thoroughly, across browsers. This may be a little too bleeding edge for you, but, let's take a look. We're going to walk through an interactive demo, talking you through each feature in FlexBox, as you change the page, live, in the developer tools. Okay, that was a ton of detail. Really I recommend you, just sketch out your design, and then party on it with Flux Box. Flux Box is super powerful, and it's really super easy to use. Incidentally, I did mention, Flux Box is still making its way into all the browsers out there. So ,there are some Flux Box polyfills out there, that can help you, like Flexy. So these tools give us the ability to build designs that are fluid. But as it turns out, that's not enough. As you may have noticed as you went through this lesson, the experience of re-flow from a very small window size to a very large window size is not really a great one for the user. Now that you know how to build fluid designs, you need to learn to adapt those designs to radically different scenarios, like a four inch phone screen, and a 30 inch desktop screen. And that's what we're going to be talking about in the next lesson. In the last couple of lessons, we learned to build fluid designs that reflow across different screen sizes smoothly. Of course, truly adapting a design across multiple environments, from a four inch cell phone to a 27 inch desktop monitor, it's not quite as easy as just dividing the screen app using percentages. Sometimes, different devices ,call for fundamentally different design. We can accomplish this using media queries. You might ask, why don't we just use reflow across all devices? Is it because there are new phones and other form factors that come out all the time? Because each form factor has a different best user experience. Or is it just because reflow and fluid layout are hard? The answer is that different form factors typically need to be taken advantage of differently. An ideal interface for a phone scenario, will really be pretty different than an ideal desktop presentation that's designed for a large screen. You need designs that adapt to the general scenario of device, like phone or tablet or desktop. And then use re flow and fluid layout techniques to adjust for smaller differences between devices in those scenarios like, different models of tablets with slightly different screens. Even as basic a thing as flipping a device from portrait to landscape orientation might change the best interface pretty dramatically. Like this audio recorder I wrote, where the best way to lay out the interface changes in landscape mode. This isn't just reflow and percentage sizes. I needed to change some more dramatic styling to make this interface work well. In today's landscape, you should really think of your designs in terms of three main scenarios. Phone, tablet, and desktop. This may share some design characteristics of course, and they'll certainly share data, but you should consider the optimal experience for each of these scenarios separately as you build your design. This combination of fluid design with adapting to scenarios is generally referred to as a responsive web design. Many books have been written about this topic, including this one by Ethan Marcode, who coined the term. Responsive design isn't just about flexible fluid designs, it's also about adapting to different scenarios and environments, and our primary tool for doing that is Media Queries. Media Queries have their roots in the media type for style sheets, used to declare a style sheet that's only applied to certain media types; like when printing. And in the at media section, in CSS, where you can declare a subsection of the style sheet to only be used for print or other media. For example it's helpful to display the URL of hyperlinks when printing, since you can't click on the links on paper. So that's what this rule does, but CSS3 Media Queries add a media query terms. This lets us make condition rules in our style sheets based on environmental factors, like the width of the window or the orientation of the device. This opens up a huge opportunity for us to make truly adaptive layouts. There are a number of different properties available inside these Media query expressions. Like the width and height of the current window, the width and height of the device, the device orientation, the device aspect ratio and window aspect ratio. Weather the, the device is grid based, how many bits per color the device uses or weather it's an indexed color device, or weather it's monochrome, the overall resolution of the device, and weather it's progressive or interlaced scanned. Even just using orientation and width. We can easily place different form factors into a few buckets that we can target. Note that using media queries, we're defining these buckets in terms of things like physical dimensions, width and height. Not in terms like for an iPhone 5, do this. This strategy, along with the fluid design strategies we learned in the last lesson, helps our designs adapt to general scenarios, and, new devices as they come along. For example, let's go take a look at the front page of our Conference Application. First, let's look at it in Landscape Mode on a Tablet, now let's look at it on the phone. See how the layout is different? Let's take a look on this on the Desktop and see how it adjusts, when you drag the Window. You can see how the Buttons pop into two rows when the window gets too narrow to fit all four comfortably, let's take a look at the magic that makes this happen, it's actually quite simple. The Menu items are laid out inside a flex box, and the items inside that flex box by default are told to take up 46% of the available space. That means, of course, that only two items will fit on a line. However, there's an app media rule that overrides this if there's a minimum width of the window of 500 pixels. In that case, the items will each only take up 24% of the space, so all four items will fit on a single line. Using Flexbox can be a great way to transform your page. You can change flex direction or flex order to make dramatic interface changes like the one I did in the Audio Recorder earlier on. So now its your turn. Go ahead and update this CSS file to make sure that the menu items grid class is set to column flex direction when in portrait orientation. It's actually kind of impressive how short the code is to do something like this, we just wrap a menu items grid flex direction column rule inside a media query on orientation portrait and we're done. Now, if you're a pretty observant gadget hound like me, you may be wondering how is it that these bucket breakdowns actually work. My Nexus 7 tablet, for example, is only 800 pixels wide in the portrait orientation. This Galaxy x4 phone is actually 1080 pixels wide, in the same dimension. Even though the S4 has more pixels, it's somehow turning up as a phone. Why is this? The answer lies in a little bit of magic called the device pixel ratio, and the fact that once again, the web platform is lying to you. The device pixel ratio, is the ratio between device independent pixels and an actual physical pixel on the screen. Remember, back in the viewport lesson, when I said you should just give this magic boilerplate at the top of your file, and you'd get the actual number of pixels on the screen as your width? Well, that's not actually quite true, because we've a concept called a device independent pixel. The first time this really came into play, was when apple released the iphone 4. The original iphone and the iphone 3G and 3Gs, had a screen resolution of 320 by 480. The iphone 4, however, had what apple called a retina display, which doubled the horizontal and vertical resolution. To 640 by 960, but they still wanted text set in pixels to be the same height. To go back to the viewport lesson for a second, even with width set to device width, they still wanted to have the same pixel width fed to the layout algorithm, so you got consistent layout across the iphone 3 and iphone 4. In essence, they caused the lay out algorithm to lie again. Even though the screen is 640 x 960, the layout algorithm treats it like it's 320 x 480. That way, sizes that formatted for the original 320 x 480 screen still layout well on the higher resolution screen, and text and images are rendered at the higher resolution. So, it can look better as well. That's why, even on the iphone 5, if you set a view port with device width, the browser width is returned to you as 320 pixels not the actual 640 pixels that there're across the screen. There're are 2 device pixels for every pixel that the system lays out. The new screen, of course, is a little bit longer. So, the vertical dimension is different. Window.device pixel ratio captures this ratio. The number of device pixels, for every formatting pixel in the layout system. It's basically a way to identify the density of pixels on the screen. Now, this may not be the precise device pixel density. It's sometimes rounded to the nearest integer. But, this lets us know high resolution density the screen is, rather than just how many layout pixels there are on it. So, let's go back to the original question. How is it that the Galaxy S4 is getting the phone layout in our conference app, while my Nexus 7 is getting the tablet layout? Even though the S4 has couple hundred more pixels across, than the Nexus and we're using pixel count to switch in our media query. Well, the answer is device pixel ratio. The Galaxy S4 has a device pixel ratio of 3. The Nexus 7 is only 1.3. So, if you look at the formatting width, the width passed into the viewport, the windows screen width. Well, on the S4 it's 360. But on the Nexus 7, it's 601. Mobile devices not only have different numbers of actual pixels, but they fit very different numbers of pixels into each inch of screen real estate. So, to get roughly consistent formatting, they pass different numbers of layout pixels into the view port. This chart shows the number of physical pixels for each device, the device pixel ratio. And then the resulting layout viewport. If we look at the number of device independent pixels per inch, this results in for each of these devices, we'll note that almost all the mobile devices are very close to 160 device independent pixels per inch. This makes layout design much easier for us. The device pixel ratio gives you a clue as to how high resolution the screen really is. Not just how many layout pixels there are. You can use device pixel ratio in media queries to control properties like background images. And in fact, this is going to become very interesting in the next lesson, where we learn about how to use adaptive images. Now you have the tools to build fluid designs from previous lessons. And you can adapt those designs to radically different scenarios using media queries. The only thing that's still missing is how to make images look beautiful, across all these different devices and screens. So that's what we're going to take on in the next lesson, when we dive into adaptive images. In the last couple of lessons, we've talked about the range of screen sizes that our content needs to scale to, and how device pixel ratio represents screen density. Your web applications need to deliver good image quality across a broad range of devices, but they need to do so at a minimum cost. In short, when we render images to the screen. A pixel layout dimensions may well not equal a pixel in real device terms. And that relationship isn't a fixed one either. Here, we have the same page on two different devices. But even though the image is approximately the same size on both devices, this image only needs less than half the pixels of this image to be rendered at one to one. Rendering an image at one to one gives the best quality. But even more important, you don't want to be pushing a lot more bits down with the network than the device can use, and you don't want to have poor image quality because you're not pushing anywhere near enough high resolution imagery either. The best way to think about this is that it's much like the difference between standard definition tv and high definition tv. For most of my life I watched standard definition tv, but now that I watch most shows in HD, when a show is broadcast in standard def, I defininately feel like I'm living like an animal. You need to deliver an HD experience when the user's device supports it. You should have one goal, to make images look as beautiful as they can on the user's device, while using as little bandwidth as possible. Now this last point is critical. Network bandwidth is most assuredly not free, particularly on mobile devices. We'll learn more about that in the next lesson on performance, and in our final lesson on offline. If you didn't care about bandwidth, you could just serve massively large images all the time. But a full screen image for a ChromeBook Pixel is 4.1 megapixels, whereas on a Nexus 4, it's only 0.9 megapixels. IPhone 5 is only 0.7. The best size for images is very different on each of these devices. In short, different devices, have, different display densities. Some of them, can make, use of a lot of pixels. Some of them can't, in essence, what you need to do, is, produce content that can be standard definition, on a standard definition TV. High definition on a HD TV. And 4k on a 4k tv. So how do you do this? Well, I'm pretty lazy and my first reaction is always to try to avoid the issue if possible. Remember, anything that the browser is responsible for rasterizing it can probably do at the native resolution of the screen. So if you can effectively use vector graphics like scalable vector graphics, or canvas to draw your graphics, You absolutely should. Although I do want to note that by default, canvas has a backing store set to a 1x pixel density. That is, it won't rasterize in higher resolution on 2x or 3x displays. You can change it and get a higher resolution backing store by setting the width and height on the canvas to the upscale dimensions. Multiply them by device pixel ratio, then scale your entire context, or use css width and height to get it to lay out to the appropriate size. We don't do this automatically in the browser though, if we did, canvases on two x devices would cost four times as much memory, and 3 x devices with cost nine times as much memory. On mobile devices that might have pretty limited memory to begin with. Now, for small icons or glyphs, you may wish to use icon fonts which are a handy way to get pretty looking icons that scale well. For general prettiness, using CSS features like gradients, rather than a gradient image is a radically good idea. And, CSS3 features like rounded corners and boarders. Save you from having to supply custom graphics for each corner and they have the added benefit of reducing the number of requests your page makes. But let's presume you really need a raster image because some things just can't be represented well by a vector drawing. This is a 21 megapixel photo of my cat. Obviously, you probably really don't need that resolution pushed down to a mobile device if I'm just writing a blog post about my cat. This is a 4 megabyte image after all. So what should we do with this image to deliver it to different devices? Your first option is to kind of cheat. You can always deliver a high resolution but low quality encoding everywhere. That is, give this same image to all devices. That's a higher resolution, a 2x image for example. But lower the quality in the jpeg encoder to 20 rather than 90. This typically can result in a 2X image that will look better than an uncompressed 1X image. And you'll notice at the same time, it actually has a smaller file size. Using this technique will work well in many cases. But it does come at a cost. The browser also needs to spend some time decompressing the image, and on a 1x device, it needs to scale the image by 50% to fit it into the available pixels. You can also start to see some color [INAUDIBLE] and some gradients using this approach. Sure, lower pixel count devices will get a bigger image than they need But not too much more data since it's low quality. In higher pixel count devices, we'll get the right size. Although they will get a slightly lower quality image than they would normally want. This option isn't great, but it's definitely better than only serving low pixel count art. Or serving only high pixel count to all devices. So given that just using a higher resolution image, everywhere, isn't a great solution, what do you think you should do? Should you use a low quality source image? Replace it with JavaScript? Should you expect the server to give you the proper pixel density image magically? Or, should you make several copies of the image and conditionally request the right one from the client? It's true that you could use a normal resolution image in the source and then replace it with javascript with a higher resolution image. when you programtically detect the device pixel ratios greater than one. However ,this means that you would be downloading the normal image and then a high density image ,on all high density devices. And unfortunately, most of the current high density devices, that is where device pixel ratio is set higher to one, our mobile devices, like my phone and my tablet ,where bandwidth is probably at a premium. So ,this isn't really a good solution for any reason except simplicity. It is possible though, that this will be solved on a server side .For the device pixel ratio scenario particularly, by something called client-hints. Client-hints is a header sent to the sever to let it know what device pixel ratio you're rendering at and what size you're actually looking for. It uses the vary header to let it know that the version shouldn't be reused by caches improperly. However, client hiddence isn't broadly implemented and deployed yet. And, this approach won't necessarily solve everything about responsive images. However, once this approach is actually implemented broadly, it will definitely be a great tool for fixing density issues. For now though, you need to make the decisions on the client side and ask the server for the right image for your device pixel ratio. Except remember, its not just device pixel ratio. Keep in mind that for responsive images, like adaptive layout that we learned about in the last few lessons, we frequently will want to adapt the size of the image, the layout size of the image, depending on how much space we have. Sometimes we do that with simple scaling, for example, here, on our conference app, we're currently rescaling the speaker images depending on the layout size. Sometimes though, we may actually want to switch between subjectively different images too. For example, you might want to crop your subject more closely when you don't have as much space to render the image. Using images differently in terms of art direction in different scenarios is part of what makes these responsive images rather then just scalable pixel ratio images. So in order to do responsive images right, you need to request different images based on the device-pixel ratio, but also possibly based on the layout width. These images may be the same image simply transcoded to different sizes. But they may also be actually different images depending on the layout size and how appropriate that layout is. The key here is to serve the right image to the device that needs it. The original of my cat picture here is a 21 megapixel image. Obviously I probably don't need to send that to a mobile device. It has only a half a megapixel display. But it helps to start with high quality art. And you know you'll need to provide multiple copies of this image, so low pixel count devices can save bandwidth or high pixel count devices can get a crisp image. It's possible to do this on the server side in some cases. In fact, some content systems let you simply specify what size you want a given source image app And they deal with the trans coding on the server end including caching. If you want the images to actually represent different art, different crops for example you'll have to do that manually. For each of these images though you should remember to tune the quality parameters to minimize file size while maximizing quality. You'll need at least 1x and 2x versions of your images although 1.3x and 3x are fairly common too now. Again, note that although I'm speaking of this as 1x or 2x, for purposes of device pixel ratio, for responsive images, you may request different images based on available layout width. You may even want to change the image itself. For example, in Landscape mode, I may want to crop the picture completely differently. Finally, we need to get the client to ask for the right image to be downloaded. That is, it needs to know what device pixel ration the device is using, and potentially the layout size too, if it's responsive to the layout width. And then request only the appropriate image. This last part is the hard part, because the web browser tries to kick off the image downloads. As early as possible. Which of course is a good thing for getting content on the screen quickly, but bad if the client asks for more than one version, particularly on a mobile device with limited bandwidth. So how do you think we should approach this problem of asking for the right image at the right time? What you really need is the ability for your client to selectively choose what image to use. After all, it knows what resolution it needs right? Unfortunately, this problem hasn't been cleanly solved yet. An ideal solution would be semantic, and it would validate properly. It wouldn't require Java Script or a server configuration, necessarily. It would only load one copy of the image, and it would work across all browsers, and be accessible. Unfortunately, that solution doesn't exist today. There's several solutions under discussion. Right now, it looks like the end solution will be some version of the picture element. Hopefully, this will be hashed out in the relatively near future, so stay tuned to the standards community for more. There's a link to the Responsive Images Community Group in the Instructor Notes. In the meantime, though, let's take a look at some other solutions. CSS3 introduces image-set, a new value for the background image property that let's us specify different background image files depending solely on the display density. This won't let us change based on layout size but we can do that using a media query. This works great to switch between different versions of the same image. Image, purely based on pixel density if that's all you need. That is, your layout size in pixels won't change and you don't mind using background images. If those are good for you, this is the way to go. Foreground images are a bit trickier because you'll either end up with an invalid HTML and no source attribute. With problematic accessibility or you'll end up downloading an image you don't need in the high device pixel ratio cases. This is one place you probably don't want to roll your own solution but use a library to polyfill until we get the right solution. There's a great article written by Chris Coyier That has a collection of solution libraries that he and Christopher Schmitt have put together. My personal favorite of these is the Picturefull polyfill, because I think it's most likely to be relatively close to the eventual standard solution in its markup. But there are many other techniques with differing complexity. For example, the clown car technique designed by Estelle Wile. This technique makes use of SVG encapsulation, to make each image a single reference. But to an SVG file, that inside it has its own media query that selectively sets a background image on the SVG object. Background image, again, in order to prevent the browser from downloading all of the image references early. This technique is quite workable but its also a bit complex and markup particularly if you want it to work in internet explorer. Although getting beautiful images rendering across a wide variety of devices is quite challenging right now, it's critical in providing a first class experience across all devices. Stay tuned to the standards community, and the Chrome developers channel, and hopefully this will get even easier in the future. In this lesson, we're going to talk about, how to build your web applications, to be wicked fast. But first, I want to make sure, that you understand, why performance, is so critically important, to your bottom line. For example, let's say you accidentally, introduce a performance issue, that causes your page to take an extra half second to load. That's just 500 milliseconds. That's a pretty small difference. What kind of difference, in user engagement ,do you think this would cause? No, discernible change? A 1% drop, in user engagement? A 1% gain, in user engagement, or a 5%, drop in engagement? That's right, even such a small change, causes a slightly more than one percent drop in user engagement, and realized income. Now that may seem tiny, but one percent of your income is probably pretty significant when it's such a small performance change. If the perf delay is a second, revenue drops by more than double. It's not even linear. Many well publicized studies from Google, Microsoft, Amazon, Facebook, and others, all show that UI performance translates directly to dollars and cents. A drop in performance directly drives a drop in user engagement. In short, speed is not a feature, it's a requirement. Users won't use your app if it's not fast Of course, it's nearly impossible to graph performance into your application after it's already been built, but before we get into good performance patterns, the first step to insuring great performance, is being able to analyze your performance. I want to introduce you to Colt McAnlis, who you may remember from his excellent HTML 5 game development course. Colt's going to show you how to analyze your performance using the Chrome developer tools. Many developers take way too long to start addressing performance in their applications. You see, they get in their time lines and schedules, and they try to get features checked in, and all these other things. And way too late in the game, they actually realize that performance is actually a huge issue. But you, because you're watching this video and we're having this little private one on one talk. Are not going to fall into that same pattern, instead your going to do two things to stay out of it, now the first thing your going to do, is your actually going to follow the perfmatters hash tag on your favorite social media network, there's a lot of smart people talking a lot about web performance. All over the net. And following this hashtag is going to get you keyed into the exact problems on the net and how to fix them. The second thing you're going to do, is you're actually going to become an amazing ninja by using Chrome developer tools to find your performance problems. Now, we're going to walk through some of the key scenarios. And some of the key tools that you're going to use to address these problems. Let's take a look. Alright, so to get started showing you soem of the performance techniques in Chrome Dev Tools, I want you to load up the Dev Tools bar, and also check out this great HTML-5 game called Biolab Disaster. Now, I love this game. It's made with a fantastic framework called Impact JS. And, happens to be a lot of the motivation on how we did the Grits Code Base back in the other course. Now, let's take a look at what we have here. When we talk about performance, we always talk about three pillars of performance. Network, render, and compute. What we are going to talk today first is the Network pillar. In order to get an understanding of how your web application is loading, what resources are coming down to the wire. And how long it's taking, but first thing you need to do is open up the network tab in Chrome Dev Tools. This is a fantastic GEM and treasure trove of information. Because basically, this actually records every request that your web application is making to the server enlisted here with a lot of very valid information. For example, you can see what type it is, the status of the request The content, how long it took to get it, and when it came in in the overall request structure of your entire loading sequence. Now, we could spend an entire Udacity course actually going into the nuances of this tool and how to use it, but instead I want to focus on a couple Key things. First off, when you're talking about loading web applications on mobile devices, there's two things you need to worry about. The first is how many requests you're actually making. So for instance, if you scroll down for playbiolab.com, you can actually see that there's a lot of assets that are being loaded here. Right? Every time your phone has to grab one of these assets off the Internet, a lot of things occur, but most importantly is, it takes time away from loading your application. Mainly because the medium to retrieve the data is a little bit slower than just loading it, say, off the memory or off of the disk. Now, the second thing you need to be concerned about is actually the size of the content that you're trying to load. So if you go over here to the size button, and you actually click on it twice, it's actually going to sort all of the assets that you requested by their size. Now, notice right here, this top one actually has two megabytes. Now look at That's a single OG file. Of course that's going to be music. But basically that's two megabytes that has to be downloaded before this web application could be played. Now, did you know that according to http archive, the average website size is only 1.1 megabytes? So already this single asset is larger than most of the websites on the web. Listen, that's not going to help you load this on your mobile device any faster. So by sorting it by size you can get a great sense of what assets you have, what sizes they are and see the relative proportion on how long it takes those assets to actually be loaded. Now, the second of our 3 pillars is going to be compute performance. And, to get a sense of how your application is actually spending it's time during a given frame, you really want to check out the timeline tab inside of Chrome developer tools. How this works, is that you actually load the timeline, hit this beautiful record button down here on the bottom, and then watch magic unfold. So, let's take look at how this plays out with Biolad Disaster. If I start the game, it goes up very simple. Now, when I hit the record button down here on the bottom, you can actually see that it's logging all of the event information that's occurring while this game is happening. Now, I'm not doing anything, I want to point that out, yet events are actually being fired. So, let's take a look at what's actually going on under the hood here. So, if I size this up, I can actually see the number of events inside of my window and drill down into what's going on. So, I've an animation frame here. And if I expand that, you can see that there's actually a request animation frame that has occurred at that point. Now, you'll notice down here on the bottom that there's actually different type of check boxes to filter out what events you're looking at. And each one has a respective color. For example, loading is blue, scripting is gold, rendering is purple and painting is green. So, if I toggle painting you can see that those events actually disappear from the timeline. Now, I did another quick little capture while you weren't looking, I saw you going to get peanuts from the bag. Now, if I slide my visibility window to another part of the timeline, you can see that there's actually a little block here that seems to be wider than all the other blocks around it, what this implies is that there's some scripting occurring between our windows here that is taking longer than the other frames. Now, below us, we actually have a list of events that occurred, plus as you remember these little triangles that allows us to drill down into the event. On here in the side, you can see that we have the same animation Frame Fire that we saw earlier, but the new one that we see showing up, is a GC Event, where 1.4 megabytes of data was actually collected. Hovering over it brings a popup dialogue that shows you that this actually took 2.7 milliseconds, out of our frame budget to actually do a garbage collection event. That's why you can see that this block here, is actually larger then the block next to it, because we have an extra 2.7 miliseconds that went to do a garbage collection event. We can actually see this mirrored, by clicking on the memory option for the timeline. Now, what this's actually going to show us is a linear graph of where allocations are actually occuring, and lo and behold, you can see, between our 2 divets here, when that GC event occurs, the amount of memory allocated in our application drops down, thus showing the garbage collection freed memory. Now, I want to show you what this looks like live, because it's really interesting to watch. How an application, actually allocates its memory. So, you can see that over time, this application, when I'm doing nothing on the screen, is actually allocating about 1 megabyte every second or so. And then you can see the garbage collector actually kicks in, and frees a lot of that data. This type of sawtooth pattern that you're seeing along the timeline here, is very common in different web applications, that do a lot of dynamic allocation of objects. Now, there's an article out there that I've written on HTML 5 Rocks, that details different ways to address this type of sawtooth pattern, using object pools. But, we're not going to go into that right now. Let's stay focused on what's in front of us. Now the final tool I want to show you today, is going to help you track down a lot of your compute performance problems, so this is actually the profile tabs on chrome dev tools, clicking this option will give you three options or more depending on what chrome decides to roll out in the future. The first one you need to take a look at is, Collect JavaScript CPU Profile. By hitting the Start button, what actually occurs is, Chrome is recording all of the application and JavaScript code that's running right now. Hitting Stop actually gives us this beautiful chart that allows us to see where my JavaScript was going. Now, this is actually broken up into two areas. On the top here, you can actually see a generalization of spike of CPU time utilized, and on the bottom, these beautiful, beautiful colored line is actually what we call a flame chart. Scrolling my mouse cursor actually allows me to zoom in, and what you see is a treasure trove of information. This flamechart doesn't just show us pretty rainbow pictures on the screen, but it actually represents a inverse call graph whose horizontal size represents how long a function took to execute. So for example you can see the animate function was called here, and then it called the run function, then the draw function, then another draw, and then another draw. And eventually we keep going up and up and up the chain. Of course, hovering over shows you the total time that these events took. And then where, in the name, shows you who actually called that function. Now you can see we have pillars of function calls. Basically, that's the call graph going through. But between them we have this really interesting little program bar that no one seems to understand what's going on there. What you're looking at here, is that these tall pillars actually represent a frame of computation. So this is actually a request animation frame where the page is updated, scripts are run, everything's drawn to your screen. And then when it's done, it relinguishes control back over to Chrome. What you see here in the program bar, accounts for the time that the browser takes before it comes back and gives control to the game again. So you can see here that we're actually giving about 12 milliseconds for Chrome to do it's job, and then once we get back it takes about two milliseconds for up to update the scene, do any important calculations, and move onto the next frame. Now, for a long time, I've been in proponent of saying that it doesn't matter what your language is or what your platform is. If you follow the memory, you'll find performance problems. And believe it or not, JavaScripts and HTML5 is no different. That's why I want to point you at this final option down here on your Profiles tab called Record Heap Allocations. Now, what this is going to do? This is actually going to make a log of all the allocations that occur. While your web application is running. So I'm going to turn this on and play through the game a little bit so you can see how the memories reacting to the game play. [NOISE] Now of course with that one alien destroyed, I've now saved the universe. Now, sizing up this window a little bit actually gives us a lot of information about what was allocated during that small time playing. So first off you can see that we have the types of objects that were allocated in this column. The distance is not necessarily as important as you would need it to be right now, so let's ignore that. Most important is actually this shallow size measure because it actually shows you the number of bytes allocated to this type of object so you can see here that the compiled code object is roughly taking about 2 megabytes or 28% of our overall frame heap. Expanding compiled code actually gives us locations in executable memory that tells us what type of data is being allocated. Now, this is code information, so it's actually not going to be that important to you unless you're be doing a lot of script injection. Now, probably a lot more useful to you is actually going to be a little bit lower in the stack. This object header you see here. This is actually going to list all of the class types or object definitions that have been created during our little playback. Expanding this actually gives us a bunch of pointers into the memory heap. Clicking on one shows us the retaining tree for the object. So if we bring this up a little bit. We can see that there was a module that was called from IG, and you can see that there was a lot of little global functions that kind of came into play. So clicking through this list a little bit more, we can find probably some interesting data. So here you can see that this one was actually an allocation of a collision map object. So somewhere while these objects were falling or debris was occurring The collision map was called and you can see a lot of the object information listed here. Now there's another great way you can track down information about this. If you go back to the Profiles tab, you can actually take a heap snapshot. Now what the heap snapshot is going to do is actual going to give you a listing of everything that's been allocated up to this snapshot in time. Of course, this really doesn't help you because it actually lists a lot of system-level resources that have been allocated as well. What you need to do is actually take a second heap snapshot. Now, when you take these two half snapshots you can actually go down here to the bottom where it says all objects and instead set this to show objects allocated between those two snapshots. Now this is going to tell you only the objects that were actually created in memory between clicking that button. Now if you remember before we showed that saw tooth pattern, inside of the time line view. Which basically told us that memory was being allocated even though I was going nothing. And with our two snapshots you can see that same principle occurs here, that about 612 bytes were allocated between the three seconds it took me to take two snapshots. If we drill down into some of the objects here you can see that a bunch of numbers were actually created. Most importantly you can see in the call stack, that these are x objects. So it looks like some velocity has been changed, right? You can see velocity here, velocity.x. So somewhere in our little application, the x property of the velocity object was actually created. Clicking on the Objects tab actually shows us the same thing. We can see an object was created with a value of x and a type of number for some sort of proto-object. Now playing around between a heap timeline and heap snapshot, gives you an amazing amount of visibility into how memory is being used in your web application. Remember, follow the memory, find your performance problems. Listen, you want to know more about performance. You want to get your application running fast and smooth and junk free so that your users don't have to complain about it, follow the tips I've detailed and most importantly, follow the perfmatters hash tag on your favorite social media network. There's a lot of extremely smart people out there, all trying to handle these problems in very important ways. Following this hash tag is going to key you in to how they're thinking and how they're solving the problems. Now that you have some idea of the tools you have to work with, I want to go back to the three main pillars of optimizing performance that Colt mentioned, Network, Compute, and Render. Let's start by taking a look at Network. The first question we have to ask is, what aspects of network usage should we be targeting for optimization? The number of bytes transferred? How often we send requests? The power consumption of the network stack, or the maximum number of TCP connections we use. Of course, optimizing the number of bytes transferred is important. You may expect that optimizing network usage just means minimizing the number of bytes transferred. Things like, don't send a multi megabyte image to a phone when it's only going to be rendered at a small pixel size. That's certainly part of it, but there's other things at play, too. And in the end, all of these things are important. How often we send requests needs to be optimized for the latency of the particular cellular network, and we have to be careful about the power consumption, as well. Although it's less important now, we do still need to optimize for the maximum allowed TCP connections. It is pretty commonly understood that the biggest battery drain in most mobile phones is the display screen. You can tell this easily from the Android battery display even. But what hardware component do you think is the second biggest battery consumer on most mobile devices, the CPU, the cell WiFi radio antenna, memory, or the GPS? That's right, the cellular and WiFi radio antenna are generally the second biggest power consumers in your mobile device. Although the GPS takes a fair amount of power, it usually isn't on all the time, so its not that big a drain overall. Now, you can't do much about needing the screen on all the time, but you can control your applications' network usage pattern. It's important to understand that, in terms of power consumption, the pattern of network usage, is at least as important as the total amount of data transferred. There're definite anti patterns to network usage. It turns out that the cellular radio is designed to switch to a low power idle mode, when not in use to conserve battery life. Let's take a look at the different states the radio can be in. The cellular radio, has something called the radio resource controller, or RRC. I'ts kind of like a traffic controller for the radio. We start out in the idle state, and, when we make an initial request, it takes around 100 milliseconds (no period) for us to get connected, and into the active state. Once we're there of course, we can make as many requests as we want, and stay active. Once we're in the active state, though, if we don't make a request for about a tenth of a second, we drop into a short sleep mode, which uses less power, but, it'll take us up to 50 milliseconds in order to get back into active if we make a request. Then, if we don't make any requests for another 100 milliseconds, we drop into a long sleep mode. Again, we can get back to active in under 50 milliseconds. But, if we don't make any requests for about ten seconds, we drop all the way back down to idle. Which will of course take us longer to get back into active from. The critical part about this of course, is that each one of these states, has a different power consumption for a file. Idle of course takes the least power. Active takes the most. Short sleep and long sleep, both take inbetween. But, certainly more than idle. So, it's important for us to leave the connection idle, as often as possible, and try not to spend too much time, cycling back and forth between sleep and active. So, although it's pretty intuitive that radio use at full power can drain a battery in a matter of hours, it's critical to understand that intermittent network access can be just as bad. AT&T has a great free tool you can use to analyze your network use, the Application Resource Optimizer. This tool can help you visualize the state transitions your application causes in the radio stack. So now that we know we want to minimize the time the radio spends at full power, what can we do to ensure this? Should we prefetch and cache data? Should we eliminate periodic transfers like polling? Or, should we batch our requests? Actually, all of these are good things to do,. You should prefetch and cache data to front load the requests as much as possible. You should also eliminate, or at least reduce, periodic transfers like polling. Otherwise, you're going to keep a continuous connection alive and you're never going to let the cellular radio go into low power idle mode. If you can, you should batch those requests instead. Store up several requests and then grab them as necessary. One of the surprising things about network speed is that a lot of what determines the end to end speed of a network in practice is not the throughput, how fast you can push bits through the channel, but the latency, the time it takes to get a response from the other end. Let's take a look at where that latency comes from. For each HTTP request, even after we've gotten the radio to wake up, we have to do a DNS lookup to figure out what that domain name server actually means in terms of IP number. We have to make a socket connection to that site. We have to actually send the HTTP request and then we actually get our data back. Each one of these steps takes time. On an LTE network, each one of these requests takes between 240 and 500 milliseconds, depending on whether we already have a connection going or not. On 3G, each request will take 600 milliseconds to 3.5 seconds, that's per every HTTP request. So the first thing that you should do, in order to minimize network latency, is to minimize the number of HTTP requests. And a major, major way to do this, is to avoid page redirects. each redirect can cause a DNS look-up, TCP connect, and the sending of the actual HTTP request itself all over again. HTTPS has even more round trips per connection. So you're looking at high hundreds of milliseconds per redirects, as a penalty, at least. If you have a legitimate need for redirects, for example if you've moved a resource, that's great, but use a 301 redirect if you can. Lots of browsers will actually update links then. You also want to illuminate render blocking resources, like waiting on multiple style sheets or fonts of the like. Anything that forces the browser to wait for another HTTP transaction to complete, before it can render the app, is going to be much more noticeable on mobile. So, combine and minify those style sheets kits. This also includes avoiding blocking rendering by waiting for the download of JavaScript files. If you can use async or defer on script to let the content render as soon as possible. In short, you want to prioritize the network transactions or whatever you need to render the initial page full of content. Make sure you're loading images on that first page first, before ones that may be down in the bottom of the page. Get that first page on the screen as quickly as possible. You should obsess over the network page and the developer tools. To make sure you're loading items in the correct order. Now let's go back to our Performance pillars, and move on to Compute. The first thing understand about optimizing computation for mobile CPUs. Is of course, the mobile hardware is generally going to be less powerful, than desktop equivalents. Your app is going to have to deal with slower CPUs and GPUs than you're used to on desktops. Also, memory space is much more constrained on mobile. What kind of problems do you think this could cause for your site, that your going to run out of memory more frequently, the garbage collector will run more frequently or that low memory conditions will drain the battery? Of course, with less memory, you're going to run out of memory more frequently. And you'll have to make sure that your code is bulletproof in low memory conditions. But, this also means that the garbage collector is going to run more frequently. And, running the garbage collector will actually, often, also cause a spike in battery usage. So, all of these are true. However, the battery drain, caused by the garbage collector, is less of a concern than stuttering and other rendering problems that the garbage collector can cause. When the garbage collector needs to clean up, it pauses all JavaScript execution and rendering on your thread. So if we want a garbage collector to run less frequently, can you think of some ways to achieve this? Of course, if you can simply use less memory, that's great. But of course, your goal is to minimize the dynamic object allocation and de-allocation. Freeing up those dynamic objects is what the garbage collector is cleaning up after. So you really want to try to minimize dynamic object allocation. One way to that of course, is to manage your own static object pools, implement your own memory management. For example, you can allocate an array of objects and hang on to that whole array and just swap out which ones of those you're actually using. Of course you need to be sure that you're not actually allocating more than you need. But the key to reducing the impact of garbage collection lies in eliminating excessive object churn, not just memory size. Finally of course, you need to test your code very carefully for memory leaks. Since memory is so constrained, it's doubly important that you don't leak memory. And you don't want to keep increasing your static memory pool. There are whole books and discussions on best practices to avoid memory leaks, so we won't go into this in depth here. In order to help the garbage collector do its job, you want to be sure you're not holding on to objects that you no longer need. The easiest way to do this is to use an appropriate scope for your variables. Instead of using a global variable, that you then have to dynamically allocate and de-allocate, just use a function scope local variable. When it goes out of scope the garbage collector can take care of it. Also, be sure to unbind any event listeners before the dumb objects they're bound to are to be removed. And finally, if you're using a local data cache be sure to clean the cache through using aging mechanism to avoid any large chunks of data being stored that you don't really need any more. One final note on computational performance. If you're using third party libraries you should check and see if there is a smaller, faster mobile-optimized version. For example, if you're using Jquery you might consider switching to Zepto. For any library you use though, be sure to use the most up to date version. Many libraries are in the process of optimizing for lower memory and CPU consumption, and this can be a great way to save some cycles. Now, let's move on, to rendering performance. Your goal for rendering, for scrolling and animations, particularly, should be smooth, gent free rendering. If your app, is jumping around, as the user scrolls, or an animation is periodically freezing, or, running at less than a fast consistent frame rate, then your users will be unhappy, with the experience. On desktop, we always, tell you, the magic number is 16 milliseconds. That's a single frame, when you're running at 60 frames a second, which is the usual frame rate of the monitor. That's not always true and actually, it's not even that you need to consistently hit 60 frames a second. It's far more important, to have a consistent frame rate, than a high frame rate. Now for talking about animations, we first have to figure out what API to use in order to create animation effects. Which of these 3 APIs should you use to repeatedly call in animation code? Set Timeout, Set Interval, or Request Animation Frame? If you're still using Set Timeout or Set Interval to do animation, please, please, just stop. Go check out a magic little API called Request Animation Frame. Request Animation Frame is kind of like Set Timeout. It's a method you call to set up a callback to happen in the future. But, you're past callback is called only when the system is ready to update the visual screen. The fact that request animation frame, runs once and only once during a redraw cycle also let's the browser optimize concurrent animations. SVG, CSS transitions, scrolling, your own dom-based manipulation together, into a single reflow and repaint cycle. Rather than, each of these poking in in it's own timer and updating the screen whenever it feels like. This leads to much higher fidelity visual refreshes. But, in addition to causing all these refreshes together, this has the effect of locking the updates, to the visual refresh rate as a maximum. You won't accidentally call your drawing routine more than once during that magic 16.7 millisecond long refresh cycle, which would waste work. Request animation frame won't be called again, until the current frame is pushed out to the screen and it's ready for another frame. And then finally, there's one more key feature to request animation frame. Their callback won't be called, if the browser tab isn't visible. That's, if you're running the animation loop in a tab and the user switiches away, the browser won't keep calling the visual refresh callback, it will once it's visible again. But, this means you won't be using the CPU, the GPU or extra memory potentially. Which will lead to longer battery life on a mobile device. Finally, I want to emphasize again that a key requirement in mobile web development is optimizing for battery usage. Battery life in your user's mobile device is an incredibly precious resource. So I want to call this out as an explicit goal, even though it's hard to directly measure. The best way to optimize battery life is, well, to only do work when you need to. This may seem pretty obvious, but all the things we've talked about in this lesson are applicable to this. In fact, network usage, computation, and rendering are all heavy indicators of battery usage. But the other APIs we'll talk about later can also affect this. For example, using the GPS changes battery usage, as does the camera. One final comment, there are several tools out there that will analyze your page for you and make some suggestions on how to improve your performance. My personal favorite, of course, is PageSpeed Insights which is a Google tool that you can point at any website and it will give you feedback on your performance. With that, and the tools you've acquired in this lesson, you're on your way to designing performant web apps. In the problem set, we're going to be going over testing the conference app, with PageSpeed. As you can see, web performance is a pretty huge topic, and it's constantly changing as web browsers change and update. We can't give you a definitive list of things to do and not to do. What we really want you to take away from this lesson is the need to constantly analyze your web app's performance. If you have the right tools, and you familiarize yourself with how to use them. You can build amazingly performant web applications. One of the most important factors in an immersive user experience on a mobile device is touch interaction. You expect a responsive interaction from a device that you hold in the palm of your hand, and with most mobile screens, your primary pointing device is your finger. As a mobile web developer, you need to be sure that you're building great touch enabled user devices. Now before we get into the details of the touch API's I wanted to share a few simple user interface guidelines. First and foremost, using hover effects as part of your primary user interface is really a bad idea. Touch screens don't generally support hover. And even worse, for those that do, your finger is typically obscuring whatever you would hover over. Secondly, you'll also notice that in great touch interfaces You need to make sure the size of hit targets, like links and menus, is appropriate. A mouse is a very accurate pointer, much more so than a finger. Most user interface guidelines suggest using hit targets that are at least ten millimeters. It's important to note, that touch is starting to show up in many desktops and laptops, like my Chromebook Pixel and many Windows eight machines. So ,don't make the mistake of thinking that touch is only for mobile devices. In fact, this is a critical point. Touch and mouse are not mutually exclusive. The user may use them both on the same device, even at the same time. One bad pattern that some mobile developers got into was detecting if touch was supported on the device, and if so, only supporting touch, not adding the mouse handlers at all. That's a bad idea. If you do this, my Chromebook Pixel will only get touch support and the trackpad won't work. Instead, you want touch support to be purely additive, like this. Notice, that the mouse handlers are still added, even if touch is supported. Now before we explore touch support in detail, it's imprtant to dunderstand that you may not even need to do anything in order to support touch. Touch evenets emulate mosue clicks already, and the web broswer builds in some estures like scrolling and zooming. So, you only need to implement somehtin here in cases where the gesture support Or mouse emulation does not give an optimal user experience. In fact, for most of our conference app we don't use touch or pointer events at all. The built in mouse emulation works great for clicking on items and it's only buried inside the session schedule and the map that touch is handled directly. The one thing that you do need to pay attention, to ,with touch on mobile, is the click delay. Touch supporting mobile browsers, usually interpret double tapping, as a zoom into this element gesture. Unfortunately, this means the platform, delays finds click of it until it can decide whether, the user is double tapping, about a third of a second, chrome has recently checked in some changes, that minimize this behavior. But, pretty much, all mobile browsers, have this click delay feature, to some degree. There are a few ways to fix this problem, and, get clicks without a delay, you can set the view port, to be non-scalable. Either, set user scalable, to no, or set minimum scale and maximum scale, to one, which has the same effect. This can cause accessibility problems, though, so be careful jumping, to this solution. You need to make sure, if you do this, that your site will never ,need to be zoomed. You can use a fast click library, like the ft labs one, that we've linked down below. But ,you do have to be careful, about how this impacts, your scrolling performance, be sure to read the directions, very carefully. Where finally, of course, you can implement tech support yourself directly, if you consume the touch events, you won't have this issue. So let's dive in to supporting Touch Events, presuming that you really need to. Touch is supported across all major mobile browsers and Chrome, Firefox, and Opera on desktop as well. So touch has its own set of events, touch start, touch move, touch end, and touch cancel. These are somewhat analogous to the Mouse Events. Mouse down, mouse move and mouse up. Although Mouse Events have only one pointer. So the target element and coordinates of the Mouse Event are just on the event object. The Touch Events are multi touch. So there are three lists of touches on each touch event object. All the active touches All the Touches that are affecting the current DOM element and all the changedTouches. In each of these lists, each individual Touch is represented by an object that contains a unique identifier for the Touch, the coordinates of the Touch, and the target DOM element in the page. Although this is an important difference. Touch events are always delivered to the element that first received that Touch. They don't walk across boundaries like Mouse Events do. So it's important to hook the right elements. In fact, it's a good idea to add the touchend handler during your touchstart handler. And, keep in mind too that even if you remove a DOM element from your tree, it still gets the events until the touch ends. So how do we test out how our desktop application works with a touch interface if we don't have a mobile device handy? Well it turns out that Chrome developer tools let us use the mouse to emulate touch event support on a non-touch desktop. Just open up the Chrome developer tools, go down to this gear down at the bottom And under Overrides, select Enable, and Emulate touch events. Now, close the overrides, but be sure to leave the dev tools open, you can minimize them to get them out of the way. And now, as you move across your interface you'll see the cursor represented by a small dot, this is emulating a touch event cursor. [MUSIC] And clicking the mouse is the same as pushing your finger down, or lifting it off. Now, you don't want to rely on this too much, it isn't perfect and it isn't exactly like having a real touch interface. So be sure to test on a real touch interface and a mobile device as well. Now when I wanted to add touchscreen support to the synthesizer application, I initially started with touch events. There were two challenges, though. First, you'll notice that on the desktop, if I don't have that touch event emulation turned on, it doesn't actually work at all when I use the mouse. [NOISE] Of course, this is expected. But I didn't really want two code paths, one for mouse and one for touch. Secondly, I really wanted to be able to have a drag across the keyboard. Play each note as you slid across it in turn. But with the way touch delivers all the events to the originally touched down element, I would have had to calculate the hit testing myself for these. And that was kind of a pain. I really wanted these touch events to be delivered to the down element for each key. Instead what happens in this synth, is when I hit one key [SOUND] and then drag, it doesn't actually move where the events are delivered. To rectify this situation, Microsoft made a standards proposal that reconciles touch events and mouse events and pen input too, into one model called pointer events. So you'll notice that pointer events are currently only natively implemented on Internet Explorer and IE mobile. For all the other browsers out there, you're going to need a poly fill library built on top of touch events. Luckily, there's a great poly fill library out there as part of the polymer project. This is what I used to implement pointer event handling in my synthesizer. The set of pointer events should look pretty familiar to you if you used mouse events before. They basically map all the mouse events directly. And then add the pointer cancel event from touch, as well. The pointer event, itself, derives from mouse event. So it gets all the same coordinates as mouse events. As well as a few things from touch. It has a unique pointer ID, similar to that touch ID we saw in touch events. And, it also has a width and a height of the touch point in touch cases. For pen cases it may have pressure or tilt. And, of course, the pionter event tells you what type of pointer it is, whether it's a mouse pointer or a touch pointer or a pen input. So let's get started using Pointer Events. To use the polyfill, you just need to include the library in your project. Or if you are already using polymer, you don't need to do that. I am in my synthesizer app, so I don't need to include anything else. Then, for each element that you want to get Pointer Events, you need to add a touch-action attribute. This let's the system know that you want to consume the events rather than having them use to do default actions like scrolling. So in my case, I added the touch action attribute to the keybox. The element that contains all of the keys. Now the spec says this should be a CSS property, but the polymer polyfill needs them to be an attribute because CSS properties are actually quite hard to polyfill. Then, I add a set of event listeners for the pointer messages. And of course, I have the actual handlers. Now, I have one set of handlers for pointer events. And, look how smoothly it works across the desktop, where I'm using a mouse input. [SOUND] And across touch interfaces as well. [SOUND] Since the conference app doesn't use touch that much, we're going to have you take a look at adding touch support to a different example. Let's take a look at how we would code a simple drawing application on a web page. First, let's look at this, as we would write it for the mouse. You can see where we've hooked the mouse down, mouse move and mouse up events. And you can see are handlers for each one of these simply creates a new stroke and the adds points to that stroke as we go. Now, we'd like you to change this code to use pointer events. Don't forget to set the touch action attribute on the HTML element that you're using as an event listener. We've already included the polymer polyfill, so you don't need to worry about doing that. Just change the event handlers to be pointer events and then make any appropriate changes to the handlers themselves if there are any. That's right, in this case we can pretty much just include the pointer polyfill, change the event handlers to be pointer messages rather than mouse messages, and use the same handlers we don't really need to change anything. Now the only problem with this code is that pointer events may be delivering multiple pointers with different pointer ID's at the same time. For example, if I'm using two fingers on my touch interface, you can tell it's getting a little bit confused about where to draw. So to fix this, I actually differentiate by pointer ID and I keep an array of points for each pointer ID. And then I use that to mask where I'm adding points to. And this version you can tell works much better with multiple pointers at the same time. I did want to mention, the touch events, and therefore, pointer events, can come in very fast. Most touch, input devices, actually, give a lot more data, than most mice do. So, what should you do, in response, to this? Should you just upgrade, your computer? Ask your users, to move, their fingers more slowly? Or, maybe, there's something that request animation frame? That's right. With a touch input type in particular we can easily get multiple touch move events, inside a single rendering frame refresh. It's pretty silly to try to paint the screen multiple times during a single video frame. We're just wasting work like we learned about in the last lesson in performance. So, it's even more important when writing touch event handler code. To not actually draw things, inside that touch event handler. But actually, buffer them up and paint them inside a request animation frame handler. Now, you may have noticed, that inside my synthesizer, I'm actually setting classes, which cause CSS refreshers in response to touch messages. This could be a problem, except that setting that class happens relatively infrequently. It only happens when you transition from one key to another. So ,it's not causing multiple refreshes per paint cycle. Which is what we're, really trying to avoid. It's also best practice, in order to reduce janking while scrolling, to use as few handlers as necessary in your application and keep the areas with touch handlers as tightly constrained as you can. That way the default scrolling mechanisms can take over as much as possible. You're probably thinking at this point, this is really low level. I really want to be able to pinch, zoom, and rotate a single visual element. Well, that's a complex gesture and there's no built-in gesture recognition in the web platform. However, there are some great gesture recognition libraries out there. Hammer JS, JQTouch, even what's built into Centure touch. If you want more complex gesture support you might want to look at one of these. Rather than attempting to roll your own. To build great touch-enabled user interfaces, there's no substitute for testing on actual touch-enabled devices. So build your designs and then load them up. See how they perform in the real world. Next up, we're going to talk about how to easily get other types of input from your users. Now it's time to talk about getting input from your users. Few of us like writing long letters on our mobile device, although I have stronger thumbs than I did even a few years, it's still relatively painful to type lots of content on a mobile device. You need to make it easy for users to input their data. Of course it's important to use relatively large text sizes. I can't read six point font with my magnifying glasses. But aside from that, one of my pet peeves is having to switch between input keyboards manually to input different types of data. If a form is asking me for my phone number, it should just give me the number keyboard by default, right? Well it turns out, this is pretty easy to do. HTML5 added new form input types to make input easier. Let's go into the dev tools, and change this text input field to a tel input field. And now, let's click on the field again, and you'll notice now, not only do I get a number pad, but I get a telephone umber pad, complete with the hash and star symbols, and alphabet assignments on the numeric keys. HTML 5 edit types for phone numbers, email addresses, URLs, numbers and dates, among others. For each one of these fields, I can go into the depth fields and change it. For example, email, right now, gives me the standard keyboard. But, if I go in and change its type to email, you may notice one subtle difference. And I now get an @ symbol on my keyboard by default. Some of the biggest changes were for dates, where I now get an actual calendar and colors, where not only do I get a nice color selection box, but I can actually edit the color. And finally, there's a simple number input type. You'll notice this is somewhat like the number input for telephone numbers, except there's no alpha numeric's and there's no hash and star sign. You may notice for some types like e-mail, there's some basic validation. But, it doesn't really understand. If you want to do better client side validation though, HTML-5 supports that too. There's also a pattern attribute on the input element, that you can use to validate on the client side. The pattern element takes a regular expression, as expressed by the java script regex syntax. Regex is a topic in itself. So, if you're not familiar with it, you'll have to look it up. For example, let's presume I want to only allow U.S. numbers with area code prefixes. So, an 11 digit number. I can put in a regular expression for this, and now when I try to input a telephone number and then submit, it pops up an error message that says I have to match the requested format. That error message, by the way, is the element's title, so you can customize it too. And now, I get my custom error message. Normally of course, I'm not going to want such a simplistic pattern. I'll probably going to want something more, like this string which says, I want a 3 digit number possibly preceded by brackets, and then optionally a space or a period or a dash, and then another 3 digits, and then the same space or period or dash, and then another 4 digits. Now, this gives some options, for how I enter telephone numbers, but I can just say, and it'll accept that. There are two more features I wanted to mention on inputs. The required attribute and the place holder attribute. Required just lets me say, this field is required before you can submit the form. So, for example, if I want to make sure that my lemur afficianados enter a telephone number, I can do that right on the input. Now, if I try to go into this field, and let's say I don't want to give a telephone number, so I just skip it And I try to submit the form. It tells me that I have to fill that field out. The other feature, is the placeholder text. You may want to give hints to your users. In some fields, they go away when they start typing. You can do that pretty easily by just setting a placeholder attribute. And now you can tell I get placeholder text in that field. But once I start typing something, it goes away. None of this removes the need for server side validation of course, but it does make it easier users not to accidentally submit something that's not valid, and it doesn't require any JavaScript on your page to do that or to provide place holder text that get's out of the user's way. Now, of course, we have to keep in mind that not all mobile browsers are going to support these new input types, at least, not right away. So the question is, what do you think should happen if a browser doesn't know how to deal with these? Should unknown types fail to display? Should the browser automatically send a detailed bug report to its vendor? Should unknown types fall back to input type equals text? Or do they just crash? The HTML spec says that unrecognized input types are to be treated as text. So, new input types will still work even if they're not supported on a particular browser. They'll just function like text inputs. Not quite as useful, but still functional. Graceful degradation at work. I did want to mention something very specific, here. You should always wrap label elements around your input elements, and their associated labeling texts, because it increases the touchable area of the control. The only difference between these two controls is that one of them has a label element around it. But you'll notice, it's much easier to touch the one with the label. The one without a label, you have to actually touch the check box itself, in order to activate the control. I mentioned before that it's still a good idea to validate your data on the server, even with client side validation. Why do you think this is? Is it because if javascript is disabled, client side validation won't work? Or because, older browsers might not recognize your new input types? Or could it also be because, it's fairly easy to circumvent client side validation? Since this new client-side validation, doesn't use Javascript directly, disabling Javascript, won't actually disable it. But, older browsers might not recognize that input type and then it lets the user type in whatever they want. And in general, it's fairly easy, to, circumvent client-side validation. And one more thing. On mobile, you can use a telecolon URL to create a URL that when activated will actually dial a telephone number. Of course, on desktop, these URLs will typically fail, so you probably want to deactivate them using a desktop media query. This is a really handy feature, particularly for business websites. Customes can instantly dial you. To sum up, the new HTML5 input types make it easy to enter phone numbers, dates, email addresses and more. And they perform powerful client-side validation as well. This can enhance the desktop experience, but it's absolutely critical for a great mobile user experience.