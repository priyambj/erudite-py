Okay everybody. We are gonna talk about the final exam. This is basically building on everything you've learned in this class. It's just another cohesive project, and what I'm going to ask you to do is build a wiki. For those of you who don't know what a wiki is, I will give you a demo. It should look something like this. Here's the front page of a wiki. A wiki is just a website where any page can be edited. For example, if I were to click edit on this page, you see the HTML of this page and I can add some text. Let's add a blank line. So I just added some text in this text box and I click save. Then we save the page and then it has this text in here. Now, one of the things that's cool about a wiki or at least in this one that we want you to build is you can go to any URL or in this case /newpage, which doesn't exist yet. If the URL does not exist, it'll redirect you to another URL. In my case, I'm using /_edit and then the page name where you can edit some content in here. And if you were to click save, it will take you to that URL. In my case /newpage with the content and of course you can edit this content. Let's add a link to the front page. We just use the anchor tag with an href to slash, which is the front page. And if we click save, we can see that it renders that HTML I typed as a link. If I were to click on this link, it'll take me to the front page, which is a slash. W'll go through the specific requirements in the instructor comments, but the important thing-- the first thing--is if you type in a URL that doesn't exist, you go to an edit page. If you type in a URL that does exist, it renders the content of that page, and you can edit the content of that page if you want. Now, I've been logged in this whole time. You should have user accounts integrated in this. If I were to click logout here, it keeps me on the same page. What this did is that it did just like we did in Unit 4. It cleared my user clear key and just redirected me to the page that I came from. I can view any page logged out, I can view the front page as well, but I can't edit any pages. See, the edit link is gone. Now, we can't grade how things look very well, so we're not going to bother doing that, but we will try to submit an edit form while being logged out and that should fail. Now, I will log back in. Now notice it's the same signup form we've been using all along. Actually, in the version I'll put online, I'll probably clean this up a little bit before I do that, because it's been bugging me in the code, but this is actually the exact same code I've been using the whole time. I'll log in as my user and you can see now I have a new edit link. That's the gist of the main wiki--of course, instead of clicking login, I could also click signup to create a new user. This is the same form we've been using for this entire class with the errors and whatnot. If I were to try to create a user that already exists, I give out that error. That's why I'm going to sign a different user spez2, click submit, and I'm logged on as spez2. That is the main task that I'm going to ask you to do. Log in. Log out. You've already done that. Editing a page. It's basically a simple form submission and some fancy redirecting in there. Again, in the instructor comments we'll include more specifically how to do that. When you have that working, submit the URL here. This is the final exam homework solution. Let's talk about the basic version first without the bonus problem. The basic version was to have a basic wiki. This is the front page. Of course there are other pages you can go to. If they exist, you see the content. If they don't exist, for example /foo, you would see an edit page. But I wasn't logged in so we won't see an edit page. Let's try that again. If you try to visit an edit page when you're not logged in, it should redirect you to the login page. So I go to a page that doesn't exist--foo. Now I'm logged in. We can see I put the user name in the upper right here. Then we get an edit page, and if we save this page, you can see we can now go to /foo and we can see this content. We go back to our front page and all is well> We've got logging in and logging out. All that works. Let's take a peak at the code. Now, this actually wasn't a whole lot of code to get a pretty functional wiki. A lot of this code you've already seen before. Oh, there's my secret. I guess I'll change that before I upload this. All of this code is basically from previous homeworks. I've actually given you most of this code. Here's my normal renderstr function and my makesecure_val for the cookie stuff and checksecureval. I added this new function called gray_style, and we'll come back to this for the bonus question but this is just a little function I wrote to alternate the coloring of rows in the UI. I don't know if there's a better way to do this or not, but this is how I did it, using something that would work in Jinja, the templating language, that I could figure out how to do otherwise. All of these functions--remember this is our superclass Handler that we've been using for all of our handlers. None of this stuff has changed. I've added it to my render_str function, I make it sow in templates so I always have access to a variable called user, which just references self.user. I have access to the function gray_style, which is that function I just pointed out. We'll come back to that. Everything else in here is actually the same. These are all basically how I left it after the end of Unit 4, really. You can see there is still some security stuff in there. I had made it so only spez could submit to the blog, and this variable isn't used in this program anymore. It's just leftover. I made a new 404 page so I could call self.notFound, and it'll actually say 404. That was something that I found kind of useful. We've got all the solved and valid password and hashing functions. This was all, again from really Unit 4 homework. The user code hasn't changed at all. The same stuff I demoed there. The SignupHandler is just about identical from Unit 2 and Unit 4 where we did the registration. The same form and the same validation. You've seen all this code before. The login is all basically the same. The only real change--actually, let's go back up to signup. I'm using the refer to keep track of what URL the form should go to after you submit it. Before we render the form, I create this variable next_url, which uses the refer header, which is sent along with every request. That's the page you are on before you went to this page. If I was on '/', and I clicked on login to go to /login, the refer would be '/', and then of course I have it default to '/'. That gets sent in to the form as an input type hidden, and the URL to go to next after we're done signing in or logging in gets passed in the form, and you can see that document here. This is the signup handler. In the post for that I look for next_url in the requests, and if it's there and if it's not login, because I don't want to have somebody signup and then immediately redirect them to /login. That came up during testing. If that parameter wasn't there or it's /login we just go to '/'. Otherwise, next_url we've validated everything and we redirect the user to next_url when they're done registering. That allows somebody to click signup on any page, and then once they sign up we take them back to that page. It's just an extra kind of nice little convenience. The login handler is almost identical to Unit 4 as well except it has the same next_url functionality. We get the referer header. I send that to my login form. I include it as an input type hidden. Then we redirect to it when the user logs in successfully. The rest of the code is the same from the Unit 4 homework. Login is basically the same except it also has a next_url. It just again looks at the refer and redirects the user to that. Now, I should probably clean this up a little bit. We've seen this exact line--this nexturl = self.request.headers nexturl--in three different places. It'd probably pull that up into the handler, but this code is kind of a work-in-progress. You're seeing it here in a little bit of a raw state. This is my page class. The page model is pretty simple. It just has content, a created time, and a last_modified time. I also wanted to have a notion of an author of what user created a particular page, but it actually wasn't relevant to the demo, so didn't bother finishing the implementation, but it would have looked something like this. You can see, again, this code is kind of in a working state, and actually what is online right now might differ from what I'm explaining here, because I've had a few more weeks to work on it to make it a little prettier. You may see this feature implemented when I release the code, or you may see this line be gone altogether. Now, I've added a couple of class methods. Some of you actually asked about this in some of the previous homeworks-- what staticmethod and classmethod do. Staticmethod basically means you don't have to pass in self to a function, which means this method here is just static. It doesn't run on an instance of the class. It's just basically a way of organizing your code a little bit better. This function parent key is only going to be called in the context of a page, so I just basically say this parent key function belongs to the page and that's how we're going to reference it in our code, but it doesn't actually take an instance of the class self or the class itself like class. It operates kind of independent. What this function is actually doing is to make the history function work. This is a little trickery there. I'll come back and explain this in a little bit more detail when I explain the solution to the bonus problem. Then I added two class methods. One is by_path for looking up a page by URL, which is kind of the default way of looking something up. All this does is this runs an app engine query or datastore query. This is a class method and what class method does is it says instead of running by_path on and instance of page, run it on page itself--just the definition. You can say Page.by_path, give it a path, and it will return a query object. Basically what this is say is get me all the pages for this URL sorted by creation time. That's kind of how I did versioning. I'll come back to that in more detail again when I talk about the bonus problem. Of course looking up Page.by_id--this is strictly for the bonus problem-- looking up older versions of a page, so if you want to look it up by id in addition to the path, that's what this function is for. NoSlash is a special handler for getting rid of extra slashes in the URL. It was kind of a work-in-progress. It wasn't working in this demo. I'm going to have to come back and clean that up. Just ignore that for now. Here is the EditPage handler. EditPage is the handler for actually editing one of the wikI pages. First thing we do is we check to see if the user is logged in. If the user is not logged in, we redirect to /login. That's important because you don't want non-logged in users to be editing your pages. They should be registered, so you know who's doing what. This code here is for the bonus problem. If you didn't do the bonus problem, all you need to really do is look up a page. This is that by_path function that I just explained on the path object. We give it the path, and then we get the page object. You can structure this however you like. What that by_path function returns is a query and on a query datastore you can either call get to get the first element of the query or you can call fetch to get multiple ones. I'm calling get, because I only want the first one. Then we render edit.html with that page, and we include that path so I can render some of the links that appear in the navigation section. Here's the definition of a post for the edit page. Again we check to see if the user exists. Now you may say, well, if the user didn't exist, how did they view the edit page? Well, they could have a couple tabs open or multiple browser windows open. If they log out on and then submit a form in the other that could cause some problems. What we do is if the user is not logged in we just return a error 400, which is basically a bad request, and return. I didn't do anything user friendly here because that shouldn't happen. It just kind of silently fails. Then what we do is we look for the actual content in the request. Then we look up an old version of the page. Then we have this little thing here. Basically, if there wasn't an old version of the page, you're creating a new page, and there wasn't any content--just return. I'll probably expand this to have an error message, but we left out a little undefined in the problem. I hadn't implemented it right away and so right now we're just kind of ignoring that. Otherwise, if we either don't have a page and have content, which is what this clause implies, or we do have a page and the content has changed. I make a new instance of page. Now, depending on whether or not you did the bonus problem, you could have edited an old version of the page. In mine, I want to keep this version history, so I create a new page for every change. Then we store that in the database. Then we redirect to just the path without the _edit, so you can actually view the content. I'll skip the history page handler, but it's actually pretty simple. We'll come back to that in a second. WikiPage is the handler for actually viewing any pages on the Wiki. It takes a path argument just like the edit page does. Notice it's only get. There's no post here. This code here is identical to the edit page, and so again, I'll probably clean this up. This basically decides whether you're looking at an old version of Page with the version number or the most recent version of the page. If you didn't do the bonus problem all you need is something like this. This says just look up the most recent version on the page. If it exists, we render page.html with that page. I also include the path so I can render those links. If it doesn't exist, I redirect this /_edit plus the path. So how do I do all the URL handling? It's actually pretty simple. What I did is I created a regular expression to match what I think is a valid URL> Basically, it has to start with "/" and then it contains one or more of the following characters--little a through little z, big A through big Z, 0 through 9, underscore, and dash--followed by an optional slash and then as many of those clauses as you want. That basically means slash is valid and then any number of these clauses is valid after that. Then our URL handlers look something like this. So /signup goes to Signup handler, /login Login, /logout Logout. These are all handlers you've seen from Unit 4. This was my NoSlash thing that is currently not working so I commented it out. Now, remember these URL get matched in order. You want to make sure that this handler here or this regular expression for rendering a wiki page would actually also capture the history URL and the edit URL, so we need to put those history URL and the edit URL first so they get matched first. What this one says here is it says if the URL is of the form /_history plus this regular expression--basically /_history/anything-- match the history page. If the URL is /_edit, basically anything, go to the edit page, and if it's anything else, go to the wiki page. That's how we go to one of those three handlers. If we take a look at the app again in the browser now that we have seen the code, some things will make a little bit more sense. When you just go to "/" we go through our URL matcher, and we say, okay, it doesn't match login, signup, or logout. It doesn't start with history oredit, so we match the other thing. Our path now becomes "/" and then we look up using our database query the page for "/". We get this page. If I were to go /newpage, we do the same thing. We use this as the key into our database, and we look up the most recent version of newpage. Here it is. Now, let's talk about editing a page. I'm not logged in, so I don't have my edit link. Let's go ahead and log in, so we can see the edit link. Here I am on newpage. Now I'm logged in as spez. I have my edit link. I'll show you those templates in a moment. When I click on edit, you can actually see it basically links to _edit/newpage. It basically inserts an _edit here. Remember that goes through our edit handler instead of the normal wiki handler. When I visit this link, the edit handler draws the different form, which gives us this whole form. I'll just click save here. It didn't change the content, so we didn't create a new version. That's how edit works. Now, of course, we can go to any URL. It matches the wiki handler first. Let's look at the wiki handler again. This wiki handler first--remember if the page, if it doesn't exist, we redirect to /_edit plus the path. The path is passed in by this regular expression. We'll go back to our browser. What's going to happen is we're going to redirect to _edit this string. There we go. That works. Now, what if I go something like this. Actually, let's take a page that already exists. Will this work? Yes. We get the edit page on this URL. Remember, our regular expression just basically matches any number of things. We can actually create a whole complicated URL structure. That's pretty cool. If I were to say here is the subpage and submit this, it works. If I were to go back to newpage, that works as well. Pretty cool. Okay. A little bit more. I'm going to add a bonus problem to this final. This is not required but if you do it you'll be eligible for a higher level of distinction in the class, and again we'll enumerate all that in the instructor comments. This bonus problem, and you may have seen this link in the demo I gave, is to add a page history to each page. This history link--implement this. When we click this history link, the URL changes to _history and then URL. In this case, we're going to front page it with a slash and you can see all the previous versions of a page. Remember, in the original demo of the problem, I just had it say, "Welcome to the Final" and then I edited the page to say, "Your task is to build a wiki." I'm just including the first 100 characters or so of a page. I can click on view of either of these links to view older versions of a page. This is the most recent version. If I want to edit a page, I can still click edit. Notice how the URL changes to _edit. If I add this other statement and I click save, you can see the page is updated. And if I were to click on history, you can see that there's a new version at the top here. This might be a little tricky. But for those of you who can figure it out, this will be a really good exercise. Let's go back to that other URL we are looking at before--new page. This was a page we added in the first part of the assignment. If I were to click history on this page, we can see that this also has two versions. The original version I made--Here's a new page-- and then the other version that had some HTML in it. Now you can see here of course in the history page, the HTML is escaped, and when we view the HTML is unescaped causing it to behave exactly like HTML. We are not going to test on that because it's up to you to decide on your wiki whether or not you want to trust your users not to put a bunch of garbage on your page or not. You know that's a decision you can make as a website owner, and we won't grill you on it. But of course in editing, the text area form should escape things properly if they're in there. so it can be edited properly, and that's all we've got. When you have that working, submit your URL here and good luck. Let's talk about the solution to the bonus problem now, which was add version history. The way that works remember is if I click history, we can see the previous versions of this page. If I were to make a new version of this page, I can click any of these edit links. If I click save, we can see we edited the page. If I click on history again, we can see this new version--version 3. You can see the content of that page up here. That was feature number one required for the bonus, which is view the history of all these pages. Feature number two is view any particular version of this. I can't just go to /new page. I have to also say what version it is. If I were to go to this middle version here, I'm going to newpage, and then I added a get parameter for what version it is. In this case it's 5. That's just the database ID. I think this one is version 10, because I've made other objects. So Google is just assigning the IDs and it doesn't really matter. Now, of course, I can edit any version of these. They have their own special URL. This is editing new page v4, which is that first version. If I were to save this, it overwrites the newest version. If we were to look at history again, we can see it's plopped up on the top. If I want to just store the most recent version, I can just click edit, save, and there is our page again, and if we go to history, we can see all the history. That's pretty cool. Let's talk about the implementation. The first thing is there are a number of ways you could've done this. You could have one page that has, instead of content, it could have a list of contents. There is a way to store lists of things in datastore. That's a fine way to do it. What I did is I basically said every page has a name, which is always going to be pages, and it has a parent called /root plus the path. I put /root in there because I thought it was going to be more complicated than it was. But basically remember entities in the datastore can have these ancestors-- this hierarchy of objects. Now, we didn't spend a whole lot of time talking about this. Understanding that isn't required for doing this homework, because there are many ways you could have done it. This is how I chose to do it. Every URL has basically this common ancestor. So when we look up a page by path, all I'm really doing is I'm saying get me all the pages that have this ancestor. Basically give me all of the pages that belong to this URL sorted by most recent. Then I always just use 'get' to get the most recent. If I want to get an old version, I use the getbyid function, which takes an ID, and it also takes a parent key, which uses the same key as the main path query. What this is saying is get me the page--in this case class refers to the page, because it's the class method and we're in page-- get me the page by ID. This is built in the datastore. I want this ID and this parent. So we can go get older versions out of history. Then we we're rendering this stuff, you can see here on EditPage I can call by_path and then call get to get the first response out of the query, or I can do this other thing, which is look for the v parameter, which is the version. If it's there and if it's a digit--if it's basically valid--try to run by_id on it. If that's not there, that page, that version just doesn't exist--Not Found. Otherwise--basically if there's no v parameter--just look up the normal version. We have the same block of code in the normal wiki page for viewing any page on the wiki. This exact same block of code, and of course we'd want to clean this up. The code that I'll give to you will probably have this cleaned up in it. Let's take a look at some of these templates real quick so we can see the last bit of how all this fits together. I'm using template inheritance again. My base template basically has the title of the wiki. It references my style sheet, and it's got the basic structure of my document, which is going to have a body tag and then a couple of divs. These classes are just for styling--not required for completing this homework. Just required to make your homework look a little bit better. I want my stuff to look slightly good, so I use them. This is the whole header area where we draw those links. Basically, if there is a user, we print the user name and then we print the logout link, which is just a basic link to /logout. If the user is not logged in, we draw two links--one for login and one for signup. Those are also just basic links. They both have the gray link style, which is how I make them gray and I make that underline hover thing work. Then I have a div here that basically doesn't have any thing in it. This is just a block. Remember this is kind of a way of doing this kind of templated inheritance stuff, so you don't have to write the same HTML over and over. Other templates that inherit from base will fill in this block. This where we put in the controls for editing a page, viewing a page or viewing the history of a page. All that stuff gets overwritten in the other templates. This clear div technique--the technique I use to float those links over to the right is called "float." When you float something it doesn't take up any space. One of the techniques to make it take up space is use this clear div. I'm not going to attempt to explain that here, but it's basically a CSS trick for floating something over to the edge of the screen and still having it have vertical height. Here we have the actual content. This is where the edit window is going to go or the wiki content page. And again there's no content in here, we just define the block and the other templates will override it. Let's look at the template for page html which basically draws the actual wiki content page. It extends base.html, which basically says use all that other stuff and then we can just override the two blocks. On an edit page, or I mean sorry on a viewing page, a normal wiki page, you have two links. One for edit and for viewing the history. But we only draw the edit link if the user is logged in. If the user is logged in, draw the edit link, regardless of whether the user is logged in, draw the history link. And these two links are simple. One is _edit and the path, remember the path was passed into my render function. And one is _history to the path. Both those links are simple links that are handled by the appropriate handler . Then, the actual content, we render the page content and I use the jinja safe notation which basically says don't escape this, which basically says take the html that was typed in and insert directly in the page. Security issues be damned, since I entered all the html, I know it's okay. Now, if you're going to put this website online, you want to have probably some special escaping. What a lot of websites do, is they only allow some html or they have a special language that turns into html or they don't allow html at all but that wouldn't allow links and then the wiki wouldn't be very useful. That's a design issue, that's up to you. Edit html, this is our template for the edit page. The controls are very similar to the viewing page. We have a link to just called view which links to the page itself, basically kind of like a cancel button. Then we have a link to the history of the page so you can view the history of the page right from the edit page. And these are just basic links and we only draw these links if the page already exists. If you're creating a new page, there's nothing to view and there's no history so that's what if page is done. And remember when we call this template, we pass in whether the page existed. Now here is my form, it's a method post, it has this class, it's called main edit, that's just for styling purposes to make it render nice and big. It's basically a giant text area whose name is "content" and who includes basically page and page.content. So if the page exists, render its content, otherwise render an empty string, that's what going on there. Then, at the bottom of the form, we have this little area called form footer which just has the safe button. We'll go through all that CSS. So the edit page is actually fairly simple as well. The history page is for viewing the history of a wiki page. Again, we've got our controls, if the user exists, draw the edit link, just like the main wiki view page. Regardless of whether user is logged in, draw the view link to just view the page instead of viewing the history. Then our content here, I'm drawing a table. Now, we didn't spend a whole lot of time or any time at all on tables in this class so use some of the examples that I've given you. But it does what you would expect, it draws a table. We draw a table, history table is what I used to style it. Now, I will show you that function again called gray style. What this does is basically for p and posts, return the p and basically whether that row is even or odd, so that's how I do that effect where each row, one is white and one is gray. So I will show you the effect first. Here it is, this is the history page. You can see the first row is white, second row gray, white, gray, white. That's kind of a nice effect when you have a table. I just did a simple version of that. The code to generate which of these rows should be gray is something like this. Here is that gray style function, we'll look at this in template again but basically it takes a list and it enumerates over the list, this is a built in python function that basically says return the elements of list in a tuple along with the index of that element in the list. For x and list, it would return basically each page, page 1, page 2, page 3. For n x in enumerate list basically says index into the list, 0, page 1, 0, page 2 as tuples. Then if n is modulo 2 = 0 basically if it's even, the row should be blank or basically return x and blank. If it's odd, return x and gray. There's a lot of stuff going on in this function. It's also using yield which is how you build generators. This is complex stuff, not required for the homework at all but this is how I wanted to create that effect. You can also create the effect in the template itself by having a variable that you create and check to see if it's even or odd. This is the more pythonic way of doing it. Back to the template, p rowstyle so rowstyle is either going to be a blank string or the string gray. Then I use that in the class name for each row. Each row is either going to have a class of nothing or of the word gray and that's how in the CSS I decide whether to make the row gray or not. So then I have three columns, that's what TD does. First column is the date, so I just print the last modified time. The second column is the content, I print the first 100 characters of the content and then the next column is a link to view that version of the page, which is just a normal link, it's got that gray link style on it which makes it look like my other links. Then href points to the path and then I add a gip parameter v = and then the ID of that post. Remember .key.ID is how you get the ID of an element in Google datastore or of an entity. The url would be basically the path of the page we're on plus the ID stored in the v parameter. We saw in the edit and the wiki handlers, we look for that v parameter to see if we can find a specific item. Going a little bit further down, if the user is logged in, if user, we create the "edit" link. This is a link to edit or it's a link called "edit" and it's a link to /_edit and then basically the same link as up here. Path, v = and then we include the idea of the page. Now, I should probably clean this up, I should probably have a function maybe on page that says "edit url", "history url", "normal url", "version url", that sort stuff would be really handy and I would have to keep including that in the template and that's probably one of the first changes I'll make because this is kind of error prone, you've got all this code that's the same, these two lines are the same basically and you don't want to get into that situation, because if I edit one I've got to remember to edit the other, etc., etc. Then we just close out our if statement, our four loop and our table and that's how we do the history page. So that's all the templates, I'll walk you to the CSS real quick, that I use to style things and then we'll be done. First I say "html", remember outside the body element is the html element, I say height 100 percent and this is part of what allows me to make that text area on the edit page take up the whole page. Let's take a look at that real quick. If I click edit up here, my technique for making this text area fill the entire browser is basically to make the html which normally is just the size of the content, actually take up 100 percent of the space so that's what that 100 percent does. The body element also needs to be 100 percent for the same reason. Position relative is when you need to adjust where things appear relative to where they should appear or you need to have position relative on a parent element of an element that you're going to position absolutely which is what you do when you want something to be positioned specifically on the page and we'll come down to that. I choose my font, my default font size, the width of the whole document which is 800 pixels. Margin 0 auto basically says center that. Our default color which is this gray color for all our text. The header area of the page is 30 pixels tall, the line height is 30 which causes the text to actually center vertically. We get a 10 pixel margin for the content. The control element floats to the right, control element, those are the links for editing, viewing and history that appear over here in the browser. Float right says take the content and float it to the right. And it's gray, font size 13. Controls following controls, give it a little space between them, remember we have separate controls for logging in and sign-up and for doing the page actions, then just put some space between it. I can show you that real quick. Right here, this is that 20 pixels, between those two things, this is one control element and this is another control element and they're both floated to the right so they kind of stack over there. That's what those two things do. A gray link , we use this all over the place, basically make our links gray and don't underline them. If they're visited, instead of drawing them as purple, draw them as gray. If the mouse is over them, that's what hover does, draw the underline, so that behavior will look something like this: when I put the mouse over the log out here you can see the underline appears and all of our links have that effect and that's kind of an effect I like. You can see we used the gray link over here on all these styles as well so the underline appears when the mouse goes over it and you can do that all in CSS. Errors should be red, we use that all the time. Main edit, this is the class that's on that main form and it's position absolute so that allows me to basically force the positioning of this element so I say positioning at 45 pixels from the top of the page, 0 pixels from the right, 10 pixels from the bottom, 0 pixels from the left so that makes our form grow up to fill the whole space. Then text area under main edit is the same thing except 0 pixels from the top of the form, 30 pixels from the bottom of the form, that gives us room for the button and then 0 pixels from the left, 0 pixels from the right. That makes our text area take up nearly the entire form. Our form footer is also positioned absolute and that's at the bottom, 0 pixels from the bottom, 0 pixels from the left, 0 pixels from the right. I didn't specify top which basically means draw it normally and I say height 30 pixels so that draws a row along the bottom for a save button that is 30 pixels tall. Our submit button is font size 18 pixels. Here is our table, border collapse, collapse basically just shrinks our table a little bit, otherwise tables have this default spacing between all of the cells. If a table has a CSS attribute of gray, which is how we do alternating rows, set the background color to "eee" which is basically light gray. If it's a date cell, make the width 200 pixels. If it's a content cell give it some padding so it fattens up our table a little bit. If it's a link cell have a little--padding, just giving it a number says put padding on top, bottom, left and right 10 pixels. If you do it like this, the first number is vertical padding which we say zero and this is horizontal padding five pixels and this gives us this effect. The little five pixels between the view and edit here, if I got rid of that these would actually-- there would be no space between these words because we're in a table so that just adds that little space. That's it, I know it's a lot. We didn't cover CSS in this course but I'd still like to show you it in case you have questions. I'll provide the CSS and you can play around with it in your own projects and that's it for the final. If you managed to figure all that out, that's really impressive. I know that the final stuff was challenging and the bonus question of doing the history itself was also pretty tricky. So if you managed to get all of this working that's a very good job, that's really cool and that's a sign that you have learned a lot in this class and for those of you who didn't figure it out or didn't try that's something to aspire to down the road. So that's it for the class, I want to thank you all for hanging with me this far, it's been a really fun experience and I hope you learned as much as I did. Over the last few weeks, it's been a lot of fun. I'll see you around the internet and good luck out there! Hi everybody. Welcome to Web Development. In this course, we're going to learn how to build web applications together. Over the entire course, we're going to be basically building a blog. A fully functional blog, that'll have user registration, submitting links, viewing, everything together, just like a real blog. And it'll be online on the real internet, for you and anybody else to see. And by the end of this class, in addition to that blog, I'll also get you to build a wiki as your final exam. And I figure if you can build a blog and a wiki and get those things online, you can build just about anything. In this lesson, we're going to take it from the very top. We'll start with the internet and browsers, and how these things fit together. We'll also talk about basic HTML. And we'll develop a common vocabulary, so [INAUDIBLE] communicate through the rest of this course. With that said, let's get started. Okay, hey everybody welcome to Unit 1. In this unit we're going to be basically discussing the basics of the web. So, in this unit we're going to cover the web, what it is, what it looks like, how, how their major pieces fit together. We'll talk about HTML which is the main document type of the web. We'll talk about URLs which is how you refer to documents on the web. We'll talk about HTTP which is the protocol that unites the web, that the web runs on. And then we'll talk about Web Applications and, you know, what they are and how they fit into this big picture. And this is, you know, the grand finale. This is what the course is actually about. Let's begin with a discussion of the World Wide Web. The World Wide Web is a collection of HTML documents. These documents are made up of something called HTML, which stands for HyperText Markup Language. This is the basis for almost every webpage. Even though there can be, you know, documents, images, videos, and you know, all sorts of things online. HTML is what glues everything together, and the links between these pages called hyperlinks or links for short, is what makes the web, web-like. The web was invented in the early 1990s, and has something on the order of 30 billion pages. Time for the first quiz. What is the main type of document on the web? Is it HTML, Microsoft Word documents, PDFs, or Plain Text? The answer is HTML. While all of these things can exist on the web, any type of file can be linked to. HTML documents are the, the basis for everything on the web. Okay, let's do another quiz, and I promise these will get more challenging as we go. [LAUGH] Next question. What type of files can be found on the web? Check all that apply. Plain text, HTML, images, videos, or music? The answer is all of the above. As I said, anything can exist on the web. While HTML is the, the main type of content, you can link to whatever you like and these are all perfectly fine examples. Okay, let's take a step back for a second and talk about the major pieces of the Web, or, or, or the major concepts we're going to be discussing in this lesson. The major pieces are you, your computer running a Web browser, the Internet, and servers. Your browser makes requests via the Internet to servers. These requests are using a protocol called http and the servers respond with files that your browser displays. Some examples of browsers are Internet Explorer, Chrome, Firefox. You're probably running one of those right now. These servers are computers just like yours except they are optimized for sitting in a closet and hosting files rather than sitting on your desk, you know, browsing these files. And the protocol http that we are speaking is, is just a very simple protocol that your browser uses to communicate with these servers. We'll discuss each of these pieces. Well, we won't spend a whole lot of time on the Internet, but we'll discuss each of these pieces in turn throughout this lesson. Okay. Time for another quiz. What I'd like you to do is, take the letters that are near each piece of technology we just discussed and match them up with their name and definition. Your options are HTTP, the main protocol of the Web. Servers, computers that host the files that make up the Web. The Internet, the worlds largest computer network. And your browser, a program that runs on your computer to display files found on the Web. Take the letters next to each piece of technology and put them in the correct box. The answers are HTTP. That is represented by these little arrows, and letter C. Servers, that is represented by these little purple boxes, D. Okay, the internet, that is represented by the industry standard picture of the internet, which a cloud, letter B. And your browser, which is the little squiggly program running on your laptop, A. Another quick quiz. Which of these browsers is the best? Your options are Internet Explorer, Firefox, Chrome, Safari, or Opera. Check which one is the correct answer. And the answer is, none of them. This is more than just a trick question. The point I'm trying to make, is that all of these browsers are a little different. And if you've used more than one of them, you'll know that, that's obviously true. However, none of these browsers are perfect. And in fact, it's not even clear when we're doing web development what perfect is. It, it's a very imperfect art the web design is. And so, while you may have a preference for one of these browsers, it is not necessarily true that your users agree. You know, you may like Chrome, and your users may prefer Internet Explorer. Or more realist, realistically, you may like Chrome, and your users are forced to use Internet Explorer. So you need to have in mind that all of these browsers are different. They all behave differently. And you need to keep that in mind as you as you develop and test in as many browsers as you can. Okay guys, we are going to discuss HTML or Hypertext Markup Language. HTML documents are the, the heart of the Web. The Web is basically made up of these documents that can do a number of things. So HTML is made up of text content, which is what you see. It's made up of markup3 which is what that content looks like or how it's arranged. It's made up of references to other documents, like images and videos. You may have something that looks like this and you've got some text and you'll have a, you know, an image on your page. Or like the page you're looking at now, which has got a video in the middle of it. You know, the page you're looking at now is made up of HTML and it's got references to a big fat video. And it can be made up of links to other pages. And, I'm sure you're very familiar with what links are and how they're used. Let's let's play around with HTML a little bit. This is a simple HTML editor we have so we can play with things and test them out. You can follow along by either, I think there should be a link in the course notes, or you can also go to www.udacity.com/html.playground. And that should get you this this little page where you can kind of experiment a little bit. This is kind of a, a fake little test browser. So, the first thing I'd like to show you is that if we have just some blank text. If we were to render this as HTML, it would look the same. Plain text is plain text in HTML, for the most part. But if we want to make the text look different, we need to use something called markup, which is one of the other facets of HTML. And let's learn a little bit about markup. HTML markup is made up of things called tags. Tags look something like this. The way a tag is structured is, you've got, a less than symbol, the tag name, a greater than symbol, the tag contents, which can actually be other tags or it could just be text, another less than symbol, a slash, the name, and a greater than symbol. There's two ways that I might refer to this. We'd call this the opening tag. This one, the one with the slash in front of the name, we call this the closing tag. The names are always the same, and the only difference is the closing tag has a slash in front of the name. So you've always got name, contents, name. Opening tag, contents, closing tag. Now, I'll also refer to this whole thing as an element. And, you know, this, this isn't something I'm, I'm really going to quiz you on. I just want you to, you know, understand that when I'm talking about HTML I may refer to a tag or I may refer to the whole thing as the elements, or sometimes I kind of switch the words a little bit. But, that's what I'm referring to. I'm just referring to, you know, this structure here. Let's learn about our first tag. Okay, the first tag we're going to learn about is the b-tag and it looks like this. It's got an opening b and a closing b. There's a closing slash. And anything that appears inside the b-tag appears bold. So, this is b for bold. Pretty simple tag. Let's let's play around with this in the HTML editor a little bit. Here we are. We got this you know, this plain text that we've typed in before. Let's let's make one of these words bold. Okay. So, I took the word love and I preceded it by, an opening tag and a closing tag. And when we, when we click UPDATE here to update this. The word love is now in bold. Pretty simple huh? Quiz time. In the box below, make the words reasonably straightforward appear bold. The answer should look something like this. Should be, the HTML is, and then we have our opening b tag, the words, reasonably straightforward, and then our closing b tag. It's also possible to do this, and I didn't, I wasn't super clear when I gave you the problem, that you could put a b tag just around the word reasonably and just around the word straightforward. But, obviously it's easier if you put it around just the whole phrase and, you know, then you only need one element instead of two. I want to teach you about another tag. This one is called the em tag. It stands for emphasis, and it makes things italic. It looks like this. You've got the opening em tag, contents, and then the closing em tag with the slash. Same structure as the bold tag. Nothing too nothing too complex here. Let's try it out in the browser really quick. Okay, so here we are in our browser again. Let's make the word learn italicized. So all I do is I put an opening em tag and then I put a closing em tag, and I hit Update. And that took the word learn and made it italicized. What I'd like you to do is take the whole phrase below and make it italic. And the answer should look like this. You've got your opening em tag, the phrase HTML is reasonably straightforward, and then the closing em tag. And, our b tags are still where we left them. Hopefully you managed to figure this out that HTML tags can be nested just fine and the, the whole phrase is in italics because the whole phrase is surrounded by these tags. And just the words reasonably straightforward are in bold because those are just the words that are surrounded by the b tags. Let's experiment with that in the editor a little bit here. So I'm going to take the closing em tag off here and put it on the back. And if we update this, we can see that the whole phrase learn to love HTML is in italics, and that's what we just saw on the quiz. Let's change it up a little bit. I'm going to delete this closing em tag, and I'd like you to tell me what happens when we don't have the closing em tag. In our previous example, we had an opening em tag and I left off the closing tag. When happens when we forget to close that em tag? Nothing is italicized. The browser crashes. Everything after that opening em tag is italicized or, I don't know, your guess is as good as mine. The correct answer is, everything after the opening em tag is italicized. If your browser crashes you should quit using Internet Explorer, and you know, maybe this last answer is more truthful than joke, because [LAUGH] there's definitely a world in which browsers behave in a somewhat. Unpredictable manner, but I think in this in this simple example, everything after the em tag should be italicized. And let's let's try it out in our browser just to be certain. Okay, text is where I left it. No closing em tag, update. Cool, everything's still italicized. If I were to you know, move this em tag closing em tag here. And update, we can see that HTML straightens up because just the em is around this phrase. Enough of those simple tags, let's learn something a little bit more complex. Okay. I like to teach you about a new concept. These are called HTML attributes. They look something like this. We still have our opening tag name and, and a closing tag as before with this slash but we have an, a new thing called an attribute. Attributes have a name, in this case, I just called it ATTR. Equals, and you've got quotes and the value is inside the quotes, and attributes these days always equal a value. Didn't use to be the case to be the case to be honest but everything we're going to do is, is, equals a value. And tags can actually have multiple attributes. An example of a tag that uses an attribute is the anchor tag, which is the a tag, and a full example looks something like this. You've got the opening a, you've got an attribute called href, you've got its value, in which in this case is a URL, you've got the contents, and then you've got the closing anchor tag. So if you were to render this in HTML we'd just see the word derp, but it would be a link to reddit.com. Anchors are for making links. Let's play around with this in our browser a little bit and see it in action. Okay, so we've got our HTML from before. I'm going to clean out some of these tags here, so we have a little bit more room to work. Let's make the, the words HTML here a link. So, we're going to make an opening a tag. An href to www.w3c.org/html and a closing a tag. When we render this, we see that HTML has turned into a link and if I were to click this it would open this page, w3c.org in a new window. Pretty neat, huh? Okay, so quick quiz. Take the phrase below or take the words my favorite from the phrase below and make those words a link to udacity.com. And the answer is you just take the phrase my favorite, you surround it by an anchor tag opening and closing, and then you have an href attribute equals udacity.com. Easy peasy. Alright so, let's learn another tag. This one is the image tag. It looks like this, IMG, and this is for including images. It has the following structure. The opening IMG tag. It has an attribute called source, SRC equals, and this equals the URL. This is the URL of the image to download. Remember, we talked about how the web service can serve all sorts of different types of content? If you're going to serve an image, this is how you would do it. You would include it in an image tag in HTML, and you reference the URL. And then there's another attribute called alt. Which stands for alternate, and this is text that gets displayed when the image doesn't load. Its required in the sense that HTML parses will complain at you if it's not there? Nothing will break, but it's really nice to include it. So broken requests like if, if, if our browser requested a URL that doesn't exist, this is the text that gets displayed, and it's also for blind people. You know, it doesn't take much to add an alt text that'll make somebody's life or somebody's day at least mildly easier. And one other thing I'd like to point out here, is every tag that we've talked about so far has had a closing tag. Images don't. This is the entire tag. There's no contents to an image. See? It just ends right here. This is called a void tag, and a void tag is a tag that has no content, and because it has no content, it doesn't need a closing tag. Let's try this thing out in the browser and see how it looks in real life. Okay, so here we are in our little HTML previewer. Let's, let's add an image. Okay so, we've got our, our image tag, src equals udacity.com and hipmunk.png. This is our URL of an image that I've prepared for us. We've got some alt text there. Let's go ahead and click Update. And ta dah, there's our image. Now, a couple other things we can do. I can put some text here. There's our text. Images just appear in line with text. Yeah, so a small image just appears right in the middle of other text. Let's talk about whitespace for a moment. So, you may have noticed when I was entering text in the, in the editor before, that even though I put text on multiple lines, when I rendered it in HTML it rendered all on a single line. This is because in HTML all whitespace, new lines, tabs, spaces all turn into a single space. To force our HTML to have multiple lines we can use another tag called the br tag. It looks like this. It is also a void tag, stands for break, and it's a void tag. And you put this after, after any lines that you want to appear on multiple lines. Let's lets play around with this in the browser a little bit. Here we are in the browser. Let's let's enter some text. We've got this text that's really too long for one line, and when we render this, it appears as one line. Let's put a line break here. When I render this, it still appears as one line. If we want to render multiple lines, we can enter the br tag like here. No problem. And now we have a line break. And we can even enter multiple br tags if we want multiple line breaks. 'Kay? There we go. Two line breaks or two br's equals two line breaks. Cool, huh? Another way of doing line breaks is to use the p tag. This stands for paragraph. This is not a, a void tag. So the p tag has content and it looks like this. So it's, that you know, because it's not a void tag, it has a closing tag, and we have a opening tag. So you've got opening p, content, closing p, and this will render as one paragraph. Lets check this out in the browser really quick Okay. So we've got these two lines. Let's take a different approach. I'm going to start this line with a paragraph tag, and we'll, we'll render this. Ah-ha. Now we've got a line break here in our text. Now the font got bigger, and that's kind of a side effect of our, of our HTML tool. It must be some sort of style set on p. That doesn't normally happen. I'm going to wrap the, the bottom line with a paragraph as well. Okay. There we go. Now we've got two lines the same kind of basic idea as we had before. Now, we'll, we'll talk about why there's this extra space in here even though there's no space between this text up here. We'll come to that in a minute. But first, quiz time. Take this text here. Hello, everyone, we're using two lines now. And enter the HTML to draw that as it's formatted here, with two lines. And I want you to use the, the br tag. Okay, so the answer looks something like this. We've got the string hello everyone, the br tag, and then more text. We're using two lines now. Pretty simple. Okay. Now I'd like you to do the same thing, and this time use the paragraph tag instead. And the answer should look something like this. We've got an opening paragraph, some text, closing paragraph. That's our line one. And then we've got another opening paragraph, line two, and then the closing paragraph. Not too tricky, I hope. One last thing I'd like to talk about with br and p, I'll show you right now. Let's let's make this all be one line again, okay? So I update this and we have one line. If we, we can put a br tag in the middle of this. We don't actually have to have the line breaks in our HTML. So when I click Update, we, we get our, our line break no matter how the HTML is formatted. So, we can format this however we want, put all of these spaces in here. And when we update this, it'll always come out the same. There's an example. All this white space turns into turns into one single space. All of these new lines here, turn into one single space. You know, this text space is really, you know, you get the idea. Okay. Why do we have two different ways of making new lines? Why do we have a br tag and a p tag? The answer is because the br tag is what we call inline, and the p tag, is what we call block. Now, so what the br tag was actually doing was just ending a line. So when we have some text and we put a br in the middle of it, it just basically says the line ends here and this guy wraps to the next line. The p tag works differently. The p tag actually makes an invisible box. So when we have HTML looks like this, this creates an actual box. So instead of just rendering text, blank line, what this is actually rendering is something sort of like this. Here, we've got two lines of text and there's actually this invisible box around text. And that's what the p tag does, is it makes this invisible box. And this invisible box can actually have height, and it can have width, where inline elements are just text. So the example over here would be more like this. So it's just two lines of text and there's really just a little new line here. There's nothing nothing fancy going on. And the difference between inline and block elements will come up a fair amount later in this course and it's just it's important to know that there's a distinction and they have kind of a different behavior. So far, all of the elements we've learned other than p are inline elements. So, inline elements are b, em, even img is an inline element. And we saw how, before, our our little Hipmunk image appeared right in the middle of the text. That's because it's inline. And so far, the only block element we've learned is the p element. Two more elements I'd like to teach you. These are called span and div. Span and div are both normal elements. They can both have content. And the only difference between these two is, span is inline, and div is block. We'll play around with these in the editor a little bit, but these elements don't do anything other than just contain their content. And there's a way to attach styles to them, to adjust different behaviors of how they display. That looks something like this. So you can see I've added two attributes, or an attribute to each of these called class. And this is a CSS class, and this is not something we're going to spend a whole lot of time on in this course, I'll provide most of the CSS. But it's a separate language for adding styles to your documents or changing the, changing how different text looks. And we'll be using spans and divs a lot for, you know, controlling how text is laid out. But the important thing to remember is that spans are inline and divs are block. Let's play around with these in the browser a little bit real quick so you can see what I'm talking about. Okay, so we've got our text. And my first line is wrapped in span, and it behaves as, as we would expect an inline element to behave. Now if I were to change the span to a div, it behaves more like how the paragraph tag before behaved. This div is actually this, creates a box around this piece of text and you can see my, we actually did something interesting, I added a little period after the div and the period appears down on the second line here. What I'd like you to do is check all the elements that are inline. Some of these elements you haven't seen before. So I would like you to try them out in your own browser and figure it out for yourself. Okay, so the answer the inline elements are a, the anchor tag, the span tag, the image tag, the strong tag, and the line break tag is actually considered inline. This one is, is a little tricky, but the br tag doesn't have any with, it doesn't behave like the other block elements do, it doesn't make like a box on the screen. It just creates a newline. So, anyway, hopefully you managed to figure that one out or you learned something today. That's enough HTML elements for now. I want to talk about the structure of an actual HTML document really quick before we move on. Now, what we've been seeing before is just little mark up. We've been seeing things like this. You know little tags, a few little simple tags. But an actual complete HTML document has quite a bit more in it. Here's a whole lot more HTML. Let's take this piece by piece but this is what a complete HTML document looks like. First we have the DOCTYPE. And this is what kind of, of HTML this is. This string right here is, used to be a lot more complex. If you were to Google for DOCTYPES you would see a lot of different answers here. But now that we're using HTML5, it has a nice clean simple doc type, which is just the string HTML. Very simple, okay. Then we have a tag. This is the basically the, the opening HTML tag and the closing HTML tag. This surrounds the entire rest of the document. That's all it does, is it surrounds the entire document. Now I've got this other tag here, the head. This part of the document has kind of metadata and, and another random stuff. If you were to include JavaScript and CSS, CSS, remember we talked about it as the filing sort of stuff, that would be included in the head section. Now we also have this little tag here, the title, and this is the title of the page. This is what would appear in the top of your browser window, or in, in your browser tab, this string right here. Then we have the body tag, and the body tag is the actual contents of the document. And basically, we've been, we've been working just in the body tag in this lesson. And for most of this course, we're really just going to be focusing on generating the content that fits between the body tags. It's all this other stuff is important and you'll see it, and we'll be, you know, we'll sending over the wire. But it doesn't change very often and, you know, it's pretty simple, but it is pretty important for it to be there. All of the interesting stuff though happens between the body tags. Okay, let's take another view at HTML documents, they have a structure that can visualized like this. An HTML document this whole thing has a head section and that's where we have our title, references to any CSS files, and Java script files, and that sort of stuff. And then we have the body section and this is where the actual contents of the document, the stuff that you see on the screen. This is where that comes from. And in this course where mostly going to focus on this part of an HTML document. Just the body section and there's a lot of content that can go in there. Well, we'll, you know, discuss briefly, you know, CSS and JavaScript and how they fit into everything. But, for the most part, we're going to be generating the contents, the body, of, of an HTML document. Let's talk about URLs. undoubtedly, you've seen URLs before. URL stands for Uniform Resource Locator. An example of URL would be as follows. This is an example of URL. It's got three main parts. It's got the protocol, separated by a column and two slashes from the host. Which precedes the path and in this case the path is just a slash and if we didn't have that slash there the path would still be a slash because that's the, the minimum path. Now, the protocol can be a number of things but for our purposes it's going to be http almost all the time. We will also see https from time to time. And you'll see other protocols around the web. You might see ftp or you know, things, things like that, but http basically means, you know, the web. That's, that's what we're going to be learning in this class. The host, this is the host name or domain name of the, of the server that has the document we want to access. This can also be an IP address. This host just of course, translates into an IP address, and this is the. You know, the description of the location of the physical machine that has the document we want to fetch. And the path is the document we're going to fetch. Now, the path can be more complicated. So the path would be this whole thing if we were accessing the image we were using in the previous part of the lecture. Okay, quiz. Given the protocol ftp, the host www.udacity.com and the path /about, what is the correct url? The correct answer is: ftp://www.udacity.com/about. Nice work. Okay. Let's add something new to our URLs called a query parameter, also known as get parameters, and we'll talk about this name shortly, when we start talking about HTTP. Here is an example. We've got our normal URL or the type of, the simple URL we just discussed, with a, a simple path slash foo and we've added to the end of this a question mark p equals one. And this adds an actual, extra parameter whose name is P and whose value is one. The format of a query parameter looks like this. You've got name equals value, or in this case P equals 1. And the value can be just about anything, but it's good not to use question marks and other URL characters, although you could if you really wanted. We can make this a little bit more complicated by adding more query parameters. Let's do that. We've added a second query parameter. The first query parameter is separated from the UR, URL using a, question mark. All of the following parameters are separated from each other using ampersands. First one gets a question mark. The next one gets an ampersand. In this case, the new parameter is Q, and it equals the string neat. So, we have these query parameters. What are they for? They're for basically, when you, when you make a request for this path, this is extra information the server gets, and there's all sorts of things you can do with this. If this is a, a web application doing fancy things these parameters might mean something. It can affect the caching because technically it changes the entire URL. So there are all sorts of handy uses that we'll discuss later in the class for what these query parameters can do. But they are separate from the path. But they are included in part of the whole URL that the server sees when you make a request. In the following URL, what is the value of the Z parameter? Here is your URL. The correct answer is P. There's nothing fancy going on where, you know, p equals foo and then, you know, because z equals p, z also equals foo. There's not that level of computation. Now, if the server wants to do that down the road, that's fine. But in the general, in the general case, z just equals the letter p, and that's it. Okay. I want to add one more piece to our URL's. And that's called a fragment. A fragment is separated from the rest of the URL by a hash sign. A fragment is generally used to reference a particular part of the page you are looking at. There are other fancier uses if you're, if you're going to do some complex JavaScript things. But for our purposes, it's just there. And all I really want you to know is that when you see it in the URL, it is not sent to the server when you make a request. The fragment purely exists in the browser. If we had a URL with both queries and a fragment, I'll show you how that looks. When there are query parameters, the fragment follows the query parameters. It comes last. There's another piece to URLs I'd like to show you. And this is the, this is the final piece I'll talk about right now, and that's called the port. When you make a web request to a server, this is the host, this is the, the name of the machine or, or the location of the machine you're requesting. In order to make an internet connection you need two things. You need one, the address of the machine, which is represented by the host And two, you also need a port. And by default the port equals 80. If you want to use a different port you can include it in the URL between the host and the path separated by a colon. And in this case we'll be making our request on port 8,000. Get used to this URL because this will be your local development URL for a lot of this course, and actually for a lot of your career as a web developer. You're constantly accessing your local machine and you're probably doing it on something other than port 80. There are even more parts to a URL, but they're not particularly relevant to us right now, they'll come up, you know, as we go. Let's do one final quiz about URL's before we move on. What I'd like you to do is take this URL and identify its main parts host, protocol, fragment, query, and port. Correct answer is host. That's example.com. Protocol, simple, HTTP. Fragments, that's hash blah. Query is question mark P equals foo. And the port is 80. Okay. Let's move on and now we're going to talk about HTTP. If you recall, this was what we described as the main protocol of the Web. This is what your browser uses to talk to the, to Web servers. HTTP stands for HyperText Transfer Protocol. The request from your browser for the URL www.example.com/foo, begins with a request line, it'll look something like this. This is the request line, now HTTP is a, a very simple text protocol. So, this text is sent over the Internet to the server, just like this, it's human readable too. The request line has three main parts. First there's the method, next is the path and finally is the version. The method is what type of requests are making to the server. The most common method by far is GET. And this is how you GET a document from the server. Other popular methods are GET and POST. There are other ones, but these are the ones we're going to use in the class. Next is the path. In this case, it's /foo. You remember this from the URL. But the path and URL comes here. This is the actual document we're requesting from the server. And finally is the version. It's always http/ and then a version number. Most browsers and servers these days speak at 1.1, but we'll also touch on 1.0 a little bit in this class. Because 1.0 has, you know, a few uses of its own. Now, you're wondering where the host name is in this request line? It's not here. All that's here is the path. We're connected to this host, your browser connected to this host. Or, if we're playing around with HTTP, we made the connection. But that's how we know where we are. So that's, this is used for making the connection, and the path is used for making the request. Let's have a quick quiz. Given the following URL, example.com/foo/logo.png?P=1#tricky, what is the request line to get this URL using HTTP 1.1? The answer is GET /foo/logo.png?p=1 HTTP/1.1. Now, the GET makes sense, that this is the method we're using. The version is pretty simple. That's, that was specified in the question. Now the path is a little tricky. The path includes this much here. But the fragments are not included in the path. They're never sent to the server. So when your browser makes a request, for this path, this is all it sends to example.com. The fragment and the hash mark stay purely on the client side, or in, also known as in the browser. Final URL question. Which method is most often used for requesting a document from the server? The correct answer is Get. Other answers we've talked about today or other potential answers would be Post but Post is most often used for sending data to the server. That's enough of request lines for now, let's talk about the rest of the HTTP request. OK so we had a request line that looks something like this. It is followed by a number of headers. Headers have this format, Name: space value. Let's add some headers. When you make a request, all of this is sent at once, the request line followed by a number of headers. These aren't the only headers that are sent but these are some of the more popular ones. The first one is called Host, and this is from the URL. This is the host part of the URL. It's required in HTTP/1.1. It's not strictly required in 1.0. But why is this useful? We're already connecting to the machine. So why do we need to say what the host is again? It would be like if you came up to me and said, Steve, what is your name? Obviously, you already know my name. So why are you asking? Well, it's because web servers may have multiple names. One, one machine, one web server, can host the website for many websites. For example, with udacity.com, which is hosted on Google's app engine, each of those machines host many websites. So, we need to say which website we're requesting a document for. The next header, this one is called User-Agent. This describes basically what, who is making the request. This is generally your browser. Your browser put its name in there and there's also some, some version info and things like that. And this is really helpful for the servers so they know what type of machine is making a request. Okay, so I want to add a little more about user agents. So it's, it's one of the most important headers in an HTTP request. And when we were doing Reddit, user agents were really important to us. So we had the site that was online and really popular. And users were always you know, often writing scripts to, to pull content out on Reddit. And, you know, mostly they were doing good things. They were building you know, tools to, you know, do data collections so they can do some, you know, cool blog post about how Reddit works and that sort of thing. Sometimes they're doing bad things. You know, there are spammers, you know, looking for weaknesses or, you know, looking for ways to game the system. And user agents are important because sometimes, you know, a user would hit us a little too hard too fast, you know, basically, you know, hurting the website for real users. And if they had a legitimate user agent, we could look at them. We can you know, rate limit them accordingly or we can reach out to them and say, hey you know, you are hurting us and you know, they, they would adjust, and it's cool. The Googlebot is a really good example of this. The Googlebot is Google's WebCrawler that indexes website for, you know, their search engine. Googlebot would just punish us. They would hit us as fast as they could, and sometimes that would actually slow down the site. And until we learned how to handle that properly, we would just, you know, rate limit them a little bit. And, you know, Googlebot, you know, their feelings weren't hurt, they can still index the site. We just made them do it slower. But when people show up with fake user agents and we can tell that, you know, this one IP and this one user agent is just pummeling us and, and they're trying to pretend to be a browser, we would just block them altogether. So, using good user agents when you're writing software that, interacts with other people's websites is, is a really nice, courteous thing to do. And it's one of the things that makes the web work well for everybody. So it's always important to have a nice accurate user agent and to be honest when you can. Okay, now that I'd like you to do is promise to always use user agents appropriately when you're writing your web software. Okay, quiz question. Which of these are valid headers? User Agent: Chrome, Host: www.hipmunk.com, host www.example.com, User-Agent: ignore me I'm a spammer, and i-made-this-up: whatever. Choose all that apply. Okay, the correct answers are this one, this one, and this one. The first is not valid because there's a space in the name. The name needs to be one string of characters followed by colon followed by space and then the value. The second is correct. The third is not correct because there's no colon. There needs to be a colon between the name and the value. This one is correct, User-Agent: ignore me I'm a spammer. Now, the value, as we mentioned before, can have anything you want in it. The final one is also correct, i-made-this-up: whatever, is also correct. Obviously, very few people use this header. You can make up all the headers you want. And often, people do, you know? If you, if you have machines talking to other machines, they can respond differently to different headers. And that's a good way of adding extra meta information to the request That's the basic HTTP request, now let's talk a little about HTTP responses. Let's talk about where we are first. You've got you and your machine and you've got these servers. Your browser makes a request to the servers, and your server sends back the response. We talked about the requests already, and the server responds with, a response, the document that you requested or, you know, information about the document depending on what you requested. A basic HTTP response looks actually very similar to the request. For a basic request that looks like this, the response might look something like this. Okay, so we can see a couple easy things. First of all the stat, this is called the status line. And this is analogous to the request line we had over here. Now the version of the status line matches the version of the request line, and then it's followed by two other pieces of information. One is the status code and the other is the reason phrase. And this is just an English language description of the status code. There are some really common status codes and I'll I'll show you some of them here. 200 OK, that means, the document is found. This is a far and away the most common status code on the internet and hopefully we'll be seeing a lot of these. 302 found that means the document is located somewhere else. 404 not found you've probably seen this one a lot, this means the document wasn't found. And 500 server error, that means the server broke trying to handle your request. Unfortunately we will probably also be seeing a fair number of these in our adventures in this course. Status codes basically begin with one, two, three, four or five. If it begins with a two, it basically means success, if it begins with a three, it basically means we need to do something different technically to find this document. Four means there is an error on the browser side, requesting a document that doesn't exist, for example, and five means there's an error on the server side, such as, the server's broken. Okay, let's let's move on a little bit and talk a little more about responses. We have our basic response status line and just like the request, the status line is followed by a number of headers. I give you a few examples. Here are some headers that are commonly included with http responses. Now just like the client request, the headers that you see aren't always the same. Some of them are required and when I say required I mean usually they are, but the web has evolved organically over time, so many of the headers that are you know, required are you know, often not there or things will work without them but anyway, okay. So date is there all the time. That's when the request happens. You know, no surprise there. Server, this is similar to the user agent header on the request. This is the, generally the name and version number of the server that's handling the response. Now, personally, I try to never include this. Or if I do include it, I make something up, because otherwise you're just giving free information to you know, a would-be, a would-be hacker who wants to know, you know, which vulnerabilities work against you. Content type, very popular. This is the type of document that's being returned. This is so your browser knows how to display it. So text html is a common one, obviously, you know, that, that's what an HTML page would be. You could see image PNG or, you know, image GIF, you know, if, if, if it's an image that sort of thing. And content length is how long the document that follows this. Content length is often included but it's not strictly required because the browser will know when the document's done receiving data because the connection may close. There are other ways of also telling the browser that I am done sending data, but it is not super relevant right this second. We have discussed the basic requests and responses. Let's let's play around in the terminal a little bit and you know, practice with these a bit. Okay, so open up a terminal if that is not straight forward on your machine we'll have some class notes on on how to do that. You Windows users might have some challenges in front of you. So we're in our terminal and we're going to use a program called tell net to make some Internet requests to web servers and watch the http go by. So we can see them in practice. Okay. So, let's make a request. Okay. I'm making a request to udacity.com port 80. This is the request your browser will be making if you are loading udacity.com in it. Here we connected to udacity.com port 80 which, if you recall, 80 is the default. Okay, so I'll hit enter. We connect and I'm going to send the request line that we talked about before. And I'm going to send an HTTP 1.0 and I'll explain why in a second. And I'm going to include the host header. Google wants this because, as we discussed before, it's hosting a lot of different web servers on a machine. Now, let's scroll back up to the top of this. You can see the request we made, get/HTTP 1.0, host udacity.com. Now, why did I do 1.0? Because the default behavior in 1.1 is to, is for the server to not close the connection. To allow the browser to make multiple requests from multiple things. Which is an optimization, but when you're testing by hand, it means the connection stays open, and then you have to close the connection on your machine, which is, you know, when you're using telnet is sometimes a little bit of a pain. So we see our response or our request, 1.0, host, udacity.com, and then you see the response from the server. Here's the status line. HTTP/1.0 200 OK. So, that means it worked, and now you can see a bunch of headers. Some of these headers we've, we've seen and discussed before. Here's date. Here is the server, it's Google front end. Here's the content type, text HTML, that means we're receiving HTML, which is no big surprise. And if we scroll down following the status line on the headers, we see the actual response document. And this is HTML. This is the type of stuff we were working on before. This is complex but you get the idea. Lots of HTML. Use telnet to make a request to www.example.com. The request is going to be a get request for the path slash. Remember to use HTTP 1.0 to make your life a little bit easier. When you do this. I want you to answer a few questions for me. First, what is the status code in the response? And second, what is the value of the location header? Status code is 302, and the location header was this URL. Iana.org/domain/example. Okay, I'll work through how I find the answers and hopefully you did something similar. So we go to our terminal and we said example.com. So let's make that request, telnet to www.example.com. Port 80. Okay. Now we say GET / HTTP/1.0. HOST, www.example.com. Uh-huh. Nice simple response. We can see our status code is 302. And we can see our location header is right here, iana.org. If that didn't work, you know, here's how you do it. All right, so let's let's play around a little bit more. So we see that this is a redirect sponse, response because of status code 302 and it's saying the actual content is here. Let's give a shot at making the request to find this. We're going telnet to iana.org and make a request for this path and see how it goes. See if we can get a 200. We make the request to iana.org. Telnet to www.iana.org port 80 and then we say get slash. Domain slash example http slash 1.0. Okay so here we are. You can see where I telnetted into Iana.org and you can see the request I made for slash domain slash example. I used http 1.0 again. And you can see the response. [LAUGH] This is actually kind of funny. So we respond it with HTTP/1.1 status 200. This is actually a good example of, you know, the web not aligning up exactly correctly but that's how it goes. Generally, this 1.1 should have mashed this 1.0 but since these guys control the web, I guess they can do whatever they like. Okay, so you can see the common headers, dates You know, today [LAUGH] actually today for me and the past for you. You can see the server header, Apache and you see it. This is an interesting how they're last modified. This page was last modified over a year ago. This is for caching purposes. This tells our browser that we don't need to bother requesting this page again, you know? We don't need new updates if it hasn't changed since this date. Content type. This is typical. Text HTML. And, below that, you see the content. Pretty cool huh? Okay. So now, we've discussed basic browsers, HTML, HTTP, which is how the browsers talk to the servers. And now, we're finally going to get to servers, which is what most of this course is going to be about. How to run programs on servers. The purpose of a server is to respond to HTTP requests. We've drawn this picture a couple of times now. This is you. This is your computer running your browser. And these are our servers. These little pink boxes. Your browser is speaking HTTP to these servers to request documents. There are two main classifications for the type of responses the server will do. They are called static and dynamic. Content is considered static if it's a pre-written file that the server just returns. An example would be an image. Most images are static requests. All the server does is says, it looks up the image off of its hard disk or off of its cache, and just sends it over the wire using HTTP. More interesting requests are dynamic requests. These are requests where the response is built on the fly by a program that's running. Just about all of the content online these days is dynamic. That didn't always use to be the case. When the web was first invented in the early 90s, almost all of the content online was static. They were just files. People would edit the files, put them on their servers, and they all linked to one another, but that was that. These days, almost every website including Udacity, Reddit and Hipmunk, the two websites that I worked on. Wikipedia, Facebook. All of those pages, almost 100% of them are built dynamically on the fly by programs called web applications. And a web application is just a program that generates content. And that is what we're going to learn how to build in this course. So we've spent all of this time getting to this description of what a web application does. Which is, it lives on a web server, it speaks HTTP, and it generates content that your browser requests. Let's have a quiz. Which of these requests is for dynamic content? Check all that apply. So, your Facebook page yes definitely dynamic. It's built by Facebook servers and rendered in your browser. The udacity.com logo, not dynamic. It doesn't change very often it's just a file sitting on a server. A blog's front page. Yes, definitely dynamic. You know, a blog's front page probably takes all of the blog's and resets somebody has written and collates them together and renders a page that you know, includes you know, the top ten or whatever. And Google search results. Definitely dynamic. You run a search, Google in the background you know, does a search on, on all of their computers, puts together results and then renders them for you on the fly. So, these are all examples of dynamic content. You know, content that's basically put together by programs. And, in this class we're actually going to be building a blog, so that's what you're going to to learn how to build. Welcome to lesson two everybody. In this lesson we're going to learn about forms. Forms you've seen all over the place on the internet. They're the text boxes, check boxes, radio buttons that basically allow websites to get information from users, including on [UNKNOWN] own site. Every quiz you do is submitting a form. So we are going to spend a lot of time, basically learning how to build this things in your editor in a browser testing them out. And we're also going to spend time learning how to make sure the data you're getting from the user is actually secure. Because this is how you let the users basically into your website. So we have to make sure that we only allow them do what we want them to do. So, let's get started. In this unit, we're going to talk about forms and how you get data from your browser to a web server, and we're not going to spend a whole lot of time here on the sketch pad today, but first things first. What I want you to do is open a text file in your editor of choice and put some text in it. I'm in my editor here, and I'm just going to add some text, kind of standard text. I save this file as play.html, and the next thing I want you to do is open this file in your web browser of choice. What we have here is the text that I entered in the editor here in the browser, and if we were to go back to the editor and change something-- we'll change our word here--save it and then go back to the browser and reload, you can see it live updates, so this is a handy way for kind of playing with and experimenting with HTML in a real browser, and we're going to be doing a fair amount of this today. The first thing I want to teach you about is HTML forms and the elements required to make them. We have another tag called "form," and it looks like this. And like many HTML tags, it has a closing form. We're going to go back and forth here, between our editor and our browser and here while I'm explaining things. Let's enter this in our editor. Here we are in our editor. I'm going to replace this text with that basic HTML tag I just showed you, . Okay, there we go. We're going to save this, and we're going to go back to our browser and reload the page. Nothing is there. And why is that? Because we didn't enter any content. Let's talk about the content that goes in an HTML form. There are a few things that can go in here, one of which is an element called input, which looks like this. Let's enter that in our HTML editor. Okay, now we go back to our browser, and we reload this. A-ha. Now we have an input box, and we can type things in this box. Pretty cool, huh? The input tag can take a couple of attributes, one of which is called "name," and name looks like this. It's like all attributes. We have the actual attribute, which in this case is called "name," and then the value, which I've written here in red. This can be whatever we want. Okay--quick quiz. What I'd like you to do is enter the HTML for an input tag whose name parameter is q. And the answer is: input name equals q. With a less than sign, greater than sign, and the appropriate quotes. What I'd like to do now is add this to our file that we've been editing. So we already have an input tag here, let's add that name parameter. Let's go to our browser now, we'll reload, you can see our input box hasn't changed. We added a name attribute in our HTML, but the appearance of the input box doesn't change-- the name attribute doesn't affect it. What I'd like you to do is enter some text in this box, and press enter, and we'll see what happens. So--put some text in the input box in your browser and press enter. What happens? Nothing, the URL changes with my text, an error message appears, or the text disappears. The correct answer is the URL changes to include your text. Let's take a look at that in the browser. Okay--so here we are. We have our text in our box, and we press enter. Ah--what happened? Our URL changed, and you can see our parameter q-- which was the value of the name attribute-- equals Udacity--equals the text we typed in. We can put new text in the box, hit enter, and we see that q equals our new text. Pretty neat. Okay--I'd like to add a new element. So instead of requiring users to put text in the box and hit enter, we'd like to give them a button to click on to submit our form. We're still going to use the input element, but it's going to have a new attribute-- and it'll look something like this. So--we're still using the input element. This time we have an attribute called type, which equals submit, and this instead of drawing the text box that accepts input from users. We'll draw a little button that should allow us to submit the form. Okay--I'm going to add this in our HTML now, and then we'll load it in our browser to see how it looks. Okay--so we're adding a second input element, and this one is type equals submit. There we go. We'll save this file. We'll go to our browser, we will reload the page, and there we have it--we have a new little submit button. Now, I'm going to enter some text into here, and click submit. Okay--so--before I click submit, I'd like you to click submit, and tell me--is clicking submit any different than pressing enter in the form? The answer is no. Let's look at our browser. When I click submit here, the URL updates just like it did before, with--this time the q parameter equals computer in our URL. Now, what's happening here when we hit enter and press submit is that we're actually submitting the form. And by default, the form submits to itself, which--while is neat for playing around in our browser-- and--you know--editing the URL--isn't so handy. So--let's talk about how we can make this form submit to someplace else. Okay, I want to add a new attribute to our form. This attribute is called action, and this controls where a form submits to. I'll give you an example. Right now we have our tag form, and it looks like this, and it has a couple inputs in it, and we have our closing tag, and this is basically the structure of our document right now. I'm going to add a new attribute to form called action, and it looks like this: action equals, and then a URL of where we want the form to submit to. We can put any URL in here, and when we click submit on our form, it will send the data there. Okay, so for your quiz, what I'd like you to do is add an action attribute to your form element whose value is http://www.google.com/search. I want you to type some text in the box, click submit, and tell me what happens. Is it nothing? Does the URL change with what you entered? Does your browser go to Google search results? Does it appear as though you've written an entire search engine? The answer--I hope--is your browser went to Google search results. I'll go ahead and do this with you, and let's talk about it. Okay--I'm in my editor and I'm going to add the action parameter. And I make it equal google.com/search, I save this, I go to the browser, I reload, I type something in the box, I click submit, and voila, we have Google search results. Pretty neat, huh? Now--what happened is--we set our form action to be google.com/search-- we can see here in our URL--and the form added the value that we typed in on our form to the q parameter. Remember--q came from our HTML. It's the name of the input element--it's the name of that text field. And that's why we keep seeing it in the URL. Let's go back to our form. Okay--I'd like you to type something else in the form, and you're going to tell me what happens. This time we're going to type in better flight search--and click submit. Okay--so--what I'd like you to do is go to your form, type the phrase "better flight search" into the form, and click submit. What I'd like you to tell me is what is the value of the q parameter in the final URL? The answer is better + flight + search. Let's do that together, and we'll talk about what happened. Okay, I click submit, and I get taken to Google search results for the phrase "better flight search." I can see in the URL better + flight + search. What are these pluses doing there? Because you didn't type them in the search form. The answer is because URLs can't have spaces in them, your browser did what's called URL encoding or form encoding or URL escaping. They're all basically words you'll see that refer to the same concept, which is we turn spaces to pluses. We also do some other things. If we go back and enter some different text in here, we can see even more behaviors. Let me add an exclamation mark and hit submit. Now you can see in the URL we have this %21. That's because exclamation marks generally also get escaped. Now, the behavior could be different in your browser. All browsers have slightly different behaviors in this regard, but this is what we see in ours, and you'll probably see something similar. Okay, so let's move on to some live web applications. So, at the end of your last homework, you should have Google App Engine running on your machine, and you should have a basic site online. We're going to start with basically the simple hello world example that Google has on their site, which I have. This is the main hello world Python file from the Google App Engine example page, and it's got 2 main sections. We'll start with this section down here at the bottom. This is the URL mapping section, and in this case, we have 1 URL, slash, and it maps to a handler called MainPage. MainPage is defined in this class called MainPage. It inherits from webapp to RequestHandler, which is the generic request handler from Google. If you don't know what classes are, you can learn about them offline. It's basically a convenient way for grouping together functions and data that are all related to the same thing. We're not going to spend a whole lot of time on it here, but you should be able to keep up just fine. Our class is a function called get, which takes a parameter called self, which is the common first parameter to most Python methods. So, this function does 2 things. First, it takes self.response, which is the kind of global response object that this framework uses, and it sets a header. It sets the Content-Type header to equal text/plain. By default, the content type is text/html, but in this case it's setting it to text/plain, and then it's writing the string "Hello, webapp World!" If we start up Google App Engine, I'll start Google App Engine in my terminal here, and then I'll go to my browser and load the page, and this is what we see. We see that string that our program was writing out in our browser, "Hello, webapp World!" Pretty neat. Okay, so the first thing we'd like to do is take this form out of the temporary file we were playing with before and put it in our application. Okay, so what we're going to do is we're going to create a new variable at the top of this file called "form." We'll use triple quotes, which allows us to enter longer strings, paste in our form, close this up, save it. Now, instead of printing out the string "Hello, webapp World!" I want to print out the string of our form, so let's make that change. We're going to just return form instead of that string. Let's go to our browser and see how this looks. Okay, here we are in our browser, and we're going to reload, and we should see probably the form from our little text file. A-ha, this is not what I was expecting. I was expecting to see the form from our previous HTML, but instead we've got the HTML itself. Why do we see raw HTML instead of our text box in the browser? Is it because Google App Engine can only send raw HTML? Our browser is misconfigured? We're sending the wrong Content-Type header? Or our HTML is invalid? The correct answer is that we're sending the wrong content type header. If you look at the program we're using, we still have this line in here which says content type to text plain. If we get rid of this line, I'll comment it out, save this file-- so we got rid of that line, and when I reload my browser-- aha--now our form is as we expected. That's because in Google App engine the default content type is text HTML, which tells the browser that it's receiving HTML and it should interpret it as such, our text is then interpreted as HTML. When it was sent as text plain, it was interpreted as plain text, and the browser showed everything we sent back, you know--angled brackets and all. Now--let's see if this form behaves the same way as our old one did. It's working just as it did before, except the difference this time is the HTML is served by our live web application running on our machine instead of just a plain text file. Okay, let's make some changes to this file. The first thing we're going to do is we're going to get rid of this Google action and replace it with /testform, and now that's going to cause our form when we submit it to submit to /testform instead of to Google. And since our application can only respond to slash, we're going to need to add a handler for that as well. We'll come down here to our URL handler section, and because we only have a handler for slash, we're going to add another handler for /testform. /testform will be handled by the handler called TestHandler, which doesn't exist yet. Let's create that. Okay, so we've added this new handler called TestHandler. This also has a method on it called get, like our other handler, and what this does is it sets a variable called q, which comes from self.request. Like response is the object that represents the response we're going to send back to the client, request represents the request that came from the browser, and you can call get on it to get different parameters, so in this case we're going to get the parameter q. And then all we're going to do is we're going to turn on the response self.response.out.write(q). So if we go to our browser, we enter some words, and we hit submit, we see the string hello world! You can see in the URL q = hello World! which is what we answered, so this is hitting the same URL we were hitting before, but this time there's a web application on the other end listening for requests and returning responses. The exclamation mark turned into a %21. That was the escaping I was referring to before. Okay, now I'd like to make another change. I'm going to comment out these 2 lines and show you something neat. I'm going to take this content-type line from up here because we want to print some text, and we want it to work properly. This time, instead of writing out q, I'm going to write out self-request itself. Okay, let's go to our browser and try this out. Here's our form. You may have to go back to URL and reload. That's fine. Type some text in the form and click submit. When you click submit, what just happened? Did you see garbage? Did you see the HTTP request? Do you see a message from the future, or nothing happens at all? The correct answer is--you should be looking at the HTTP request. I'll try it myself--okay--we have our form, I click submit, and--boom--here we are. This is actually--what we're looking at--is the HTTP request. We'll look at the code in a sec to remind ourselves how all of this happened. But do you remember from our first lesson when we talked about HTTP requests and how they look? Well--here's our request line-- GET--and then our URL--/testform, and then q equals the text we typed in the field. You can see a couple more headers, Accept and what languages we are expecting to receive-- what character sets are okay. We can see the host header--we're familiar with that one. You can see the referer header--referer header is interesting. This refers to the URL that sent this request. So--the URL of our form is localhost8080/ and the URL we're on right now is /testform, but this header is helpful for telling the server where the request came from. You'll notice that referer is misspelled here, that's because in the original HTTP spec the word referrer was spelled wrong. It normally has two Rs. But it's lived on for backwards compatibility reasons, for nearly 20 years now. And--this is actually symptomatic of how a lot of things in HTTP or on the web are, which is--you know-- somebody made a decision--you know--20 years ago that still haunts us today, and it's not necessarily a bad thing, it's just a side effect of when things grow organically over time. Another header we've talked about--our user agent-- in this case I'm using Chrome--you can see that here-- amidst a bunch of version information on Mac OSX. Looking at our code--here's what we did. We set the content type to text plain. If we hadn't done that, the response we were looking at in HTML, or in the browser would have looked weird, because the browser would have assumed it was HTML, and a lot of that text wouldn't have shown up. So, we set it to plain because I knew what we were going to do. Then instead of writing text or writing out our q parameter, we actually wrote out this request object itself, which is the Python object that represents the request, but conveniently it prints out very much like HTTP looks, which is not a coincidence. So--it's a handy little tool though when you're writing web applications and debugging, you want to see--you know--where something broke or what's going on, you can just print out the request and see. So--let's replace these two lines again, back to the way they were, and move on to something else. I'm just going to comment these lines out, however, because we're going to need them for later. So--this is how our file was before, let's move on to a new section. I want to add a new attribute to our form, and this one is going to be called "method." I go up here. Let's add method and make it equal post. Now, the default method has been get. We've talked about this in Unit 1, the difference between a couple methods, so we mentioned that a couple methods exist, and the most important ones are going to be using our get and post. If you don't specify method at all, it defaults to get, and that's what we've been seeing. We've been doing get requests, and the parameters in the URL are called get parameters. Now we're going to use a new method called "post," so make this change, and let's go to our browser. Okay, here we are at our familiar form again. Let's type in some text and hit submit. When you clicked submit, what happened? Was the text that we entered displayed? An error message was displayed? The request headers were displayed, or we ran a Google search with our text request? The correct answer is an error was displayed. Let me try that in my browser. So--we have our text, we click submit, and we get this error 405--method not allowed. Now--remember--this is a status code-- we talked about status codes in the previous unit and in this particular case, 405 means method not allowed. And if you recall, status codes that start with the number 4 are considered errors on our side, or on the browser's side. So in this case, our application is saying, the method POST is not allowed for this resource. Resource is referring to slash test form. Let's take a look at our code. What we changed in our code is we changed our method from the default get to post, but our test handler down here, which handles requests for slash test form is only configured to use get. So, let's change this function to the word post. What the Google framework allows us to do is have a different function for each type of method request. So until now we've been using get, but now that we're doing a post request, because our form method is post, we need to have that function implemented. Okay--so we change this to post, and we go to our browser and we try it again. Okay--here we are in our browser, we type some words. And we hit submit-- ah--it's behaving just like it was before, except this time our q parameter isn't in the URL. Time for a quiz: Where did our q parameter go? Is it in the URL? Is it after the HTTP request headers? Is it in a second HTTP request? Or is it in the HTTP request headers? The answer is: it's after the HTTP request headers. Let me show you how to find that out. So first we'll go to our Editor and we'll switch these lines around again so we can see the actual request. So I comment these two guys out, and I uncomment these two guys--this is what we've been doing before. Let's go back to our browser--okay, let's give it a shot. We're going to reload this page, which is going to ask us if we want to resubmit the form. We'll do so--aha! And now we see our HTTP request. This time it's a POST instead of a GET. That's because we changed the method to POST. We see more headers--we actually see a couple of these headers twice. That's kind of a side effect of the fact that we're not printing the actual request. We're printing the Python representation of the request, which is a little glitchy--not a big deal. We can see here, after all of the headers, we have some data: q=some+words--that's what I typed in my form. Remember, spaces get turned into pluses. So one of the big differences between GETs and POSTs is that GETs include parameters in the URL and POSTs include the data in the request body. Let's talk a little bit about the difference between GET and POST. We've already seen one of the differences, and that's GET parameters are included in the URL and POST parameters are included in the body. Another difference is that GET requests are often used for fetching documents and GET parameters are usually used to describe which document we're looking for or maybe what page we're on or things of that nature-- basically, things that are describing what we're getting; where POST parameters are often used for updating data-- for actually making changes to the Server or to the data held on the Server. Another difference is that GET parameters-- because they are in the URL-- have a maximum URL length, or they're affected by the maximum URL length because you can only encode so many parameters. For example, I think Internet Explorer allows 2000 characters in the URL, or something like that, which can be quite limiting. POSTs, by default, have no maximum length. Now, the Server can be configured--and most are-- to have a maximum length, but it's usually substantially longer than 2000 characters. It's probably a few megabytes. Another difference is that GET parameters are generally okay to cache. And when you make a GET request--a simple request for a URL-- there's a good chance that it's been cached. There are a lot of machines between you and the Server-- or often there are-- and it saves a lot of effort if we know the document hasn't changed to--you know--cache it along the way so you don't have to request it new every time. POST parameters are almost never cached. That's because you're probably updating data on the Server. And so the industry standard is: don't cache POST requests. One more difference is that GET requests-- because they're okay to cache and because you're usually describing which document you want-- they shouldn't change the Server. You should be able to make the same GET request over and over, and the Server shouldn't change. POST requests, on the other hand, are okay to change the Server. That's what they're generally used for, is requests that update the Server. That's why they're not cached; there's no max length, and that's the whole story. So in short, GET requests should be simple requests for fetching a document. And GET parameters should be used to describe what document or what page you're looking for. And POST parameters are used for making updates to the Server. And POST requests generally are destructive in nature. Now, if you don't follow these rules, you can get into a little trouble. Okay. So we talked about some of the differences; now let's talk about what happens if you don't obey those rules. I remember, about--this is probably 6 or 7 years ago now, when we first starting Reddit-- there was a program online called Basecamp, and it's made by a company called 37 Signals-- and it's used for organizing To-Do Lists and stuff. And so the page kind of looked like this. You had like these To-Do items and next to each of these To-Do items was a little link that said: Delete. And this was just a link--and if you recall, normal links, with the anchor tag that you would see in Click On-- those make GET requests. To make a POST request you need a form, and these were just links. And so if you were logged in, you could create these To-Do items; and if you wanted to delete it, you could just click on Delete. Well, there was another program out at the time, called "Google Web Accelerator". And what that was, was it was a browser plugin that would sit in your browser, and while you were browsing-- you know--let's say this is the browser you're looking at-- let's add a picture here. While you were browsing, a bunch of text-- you know--there might be some links throughout the document-- the Google Web Accelerator would make those requests, behind the scene, so that when you clicked the links, the pages were ready to go. The problem is, the Google Web Accelerator was hitting these links. So users would go to their Basecamp page, look at their To-Do lists, and find that their items were deleting on their own, and that's kind of a big problem. And that's what happens when you use GET requests to alter the Server state. Those guys, at the time, just assumed that since we were logged in no bots would ever hit the page; it would only be used as clicking. But if your browser's behaving funny or if you've got a plugin running that's clicking on all the links for you, you'd better be certain that those links don't actually change the Server. So what you should design instead is instead of making links that alter the Server, you can make little forms--and the form can just have a little button in it that says: Delete or it can have a special link that causes it to submit the form-- but it should be making a POST request. Okay--quick quiz: Which of these are appropriate for GET requests? Fetching a document, updating data, requests that can be cached or sending a lot of data to the server? And the answer, of course, is: Fetching documents are good with GET requests, and requests that can be cached. GET requests are often cached-- not always--you can control that with headers but, generally, yes. For updating data on the Server, a POST request is more appropriate. Likewise, sending a lot of data to the Server-- a POST request is also more appropriate because, of course, the amount of data you can send in a GET request is limited. Okay. So here we are in our Editor again, and this is the basic HTML file we were editing before and that we were opening in our browser. We're going to go back to this a little bit so we can learn some new form elements. So the first thing I'm going to do is remove the Action parameter from the Form element so that we can submit the form to itself and we'll see the "q" parameter in the URL again. This makes it easy to demonstrate what's going on, without having to go back to our app Server and all of that stuff. So I removed that; let's go to our browser and let's give this form a test. So I reload the page, I type in: "some junk" here, which it autocompletes for me. I click Submit, and we see "some junk" in the URL: q=some+junk. Okay. Let's go back to our Editor. So here we are in our Editor. One thing that I'm leaving off is the Type parameter on this first input. So let's go ahead and add that: type="text"-- type="text" is the default type of an input parameter. I didn't include it originally because I didn't want to spend a whole lot of time talking about that, at the time. But in reality, we want to be a little bit more specific with our types, especially now that we're going to learn some new types. So if I change that to type "text" the behavior won't change in the browser. And the first thing we're going to do is learn a new type. So instead of being "text" we're going to change this to "password". The "password" type is useful for entering passwords in a text box. Okay--so here we are in our browser. Now when we type some text into the box here, it appears as dots instead of the actual text. So for the next quiz, what I'd like you to do is tell me what happens when I click the Submit button. You can try this out on your own, at home. Okay. And the answer is: Whatever I typed in the box will appear in the URL. There's a small chance that the value of the "q" parameter could have been "hunter 2"-- if that's what I typed in the box, but it's not what I typed in the box. Let's go ahead and see this happen, for real, in the browser. Here we are; I click Submit, and you can see that "q" equals what I typed in the box. In this case, it was the text, "some dots". So this is important to know: you should use the password form element or the password input type when you're collecting passwords on your site, but you should know that that password is not sent securely to your Server. It's sent either in the URL or in a POST parameter, just like any other parameter--so it's really only to prevent somebody from looking over your shoulder. Okay--let's learn about another input type. I'm going to change our main input from type="password" to type="checkbox". And this, as you might imagine, will make a checkbox. When we go to our form, I hit Reload, and now we have a checkbox next to our Submit button. When I check this checkbox--you know-- a checkbox is for toggling something on and off--I'm sure you've seen them before. When I check this checkbox and hit Submit, we see in our URL the "q" parameter equals "on". That means that the box was checked. What happens--and you can try this yourself-- when I hit Submit, when the checkbox isn't checked? Is it off, the parameter doesn't appear at all, the parameter is blank or is it the string, "hunter2"? The correct answer is: The parameter doesn't appear at all on the URL. Let's try that out in the browser to see it, for real. So here we are in our browser; I click Submit, with the checkbox unchecked, and there is no "q" parameter in the URL. Simple enough. Now--when I'm writing Server site software to look at these values, I usually check for the "q" parameter equaling "on" and anything different from that means it's "off". That's because I don't believe that all browsers are going to behave quite the same here. I know "on" is "on"--but, maybe it says "this string off"--who knows. So I always just check for one case, and the default case will just be "off". Okay. So that's how a single checkbox works but, rarely do you see a single checkbox by itself. Usually you see them in a group. So let's add a few more here. So I've added two more checkboxes-- type="checkbox"-- and I've made their names be "r" and "s". So now we have "q", "r", and "s". And then I also added a line break so it can have a little separation from our Submit button. Let's see how this looks in our browser. Okay. If I Reload this page in our browser, now we see--we have 3 checkboxes and they can be toggled on and off, as you do with checkboxes. Now what I'd like you to do is tell me what happens when I check these first 2 checkboxes and I hit Submit. So when we select the first two checkboxes and click Submit, what does the "query" section of the URL look like? Remember, the query section--that's the name for the portion of the URL, after the question mark. Okay. The answer is: q=on & r=on because those two checkboxes were checked "on" and the third one, "s", wasn't checked at all. Let's go ahead and check this out on the browser, for real. Here is our form--just how we left it. We've got our first two checkboxes checked. And when I click Submit, we see in the URL: q=on&r=n. Simple enough. Cool. Okay. Let's learn about another form element. Instead of checkboxes, I want to use radio buttons. So let's change the word from "checkbox" to "radio" for these 3 inputs. Okay. I've changed "checkbox" to "radio" for these 3 inputs, for the type="radio", and I've left the names the same: "q", "r", and "s". Let's take a look at this in our browser. Okay. Here we are in our browser, and you can see we have our 3 radio buttons instead of checkboxes. And I can turn a Radio on by clicking on it. And if I click on a different radio button, it also turns on. Now that's probably not the behavior you were expecting. Normally, when we have radio buttons, they behave in a group. These ones, obviously, aren't doing that. What happens when I click the Submit button here? You can see that they behave, actually, just like the checkboxes do: q=on, r=on, and s=on. So these are--basically what we here are checkboxes that you can't be unchecked-- really convenient, right? So now you know how radio buttons normally behave. I should be able to select the second one and the first one should go off. How do you think we might accomplish that? Which of these yields the "group" behavior we were expecting from the radio buttons? Do we give them all the same "id" attribute, the same "name" attribute, the same "group" attribute-- or do we include all the s in a element? You can go ahead and try this out on your own and see what you find. Okay--and the correct answer is: Give them all the same name. Now, one thing worth noting is that this quiz, itself, involved Radio Buttons. You select which one is the correct answer. So--small world, huh? All right. Let's go ahead and try this here, and we'll play around with it in our browser. So right now, these 3 radio buttons have 3 different names. Let's give them all the same name--so instead of being "q", "r", and "s", we're going to make them "q", "q", and "q". Okay. We Save this, we go to our browser and Reload the page. Now we have our 3 radio buttons again. And now, when I select the first one, it behaves as we expected. And I select the second one, and it will unselect the first one--so that's cool. So now we can only select one option and things work as we expected. And when I submit the form, we see that: q=on because that was the name of the inputs. A major downside to this is that, no matter which radio button I selected, "q" still says it's equal to "on". So that's not particularly helpful because we want to know which radio button is selected. Well, that is what the value parameter is for, and let's take a look at that. Here we are in our Editor again, and we're going to learn about another parameter--this one's called "value". So I'm going to add a value parameter to each of these inputs. I'll make the first one be "one" and I'll make the second one be "two"-- and I'll make the third one be "three". So now we have: type="radio" name="q"--for all 3 of these, but the first radio button has the value "one", a second has value "two", and the third one has value "three". Let's go ahead and try this out in our browser. Okay. I've reloaded the form and now I'm going to select one of these radio buttons. Let's go with the second one, and I would like you to tell me what happens when I click Submit. So what will the value of the "q" parameter in the URL be when the form is submitted with the second radio button selected? The answer is: two. The value of the "q" parameter in our HTML was "two" so when we submit the form, we should see "two" in the URL. Let's go ahead and try it out. Here we are in our browser; we can see the second radio button is selected, and when I click Submit, q=two in the URL. That's because the second radio button-- "one", "two", "three"--its value is "two". Pretty straightforward. Keep in mind that the meaning of these parameters is whatever we make of it, on the Server side. So on the Server side, we can look for the variable "q" or the parameter "q", and do what we want with it-- or we can ignore it altogether. We can check to see if it equals "on" or we can check to see if it equals "one", "two" or "three". That's all up to us, and we'll talk more about that when we start working with our Server side app again. Okay. Now one thing to note here is we have our radio buttons and how is the user to know which is which? They're just 3 anonymous radio buttons. Well, that is what the element is for, and I'll show you how to use that in our Editor. So to give the user a sense of what they're clicking on, rather than just clicking on random dots, we're going to use the element--and it looks something like this. I'll add the element to each of these inputs. So I've added one element. The elements stay the same for this first one. I wrapped it in a element that also has the text, "One" in it. This will cause the word "One" to appear next to the radio button. I'll go ahead and add it on these other two as well. Okay. So I surrounded our other two s with a element. I added some line breaks in here so it's a little bit easier to read, but all that's really changed is I've added opening , a closing , and then some text to each one of these. Let's see how this looks in the browser. When I load this in the browser, now we can see the labels before our radio buttons. And so when I select one of them--"One", "Two", "Three"-- that makes it easier so the user can see what they're actually doing. You know--you give the radio buttons a label. And when I click Submit, as we expected: q-three in the URL. Now, of course, the label doesn't have to match the value of the radio button but, generally, they're closely related. There's one last form element I'd like to expose you to before we move on to something else, and this is for doing a Dropdown. I'm going to get rid of this text here. And a Dropdown has a form that looks like this. It has a element, with a name-- we've been calling everything "q", so why stop-- and then it has a couple of elements. So here I've put in a complete Select element. We've got an opening and closing . And the opening has the Name attibute equal to "q"-- which is what we've been using-- and then I've added 3 elements. Each has the text inside it: one, two, and three. Let's see how this looks in our browser. Okay. So here we are in our browser--and now we see we have a Dropdown, and it has a couple of Options. And you can choose one of these Options--you know-- one, two, or three--and what I'd like you to tell me is what happens-- when I select "two" from the Dropdown and click Submit, what appears in the URL? Okay--so when we select "two" from the Dropdown, what will the value of the "q" parameter in the URL be? Go ahead and give this a try yourself. And the answer is "two". Let's go ahead and check this out in the browser to see for ourselves. So here we are--I've got "two" selected. I click Submit, and "q" equals "two". All right. Easy Peasy. Now what if I want to have-- you know--I want to have text up here--here in the Dropdown-- but I want to have a different parameter up here in the URL. You know--that's useful when you want to have more descriptive text here. The way to do that is to use the Value parameter. Let's look at that in the Editor. Here we are in the Editor--you can see our elements and elements the way we left them. I'm going to add a Value parameter to this first one. And it's value is going to equal "1"-- the number, "1"-- instead of the string, "one". Let's go ahead and make these a little bit longer. Our first value in the Dropdown--or our first element in the Dropdown now has a value equal to the numeral, "1" and contents of the words, "the number one". All right--let's see how this looks in our browser. So now we can see our Dropdown has changed. The first element says, "the number one" and the other two are the same as they were before as they were before because I didn't change those. What will "q's" value in the URL be when we submit our form with "the number one" selected from our Dropdown? Is it "the number one"--the string? Is it the numeral "1"--the digit? Does nothing appear or does the string, "hunter2" appear? The correct answer is: The numeral "1"--the digit--appears. Let's go ahead and see this, for real. Okay. Here we are in our browser. We've got "the number one" selected. When I click Submit, I see "q" equals the numeral "1" because that's what we specified in the value parameter. And if we selected one of these other options-- let's go with "three" this time-- when I click Submit, we see "q" equals the word "three" because that's what was the contents of the Option parameter. And if you don't specify a value, the value of the "q" parameter in the URL will default to the contents of the Option elements. So if you want to have a different value in the URL-- that's different from the contents of the Option element-- that's what the value parameter is for. Okay--onto a new concept: this is the concept of Validation. Validation basically means verifying, on the Server side, that what we received is what we expected to receive. So we have you, and we have our Servers-- and you're submitting to our form certain values. Let's say you're sending the "q" parameter. It's a checkbox that we've put on our form and its value equals "on". And the Server receives that and knows what to do if "q" equals "on", and it knows what to do if "q" is not present-- you know--that means the checkbox wasn't checked. But what if there's a bad guy and he's wearing a hat, and he submits to our Server the "q" parameter--but instead of equaling "on" or not being present, he submits the word, "broken"? Now, depending on how our Server is programmed-- you know--it can just say oh, well I don't know what "broken" means so I'm just going to assume it's unchecked, which is probably the smart thing to do. And that's great. The point I'm trying to make, however, is that just because we have a form with a checkbox on it that limits what a user can send us--through the form-- it doesn't mean that somebody can't send, directly to our Server, parameters with arbitrary junk in them. And it's up to our Server to make sure that we handle it safely. Always remember that your Server can receive junk and it needs to be smart enough to deal with somebody sending completely broken data. And it doesn't necessarily have to be the string, "broken", right? This could be a megabyte of trash, and you don't want to just blindly do something with it. So make sure you're always validating your parameters, and that's what we're going to talk about now. So we're going to go back to the live web app we were working in before. This is the main file we were using. I'm not going to ask you to follow along with me anymore because I'm going to be writing more code, and it'll be tedious for you to try and keep up. I'll try to type slowly, and we'll quiz as I go. So the first thing we're going to do is adjust this file to work better for our needs. So remember, we we're submitting to a different URL before. We were submitting to /testform. That's when we were learning about multiple handlers. We're going to get rid of that. We're going to get rid of that action parameter, and we're going to get rid of that whole handler. We're not going to be using that anymore. And we're also going to get rid of the URL reference to that handler. We don't need that anymore. So now I've simplified this file quite a bit. We have our simple form that we were using before, and we have our main handler that's mapped to by /. / maps the MainPage. Here's MainPage with a get function. And this get function just prints our form. This is a very simple example we started with from the very beginning. Let's make sure this still works. Here we are in our browser. We've got our basic form. Everything is as we expected it. Okay, let's go back to the Editor. So instead of having this basic form of just a text field, we're going to make a form to ask somebody for their birthday. So we can validate their inputs. So let's get rid of this input. and we're going to ask the user, what is your birthday? We'll have a blank line. Then we'll have 3 inputs--1 for the month, 1 for the day, and 1 for the year. So I'll go ahead and add those. So I've updated our form a little bit. It has a string, what is your birthday?, a blank line, 3 inputs, all of type text and they're named month, day, and year, 2 more blank lines, and then our submit button. Let's check how that looks in our browser. Here we are in our browser. We've got our text, what is your birthday? We've got our 3 inputs for month, day, and year, and our submit button. I made the font a little bigger in the browser, so we could read it better. Now this is not very clear what we're asking for. Remember we have a solution for that though. Let's add some labels so we can see month, day, and year next to our text inputs. So here we are in our Editor again. I'm going to add a few labels. Okay, so all I did is, I added label elements like we did in the previous examples. Here's an opening label, our old month input, some month text to appear next to our text input, and then the closing label. I did that for each of these inputs--month, day, and year. Let's see how that looks in our browser. Okay, here we are in our browser. I've reloaded it, and things are looking nice. Now we can see that we're asking for the month, the day, and the year. Now I'm going to type in some data here, and I'd like you to tell me what you think is going to happen when I click submit. So when I hit submit on that form, what do you think is going to happen? Will the form clear? Will we get an Error 405 because we never added a post() handler to /? We'll see the form values in the URL? Or will the app count down to my birthday? The correct answer is we'll see an Error 405. We never added a post() handler for /, and so our application will complain. Let's go ahead and see that in real life. Okay, here we are in our browser with the text that I entered, and I clicked submit. 405--The method POST is not allowed for this resource. That means we never wrote the POST function for /. Let's go ahead and add the post() handler. Okay, so here we are in our editor, and we've got our get handler, and this is what draws the form. Let's add the post version, and this will get called when we post to the URL, which is what happens when we submit our form. Okay,so I've added a post function that goes along with our get function, and the post function will get called when we post to /, which is what our form does. And upon a post, we will return back to the browser-- the string--"Thanks! That's a totally valid day!" Alright, let's give that a shot in our browser. Okay, so here we are in the browser. I've reloaded my page. Now I'm going to type in some submissions, and this isn't exactly a valid month, day, and year, but let's click submit. Our form says, "Thanks! That's a totally valid day!" which is nice of it to say, but our day isn't exactly valid, is it? Okay, so what are some possible solutions to users entering bad data in our form? Should we use dropdowns to limit what the user can actually enter? Should we assume that the users will only enter good data? Should we verify what the user enters on the server side and complain if the data is bad? Or should we just make values up? Check all that apply. The first option--use dropdowns to limit what the users can actually enter-- yes, that makes sense. In fact, when you fill out your date online, I'm sure they usually have dropdowns for month, day, and year because that simplifies things a little bit. But no matter what we do, we also need to verify what the user enters and complain if the data is bad because as we talked about before, just because our form limits what the user can actually enter, a malicious user or somebody goofing around can make a form that posts to any URL they want, including our server, and they can put in whatever junk they want, and they very well could break our server verification. A lot of forms--a lot of websites out there think just because they use dropdowns that they don't have to verify the data on the backend. So have fun out there playing with that. Okay, time for a quiz. What I'd like you to do is write a function that, given input from the user, returns whether or not it is a valid month. Okay, here's 1 version of this function. First, what we do is we take the month string from the user, if it's there, if it's a nonempty string. I capitalize it because the list I include before of all of the months has the days capitalized, and if that capitalized month is in that list, return that value. So let's try a couple versions of this. Valid_month('january'), and we run this. We see it prints January. Let's try 'july'. I run this, and it prints July. Everything is formatted nicely, and all is well. Okay, now let's try answering some junk in here. Okay, we run this, and it returns nothing. What happens if I answer in nothing? We get nothing. Okay, so this seems to be working. Now what if we wanted to make this a little bit more user friendly, so the user doesn't have to type in a complete month and spell it correctly. Here's the change I would probably make. At the top of this file, we have a list of months. What I'm going to do is, I'm going to build a dictionary--a mapping of just the first 3 letters of the month name to the month name itself, so we're only going to match on the first 3 letters of what the user enters. Okay, so I've added this dictionary, and for m in months, which is our list from above of the month names, we're going to make a mapping of the first 3 letters of that month-- that's what this m[:3] is--lowercase using the lower() function to the month name itself. If I were to print that out, it looks like this down here-- 'mar' to March, 'feb' to February, 'aug' to August--you get the point. Now this isn't in any particular order because in Python, dictionaries aren't ordered. Now let's update the main function here to use this new dictionary. Okay, so now I've made the changes. We still say, if month. Now I'm making a new variable called short_month, which just equals the first 3 letters of whatever the user typed in, lowercased-- so first 3 letters, lowercase. Then I use the GET function on a Python dictionary to see if those first 3 letters the user typed in is in that mapping, and if it is, we return the value from that mapping. That's what the GET function does. It says, if our key is in the mapping, return the value. Otherwise, return none. We're going to return either that value or none. Let's try this out together. So print valid_months. Okay, so I run this function on 'january', like we did before, and it prints out January with a capital J. That's the behavior we had before. Let's try something a little bit different. What if I type in just 'feb'? If I run this, we get February with a capital F, so now our date field in our form will be able to accept a wider variety of things. If you're like me, and you can never spell February correctly--I'll misspell this, and I hit run, we still get February nicely. This is nice, so I can type in any sorts of junk, and if the first 3 letters match a month, we can assume the user was probably on the right track. Okay? See--December. Next, I'd like you to write a function that, given what the user types in for the day, returns whether that day is valid or not. Okay, so here we are. Here's my version of the solution. We take in day from the user. First thing we need to do is we need to check if day is a number or not. Remember everything we get from--we get in our web app is going to be strings. HTTP and our web app doesn't know whether the user is typing in numbers or strings or whatever, so we get all strings, and we have to make sure our string is made up of digits. That's what the isdigit function does before we convert it to an integer, which is what the int type does here when we call it as a function. So now day, here, will be an integer, and if it's between 0 and-- if it's greater than 0 and less than or equal to 31, we return it. You can see down here, I've run it on 25, and we got 25. Let's try some of the error cases. I'll try 0. We'll run that. Our function returns none, which is what we expected. If I type in 'foo', one of our test strings--we'll run that. We get none again. Let's try a correct date again--31. We'll run that. Okay, all is well. Now, we could have made this more complicated by also taking the month, and then making sure that February has only 28 days and March has 31 and that sort of thing, but we don't need to make this too complicated. I'm not trying to quiz you on calendars. I'm just trying to quiz you on writing basic functions. Okay, one last function to write. This is to determine if what the user entered for the year is valid. Okay, here is my solution for a valid year. It's almost identifical to valid day. We take in a year. First, we make sure it's all digits, then we convert it to an integer. Then we check to see if it's within 1900 and 2020, and if it is, we return it. Let's go ahead and test this. Okay, I'll start with a valid year--1995. We'll run this. That works. Let's try another year--2000. Let's try that. That works. 2000. Let's try an invalid year--1875. If any of our users were born in 1875, they're probably not going to enjoy using our web app. Okay, so it returned none as we expected. Let's try some junk strings to make sure our function doesn't blow up. Also returning none. Let's try another string that's too big--2300. Also prints none, so our function is good. Alright, good job! Let's move on. Okay, so now we have these functions to validate the user's input. Let's talk about how they're going to fit into things. So we have you, and we have our servers, and you make a request for the form. This is a GET request, and the server responds with the form data, and then you make a POST request to the server with the data. In this case, it will be a month, day, and year. Now the server is going to run our validation functions, and it's going to do 1 of 2 things. If the data is good, the server will say, thanks, but if the data is bad, the server is going to respond with the form data again, and the server will also include an error message telling user to reenter their values, and they'll have the form handy so they can do that easily, and then we'll go up to this phase again. Okay, so let's talk about our approach to doing this. We're going to have to do 3 things. First, we're going to have to verify the user's input. Next, we're going to have to detect if it's an error and render the form again, maybe. And when we're rendering that form, we're going to need to include an error message because if we don't include that error message, the user is just going to hit submit on their form and see the form again, and they'll be confused forever. Okay, so here we are in our editor, and we've got our form handling code, and right now, it just prints, thanks, everytime. Let's actually use our new verification functions. So I've added a line here. I'm calling the valid_month function that we just wrote. I'm sending in as the first argument to that function the 'month' parameter that was included in our request. So this will indicate whether our response was valid or not. I'm going to go ahead and add this for the day and the year as well. Okay, so we've got these 3 variables, and now let's actually check them. If not (usermonth and userday and user_year), we're going to rerender the form again. If all 3 of these aren't true, we're going to render our form. Else if they are all true, we're going to say, thanks, which we have down here. So to recap, we're getting our 3 parameters from the request. We're running them through our valid_month, day, and year functions, and if they are not all true, we rewrite the form, and if they are all true, we say, "Thanks! That's a totally valid day!" Alright, let's give this a shot in our browser. Okay, so here we are on our browser. I'm going to type in a day again. Okay, so I typed in what I think is a valid month, day, and year, and when I hit submit, our browser says, "Thanks! That's a totally valid day!" Let's go to the form again, and this time, we're going to type in something invalid. Okay, now I've got an invalid month and normal day and year, and when I click submit, the form just clears because we sent back the form again. We can improve this a little bit, and let's start doing that now. Before we go too much further, I want to teach you a quick little Python thing about how to do string substitution. This will make generating our HTML a little bit more convenient. If we have a string in Python that's represented like this. This is a string that will probably be returning something like this in our web app-- you know--a little bit HTML with some contents. If we want to return a lot of different types of bold contents with different text, it's a pain because we have to make this whole string everytime. Instead we can do something like this. Okay, so here we have the same structure of the string. We still have got our tags for bold, but I've replaced the contents with this %s, and what this does is if we follow the string with a % sign and then a variable, it will substitute the contents of this variable for %s. So if this were instead a, and a = "some bold text", when we print this string, when we print "%s % a", we'll actually get output that looks like this, and this is how it can generate the strings. So this is really convenient because we could have a function that just substitutes 1 variable into a string, and then we don't have to build that string over and over again. Okay, so time for a quick quiz. Okay, here's my solution. I hope you used the new % thing we learned. Let's run it a few times. I'm going to substitute the string 'running', and we get, I think running is a perfectly normal thing to do in public. Okay, great! That seems to work. Let's move on to something a little bit more complicated. Okay, so that allows us to substitute 1 string. What if we want to substitute multiple strings? This is how to format, like this. If we want to substitute multiple variables into a string, we can include multiple % s's, but it means we need to include multiple variables. If you don't include enough variables, Python might get mad at you. Why don't you try that out in the editor? We'll do a quick quiz. Here's my solution for the second problem where we have multiple %s's, and if you recall from the lesson, the way we include that is we just include them in a tuple or a list. So let's give this version a test. Okay, we run this, and it prints, I think running and jumping are perfectly normal things. Okay, while we're on this editor, let me show you some common mistakes. One thing you might do is you only include 1 variable, so I got rid of the s2 there. Let's try running our function now. We get this big exception. There are not enough arguments for format string, which basically means our format string--this t2 string--has 2 %s's in it, and we only included 1. So if you see that a lot, or if you see that, that means make sure you have all of your parameters. Let's move on to an even more complex version. Okay, so now you know the basic % s and how to include multiple variables. Let's make it even more complex. What if we want to include the same string--the same variable twice or you want to not go insane trying to remember how many variables you've included and have to count % s's. There's a new syntax for that, and that looks like this. Instead of saying % s, we can include in parenthesis a name, an identifier, and then instead of including just variables at the end, we can include a dictionary that maps name to value, and name can appear in the string multiple times, and we can have multiple names. Let's have a quick quiz with that. Okay, here's my solution to the 3rd substitution. We've got our new string that takes these name substitution variables, and this time, it uses our function parameters and substitutes those into the string. Let's make sure this works. I run this with a couple things and it says, I'm maverick. My real name is steve, but my friends call me maverick. Cool. Now as you can see, this one is more complex, and it's starting to resemble something that might be useful to us. Of course, this whole string got cut off a little bit, but it's over here on the edge. Alright. Okay, let's talk about how to use this in practice now. We're back in our editor, and we have our app that if the submission is not valid, we just rewrite the form out, and if it is valid, we say, Thanks! Now let's work on this invalid case. Let's make that a little bit more friendly. The first thing we want to do is tell the user there was an error. Let's figure out a way to do that. We're going to add a little section to our form here for a little placeholder for our error message. After our form, we're going to have a . You remember . It's just a block element with no special styling or anything like that. It'll just make a new line for us, and inside that, we're going to print our error message, and we're going to use the string substitution we just learned to print our error message. Now I'm going to do 1 more thing here as I'm going to make this text appear red. I'm going to add a little CSS--style, color, red. Now this is--like I said, we're not going to spend a whole lot of time in CSS, but this is 1 example of how'd we use it. This will make this text in this appear red. Okay, so we need to update our form a little bit or the way we use form to use this. Since we're going to be printing the form in a couple of places--here and here-- let's generalize this into a function. So I'm going to add a new function called write_form, and this is going to take a parameter for the error message, and the default value of this parameter is going to be the empty string. All this is going to do is just going to self.response.out--it's going to write our form like we've been doing before, but we have to use a string substitution now because we've included a variable in our form. We have to address it here, and we're going to say, error equals error. So this is going to say the string error in our form will be equal to the value of this variable here, error. So this variable in the function is used down here, and it refers to the string substitution error here. Okay, now we need to use this function, and we have this new function write_form, so let's use it everywhere where we draw our form now. So we can use it here in our GET function, so now we can say self.write_form, and error takes a default parameter, so we don't need to specify it here. We can also use it down here in our POST function. We can say self.write_form, and now we can give it an error message. Okay, so what have we done? We've updated our form. We've made a new write_form function that should be a nice way of calling this, and we've used our write_form function here. Our GET, remember, just draws the empty form and our POST, down here, should draw the form with a new error message. So let's give this a try out in practice. There's one last thing we forgot to do. The first parameter to all of our functions inside a class should be self because otherwise this self here wouldn't be referring to anything. Okay, so we've got that in place. Let's try this out in our browser. Here we are in our browser. Let's give our form a shot. I'm going to type in some invalid data first because that's what we were just testing. So invalid everything, and we submit this form. Aha! Now we have our error message, and it appeared red like we wanted it to. Really cool! So now the user has an opportunity to submit the form again in a valid way. Okay, so we're going to fill out this form with correct data, and when we submit it now, we still see our success message. Cool! Alright, so we're making progress. One thing that would be nice is if when we entered bad data-- when we entered an invalid form--and we submit this, it would be nice if it left our values in here for us, so we don't have to enter everything over and over again, especially the ones that are already valid. Let's make that work. So before we do the work in our Editor, I need to teach you another little bit of HTML. So we've seen the value parameter on some form elements, and let's talk about how we use it in the text element case. This is our normal text element that we've been using. Now, of course, this will all be familiar to you: And this part is new--this is a value attribute, and this causes the text box, when we render it, to have this "cool" as the default value. So you can see, this might be useful for rendering our form with the values that the user just typed in-- so they don't have to keep reentering things all the time. And you can also use this to fill out form fields with default values, if you know what the user is probably going to enter. Okay--so I hope you can see the direction we're heading. We're going to populate our form s with what the user typed in. So which of these little bits of HTML is the correct for preserving the user's month? And the correct answer is this guy. We still want to have , we still want its name to be "month", and we want the value to be this variable substitution: "%(month)s". Now we didn't talk about what variable we were going to use but I figured you can guess it from our s here. Okay--so, cool. Let's try this out in practice. So here we are in our Editor--here's our form HTML. We're going to have to edit this to make it a little bit more complex. And I want to put in a few new lines as well to make it a little bit easier to read. So I'm done editing the HTML. I've actually only made a fairly small change but I put some new lines in here so we can read it. So now we've got , the string, Month--which is what it said before, and our field--and I've added this new value parameter for (month), and I've added another one for (day), and another one for (year). And we're going to pass these values in to our function below so that our form renders extra values. Okay. So let's edit the function below and put this whole thing together. We're going to edit, now, our write_form function. We're already passing in error--let's add in the other parameters. So I'm adding the extra parameters, and they're all going to have defaults to (blank) month, day, and year-- nothing crazy about that. and let's also edit our Dictionary that we pass into the form to use these variables. We've updated the dictionary; now we're passing these variables into this dictionary, which gets passed into our form string. And so, now, whenever we write the form, our form function--our write_form function-- can take extra variables to populate the form. Let's make sure everything still works the way it did before-- before we go ahead and call this function. Here we are in our browser; let's type in: some junk, submit our form, and see if everything works. Okay. We didn't get an exception; nothing broke-- so we're in good shape. Let's go ahead and get these fields populated. Here's our new write_form function, here's our POST function. Here we've got our three variables that represent what the user entered--we're getting them from the request here. Let's edit our POST function to use these new variables. Now we're going to have to restructure this a little bit because right now we're calling valid_month on the request parameters. And if one of these parameters is invalid, we're just going to get False back, and that's not what we want--so we need to change just a little bit. So let's restructure this. So I got rid of our calls to valid_month, day and year-- and user_month just equals what the user actually entered in for month, day, and year. And then I'm going to use different variables to test their validity, and I'll add those now. Okay--so I separated the calling of valid_month, day, and year from fetching the parameter out of the request. And this is so we can have both variables that represent whether the values are valid or not, and also variables that represent what the user actually entered-- because we may have to reuse those. Okay--so let's change our validity check now to use the proper variables. Okay. I've changed our validity check here to make sure we're using month, day, and year now-- those variables instead of user_month, day, and year. And now let's change our call to write_form. And now I'm passing in these strings that the user originally entered into our form so that when we have an error we'll render the form with whatever the user typed in. Let's give this a shot in production. So we've got our form; let's type in: some junk. When we submit our form now what we should see is an error message and our form field should still have our values in it. There we go. It doesn't even look like our form was rerendered because all that appeared was our error message. That's pretty neat, huh? And let's make sure that submitting the correct answer still works. Okay--so we're going to enter in real data. This is going to go through our validators, and let's submit this form: success! So it rejected our bad form and it accepted our good form. That's pretty cool. So I've entered in a normal dau and a normal year but in a month, I've entered in a quote and some more text. What's going to happen when I click the Submit button? Are we going to see an error message and our inputs will be on our form --you know--our normal error behavior? We'll see an error message, but quote messes up our HTML? Will we cause on error on the Server side? Or will the page just render: blank? And the correct answer is this: we'll see an error message, but the quote messes up our HTML, And let's see that happen, together. We said the quote was going to mess up our HTML-- let's submit the form and here we go. We've got our error message, but the string that I answered was: bar">what and "what" appeared outside of our text box. Now it's not too tricky to see why this happened. What happened was this string here-- this Python string--doesn't know it's HTML and when we entered in a quote in our string, Python substituted a quote in the middle of here and then I also put an angle bracket in, and that closed the tag. And then the other string that I typed appeared outside here. So what happened is our looks something like this. I left off the other attribute--it's no big deal; our variable (month) gets substituted into the string. So if: month = "November", the string, "November" renders and we get a text box that looks like this--which is what we'd expect. But if (month) equals the string, foo--with a quote in it-- and an angled bracket and some more text, the string we'll render ends up looking something like this, where we substitute this variable into here because the value for (month) is actually this whole string-- including the quote and the angled bracket, which screwed up our HTML. So our browser saw this-- and it sees an and says: value equals "foo"; and then it sees a closing quote and a closing angled bracket, and it gets this other string, derp, and it just prints that. So that's, obviously, not the behavior we want. The rendered HTML ends up looking-- or in the browser--ends up looking something like this. You've got a text box with the word "foo" in it, and then it's just a quote and an angled bracket, and the string, derp, just hanging out there and-- you know--that's not what we intended. And what's really scary is this allows somebody who knows how our Web site works to not just enter random text, but what if they put HTML in our ? What if, instead of (derp) it was something better? Let's look at that in our browser. So we're going to enter our bad data again--and this time, we're going to put HTML in there. Okay. So this time, I've put in a quote, an angled bracket--to close our tag, and then I've put some HTML--a line break and some bold text. And let's see what happens now. Oh, man! We completely broke our form. You know--now we're printing the bold text, "oh no!" and we add a line break and this allows a user to completely manipulate what our document looks like. So that is not something we want to allow. Let's talk about how to fix this. The problem is we have these extra--these characters, this quote and this angled bracket-- that shouldn't be allowed in our . Now we can check for that, and there's a couple of ways to go around this. But the nicest way to fix this is through a method called "Escaping"-- hence, the title of this page. HTML allows you to Escape certain characters or change them so that when the user types in (") we can still show the quote in the text box. What we do is, instead of returning (") in our HTML, we include this other string. Instead of including a ("), we convert it to (& quot;) and we can also Escape angled brackets. We'll convert the closing angled bracket into (& gt--which stands for greater than--;) and we've got some other Escapes we can do as well. We can convert the Less Than symbol--the opening tag-- into (& lt;) and we conclude the ampersand--or we can Escape the ampersand itself into "& amp;" So if we conclude these in our HTML, what will appear are these symbols-- but they're not actually HTML. All right. Let's play with some of these substitutions, in practice. All right, here we are, back in that simple text file-- the play HTML file I was playing with before-- and we're going to use this because it's a little bit quicker to demonstrate what I'd like to talk about. So I'm going to enter some text. So I've typed in some text; I Save it this and I load this in my browser. Okay. So here we are; I've loaded this text in my browser and, if you remember--if I just type in plain text in an HTML file, it just shows up as plain text in the browser. Okay. Now I'm going to surround this tag with angled brackets and let's see how this renders in our browser. When I Reload my browser, that word, html, disappeared. That's because, when I put angled brackets around it, it turned into a tag, and tags don't render an HTML. They turn into tags. So if we use the Escaping we just learned and I replace this Less Than symbol with our Escape, which is: < and I replace the Greater Than with: > and I Reload this in my browser, what we see is the actual text that we wanted to demonstrate-- which is the actual angled brackets. So let's try another quick example of this. If I were to change the string, html, to the letter, "b", and Save this and Reload this in my browser, we now have the tag. And if I were to go back to my Editor and change these Less Than's and Greater Than's back into the actual < and >, and Reload this in my browser, our text turns to bold. So if we don't want our HTML to behave as HTML, we need to Escape it. And if we want it to behave as HTML--we don't Escape it. All right. Try some Escaping on your own. So what is the correct way to include the text: & = & in rendered HTML? So it should look like this once it's rendered in the browser. What do we need to include in the HTML to get that ? And the answer is: & =& amp; And so this translates something like this: this portion turns into an ampersand, this portion turns into an ampersand, and this portion is just text, So that's what we get--nice work! Okay. So what I'd like you to do now is implement the function: escape_html ( ), which will take one argument, (s), and will replace any occurrence of the Greater Than symbol on that string with: > the Less Than symbol with: < Double quotes with: " and an ampersand with: & And then it should return this string with this side replaced with this side. Okay. Good luck! Here is my version of the function for each of the characters we need to replace: "&", ">". "<", "quote". I replace it with is appropriate escaped version of the string. I'm just overriding the same string, over and over again-- which is maybe not the finest way to do it but it'll work, in our case. And keep in mind that we need to replace the ampersand first. If you did it last, for example-- and I enumerated it last, to be a jerk-- you would replace ">" with ">" and then you'd replace the ampersand in your new Escaped string with an "&". So let's test this a few times, make sure it's working. Okay. Obviously, it prints this test string test. Let's give this one a test. Okay. And this is what we get: We see our "<" is Escaped to "<" and our ">" is Escaped and so is our next "<" and our next ">". Let's test the other ones, to make sure everything's working. I'm going to get rid of these quotes and use single quotes instead so we can test the escaping of those. And what's the other one we didn't test? Aha! Yes, we'll do our quiz from before: & = & And we'll see how this prints. Okay. So here we go--Run. We see our double quote was replaced with: " and then our ampersand-- this was the quiz question we asked before-- so we have: & (which turns into one ampersand here) =& (that ampersand); just: amp--for the letters a-m-p; and then our closing quote. Okay. So let me show you one other simpler way of writing this function. We can replace most of this code-- like so. We could say: import cgi. As it turns out, this function is already included in Python: cgi.escape (s, quote = True) Otherwise, it doesn't Escape the quote and--oops--let's return this. Okay. So another way of writing this function is just to use the cgi module that is included with Python, and let's give this a shot. And, as you can see, it works just the same: "hello, & --blah, blah, blah, blah-blah. We see our Escape version of our string here, and this is obviously a lot simpler than writing in your own. You may need more functionality yours, if you want to do that in the future. But for now, the built-in one will work just fine. Okay. Good job. Okay, so, I just had you implement your own HTML escaping function and then promptly showed you that you didn't actually have to do that, because it was already built into Python. Well, the exercise is important, because now you know what actually goes into the escaping function that's built into Python. But you should probably use the one that's built in, because it's been written by professionals and seen by thousands of people and used in production, so it's probably pretty safe. If you don't use the safe one, sometimes you can run into trouble, like we did at Reddit once. So, we had our own HTML escaping function, nearly identical to the one you just wrote, except it had a few extra features in it, because we had a few extra features in our comment pages. Now we, at one point re-wrote this function in C, from Python, because C is much faster and we needed that function to be particularly fast. Well, when we open-sourced Reddit, we did a quick scan of our code for security holes, and, we weren't too concerned about this because most of Reddit is written in Python which is a fairly secure simple language. C, that's not quite the same case. So, on the day we open-sourced Reddit, somebody found a security hole in our HTML escaping function that we wrote in C. It was only like 20 lines, but within there, there was a hole. And, it was super embarrassing. We fixed it right away, but it just goes to show, you know, unless you have a really good excuse, you should probably just use the built-in functions. Otherwise, you're going to end up looking like dorks, like we did. Okay. So we have our Escape HTML function. Let's go ahead and use it in practice. So what we're going to do is--we're in our write_form function-- when we print out values that came from the user, we want to make sure they're Escaped so we want to call it on everything that came from the user. So we've called our escape_html function on each of these variables that came from the user and so now, when we render the form back to the user, we'll have these new Escaped versions of their . Okay. So here we are in our browser. Let's go ahead and enter some broken text. We'll enter the same broken text we entered before, starting with a quote and the other ones are just normal stuff for here. And now when we submit our form, we get our error message and our HTML isn't totally broken. Remember, the Escaped versions of strings render as the unescaped versions in the form. So, in reality, our HTML said: &" &>& You get the picture. But when the browser renders it, it looks totally normal. Now we've got our error handling pretty solid. You can type in all sorts of garbage into these fields, and we get an error message. And when you type in the correct answer, it says it works. So let's type in the correct answer-- and now that we've got the error case handled pretty good, let's handle the success case a little bit better. So we type in a valid date and we click Submit-- and we get our Success message. But this page has a major limitation. The first is that we can't link to it. If we try to link to this page-- if I want to say hey--to my friend-- look at how good I am at entering dates and here's a URL to prove it, I can't share this URL because if I share it he just gets an empty form and he doesn't get to see how good a job I did. So let's submit this again. The other problem this page has--if I want to Reload it my browser says hey, do you want to resubmit this form? That's because we're Reloading a page that was drawn with a POST. And if you Reload a page that's drawn with a POST, the browser says hey, should I do that POST again? That's what this dialogue box is and just about all of your browsers will have some message that basically says that same thing-- do you want to resubmit this form? And if you click Continue, it runs our application again, and it draws this messages again. That's not quite the behavior we want. This is annoying, for a couple of reasons. Okay, so we're just playing in the browser, and we had a couple of annoyances. They were: We can't share the success link and we can't reload the page without an annoying message. The way we work around this issue is by using a redirect. Instead of rendering the result in the post, we send them to another page that says thanks. So remember I drew this picture before of you and the servers making requests, or you and your browser. We made that first request, the get request for the form, and then the server responded with the form HTML. You posted your answer, and then if you submitted something correct, the browser responded with the success message. Now, this seems simple and nice, but as we said, if you respond to a post with content you've got these two major limitations. The link doesn't share well, and you can't reload the page. Now imagine we weren't doing a contrived example like entering dates into text boxes. Instead we were adding a new blog post to our blog. We'd want to be able to see our blog post once we submit it. We want to be able to link to that blog post. We want to be able to reload that page without editing our blog post. Every time you post something to the server, the server has to do some work. We don't want the server to have to do that work of validating our date every time over and over just when we want to see our success message. So instead of returning the success HTML, we return a redirect. We'll send a redirect to go to a different URL, our success page, to which the server will respond with our success HTML. Now, you may think the old way had only 2 round trips: Get, post, answer. The new way has: Get, post, and get the success page. So that's three round trips, but we can avoid both of these issues. Why is it nice to redirect after a form submission? Because posts can't return HTML? So that reloading our success page doesn't resubmit the form? To remove the form parameters from the URL? Or so that we can have distinct pages for forms and success pages? Check all that apply. Okay, so the correct answers are not because posts can't return HTML. We've seen that posts can return HTML. They can return our error page, for example. Reloading our success page doesn't resubmit the form. That's a nice benefit to remove the form parameters from URL. Technically, if you had a get request that submitted your form, and then you redirected when a form was valid, yes you can remove the form parameters from the URL. However, if you're sending data to the server with the get request you have not been paying attention to this lesson. So I'm not going to count this as correct. Finally, so we can have distinct pages for forms and success pages. This is also true. What I've been getting at is this nice behavior you can have where you have your forms, and you submit that form over and over, you post to it, and you keep getting that form over and over until it's valid. Once it's valid we bounce the user, we redirect the user to another page, whether it's a permalink to the blog post they just entered or a thank you for being so good at entering dates page, to a thanks for registering on our website page. There's lots of things you want to do there, but having separate pages for those is nice. It's a nice way to structure app. So let's go ahead and make this change to the app we've been working on. We're going to make this change to the app we've been working on, and we've got to do two things. We need to make a thanks handler. We need to add the thanks URL, and we need to redirect to the thanks URL. Okay, let's go ahead and do these. Here we are--we have the functions you're familiar with, our normal form handler. Let's go down to the bottom of our file and add a new handler. I've added the definition for the thanks handler. This has the same structure as our other handler. It has a name, and then it inherits from webapp 2 request handler. We're going to add a get function to it for get requests. We're going to take this behavior from here and move it down here. Okay, now we have our handler. Let's do the redirect here. So instead of printing thanks we're going to redirect. This is how you do redirects in google apps. You call the function redirect on self in a handler, and it will redirect you to the URL that you provide. We don't have to say HTTP here because we're redirecting to the same domain. So we can just specify the path. We need to do one final thing. We need to add the thanks URL. We need to map it this handler; so let's go ahead and do that. Okay, I added another URL down here in our mapping area. It maps /thanks to the thanks handler. Let's go ahead and test this in the browser. We reload our page, we enter in a valid date, and we click submit. Now, remember submit is going to give us a redirect instead of just sending us data in the post. Here we go. We are now at /thanks, and our web application is saying thanks. Now we can reload this page as much as we want, and we don't get any silly resubmit this form thing. I can share this link with my friends and say look how smart I am. I know my birthday. They will be suitably impressed. The server won't have to validate our form over and over again. Okay, that's it for basic forms. Thanks very much. Okay, everybody. Welcome back. This is a little mini lesson, we are going to do, talking about how to use templates. And we are going to spend a lot of time today in our editor and browser, basically working together to build a few templates in a simple web application. So let's start with what a basic web application looks like. Here we have a, a basic little web application. This is effectively the Hotel World homework that you did from lesson, from the first lesson. And you know as you can see it doesn't really do much. It's got one handler on slash called main page. Which is here. And all it does is it prints the string hello, Udacity. I've made my main page handler inherit from a class called Handler, which I defined up here. And this just adds one method called Write. And all write is, it just lets me print a string without having to type self response.out.write, I can just type self .write. And we'll be adding a few more helper functions, to this handler, as we go. So we've got this basic file here, we've got this basic app.yamal, you know, nothing, nothing crazy here, this is, this should all be familiar to you by now. Lets go ahead, and make sure this works. We go to our terminal. I'm in the template lesson directory, where these files are. As you can see, ,we'll run the app server, like so I, I prefer to run the app server from the terminal so I can just see what's going on, and can kill it easily, it's telling me we're running at local host 8080, so let's go ahead and check that out in browser. We'll go to local host 8080. We'll load this page, and we see our text that I typed hello, Udacity! Let's just make sure everything is working as expected. I'm just going to change this string, adding a few exclamation marks. I'll save this file and the go back to our browser and reload, and just make sure that everything is working end to end. Okay. Here I am in the browser. I reload. My extra exclamation marks appeared. So we are all good there. Now in this slide, I'm going to ask you lots of questions like, what happens when you do x or y or whatever. So try to follow along with me as we go. that'll, that'll kind of keep things going smoothly. Now you're remember if from the end of your homework from lesson two um,where we made a basic form, if you want to make a basic form we can just return html directly from our handler here. So I'm going to add a quick string that represents an HTML form. I'm going to start with a triple quota string. This is basically the python syntax for a multi line string. Anything I type between these two triple quotes will just be a part of a string, including other quotes and such. So, it just makes it typing html a little easier. Okay? So, a form tag, remember that just starts a form. A little h2 tag, that will just add a little title. An input box, type text and we'll give it the name food. And the button to add this food. Now it looks like we're building some sort of food or shopping sort of thing and indeed we are, we'll kind of build there as we go. But for right now its going to start with this basic form. App returns this html and the fact, I am going to rename this form html, so it's little bit easier to see down here. So, lets replace this text with form HTML and we will give this a [UNKNOWN] in the browser. Reload the page. And I see a basic form. Now, recall that since we didn't set a method on that form, the default method is going to be GET. Which means when I submit this form, it'll just add that parameter to the URL. And let's go ahead and see that work. Okay, so I, typed in a food in the text box. And when I hit enter, the page reloaded with the food I just entered in the URL. Our first quiz is going to be. When I type in a new food. In this text box and hit add. What happens? When I submit a new food in the text box, what happens? Choose the correct answer. The food parameter in the URL updates to match our new food. Do we see a second food parameter in the URL, so it'll have both steak and eggs in the URL. Or, does the browser report an error? The correct answer is the food parameter in the URL updates. Let's go ahead and see that in action. Okay, you can see that we've already got food=steak in the URL from the first time that we submitted the form, and now when I click add for eggs here, the parameter updates in the URL. Now, we've done this before, but it's nice to have. A good refresher because it's going to get a lit bit more complicated soon. Okay, we're going to go back to our editor and add an extra little feature here. Okay, so we're got our first input, type equals text. I'm going to add a new input that we may not have dealt with before called type equals hidden. And this is a sneaky way of including values when you submit your form that the user can't actually see. Sometimes when you submit a form you actually want to have more information then what the user's just given you. That's what type hidden is for. I'm going to give it name, food and I'm going to give it value X. Okay, back to the browser. I've refreshed our browser and reloaded that new page. Now, I'm going to enter in steak here again. And time for another quick quiz. What happens when I click add here? What happens when I submit the form, that has a hidden input in it already? Do we see one value in the URL with what we just submitted? Do we see two values in the URL? The one we just submitted and the hard coded value. In this case, the hard coded value, what I mean by that is. The word eggs that we put in that hidden input that was in our code. Or does the browser error? And the correct answer is we see two values in the URL, the value we submitted and the value we hardcoded in our code. So let's take a quick look at this again. Recall that in our code, I added this extra input type hidden, name equals food, which matches this name and the value eggs, hardcoded. And then in our browser, when I click steak, the URL updates to have both steak, the one we've just added, and eggs in the URL. Let's try a few more examples while we're here. Let me try adding pizza. You can see steak, the one that came from us, changed to pizza, and eggs remained. Let's see also what happens if I type in eggs. Now we get eggs twice. So you can see we always have the value that was in our hidden elements in the URL and then what came from the user is also there. But we can't add multiple things quite yet. To be honest with you, I wasn't actually sure what was going to happen when I was writing this lesson plan. Just happened to work out in a, in a way that I could make a nice example. And just goes to show you, you know, some of the stuff is a little tricky, but it's very easy to just play around in your editor and in your browser to actually, you know, see what happens. Now let's go back to our editor and turn this into a mini shopping list application. Okay we're going to add a bunch of code here that I'll walk you through as I go. Okay first thing I'm going to do is replace this input type hidden line with a percent s and if you recall percent s is the. Python string formatting character I'm going to give you a quick example of that. I'm in Python real quick, if we have a string you know, hello percent S. And I say percent Steve it substitutes the string following the percent sign in to the percent S in the string. So if I were to say greeting, equals hello percent S, and I can say greeting [UNKNOWN] it substitutes that string in. So, anyway just kind of basic Python, but I just wanted to make sure you understand it, because I'm going to abuse it in this lesson. Okay, so a replaces input with percent S, and I'm going to add a couple more templates here and then explain things as I go. Okay, and now I'm going to add a couple more strings, HTML strings and I'll explain them as I go. What I'm trying to do here is trying to make a big mess here for you that we will clean up using templates later. Okay, again I'm making, I'm using another triple coded string so I can enter HTML [SOUND] I'm going to make my input type equals hidden. Name equals food again. And value equals percent S, because I'm going to substitute more values in here. Then I'm going to make one final string that will represent a shopping list. A couple blank lines, a little title, and then an unordered list. Remember the UL tag makes an unordered list. I'm going to use percent S to represent our content inside there. And them I'm going to close my unordered list tag. Now you'll notice I'm not really indenting things or not getting any nice syntax highlighting. That's because I'm editing strings in Python. It's not an ideal way to go but, it's what we're doing for now. Okay, now let's update our main page handler to do more than just print out the form HTML. What? Actually, let's take a look at what happens if, if I just print out this HTML as it is. "Kay, we're back in our browser, and I've rerouted the page, and now you can see there's this big ugly percent S in the middle of our form. And remember, this is in the HTML, this is where our hidden element used to be. If I were to look at the source of this page, you can see it right here in the browser that ugly percent S. So, anyway, lets go back to updating our code. First thing, I am going to do is build up a string called output. It's going to be, it's going to start off as our form HTML and this is what we are going to return to the user. So, go ahead and, and update this to return output. Okay, and now remember our, form HTML has a percent S variable in it so I'm going to make a holding place for the value I'm going to in there, and I'm going to call that hidden HTML, and that will refer to that'll hold the content that we're going to sub into there, that'll be where our hidden inputs go. 'Kay, now this line here gets all of the get parameters, or post parameters for that matter, called food. get_all basically means in, in App Engine, basically says, if there are multiple parameters with the same name, get all of them, and put them in a list. So items will be a list of all the food parameters that are in the URL. 'Kay, now we're going to loop overall each of those items. So, the first thing we're going to do is we're going to add our hidden HTML line. Okay, and actually I have a little bug here. I am going to replace, I going to rename hidden HTML to be output hidden. I'm going to prefix all of my strings that are holding output HTML with the word output. And because I originally called that hidden HTML but we're already using that up here to refer to this little HTML string for hidden input. So, for each item in items add to the string hidden HTML substituting the food name. So basically output hidden will be a bunch of input type hiddens where the value is the food from the URL. Okay, I'm going to add another [UNKNOWN] here we'll call output items, [SOUND] and also for each item and items, we're going to append another little bit of HTML. And you can see actually I didn't create item HTML, let's add that real quick up here after our hidden HTML. And this will be a list item that goes inside the shopping list HTML. So we're going to create up, add up a bunch of those. So we've got output_hidden which will be a bunch of hidden inputs and output_items will be a bunch of list elements. Okay, now we're going to use our shopping list HTML equals shopping list HTML substituting in our items and then our output. And then to the end of our output we're going to add our shopping list. And we will only want to add things for our shopping list if they were actual items in the response. So if the response is empty, none of this is going to work. So let's make sure we do this properly. So I indented everything. As you can tell, this is getting somewhat hard to read. That's kind of the point. And finally we're going to take our overall output and substitute in the, the hidden string that we've been building up here. Now, when of all this is said and done, this is going to give us a basic shopping list functionality. Which I'll demo now, and then we'll walk through the actual code. Okay, so in our browser I've reloaded the page and let's test out all that new code we just wrote. Okay, so I added steak and you can see it reloaded the page food equals steak in the URL and it added our shopping list. So now you can see what we've been working towards this whole time. Let's take a quick view of the source code of this file. So you can see our form here and you can see we stuck in the input hidden value equals steak. And then our shopping list that we appended to the end of that output HTML you see a list item for steak. Now let's go ahead and try adding another food, eggs. You can see what's on my mind this morning. Okay, so you can see we have both our elements in the URL, that's because, when this page loaded last time, it had steak as a hidden input, remember, and when we submit the form, the hidden input stays preserved. Let's look at the source for this version of the page now, and you can see we have two inputs two hidden inputs, one for eggs, and one for steak. And then we can see, we have the list items, we have been adding. Notice that the whitespace here, is kind of messed up. HTML always puts list items unless you install it otherwise, on their on line. So, independent of whatever white space is in our source, HTML will display it. Lets, lets try, just for fun, adding something to URL here. How about food equals pizza and when I hit enter we get pizza added to our list. Lets go through this code one last time so you can understand fully what just happened. We got our form HTML's from just a basic form and inside that form that's where we're adding in the hidden inputs. If I were to view the source of a version of this page you would see that we have three hidden inputs when we have three items, food items in the URL. The HTML that describes those hidden inputs is here. Now, in our code, we said that if there were any items in the URL, any items that come from the food parameter, that we would do all of this string formatting here where we basically build up a list of the hidden items, and then build up a list of the list items. These bits of HTML here. And then concatenate everything together, putting the items into the list and then putting that whole shopping list at the end of our output, and then, finally, we substitute our hidden html that we've been building up into our output string and we write the whole thing back to the user. So, the functionality we get here is a kind of neat side effect of how storing data in the url allows us to build this fake shopping list functionality. But, it was a little bit of a pain to write. Okay, and now it's time for one of those quizzes where you probably already know all of the answers. So what is wrong with that previous solution that we just went through? Check all that apply. one, it's a pain to change. Next, we don't get any syntax highlighting in our HTML. Our code is ugly, and it's very error prone. And I, I'm, I left out of the video the part where I was swearing trying to get all of this working for you. Okay. Check all that apply. And, obviously, the answers, are all of these. It is a pain to change. We've basically hard-coded these percent s's here and there and we're doing this complicated logic to put everything together. That is zero fun. We don't get any syntax highlighting. That's correct. Because we're putting HTML in our Python code. So, we're not dealing with HTML. We're basically dealing with big strings. And that's really tedious to manipulate when your editor is set up to write Python. Our code is ugly. I didn't have a whole lot of fun explaining that code to you. I can't imagine you had a whole lot of fun listening to me attempt to do so. We can certainly make things a lot more clear. And it's error prone. You know if you miss one of those percent s's, you get a percent s in your output. If you want to, you know, add extra things, it's very difficult to reason about and kind of figure out what goes where. So this is, obviously, not a particularly great approach for generating HTML from our web application. It works for short, little things like just a simple, simple tiny form. But anything more complicated than that is very unwieldy. Fortunately, there is a better way. We are going to use a technology called templates. Templates generally refer to a library. As a template library is a library to build complicated strings. And by strings I really mean any string. But when you're developing web applications, most of the time, we're referring to HTML, because those are the strings [UNKNOWN] generate the vast majority of the time. And in this lesson, and really for the rest of this class, I'm going to be using a template library called Jinja 2. The reason we're using this is because it's built in to Google App Engine and, you know, there're many templating libraries, and they're all very very similar and Jinja2, while this course is the first time I've been exposed to it. Was very easy to learn for me because it is very similar to other template libraries that I've used, so it should be very similar to other template libraries that you will probably find yourself using, down the road. You can find more information about Jinja at jinja.pocoo.org. P-O-C-O-O.org. Let's start integrating this into the little toy app we've been building and see how things look. Okay, the first thing I'm going to do is update our app. [UNKNOWN] this is an app engine thing. If you want to include external libraries, you need to do this. You got a libraries line, you have the library name, and you say which version to use. You don't need to fully understand this right now and to be honest, I don't fully understand this right now. You can find more information in the App Engine docs, if you want to start including more libraries. Next what we do is we add an import statement to import Jinja. At this point I'm going to reload our web app just to make sure this import statement worked, which basically implies that the apps, the app.yaml update worked as well. So I get to this page, and I hit reload, and it looks like it worked. If there was an error, you know, let's say I type this incorrectly, you know, adding an extra 2, this is something you might see when you're doing this on your own, and I reload this page, you'll get you know, you'll see blank or nothing. And then if I look at my terminal, we can see an error in my terminal, no module name jinja22. So, if you see this, you know, make sure you updated your [UNKNOWN] properly and make sure you typed the, the module name properly. Okay, let's get rid of that. I'm going to add a couple lines to initialize Jinja. These two lines are basically where you're using the OS library, which is built into Python. os.path.join, this concatenates two file names. And I'm, so I'm concatenating, this is basically the directory that my current file is in. And then I'm adding the word templates to this. If we were to run this in the python terminal, it would look something like this. So here I'm in the python terminal. I just want to, I just want you to see what's going on here because this is very simple, but if you've never done it before, it can be a little confusing. And you may as well just understand everything that's going on. So if I were to say os.path.join and run it with a string like home and a, and a string like Steve, it just [UNKNOWN] the two together, gets the slashes right. You know you could just say plus, but it just makes sure that everything adds up. So that's os.path.join. This, this other part the os.path dirname, returns the directory of the current file. That's actually not going to work in the terminal, because underscore underscore file doesn't exist. But it exists when you're running a program. So this is just basically says, my template directory will be the current directory I'm in, slash templates. Okay, next we instantiate what we're going to call the Jinja environment, jinja_env. And, basically, this is a new jinja environment, and, we're going to use a FileSystemLoader using our template_dir which we just defined there. And this basically says, when we render templates Jinja's going to look for those templates in this directory. Current directory slash template. Nothing too complicated there, and you can just copy these lines. Next, I'm going to add a couple of functions to my handler class here. I added two functions. Render str and render. So the first function here is called render str. And this basically takes a file name, and a bunch of extra parameters. This is the python syntax for, basically, extra parameters. And we use that Jinja environment that we created earlier above, and we call it get template and give it a file name. This basically causes Jinja to load that file and create a Jinja template. We store it in t, and we call t.render passing in the parameters that were passed into this function. This'll be more clear when we actually use this as an example. And this just returns a string. And then I added this other render function, which I'll use all over the place, which again takes a template, a bunch of extra parameters and it just cause render stir this other function, but it also wraps itself in self.write. Which is the one that actually sends it back to the browser. You'll actually see these 3 functions in most of the examples, most of the homework solutions and stuff I use in this class. I've just been copying them around. And in fact what's funny is actually just interviewed a guy at Hipmunk, who had these three functions in his code. And I had asked him. I was, like, where did you get those, those functions from? And he, he couldn't remember. I was like, Yeah, it's from this [UNKNOWN] course I taught a little while ago. [LAUGH] So, anyway, yeah these are handy little things. Feel free to copy them around. It's just for rendering basic templates. And next one I'm going to do is move some of this HTML out of HTML and into a file. So let's create a new file, and copy, and let's copy this code, or this HTML into that file. Let's get rid of this percent s for now. I'm going to save this file, I'm going to call it shopping list.html, and I'm going to store it in this template structure that I just created. Okay. Now as you can see, sense we're using this editor sublime, and it knows it's HTML. It actually just started Syntax highlighting things for us. And we can also clean up our indentation here without too much drama, so it looks a little bit better. You notice I still don't have any of the HTML scaffolding around this. You know, the head and the body and the, the actual HTML tech. That's because it's not really needed for this example, and we'll add it in later. It's generally good form to do so, but, there's no reason to make you guys watch me type that over and over again. Okay so we got rid of this form HTML, let's just get rid of this altogether, and let's see if our basic scaffolding is working. So, instead of doing all that other stuff we were doing down there, let's just say, self.render, that's the new function we just added. Shopping_list.html, so this should just render that empty form, and then we'll go ahead and comment out the rest of this. Okay, and we'll take all of this other, other junk that we were doing before, and and we'll comment it out for now. Okay, let's go to our browser and make sure this works. Okay. I reloaded the page, and we have our add food thing again. And if I add foods, we can see them getting added to the URL, but since we don't have any of that that hidden input trick and we're not pulling things off our parameters anymore, it's just replacing the one item in the URL. But that basically shows our template is working end to end. Okay, so hopefully you were able to follow along with me through that. I know, I know it's kind of tedious, but now that we have the scaffolding up, we can actually start using these templates. So let's go ahead and learn a few things about Jinja templates. Now we're actually going to use these templates. First thing we're going to learn is, variable substitution. The syntax for in, substituting a variable in Jinja is just double curly braces, and then you include your variable name, and then you close your curly braces. Pretty simple, right? Basically these curly braces, it just means print. It's as if you typed the print statement. In the middle of your HTML code. So let's see what that looks like in practice. Okay, I'm going to go into my shopping list HTML file. And add, I'm just going to add a string right to the bottom of the file. Okay. So I just said hello, and then I added in a curly, curly name. Now, where is name defined? It does not define anywhere yet. Let's see what happens when I reload this page with just this. Here I am in a browser. Let's reload this page. And it says hello, and there's nothing there. Actually we can get rid of this egg. That's a little leftover. So Jinja, if the variable's not defined, just quietly doesn't include it. Now let's go ahead and include name. Lets just kind of hacked this in real quick. Name equals Steve. Okay, so, remember before I was talking about this star, star syntax. Name equals Steve basically gets passed in as star, star kw, which gets passed along here. Which gets received by render string as star, star params. Just different variable names, to be deliberately confusing for some reason, and which gets passed into the render function from Jinja, which expects keyword parameters. So, it's going to define name equals Steve, and if we go to our browser and reload this. We see, it says hello Steve. Let's see if we can make this a little bit fancier. What is instead of name equals Steve all the time, we said name equals self.request.get name. So we can put name as a, as a parameter. Let's see if that works. Okay, if I reload this page, I get nothing, because there is no parameter. But if I add name equals udacity, we can see that udacity appears in our template. Okay, so, right now we basically have this very elaborate way of doing string substitution via these files, but we can, we can always see we're somewhat on the right direction of having cleaner code. And, time for our quick quiz, okay, so what I want you to do, is use variable substitution, the syntax I just showed you, to make this string. The quick brown and then the variable, animal1, jumped over the lazy, and then the variable, animal2. Go ahead and type this complete string with the correct variable substitutions for these variables, in the box here. And the answer, of course, is the quick brown, and then we say squiggle, squiggle, animal1, squiggle, squiggle, jumped over the lazy, squiggle, squiggle, animal2, squiggle, squiggle. Not too complicated. Huh? So, good job. Let's learn some more. Next, we're going to learn about the statement syntax in Jinja. The statement syntax is very simple, it just looks like this. This is squiggle percent, and then you have your statement, and then you have a close squiggle percent. And then you'll often have an ending statement, which is surrounded by squiggles of course, and in the middle you have your output. For example, an if statement might look something like this. So I'll say if name equals, equals Steve, this is just a Python syntax for an if statement. Notice there's no colon at the end. Will print hello Steve. Else will print, who are you? This whole thing is followed by the end statement block. Which in this case just says end if. Now this whole thing is followed by the end statement block, which in this case just says end if. In Jinja we have to tell it when the if statement is over. So what this will do when this is run, if the variable name Steve or if the variable named name equals Steve, it'll say, hello Steve! Else, it will say who are you? And this ends it. Let's go ahead and see this in practice. Okay, I'm going to get the variable n from the request and n will be a number, and we're going to change this to be n equals n. Then we're going to go into our template and we're going to change this. We're just going to work on the same template here if you don't mind. We're going to change this to use a basic if statement. So if n equals one, say n equals one, else say n does not equal one. Okay. We've got our basic if statement, if n equals 1 in Python, we print the string n equals 1. Else, n does not equal 1. Now notice anything I put between these curly braces, this could be HTML, this can be anything. This is just text. And then finally, we finish this with end if. Notice there's no space between end and if, that's all one word. So when we go to our browser to run this, and we reload the page, we see n does not equal 1. Well that makes sense because we haven't specified n in the URL. Now, I hope you're following along with me, and let's go ahead and add n as a Get parameter, and we'll make it equal to 1. Okay, so we set n equals 1 in the URL here, and when I hit Enter, hm, I expected this to say n equals 1. I wonder what happened. Maybe you can figure it out. Why didn't that work? We put n equals 1 in our div parameter but when we checked for it in our template, it was saying n does not equal 1. Is it because n was modified going into the template? Is it because jinja has a different notion of equality? Maybe it evaluates double equals differently? Was it cause we have a syntax error, or is it because n is a string, but we're comparing it as an int. These are plausible situations, see if you can figure out which is the cause of the error in this particular case, because what we just did, should work. And the answer is, because n is a str but we're treating it like an int. Let's look at our code again. So on our code here, we're getting from the request and we're just storing on th, in the variable n here. Now the problem is, when things come out of the requests there're always strings. So if we want a, if we want to be an integer, we need to make it an integer. Let's go ahead and do that. So basically, if n was specified, convert it into an integer. Now let's see if it works in our browser. Okay, here we are, N equals 1. I'm going to hit Enter, and N indeed equals 1. And if we set it to something else, N does not equal 1. And if I set it to a string, we don't get anything. And actually what really happened, is we got an error because we tried to convert the string Steve into an integer and Python did not like that. We're not going to go ahead and fix that, but what I wanted to show you, was that when you expect an integer as a parameter from user, you need to actually convert it. because the web application, or the browsers, or the HTTP has no idea what's an integer and what's a string, so you have to actually do that check yourself. And if we want to make that previous example work, we would have to check to see is the string all digits first, and then, only then convert it to an integer. So, it's a common mistake, I actually, I made it when I was doing this lesson in the first place, and so I thought I would let you see it as well. Let's learn another quick piece of syntax that is pretty handy, that I'll use a lot in this course. And it's just for doing a for loop. So, the syntax is very much like that of the if statement. In fact we use, false statements are like this, so, it's going to look like this. Curly brace and then we'll have our for statement, percent, close curly brace. And then we can have our, our the body of the for statement. And just like the if statement, we have a closing block as well. And our for statement will be just like the Python for statement, and this, is, allows us to execute or print or whatever, whatever is in body, do that, you know, in a loop, which is really handy in a template. So let's go ahead and see a quick example of that. Okay. We're going to leave our n the way it is. Okay. And let's replace our if statement demo with a little for statement demo. So, I'm going to put all of this in an ordered list. Now, we used unordered list before. Remember ul, ol is this ordered list, which means I'll actually print the item number. It's kind of handy. So, for x in range 1 to n plus 1, so this'll basically if n is 10, this'll go from 1 to 10. And say put a list item, for x to the power of 2, x squared, which is Python syntax for doing that. Now notice inside the, the double curly braces, remember, this just means print. So, and we can put. Just about any arbitrary Python inside here, which is indeed what I've done, so x to the power of 2. And then we end our for statement, and we close our list. So let's go ahead and see if this works. I'm going to set n to 10, and indeed, it works. And we can see, this basically is printing x, 1 through 10, along, in the left column, and then x squared in the right column. Lets go ahead and view the source for this file. You can see down here, here is the code we generated. Ordered list, and then 1, 4, 9, you know, 1 squared, 2 squared, 3 squared, 4 squared, all the way down to 10 squared, and then close ordered list. And so the template made it real handy to do that. Lets go ahead and see what would happen if I changed this ordered list to an unordered list in our code. So if we change this ol to a ul, and we go back to Chrome and we reload this page, you see the o changed to u. And we go here, instead of the numbers for our list items, we get the little dots. It comes up from time to time, these days you often just generate your list markers yourself using templates but. You know, for quick and dirty, you can just use ol or ul to get, to get what you want. Okay, time for a quiz. Okay, create template that when provided with the variable n prints FizzBuzz up to n. Now, what is FizzBuzz? FizzBuzz is, is a little programming test that's easy, it's, it's a quick way to see if somebody actually knows how to program simple things or not. Basically when you do FizzBuzz, I want you to follow this logic. If n is divisible by 3, I want you to print Fizz. If n is divisible by 5, I want you to print Buzz. And if n is divisible by 3 and 5, I want you to report FizzBuzz. And if it's not divisible by 3 or 5, just print the number. Let me show you what this will look like when it's working. Okay, so here is a working FizzBuzz app. I'm just going to ask you to paste in the template for a FizzBuzz, but here's, here's what it looks like. So if we were to say FizzBuzz of n equals 100. This is what it would print, one, two, three is divisible by three. So it would print fizz, five is divisible by five, so print buzz. Four is neither. Six is three so print fizz. Come down here to 15 we print FizzBuzz. So as you see anything divisible three or five prints fizz or Buzz, both Fizz and Buzz. And if it's neither, it just prints the number. And the source that we generated looks like this. It's an ordered list and then I'm just printing list elements for each value as we count up to n is 100. As you can see n equals 100 down here. The handler that I'm using looks something like this. I just added this to the end of the file we've been working in. I made a new url called FizzBuzz which uses FizzBuzzHandler. Which is defined here, which inherits from Handler. And it gets n from the request defaulting to zero, converts it to an integer. n and int(n) is the same as basically saying if n, n equals int(n). And then we're rendering fizzbuzz.html passing in n equals n. What I want you to do for this quiz is generate fizzbuzz.html. And once you've got that working, I'd like you to paste that right here. Okay, good luck. Okay, how did you do? Spectacularly well, I hope. Lets go over the solution. Okay, so my solution looks something like this. First we have an ordered list at the top and bottom. You know? Opening and closing. And then we have a for loop for going over the range from 1 to n plus 1 and then we say, basically, if x is divisible, and we can use the mod operator to determine if something is divisible. Mod basically says, it gives you, it gives you the remember. So, x is divided by 15, what is the remainder. If that, If that's zero that means x is divisible by both 3 and 5 we print FizzBuzz. If it's divisible by 3 we print Fizz, if it's divisible by 5 we print Buzz, else we just print x. And we have our end if and our end for. Okay, not too bad huh? Now there's lots of ways of, you know, if you want to minimize the logic done here but that's not really what I'm trying to look for right here. I just want to see if you can actually use your for statements and your if statements and your variable substitution. And your variable substitution to make a quick little template. So if you got that, nicely done. Okay. Now what I'd like to do is update our shopping_list app to use all of these techniques we've just learned with templates. So first thing what we're going to do is going to get rid of this code that we've been playing around with. [SOUND] I get rid of this n equals n, we don't need that anymore. Then we're going to go to our shopping list and get rid of this stuff. We don't need this anymore. [SOUND] Okay. Let's go back to our browser and make sure things okay. When we reload this we see our basic shopping list. Type in food and it appears in the URL. We could type in different food, milk, and it updates that parameter in the URL. Now, let's go ahead and add in the functionality that we had before with the hidden input elements and actually showing the list of foods that we had added so far. Okay, now, first thing we do is we can get rid of all of this, well, most of this stuff. Let's uncomment it for now. Okay, so we don't need any of this HTML junk anymore. This stuff is nasty, so let's get rid of all that, and we don't need any of this stuff. And, this line, can just go there. Okay, so, we're just going to get our food, get all get perimeters food out of the URL, store them in items and we're going to pass items into our template. Now the variable names don't always have to match when you're passing things into the template but, I find very often they do. Generally makes your life a little easier because then, when you're thinking about, you know, you're often working in your template and in your handler. It's handy to just call things the same thing, so, you known, you don't have to do that translation in your head. Now we had all of this HTML up here, we're not going to use this anymore so let's just g a head and get rid of it. Now let's go ahead and update our shopping list template. Okay, so the first thing we want to do is add in hidden input elements. So, if items four item and items. Lets add our hidden input. Input type equals hidden. Name equals food. Value equals, item. Notice, we can substitute our variable right in the middle of this HTML here. Because in the template the HTML is not special. It's just, it's just a string. And we can substitute anywhere into the string that we want. Let's close up our loop. Okay. Let's make sure this part worked first. Recall if this part works, we should see things appearing in the URL. So it's always good to test as you go in case you make a mistake you don't, you don't, have that mistake for too long. Okay, milk, and now if I add eggs, I see eggs and milk in the URL. Let's add some more food. You can see things are starting to accumulate in the URL, which means if we look at the source that our, template is actually working and we're adding all these hidden inputs. Notice the white space is all messed up. It's not a big deal. It's basically because our template includes white space. And it's getting put in here literally. But HTML doesn't care about extra white space. All is well here so far. Back to our template. Let's add that shopping list to the bottom. So again, only if we have items, if items. We're going to say we're going to add a couple of blank lines. This not the best way to add blank lines but it works for us. Okay. We do our shopping list and it is going to be an, let's say, an unordered list. Now, for each item and items list that item. We'll go to unordered list. And our if statement, and let's indent everything, and let's, let's fix our indenting. Okay. And lets see if this works. Close the source, reload this page, and we load this page. And there, behold, is our shopping list. Let's add some more items. Cheese, it appears on our list, it appears on our URL and if we view the source of this page, we can see our hidden inputs here. And we can see our shopping list down here. And if I were to modify this URL we can see that everything disappears. Likewise, if we delete it here, [SOUND] everything goes away. Okay, very cool. Now, looking at our code this is much simpler. We have our, our parent class, that just has our simple rendering functions and then our main page handler, has actually gotten a lot shorter. All it does, is it gets the items out of the URL, and passes that into the shopping list template. Which, now has the structure of the HTML that we're actually generating, and this is a lot easier to think about than that madness we had before with string substitution and string concatenation, and all of that. That was very difficult to read. And everything here, works you know, much more smoothly. Now there is one little problem that I'd like to show you. Let's add some food here. Now we can just auto complete our food, because our shopping list is learning our tastes. What happens if I really want some pizza and I put our pizza in an H1. Okay, nothing. The HTML is not interpreted and the food is just added directly to our list. Or the raw HTML, in this case, the H1 is displayed. Or HTML actually rendered, in which case our food appears very big in our list, in this particular case. Why don't you go ahead and try yourself and see what happens. Okay, the answer, of course, is HTML is rendered by the browser. Let's go ahead and see that in practice. When I click add here, pizza gets added very largely to our shopping list, of course this is probably not what we intended, and we can even put better HTML in here. Potatoes, the marquee tag is always fun for this sort of thing. And as you can see, we have now totally screwed up our shopping list. Now we discussed this in the previous lesson. This is because we did not escape our HTML when we displayed it allowing the user to enter raw HTML into the page. Now, let's see what, how this happened in practice. When we actually rendered our list, we're just sticking the raw HTML directly into the page, allowing the user to put arbitrary HTML into our page. And in this particular case, it's somewhat amusing. But if they had inserted javascript into our page, which, to be fair, modern browsers don't allow you do it anymore. They could actually do some really nasty things, like, steal my authentication cookies and send it back home. Which is a common way of breaking into websites that I may or may not done a lot of in my youth. Let's talk about how we fix that issue. Ginger makes it easy to do this. There are two ways, I'll show you the way that's simplest first. They've got the syntax for adding a pipe and then a filter. There are a couple, there are lots of built in features in the Ginger. One of them is called escape. So if you say when you print your item, if you say pipe escape, it'll actually get escaped. Let's see what this looks like in our browser. Now when I reload this page, the junk is actually getting escaped. And if I look at the source code for this page, we can see down here that Ginger ran it through an HTML escaping function and replaced the less than symbol with ampersand less than, and the greater than symbol with ampersand greater than. Just like we did in the previous lesson. And again, you can see that down here with the h1. But that's not how I prefer to do things in any templating language. Because it's a little error prone. If you forget to put this in, you've got a security hole. There is another way around this, however. If you go, when you initialize Ginger, if you say this, auto escape equals true, Ginger will automatically escape all variable substitutions. So let's make sure this is still working in our browser. I reload this page, trust me I reloaded it, nothing changed. If we check our source code, again nothing changed. We can see it's all skipped properly here. The reason I like to do this, is that prevents you from accidentally making a mistake. It's a lot easier to see that oh, I need to deal with this input when it's here, than it is to see a subtle error or you know, not be able to see it at all when a user is trying to hack your website. So I always, in every templating language that I use, look for the equivalent of auto escape equals two. And so far every one I have used has something along this line. Now what if you actually want to display the HTML? Well, there is a filter for just that. And you can say safe, pipe safe. And so if you know the HTML is safe, you can undo it this way, and I feel like this is the best way, you to opt in to the unsafe way rather than opting in to the safe way. So if I save this and we go back to our browser and I reload this page, we can see that it is rendering unsafely again. But at least this time we did it on purpose, we knew what to expect. And you do this if you want to you know, sanitize the out put a little bit. For example if your building a comment page and you want the uses to have some amount of formatting but not everything. You can only allow certain things and then print it using this filter. But anyways, let's get that out of here because we don't, we don't trust our shopping cart users. Okay just a couple of helpful tips, to reiterate the one I just gave you before is, always automatically escape variables when possible. Not every template language will allow you to do so, but always give it a look. Jinja certainly allows you do to so. So in this class you should definitely do that. Next is, minimize the code that you include in templates. What I've showed you so far is statements and foreloops. That's about it. Jinja will allow you to put almost, like arbitrary Python into your templates. But, you remember the whole reason we're using templates in the first place is, so we don't have to have HTML in our code, likewise we don't have code in our HTML. Because it makes it very difficult to, to modify, to edit, to debug, all those things. It's a total pain. So, and of course, the inverse of this is minimize your HTML in code. I generally, I have a rule generally, where we have zero HTML in our code. Even if it's a little one-line thing, we put it in a template. That way all your HTML is in one place, all your code is in one place, and you don't, your not using the wrong tool for the job. Which inevitably will bite you down the road as your projects get more complex. Those are just some things you know, these aren't hard and fast rules but these are things that I've found that have served me well over the years. There's one last thing I would like to teach you today, and it's called Template Inheritance. Now, we can make this quite complex, but for our purposes we're just going to do this simple thing that'll make our templates much easier to use. If you notice on a web page, let's draw one. Most web pages have a title and a footer. And then they have some content in the middle. This might be the page slash. And then you might have another page that looks identical. Maybe this is the /about page. It also has a title. It also has a footer. The same title and the same footer, and has some different content. When you generate in HTML, you don't want to have to write the same title and the same footer over and over again. Just like in your code when you use functions and classes to better organize your code, so you don't have to write the same piece of code over and over again. You can organize your templates in the same way. And that's what I want to talk about right now. You can use template inheritance. So you can have one template that includes the header, and the footer and then you can have a bunch of subtemplates that redefine the content in the middle. So here's how we're going to organize our code now. So here's what we have right now in our code. We have shopping_list.html, and we have fizzbuzz.html, and these files don't have anything in common, but we want to add a little title to this page. We're going to make each of these inherit from the base.html. And we're going to make each of these inherit from base.html, and base.html's going to have some common html that these two templates will share to make them match a little better. And I'll just go ahead and show you an example of how to do this. So first thing I'm going to do is I'm going to make a new filed called base.html. I'm going to go ahead and put in things I want these files to have in common, and I'm also going to do a proper HTML document this time. I saved it as base.html. Now remember, HTML documents start with a doc type and then we have the html tag. And then we have the head. And within the head, we can have the title. And so, both our pages will share this title. Within html, we have body. And now, I'm going to add a new syntax here. Okay so then we have our body, open and close, and then we close our html. This is basic structure of an HTML document. And it's what goes inside body that makes the page unique. And I wanted to change that title too, while we're at it, but let's just worry about the body. In jinja, the syntax that we can use will look something like this. The syntax for creating a block, and a block is something that will be shared amongst templates, you just say, { % block, and then you give the block a name. In this case, we're going to call it content, and then you can say endblock. And we can make each of our templates use this block of content. So, let's show how we would use this base.html in shopping_list. Let's add some code to our body that all of our templates are going to have in common. I'm going to add a little header across the top. Okay so if it's add a little title that we're going to put across the top of our page, it's just an h1, and I gave it a little extra styling. This is CSS. We gave it a background color of ddd, and a foreground color of 888. This is kind of gray with a slightly darker gray on top of it. I got rid of it's margin and I gave it a height of 50px. Also I'm going to add a little style to the body. This will make it layout a little bit nicer, margin: 0. Okay, so let's go ahead and use this template in our shopping_list. The syntax for this is quite simple. All we do is at the top of our file we say extends "base.html". This tells this template that we're going to be a part of base.html. Now let's see what this does in practice. Let me make sure everything is saved. Nothing here has changed and our main handler, we're still rendering shopping_list.html. Let's go to our front page. Okay, it's still quite a mess here, let's reload this. Once I reload it, we can see that the header that I wrote is here with the kind of grey on grey background. But none of our content is here. Let's look at the source for this. Okay, we basically see this is our base.html file, but we're not seeing any of that content because that was in that block content, and we didn't overwrite that. Let's go ahead and take a look at our templates again. This is our base.html. This is basically what we were seeing as the source in our browser. But our shopping_list.html hasn't actually filled in this content yet. Let's see how we do that. All you do is here, you say block content. And this line here, block and then the name content, matches this line here in base.html. And I've put a closing one at the bottom, endblock. We save this file and we go back to our browser. Then when I reload this page, we see all of our stuff done here now, within our base.html template. And when we view the source, we can see we have the base.html header. Then we can see we have our form contents, here in the middle. And then we can have down here, it's hard to see because of the scrolling, but the end of the base.html template. So, that's pretty handy. This allows us to separate the content of our pages and the templates for that content from the surrounding content that all of our other pages might have in common. And I use this a lot in this course, especially during the blog and some of the other things. Okay. And, what I'd like you to do know, I'd like you to update your fizzbuzz.html template, make it inherit from base.html, and fill in the content block. And when you're done you should get a result that looks like this. When I go to /fizzbuzz now, we have my common header, and then we have the content of fizzbuzz. So go ahead and paste the result in here. Okay, did you get that working? If so, good job. Let's go ahead and test everything. I'll show you my solution. Here we are, fizzbuzz.html. All we had to do is extend base.html, surround our content with the block content and end block, and all is well. And so it's basically the same thing that we did here in our shopping list html. And our base html doesn't change at all, neither do our handlers, still rendering fizzbuzz.html and shopping_list.html. And the benefit of this is, if I change my base template to be more exciting and then I go to the browser. And I reload this page, we get our exclamation marks, and if I go, get away from fizzbuzz, we also have our exclamation marks there as well. So, we changed one file and then our entire website changed along with it. Okay and that's all I want to show you about in, inheritance, and in fact that is all I am going to show you about templates. So just remember that templates are, a great way to separate different types of code. You can keep your HTML separate from your python for the purposes of this class, which will make your life a little bit easier I hope. At least your code a little more clean hm. Make more readable code, better organized code is more readable. Make more secure websites. You know, if you use the autoscaping feature of Jinja or other template new languages you dont have to worry so much about putting, you know, insecure malicious data into your website. And finally, you know, you have HTML that's much easier to modify. Instead of trying to manipulate strings in python you have HTML in your HTML editor. It's much easier to manipulate. So if you want to learn more about Jinja you can go to this URL, to learn more. And the slots of documentation here and there's all sorts of nice little escapes and filters and convenience things that can make the templates more and more powerful. So thanks for listening so far and I hope this helps you in the future. Welcome to lesson three. This'll be databases. Databases are how you actually store all those information that we've been collecting from users. This is basically the final piece that'll allow us to build fully functional web applications, and your homework for this lesson ought to be actually build the first version of your blog. So. Databases are actually quite complex. We can spend a lot of time talking about them. You can actually get a Ph.D in databases if you want. But, in this lesson, we have about an hour, so we're going to divide it into two parts. The first part of this lesson will talk about SQL and kind of basic database technologies, a lot of things you'll probably encounter outside of this course. And then, in the second part of this lesson, we will talk about Google App Engine's data store which abstracts away a lot of the headaches of installing a database and getting it setup. It's actually the reason we decided to use App Engine for this course, it was the ease of getting started with databases, so let's dive right in. Okay, so let's jump right in. Databases. The first question we want to answer is what is a database? There's a number of ways of answering this question, but probably the simplest definition is a program that stores and retrieves data, particularly large amounts of data, or even more particular, large amounts of structured data, and we'll talk about what that means in a sec. Let's go to the picture we've been working on quite a bit in this class. We've got our user and his computer and the internet and our servers. Now, up until now, we've been referring to these servers as basically these are web servers running our web applications. But in many cases, these servers are actually database servers as well, and so we might have a special server just for databases. A database can refer to a program that's storing and retrieving the data, or it can refer to the machine running this program, or it can refer to a system of machines running this program operating together. And just like a web server it may refer to just a program with a web server or the physical machine or the group of machines all working together to host your web application. A request may come in from a user via the internet through our servers, and then we may need to retrieve some data for that user. Let's say this is Reddit, and we need to draw the front page, so we need to get the list of links that we're going to draw, and we get that from the database, and then database responds with the data to the web application, which may manipulate the data and somehow get it ready for display and then send it back to the user. But anytime you're storing large amounts of data, you're probably going to be using a database, and that is what we're going to spend most of our time in this lecture talking about. Okay, so a quick quiz. What does a database refer to? Is it a program that stores and retrieves data? Is it the machine running that program? Or is it a group of machines working together to store and retrieve data? Check all that apply. And of course, the correct answer is all of these. A database can refer to the whole system or just the program itself, and all of these work kind of interchangeably. It should be obvious from the context what I'm referring to. Now, every problem is a little different, and all of the database products are a little different, so most of what I'm going to cover in this lesson applies in the general case, but not always. But one of the things that does apply in almost every general case is this notion of tables, so let's say we're building a site like Reddit that's going to take links from users, and we will store them in a database and allow users to vote on those links, and then we'll show what's the most popular. We'll probably have a table for links, and this link is made up of a number of things. It's got an ID. It's probably got a number of votes. It's got the user that submitted the link. It's got a date of when the link was submitted, and it probably has a title. This is what we'd display on the site, and a URL. These are all called columns of the database. Columns are basically the properties that make up a particular type, so in this case, our type is a link. That's what we're going to call our table, and these are columns. Now, every entry of a link in this table is called a row, so we might have a link that looks something like this. Here would be an example ID, 5. It's just an integer. The number of votes that this link has. The user that submitted it. This is an interesting column. We'll come back to this. The date of when the link was submitted and a title and a URL. Let's talk about each of these columns. Now, this thing in its entirety is called a row, and a row is one instance of an element in this table, so we'll have many, many rows for all of the links that are submitted. And my label isn't very good here, but these are the columns. Columns go down, rows go across. Let's talk about each of these columns. The ID column is important in almost all tables. Generally every row will have an ID, and this is how you refer to that row specifically. This is link #5. It's not required in most databases that you have something called an ID, but it's really helpful, and in some databases, it is, in fact, required. Usually it's an integer. It could be a string. The database on Google App Engine allows you to use integers or strings. This column here, votes, this column is also an integer. This refers to the number of votes on this link. This column here, user, is also an integer, so this is a reference to the ID of the user who submitted the link, so we may have another table called Users or User that may have its own set of columns, one of which is an ID. It may also have name and date and maybe password. There could be another table called User that stores all of our users, and this column is just a reference to this other table, and we'll come back more to these types of relationships later, but just know that this is a common way of doing things. Okay, so then we'll have our date column for the link, and this probably has a type of date. Not all databases support the date type, but the ones we'll be using in this class do, and it's really handy to store this stuff. And this is ultimately probably an integer, but depending on the sophistication of the database, they may have a real date type. And of course, we'll have the title, which is a string. This may also in some databases be known as text or varchar or there's lots of ways of referring to it, but it's basically just referring to this type, but it's just a string. And URL is the same thing. It's also a string. Our table is made up of--defined of columns, and it's filled up with rows. Every time a user submits something, we add a new row. If another submission comes in--we may have 0 votes and submitted by user 27-- this table can have a lot of data in it. Before we go into specific database stuff, let's work through some examples in Python of how we might manipulate this kind of structured data programming. Okay, so here we are in the IDE. I've made a simple class called Link that just has a few properties, ID, submitter ID--this was the user-- submitted time--this was the date we were referring to before-- votes, title, and URL. And then I've got a Python list of these link objects, just a bunch of them. And the first thing I'd like you to do is before we learn how to use databases, implement this function query for me. And what I'd like query function to do is return the number of votes that the link whose ID is 15 has. So, all of these links have an ID parameter, an ID attribute that you can look at, and I want you to return the number of votes for that particular link. You need to find it out of this list and then return the number of votes. Good job if you got that. Here is my implementation. We just iterate over the list of links for l in links, and if ID = 15, I return the number of votes. Not too complicated. Now, what if I were to ask something a little bit more complicated? What if I were to ask this question instead? Make the function query return a list of links submitted by user 62443, and sort those links by the submission time ascending. The earliest submission first, and the last submission last. Here is my submission. What we had to do is I built up a list called submissions. That's going to hold the links that are submitted by this author. The first thing I do is I iterate over the list links for l in links, and if the submitter ID matches our constraint, 62443, I add it to our list of submissions here, and then I said sorted by time ascending, so then I need to call sort on this list here, and if you haven't used the sort function, it's pretty handy. You can just call sort, and that will sort by whatever the Python default would be, so if it's integers, it sorts by integers, but these aren't integers. These are entire link objects, so Python would probably sort it lexicographically based on how it prints out, I think, so we want to sort it on submitted time, so that's what the key parameter is for. And then I return the submissions, and so if I run my query, you can see the output down here, and you can see we have 3 links. It's not the easiest thing to read. Here is link #1, and the submission time is 133390, and we can see our next link is here, and we can see the submission time is 133393, so bigger, good. And finally down here we can see our last link and its submission time is 1334. Okay, so they're sorted by submission time, and we see they all have submitter ID 62443 here and here. Okay, so that was not too hard, but it was still a little tedious, and this is the type of thing these types of problems a database can help with. Okay, so we just ran some queries on our list of 25 links by hand, and that was a little tedious, so what are some of the downsides of querying data by hand? Now, I know we only had 25 links there, but one problem is it's very error-prone. You have to write code for every query you want to answer, and if you don't get the sort order right or something like that, you have trouble. It's tedious. I could ask you a lot of questions about-- get these links sorted by this and that and links submitted by this user and that user, and writing a function for each of those can be a bit tedious, and one of the most important reasons is it's slow. Now, you didn't see that yet because we only had 25 links, and iterating over all of those links sequentially wasn't a problem. There's only 25 links. But if there were a million links or a billion links, you wouldn't want to do that, or you wouldn't even be able to do that. I wouldn't have even been able to build that kind of fake database in memory like I did there, so databases basically exist to take big chunks of data, like our collection of links, which could be in the millions, and answer queries on them in a reasonable amount of time without having to write a lot of custom code, which is always an option. There are lots of different types of databases, and we're going to focus on kind of the major ones. We've got one type of databases that are called relational databases that often use a language called SQL to manipulate them, and so we'll refer to these as relational databases or SQL databases. Some examples of relational databases are postgreSQL, which we use that in Reddit. We currently use that in Hipmunk, and lots of people use this. It happens to be my favorite. There's MySQL, which is extremely popular, and this is used by Facebook and basically everybody. Not strictly everybody, but MySQL is far and away the most popular database, and I'm sure you will encounter it in your web development adventures. Also pretty common is SQLite, which you'll actually use in this class. This is a really lightweight, simple database. It's not for working on huge amounts of data, like postgreSQL and MySQL might be. It's generally better as a replacement for where you would normally use flat files but really handy, and of course, there's also Oracle, which is a huge company that sells the Oracle database product. And incidentally, Oracle bought MySQL a number of years ago but has largely left it free and open. These are all free. And these databases all basically work with tables. They use a language called SQL to manipulate those tables, and we're going to talk about that in this class a fair amount, and in our general purpose, handy things. There are other databases in the world. Some examples might be Google App Engine's Datastore, which is what we're going to be using a lot in this class, and it's got a lot of similarities with these relational databases, but also a lot of differences, and we'll spend a fair amount of time talking about these differences. Dynamo, which is by Amazon, and the reason I mention this is because there is a great paper online that describes how this database works, and I'll include it in the course notes. It's worth a read. It's a really nice approach, and they take a completely different approach from these SQL databases, and there's a lot to learn there. There's the NoSQL databases. Of these, maybe Mongo is pretty popular. Couch is pretty popular. We're not going to discuss these much in this class, but these are products that try to solve some of the limitations that SQL places on you that we'll get to in a moment. But in this class, we're going to focus on kind of the basics of SQL and then Google App Engine's Datastore and how to use those to build your web apps. Okay, quick quiz. Which database is the best? And the correct answer, if you remember this from the browser question, is none of them. Databases are very similar to browsers in that there are many of them, and they all behave a little bit differently, and they all have their place for solving different types of problems. It's not uncommon for large websites to actually use multiple websites. We'll be using the Google App Engine Datastore for most of our stuff, but using Google App Engine doesn't limit you to this. I think they also even provide some sort of MySQL interface, if that's what you prefer to use. The answer is there is no best database. There is certainly the most popular database, which is probably MySQL, of this list, but there's definitely no best. Let's talk a little bit about SQL, or "sequel," or structured query language. SQL is a language. It's not quite a programming language, but it's a language for expressing queries, and so you would use SQL on a relational database to ask questions of the database to get that out of it, so MySQL, postgreSQL, SQLite. Obviously they all have SQL in the name, and they all use SQL for putting data into the database and getting data out. It was invented in the 1970s, which was long before the internet existed or the Web existed or web applications even existed, so SQL was designed to solve problems that are very much different from the problems you'll be solving building a consumer web application. There's still a lot of very important parts to SQL, and we'll be discussing the major pieces today so you can know how to use them, but just keep in mind that SQL and relational databases have existed long before the Web, and so there are some things that aren't exactly relevant. SQL looks a little something like this. This is a basic SQL query, and what this says is select, which basically means retrieve data, *, this means all columns, from links, this is the table that we're fetching data from, where, ID = 5, and this is a constraint. SQL, as you can see, it's a fairly readable language. Select all from links where ID = 5. That's almost similar to the quiz I gave you earlier in this lesson. There are a couple parts of this line that are relevant. This first section, the select *, this is basically what we're selecting. The can--instead of being a--can actually be a list of columns, but for a lot of things we're going to be doing, we'll be selecting all of the columns. But if you don't want all of the columns, let's say you just wanted just the URL from the links, it might look something like this: select url, and you could put a comma, select url, title if you wanted to select just the URL and the title. But we'll be using * for now. Now from, this is the from clause right here. This is where we're going to fetch the data from, so we've only talked about really one table, our links table, and in my example, that's what I'm going to use. But you can actually include any table of your making or multiple tables, and we'll talk briefly about what that means a little bit later, but for now, we're just going to be selecting from the links table, and that's the name of the table we made. Where, now the rest of the SQL, or the rest of the SQL you can see here, this is the where clause, and these are the constraints. These are which rows from our table to return, and this is actually a really interesting part of the statement here. We can actually put quite a lot in here. Let's play around with this a little bit in the IDE and see how it works. Okay, so here we are in the IDE. This is going to be basically the same file we had before, the link class and all of the links that we make. I'm importing a new module that's built into Python called SQLite3, and this allows us to use SQLite in Python, which is pretty cool. I've got some code here which creates an in-memory SQLite database. You can see some SQL here that we haven't discussed for creating the links table and then inserting all of the links into that table. This code isn't super important to you right now, but if you're curious, I just basically made a SQL table with all of that link data, and I've given you some instructions here. And let's play around with this a little bit. The important thing is that we've got this db variable, this global variable. That's going to represent our SQLite database right here. And let me show you how to run some SQL. I can say c = db.execute, and I can give some SQL. In this case, I'll say select * from links. And this doesn't have a where clause like we talked about before. Where clauses aren't required. They're only required if you don't want to fetch everything. This little bit of SQL here, select * from links, just selects all of the columns from the links table. And what this creates is what's called a cursor, and a cursor is just a position in the database. We can call this function fetchall on c, on the cursor, to actually load all of the data out of the database into this list of results, and in this particular case, I'll just return the results. We'll go ahead and give this a run. That's a lot of data. We executed our SQL, and we saw some results. Let's change this up a little bit. Let's change this from a to title. We'll just look at the titles from the links, and let's go ahead and run this. Now I see a list of all of our titles. That's kind of cool. Let me show you some other things we can do before we have quiz time. Let's change this back to *. One of the things we can do is we can iterate over a cursor. I can say for t in c. Okay, so I want to make these variables a little bit more clear, so for cursor, for link_tuple. Tuple is a reserved word. If we iterate over our cursor, we get the results one by one from the database, and we get them back as a tuple, not as our link objects, so what we actually want to do is make the link objects, so we can do that by saying this: link equals--little link, our little instance-- equals capital link(*link_tuple). And this is a Python syntax for passing in all of the parameters in this tuple as arguments to this function. In this case, it's not really a function. It's the constructor link to make the object. But now we have a link object, and here let's say print link.votes. Let's go ahead and run this. What this should be doing is running the SQL, select * from links, iterating over all of the results that are returned to us as a tuple, converting those tuples into a link object, and then printing .votes. We can see it printed all of the votes for our links. Pretty neat. Let me just show you one last thing, because I'll explain what's going on here. I think this might be new to some of you. If I were just to print the link tuple like this, and we'll just print exactly what we get back from the cursor, I'll show you what that does. This prints each row of the database as a Python tuple, so you can see one row here, and the columns are in order that I define them, and I conveniently define them in the same order that the constructor expects them. You've got the ID of the link. You've got the user ID, the time it was submitted. This is in epoch time, second since 1970. This would be the number of votes, and then the title here, and the URL for each of these links. And if you put a * in front of a tuple like this and pass it into an object's constructor or in any function, the arguments get put in place like that, so that's all that was happening there. And I'll show you real quick how we created this table. This is SQL, and you can see I create table links, and I've defined the columns here, id, submitterid, submittedtime, votes, title, url, and you can see I included the types, so anyway, that's not super important, but it's there. All right, time for a quiz. What I'd like you to do is make this query function return the number of votes that the link with ID 2 has. Now, I've written some of the function for you, and all you need to do is put in this SQL here to find that link. What these other lines do is they take the cursor return from db.execute here, and it runs this function called fetchone on it, which basically returns the first result. And then we use the * syntax to pass that into the link constructor, which makes our link object, and then we return link.votes. All you have to do in this quiz is figure out the SQL. Good luck. Okay, and here is the answer. Select * from links where ID = 2, and we'll convert that into a link object, and we'll return link.votes. And let's go ahead and give this a run. 81, and that is our correct answer. Nice job. Let's move on and learn some more complicated SQL. We just use some basic SQL to pull out one link. It had a where clause that looked something like this. Let's talk about how we can make this a little bit fancier. Instead of just saying ID = 2, let's change this constraint a little bit. I've changed the clause to be instead of ID = something to submitter ID = 5. Okay, so I've added an and clause. Select * from links where submitter ID = 5 and votes > 23. And this is a perfectly legit SQL query, and it will also be even more expressive. We could change this a little bit even more. We could change this and to an or, for example, and this would return us all of the links that were submitted by user 5 or all of the links who have more than 23 votes, and so you can see SQL is fairly expressive, and you can use and and or, and you can use equals and greater than or equal to and less than and all sorts of cool stuff. And already you can see we can ask fairly sophisticated questions of our database. What I'd like you to do for this quiz is make the query function return the ID of the link that was submitted by user 62443 and has greater than 1000 votes. This time I didn't leave you any code to work with, but you can still scroll up in the file and see the example here. Okay, here's my answer. It centers around this SQL statement. Select * from links where submitter_id = 62443 and votes > 1000. Those are the constraints of the question. I make a link just as we've done previously. I use the fetchone function, and then I return that first link's ID. Let's give this a run, and we see that the answer is 15, which is the correct answer. Now, if you didn't remember that submitter_id is the is the column name for the user's ID, you could have found it in a couple of places. One, you could have looked at the SQL here for creating the table, and you can see it's called submitter_id. Or you could have gone up here to the definition of the link class and guessed that I would have used the same property. But that's the answer. Okay, let's get a little fancier with our SQL here. Okay, so more SQL. Let's start with the basic statement we've been using so far-- Select * From Links. Let's add a Where clause where votes are > 10. That gives us only the links that have a few votes. And let's add a new type of clause. This is the Order By clause, and this says to sort the results. I've got Select * From Links--we're familiar with that-- where Votes is > 10--and we're familiar with that. Additionally, all of those rows that you're returning to us, order them by the number of votes. And by default, the votes are in ascending order, but if you can't remember that, it's perfectly fine to specify. You can say ASC for ascending or DESC for descending. I usually specify because I can never remember which is default. Pretty simple statement. One other thing to note is that the Where clause is not required. It's never required. So I could change this to look like this. Just Select * From Links, Order by Votes Descending. That would give me all of the links sorted descending by votes with no constraints whatsoever. Okay, here's a quiz. We're in the same file, and we're still manipulating our query function. And what I'd like you to do this time is make the function query, return the IDs of the links that were submitted by user 62443, and sort them by submission time ascending. And remember that a submission time is the column called Submitted_Time. Okay, good luck. Okay, so here's my answer. The SQL is Select * From Links, where submitter ID equals 62443, order by submitted time ASC, for ascending. And these are the constraints of the question--62443 and submission time. And then what I'm doing is I'm iterating over the results, making a link, appending the link's ID to the list of results, and then I'm returning results. Okay, so let's go ahead and give this a run to make sure it works. We see our answer is 15, 18, 21. Those are the correct link IDs. My answer looks the way it does because I've been following the form we've been kind of working in-- the general structure of this function. But if I were actually to make a function that does just this-- just returns the IDs of the links-- there's a couple things that are wasteful in here that I'll go ahead and clean up and show you. So the first thing is we don't need to select * from links. All we care about is the IDs. So we'll just select the IDs. Here we're creating a link object for every row we get back. Well, we don't actually need the link object. If we're just going to get the IDs from the results, we can just return those nearly directly. So let's get rid of this loop and instead change it to something like this. Okay, so I simplified this quite a bit. This syntax here is a list comprehension. It's a simple way of making a list. So we still run our SQL. This time we're selecting ID. And since SQLite Library in Python returns tuples of the results, and in this case we're only asking for the ID, we know the first column is going to be the ID. So for t in c--so for the tuple in the cursor-- make a list of the first element of each of those tuples, store that in results, and return it. Let's go ahead and print this. And the answer is the same--15, 18, 101. Okay, so just a little extra Python there for you. Let's move along. Let's move on to a new topic that we're promptly going to forget. This is called Joins. So this is a type of SQL query that you can use that involves multiple tables. Remember we have our Link table. We've been working with that this entire lecture. It looks something like this. It's got the columns--ID and Votes and the User ID Submitted, Data, Title, URL. So let's make up some values for these. Now, what I want to talk about right now is this User ID column. Remember I mentioned before that if we had another table called Users that looks something like this-- it's got a column for ID and a column for Name and Password and Date-- the User ID in the Links table refers to the ID column of the User table. This should always match up, because you want everything in your system to be consistent. So for every unique User ID in the Links table, there should be a valid user in the User table. Now, one of the things we can do in most SQL databases is something called a Join, which is a SQL statement that involves two tables. So we have a basic SQL statement that looks something like this. So select from the Link table, where user ID equals 22. So that would return all of the links submitted by this user, assuming there's more than one. What if we didn't know the user's ID? What if instead we wanted to select from the link table all of the links submitted by users with the name Spez? Well, there's a couple of ways you could do that. You could first do a lookup for what is the user ID of the person named Spez, grab this user ID, then run the SQL query. So you could do two queries. It might look something like this. So I could run one query to get the ID from the user table for the user whose name equals Spez, and then we can use that ID in a second query. But there's another way of doing this query. I could, instead of running two queries, combine this into one query. So instead of From Link, we can change this to Link, User-- which will scan both tables. And we don't want to get all of the attributes. We want to preserve the same results from the query, so we don't want to select * from link, user-- we want to select link.*, which will return just the columns from the link table. Then we want to change our Where clause to link these two tables. So where user_id=user.id. I could have also said link.user_id so we include the table names in all of our properties. That will make things more clear. I need to add another clause to this. And user.name = Spez. So what does this do? Select all of the columns from link--link.*-- from the link table and the user table, where user.name=Spez and link.userid=user.id. And what this does is what's called a Join Query. And your SQL engine will decide which of these tables to scan first, and in this case, it will probably do the user table first. So it will find the username Spez, and then it will find all the links whose user_id property matches the ID field in the User table. So this is a handy thing. Now, the reason I said we were going to learn something we were promptly going to forget is because we don't use joins very often when writing web software. It's something you'll see in almost every SQL tutorial, but for reasons we'll explain later in this lecture, joins don't work very well for the types of problems we're going to be solving writing web stuff. But you should be familiar with them; you should know what they are. You may be writing something that requires this, but they're often--well, as I said, we'll get into this later in the lecture--why we don't want to use joins. Let's move on to something new. So far, we've been doing--in our Phyton IDE-- we've been doing what are called sequential scans. And a sequential scan is where you have a list of something. In our case, links. We have this list of links that have these IDs--link 1, link 2, link 3. And we've been doing things like find the link with the ID of 2, so in which case we write a loop to go over the list and find the one who has ID 2. Or you just eyeball it by hand and answer your quiz just by writing in the answer by hand, which is actually totally fine because you went through the same process. You had to look through this whole list of links by hand. Now, that works fine if you have 25 links, but if you have a million links or a billion links, iterating over that entire list is going to take some time, and we want to make our websites fast, or at least reasonably responsive. So that's going to be troublesome. So I'd like to introduce you to a new concept called Indexes. And index is just like an index in a book. They make lookups faster. One index you're probably familiar with already is the hashtable. So in Python you can have a dictionary that looks something like this-- that is a mapping--a key--to a value. Let's assign this to a variable. We'll call this just index. Now, you can do very fast lookups in your code by writing something that looks like this, which we'll refer to the index key 2 of this hash table. And when you do a hashtable lookup-- you learned this in CS 101-- we hash this value, we find it in the hashtable, and then we return the key-- or we return the value. We don't have to scan over every element in the list and see if it matches our constraint. We can jump immediately to that element. And that makes queries run much faster. Okay, so let's play around with this in the IDE a little bit and see what we can do. Here we are in the file we've been working in this entire lecture. This has our class link. That just has the basic properties, and then 25 instances of that class that we've been scanning and searching over. What I'd like you to do--this doesn't involve any SQL-- is implement this function link by ID. That takes a link ID and will return the link object itself. So for example, if I gave it 24, it would return this entire link object. Use the global variable links to find this. Okay, good luck. Here's my answer. We've actually done this before, basically. For L in links, if l.id=link id, return l. Let's give this a test real quick. So print link by id (24). We give this a run. And we see our link has returned. And if I give it a link ID that doesn't exist-- let's try 50--and run this-- we get none, which is what we expected--nothing. Okay, let's make this a little bit more complicated. Okay, the next thing I'd like you to do is implement this function called build link index. What this is going to do is it's going to iterate over the list of links we have, and it's going to return a dictionary that maps a links ID as an integer to the link itself. So just return that dictionary. All right, good luck. Here's my answer--build link index. I created a dictionary--an empty dictionary--called index, and then I iterate over the list of links for l and links. And then I update the index l.id=l, and then I return that index. So let's give this a quick run to make sure it works. Okay, I'm going to just call this function and print the result. That looks about right. At least the first one looks good. It maps 0 to the link with ID 0. Okay, good enough for me. All right, let's move on. So we've got this function, build link index, that makes our index. We just wrote this together. Let's use this new index function. So the first thing I want to do is actually run the function and store that somewhere. So we'll store that in a variable called link index=build link index. Now, this isn't the best Python code. Normally we wouldn't use global variables like this, but this is fine for this example. One time, we're going to build this link index. And now I'd like to update our link by id function to use our new index. Okay, so I've improved this function to instead of iterating over the entire list of links, to just look up the link id in the index. And let's give this a test. Okay, so let's call this function link by id(24). We've done that a couple times. I click run. Ah, and we see our link--id=24. Now, what happens if we run this on a link that doesn't exist? Barf! Our program died because we tried to look up, in a Python hashtable, an ID that doesn't exist-- or a key that doesn't exist. So there's an easy way to fix that in Python. I'll show you how to do that. Instead of using these braces, we can use the function called get, which Python hashtables have. And what this does is it checks to see if this key is in the hashtable, and if it is, that's what this function returns; otherwise, it returns none. So let's give our function a test again by running this. Okay, now we return none. Very cool. That's what we expected. And let's just make sure that our function is still working the way it worked before by sending in a link that we know exists. In this case, I'll do 4. Here we go. So we see link id 4. So now we have this function link by id that uses our index. So if we had a bunch of links, all we'd have to do is build this index once, and then we don't have to scan over it every time we do a lookup--every time we do a query. Instead we can just hit the index. Okay, now there's one last function I'd like you to add. What I'd like you to do is implement this new function called add new link. It's going to take a link--it's going to take an instance of link--as a parameter, and then it needs to both add the link to our database-- which is this list object we've been working with links-- and it's also going add the links id to the list--the link index. Go ahead and implement this function now. Here's my solution to this quiz. We first add this link that was passed in as a parameter to our links list. And then we add it to our index by saying link.id=link into the global index here. And let's go ahead and give this function a test. The first thing we need to do is create a link, so I'll do that now. So we create a new link, and it's going to have id 50. And then we needed a user id, a submission time, and number of votes, which we'll just set to 1 for now. It needs a title and a URL. So that should make a link. And now let's actually call our function add new link L. And now, let's make sure it works. So the first thing I want to do is make sure we added it to the list link. So we're going to say print links negative 1, Which will print the last element in our list of links. And that's where this link should be because we appended it to that list. I'm also going to print link by id 50. So these should actually print the same thing and they should both be our new list--or our new link. Let's go ahead and give that a shot. Ta-da! All right, so we've updated our list, and we've updated our index--pretty cool. So as you can see, an index is really handy making reads simpler so you don't have to iterate over the entire list, but there's a certain maintenance cost to having them in that you have to keep it up to date when you're updating the rest of your database. And you can imagine if you had multiple indexes on your table, which you can, every time you insert a new element into your table, you need to update all of these indexes. Okay, great. Let's move on to another quiz. So this quiz--which of these statements are true? Indexes increase the speed of database reads. Indexes increase the speed of database inserts. And the correct answer is indexes increase the speed of database reads. Yes, that is true. That is what they are used for, at least. Sometimes you don't make the right index, but assuming you made the correct index, your index matches your query, yes, you will increase the speed of reads. At least you hope so. Indexes increase the speed of database inserts. No, that is false. They probably decrease the speed of database inserts. That is because when we're inserting a new round to our table, we probably also have to update all of our indexes, and that takes time. So there's a tradeoff. We can probably get faster reads at the expense of slower inserts. And probably slower writes in general, for just updating a row, but there's actually a few perverse cases where an index can actually increase the speed of an update. Let me give you a little real demo of how indexes can affect things in the real world. Okay, so time for a demo. I am currently logged into my development machine for Hipmunk. We use Postgres as our database, and I'm going to log into that database right now. Psql is the Postgres command. And we have a table for our hotels--for our hotel search product. So we can say select count *-- count is a SQL command for counting the rows in a table-- from hotels. So you can see we have 302,000 rows in this table. Okay, so let's run a quick SQL statement against this thing. We're going to say select name from hotels where id=51492. This is a hotel id that I happen to know exists. Okay, it's called the Hotel Karlsteiner Stuben. So one of the things we can do in Postgres is I'm going to run the same command again--the same SQL statement again-- with explain analyze. What this is going to do is this is going to run the query and then explain to me what it did. What this says is that it did a sequential scan on hotels--that's our table name, hotels-- sequential scan on hotels, filtering for id 51492, and it took 142 milliseconds to scan that table of 300,000 hotels and find the one with the correct id. Now, if I were to create an index on that field--on the id field-- things should get faster. So let's go ahead and create the index-- create index hotel id on hotels id. This is the SQL command for creating an index. I'm not going to quiz you on this, but this is what it looks like. Create index--this is the name of our index, hotel id on which table. So in this case, it's the hotels table. That's the table we're using. And then it takes in parentheses which field we're going to use. And in this case, we're going to give it the id. I submit that. Postgres creates our index. And now let's run this explain analyze command again. So now instead of doing a sequential scan, we did an index scan, using hotel id--that was the name of our index here-- on the table. And in this case, we can see the total run time went from 142 milliseconds to 0.163 milliseconds. That is a substantial improvement. And let's go ahead and drop that index-- drop index hotel-- and we'll rerun this command one more time to see it slow again. Ta-da! We went from 0.163 milliseconds to 141 milliseconds. So that's just a quick real-world demo of what an index can do. And it's pretty handy that the Postgres database will explain to us what exactly is going on. All right, let's move on. One last concept I'd like to discuss regarding indexes is for using them for sorting. So far we've been talking about using a hashtable to create an index, but one of the characteristics of a hashtable is that it's not sorted. A hashtable is just a mapping of keys to values, and if you remember how they're implemented, they're implemented as a big array with all these fields, and inside these fields are these keys that are basically the hashed version of sum value. If you add a new element into your hashtable, the new element can go into any one of these cells. It could be the case that this key was added last. It just happens that that key hashed to this position zero in the hashtable. So we lose our sorting information when we use a hashtable. And we saw some SQL queries before that used the order by statement. Obviously that requires some sort of sorting. So there's a different type of mapping we can use, and this is called a tree. Trees are a basic data structure that accomplish something similar to a hashtable, but they have the nice property that they are sorted. Why would you ever use a hashtable when you can use a tree instead? Well, the downside is that the lookups are slower. Hashtable's lookups are faster. So I don't think we've talked about these algorithms yet in 101, but basically a hash table has constant time lookup, which means that generally looking up any particular key in our hashtable is not a function of the number of keys in the hashtable. Their inserting can be a little hazardous. Remember those collisions. I think you talked about that in 101. But in general, the lookups are going to be constant time. And in a tree, the lookups are going to be roughly a function of log n, where n is the number of elements in a tree. So lookup speed decreases with the size of the tree. And depending on what you're going to use your index for, you may choose to use a hashtable or a tree. Many databases let you choose. Some actually don't, or some choose for you. Interesting property of indexes used by most relational databases is that they preserve sorting, and there's some cool things we can do with that. One is that if you wanted to find all of the links in your database sorted by votes, if you created an index on votes, that would be a very, very fast query. You would just go to the front of your tree-- your index on votes--and just read off the links. And I'd like to show you how we use that at Reddit to make the hot algorithm work. If you've used Reddit before, you know it's a big list of links and you can just vote on those links up and down. The front page is whatever is the most popular. They can be voted up or voted down. And good links stay at the top of the page for a long time, and mediocre links may make an appearance but disappear after a short while. So this is a really cool feature of Reddit, and it's actually not that hard to compute. What we do is we use a special index. I'll show you how that works. So we've got a table--a link table-- that looks something a lot like what we've been dealing with. It's got an id and it's got a number of up votes, a number of down votes and a date. And it also has this field called score. It's a floating-point field. And this is the total score of the link. So you may have 10 ups, 1 down, and the score might be actually 25. And the way the Reddit hot algorithm works is there's an index on the score field--it used to just be called the hot index-- and it was really just on the score field. One approach to generating this front page might be to take all the links submitted in the last 24 hours, do some fancy math, sort them by how many up votes and down votes-- the spread between these two votes is-- and sort it that way. But that doesn't really capture that hotness-- how things rise and fall. So every time--like for example--you add 1 up vote, we actually increment the score by some other amount. And this other amount is computed through this hot function, and that hot function looks something like this. It's a hot function, and it takes the number of ups, the number of downs-- so it can compute a total score, which is ups minus downs-- and the submission date of the link--this field. So what happens is, over time, the value of an up vote increases. So an up vote today might be worth 1 point, and that same up vote tomorrow, on the same link, will be worth 10 points. And what this causes is it causes our scores to, over time, be constantly increasing. So newer links always have higher scores than older links. So a link that's one day old with lots of votes has the same popularity as a link that's one minute old with just a few votes, and that's what keeps our front page churning. And it's really actually very simple, and it's a very fast query we can do. We can just say effectively something like this. Select * from links order by score descending. And then we get the hottest links on Reddit. And this is a very simple and fast query, because all it does is really just bounce off the hot index. And it's neat. You get this really cool effect for not a lot of cost. Now, to be fair, it took us a little while to figure this out, and we actually--the first person who read it, took the approach of taking all of the links from the last 24 hours and doing some math on them and sorting them in memory. But later one of our guys came up with this notion of a hot score, and we can just convert that into an index, then there we go. We've got a database that keeps our links always sorted in order of hotness whenever we need them. So I thought you might enjoy that. Let's move along. I want to talk for a moment about how to scale databases. Now, like databases themselves, this is a very broad topic, but there's a couple concepts I'd like to introduce because they're going to affect us in this class. There's two reasons you might need to scale a database. One is too much load, as in a database that's just doing too much work. You've got some website that is getting millions of requests a day--thousands of requests a second-- and you've got this one machine that's got your data on it and it just can't keep up with all the work. So what you might do in this case is take your database-- which are often represented as little cynlinders-- and replicate it to other databases. So every time we insert a piece of data to this database, we send it over to the other guys. So all of our database writes go into this one master database. In turn, all of that data gets replicated to these slave databases. So now we have 3 databases with all of our data on it, and so if you've got a site like Reddit that's getting thousands and thousands of requests a second, instead of sending all of the database reads-- all the lookups--to this database, we can send it to these databases. And that alleviates a lot of this load off of this master database. Now, there are much more complicated schemes where you might have a multi-master system or a bunch of databases that are all working together, but this is a fairly common setup and a fairly common approach to spreading around the read. Because generally in most systems you have a lot more reads than you do writes. So if your master can keep up with all of the writes, your slaves can handle all of the reads. There are some downsides to this. One is that it doesn't increase the speed of writes. We're still bottlenecked by this master receiving all this data, who in turn has to send it to all these slaves. So if we can still fit all our writes on this one machine, we're in good shape and we can spread the reads over as many machines as we need. Some of these slaves can even replicate the other machines. Another downside is this notion of replication lag. And this occurs when you write a piece of data to the master but the read hits one of these slaves before the data has propagated, and that's called replication lag. You can sometimes get some funny behavior. And the reason I bring it up now is because in the database we'll be using in this class, you can occasionally see symptoms of this type of behavior. It's not necessarily owing to a master/slave setup, but this is the general concept. What happens if you have too much data for one machine? The replication handles the case where you have too much load. Basically, you've got to do too many reads, so you can replicate your database--scale this up. What if you just have too much data, your master database--or any one of these databases--can't even hold of your data, it doesn't fit in memory or even in disk, there's just too much? One of the things you can do is you can shard the database. This is a fairly simple approach, where instead of having one master you might have a couple that are all the same size, despite my drawing. So let's say we're storing our links database. One approach to shardding might be to store links 1-100 here-- actually, more like 1-a billion here-- and 101-200 here and 201-300 here, and basically you store some of your links here and some of your links here and some of your links here in this database. Obviously, 1-100 probably isn't the correct approach. You could probably use a hashing approach as if we had a hashtable and these were all cells in our hashtable and you hash on some particular key. In this case, I'm referring to link ids--the id of whatever you're storing-- to figure out which database you want to store it in. This is cool because now if we triple our write load from this scenario over here, we have 3 database machines to handle it. Likewise, we already have 3 machines to handle the read load. And of course you can replicate these machines as well. A lot of systems both shard and replicate your machines if you really want to get fancy. But there are some downsides to shardding as well. One of the downsides is the queries get much more complex. What if I said that this helps the case of find me the link whose id is 150? We just say, okay, which does 150 go to? You know what hash is to this machine, and we do our read and that's that. What if I said get me all the links sorted by hotness, for example. Well, we don't know where that link may reside, especially if we're using a hashing algorithm that's more sophisticated than 1-100. That's called a range query, and a range query might have to hit all of your machines. Then we've lost one of our advantages to using this. Now, you could replicate these to spread that around, but you have to hit all these machines and then merge the results probably and do the sort again and memory. Some queries become very, very complex. Another downside is that joins become difficult or impossible. That makes sense. If we have this massive database that has multiple tables on it, we can do joints. But if we start shardding our database up-- we have one database that doesn't even fit on one machine. So if we can't fit one database on our machine, how are we going to fit multiple databases? This notion that you have all of your tables in the same place to do a join-- to do those fancy join SQL queries-- becomes a lot more difficult. Now, there's a lot of research going on of building systems that can overcome these downsides, but if you take the naive approach to replicating and charting, these are some of the things you'll have to deal with. Generally the benefits outweigh the downsides, because if you design your data in such a way that you don't need to do joins or you don't need to do complex queries, you're in very good shape with both of these. Or maybe you have multiple setups-- one setup for handling your general load and another setup for handling your complex queries. That's okay, and that's actually very common. Now, I wanted to introduce these concepts because the database we'll be using in this class-- Google the App Engine Datastore-- actually has some of these limitations. There are no joins allowed, even though it does provide a SQL interface. And a lot of more complex queries that you could do in a general SQL database, you can't do in Google Datastore, but that's okay. You get this really nice benefit of having a database that is shardded and replicated to wazoo and back. It's actually very fast and reliable. You're probably not going to have to worry about systems crashing. It's something that replicating a database can help with and shardding a database can help with. Okay, so I just wanted to introduce those concepts. Let's have a quick quiz on it before we move along. Which is an appropriate technique for increasing the read speed from a database? Get a faster machine. Replicate the database. Store less data. Or press the turbo button. And the answer I'm looking for, obviously, is the thing we just talked about-- replicate the database. Now, yes, you can get a faster machine, but sometimes you don't have access to a faster machine, and that's obviously not what I was asking. Of course, you can store less data. That was something we used to say. I read it all the time. This site would be a lot faster if we didn't have any users. Or you could press the turbo button, which is really just a subset of get a faster machine. I don't know if you guys remember computers with turbo buttons, but they were pretty cool. But the answer I'm looking for is replicate the database. If you take your database and you replicate the data to a bunch of different machines, you can do more reads. So, all right, next quiz. Next quiz--which is an appropriate technique for growing a database that won't fit on one machine? Do you replicate the database? Do you get a bigger hard disk? Do you shard the database? Or do you store less data? And the answer I was looking for is shard the database. You wouldn't replicate the database because if it won't fit on one machine, it's probably not going to fit on the next machine, and it still doesn't solve the machine we're talking about. Get a bigger hard disk--well, that is technically true, but if you put this, you did not get the correct answer. Shard the database--that's what we just talked about. That allows you to take your data and spread it across multiple machines, where each machine is storing just a piece of the data. Take your data and spread it across multiple machines. That's what sharding a database is. Or you could store less data. You can delete some data from your database and of course it will fit, or you can use Mongo and it will do it for you. There's one last set of concepts I'd like to cover before we move into some actual programming and this is ACID. Now again, like many of the concepts in this lecture this is a very, very broad topic and we're just barely going to scratch the surface. But I want you to be familiar with these concepts because this is the type of language we'll be using when we're building our system. So, ACID, this stands for, A for atomicity, C for consistency, I for isolation, and D for durability. Atomicity refers to the notion that all parts of a transaction succeed or fail together, Now, we haven't talked about transactions. But these are basically just a group of statements. So if we were updating our database which is actually not something we spent much time on. There maybe the case where updating two tables at once or updating multiple rows in our database together, in one cohesive unit. For example, if for working from the written example if we had a link table and user's table and somebody upvoted on the link and that increases the user's reputation. In that increase the score of the link and also increase the reputation of the user. And those would happen in something that's called a transaction, which groups together multiple commands. Atomicity refers to the notion that either all of those commands are going to succeed, or they're all going to fail. But we don't do part of it. We don't have just updating the link and not updating the user, everything happens together. So this is a nice property for a database to have. Consistency refers to the notion that the database will always be consistent. And to work from our Reddit example, let's talk about this idea where we have a link and a user who have properties. If we have this notion that a link has a score that gets updated periodically, and the author or the submitter of that link also has a karma score that also gets updated at the same time. Consistency refers to the notion that both the score and the karma will be consistent with one another, so that we don't update the score without also updating the karma. Basically means the database will move from one valid transaction to the next so we'll never run a query that gets a link's updated score but can't also get the user's updated karma. So isolation refers to the notion that no transaction can interfere with another. So let's say we a link that is both getting, two votes coming at the same time to increase the score of this link. That means we're going to be updating the link score up and down, and the user's karma up and down. And isolation refers to the notion that this upvote won't affect the computation of this downvote. If we were overriding this link in our database, it would be a shame if that downvote was applied to the original link's score before the upvote was applied. Because the net score change in here should be zero, but it could be negative one if these aren't handled properly. So, isolation refers the notion that each transaction cannot affect other transactions. Sometimes this is accomplished through locking. If two transactions affect the same row, only one can go at a time, and there are other ways of resolving transaction and conflicts like that. Isolation refers to a database's ability to do that. Finally, we have durability. Durability refers to notion that once a transaction is committed it won't be lost. This means that for example if we send an update to our database and we update some rows and the database says okay successful. That even if the database is turned off or crashes or is unplugged we won't lose that data. That is durability. One thing, I'd like you to know, I know we introduced a lot of new concepts in this portion here, but the important takeaway from this, is that when you're talking about different database systems, that you have different trade offs. It's hard to be fully, have a database that's completely atomic, that's completely consistent. All transactions are isolated and is completely durable. There is always some trade-offs. Okay. Now let's start working on some real code here. We're going to do an extended example. This is going to reflect what you'll be doing in your homework for this Unit quite closely. We're going to be using the Google App Engine Datastore and this is the database provided by App Engine that is actually pretty cool to use. A couple things that are worth pointing out: What we've been referring to as tables are known as entities, in the Google App Engine Datastore. They serve, basically, the same purpose, which is how you organize things of the same data type together. Instead of having a table for links, you would have an entity called Link, and then you would have a bunch of links. A couple things about entities: The columns are not fixed. That is, in a table, you had to have a fixed number of columns that you define when you define the table and in the Google App Engine entity you can have whatever columns you want-- even entities of the same type don't have to have the same columns. This makes development, actually, a lot easier. When you're working with tables, often you build your table and you add a feature, and then you realize--oh, I needed this column, and then you have to add that column. And sometimes adding a column to a database with millions of rows can be quite troublesome. In Google, we don't have that problem; you can have whatever columns you want. You can actually change the columns while you're developing. It's very handy. Entities all have an ID, and this ID can either be assigned automatically by the Datastore, which is what we'll do in most cases--or you can make up your own ID. So if you want to use integers or if you want to use strings--you can use whatever you want, but every entity has an ID field. And another important thing that will be a factor, going forward, is that entities have this notion of parents and ancestors. And this is a relationship to other entities that has a couple of very specific use cases. So--keep going with our link example-- if we had an entity called a Link, it might have a parent that is Reddit. Then we can do queries to say get me all of the links that are a child of Reddit. And this has some interesting notions with regard to consistency in the App Engine database. So it's not something we need to understand deeply, and to be honest, I'm just learning how to use the Datastore myself. So I am, by no means, an expert in how the Datastore works. But something that's important is that if you give your entities a parent, you can get around some limitations on consistency, which is one of the things I'll talk about. Okay. Another difference is, in this class, we've been talking about SQL and in the app store, we've got something a little different. It's called "G-quel"--GQL and it's basically a simplified version of SQL that works only in the Datastore. And the main difference is all queries begin with SELECT* so there's no way to select individual columns-- So this actually simplifies a lot of queries we can do. For example, we can't do joins, which is why I didn't want to spend a whole lot of time on joins earlier. Even if I were working in a SQL database, I probably wouldn't be doing a whole lot of joins and in the App Engine Datastore, we won't be doing any joins whatsoever because it's not possible. When we're using GQL-- actually, we don't even have to use GQL at all. The Datastore has a kind of procedural language you could use as well. But since we've spent all this time practicing SQL and you'll probably use it elsewhere in your career, we're going to use GQL for this example. So we can at least have some consistency there. Another difference is in a kind of generic SQL database, as we've been talking about. You can run arbitrary queries-- no matter how slow, with or without indices. And in App Engine, all queries must be indexed. This is important, right--because when you're running your own database, you can do whatever you want. But Google--it's very nice of them to give us this whole system for free-- at least for small-use cases-- but we can't beat their machines to death. All the queries must be indexed. It's actually not just so we don't beat them to death but it's just the way the whole system is built. As you get more familiar with it, it'll kind of make sense-- why things are designed the way they are. So for the most part, in this example that I'm going to build and your homework, you won't actually have to build any indices yourself. Google App Engine will actually build the indices for you, which is really handy. If you wanted control over what indices they build-- yes, you can do that yourself. Sometimes, it might build, not the most efficient index, and you can define your own--so that's pretty cool as well. One last thing I'd like to talk about is the fact that the Datastore is sharded in some way and replicated. Google doesn't really share details of how this is implemented at a very low level, but a lot of the constraints that we'll be dealing with imply that the database is both sharded and replicated. So there are some really nice properties here. One is that you are not going to have to think about scaling-- too much. Your queries will generally be quick because they have to be simple. And we might have to think about consistency, which is why I talked a little bit about replication lag so much before in an Intro Class. Because things are sharded and sometimes your data changes and updates take time to propagate through the system, we're going to actually have to acknowledge the fact that we're in a big database system and things may not always be consistent in all cases. It's easy to work around these cases, but it is something you have to do consciously. Let's do a quick quiz. Do you understand everything there is to know about the App Engine Datastore? And the correct answer should be No. If you marked Yes, and you insist on marking Yes-- even though we're going to mark you Wrong-- well, then you probably work on the App Engine Datastore, and thank you for taking this course. But for everybody else--myself included-- the answer is No. You should get very comfortable with the App Engine Datastore documentation--it's all online, there's a lot of it, and it's very helpful. We'll link to it in the course notes and we'll link to it in the homework. I reference it a lot while I'm even teaching these lectures. So anyway, get familiar with the docs--there's a lot to know-- and let's move on to the fun part. Okay. So we are going to build a Web site-- right now--called ASCII Chan. And this is going to be a message board for sharing ASCII Art. It's going to have this general structure where we will have a form with-- you know--it'll take a title and some ASCII Art-- a little submit button-- and the user can submit this and below this form, they'll see ASCII Art that's been submitted by other people--things like that. So it'll be a one-page Web site. It'll have a form, and then the contents here. So for those of you who don't know what ASCII Art is, let me give you a few examples. Here we are, on this Web site, Chris.com-- pretty awesome domain name. This Web site is dedicated to ASCII Art, and as you can see here-- I'm just looking at a bunch of ASCII Art of cows. All ASCII Art is--it's just little pictures, drawn with keyboard characters. SO pretty cool; there's this huge--huge--encyclopedia of ASCII Art online and we are going to build a forum for people to share their own ASCII Art. Anyway, if you haven't seen it before, that's what it is. It's a fantastic way for people to waste time in front of their keyboards. Okay. Here we go. Here we are in our Editor and I've got the framework of a basic application. And this is actually the framework I've been using for the homeworks and stuff that I've been doing. I've been using this notion of templates, which is not something I'm going to explain thoroughly in this class. But instead of doing string substitutions for big wads of HTML, we can keep our HTML in separate files that look like HTML and that have just little escapes for variables. I'll be using that in this example, and you're free to use them on the homeworks yourself if you're tired of doing string substitutions for generating large chunks of text. And also--this kind of little framework, we can provide if you'd like to use that. So all I've done is-- You may recognize this as a standard Google App Engine app. I added a class, called Handler, which this inherits from the webapp2 handler, which is what you normally use. And I've just added a couple of convenience functions. I made a function called "write" which just calls: response.out.right so I don't have to type that all the time. I made a function called render_str, which takes a template name and it returns a string of that rendered template. And then I made another function called render, which instead of returning just the string, it calls "write" on it. And I've got a Main Handler down here--MainPage-- which is mapped to from 'SLASH' and all this does is it writes this string, ("asciichan!"), to the browser. So let's go ahead and switch to the browser, real quick, and make sure this is working. Here we are, in our browser. We're printing: asciichan! Okay, all is well. All right. Let me show you how the Template works, real quick. I've got this file called front.html. It's currently blank. I'm going to type in some HTML. We've got our DOCTYPE--you know-- our , our /ascii/, We've got our here, and inside our we've got an tag, which is just--basically, it's called a HEADER1. It draws your text bold, a little larger-- with a little margin around it, and that's it. So that's in this file called front.html. If we had opened this in our browser, it would just print the words: /ascii/ and let's go ahead and instead of loading this in our browser, return it from our file here. Instead of calling self.write, I've changed this to self.render("front.html"] and let's give this a whirl. Okay. Here we are in our browser--I've reloaded the page. We can see my title is set to /ascii/ and we've got the text, /ascii/, up here. The slash is just kind of a joke. That's how Fortran does their titles and stuff. In our Editor, you can see--we just called the self.render function, which is defined here. All that does is it calls render_str on this Template name-- this file name which render_str loads, renders--and then we write. Okay. So, simple enough--that'll just save some time. It's a little bit more convenient to edit HTML as HTML--especially if you're editor is going to help you-- than to have a big string in the middle of your Python file. All right. Let's go over to our HTML, and the first thing we want to add is our form. So the method="post" and we're not going to define an action; we're just going to submit to ourselves, which is something we've done a lot. So I've added one input field. We're going to call it "title"-- and I'm going to include "title" in a little here, just to put it on a new line, and then it's going to be an and this is going to be for the title of our image. Let's go ahead--and I closed the tag. I'm going to Save the file, and let's load it in our Browser to make sure everything's working. Okay. Here I am in the browser, and I reload and now I have my title string and a box I can type in. Okay. All is well. Let's add the next form field for inputting the art from the user. So we're going to call this "art", and let's interrupt this for a quick quiz. Which is the most appropriate form element for inputting ascii art? Is it , a , a element, or ? The correct answer is . Now, of course, you can use other ones, but--well, really, or are the only ones that are remotely applicable. And is nice because it will give you like a big box to draw in or to--in our case--paste into. Now that you've solved that devious quiz, let's go ahead and add our text area. We're going to call this name equals art, and remember text area is not a void element like input, it has a closing tag, and the default text of the text area would appear between those 2 texts. Let's close this label. Save this file and give it a test. Okay, here we are on the browser, we reload. Okay, now we have space for some title. I've got this big box where we can enter in our ASCII art, and all is well. Cool. The next thing we need to do is add the form handling. We need to add the POST method in our application. So we are in our application. We've been rendering that front_HTML form, that's what we've been editing. Let's go ahead and add our post function to deal with the user types list. Okay, so we add the post function. The first thing we need to do is get the parameters out of the request. Self.request_get ('title') and self.request_get ('art'), and that will get those values from the posts from the form submission. Let's go ahead and add some basic error handling. Okay, so I've added the shell of our kind of error handling. So if we have both the title and art, for now, we're just going to say thanks, you know, that's just a stub. If we don't have a title in art, we're going to say--we're going to set this error variable, and then we're going to render the form with our error message. So I'm going to pass the error variable I made into this function render, which is going to pass it to our template, and so we need to add a place for our error in our template. Let's put this right at the bottom of the form. Okay, so I've made a basic div. I'm going to call it class error, because I have intentions of styling this later to make the text red, and classes are how we attach CSS styles to things. Now what I want to do is I'm going to say {{error}}, and then I'm going to close this div. Now what this does, this is part of our template language. This includes the--any variables that the template is rendered with. It will render them right in place here. So this is a little bit nicer than the string substitution thing we were doing before, and while I'm in here, I'm going to go ahead and add a submit button because we forgot that before. So we're going to give this a test, here we are in our form. If I click the submit button without submitting anything, we render our form and see our error message, that's perfect. If I type in just the title, and I click submit, again the form with the error message. Just the art, perfect, and now if I type in both, I see thanks. Okay, so it looks like this thing is working. One thing I want you to notice is when I type in text in the text field and I hit submit and we get our error, we lost our text. Remember we've dealt with this before, so let's go ahead and fix that bug while we're sitting here. The first thing I'm going to do is I'm going to pull out the rendering of the front page into it's own function because we are going to be calling it from both get and post, and I don't want to have some of this logic that we're about to write duplicated. So let's go ahead and add a new function to our class. So let's create a new class called render front, and this is going to render out front page. It's going to take in a few parameters, how about the title, which will default to nothing, the art work, which will also default to nothing, and the error message, which also will default to nothing, and all this function is going to do right now is it's going to call self.render front.HTML, and we're going to pass in title equals title, art equals art, and error equals error. All we're doing here, and you should remember this structure I hope from the previous lesson, we're just taking this variable title and passing it in to the template and so we can use these variables in the template when we're rendering our form. Now what I'm going to is I'm going to replace this call of self.rendered to self.render_front. That will draw the blank form, and them going to replace this call to self.render to self.render_front, and this will render our form with the error message, and one final thing we need to do is actually make use of these variables so let's go ahead and do that. Here we are in our input for the title. Let's preserve the title so I'm going to do--I'm going to include the title variable passed in from the other function, and then in our text area, I'm going to include any art that was passed in. Okay, let's give this all a test. Reloading this page doesnt break anything. If I type in a title, and we're testing-- we're going to test our error submission, and I click submit, we should see our error message, and we should see title still in the title box. Hmm, okay, we see her error message but we don't see title in the title box. Let's go investigate why. Okay, so here we are in our editor. I see the bug, and our error call. We're sending in the error message, but we're not sending in the title and the art that we got from the user so let's go ahead and fix that, title, arts, and we don't need to actually specify the QWORD parameters, we can just pass them indirectly, title, art, error. So we've done that, we saved the file, and let's try this again. Let's type in a title, and we click submit, perfect. Our text box stayed the same. We replaced that text with nothing, enter in some fake artwork, we still see our error message, and our text is preserved. Now one thing I would like to show you, remember we spent all that time escaping in our previous lecture, let's type in some text here. Okay, I'm going to submit this. It rendered it nicely, it didn't--we didn't have any escaping issues. Why is that? You know we haven't dealt with escaping in this file at all. Let me show you how that works real quick. And the way I'm using Jinja, it's the template language we're using by the way, that's what's rendering this HTML. One of the parameters it takes when you setup it's little environment is autoescape, and that's that autoescape = true, which will autoescape anything we include from a variable, which is really convenient so you don't have to think about escaping content that comes from users if you use autoescape, and I always, always use autoescape. If you want to deliberately include something not escaped, then you can--there's a method for doing that in your template so it forces you to acknowledge that issue whenever you want to be unsafe, and in the default case, your just safe. Okay, so we've got our form, you've done all this before. We've got our error case. We've got a shell of a success case. We are going to go ahead and fix that now soon, and we're rendering our form nicely with our error message and preserving our fields. So far nothing is new to you other than the templates. The next thing we're going to do is we're going to start adding the database so we can store the art work that is submitted by users. The way you define an entity in Google app engine is to define a class. So we're going to make a class called art, and this is going to represent a submission from the user, and this inherits from db.model, and db.model is something that is included from Google. You can see I've actually already imported up here from Google.appengine.ext import db, and so our art class inherits from the db.model class, and this, this will allow us to create an entity. So the first thing we need to do is we need to define the types of this entity. Google app engine has a number of different options for the types of the properties of an entity, or if we were to use our old verbiage, the columns of our table. Some of the popular ones are integer, which is for storing integers, float for storing floating point numbers, string for storing strings, and we've got a date for storing dates, we've got time for storing times, and then we've got date times for storing both dates and times. These are pretty handy. They even have properties that are things like email, a link, a postal address. App engine has all sorts of handy types you can use. So what I would like to do really quick is have a little quiz. We are going to have a couple of properties on our art class. Properties remember are basically what we have been calling columns. We're going to have one for the title, we're going to have 1 for the art, and I'm going to have another one, I'm going to call it created, and this is going to be when the art was submitted to our site. What I would like you to do is decide which of these types we should use for each of these properties, and oh, by the way, this has turned into a quiz. Okay, so the correct answer is for the title, we're going to use a string. For the art, we're also going to use a string, and for the created, we're also going--we're going to use a date time. Now, actually I lied to you, we're not going to use a string, we're going to use something called text, but there is no way for me to ask a quiz without giving away the answer. I learned while writing this that there is another type called text, and the difference between a string and a text is that a string must be under 500 characters and can be indexed. Text can be greater than 500 characters, which is really handy for ASCII art. ASCII art that is under 500 characters is not very fun at all. I actually learned this while building this lesson, and text cannot be indexed, which means of course that we can't sort based on a text property. This is fine, you know in our case, we're going to sort probably on the created property so we can show things in order. We won't be able to sort things by the artwork, which is fine, because what would that even mean? So if we were to use the string data type, which we're going to use on our titles, yeah it is indexed so you can do queries, you can say get me the artwork to title = X. You can't--we can't do a query get me the art where text = X because it's not indexed. Let's go ahead and define our data type. Okay, I'm going to go ahead and add these properties to this class. This is how you do it. You say title=db.StringProperty. This is in the database module from Google, and this is how you say something is a particular type. You give your property name, and then you say equals, and then you give the type. This is the class that represents the string type--string. I'm going to add another parameter here--required-True. And this sets a constraint on the database. It means if we try to make an instance of art without giving it a title, we will get an exception--Python won't let us do that-- which is handy. You want to always have as many constraints as you reasonably can to prevent you from making silly mistakes and putting bad data into your database. Having bad data in your database is really annoying. Sometimes it's really hard to find because you don't have the appropriate keys to do your queries to look it up. So constraints are important, and this is a handy one that Google provides--required=True. Let's add another field. This is our art. This is going to be a db.TextProperty. This will also be required=True. Simple enough. Actually, the first time I wrote this I used the string property, and then I got through this whole project and all of a sudden I couldn't paste in ASCII art longer than 500 characters. So text is handy there. And we're also going to add our last field for created, which will be a DateTimeProperty. And this takes another parameter called autonowadd=true. And what this property does is it automatically--when we create an instance of art-- we'll set the created to be the current time, right now. So we don't have to actually deal with that ourselves. This is really handy. Now, you may be thinking this is an awful lot to know. You don't have to know this. This is all in the Google Datastore docs. So when you're working on your homework and stuff, please have those docs handy. It will save you a lot of heartache. There's some interesting stuff in there. This is one of them--autonowadd. Okay, so that's all we have to do to define a type, or at least our simple type here. Let's go ahead and start creating these things. Here we are down in our post function. In our success case we want to behave a little differently. What we want to do is make an art. A--that's going to be our art-- equals a new instance of art. We're going to pass in title equals title and art equals art. We don't need the pass in created. Because of the autonowadd, we'll automatically get that property. So we're going to create a new instance, and then to store this instance, we say a.put. This will store our new art object in the database. When we're done, we're going to redirect to the front page so we don't have that annoying reload message-- the resubmit your form--if we hit reload. Okay, so let's go ahead and give this a test. Here I am in our browser. Now what should happen is when we submit a valid title and piece of art text, we should store it in our database. Okay, so I'm going to type in a title. This title will be camel, and then I'm going to put some art in our text box here, which is a camel that I copied off of that ASCII art site, and I'm going to click submit. I click submit. We're back on the front page, so we think it worked, but we really have no way of knowing for sure right now. So let's add the rest of this feature, which is going to draw our artwork at the bottom of our form. Okay, so we want to look up all of our artwork out of our database. In theory, we just put something in the database. Let's see if we can find it. We want to do this every time we render that front page. We want to both show the form, and we want to show the artwork. So I'm going to add some text to this render front function. Our arts equal--and this is how we run a query. We say db.GqlQuery, and then we can include our query. But first, I would like you to tell me what that query is going to be. So what I'd like you to do is write for me the SQL--in this case, the GQL-- to fetch all of the instances of arts from our database, sorted by the creation time. Now, I know this is a little bit much to ask. In this case, Arts is going to be the name of the table. That's how you do GQL queries. And remember creation time? That field was called created. Okay, good luck. The answer is select * from art order by created descending. So remember our table is called Art. I hope I didn't confuse you by adding the s here. I think we will accept both, but our class name is Art, so that's the name of our table. So select * from art, and remember all GQL queries have to say select *, so you have no choice there. Then order by--that's how you sort something--created. This is our property that represents when this particular piece of art was submitted. And since we want most recent first, we add DESC, for descending, at the end of this query. Okay, let's go ahead and add the store program. So I've written the SQL select * from art order by created descending. I used multiple lines here. That makes it a little bit easier to read. That's going to store the results from this query, which is actually going to be a cursor. The cursor is just a pointer to the results in this variable called Arts. Let's go ahead and pass in arts to our template. Let's go to our template and make use of it. So below our form--this is going to get a little fancy-- we're going to display all the artwork we've received submitted. So I'm going to start with an HR, which just draws a line across the page, and then I can use a loop in this template. This is going to be actually--it's going to be Python code embedded in our html. You don't have to understand it, but that's what I'm doing. For art in arts, this little curly percent syntax is used by Jinja, the template language, to separate html from Python. We're going to create a div. We're going to call it art. Remember this class doesn't do anything until we add the styles, and we haven't added any styles yet. So it basically just creates a new line. Div class equals art title-- again, another div doesn't do anything yet. We're just going to put the art title in here. This is how we include a variable. Remember the double curlies. So for art in arts, I'm going to take that art here and access its title. And this object art here is actually an instance of this class art here, and it has a title. So it can access the title using the period syntax. Then we close those curlies, we close our div, and then we're going to add the art body. I'm going to use the pre tag. The pre tag is a handy little tag that basically preserves the white space that is inside it. So remember how we talked about html, how it converts all spaces to a single space and all new lines to a single new line? That's why we can indent our html, because there's actually all these spaces between all these tags and things to print as you'd expect them to. The pretag basically says any white space between this pretag is preformatted and it's going to stay that way. So we're going to include our art.art. Now remember, this art here-- this is a little confusing, I realize-- this art here refers to this instance of our art class, and our art class actually has a property called art, which is actually the text of the art itself. So that's what we're going to include there, and then we're going to close our div, and we're going to end our loop. And that's the end of our html file. Let's review what we just added. For every art in arts, render this html. Remember arts comes from this query that we run here--this GQL query-- to select all of the art. We're going to store that in a variable called Arts, and we're going to pass it into our template. So let's go to our browser. Here we've got our page. And now, when I reload this page, I should see all of our artwork. Aha! And here is the camel we submitted. There's the title, and there is the camel. Let's submit a new piece of art. I've gone and I've fetched some art. In this case, you can probably guess what it's going to be. Title Batman--let's paste him in here. And when I click submit, we see our Batman. Pretty neat, huh? Now we have this nice art channel. So this is our html. I've been including these classes, and I keep referring to, oh, these are good for styling things and this area is good for styling things. I'm going to go ahead and show you a few styles here that just make this app a little bit better. So you can add a style tag. This has type text/css. We are not going to quiz you at all on this. In a lot of our homeworks and stuff going forward, I'll provide the styles, but I'm going to pop in a few here that I wrote. Okay, I just pasted in a bunch of styles, and I'll just walk you through them real quick, because it's fairly easy to read. Basically, the syntax is body. So this means our body tag is going to have a font family--sans serif so we'll get rid of the serifs. It's going to be with 800 pixels. This is a trick for centering it and giving some padding. Our error style that we added for our error message-- that's going to have red text. Our label, instead of being displayed inline, I'm going to make it display block, which is going to cause it to use its own line. And I'm going to make the font bigger. Our input for our title--I'm going to make that wider with 400. I'm going to make the font size bigger. I'm going to add some padding. That padding is kind of spaced between the outside of the element and the contents. I'm going to make our text area wider and taller and give it a bigger font and also make it a monospace font, which is good for ASCII art. I'm going to make the text of our submit button bigger. I'm going to add some margins between these elements that our HR--our rule--is going to have 20 pixels on either side. Our artwork is going to have 20 pixels between each of them. And our art titles are going to be bold, and they're going to be 20 pixels tall--the font. And our art body is not going to have any margin on it, and its font size is going to be 17 pixels. So I know that was a lot. You don't have to know this, or really even have to understand it. I just want you to know what it does or what it is. And let's go to our browser and see how this looks. So here's our old page. I'm going to reload this with our new styles. Oh, yeah, look at that. Now we've got this big form, nicer fonts, and a big, big, much nicer Batman and a much nicer camel. 25 Just a few little styles can go a long way to making a web app look a lot nicer, actually. Okay, so I hope you enjoyed that. I hope you learned something. That's the end of this unit. Your next homework is going to be basically using these skills I just demonstrated. So I hope you had fun with that. Thanks for participating so far. Welcome to lesson four. Lesson four is all about authentication. This is one of my favorite lessons, actually. We're going to build a complete log in system, or learn how to build a complete log in system rather. And then you're going to build a complete log in system for your blog. So users can actually log in and register on the blog that you've been working on so far. We're going to learn about cookies, which is a little bit of information your browser stores to know what user is logged into your blog. We're going to talk about passwords, an hashing passwords, an how to store those securely in your database. An we'll also just talk about hashing in general, because it's a really handy little tool that'll come up, many times throughout your, programming career. It sounds simple but it's actually quite complex. It'll be a lot a fun. So, let's get started. Cookie is a small piece of data stored in the browser for a website. And by small, I mean less than four kilobytes. And in practice, we're only talking about 100 bytes, just a small you know, really just a string. It takes the format conceptually is something like this, name equals value. And in practice it may look something like this, user.id equals 12345. Cookies are really commonly used for things like user IDs and, and you know, kind of temporary information that, that a browser wants to store, you know, whether you're logged into a website. You know, generally, you, you have a cookie that represents the, the fact that you're logged in as user, you know, 12345. So to kind of draw you a little picture of how these things fit together, you know, we might have your browser, and it makes requests, you know, to some web servers. And a web server might send back, in it's response, some cookie data, and this is in the form of an HTTP header. And then your browser basically just stores this cookie, it's associated with this website. We'll talk more about that shortly. And then every time your browser makes a request to this website in the future, now that it has this cookie, it will, it will send the cookie back to the server. So, you know, if you are logging in, you might, you might post some form here and the server might respond with okay, welcome to our website you are user 12345. And then on every future request, you say, hey, I'm user 12345. And that's how the website knows that you're logged in. And a cookie, you know, is, is just basically a file that your browser stores. Generally, you can store about, about 20 cookies per website. Now, this is basically up to the browser. It's some sort of, it, it, it's a browser limitation. Another limitation is probably the length of the cookie, which we said is less than four k, but in reality [LAUGH], you know, this is this is five bytes. And we're probably, you know, most of the cookies we're storing are not, you know, thousands of bytes. Another limitation is a cookie has to be associated with a particular domain. So, you know, a cook, a cookie for udacity.com is only sent to you to udacity.com and, and udacity.com can only set cookies for udacity.com. So, it's, each website has you know, a few cookies that it can store that are private for that website. A lot of this depends on the browser to behave properly. So, you know, this 20 cookies per website that's an old Internet Explorer limitation. Honestly I don't know what the limit is for modern browsers. But if you're storing more than 20 cookies on, on a particular domain, you'll probably rethink things a little bit. You know, maybe store more data in, you know, in a, a single cookie. The four kilobytes, again, there, there's so many things that can go wrong when you start sending big cookies that are, you know, 4000 bytes long. You know, you can set, some, some browsers don't handle multi-line cookies properly. Some web servers don't handle multi, multi-line cookies properly, so I would suggest keeping it short and simple. And, and most of our use cases are for storing small pieces of data that you don't want to store in a database. It's easier to just store them in a cookie. Or, you know, small pieces of, you know, temporary data that is, that is only relevant to this particular user in this particular browser right now. Now this, this constraint, you know, a cookie being associated with pick your website is, is important. It prevents you know, me from, you know, the, the cookie is, is, is what makes me be logged in at a lot of websites, so. If another website could forge this cookie or read this cookie, you know, they could pretend to be me on another website. You know, they could steal my log in information. So cookies, the, the domain that cookie belongs to is, is really important. But it's up to the browser to enforce those rules. And sometimes browsers have bugs you know, none of the modern ones do. I can't remember the last time that happened. But you know, it's just something to be aware of. These are, this is all kind of browser side, you know, client side, enforced So, what are some good uses of cookies, you know? In other words, what, what are problems that cookies are good at solving for you? Storing login information, storing small amounts of data to avoid hitting a database, storing user preferences and tracking you for ads. Check all that apply. Okay, so, now I know this is kind of a subjective quiz, but here are the answers I was looking for. Storing login information. This is something, you know, I just mentioned previously. That's a really common use of cookies. So when you log into a website, the web server gives you a cookie, and that identifies you for future requests. Storing small amounts of data to avoid hitting a database. Yes, this is another kind of handy little thing. You know, if you've just got a small piece of data that you want to store. You know it, it's, it's temporary. It's small. You don't need to have all the infrastructure of a database to store it. And have to you know hit your database on every request to retrieve it. That sort of thing. Especially if it's, it's, if it's you know, anonymous data. You know, data you don't mind losing. Because a user can of course clear all the cookies out of their browser or you know, a browser may not have cookies enabled at all. Storing user preference info. no, this is not a good use of cookies. At least in the notion of a user as we've been kind of talking about where, you know, you might log into a website and you have these preferences. This is because you want the data to survive. Now, cookies can be erased at any time. A user can change browsers, they can go to a different machine, and the cookies don't, you know the cookies are specific to one browser. And as long as the user allows them to be there. So data like user preferences that you want to exist until a user changes them on your website Shouldn't be stored in cookies and tracking you for ads. This is unfortunately maybe not a a good use more of an appropriate use because tracking you for ads isn't really inherently a good thing, but its a really common use of cookies. You go to a website, you may find yourself with 20 cookies that are tracking you for different ad providers. And in fact, I had a friend that worked for an ad tracking company for a while and these transfers are kind of related. They used to joke that they had the world's largest database stored in users' browsers all across the internet. They had like, many hundreds and thousands of, of terabytes of data. In theory stored you know, a few hundred bytes at a time, in users' cookies. Because they powered a lot of really big ad networks. Cookies, and we'll come back to a little bit how ad networks work. I think it's, it's interesting to understand. That cookies are a critical technology for tracking you for for advertising purposes. Okay. So I alluded to this before. Cookies are sent in HTTP headers. So when a server and, and an HTTP response, wants to give you a cookie, wants to assign a cookie to your browser it uses a header that looks something like this. The header name is Set-Cookie. Like all headers, it's followed by a colon and then a space and then the value of the header. And in this particular case, you say, name equals value. There are some other parameters you can have on the cookie that we'll discuss later but, basically, they use the Set-Cookie header to, to set cookie named user_id to this value. And remember, this is the value, and this is the name, and the value can be, you know, up to 4K. Honestly, I don't know if there's a limit to how big the name can be. generally, this is very, very short. If the server wants to set, send the multiple cookies, it can do so by using multiple Set-Cookie, Cookie headers. There's no restriction that says headers have to be unique. A, a server can send as many cookies as it wants. It's up to the browser to decide whether or not to store them. Remember, I said about 20 is the max. So try to, try to keep it under there. Now, when, when a, this is under Response. Now, in future requests, the browser sends its own header, that this is the, the name of the header, and remember, this is, you know, this is also the name of the header, over here, Set-Cookie and then the value of the header, in this case, is user_id equals 12345. Again, we have the, the name of the cookie and the value of the cookie. If we were to make this H, this request match what these two cookies were to, when our browser sends multiple cookies, it'll look something like this, user_id equals 12345; which separates each cookie from each other, and then any other cookies. So the browser sends one cookie header with all of your cookies in it. The semicolon is important and you may be wondering, well, what if I want to put a semicolon in my cookie value? And the short answer is, don't. And if you really want to, encode the cookie value, you know? You, this, this can be whatever you want. The browser doesn't care so you can, you can Base64 it, you can encrypt it, you can ROT13 it, you can do whatever you want here but make sure you escape those semicolons so you don't goof up your the incoming cookie header. Some frameworks will do this for you. We are going to be operating at a lower level so that's something you'll want to think about. Okay, let's do a quick demo, remember when we played around on Telnet in Unit One to, to manipulate Web servers directly? I'm going to go ahead and do that here, and we can look at some more HTTP headers. So, if I were to Telnet to google.com, you know, port 80, as we've been doing. So, we do our HTTP request to get the front page remember our host header. We see our results, we scroll up to the top of this, we can our our header. So here's the request I made, and here are the headers and here are a couple set cookie headers. So in this one, this sets a cookie named pref, to this value and it's actually Google's doing a very typical Google thing, and storing multiple pieces of data in one cookie. So this is the equal sign that's part of the cookie header, and this equal sign is actually part of the cookie value. This is the end of the cookie value here, we've got a semicolon and then we have some extra parameters that we haven't talked about yet. We have an expires time, and this is when the cookie expires. So after this date, April 19th, 2014, this cookie will no longer be sent and this cookie is relative or relevant to the path slash so you can restrict cookies to specific paths and this cookie is specific to google.com. So this basically means that anybody at google.com will receive this cookie. Here is a, another, another cookie this one's called NID. And you know, you can see the value comes all the way down here, to the first semicolon. Expires time of its own a path, a domain, some extra constraints. This cookie's only and relevant to http which, which, is, is just another, another cookie Option you have at your disposal. I want to show you one quick thing while we're in the terminal here. If you're on a Mac or Linux you can use the Curl Cmd which is pretty cool. Say, curl -I, which basically says, get me the headers. curl -I google.com, and that'll just run the headers. I'm not going to quiz you on that, but if you're on a Unix machine, you can use Curl instead of Telnet, and you don't have to type so fast and type so much stuff. So anyway, curl -I, handy little tool for viewing HTTP headers. I'll show you one last way to inspect cookies this may not work for everybody, but it's another neat experiment. Your on in Chrome I'm in you know special private browsing mode which is what all this is talking about. Basically I'm in the Private browsing mode because I'd, I don't want to have any cookies, and that's generally what this Private browsing modes do, is they throw away all your cookies. So I'm going to, I'm going to do something here, I've open up to the Bug tools in Chrome, this are in Developer tools that are built in the Chrome, you can Google around for, how to show this in Chrome or you know Safari and Internet Explorer also have, a similar feature so you can kind of watch requests. And I'm going to go to google.com and on here I can see all of the requests we made at google.com and one thing I can do is I can actually view the headers. We can actually view the request header I made for Google.com and you can see we, we sent some various headers. We didn't send any cookies, cause we don't have any. And if we scroll down a little bit, we can see you know one of the cookies that got set, right here. This is one of the cookie headers, so that cookie. If we were to reload this page now, our browser, Chrome here, has stored this cookie. If we were to load this page, we should see a new request header, I will do that now. I have reloaded the page and now we see the request we made for the google.com the request has a cookie header and this says the exact same context as the sec cookie. Well at least the name here, and the value is the same. You don't have to resend Path and Domain and all those other Options, those are just for the browser to know when to send the cookie. If, if, if you're feeling adventurous, you can find a, a Debug mode in your browser and experiment with this sort of stuff. It's kind of, it's kind of neat to see what's there. Which header does a browser use to send a cookie to a server? You know, what is the name of that header? Go ahead and answer that here. And the answer, of course, is Cookie. Now, of course, generally, I've been writing with the ca uppercase C and that's how you see it around the internet. I case actually doesn't, doesn't matter or shouldn't matter. But, I say shouldn't because you never know where you're going to find a web sever or, or, or browser that, that, that, that wants the headers or, or that wants the capitalization, you know, like this, you know, capital C lowercase ookie. So I would, I would, try again the habit of using it that way if you can but that's that. Okay, another quick quiz. Which header does a server use to set a cookie? Just put the header name in the box here. And the answer of course is set-cookie. We just saw quite a few of those and of course the capitalization is the same as I described before. Capital S, little e t, dash, capital C, little ookie. So as we saw in the demos, the cookies can have extra parameters, not just the value. So, let me, let me draw anoth, an, an example cookie for you. Here's a, here's an example set cookie header for setting this cookie, whose name is name, nice and confusing. Whose value is Steve. And now we've added a couple extra parameters. We've got semicolon to end the value. We've added this domain parameter. And this is what domain this cookie is relevant to. So in this case, it is relevant to www.reddit.com and this is the path that it's relevant to. So the path is easier to explain. basically, you can put whatever you want here and then, in this case, this is the default path. If you don't specify a path we just assume you mean slash. And this is actually the most common use case of cookies. You the cookie applies to all of the paths. But if you want to restrict the cookie to a particular path, you can specify that path here and the browser will make sure that the path you're requesting starts with this value before it sends the cookie. So the domain is much more interesting and much more complex. And let's, let's talk about this a little bit so this means that basically, this cookie will not get sent by the browser to the server unless the server's domain is www.reddit.com or basically, ends with www.reddit.com. So, domains that this work for are, for example, www.reddit.com foo.www.reddit.com. Domains that, that will not receive this cookie, would be for example just reddit.com without the ww, or bar.reddit.com because this cookie was restricted to www, so basically, the, the site you're at has to begin, or I mean sorry end with www.reddit.com. You can't set cookies to just .com, you have to have at least two periods. So the minimum domain you can set a cookie for is .reddit.com. If you try to set for just reddit.com, the, that first period will automatically get added. That controls, the domain controls which domain a browser will send the cookie to. What about, you know, can, can I have can I have a web server at reddit.com that sets a cookie for google.com? The answer is, no. Similar to how the domain parameter restricts which domains a browser will send a cookie to, the domain who's serving the request, the, the, basically the domain of the web server, that, of, of the webpage, you may only set a cookie to that domain or higher. So if we're at www.reddit.com the browser will only accept cookies for by default, www.reddit.com if there's no, no domain parameter. If there is a domain parameter, the only valid domains are www.reddit.com or reddit.com. We can't set a cookie for bar.reddit.com or foo.reddit.com. And, and this is to prevent you know, if you have multiple websites, kind of sharing the same top-level domain, you know, halfspot.com for example, you know, you don't, I, I can't see a cookie on, in my app that affects the behavior of your app. I can only set a cookie that get sent with www and with the top level. That's how the domain restrictions work. Let's have a little quiz. Lets quiz this domain stuff. So, which of these domains would receive this cookie? That is, if you went to one of these domains in your browser, and you had this cookie set which of these domains would get this cookie sent back to them? Is it udacity.com, ide.udacity.com, other.ide.udacity.com, or other.udacity.com? And the correct answer is, obviously, ide.udacity.com. You know, if we had a cookie in our browser for ide.udacity.com, when, if you visited ide.udacity.com, we'd send that cookie. And we'd also send that cookie to other.ide.udacity.com. Basically, any sub domain of this domain would receive that cookie. And that kind of makes sense, right? If you, you set this cookie anything below that domain is kind of part of that domain so you would receive that cookie as well. Okay good job, let's try another one. Okay, the same quiz but backwards. This time, if we're visiting one of these domains in our browser and the response from the server gave us this header to set this cookie, which of these domains are allowed to set this cookie? And these are the same domains from before, udacity.com, ide.udacity.com, other.ide.udacity.com or other.udacity.com. And the domain for the cookie is, of course, is ide.udacity.com. The first answer is ide.udacity.com. And again, that makes sense for the same reason as, as before. If the domains match, it's a simple case. Of course this domain can set this cookie. The second answer, other.ide.udacity.com. This basically means if other can set a cookie for its parents. Which works fine. What, what is not a correct answer is udacity.com. Other.ide can't set a cookie for udacity which would set to, you know, any sub-domain of udacity. And it can't set a cookie for, you know, a sibling. Other.udacity.com can't set this cookie. Only these two domains can set this cookie. I want you to be aware that the domain you're setting a cookie for is very important. And, you know, of course, when you are developing software you can just experiment and see which ones work. But these are the general rules. You know, just, just look for, you know, either a direct match or the server. Or the cookie should be a subset of the server. And you're in and you're in good shape. So one last point I'd like to show you about domains. Is browsers generally all have a Preferences page. And here I am in Chrome's preferences. If I go to Under the Hood, and I click on Content Settings, I can actually choose some relevant options. Basically for Cookies, we can Allow all data to be set. And this basically says, you know, allow all, all cookies to be set. Now the next option basically says, Only set cookies that exist in this current session. So when I close my browser, all those cookies will disappear. You know, we can block sites from setting, setting any cookies. Or we could block cookies or, or websites from setting, setting third party cookies. So that means if reddit.com makes a request to google.com, we won't accept any google.com cookies. Because our browser says reddit. Even though we might make requests you know, for images or, or other things from other domains. And you know, another option, Clear cookies. So you know, this is kind of well trodden ground to set you know, which, which domains are allowed to set what cookies. And generally I usually check this, this box. It prevents websites from linking to third party data. And then having them you know, fill your browser with ad tracking stuff. So anyway, I just thought you should be aware that these are, now you have more information of how cookie domains work. And what's allowed to set what. And you can even restrict it even further, or the user can. So you want to be sure that you know, you're not operating under the assumption that your cookies may always be allowed, and may always be there. Thought I'd take a moment real quick to explain how ad networks work. This isn't strictly relative or relevant to this class but it's kind of a neat example of how cookies are used. So say you have your browser and it makes a request to some website and you know, this website responds with some HTML. You know, one of the things in this in this HTML could actually be a little one pixel hidden image. That you don't even see. That makes requests to somebody else. For example, Google.com. And this in fact happens. And, because Google.com has an analytic's package set a lot of websites use to track you know, traffic and what users are doing. And that sort of thing. And google.com may, re, respond you know, it'll respond with the actual pixel image. You know, this might be a, you know, image source equals you know, Google something. And this may have a cookie down there that will you know, assign you some ID, so that when you come back to the website again and we, you request this pixel again, Google can track that you are the same user coming back. And you know, that you know, that's how they know whether you're a new user or a returning user. And, and so this is you know, this is an example of, of a third party cookie. You know, we went to udacity.com in our browser. But we received a cookie for google.com. You know, Udacity doesn't receive those cookies, but Google will, and, and that's how they run their analytics. And, and there are legitimate uses for this. You know, analytics is a really good example. We, you know, we use Google Analytics on. You know, we use it on Reddit and we use it currently on Hipmunk, and udacity uses Google Analytics as well so we can see, you know, what our traffic is, what people are clicking on that sort of thing. There's also more sinister uses, which is actually [LAUGH] Google is a big pro user of this. Now Google knows something about you. You know, they know that you've been to this website. And you may go to another website. You know, let's say it's, it's pets.com and pets.com, you know, returns HTML, you know, as usual, and it has the same pixel which goes to google.com. All of a sudden Google knows hey, you've been to udacity.com and pets.com because they're like a common third party here. And Google actually has, you know, between Google Analytics and Adsense and that sort of thing, they actually have pixels and presence on a huge percentage of web pages. You know they have one of the largest ad networks and so now they know this information and they can give you ads that are more relevant to you which is sometimes you know, you can argue that both ways. Oh you can say that ad's more relevant for me, so that I am more likely to click on it and it maybe that is a good thing or it is creepy that this company knows all of these different websites that I have been to. Generally we can trust Google, you can't say the same for all ad networks. So, anyway, that is kind of how they work. They have got these tracking pixels and when you disable third party cookies in your browser. You help disconnect yourself a little bit from, from that sort of tracking. And, you know, I don't mean to pick on Google specifically, because, you know, they're actually you know, not too shady. But there are a lot of shady variations of this out there. So, that's how it works. Okay, so I'm going to talk a little bit about cookie expiration real quick and then we will move on. So let's let's, let's get our cookie. Okay, so, this cookie we've been working with. I've added an extra, an extra little parameter here called Expires. Which basically gives the cookie an expiration date. And this means the browser will hang onto this cookie until Tuesday, January 1st, 2025. That means you can close your browser you know, close your tab, whatever, come back to this website and the cookie will still be there. And if you don't include this Expires parameter, the cookie will expire. When you close your browser. That's called a session cookie. A session cookie, you know, basically has no Expires parameter. And so it'll disappear when you, when you close your browser. So depending on what you want to do, you know, if you want, you know, how when sometimes you login? You know, you might, you might have a login on, on, on, on a website. That has, you know, takes a user name and password and it has a checkbox for remember me. Basically what you're triggering here when you, when you check this check-box is, whether or not to set an Expires parameter. So if you don't check it there will be no Expires parameter. And you'll be logged out when you close your browser. And if you do check it. Your, your cookie that you get when you login will have an Expires parameter. So that's generally what's going on there. You just deciding whether or not to include this extra parameter on your cookie. When does a cookie with no expires parameter get deleted from your browser? January 1, 2025. Never. When you close your browser. Or in one day from when you set it. And, of course, the answer is, when you close your browser. If you want to set a cookie that's just kind of temporary in nature, don't include an expires tag. And if you want it to last for forever, or until 2025, use the expires parameter. What I'm going to do now is I'm going to, we're going to build a little web application that uses cookies to keep track of how many times you've visited a website. And then I'll show you, you know, how to use cookies in App Engine and some, some things we need to keep in, keep in mind, so. This is the kind of template I've been working from for App Engine stuff. First thing I want to do is, is just set the content type to text so we don't have to deal with HTML for right now. Okay, so, I've added this line here that gets a cookie called visits. The way this works is we look at the request object, which is always on self. The request object will have a cookies object, which is a convenience thing that App Engine did for us, it parsed our HTP hatters and it threw all of the cookies into this dictionary-like object and we can call get on it which you know, distinct from this get, of course. This is a function we call in dictionaries to check to see if a key is in the dictionary and if it is, we get the value of that key. And if it's not, we get the default which we'll set to zero. What I want to do is I want to print through our user how many times we visited the site. Okay, so I added this line to just write to the user you've been here %s times. Remember our string substitution? And we'll print visits there. So let's go ahead and give this a test in our browser. And I'm, I've loaded my page and it says I've been here zero times. And if I reload the page over and over, it still says zero times because we're not doing any counting, we're just printing the number zero over and over. So let's go ahead and store how many times we've been to the site in a cookie. So the way we do this first we're going to take the number of visits we have and we're going to increment it by one. Visits plus equals one and then we're going to store the number of visits in this cookie called visits so the next time we come back we'll get it. The way we set a cookie in App Engine is we just set the cookie header. Okay, so I added two more lines here. Visits plus equals 1, which will increment the visits count that we got from our cookie, and then we're going to set the Cookie. So the way we do that is on the response object, there is a headers object. You know, just like when we set the Content Type. And now we want to, we're going to call add_header. We could treat it like a dictionary, but add_header here is special because remember, you can have multiple headers with the same name, and so if you used a dictionary syntax, you'd overwrite the header. So in this case, we're going to use add_header, that's what we're going to use for cookies here. So we're going to use the Set-Cookie header, and I'm just going to use, I'm not going to worry about domain and path right now. That's not what we're trying to experiment with here and we're going to say, visits equals %s, and we're going to include our Visits parameter. All right, so let's see if that works. We're on our, our browser and you know when I, and I've reloaded the page. And so we see I've been here one time, and I reload the page again. Ooh, and we see an error, and this makes sense. Need a string, int found on visits plus equals 1. Cookies you know, the browser doesn't care what datatype our cookie is here we just says that it's, you know, it's basically this, this, this string, this blob of data and here I am treating it like an integer. So let's, let's go ahead and update this code to make this work properly for strings. Okay, so, we've improved our code a little bit here. I changed our, our default zero to the string zero and so that this next line will work without exceptions. If visits.isdigit, remember that checks to see if visits is made up of only, only digits in which case we can safely convert it to an integer and we add one to it. So we increment visits every time, otherwise we just set visits to zero and that's what we print. Okay, so let's give this a whirl. So now we've got our page here, and I re-load it, the arrow went away, and we can see this counting up. Pretty neat huh, so that count is stored in a cookie in this browser. The server has no idea what the count is, so, let's go ahead and add some functionality to further my agenda. Now what we want to do, is, is let's, let's do something with this cookie value. Let's say we want to reward users who have been to our website 100 times with a special message of thanks. So let's, let's do it like let's, let's make some changes here. We'll say if visits is greater than 100, self.write you are the best ever. And for everybody else, we'll just tell them how many times they've been here. Let's see this in action. Actually so we want to, we want to do it on 100, but let's go ahead and, and test it on ten so we don't have to reload the page 100 times, just to make sure this works. Okay, so I'm going to save this, and we're going to go to our browser and give it a shot. Conveniently I'm at nine times we, reload ten times. Hah greater than ten after I reloaded it switched to you are the best ever. Great, we feel very good let's go back to our code and change that ten to a 100. So change that 10 to a 100, we go back to our browser, we keep reloading again. Okay, so we really want to see our, our special message. But it's going to take us awhile to get there, we're going to have to sit here and reload the page. Actually let's make this 100,000, okay? We're never going to get there, we're going to have to be a super loyal user to, to get up to that amount. So, what I'd like you to do is think about, how we might cheat the system a little bit. We've got our page and we want to, you know, see our thank you message, because we need validation. So what can we do to get 10,000 visits? Can we reload the page 10,000 times? Can we send the link to 10,000 friends and have them load the page for us, or can we edit the cookie in our browser? And, cheat our way to the top. And, check all that apply. So of course yes, we could reload the page 10,000 times. That might take a while and that would make this a very boring quiz. Send the link to 10,000 friends. Well that's not going to really work, right? Because if we send the link to 10,000 friends they're going to be in 10,000 different browsers. And they're all going to have their own Now, their own cookie with their own counts. So, that's no good. Or we can just edit the cookie in our browser. Which is the answer that I'd like to talk about. So, let's go ahead and see if we can do that. Okay, so here we are on our browser. I'm going to open up those developer tools again, which in Chrome that's just an, an option. And I think Firefox has fairly similar options. I don't know about Internet Explorer. When I get this little JavaScript console, and we don't have to know JavaScript but I am going to show you one thing we can do. I say document.cookies, cookie. I can actually get a list of all the cookies in JavaScript. And then I can actually say document.cookie equals, visits equals one. There are ten thousand and one. Okay, now I've just set that cookie. Trust me. And when I reload this page. Thank you web server. You are the best ever. Pretty neat huh? We just cheated. So, let's say we actually want to implement this feature, and we didn't want people to cheat. Let's talk about how we might prevent people from doing that. Okay, we are going to talk about a technique called hashing, and hashing is a technique we can use to verify the legitimacy of, of our data. So, what is, what is, what is hashing, what is a hash. Basically a hash is, is, is a function, now let's call it H, that when you apply this function to some data, you get Y. Now, so we'll say X is some data basically you know, ultimately a number but you know, it's, it's you know how data is presented in a computer. Most of our functions will be dealing with string and it returns this value Y, which is a fixed length bit string. Usually you know on the the order of. Now, depending on the algorithm, 32 to 256 bits, you know, are the, are the the algorithms we'll be dealing with. It, it can be arbitrarily length, but the, the kind of common functions we'll be dealing with basically take X you know data X of any size, you know, some big, long bit string, and returns a function, or returns a value Y that is fixed length. and, and hashes have a lot of uses. And they have a lot of properties too. So let's talk about some of the properties of this hash function H. Okay, so generally, a property of a hash function. A good hash function H is that for a particular value of Y. For a particular output. It's really difficult to find an X that'll generate that Y. You know there is, it's, it's very difficult to find a piece of data that hashes to something specific. Likewise, it should be infeasible, you know, practically impossible to find a particular input X. For particular output Y. So if we hash some value into some you know, other value Y. We take that other value Y and we cannot reverse this. This means it's a, a, a one-way function. Another property of a hash function, a good hash function, is you can't modify X without significantly modifying Y, and. Generally you want if you just change one bit in X, which could be you know, thousands of bytes long, you want Y to be completely different. And again, this, this you know, kind of hinges on some of these other properties as well. But basically the whole idea is that for any particular X, you get a unique Y. You can't get the X from that Y, and changing the X just a little bit gives you a totally unique Y. So, there's very little correlation between X and Y. You know, each of these properties has a vocabulary word associated with it and some more rigorous explanation. And if you would like to learn about those things, you should take CS387, which is applied cryptography. And this is you'll learn, you'll learn about hashes to death, we're going to use hashes quite a bit in this lecture because it's a really handy way of verifying data. There are many popular hash algorithms and, and, of course, you can write your own, but you should never write your own. The first lesson you'll learn in, in CS 387 is don't write your own, at least for our purposes. Of course, if you're building a hashtable, you know, you can, you can do whatever you want. But if you're going to use it for security purposes, don't write your own. Then, you know, if you want to learn how to make a hashtable, knock yourself out. Of course, somebody's probably already done it better, but hey, you never know. So anyways, some popular algorithms are crc32, which is basically designed for for checksums. If you were to send somebody a bunch of data, you know, like a big file you know, you might also include a crc of of, of that file and that, you know, is, is basically just a simple way to verify that you've got the entire file and it's not corrupted because you know, you can send a c you can send a hash easier than you can send a whole file. You know, you can copy and paste a hash, it's just a few bits. You can verify that the file that you received has the same crc as the file they sent. And then you don't have to, you know, verify bit for bit that you have the correct file. So, crc is really fast. Its really, its really only purpose is for doing checksums, basically creating a hash of a large file. Its security properties are not very good. It's very easy to find what we call a collision, which is when you know, when, when, when two things hash to the same value, which is, you know, the whole point of a hash is that we can get a, a different value for almost anything that we're going to hash. Now, obviously if, if the size of the input is substantially greater than the size of the output yes, there are going to be collisions. The whole point is that it's hard to find them. And with crc32, it's very easy to find them. The reason you'd use crc is because you don't care about collisions, you just care about speed. And crc is very fast. The most popular hashing algorithm out there is still md5, which used to be used because it was both fast, you know, ish, not as fast as crc32 but pretty fast, and people you know, thought it was pretty secure, except it's not. Md5 has been broken repeatedly over the last few years. And it's very easy to find md5 collisions. You know, given you know, an x that hashes into a y, it's very easy given this y to find another x that hashes into it which is, as you'll see, a big problem. So, we won't be using md5 for much at all in this class. Well, it, it has its use cases, right? If, if you have a limited input it's hard to find a collision. The certain class of attacks, you know, when making x longer and longer and longer and longer, that's a really easy way to find a collision in md5. But if you limit the length of x, then you, you, you don't have to worry too much about that vulnerability. So, anyway, just keep that in mind. When you really care about the data, don't use md5. The second most popular hash is called sha1. This is not as fast, but it's fairly secure. Just now are we starting to kind of hear, you know, demonstrations of people finding collisions in sha1. It's still pretty good. It's, it's actually is the second most used hash behind md5. But for things going forward, you should really use something like for example sha256, which is, as you might guess, just kind of a bigger version of sha1. It's actually not the algorithm I believe has changed as well. So we'll say this one is secure-ish and this one is pretty good. It's going to it's going to take some time. Now, of course, the, the trade off is speed, you know? So the, the better hashing algorithm right now, the slower it is. So these are kind of, these are basically organized in cost and in security. So, no big surprise there that there's kind of an inverse correlation between cost and security, but that's the name of the game. So depending on what problem you're working on you may to need, may need to actually make a decision. But, for our purposes, we're not going to get a whole lot of traffic. We'll probably sha256 for most things. So, let me show you how you would use this. I am in a terminal. I am going to fire up python and I am going to show you how to use python to do hashing for you because we are going to be doing a lot of this in this class. One thing we can use is hashlib. Hashlib has a couple of hashes available to you. You have md5, shaw1, 256. Those are the ones that we just talked about so let's go ahead and get the md5 of something. The way we do that is we say. X equals hashlib.md5 and we say. Now X is this hash object and the way we get something useful out of this is we call the hex digest function on them. If we call hex digest on the result of md5. We get this string. And this is the md5. Has of the string Fu. And if I were to change, let's do this all in one line. Let's say hashlib.md5, hello, hello. Whoops, hello, hello, and call Hex Digest on it. We can see our hash. Now, if I were to just change one of these characters, let's say it changed to a capital O We can see our hash completely changes. See we had f five two blah blah blah two six three here. So that's a neat property of this particular hashing function and if we were to change this back to hello hello we get our original hash. What's nice about a hash algorithm like M d five its available on every system and if I type if I you know hash hello hello On any system with MD5, we're going to get the same result. Thats pretty cool. Okay quiz, do what I just did in, in your own python terminal. Use the hashlib library in python to find the sha256 hash of the string udacity where udacity is all lower case and enter your answer here. Okay. Now, of course, the answer is a bunch of hex characters that I'm not going to type here, but I'll go ahead and show you in the terminal. Here I've imported hash, hashlib. hashlib.sha256 of the string udacity, returning the hex digest, is this big long string here. So, if you did this, now you know how to take hashes of, of simple strings. And, of course, you can send more than simple strings in here. And get a hash that in this particular case, it is 256 bits long. This is the hex representation so obviously it's not that many characters. Of course you can put whatever you want in here and the output will be 256 bits cause that's what sha 256 does, and of course if we were to change our string just in the slightest, we get a totally different hash outlook, so we can use this technique now to solve some problems we are having in our cookie application. Okay, so. We've got this new technique for that, that we just learned. About a hash thing. So we're going to use this and our cookie to prevent people from cheating. Remember we had that example where it, it kept a count. And we want to use hashing to verify on, if that count is valid And the algorithm's going to look something like this. So instead of just saying set cookie visits equal five, which an, anybody can edit, we're going to add a hash to this. So we're going to send something like this instead. Set cookie equals five. We're going to add something on the end of this. So we'll add a comma, and then we're going to add a hash of the value here five. So that, a would be cheater can't forge a cookie without knowing what hashing algorithm we used. So we sent this cookie with five followed by, you know, our hex string, you know, abc one, two three, it'll be whatever the output of our hash was. When we receive this cookie from the browser, we'll receive this five, you know, followed by our hash, what we're going to do is we're going to break this apart into two pieces. You know this will be like our our value and this will be our hash. We're going to hash this value and check to see check to see if it equals this hash and if it does, we know this value hasn't been tampered with and if it doesn't, we know the cookie's invalid and we can throw it out. So our codes going to look something like this. We we split apart the cookie value, based on this comma into two parts, value and and hash and then we rehash the value and if it matches the one we sent we know that our cookie hasn't be tampered with. Okay, so time for a quick quiz. What I'd like you to do is implement this function make_secure_val. This just takes a string, which in this case is going to be our cookie body and returns that format we were describing before which is going to be S comma and then the hash of, of that string. And we're going to use this function, hash_str, which right now is just using MD5. We're going to, I know I told you MD5 is secure, so we are going to improve this, but for right now we're just going to use MD5. So go ahead and implement this function. Good luck. Okay. So here's my implementation of the function. It's pretty simple. We just return, you know, we take s and we include it in a string with a comma, with the hash version of s using our hash_str function. So you know, %s,%s and we include s and the function hash_str(s). And here we go. And, and our output is the string cool and then. And then the hash alright pretty neat. Let's make this a little bit more complex. Okay. Next part of the quiz. What I'd like you to do is implement this function called check secure val. Which takes the string h and that's of the format you know, s comma hash. Which is you know, the output of mixed secure val. And verifies that s equals, or, or the hash of s equals the hash included in, in that response. And otherwise returns none. Okay so, here's my implementation of the function. First what we do is we take we, we take this value H, which has this format and we split it on commas. And we take the first part of that we store that in val. And we say if H equals make_secure_val of val, return val. Val is, is what, is, is the, the, the s part of what we passed in, and we want to make sure that if we run this function on that value again, that we get, what we passed in to this function. I could've structured this differently. And looked at all of the parts of h, and then called hash_str again. But if we funnel everything through make_secure_val, updates to this function will be easier going forward. So, because I, I have the advantage of knowing if, what going forward is going to look like. So let's give this a test. The first thing we're going to do is we're going to call make_secure_val on, on some string. So we'll go ahead and give that a run. Okay, we've got the string and now I'm going to copy this, and we're going to replace this with check_secure_val. And we're going to pass in that string, and now we should see the output Udacity. And let's see if that's the case. Yes, we do. Udacity, that works. Now what happens if we if we modify this a little bit, you know, we add an extra exclamation mark? And, and I click Run. We get nothing back because Udacity didn't match the hash string. Likewise, if we restore our string and we change the hash, I'll just get rid of this character, then run it, we still have none. And I'll add that, that 2 back and run it again just to make sure everything's working, and we see Udacity. Okay, cool nice work. Let's go ahead and use these functions on our program. Okay so we are going to go ahead and restructure this program a little bit to use our new secure functions. You can see I've, I've got them here. The three functions that we were working on in those quizzes. Let's go ahead and use those. So the first thing that we want to do is we are not going to store these visits in a variable called visits anymore we are going to call it visit cookie dough. Equal get visits. 'Kay. And we're also, we're going to make a new variable for actual visits count. I'm just going to give by default, be zero. And then we say if visits, cookie val, basically if it's not none because get will return none if that cookie doesn't exist at all. Which is whats going to happen if the users never been to us. We're going to run our check secure valve on this visit cookie stir. I renamed this variable to visit cookie stir and the result of that we're going to store in cookie val and remember if cookie val remember that function returns none if it wasn't valid. If cookie val visits equals int. Cookie Val. So we set visits to zero by default, we look up our cookie. If we have a cookie at all. We try to decode it using Check Secure Val, and if we got a result back from that. That's our valid result, we convert it to an integer and we sort in visits. So visits is. is either zero or what we got in the cookie. We don't need to check Any more if its a digit because we're going to assume its valid so we're going to say visits plus equals one because know we know its valid, nobody's tampered with it. This integer should have worked. Now we need to update our new our new cookie value. So we call our make secure val function. We gotta convert visits to a string before you send that in and then we are going to send that to our header. Okay, so we made these changes, let's go to our browser and give it a try. So we're in our browser, reload our page. The physi cookie has whatever we left in it before 10,001 or something which isn't going to be valid because there's no hash. So we reload the page and we start seeing our counter, but you can see our, our feature's working now. You can, you can see our counter's working. If we look at our cookie, you can see it now stores the number. And it has the hash. Notice it's got a pipe here, I notice a little snafu with Google app engine when I was working on this where a comma and a cookie had some special meaning so I changed our function to use the pipe character instead of a comma because I was getting a bug. Here are my cookie str didn't have anything after the comma. So, I have switched from commas to pipes and that is what we will use for the rest of the lesson. Back to the browser. We can see that we, we have this cookie. If we were to mangle this cookie a bit, by saying this equals 10,001 and then we will use this same hash like this. 10,001 and reload the page. It resets us back to one. Because our cookie wasn't valid, or at least the number and the cookie didn't match the hat, match the hash. So because the check secure val failed, we reset visits back to zero. Or, actually what we, we never set it to what its true value is. What we're doing now is we're storing, we have a cookie that looks something like this. And on the service side when we receive this cookie we make sure hashing one gives us this has value, and if it doesn't we throw it away. Now, does this really solve our problem? A little bit, but if they, you know, if this, if they know we're using MD5, which is, you know, pretty easy to guess, it's easy to forge a cookie, right? You can just, change the cookie value to whatever you want, run MD5 on it, append that, and now you've forged the cookie. So, how do we solve this problem? Let me show you. What we need to do, is we need to add, we need to have some secret knowledge here. So instead of hashing, you know, the number one into our hash, what we want to do is we want to hash a secret string plus the number one into a hash. So as long as this secret stays secret a would be attacker even if they know our algorithm won't be able to forge a hash. Because remember one of the properties of a hashing algorithms is it's very difficult to find, you know, find two inputs that equal the same hash. Or to find a specific input for a specific hash and, and vice versa. So, you know, they'll see in our cookie, you know, they'll still see a cookie you know, the browser will still see a cookie that looks like this, but instead of hashing this one we added an extra little secret. And as long as the attacker doesn't know the secret they won't be able to generate the same hash. So let's build the this functionality in bit by bit. There's one, one last thing in Python I want to introduce you to. So we've been using hashlib to run basic hashes. There's a second library, specifically for doing message authentication called HMAC, hash-based message authentication code. This is basically a, a special algorithm. It's built in the Python, for when you want to combine a, a key with your value to create a hash. There's a series of different types of attacks where you, you know, if you just put your key plus the value you can find a collision by just kind of extending your value. And similarly, if you put your value and then the key there's, there's other attacks you can do. An HMAC is basically just an algorithm that you know, looks something approximately, like this: hmac, a secret, a key, hashing function, returns a hash. So it, it'll, it'll look just like using hashlib, except it'll take an extra parameter for secret, which it'll incorporate in a secure manner. Now, you could just call, you know, use a hashlib function, with, you know, secret plus value. And that it gets you pretty close. And for our purposes, it'll actually probably work just fine. But HMAC is, is the proper to thing to use here. Again you can, you can learn more about HMAC you know, on Wikipedia or something. There's a wealth of information of what the algorithm actually is. But it's basically a special way of using a particular hashing function with the secret key. I'll show you that real quick in Python how we, how we use it. Okay, let's review some of the things we've talked about. If we were to make a hash the way we've been doing it, you know, we'd use hashlib. I'll create an MD5 of a string. And call Hex Digest on it and we get you know, the hex output. We can use the HMAC library to accomplish something sim-, similar but HMAC takes an extra parameter for a secret and combines it securely. You know, we could say hmac.new and we give it a secret. Then give it udacity. We say hexdigest. And, and we get a, you know, we get a similar output except this is more secure. Of course we could have done something like this. Secret plus udacity. And as long as secret stays the same, when we verify you know, our algorithm will still work. But, hmac is just basically a more secure way of accomplishing secret plus udacity. Let's use this new hmac function and a new secret key to improve our make secure value function. Okay, what I'd like you to do for this quiz is, implement the hash_str function. Now, remember, the previous version of this used hashlib and MD5. Now, I want you to use HMAC and our secret instead. We're not going to have to change our make_secure_val and check_secure_val functions, it's just going to get a little bit more secure. So let's go ahead and give that a try. Okay, here's my answer. All we had is, is a simple change. We just changed that function, instead of using hashlib md5, to now use hmac, and pass in our secret, plus our string s, and return the hexdigest of that. Now, this is actually quite a bit more secure. So, as long as we have a secret that nobody knows, and normally this would be a long string of random characters that you generate and probably store somewhere else in some other module, even if the attacker knows our algorithm or, you know, watched this, this lesson as long as he doesn't know what the value of secret is, he can't produce fake values. Let's go ahead and give this a test. We're going to say, print make_secure_val test. We'll give this a run. And we see output, our value plus our hash. And let's, let's make sure this works properly, so we'll send it to a variable and we'll say, print check_secure_val x. So we take what we outputted here and run it back into our function, and we see that we get our result. And if we're to modify x somehow, add some junk to the end of that string, we get back nothing. So, with just a quick a quick simple change, we add, introduce this notion of a secret. Now somebody who knows our algorithm still can't make fake values. So let's go ahead and try this out in practice. This is our old code, I want to demonstrate the vulnerability in our old code so we can make sure we fixed it. This is the old code running here and if we were to take a look at this. We're going to modify our cookie. Document.cookie. That is the value. Let's say we want to set this to visits to 10,001. First we need to find what the hash of 10,001. We can use python for that. Lets go ahead and try that real quick. Import hasLib, hashLib.md5.("10001").hexdigest, 'kay. We'll take this value here. Let's take that with us into our browser. We're forging cookies here. So we're going to say documents.cookie equals Visits equals 10,001 pipe our new hash value, now when we reload this page, we are the best ever. But we're not the best ever, we just cheated. Okay, so, let's incorporate the new functions we just wrote into our code. So here we are in our editor, and I've plopped in our new function. We're going to, move secret out of the way. We are going to pretend it is actually in another module that you don't publish or share. And now our functions should be as good as new. Let's try this, let's try this out in our browser. So here we are in our browser, we have dropped in a new hashing function so our old cookies are going to become invalid and when we reload the page you can see we've been here one time. If we were to inspect the cookie, document.cookie, we see that we have this cookie. Now, it's got the same format at the previous cookie, except this one is very hard to forge. Without knowing that secret, we, all we can do is guess at the hash. And that's. You know, the property of the hashing algorithms is that that is basically impossible to get correct. So if I were to modify this cookie, document the cookie equals visits equals 10001. I mean what value do we even put in here. I mean we can iterate over, you know, every possible hash and just kind of guess at it and maybe get lucky. But we'd have to get extraordinarily lucky. You see, I reloaded the page and reset down to one. When I mean extraordinarily lucky, I mean we'd have to you know, take more time than there are you know, atoms in the universe to figure it out. So, that's not going to work in our favor. Okay, so that's pretty cool. I just want to summarize that algorithm so, so it's clear what we did. Instead of setting the cookie visits equal 1, which can be easily forged And instead of setting the cookie visits equals 1, and then the md5 of 1, which can also be, also be easily forged if you know that we're using md5. We instead set it to visits equals 1 pipe HMAC, Secret comma 1. And as long as we keep this secret secret, they can know our algorithm, they can know what we're doing, they can even see our code and they won't be able to forge invalid cookies, which is a pretty neat property. We use this all the time because imagine, if we're not counting, instead of counting visits, we're counting user IDs. It would be a real big problem, you know? If, if I'm logged into, you know, my mail, my Gmail, and I've got a cookie that identifies, you know, who I am, if somebody could just say, well, you know, my user ID is Steve's user ID, and then, if he logged into my email, that would be a very big problem. So, that's why you do things like this. This prevents people from forging your cookie. And also, it saves you some effort validating on the server side, because if, if this doesn't validate, you don't have to check to see if the string is all digits and that sort of stuff because you know, it came from you, you know what you set it to, and that makes your life a little simpler. So this is a really popular strategy we're going to use for all sorts of things in this class. Okay, so we spent a lot of time talking about how to use hashing and, and the hmac variant of hashing to make cookies that won't be tampered with. Let's talk about using passwords for hashing. So, say we have a table for users in our database, and this table has a couple columns. One column is for the user's name. And another column is for the user's password. If we wanted to verify a, a user is valid we might have a function that looks like this. You know, and this would be called when somebody logs in, and it problably say like, user, you know, equals get user, where this is some function that gets the user from the database. And then we'd say, you know, so if this user exists and this user's password equals pw, what was passed in, return user, and that's, and that's simple enough. Now, the problem with this approach is that if your database gets compromised, you are in trouble. You gave away all of your users' passwords. Which means, not only are your users angry, because you compromised their privacy your website is in trouble, because you've got bad guys logging in, screwing around with all people's accounts, because they know everybody's passwords. So that's a really bad situation. So what we want to do is, instead of storing these plain text passwords in our database, we'll store a password hash in our database. So we'll have h of hunter two and h of Metallica. And if our database is compromised, all the attacker has is a bunch of a bunch of password hashes, and you know, it's very, very difficult, basically impossible, to turn the hash of this into the actual input parameter. This this function changes a little bit, so instead of comparing pw to the password field in the database, we compare hash of pw to the password hash in the database. And all a sudden we're in a much better situation. This takes very little work, and your database doesn't have any plain text passwords in it. And if your database does get compromised, all the attacker has is a bunch of hashes and not a, not a bunch of valuable passwords. So, this is a very important strategy that you should employ when building user registration systems, such as on this week's homework but before we get there, let's do a quiz. Okay, quiz. Why do we hash passwords? To keep snooping sys admins from knowing everyone's passwords? Because people often use the same password for many websites. If the database is compromised, the passwords are reasonably safe. Or, you'll, if you don't hash, hash them, you'll regret it. Check all that apply. The first answer to keep snooping sys admins from knowing everyone's passwords. That's actually correct. That's there's no reason why you as a website owner should, you know, know your user's passwords. Or maybe there are a few reasons but not very good ones. And this, you know, eliminates a whole, you know, issue that you have to worry about. Because people often use the same password for many websites. This also correct answer. I wish people didn't, and you may think well, it's not my problem. But, if you're accepting user's passwords you do have a bit of a moral obligation to keep them safe. Because no matter how loud you yell and scream, people are going to continue to use the same password, allows the passwords for many websites. If the database is compromised the passwords are reasonably safe, this is also true. They're not completely safe of course. You know they have your database now, they know what those hashes are they can figure out the passwords in some potentially huge amount of time. But it's a lot safer than just giving them the passwords. And if you don't, you will regret it. This is also true. And I'm going to share a tale of, of me goofing on this and how much I regret it. Okay, sad story time. So, in the early days of Reddit, I stored passwords in cleartext, because when I was writing Reddit, I didn't think anybody would actually use it, let alone a lot of people. So, as we grew, I had this little bird in my ear telling me, you know, this is bad, you should fix this, you should hash these passwords. I knew better, but I didn't because we actually got some benefit out of clear text passwords. When spammers would come to Reddit, they would create thousands of accounts, but they would use the same password for every account. So I was able to catch these huge webs of spammers. Now the downside of this, is if somebody had stolen my laptop. I'd be in trouble. And sure enough, somebody stole my laptop, and I had all of Reddit's usernames and clear text passwords on it, and I got in a lot of trouble over that. Now, this would've been an easy fix and it turns out, you know, after that it was an easy fix. We just went through and hashed all the passwords like we should have, but it's very important that you, as a developer, take care of the user's data, because. They use the same password on lots of sites, they probably don't really know better and, you know, it's easier for them to be lazy than for you to be lazy because you can solve it for everybody. So, always hash your passwords take care of your user's stuff and you won't regret it like I did once upon a time. Okay. Is it really, really embarrassing to have a database stolen with plain text passwords. Check yes or no. The answer, is yes. I've been there. You don't want to be there. Pass your passwords. You can save yourself some embarrassment. So, passwords are hashed. Are you completely safe? No. Sorry to lead you down this path. We have, we have more to do. The problem is, there are, you know, a handful of good hashing algorithms that people would use for this sort of thing. You know, let's, let's, let's pretend we're using SHA-256, because that's a pretty decent algorithm. If somebody were to go through and create a mapping of every word to the hash of that word. That would be a problem. because remember the whole strength of this hashing problem is that it's really hard to get from the hash to the plain text that led to that hash. You know, to, if you have H of a, you know, the hash of a. It's really hard to figure out a. But if you've got already computed it for every word, and all you have to do is you know compute at once and create the inverse table. Once somebody has this table of all this words computed once, they're done. You know, if you created a mapping of you know the SHA-256 of every word to the original word, all of a sudden you get, you get a database of a bunch of SHA-256 passwords. You can look up what the password is instantly. And this table has a name. It's called a rainbow table. There are these things, these mappings, these databases of a hash version of a password to the clear text password, they exist. You can Google for a rainbow table for a hash algorithm of your choice, you know, download that hash table or, you know, download that mapping, turn it into a hash table and you're good to go. There's a very simple way to get around this. You may remember from our cookie approach, that all we have to do is add in some secrets. But we don't want to add in the same secret over and over again. Otherwise, you're basically vulnerable to the same fairly similar technique. So what we do instead is we use something called a salt. So in our user table, we're storing our name, and we're storing a hash of the password. Instead of storing just a hash of the password, we're going to add. A secret to it. It's similar to how we did with the cookies except this is not really secret. We're just going to say this hash is going to equal our hashing function of the password plus salt. And this salt, instead of, so this looks very similar to what we did with the cookies. Right? We were using HMAC and, and we had a password, and, and a secret. Except the salt is just. It's just some random characters we make up. You can make them up and you store them in the hash field, in the clear. So, in this field, we'll, we'll actually have the hash. Now this abbreviated as H and right along with it we'll have the salt and what this does is, is this prevents this quick lookup from working because all of a sudden we've added this these random strings. So, instead of saying hash of a equals a, we have to figure out what's, well what's hash of a you know, plus the salt. And all of a sudden that table's completely invalid. So, when you store a user. You know this is the type of algorithm you can do. Now, outside of this class I want you to think very hard about doing this yourself. You know as with all crypto you should probably not being implementing it yourself because people have thought this through. They have done it securely and you are not yet qualified to do so. I want you to think very hard. About using third party libraries, because a lot of third party libraries also get this wrong. So, basically, think very hard. You want to get this right. There's a couple more things I'll tell you to look for when you're evaluating a third party library, but a lot of them really screw this up, and you don't want to just trust them blindly, so. You know, I'd rather you do it yourself knowing how to do it than you trust a third party library blindly, but the best knowledge you can have is what to look for in a third party authentication library. Let's go ahead and implement some naive functions for, you know, hashing and salting a password so you can see how the, the flow works. And then we'll talk about some of the things you should look for when you're evaluating you know somebody's approach. What I'd like you guys to do is first implement a function make_salt, that returns a string of 5 random characters. Python has a random module that has a variety of functions that can be useful to you here. So you may have to look that up. But what I want is just a string of, of, of 5 characters. And every time we run this function, we want to get different results. Okay, good luck. Here's my version. I'm using the string module as well which has this handy little thing called string.letters which is just a bunch of letters. And then I'm using the random.choice function which chooses one value from a list and returns that. And then we can join it all together in a string using join. And we're going to do that five times. Okay, so if we run my function it looks like this. And if we run it again. We get a different result and if we run again we're going to get an even different result, okay, so this is a cool little function for making our salt. The next step in this password hashing adventure is to implement this function called make password hash, make_pw_hash. Takes a name and a password, and it returns a hash of the name, password, and salt, concatenated, plus the salt. Separated by a comma, I'd like you to use sha256 so, okay. Go ahead, good luck. Okay, here's my version. First thing we do is, we call our make_salt function. We imported hashlib so we can have SHA256. And so, first I create the hash, this part of the response. SHA256 of name plus pw plus salt. Call hexdigest on that. And then I, we return that, and the salt separated with a comma. So let's give this a whirl. We run this function and we see we get this nice hash and we get our salt and if I were to run this again, I should get a completely different hash and a completely different salt. There we go. And I can keep running this and keep getting different answers. So you can see the salt basically adds an extra bit of randomness to, to what we're going to see in our hash. And it prevents a, a would be attacker from pre-computing all of the possible hashes. And it also prevent a would be attacker from you know, of course seeing all of our plain text passwords. So now we've got a reasonably decent password hashing thing. There's a, we need to write one last function in this. Let's go ahead and do that. Okay, the next phase of our quiz. So, we've previously wrote this make password hash function that takes a name and a password and that returns a salted version of that password. Now we need to write the next version the next function, which is going to basically take a name and a password as if a user entered it you know, on the login form or something and a hash value from our database and returns true if they match. Now, you're going to have to modify, make password hash a little bit for this to work. See if you can figure out how. I'll, I'll show you what the test case should look like. You should be able to say h equals make_pw_hash, name and password, and then you should be able to say valid_pw spez, hunter2, h. This should print out true if you if you, if you have a valid hash. Now, remember, in our previous demo, to give you a little hint when I was running make password hash with the same inputs over and over, I was getting a different result every time. That's because we're making a new salt every time. So see if you can work around that problem. Okay. Good luck. What we have to do is, I needed to change make password hash a little bit to take in a salt parameter. because we don't want to make a new salt every time, we only want to make a new salt when we're making a new password hash. But if we want to verify our password hash, we want to pass in salt as a default parameter. Or, salt, or pass in salt as a parameter. So, what I do is, I pull salt out of the h by splitting on a comma and taking the the second part which is the salt and then I pass that into my function. Now, you could have also implemented this by just copying this line into valid PW, which I guess this should have said. May need, but it's always better if you can reuse a function like this, so you don't have to you know, if you want to change the logic here, you don't have to change everything here. Let's go ahead and give this a run. You can see it says true. And if we add an extra print statement here, print h. And now we give this a run. We should see our what would store on the database. Here we go, there's a hash, there's a salt. And we can see that it matched. And if we were to run this again we'd see that we get a different hash and salt but it still matches. So, pretty cool, huh? Let's discuss one more thing about password hashing. One last thing about password hashing. You know, all of this is, is, is, is good to understand. And most modern computers hash passwords in just the same way I showed you. Generally we, you can use SHA-256 that works okay. The problem with most hashing functions, is that they're designed to be fast. So generally this is a good thing. You know, if, if you're going to be using this hashing function, you know, to be verifying your cookies and what not. Yeah, you want it to be fast, you want to slow down your web server verifying, you know, cookie data all the time. But for cases like passwords, when it's much more likely that somebodies going to be trying to brute force you. It would be really cool if we had a hashing function that has both really good, like SHA-256, but also kind of slow. So that computers get faster and faster, the hash function stays the same speed. And, I'm about to tell you about such a function, it's called bcrypt. The reason I didn't use it in my last example, is because it's not built into Python. So it's not super convenient for me to demonstrate. And I, and I don't want to have, you know, expect you to install it. But you know in the future outside this course, instead of SHA-56, use bcrypt instead. And your life will be better. And what bcrypt, bcrypt is cool, it basically takes an extra parameter, which is. How long do you want this to take? and, and it's neat, so now you have this function that will stay slow forever. Because you can make it slow. One final password thing. I know I promised the last one was the final one, but we've got to mention this. We know how to store a password securely on the server. We still have this issue that if you type in a password, remember how when we did the forms, I showed you that you could type in password in a password text box. You know and, and it looks like little, little circles or little asterisks. And that even when you, when you submit this in the URL, you could still see, remember we saw q equal to hunter 2 before when we're playing around with that. Submitting a form to go back to our trusted picture, you know if you're submitting this password to these servers, the password is actually sent in clear text over the internet. So you're storing the password securely on your server. If your database gets stolen, you know you're covered pretty much. But the problem is when the user logs in, they're actually sending this password [INAUDIBLE] of the internet. So if you really, really care about that, about having the password encrypted the whole way so some bad guy in the middle can't just, you know, sniff the password off the wire, you use HTTPS. And all HTTPs is, its just like HTTP except it is encrypted over SSL. That means this whole communication is encrypted, so this man in the middle in theory, unless he's hacked very sign, and they never get hacked, can't see what's being transmitted over the wire. So it's all gobbledegook to him. So anyway, that's what HTTPS is for. And if you really are, if you're building something that's secure, you know, perhaps not a blog, but you know Gmail for example, you want to be using HTTPs. And then you've got secure transmission from the browser to the servers, and you've got secure passwords on the servers. And you're in a reasonably good setup. Okay, let's, let's end this section with what I hope is a fairly easy quiz. Okay when given a choice, which is the best hashing algorithm to use for hashing passwords; md5, Sha 256, HTTPs, or bcrypt? And the correct answer, and this time there is a correct answer to the best question, is bcrypt. Use it, learn it, love it. You may find yourself intim, implementing an algorithm like I described before because a lot of frameworks to be honest, get this wrong but, make sure you're using bcrypt. There is a python module for bcrypt. There's I don't know, there's, bcrypt exists for almost everything, so. There you go alright good job guys that's that for now. Welcome to lesson five. In lesson five we're going to talk about how to make your website communicate with, not just with humans but also with other computers by building what we call an API or Application Programming Interface, which is really just a fancy way of saying instead of generating HTML that we send to browsers that ultimately just get read by humans, we're going to send data in formats XML or JSON which are similar to html, but are designed to be read by computers instead. In this lesson we're going to add a feature to ASCIIChan, that will actually allow you to see where users are submitting images from, using the Google maps API. And in the homework for this lesson, we're going to be adding the JSON output to your own blog. So if somebody wanted to build a service that used some data from your blog that you thought was important, they can actually write a program to fetch your blog, manipulate the data however they like, and then build their own web service on top of that, which is actually how a lot of the internet works. So, let's go ahead and jump right in. Until now, we've been working with this kind of standard picture of this little guy and his browser. Now, this used to be you, but now this is the user. You have upgraded to the other side of the picture where the servers are. So let's get these boxes. We've seen these 100 times. Okay, and let's add you over here. You are now the programmer. Congratulations, you are a web developer. We can talk about users and how much trouble they cause us. Now, in a normal web request, the user makes a request to the servers, and we respond with the response. No surprises there. Now, what we're going to be talking about today is when your servers start making requests to other servers. So this is our website. It runs on these boxes. Let's say we're going to hit somebody else--Twitter, for example. They have their own servers. Their servers are probably on fire, because it's Twitter. So we can have a web page that actually makes requests to Twitter. These are our computers talking to their computers. This happens all the time. They're still communicating over HTTP, and Twitter still responds as usual, but if we're writing some web program that, for example, does some data analysis on Twitter, the user might make a request to us. We might make a request to Twitter servers, they respond with what their response would be normally, and then we may manipulate that data and return it to the user. And this is actually a really common case. What I'd like to do now is actually explain how Hipmunk works a little bit, because we do a lot of this type of communication. Okay, let's change our picture a little bit to be a little bit more about Hipmunk, because I'd like to explain how our architecture works. So in this case, this is still-- we call users customers when they're actually paying-- and this is me--Steve--and this is Hipmunk servers. When a user does a flight search, what we do is we hit a bunch of our data providers where we actually get our flight data from. So the first thing we'll do is we'll take your flight search and we'll send it to ITA, we'll send it to an airline, and in some cases we'll even send it to Amtrak, if that's appropriate. Each of these guys are their own-- these are companies who have their own services that we work with. So ITA will run our flight search, and they will send us data back. The Airline, too, will run their own flight search on their own system and they'll send it back to us. And Amtrak will do its thing and send their data back to us. So then on our server, we have all this flight search data, represented by this blob here. We will manipulate all this data, collate it, make you nice results, and then we'll send back our HTML response. So what we're going to be working on in this unit is how do we make our server speak to other servers when there's no browser involved. We're still using HTTP, but we are now communicating over other protocols. We saw some of this in Unit 1, but we're going to be doing a lot of it in this lesson, because there's a lot of cool things you can do when you realize that you're not the only service on the internet. Okay, so what I'd like to do now is I'm going to go into Python, and we're going to play with a Python library for actually making an HTTP request so you can see how that works, and then prepare for some quizzes. So in Python we have a library called urllib2. There's also a urllib1, and this is kind of the evolution of Python in front of your here. We're going to use 2, for the most part. urllib1 has a few handy functions of its own, and when we use those, I'll include those in documents. But anyway, urllib2 has a function in it called url open, and we can give a url here to download. So let's say I'm downloading google.com. Actually, I need to make sure I save this. I usually save it in a variable called P for page. Probably not even the right concept, but that's my habit. I always use P when I use url open. So if you run this, we're going to get this P object, which is actually, basically, a file object. In Python, file objects-- basically, what a file object is, is an object that has a read method. And you can call a read on there to get the contents. So I'm going to show the contents in C and call read on P. Okay, we called url open on this url, storing it in this variable P, and then we called read on the response and stored it in a variable called C. Now, if we were to evaluate C, a wall of text, which is what we expect. So this is actually Google's front page. If you remember early in this class, we basically accomplished the same thing using telnet or curl. You can also do the same thing in Python. So now we have this variable C that has this whole response in it, and we can manipulate it in our programs, which is what we're going to be doing a lot of. Let's take a peek at what we have on that P object. We can use the dir built-in function in Python to examine an object. So now we can see the methods and attributes on our P object, and we can see a couple of them that are probably interesting to us-- headers, for one, and get url is another. Get code is probably the status code. This is generally how I work. When you don't know a library super well, you can use dir to kind of examine the object. So let's take a peek at a couple of these. We've also got a url one. Let's see what's in there. That's the url we requested. No big surprise. We can look at the headers. So this is an HTTP message instance. Now, I happen to know that this is a dictionary, and dictionaries have a function on them called items. If we were to run items on this in Python, this is what you can call in any dictionary--items-- to view the keys and the values, and it will actually print them, generally, nicely for you. We can see all of the headers we got back from Google. This is an actual dictionary, so we can say p.headers, for example, content type, and we can see the content type that we got back from Google. It's actually kind of interesting; we're getting an ISO charset, which is--I was expecting UTF 8, but, hey, you learn things every day. So in the future, especially for your Windows users who had trouble using telnet, you can just use urllib and get the same answer. What I'd like you to do now is play with this library a little bit in the form of a quiz. Okay, quiz: What server does www.example.com use? You're going to use the server header, which is in the responses, and I would like you to of course use urllib2 and Python to answer this. You don't have to, but it will make the rest of this lecture a lot easier if you start figuring out how to use it now. Okay, and the answer is Apache/22.3. Now, if you put in Big IP, we accepted that, but I'm pretty sure you didn't use urlib2. Because when I was finding the answer to this, I also cheated, used curl, and got Big IP, which is actually what www.example.com uses, but urllib2 automatically follows redirects, and the server it redirects to uses Apache. So let me show you how I got the example, and then we'll go ahead and talk about what happened with the redirect. Okay, so the way I found this answer is I used urllib2. I used the url open function to hit www.example.com. I stored that in a variable, and then I looked at its headers. I see that the server is Apache/22.3. And that's the correct answer. If we look at the url attribute on P, we see it's actually iana.org. Now, if you remember from Unit 1, I asked you what is the location header when you hit www.example.com. And that was because-- And this was the answer, because example.com redirects to iana.org. Now, urllib2 automatically follows redirects, which can sometimes be confusing. And in this case, it automatically followed the redirect. It hit iana.org, whose server is Apache. But we're going to do this by hand. I'm going to use curl. This is the Unit 1 example. We can see that server is actually Big IP. So hopefully you used urllib2, but if you cheated like I did when I was writing this quiz and you saw Big IP, we'll also accept that. And it's important to know, when you're using these libraries, that a lot of these libraries--urllib2, the default one included in Google App Engine called URL Fetch-- they follow redirects automatically. And if you don't want to follow the redirects, say your are writing a grading script for your homeworks, you need to look up the docs. There's almost always an option to tell the library not to follow automatically follow redirects. So that's something to keep in mind when you get behavior you don't expect as just happened to me. Okay, let's move on. Let's move on a little bit. We now know how to make basic requests with urlLib. You guys are going to become very friendly with that module. I'd like to talk a little bit now is what we actually send over the wire between two computers. We could have our servers--in this case we'll use the Hipmunk example. We could have our servers make our request to Amtrak and receive HTML back from them. Then we can actually look into that HTML on Hipmunk servers. That's actually what we do, but this is suboptimal. Let me show you why. You've written some HTML at this point. You know that it's somewhat complex. It's not very regular. You've got things like--browsers are very forgiving. You can write HTML to look something like this where you have an opening tag, and you have an opening tag to make some text bold, and you can forget to put the closing tag, put your closing tag, and the browser will actually probably render it appropriately. At least some browsers will. If you were a computer trying to parse this, you're expecting a tag to have a tag. All of a sudden you can get lost in this loop. Depending on how complicated you want to make your parser, maybe you can recover from this like browsers do or maybe not. But HTML is not an ideal language for computer-to-computer communication. It turns on Amtrak, we actually get their HTML, and I'm going to show you some of the heartache we have to go through to actually parse this HTML. Remember I gave you some regular expressions during homework 2 to verify your quiz answers--to verify a username and an email. These are a bunch of regular expressions that we actually use on Hipmunk to parse Amtrak's HTML. As you can see, this is just a wall of text. This is extremely error-prone, and you can see like we're actually looking for div with class availability. We're going to look for the span whose ID is service_span. This is what a time looks like. This is really nutso. This is not the ideal way of doing things. In a perfect world, we wouldn't have to hit Amtrak's webpage. We would instead use an API that speaks a language more appropriate for this task. Suck a language, if language is the correct word, might be XML. XML is what actually invented in the late '90s specifically for this purpose-- to have a regular way of expression data between computer systems. I can't claim to be the biggest fan of XML, but it is fairly easy to parse. In fact, you've seen a lot of it. So this is what some XML might look like. If you're thinking this looks an awful lot like HTML, you are correct. We have our first line, which is basically the document type. We have the same thing in HTML. Remember we've been using HTML5, so our doc type looks something like this. It's just the first sign that says what format the rest of the document is. Now, the reason both HTML and XML have doc types and this tag structure is because they actually share a common ancestor in SGML, which was invented in the '80s. Now, the main difference between XML and HTML is in XML every tag has to have a closing tag. We've got opening , closing . The tag format is the same. We've still got out less thans and our greater thans and our slashes to indicate a closing tag. But we have no void tags in XML. Remember in HTML we could have the tag for putting in a line break, and we never had a closing tag. That's because HTML doesn't require all tags to close. We have this notion of a void tag. The line break was an example of one of those. It's just a opening tag. XML has nothing like that . Now, if you want a tag that has no content in XML, you could do something like this. You could include a closing slash before you're greater than symbol. In fact, there is actually a doc type for HMTL called "XHTML," which basically says my HTML document is actually going to be valid XML. Instead of doing void tags with no closing slash, you include the closing slash before the greater than. You'll see that a lot in XML. The whole point of what I'm trying to say is that XML is very similar to HTML, but it's more rigorous. It's similar because they share the same ancestor. Now, I'm not going to spend a whole lot more time on the structure of XML, because we spent so much time on HTML already. Just keep in mind that it's similar to HTML, but a little bit more consistent. Okay, quick quiz. Which of these are true statements? All HTML is XML? All XML is HTML? HTML can be expressed in XML? Or XML and HTML share a common lineage. Check all that are correct. The first answer--all HTML is XML--that's not true. Despite the similarity between the two, HTML can have things in it that are not valid in XML. A good example was the void tag--the tag--with no closer. All XML is HTML. This is also not true, but it is borderline acceptable. You could certainly--if you had an XML document that was full of all HTML tags it would be very close to HTML and would actually probably render in a browser just fine. For example, if you included in your browser something like this-- and opening and closing tag--it would actually probably render just fine. Actually, that's a good question. I'd invite you to see if this enters one new line or two. I honestly don't know off the top of my head, and I'm not going to quiz you on it. Now, the next answer--HTML can be expressed in XML. That is true. When we use the doc type XHTML instead of just HTML, that says the following HTML document is actually going to be a valid XML document, and you can parse it as such. You don't have to look for broken tags. Your browser doesn't do less work. It's not expecting the HTML to be somewhat sloppy as HTML often is. If you say it's in XML, it'd better be in XML though, because the browser is not going to be quite as lenient on you. The final answer--XML and HTML share a common lineage--this is also true. Remember their ancester is SGML, which stands for Standard Generalize Markup Language. There are actually many other types of documents that descended from SGML, and HTML and XML are the two that will affect our lives in this course. Okay, let me just show you some doc types in the browser now that we have a little bit more of a framework to understand these. If I were to go to Wikipedia, and I were to view the source of Wikipedia, I would see that the doc type is HTML. This means HTML5. I know it doesn't say 5, but trust me on this one. Doc type HTML means HTML5, which is the most modern version of HTML we have. Now, if I were to go to a particular Wikipedia page, the Wikipedia page for SGML, for example, and I were to look at the source of this page, we see that the doc type is actually XHTML. It's actually XHTML transitional, which basically means the document is going to be in XML but will have some non-standard things in there. I'm not going to get into too much of how this affects things, but it does make some browsers behave differently. Why Wikipedia has two different doc types on two different pages I cannot explain to you. Although I can offer one guess, which is the SGML page is probably generated dynamically, and the front page is probably a nearly static page that are served from two different servers or two different machines, which is fine. You see things like this all over the internet. But when you see XHTML that means every tag in here should have a closing tag. You can see, for example, some of these header tags are these little void tags that have the closing slashes. You wouldn't see that in most HTML5 documents, although any browser would accept it, because it doesn't actually hurt anything. The next thing we're going to learn about is how do we parse XML? Now, I'm not going make you write an actual parser. I think there's actually probably a whole class in Udacity learning how to do almost exactly that. What I'm going to show you how to do is use the built-in parser in Python. Python has a library called "minidom," and you can get it by saying something like this: Now, one thing I would like to point out real quick here is when you're working with XML you'll often see this word "dom" up here. What this stands for is "document object model." This basically refers to the internal representation of an XML document. In Python you would have an object that has a list of children, and each of these children is some sort of tag object, and a tag object may have a name and an attribute and contents and that sort of thing. Any time you're dealing with XML programmatically, you'll see references to a dom, or if you're working in your browser, you'll see references to "the dom," which kind of refers to the document, the HTML that you're manipulating programmatically. In this particular case we're going to use minidom. Why is it called minidom and not something else? Well, "mini" kind of implies that this is a smaller, lightweight version of this dom parser. Actually, parsing XML is actually a really complicated thing, because you can get XML that is many, many gigabytes large sometimes. Parsing all of that text is nontrivial. But when you're only parsing a little bit of text, you can use this library minidom, which is basically simple and fast and will break if you throw lots and lots of gigabytes of text at it but for our purposes will work just great. I'm not going to quiz you on this sort of stuff. Just kind of carry this with you. Dom refers to the computer representation of the XML, and minidom is a handy library for manipulating this stuff in Python. Now I will show you how to use it. Here we are in Python. I'm going to give you a little demo of minidom before you start using it on your own. >From xml.dom import minidom. Now we have our minidom. Minidom has a function on it called "parseString," which is a function for just parsing a string of XML. Let's go ahead and give that a whirl. I've typed up some example HTML. We have an opening , some text, an opening tag-- remember these tag names I'm just making up. HTML has specific tags that you need to use. XML you can have whatever arbitrary tags you want. It's up to the people reading and writing the XML to agree on the tag names. I created some items--item 1, item 2. I closed my tag and I closed my . Now, when I was typing this, I had a little typo here, and I'm kind of curious to see what happens. Let's go ahead and run this with the typo and see--oh, boy! [chuckles] So I ran this with the typo to see what would happen, and we get an error--a mismatched tag. That kind of makes sense. We have an opening "chilrdren" and a closing "children." Let's just make this proper. Okay, we're going to run this without the type, and I'm going to store it in a variable so I have access to it. I'll call it x. All right. This time no exception. If we were to take a peak at x, we can see we have this minidom document instance. Let's take a peak at what we have on x. Holy smokes! Look at all this stuff. There is a lot of interesting things here in x. It looks like appendchild, functions for manipulating the document, all this creating nodes, and stuff like that. Some lookup functions--these are what we're going to be using later-- getElementById, getElementByTagName. NS refers to a name space. All sorts of stuff--parentNode, some output functions. Toprettyxml--this is actually an interesting one, so let's play with this one. This is one I use all the time. If we were to take our document object and call "toprettyxml" on it--toprettyxml. This actually doesn't look very pretty, does it, at all? Let's print that, because this is the Python string with the new lines in it. If we were to actually print it, it would look a lot prettier. Here is the xml that I entered, and you can see the structure of the document. It indents it nicely for us. That's a handy little function. When you download XML from somewhere you can see the structure of it a little bit more clearly with prettyxml. Okay, there's a function I'd like to show you here. Get elements by a tag name. Now, if I were to run this function on our x object and give it mytag, it returns one dom element. If I were to run it on item, we actually get two dom elements. Looking at the first tag called "item," we can see that we have an item. If we were to look at its children, we can call child nodes to see a list of children. We can see that we have one text node. If we were to look at the first one of those, we can access the node value attribute and see that it's 1. Now, remember our pretty printed version of our XML. What we just did here was we said get me all of the elements that are called item. Here is 1, and here is 2. On this first one, which is this guy here, get me its first child, which is basically this node here, which isn't strictly a node, but in minidom it's represented as a text node, which is basically just this text content. Different libraries may handle contents differently, but in minidom this is how we get it. Then we can actually say get the value of that text node. That's how we got the number 1 right there. This u basically means that's a unicode string. Minidom assumed that we were entering a unicode string, which is fine. One thing I'd like to expose you really quickly is RSS, you've probably heard of RSS before. It's how you read a website that has, you know, daily content, you know, like a blog or a news site and you may have a reader that is specialized for just reading the content. RSS stands for RDF Site Summary, and, RDF stands for Resource Description Framework. Now I'm not going to quiz you on this, RDF is, is an XML format for describing just about anything. For basically representing knowledge in XML actually in my first job I dealt with a lot of RDF so, I don't want to spend any more time on it. More commonly, RSS actually refers to Really Simple Syndication and that's kind of more of more of the context of how we're going to be dealing with it. You know, RDF was kind of conceived to solve this grand data, you know, organize the world's information problems. And RSS was, you know, it uses RDF but really, its just a list of, a list of content in XML. So let me show you some more example of this in the wild. I'm at the New York Times home page right now, and if we go down to the bottom of this page, we'll see a link for RSS, so I'll click that link, and I'll choose the New York Times global home page. Now, you can see in our URL, we have GlobalHome.xml. And so we've received an XML document. And most browsers will actually display XML in a nice way. So, this is an XML document. It's actually an RSS. And so, what this basically means is there's a, a particular namespace, kind of a tag space if you will, for the items in this list. You know, just like HTML has, you know, opens with an HTML and has a body and, you know, very specific tags. An RSS document will also, has specific tags. And in XML, you can use as header area, to describe what name spacing's used. So were using the atom name space, and the RSS 2.0 name space. And that's basically what this is telling our parser, is you can download a kind of descriptions of these tags from these URLs. And then we know what tags to expect. We're not going to, I'm not going to quiz you on what RSS actually is, so if you take a, a little peak at this document, you can see it starts out with some header stuff kind of in this channel section and then when we get down to this list of items. And so I'm going to collapse these first few and we can see we've got an item and this is basically just a list of stories that are in the New York times. So I can collapse and item and we can see if there is another item. There's actually a whole bunch of items. And each item has, you know, a title, and a link, and sorts of things that you know, would power an RSS reader. You know, a little description. You know, this is, this is neat. This is for an RSS reader, or a program to download the contents of the New York Times without having to parse all the HTML. Which brings us to our next quiz. Question I'd like you to answer for me is, going to the URL that we were just at, the New York Times RSS listing. Here's the URL. We'll also include this in the notes below so you can copy and paste it. Use urllib and minidom in Python to download this page and tell me how many item elements are in that listing. Remember the, the function, get elements by tag name will be particularly useful to you on a minidom objects. Okay, have at it. And the answer, at least at the time of writing, is 16. And if it's actually different from 16, we'll have our grading script update accordingly. Let me show you how I arrived to this answer. All right. So here we are in Python I first import the libraries I need. URL of two and Mini dom. Okay and then I download the New York Times page. I'm going to use URL lib to URL open and I'm pasting the URL. I'm going to go ahead and call read on that to download the contents and we're going to store that under a variable called contents. We can take a peek at contents. There we go. A lot of stuff and looks like RSS. We can see the closing RSS tag there. Now we're going to parse this with Mini Dom. Okay. That worked, got a variable d, it's got a document instance, and I'm going to use get elements by tag name, item, to find all of those. So let's give this a whirl. Success. And then we just run length on this. Okay and the answer's 18 [LAUGH]. So grading this is actually going to be a little tricky for us, all we wanted you to do is go through this process. So hopefully, that worked out for you and you got a number. And hopefully, we managed to grade that number. That's how you parse some basic XML, I think you can see probably, the value here and that many webpages have XML, interfaces them, or RSS interfaces them. Where you can actually download their content, and manipulate it, from a program. Okay, the next thing I'd like to talk about is JSON. JSON serves the same purpose as XML, which is it's a nice kind of computer and human readable way to exchange data in a, in a consistent format. It stands for JavaScript Object Notation. The reason it says JavaScript is because JSON is actually valid JavaScript code. It might look something like this. You know, to use kind of our travel search example from before. We have kind of this dictionary structure. This actually looks a lot like a Python code, because Python and JavaScript have very similar syntax for dictionaries and lists. So, we have this dictionary. It might have a key called itineraries, who's value may be a list of other dictionaries. And in this case, we have a dictionary for each routing, or something like that. Or we have a dictionary for each leg, which may have, you know, a key for from, and a key for to, and a value for each of those. Now this might be, you know, leg 1, and this might be leg 2. And you can see, you know, leg 2 is also made up of another dictionary, which is what we use the curly braces for. Which has a couple key value pairs of it's own. You know, key from value IAD and key to value SEA. And we can close our list and we can close this dictionary. JSON is really handy for expressing these types of objects. Anything you can express in XML you can also express in JSON, except JSON is a little less verbose because you don't need these kind of opening and closing tags. You can build things up out of dictionaries or, you know, a mapping or an object depending on what vocabulary words you want to use, hash table, which is just a curly and then a list of key value pairs just like you would in Python, just like you would in JavaScript. You can also have lists, which are, use brackets just like Python does, and separate the values in the list with commas. So we can have 1, 2 and the string three. So we can have both integers and strings in our lists or in the value of a hash table. The list can also be the value of a hash table. A list can also be an item in a list. This could look something like this and so we've got a list inside a list here a with two more data types, a Boolean which you are familiar with true or false and a float. And these are basically all the data types we can have in Jason int, string, Boolean, and float. We can of course also have null which would be inside, for example, the empty list. And our main data structures are dictionaries or mapping, which is the key to a value or multiple keys to multiple values and lists. So, what I'd I like to show you now is how to parse JSON in Python. Okay, we're in our Python interpreter. We can import JSON which is, is now included in Python's version 2.6 and newer. If your using Python 2.5, I suggest you try to find 2.6 or 2.7. But I think app engine uses 2.7, which is what we've been using in this class, so you shouldn't have any problem importing JSON. If we were to make a JSON string in Python here, let's call it j. So, if we were to take a string to representing some JSON, in this case, it's basically a dictionary with two keys, "one" and "numbers", and the value for "one" is 1, and the value for "numbers" is the list [1, 2, 3.5]. Let's parse that in JSON. JSON we use the function load S which basically stands for load string, there's also load but that expects a file. And in this case, we're going to be using just load S. When we run that, we get back a Python dictionary. With our same keys, numbers and 1, you know the order doesn't matter in python dictionaries, and our same values, 1, and 1, 2 and 3.5. And so if we were to store that in a variable. D. We can manipulate it like this. We can look at d numbers and we get our list. We can look at d1 and we can see our number one. There's actually, because JSON looks just like Python, we could actually eval j, and what eval does is it actually treats this as Python code as if I had just typed this at the prompt. And this is the result we get. Now, that's a neat thing you can do. Never, ever do it. Because in addition to having, you know, valid JSON in here, somebody could actually have code that might, you know, do something to your computer. So, never use eval for parsing JSON. I just wanted to show that you can use eval to parse JSON. It's a really convenient thing when you're working in Python with JSON. The two sync up very nicely. So one thing I'd like to show you in the browser is we're going to go to Reddit and we're go to reddit.json. So this is going to load Reddit's front page expressed in JSON, which is something we've implemented on Reddit so computers can, you know, browse Reddit and people can write third party software that uses Reddit. And so when you add .json to Reddit, you get this wall of text, which brings us to our next quiz. Okay, in this quiz, what I've done for you is I have a variable called reddit_front, which is what I just showed you from the browser, it's reddit frontpage expressed in json. Now this is actually quite a lot of bit of data look at my scroll bar it's a very long line, you not to worry too much about that. Just know that it is a string json string of Reddit's front page. Now, what I'd like you to do, use the JSON library to parse this string, find in there the links. It's kind of a deep data structure. You can copy and paste this into, you know, a Python editor if it makes it a little bit easier. You need to find the links, and each link has an ups attribute. And what I want you to do is write a function called total_ups which returns the total number of ups, you know, the sum of all of the ups of all of the links in this list. Now, there isn't anything else in this list that has ups. So basically, if you can find every instance of the key-value pair ups and value, add them all up, and return it. I just want to test your ability to load this JSON and manipulate it a little bit. Okay, good luck. Okay, I'm going to show you how I arrived at my answer. So I'm going to select this line. And I'm actually going to use the Python IDE, to, to figure out the kind of structure of this document. Here we are in the IDE. I'm going to paste in that first line. So I pasted in that first line. It's in a variable called reddit_front. We can go ahead, and run length on it. We see it's 26,000 characters. Okay, so the first thing I'm going to do is import json. And then I'm going to convert this, this document into json using the loads function in the json module. So now I've got this big dictionary: j. And it's got all this stuff in it. Actually, that wasn't very useful. It just printed everything. So let's look at j.keys. We can see there are two keys here: kind and data. Data is almost certainly the one we want. Let's look at that. Oh, another bunch of stuff. Let's look at the keys on this. This has just four keys: after, before, children, and modhash. Children is going to be one we want. The other ones are just simple little variables. So let's look at children. Now we're starting to get somewhere. Let's look at the keys of this. It's a list. So it's probably a list of lengths. Which is kind of what we're expecting. Let's look at one of these. Again, a bunch of crap. But let's look at the keys for the first element in the links, or in this children's list. We can see that it has kind and data. So let's look at the data for this guy. We're starting to get a little bit closer. Let's see what the keys are for this guy. Aha, perfect. And we can see that 'ups' is actually in this. So if I were to call ups, we can see that it is the integer of the number of ups on this link. So that's how I found this. So, looking at our total JSON document, were going to look at data, were going to look at children. And then for each of the children, were going to sum up the ups. If I were to change zero to one, to find the second element on the list, we can see that we get another variable. I'm going to take this piece of code with me into the ide, and were going to write a function to add up all the ups. Okay, here we are in the ide, and what we want to do is we want to sum up all of the ops. So I can say sum. So I'm going to say C data ups, for C in data children. Basically what I'm doing, is I'm iterating over the list data children, which we know is a list. For C, and each element in that list, I'm going to look up data ups on that object C. And then we're going to sum it up using the Python built in function, sum, and I'm just going to return that. Let's give that a run. J is not defined. That's means I didn't load the actual string of the Reddit frontpage in JSON, into a JSON object. So let's do that. Let's run that again. Here we go. Now, here's your answer, 103978. Simple enough. Now, what I wanted you to accomplish there was just learn how to you now load this into JSON, and then manipulate the data structure a little bit. And, you can see it's just like manipulating any Python data structure because JSON maps very cleanly to what we already have been working with in Python which is dictionaries and lists and integers and floats and that sort of thing, so. Pretty handy there. You are now a JSON expert. You know, on, on Reddit we can get any page in JSON, or we can also get it in XML by changing our extension. And a lot of webpages have this feature, where you can get their content in different formats. Another good example is Twitter. If we were to go Twitter and do a search, let's look for udacity, we can see all of the tweets about udacity. Now, if we want to get a JSON listing of this, I happen to know the URL. We can go to search.twitter.com/search.JSONq=udacity. And now we get a JSON listing of the search result that we were just looking at in Twitter. If you're writing web software and you want to manipulate another website or get data from another website, you know, it usually just takes a little bit of poking around to find their APIs. Now the way I found this API is I just Googled for Twitter API, and this was, you know, the documentation for this came up. I'll show you that real quick. There's this whole page about you know, twitter search API. One of the nice things about when you're building websites is if you have data. You know, if let's say you have a blog. Making your blog so it supports RSS. You know, an XML representation of its content, and maybe JSON representation of your content, or else other people to build software on top of your website, that, that can do equal things. And so, many large websites, Wikipedia, Twitter, Reddit, all support this types of functionality, and your homework in this class is actually going to be, to add that functionality to your book that we've been working on. Just something to be aware, most users don't really see this side of the Internet, right? It's really only other developers get to see this APIs and these other formats for the content, so it's cool that it's all there and it's good to be aware of it. But you remember when we were learning HTML and we had to escape our HTML content so it renders appropriately in the browser? If not, we covered that in unit two I believe. JSON has, has a similar issue. So, you know, if we have this little JSON blob, you have a little dictionary that takes the key story and maps it to the string once upon a time. You know, this is valid JSON. Our key is surrounded by double quotes and our value is surrounded by double quotes. What if we want to include double quotes in our value? Now if I were to just put a double quote in here, this would cause an invalid JSON because this quote actually ends the string, and then we've got a bunch of garbage after the string. You know, we'd need a comma and another opening curly brace. You know, all sorts of things. That totally screwed things up. Let's see what would happen if we tried to use that in our terminal real quick. So I'm going to take that JSON string that we just loaded. So this actually works. I'm using our Python string is actually this whole piece. This is the, this is the JSON string we're sending in to Python, and it's surrounded by single quotes. Remember in Python you can use either single quotes or double quotes to delineate a string, and that's what we're going to use here. We're going to use single quotes so we can use double quotes inside the JSON, and that works just fine. And if I were to do what I just did in the editor, and replace this p with a quote, let's see what happens. Explosion. You know, the, the, the, JSON parser didn't like that at all. The way we get around that is we escape this quote by putting a slash in front of it. This escapes the quote in Python, but what this turns into is still basically the same string we had before, which is just the quote. I actually have to escape both the slash and the quote for this to work in Python. So, basically this slash is the Python escape for this slash, which basically says we are inserting a slash in the string, and yes, we mean to do that. The JSON interpreter will see that slash. And say, okay, they must mean to include this quote. And let's give this a run. There we go. The other way to do this in Python that's a little simpler, instead of using double slashes, which is kind of confusing, is, we could put an r in front of our string, which says, this is a raw string, which basically means, Python, ignore any escaping we're doing in here for the purposes of Python, and let the json module interpret this slash however it will. And if we run this, it also works, with our quote in the value. The answer as we just saw, if want to include a quote in our value, is to input a slash in front of it. And that's the u that we had there before. So we have to escape our quotes with a slash. This is not a thing if you want to read in JSON, because we assume that the JSON we're going to be reading is valid, and if its not valid, our JSON module will tell us, it, it will throw an exception when we try to read it. Now what if we're writing JSON? Well the function for writing JSON is called dumps. And just like we had, loads, this stands for dump string. If we just use dump in Python that would expect a, a file argument so we're writing it directly to a file. But we'll be just be using dumps. And you can pass into dumps a Python object, in this case let's just say one, two, three, a list. And dumps will convert that to JSON for us. Let's go ahead and see that in the terminal. You can see I didn't put quotes around this, because this is the actual list object we've converting to JSON. It outputs a string, that's what these quotes are, of the JSON representation, which looks almost identical. That's pretty cool, huh? And if we were to make this object a little bit more complicated, map the string "one" to the number 1 and "two" to the number 2, we get our JSON. Now, the order changed, because order is not defined in dictionaries, but we get our JSON. Now, let's see where escaping comes into play. If I were to, instead, print the string two, we ought to make this string the man said cool. What would dumps do? So what I did is I changed the value for the, the, the two key to a string. Remember, these single quotes are delineating the string. And then, the string has an internal section with double quotes in it. Our JSON library will escape that for us. And you can see here that it is printing out a Python string that is valid JSON. And the Python version of the string has double quotes in it. I mean, double slashes in it. You need to be careful because this is not, in itself, valid JSON. This is valid Python representing valid JSON. That's why you have these double slashes. So you need to be careful when you are copying and pasting code, you know, or copying and pasting JSON, and it's in and out of Python that you get the escaping right. If I were to take this and instead print it so you can see the actual value, we'd just have the single backslashes which is the actual valid JSON, so. Time for a quick little quiz. Okay. What is the valid JSON representation for this Python data structure? So this is Python code. We'll include text version of this so you can copy and paste it into your editor. And I'd like you to put in this text box what the valid JSON version of this is. Basically, I'm testing the, your ability to use the JSON module, and have it escape properly. Now remember, I don't want to see the Python version of the JSON string. I want to see the actual JSON string, that if you were sending this over the wire to somebody that would be interpreted properly by the JSON reader. Good luck. The correct answer is blah equals the list "one, 2 and now "th\" r\" ee"]}. The main distinction between a Python object and a JSON representation of a very similar object is that JSON has to use double quotes to delineate a string. It can't use single quotes like Python does. So, you must escape any internal double quotes. Alright, so this is basic JSON. And as we've seen it maps very nicely to Python data structures, assuming you're using integers and floats and strings. If you want to map a more complicated Python structure 2 JSON, let's say you're doing an object or maybe a date time or some other things, the JSON dumps function isn't going to work for you. You're going to have to actually convert those by hand to a simple data structure made up of dictionaries, and lists, and integers, and strings so that we can output it properly. I'd like to now take a few moments to talk about how to be a good ciziten on the Internet. There are two key things you can do, when youre writing programs to manipulate other peoples websites, or to access other peoples websites, that will make everybody's life a lot easier. One is, use a good user agent. Remember, we talked about, in unit one, user agents are the header that describe what, what browser you are using, or what program you are using to access somebody. If you are planning on accessing somebody in a consistent fashion. If you're going to polll them, you know, every couple of seconds for updates or do something like that, use a good user-agent. When you're using urllib2 you can specify headers in your request, and you should set a user-agent header that says, you know, who you are, what your name is, maybe links to your website. So that somebody on the other end, if they see you, you know, pounding them with lots and lots of requests, they know, they know what's up. They have a way of reaching you to ask you to stop or to tell you they blocked you or that sort of thing. It's good to always include that. And the other important thing is, is to rate-limit yourself. If you want to download, let's say, all of the search results for the word udacity on Twitter, yeah, you can, you can request them 15 at a time, which is what their API returns, I believe. As fast as you can, but you'd be really sending a lot of requests to Twitter because you can have some loop and it's much, much faster than any human could type it and that will actually hurt Twitter's service. If you were to have code like this in Python, you know, while there's more stuff, make another request to Twitter, and just run this and this infinite loop, or maybe not infinite loop, but loop that's going to run through a number of iterations, you'd be sending requests as fast as Twitter could possibly serve them. Instead it's a really good to get in the habit of using the sleep function. In Python you can say import time, time.sleep(1). And this will cause your interpreter to sleep for one second. And this is nice. Then you're only hitting them once a second, which is much more sustainable. But, if you abuse their service, or do too many requests, they'll probably rate-limit you. I know Twitter does. Because I thought about having a quiz in this, in this unit that was, how many requests in a minute can you make before Twitter rate-limits you? But then I realized that that would be the exact opposite of being a good citizen on the net, asking thousands of students to go hit some website as fast as you can. It's generally not a nice thing to do. So, instead, we're just going to talk about it. I'm going to ask you to make sure, if you're hitting somebody hard, that you structure your code like this. Include a sleep so you pause a little bit and don't hit anybody too hard. Okay. Another protocol I'd like to talk about is SOAP. Actually, I'm just kidding. We are not going to talk about SOAP. SOAP is based on XML. It's another protocol for communicating between two machines. If you ever have to deal with it, you'll know why that I don't even want to bother teaching it. It's very, very complicated. But what I would like to list for you are a bunch of other common protocols and formats for communicating across the Internet. Now SOAP is one of them. We won't be spending any time on any of these. But lots of people use them. For example, hip monk, a lot of our data sources communicate via SOAP. It was invented by Microsoft to make communication online as complicated as possible. We've got protocol buffers, which are from Google. Similar to concept to json, it's a way of encoding different types of data for sending it over the wire. And there's another one called thrift. This is by Facebook. Now you've got all sorts of like, plain text, plus some formats. Now, these are not all. You know? SOAP kind of defines a whole protocol. Protocol buffers are really, you know, how to encode data. Thrift is how to encode data over the wire. These, these compare more to JSON. Soap compares more to HTTP plus JSON. Kind of the whole package. The protocol and the data type. Of course, you can always just build your own plain, plain-text, you know, protocol and, and data format, but I wouldn't recommend doing this. It's not that hard to just use JSON instead. And then, you know, somebody else who comes along and needs to use the service, whether it's, you know, outside of your company or internally, they don't have to figure out, you know, how to, you know, write all this custom code to parse, parse your custom stuff. Because JSON and Thrift and protocol buffers and SOAP, you can find implementations of these in almost any language. We mention XML and JSON. Those are also in this list. Use something that already exists, it'll save everybody a lot of time. I probably wouldn't use SOAP. Okay, quick quiz to summarize this section. Which of these are good habits to get into? Sending proper user agents, writing custom protocols, using SOAP, rate-limiting yourself, or using common protocols and data formats? The correct answers, at least according to me are: sending proper user-agents, very important, writing custom protocols, no, you know, there is a time and a place for it, generally using common protocols and data formats is a better idea, using soap. [LAUGH] Depending on whether we mean the protocol or the cleaning substance. The correct answer may be yes or no. We're going to go with the protocol, and say, I wouldn't use it if I could avoid it. You might make, you might make somebody at Hipmunk really upset. Or rate-limiting yourself, that is also correct. You know, always be kind, proper user agents, rate-limit yourself, use protocols and data formats that everybody knows how to work with that are easy to work with. Your life and everybody else's online will be much easier. We're actually going to do some programming, and we're going to add a feature to ASCII Chan. If you don't remember ASCII Chan is, we started using that in Unit 3, I believe. It looks something like this. We just have two inputs on a simple form, and we can insert in some ASCII art into the box here. Then when we submit it, we see our art here on our page, if we were to reload this page, we would show the 10 most recent pieces of artwork submitted. Obviously, this site is going to be a big deal--a big social community. I'd like to add some features to it. What I'd like to do is to draw over here a map that shows on the map where the most recent submissions came from, so that when you come to ASCHII Chan you can see what a global community it is. We have to do a couple things. Let's talk about them. One thing we're going to need to do is figure out where the user submitting is from. We're going to need some sort of service to convert the request IP into coordinates. For this we'll be using a service I just found called "hostip.info," which is a handy little website. I'll show you right now. I found this by googling. Basically, you go to hostip.info and for any IP address, they will tell you where it's located. They also have an API that has very simple documentation. Basically, if we go to api.hostip.info and include the IP address in a get parameter, they'll give us some XML with location data, and I'll show you what that looks like. For IP--their example IP--we get all this information, including city, country, country abbreviation, and what we're really after--some coordinates. Here we've got the longitude and latitude. This will be a really handle service that we'll be using. We also want to draw a map, and for this we'll be using Google Maps. Google Maps has a really handy service called "static maps," which is where we can basically make a URL that draws a make with markers on it. I'll show you where the documentation for that lives. That is here. It's called the Static Maps API version 2. If we just scroll down here to a quick example, we can see the type of thing we can build. Given this URL, it would load this image. If we were to just copy this URL here and load it in a new tab, we would get that image with the markers, and these markers are all defined in the URL itself. That's going to be a pretty cool, handy service. What I want is a map just like this, and I want it to appear right here, and I want it to have the location of the most recent submissions. Let's start with the first piece, which is going to be implementing a function that looks up the IP. Let's look at our code. Here is our code for ASCII Chan. It's not a lot of code--64 lines, it looks like. Most of it is contained in this main page handler. Remember the get function just called render_front, which is this function. All render_front does is run a basic query to get the 10 most recent pieces of art. This Google database object here renders front.html, which is my template that draws that whole form and the 10 most recent arts. The post function here grabs the title and the art work from the request, and if we have both of them, creates a new art object and puts it in a database and reloads the page by doing a redirect. Otherwise it draws an error. What we're going to do is we're going to change our code like this. I'll just kind of put in comments what we want to do. We want to look up the user's coordinates from their IP. If we have coordinates, add them to the art. That's going to be our first phase. Let's work on the first part of this. Look up the user's coordinates from their IP. We're going to need a function. We'll go ahead and throw it at the top here. We'll call this "get_cords," and this is the first function we're going to be implementing. This is going to take an IP, and it's going to make a request to hostip.info. That request is going to look something like this. Here is our API documentation. We're just going to take this URL, and we're going to paste it here. We don't want to use their IP. We want to use any IP. That's the URL we'll be requesting. We're going to be requesting this URL using URL obtuse. Let's go ahead and import that. We're going to be parsing the response. It's in XML, if you recall. We'll verify that. We're going the parsing this XML using minidom. Let's go ahead and import that. We know how to make a basic URL request. I'm going to show you a few things we do in the real world to be a little less error prone. The first thing we want to do is we want to store the content of the URL in a variable called "content.: The we're going to load the URL. We're going to urllib2.urlopen, like we've been using this whole time. We're going to call read on that response. Now, if this URL is invalid or that website is down, this is actually going to raise an exception I happen to know what that exception is, so I will go ahead and--. If there is URL error--I found this by trial and error when I was working on this the first time-- we'll just go ahead and return. There are no coordinates. That's if somehow this service is broken. Normally we might log this. If we were making a bigger site, I'd probably put some logging in here so that if I'm maintaining the site, I can see that the geocoding is broken for some reason. For our purposes right now, we'll just return none, because we'll be watching it. Then down here we can say if content--there is a chance that the page is broken in some other way and we just get an empty response, so we want to make sure there actually is content. Then in here, we're going to parse the XML and find the coordinates, which you are the lucky person who is going to write that code for me. What I'd like you to do is implement this get_coords function. It's going to take a blob of XML. Here is an example chunk of XML that comes from that website that should work. What this function should do is it should return the coordinates found in this XML. Keep in mind the coordinates here are longitude-latitude, and I'd like you to return a tuple of latitude-longitude. You're going to have to reverse them. If there are no coordinates in the XML--say, for example, we get a response that looks like this--I changed the IP to 0, 0, 0, 0, and you can see the response here. There are not coordinates in here. This is a case we're going to have to handle. Because hostip.info is a free service, and it only has the locations for IPs that people have entered. It'd also be worth your while to go ahead and go to that site and enter your location if it doesn't know it. I'd like you to implement that function. If it receives XML that looks like this, it returns the coordinates in the proper order--latitude, longitude. if it doesn't find coordinates, it just returns None. Good luck. Okay. My answer looks something like this. I had to import minidom so we could use that, and then we used a parse string for minidom, which is what we used previously in lecture to parse the XML that were passed in in this parameter. Then I used getElementsByTagName GML coordinates. Sometimes if the XML is more complex, you can't just cheat and find the one tag name that you're looking for, but in this case we know there's only going to be one coordinates element in a valid response, so we can just see if there's any element in here that has this tag name. If we have that element, this should return True. We're actually kind of going out on a limb here. If this wasn't such a simple document, such a simple protocol, I'd probably have to check to see are there childnodes? Do those childnodes have values? That sort of thing. I haven't done any testing that would suggest that. Just assuming it's all there it doesn't work. What I do is if it's all there, we call a split, which splits on the comma to get the two parts-- the longitude and the latitude--and then we reverse them and return with latitude and longitude. If we print our response, this is what we get. Now if I were to change our XML a little bit--let's say we just get rid of the actual coordinate from the sample XML I passed in--and run this, we get None as our answer. That should work for now. Good job if you got that, and let's add this to our program. Okay. Here we are in our get coords function. If we get content back from that URL we run this code. Now, I don't have the return statement here, because I want to change this just a little bit. In the quiz, I had you return lat, long. What I want to return here is db.GeoPt(lat, long), which I have learned is a part of Google App Engine. It's a data type for storing a latitude and longitude. We could just store a tuple here. I figure if Google gives us a data type specifically for a location, that's what we should use. I'm going to use one of these, and that's what we're going to return out of our function. Let's test that this function is working. A quick way we can do that is just toss in a line right here. We're going to say self.write(repr(getcoords(self.request.remoteaddr))). What I've added here is just a quick little hacky thing in our get( ) function. First we're just going to call this function write( ), which--if you recall--I added up here, and it calls self.response.out.write( ), so I don't have to type so much. I can just say .write. Then we're going to call repr( ). Now, this is a handy little trick when you're printing Python objects in HTML. Because when you print a Python object, it has angle brackets around it, which the browser will interpret as a tag, and then it won't actually print what you're trying to print. If you print repr around it, you'll get some extra quotes, and it'll print properly. Then I'm just going to call our function get_coords( ), and I'm going to call it with the requesting IP address, which is the remote_addr attribute of the request object. I learned how to do this just by looking in the App Engine docs. Almost every web framer will give you access to the requesting IP. I knew what I was kind of looking for and just found that in docs. Let's give this a shot. I reloaded the page, and I see None up here. That's better than an exception. We didn't get a location. So let's do some investigating. The first thing I want to do is I want to see what the IP was, so we can kind of debug this service. Let's say self.write( ). We'll print the IP as well. Let's give that a shot. Ah. Okay. 127.0.0.1. That means we're running this locally. It's not surprising that a service on the internet doesn't know what our local IP is. Let's verify that. We'll go to their API. We'll put in the API by hand, and we'll run it. And, yes, it's a private address. For those of you who don't know, every machine's local IP address is 127.0.0.1. This is called the loop-back address. This is how a machine refers to itself. It's not a public IP address on the internet. Local host--what we're accessing here--generally refers to that IP. Let's cheat a little bit and see if we can fix this. This is something that's going to come up during development. For our period here, I'm just going to overwrite the IP we send in this function to be an IP that I know is real--4.2.2.2. This is a big-name server than helps you resolve TNS names into IPs. We'll just hardcode the IP in this function to be this for now, so we have something to actually test against. Let's go back in our browser, give this page as reload, and see if we get anything useful. Ah-ha. So we are now seeing the coordinates of that IP address where that machine is located, or at least where this free service claims that machine is located, which is fine for us. We're not trying to be too accurate here. We just want to draw a pretty map. Our get IP function is working. We also conveniently tested the error case, which you should always do. We're in good shape there. Undo those hacks, and let's check back to our to-do list. We've done turning our request IP into some coordinates--ta-da! All right. The next step is to draw a map--actually, there are some in between steps. Before we draw a map let's look at our code again. We actually have two to-do lists. We said we're going to look up the users coordinates from their IP. Let's go ahead and do that here-- coords = getcoords(self.request.remoteaddr). Okay. That should work. Then we said if we have coordinates, add them to the art. Right now our art object doesn't take any coordinates. Let's add an extra property to our art-- coords = db.GeoPtProperty( ). Again, I found that this existed when I was reading the Google Data Store docs. Since we're returning a Geo Point here, we can store it in a Geo Point Property. Again, this is a Google-specific datatype for storing latitude and longitude, and it's super convenient. Now, I'd like to say required = True, but we already have some art in our database that doesn't have coordinates. We have a couple options here. We could either delete all that art and start over, but being that ASCII Chan is a famous site on the internet, and everybody is using it, we don't want it to just break. We'll just make this parameter not required. We'll just have it for future ones. This is something that comes up all the time when you're developing web applications. It's kind of backwards compatibility, because you're often adding features, tweaking your data model. This is one of the reasons things can get a little hairy. But it's also one of the reasons why the web is really neat, because you can kind of develop iteratively. We're adding our coords to our art, and we're going to go down here and say, if we have coordinates, add them to the art. That's easy--if coords--basically, if get_coords doesn't return None-- p.coords = coords. Now we're good. Let's go ahead and try submitting some art in our browser and see if we get an exception. Reload this. Let's submit a new picture, call this one "cat," enter in a picture of a cat, and we'll submit this. Okay, I didn't see any exceptions. Let' me show you something handy we can do in Google App Engine to make sure this actually submitted properly. You may notice that when you start up App Engine, it actually mentions in the console that the admin console is available at this URL or at a URL like this. Let's go ahead and visit that and let me show you something we can do. It defaults to the datastore viewer, and it selects all of the entity kinds we have. We only have one in this drop down. If I click list entries, I can see all of my entries, and I can see here is camel and here is cat--my two entries. I can see that camel doesn't have any coordinates, because we entered that before we added this feature, and we can see our cat has map coordinates. So our feature is working, and that's pretty cool. There's all sorts of handy stuff in this tool here. You can check out your indices and all sorts of cool stuff. It's neat to poke around in here. But, working with the database, this is a particularly handy view. So let's get out of here for now, and let's move on to the next feature, which is actually drawing this map. Here's our map API. What we need to do is figure out how to draw this map. The URL is going to look like this. It's going to be this URL--maps.googleapis.com/maps/apis/staticmap, and then it's going to have some parameters. I've done a little research already to find that the only required parameters are size-- which is going to be the size of the map, sensor-- if we were doing this on a phone or in a browser that knows where you are already, whether to actually try to figure out where the user is. We're not going to use any of that. Then we can just add these marker parameters. Here's one marker, and you can see in here this marker is defining the color to be blue, and it has a label, and then, also, you can see something that looks like coordinates in here. I've learned that the color and the label aren't required. We can just say marker and given it the coordinates. If you notice here there is another marker parameter. The way this API works is it just looks from for multiple marker parameters. We'll just add one marker parameter in the URL for each point that we have. Let's go ahead and do that. Now we want to update our front page to actually have the art images. Let's think about what we're going to do. We're going to first find which arts have the coordinates. If we have any arts with coordinates, then we need to display the image URL. First thing we need to do is we need to define which arts have coordinates. This is fairly easy. What we can do is we're going to take this list of arts, and for each one we're going to check to see if it has coordinates. Let's say for a in arts: if arts.coords: points.append(a.coords). We have to define points as equal to the empty list. This is pretty straightforward. For a in arts--for each one of these--if there are coordinates-- The way the datastore works is if there are not coordinates in the database, this'll just be None. It won't blow up on us or anything. Just add it to the list points. This is a clear way of writing it. How I would have written it is slightly less clear. A little shorter. This is just some Python learning for your own edification. Points = filter(None, (a.coords for a in arts)). This is a generator--a.coords for a in arts. This would return an iterator of all the coordinates, which may be either coordinates or None. Then filter takes two parameters. It takes a function or None and a list or an iterable and basically returns all of the items in the list that match the filter. In this case, if the filter is None, it basically says match all the ones that aren't None. This will give us all of the coords for each a in art if it's not None. That does exactly the same as this. We're going to use the slightly shorter version. This should work. Let's make sure this doesn't blow up on us. Here we are in the browser. We reload the page, and we see our little guys. Maybe we should print out the coordinates so we can see them. Let's go ahead and do that. Okay, we're going to go ahead and write that out. Let's try that in our browser. There we go. There's a list of our points, and in this case we only have one. That's good. There's one subtle bug I'd like to point out to you in this code. Arts is a query. When we iterate over arts, that's when we actually run the query. If we never iterated over arts here, this query wouldnt run. Well, we iterate over here, and then when we're rendering the front.html-- this template, if you recall, has a loop in it that draws all the arts. This also iterates over that arts query. Each time we do that we run the query. We don't want to run the query twice. That's wasteful. Not only is it wasteful a query, the results of that query could change. When ever you find yourself in a situation of iterating over results you get from a database, whether it's datastore or some other kind of curser based abstraction from a database, it's usually good to say something like this: [arts = list(arts)] What this does is it creates a new list out of that arts. The arts that comes out of here is a curser, and then we basically call the list constructor on it, which says, okay, make a new list out of that iterable. Then we can iterate over this list as many times as we want, and we've kind of detached it from the query. This is a good habit to get into if you think you're going to be using results from a database more than once or you're going to be manipulating this result from a database too far away from this query, because generally if you get a list of things from an iterable, you assume that you can go over it a couple of times. That's all this is going to do. It's basically going to cache the results of this query in a list. It's very subtle, and I was actually struggling a little bit how to demonstrate that to you. I don't know how to debug Google queries. If I could have made this print in the console, I would have. If we figure that out between now and when we wrap this lesson up, we'll include that in the instructor comments how to show what queries are actually running. But I did a little googling and confirmed for myself that this would be the case. That's good to do. We've accomplished this first part to find which arts have coordinates. Let's just stick our comments up here. Now let's say, if we have any arts coords, make an image URL. If points image URL equals-- let's call this gmaps_image, and that's going to take some points. And guess what? You get to write this function. What I'd like you to do is implement this function_gmaps image. It's going to take a list of points. Now, in the ASCII Chan program there's going to be these Google GeoPoint objects, but since we don't have access to that in the IDE I made a fake Point_class that just has two properties - lat and long so it should work the same way as a Google Point does, and I made a little fake list of points here that we'll be testing with and we'll also throw you some other ones. You should generate a URL that looks like this. These parameters are all fixed--the size and the sensor-- and you can have a template URL here and then what you need to do is you need to add these marker parameters to the end of this URL and return it. It shouldn't be too bad. Good luck. Okay, here's my answer. What I do is I make a variable called markers, which is going to be a bunch of strings of the format of 'markers = %s, %s', substituting in the lat and long for p and points. Then we're going to join those together with an ampersand, and then we're just going to append that to the base URL. Simple enough. Okay, if I were to run this with just a single point, it still needs to be in a list. Our function is still expecting a list but one point. Make up some fake coordinates here and give this a run. We see that this also works just fine-- "markers=100,200', and there's this one markers parameter. Let's go ahead and use this in our program. I'm going to go ahead and add that function to our program here. Actually, this one works verbatim just like out of the quiz. Now if we give it a list of points, it will return the URL for the image. Let's go ahead and use that. If we have any coordinates, make a URL image. We've already implemented that function. Let's go ahead and move our comment. Now we just need to display the image URL. Actually, we need to make one little change here-- img_url = None. If by default doesn't exist and if we actually have some points, we can set it to something else. Then we just need to pass imgurl into our template--imgurl = img_url. Now we just need to update our template, and we're going to insert our image. Remember, this is our template. I had a bunch of CSS. Remember I explained that kind of controls the layout of things. Then we have all of our HTML. Here is our form. We want to display this to the right of our form. I'm going to do somethings you haven't seen before in terms of getting it to display right, but first let's just get the image in here. If img_url--so basically it's not None--include our image. This is how we do that in the Jinja template language. Again, I know we haven't covered this in this class, but it's fairly straightforward. You just have some text, and you have these little escapes for actually running Python code. If the URL is there, include this image. Let's give this a whirl. I reloaded the page, and you can see below the form we have an image with a marker on it. Pretty cool, huh? Let's get our image displayed off to the right here. I'm just going to go ahead and do that, and I'll explain briefly how it's done. I've moved the image over here. I'll show you briefly what I did to do that. I added a class to map, so I can refer to it in my CSS. You can use this notion of position absolute, which allows you to position something anywhere on the page. I positioned absolute the map to be zero pixels from the right and 112 pixels from the top-- zero from the right, 112 from the top. It fits perfectly. Obviously, I knew the size of the image beforehand when we did this whole URL thing. Let's see if our program works. Remember we've got this hack in here forcing our IP. We're going to have to--probably if we're going to develop this long-term, maybe when it's in debug mode it'll chose from some random IPs or something like that, but when we put it into production it is going to use the real IP. Right now, we're just going to hard code some IPs so this actually works in the demo. I'll go ahead and include Udacity's office IP, and we'll submit some ASCII art. We'll have this IP, and let's make sure things work. Let's add a picture of a rabbit. We'll past that in or we'll draw it by hand, whichever you're faster at. We submit this--ta-da! It took a little longer to submit because we had to look up the IP, but now we can see that we used our office IP, which is down here in Palo Alto. We have our old IP from that other IP we faked, which in here in Colorado, and we can see our rabbit and our cat. Our camel didn't have a location. Now ASCII Chan is much more worldly. I'll put this online at asciichan.com, and you call can submit all the ASCII art you love to do. We'll see how this map goes. That's it for this lesson. I how you learned something about how to interact with other websites. Good luck on the homeworks. Welcome to lesson six. At this point, you guys can build just about anything. You collect data from users. You can build pretty web pages. You can store all of this stuff in databases. You can manipulate this database. You can build log-ins, all sorts of cool things. And when you think about it, just about every website on the Internet is some combination of the things you've already learned how to do. So it's pretty cool that you can, you've gotten this far. Now, one of the things we haven't touched on yet, is how to build websites that operate at a larger scale. That is that more than just a couple of people can use. When you start having websites operating at a big scale, lots of things can break down. You can run out of disk space for your data. You can run out of bandwidth, to serve all of the amazing stuff that you have. Or you can run out of you know, processor time to actually generate all of the amazing computations you're doing. Right? There's all sorts of different things that can, that are limiting factors in how your website functions. And we're going to learn how to address each of those things. How to use multiple machines if you need to, and that sort of thing. So that you can actually build a large-scale website. So, let's jump right in. Okay, let' just right into things with a quiz. So, why do we scale, you know. What problems are we solving when we, when we scale things? Do we scale so we can serve more requests concurrently? So we can store more data? So we're more resilient to failure? So we can serve requests faster? Check all that apply. Okay, so, so we can serve more requests concurrently. That's true. So, one of the limiting factors of a website is. How many requests a machine can handle at once? You know, each, each time a, a user connects to your machine that uses what's called a connection. The connections take memory. They take CPU to, to deal with. And of course, you know, the CPU to handle the requests. So, you know, we want to scale so we can handle more requests concurrently. Alright, how about storing more data? Yep, that can be a reason to scale. Sometimes just storing so much data that it won't fit on one machine, or in one, you know, one database. Or it won't fit in memory, or you need more disk space. You know, there's all sorts of reasons that data might be a limiting factor, memory, disk speed. And that's another reason to scale. So we're more resilient to failure. Yes, absolutely. You know, sometimes you add multiple machines into your system, you know, you have multiple databases, we talked about that in unit three. We talked about replication. You know re, replication is important for databases. So that if, if one of those machine dies or goes off flying. You don't lose any data and your website still works. Same with your application servers where, where your programs are running. Sometimes those break or, you know, go offline or become disconnected or for whatever reason aren't accessible. And so you have multiple ones, so you're resistant to failure. And, finally, to serve more requests faster. Yes, this is also an answer. It's similar to serving more requests concurrently. Which requires, you know, being, the ability to handle multiple connections or many connections. Serving requests faster, may require a bigger machine or some caching. There's lots of techniques for doing this. And that falls under the umbrella of, of scaling. So, these are all good reasons to scale. And, and they're, they're handful more. But these are the types of things we're going to be talking about in this lecture. Let's have another quiz. [LAUGH] I know it's rare to start a lecture with two quizzes, but this lecture, this lecture's actually light on quizzes, so you know, let's get them all out of the way. Okay. What things do we scale? This is similar to the, the, the last quiz you just did. Check all that apply. Do we scale bandwidth? Do we scale computers? You know, their memory or CPU? Do we scale power? Or do we scale storage? Check all that apply. Okay, and the correct answer is, as you may have suspected, all of these. There are many different factors in each website, is a little bit different. And, you know, different website may have different needs. some, some websites you know, video websites, like YouTube or Justin TV. Bandwidth was a major factor because video takes a lot of bandwidth. And you have to figure out, you know, how you can support that much bandwidth. You know, you're sending a lot of data over the wire, over the Internet. Machines, computers very often CPU's a limiting factor. if, if your website does a lot of computation you know, you may need a lot computers to handle all of the traffic, to do computation for everybody. Or maybe you're running out of memory. You know, you're storing a lot of data or you're caching a lot of data in memory. You may need to store that data across many computers to, to make it work. Power, you know, if you're adding a lots of computers, power is actually something you need to start thinking about. You know, I've visited Google once and it was cool that had a, a map on the wall of where the big power plants in the world were. They are building data centers in near power plants so they could always have powers. And storage, of course, is similar to memory. You know, memory, disk space, or technologies that fall in, in between. You know if, if you're storing a lot of data. You know many websites store a lot of data. If users are submitting content to you, photos and status updates, and, you know, comments and that sort of thing. That starts to become a big factor in, in your decision making, and how do you store all of that data. Facebook has so many photos, they have to. They've unbelievable amount of disk space required to, to manage all that information and you know Google has basically the entire internet indexed and you know that they have to store, they basically Google's [INAUDIBLE] entire internet across all their machines so they can do searches quickly. So all of these are things you need to scale and of course there are other, other things as well but I just want you to keep in mind that every website is different. Every website has different needs and different limiting, limiting factors whether it's machines or bandwidth or power. Anything can be the, the, the culprit when it comes to keeping your website online, stable and fast. Let's talk about some different techniques for scaling, different approaches you might take in, in a particular problem. So the first thing you should think about is optimizing your code. You know, if, if, if you have the option between buying a second machine, and figuring out how to have two machines working together on your website versus making your code twice as fast. You know, may, maybe it's, maybe it's easier to optimize your code. You know there are some trade-offs here. The cost of a machine plus the maintenance of having multiple machines. That means you need to figure out, you know, you have to administrate those machines. Make sure they're up, configure them, make two machines work together, all of that stuff. Versus cost per developer. That is development time. You know, it takes, takes some effort to optimize your code. And you know, paying people to do that or paying yourself or you know, considering the value of your own time for optimizing code versus adding another machine, you know, there's a trade-off there. And that's something you should think about. At my company, that's something we think a lot about. You know, what does it cost to pay a developer, and what does it cost just to add another machine? So, kind of a big trade off there. We're not going to spend a whole lot of time on this code optimization in this lecture. Because that's really just learning how to program better. You know, as you get more experience programming, you'll be able to write better and, and, and tighter code. And it, you know as you understand how compilers work, you can start getting even more clever and et cetera, et cetera. So, won't be covering it in this lecture, but you'll get better at it as, as you develop as an engineer. Another technique is caching complex operations. We are going to spend a lot of time on this in this [LAUGH] lecture so I'm not going to say a whole lot about it now, but this is the name of the game. Caching. You can upgrade your machines, which basically means, you know, you're replacing the machines you're using now with machines that have, more memory, more disk space, faster CPU. Now this is often a good option. Sometimes you don't have this option at all if you're using you know, a shared, shared platform where you don't have control of the machines. But again, you know, some, some you know, every couple of years machines get substantially faster, memory gets cheaper, disk space gets cheaper. CPUs come in faster varieties and, and greater numbers. So again, you know, just like you're doing the tradeoff with code optimization versus adding more machines. You have the same trade off here. Do we want to optimize the code, or do we want to just get a faster computer? This is a perfectly fine way to scale. In fact, it's one of the easiest ways to scale if you have a, a system for replacing one machine with another without breaking your website. Or maybe you might want to break your website for a little bit while you do this. So anyway, something to keep in mind. Sometimes it's an option, sometimes it's not. You know, It's not as fun as optimizing your code, but it's often cheaper and easier. And finally, another approach is to add more machines, which we will also spending a fair amount of time on in this lecture. You know that optimizing code, and upgrading machines are fairly straightforward. You know, do it when you can. Caching and dealing with multiple machines working together in a system are more difficult but ultimately you'll have to do them as your website gets large enough. And that is what we'll be spending the most time on in these lectures, how these two things fit together. Okay, so let's move on to caching. Caching refers to storing the result of an operation so that future request return faster. Basically, if you do something once you know whether it's a database query or rendering some HTML or you know, anything that might be slow. You store the results so you don't have to do the computation a second time instead you can reference the previous result. So, when do we cache? We cache things when the underlying computation is slow, when the underlying computation will run multiple times. When the output of said computation is the same for a particular input, so that we know you know, we don't have to recompute it every time, because it's going to be the same every time; the output of this computation. And another good reason you know, for, for when we cache, when you are hosting provider charges for DB access, which applies to you right now. Google APP engine, gives you a fixed number of reads and writes to the data store in a particular day and if you go over that, you have to pay for it. Even if your app doesn't get a whole lot of traffic Caching request so they don't have to hit the database over and over is a fine way to save some money. And that will be an example we start with shortly. So, whenever you have a situation where you have the slow computation that you're running multiple times, with the same output over and over, you should cache it. You should store that result somewhere else. So that you don't have to run a computation over and over. So let's, let's talk about how that algorithm looks. Let's say we have a function called db_read(), and this reads from the database. And it's slow, you know, let's say it takes 100 ms to run this. This query which is slow for a database query but not unheard of. And, and you're serving thousands of requests, you know. If every request that comes in to, to your website has to hit db-read and that takes 100 milliseconds, that means you can only do ten requests a second or you start, you know, you start doing multiple requests at the same time and your database starts to get pummeled because it's trying to do this complicated query. All at the same time and, and this 100 milliseconds maybe turns in to 200 or 300 milliseconds, or 500 milliseconds, who knows, you know. When your database is under a load it starts to really get angry at you. So, if we wanted to cached this db read, let's talk about what this algorithm would look like. Prefer it a kind of write in, in sitor code here, we will have something that looks like this. If the request from making is in the cache, return the cache version of that request, and in this case, I'm pretending cache is, is like a dictionary and the request that we're making is the key into this dictionary. And that's generally the structure of the cache, the cache is basically a large, like a large hash table a large mapping of, of keys to values. Now you know all about hash tables a hash table works perfectly well for this. So, if a request is in the cache. Returned Cache value of that request, Else start the value of this DB Read in a variable, put that variable in the cache for future look ups. And then return that variable. So basically, instead of calling DB Read on every request, the first thing we do is check to see if that request is in our Cache And if it is, we return the cached value. This is called a cache hit. And only if this request isn't in our cache do we actually return our query. And this is called a cache miss. And what we do on a cache miss is we actually do operation, and store the result of the operation in our cache, and then return that result. So future requests will just bounce off the cache. Hash. Now if you're using a hash table, depending on the size of that hash table. We're going to probably do a lot better than 100 milliseconds, we're probably going to be talking about less than 1 millisecond. Which would be you know, quite a big speed improvement. Now of course this hash table is huge and you're caching lots of things. You know, hash table have their own Performance characteristics that you'll have to take into account. But you know, you can get substantial improvements just by taking the slow pices of your code and wrapping this simple algorithm around it, which is the focus of our next quiz. What I'd like you to do is implement that caching algorithm here in Python. So, what I've given you is a function called Complex Computation. And this takes two numbers and it adds them up. But it's going to take half a second to do so. The time dot sleep function causes Python to just sleep or wait for however much time you want. In this case, I have it sleep for half a second. So, what I want you to do is use a dictionary as a cache. And it's defined right here as, called cache. I want you to make this function cache computation. Use this cache to store the results of calling complex computation on different inputs. So if we pass in the same inputs a and b twice, I want the second running of this function to use the cache. The first one, we'll do the actual computation. And we'll be grading this by running picking different values of a and b, seeing how long the first one takes to run and then seeing how long the second one takes to run. And the second one should run substantially faster. Here is my solution. We're using the dictionary as a cache. We're going to use a and b as the key to this cache. So I just made a variable here called key which is just the tuple of a and b and in Python, you can use a tuple as a key and a hash table. Not all hash tables work this way, but the dictionaries built in the Python [INAUDIBLE] convenient. So the first thing we do is to say, if key in cache and if so r equals cache key. Which basically looks up that value in the cache. If its not in the cache, we run complex computation. We set cache key key to equal r and then we return r. So lets see how this, this runs. Okay, so if I were to call cached computational. The inputs 5 and 3,. We see the value 8 prints out.Okay? And it paused for half a second but you'll just have to believe me. let's, let's add some extra information here so we can see how long it's taking to run. Okay, the first thing I'm going to do is I'm going to store in a variable called start time, the current time. If you call time.time Using the time library here. This will return the current time in seconds. That is just our starting point. Then we will actually print our cache computation like what we did before and then I will print how long it took to compute that. And so what I am doing here is I say print and then I am printing the string for the first computation took percent f seconds. Percent f is just like percent s except its, we'll print a number formatted a little bit better. And I'm going to print the current time minus the start time which will basically give us how many seconds this this computation took to run. So let's give this a run. Okay, now we see the first computation took. Just over half a second. And that makes sense because we sleep for half a second and otherwise we're just adding 2 numbers, which doesn't take very long at all. Let's go ahead and run this a second time and see what happens if we run it twice in a row. Okay, so I just copied and pasted these lines and we're going to run them a second time. So we're going to restart the start time and then we're going to run the same computation again with different numbers. And we are going to print how long it took to run. So lets give this a run. Okay, so now we have printed out 2 things. We printed out the result both times, the first time the computation took .5 seconds. And the second time when we had a cache hit, when we ran through this piece of code here. The computation took .000011 seconds. Which is substantially faster. So if we had to run this computation a lot. Let's say we're returning the front page of askichan and we didn't want to do that database query over and over again and we cached it, we could get a substantial speed improvement. Now who knows how long it takes to actually run the front page of askichan. We will get to that in a bit. But this is the general algorithm, and you should get familiar with you know, this algorithm because you'll be using it a lot. You know, there's lots of different ways you can cache things, lots of different types of caches and all sorts of things, but the algorithm is always the same. If you'd like to see if something's in the cache, if it is return it, otherwise compute it, store it, return it. So, good job if you got that and let's move along to a real world example. Let's talk about ASCII Chan and how we might improve it. I know you are thinking ASCII Chan is probably perfect already. But, that's not true. We can make it better. When an user makes a request to ASCII Chan, we have to do a number of things. First thing we have to do is, we have to process the request. This basically means parsing the HTTP. And parsing the URL. You know, doing that, the URL mapping to the, to the right handler. You know, just kind of all of that overhead before our program actually starts to run. You know, figuring out what we're, what we're going to do with this request. That takes some amount of time, you know. It, it doesn't feel like a lot of time because it's actually not right now. But, if you're processing millions and millions of requests, yeah, all that little, all that time would add up. The next thing we do, which is much more substantial, is we clear the database. You know, we have ASCII Chan on our program and then we have our, our database that is full of, ASCII art of little animals and stuff. You know, our program makes a request to the database which runs and gives us our response. Depending on the complexity of this query, this can take a lot of time. Not to mention, it may not be free. If, if we're doing so many queries that operation starts charging us that can be a big factor. The next thing we do in a request, is we collate the results. You know, we may have to do some sorting, we may have to prune some of the results out because they're spam. You know there's all sorts of things we have to do to manipulate the results. We have to convert them into these Python mode, Python objects from the, from our database results. All that little maintenance stuff to get ready to actually render our HTML and then finally we render our HTML. Now if there's lots of HTML, this can actually take a lot of time. You know, on, on Reddit, the actual time rendering all of that content, all that HTML. Was non-trivial and that required some optimization. Now in ASCII Chan things are pretty simple, but you know, like I said every website's is a little bit different. So, what I would like you to do now just a quick quiz to interrupt things, is which of these four tasks given you know, you understand the nature of ASCII Chan, you've. You know your blog has almost the exact same structure as the ASCII Chan you know, use to submit things some ways to display a list of these things. Which of these items do you think is the best place to start when we're looking to improve our website? The correct answer or at least the answer I'm looking for is query the database. This step querying the database, that means we're leaving our program and making a request to this other system, which in the leading nature of my description is obviously not as fast as these other things. And in the real world the databases almost always the slowest piece. Sometimes you don't have a database. But when you do, it's almost always the slowest piece. And improving the speed of your database is something that's pretty important. Now, we talked earlier in this lecture about kind of the, the basic approaches to Scaling. We said, the first one was optimize the code. And when we're talking about a database we're probably not optimizing code but this, this was, this stage of thinking means, you know, have the appropriate indexes. You know, make sure the query is sane. You know, make sure you're only querying for things that you actually need. If the query's simple, and all those types of things. We're not going to do that here, because our query is actually very simple, and Google App Engine makes our indices for us. But this is always the first thing you want to check. If the index App Engine makes isn't optimal for the query you're running, you may have to make something by hand. You should always start here. You know, the first step is limit the work the database needs to do in the worst case. Let's assume we've already done that, because we have, for ASCII chan. Something else we talked about was, adding more machines. We don't really have control over that, in this particular situation App Engine manages that for us. If you're not using App Engine, maybe you need to add more machines. Maybe you need to start doing replication, or sharding, or those techniques. Now, if you've ever tried to do those techniques on your own you know, that they're very difficult, they're very complex. An this is usually, adding more machines when you're talking about a database, is kind of the last resort for scaling. Something else we talked about was using big machines again we don't have a whole lot of control over that in App Engine. I think you can upgrade machines a little bit but, you know, let's, let's say we're, we're, we're done messing with that, or maybe we're tired of paying for database queries, an we just want to get to the, the fun part. The, what we're going to spend this lecture talking about, we' re just cache it. A very simple thing we can do after we've optimized the database, and we don't want to fiddle with more system administration is Cache this query. You know in ASCIIchan the front page of ASCIIchan only changes when somebody submits. So that means it's a good opportunity to Cache what we actually store. And that is what I'm going to do right now, is add a little bit of Cache to ASCIIchan. Okay, you all remember ASCIIchan, it's online at ASCIIchan.com. You remember how it works we can type in a title and then we can draw some ASCII art or in my case Paste it. And when you submit the art you see a listing of all the previous arts submitted to ASCIIChan. The way this works in the code, when you do a get on ASCIIChan, when you call this function called render_front, which is defined here. Okay, so this render_front function, basically, what it does is it runs this data star query, written in Gql, that looks up the ten most recent pieces of art. So limit ten, that's how we know we're looking up ten. Order by created descending, so that orders them by the time they were created. This where ancestor equals art key is a data store technique for basically insuring your query is consistent. I kind of wanted to talk about that in unit 3 but things seem to be getting a little complex. If you read the data store docs you, and kind of search for the word consistent, you will see what this technique is referring to so anyway not super important for our purposes so you know why that's there, it's not required. If I got rid of this at our scale, this site would behave exactly the same. So then what we do is we actually run that query, remember, this just defines the query. When you iterate over the query, or in my case turn it into a list, that's when you actually go to the database and, and get the results back. Remember I turn it into a list here so that I don't accidently run the query twice when I iterate over it again here, and then again when we actually render the page. I just want to run the query once. So, what we want to do is cache this query because our front page isn't going to change very often. Most Users come to ASCIIChen and just look at the front page. We don't need to hit the database over, and over, and over again every time a user does that. That's just going to cost us money, you know, waste Google's resources, and generally just make the world a worst place, so. First thing I'm going to do, is I'm going to pull out this piece of code into it's own function so it's a little easier to manage. Okay, I'm going to call this function Top arts. It's not going to take any parameters because we're just returning we know what the query's going to be, the query's going to be the same every time. Okay so all I've done is I've created this function top_arts and I copied this code. Actually I cut this code from render_front and moved it into this function and then we we make the query, we run the query, and then we return the result. And then in render front, we just call the top arts function, so everything should behave as it did before. We can go ahead and give that a test. Here's a front page with our art, and if I were to reload this page, we see that nothing's changed. So, nothing big there, we didn't expect anything to change, and nothing did, okay? So let's go back to the code and start making our improvements. Now, one thing we're going to want to do is we want to have a way of telling ourselves when we're actually running this query so we can actually test to make sure our code is working. Now I am not a Google App Engine pro, but I am going to add a little statement like this. Login.error and we will say that this db query. This will print in our error console, the string db query. Now normally you should use login.debug for this purpose. But the debug mode in app engine is driving me nuts right now. So, this'll be a little bit easier for me to demonstrate. I'm going to have to also import the logging module for this to work. I'll go ahead and do that, just import logging. So, this should print in the console, every time we run a DB query. And let's see if that works. So, here is ASCIIchan and I am going to hit reload on this page and I am going to go to the terminal, and you can see that I am printing error and DB query that is my string and we can also see the browser fetched slash which is the actual request to asciichan, and also the request of favicon since I haven't created it. Just 404s. So now we have this printing and we can see that everytime I reload the page in the browser and we get these lines again and I see we get the words DB Query, right before the request. What we want to do is we want to get rid of these words without just commenting out the logging statement. Okay, so let's add some caching and we're going to use the same algorithm that we used on that quiz that, that you guys just implemented. We're going to create a dictionary and we're going to call it cache. Now, we have to have a key to cache, I usually like to store my keys in a variable. In this case I'm just going to call the key Top. This is how we're going to store the, how we're going to reference the result of this query in our cache. And then I'm just going to change we're just going to rewrite this function to use the caching algorithm. So if key in cache, arts equals CACH key. Else, we want to run our query. So, we run our query in the out statement and of course we want to store the result of our query in the cache. And then we return our arts. Okay, so, pretty simple change. Now we're caching the result of this one query. Let's see if it works, we go to our browser, I hit reload. The page loads with no error, so that's good. And then I go to my console and I see that it printed out DB QUERY, and has the results. Now if I were to reload this page again again, no error. And I go back to the console, and I can see that we made a, a second request. Here it is, GET slash, but this time there's no DB QUERY. So if I were to go to our front page and hit Reload Trust me that I'm doing it. You can kind of see it blinking a little bit over and over again and then, I go back to the console, I can see a bunch of requests that note, DB queries. That's pretty cool, huh? So now our front page is a lot faster, let's submit a new piece of art to ASCIIchan here, or at least, my local ASCIIChan. It's going to be a picture of beer, looks like it's from Hofbra House. I click submit, huh my beer did not appear I still have my original art from before. What do you think happened. Okay, we have broken submissions. We can no longer submit to ASCII Chan. I submit something, but we're only seeing the cached page. So, so here's what happened. What we did is, we made a request to ASCII Chan, who made a query to the database, which came back with a response. And then ASCII Chan Store that result of that query in a cache. So now I've got all of our artwork in our cache, and we use the data in that cache to send the result back to the user. Now when we submitted a new piece of art to ASCII Chan, we wrote that art to the database, and then we redirected the user back to the front page. The user then requests to the front page again. At which point ASCIIchan said, well, the data's already in the cache. I don't need to check the database. And, return the value from the cache again, straight to the user, without the new value. This is a problem. It means now, submissions are still working. They're going to the database. But because of the new cache that we added. All of our requests are bouncing off the cache and the cache isn't getting updated which is resulting in it appearing as though submissions are broken which brings us to our next quiz. How can we fix our stale cache problem and stale cache of course refers to the fact that our cache is stale. We submitted new content to our database and our cache is now out of date. That's referred to as having A stale cache. Should we improve our cache to automatically expire things after some time? After we submit, should we just clear the cache? Or after we submit, should we update the cache? Or don't cache at all? That's not going to work. And we should find a different solution. There are multiple good answers in here. Check all of them that apply. Obviously if there are multiple good answers in here, don't cache isn't the solution and given that this is the content of our lecture, we're going to continue with our caching. So, let's look at these other three. Improve the cache to automatically expire after some time. I'm not going to count this as correct. Although it is possible. And actually many caches, and the, the, the main cache we'll be talking about shortly, has this ability. But that doesn't solve our problem here, because if things automatically disappear out of the cache after some amount of time, there's no guarantee that that's going to coincide with our submission time. So let's look at the other answer, after submitting, clear the cache. Yes. This will work. This basically restores the cache to the state that it was in before we did a request. So you submit some art. We store it in the database, and then we blank the cache, and then the next page load clears the cache. Another answer after submitting, update the cache. This also works, but it makes things more complicated. So, in other words, after submitting a piece of art, we update the database, and we immediately update the cache at the same time so that the next page load of the front page has an updated version of the art. This would work, but it's, it's more complex, so let's start with the first solution after we submit clear the cache. We've seen this picture a few times, let's talk about how our algorithm is going to change. So what we're going to do is you know, user makes the, makes a request. We go to the database, we run the query, we get the results out we store them in the cache. And then we return the HTML to the user, that's kind of our standard use case and then any future requests Hit ASCII chan, bounce off the cache and come back. Now, we're going to improve the situation a little bit. So that when you do a database write, so we post a new piece of art. And we do our write to the database. At the same time, we're going to clear our cache. So that after we've redirected user to the front page. And the user fetches Slash again. We're going to run our query, we're going to get our result, we're going to re-cache the new version, which has you know, multiple things in it, and then return correct HTML to our user. So, let's go ahead and see how that looks in the code. Okay, now despite the complexity of that picture This is actually a fairly easy change. Our rendering front page doesn't change at all. And our top arts function that runs the cache database query. This also doesn't change at all. The only thing is going to change, is when we submit new art which is in this function here, the post function. After we put this art in the database. Let's just clear our cache. Which looks something like this. Cache.clear. Clear is a function on Python dictionaries that just basically empties the dictionary.cl In our case, this will work just fine, because we're only storing one thing in the cache. So we, it's, it's fine to just delete everything. Alternatively, of course, we could have just said cache, you know, top, equals none, something like that. But, let's go with the simple solution for now. Okay, so let's see how this works. So here we are. I'm going to reload our front page of Ascii Chan. We see our beer is here now because I changed the app so our cache got cleared anyway. If we go to our terminal, we see that our most request did a database query, and if I go back to Ascii Chan. Reload the page again, and then go back to our terminal. We can see that our most recent request did not make a DB query. So, that's pretty cool. So our caching is still working on our front page. Now let's submit a new piece of art to ASCIIchan and see if the site still works. I'm going to put a few blank lines here so we can see where we were when we come back to this. Okay, so here we are in ASCII chan. Let's go ahead and submit a new piece of art. In this case it's going to be a cake. Now, what should happen is we're going to store this in a database, clear the cache, reload the page, update the cache, and have our new piece of cake. Okay, so I submitted and now we see our cake is here. Let's go ahead and look at our terminal to see all these requests. Okay, so we can see our post here. That was the submission and then we responded with the 302 which is the redirect and we can see we print off db query and we see our front page request and all is well. Now if I were to reload our page again, here we go, and go back to the terminal we could see the follow up request didn't hit the database. So, now we've got this cool system. When we submit to the database, we clear the cache, and then the next time we hit the front page, we rerun the query and every page after that doesn't hit the database anymore. So now we're doing only as many database queries as we actually need, and so every user to Ascii Chan wont have to hit the database unless there's a new submission for them. This is going to cut down on our database requests substantially. You know, instead of doing one database read on every page view, we're only doing one database read on every submission, which happens far less frequently. Okay, so we implemented our new algorithm and before in the original algorithm we were doing one DB ready per page view. This is really bad. You know, this is doing a lot of unnecessary database reads. The name of the game when you're scaling websites, is only do the minimum number of database operations that you need to. And in this case, one read per page view is the opposite of that. After our solution, we're only doing one DB read per submission, and since submissions are rare, you know, most of our users, you know, the vast majority of them, aren't submitting new content. They're just reading content. We've cut down the number of database operations we're doing significantly. So when you're looking for speed and you're looking for sufficiency and you're looking to not spend all of your money paying for database access, this is a much better approach than this one. You know, if we're getting a thousand page views a day. And ten submissions today, we went from 1000 DB reads to ten. That's a big improvement. And those are approximately the real numbers from ASCII chan, so, you know, we just saved Steve a bunch of coin here, so, good job, everybody. Okay, so I'd like to talk about this a new concept called a Cache Stampede. So we, we've got a use case now, you know a user makes a request and a request probably bounces off our cache and returns. Now if, if a user makes the, a post request that edits the database. We clear the cache and on the next request from that user, we go back to the database and update our cache and return to the user. The user submits, we clear the cache, and on a following request we do the whole chain agian. Now, a problem happens when we have many users. Say that one of these guys posts to the database. Which writes the database, which clears our cache, and then the rest of these guys, you know, they're just browsing the site. They all come to the site at the same time. So we've got all these requests coming in to ASCII Chan and our cache is empty. They're all coming at the same time. We just cleared the cache, and what's going to happen is they're all going to say okay, the cache is empty, therefore we must all read from the database at the same time. Cause they're all like okay, cache is empty, we need to update the cache, and them bam bam bam bam bam, they all hit the database, running the exact same query just, so they can store in the cache. This is called a cache stampede, and what happens is the database gets beat up, and. You know that query that only takes a few milliseconds before, because it is a small database could take a lot of time. Or never return at all because of all of the queries are blocking at each other. That is something that we saw happen at reddit we kind of went through this whole process kind of learning as we go. Cached stampedes are really painful, but the solution is Fairly simply. So a Cache Stampede is when multiple cache misses from so much traffic create too much load on the database. Or not necessarily database, whatever slow computation you've got going on that you don't want to do very many of. You know that you constrained for resources to compute. Let's have a quick quiz and see if we can figure out the solution to this problem. Okay how can we avoid a cache stampede? We replicate the database to handle more reads. Only allow one web request at a time. Only allow one database request at a time, or database query, at a time. Or, don't clear the cache, but instead overwrite it with new data. The answer that I'm looking for is the last one. But let's go through the other ones. Could we avoid a cache stampede by replicating a database? Yeah in theory. it, but, but, it's, it's not a very good solution because as we said there's a, there's a cost to maintaining multiple machines. To running database queries It's, it's probably not the right approach. But, it could work if you had enough databases to handle all of the reading you're doing. Only allow one req, web request at a time. Now this could kind of sort of work but it means, you know, when a request comes, you, you basically queue up all of the simultaneous requests that you're receiving so that only one person is, only one person is hitting the database at a time. This could also work in theory but then you've gotta queue up these users somewhere and it slows down your site and. It's generally, probably going to be fairly painful. Only allow one database request at a time. This is similar to what I just mentioned. We'd have to basically have all these requests basically block, or wait on, on one request that's actually updated in the cache. For doing the query that sort of thing. You can either blo, do it in your web application, which, which would be tricky. Or you can have some sort of lock in your database. Either way. It's, it's, it's not going to work out as, as well as you would like. And finally, you know, we, just don't clear the cache. instead, overwrite the cache with new data. So there's never this in-between time, between when we write to the database and when we read from it again, where the cache is empty. Make sure the cache is always, always full or, or warm. You know, basically, we refer to a, a, a cache hit as, you know, it's hit a, it's hit a hot cache or a warm cache. That means the data is already in there. And this is a very simple approach, and this is what we'll go with. Let's go ahead and implement this in AsciiChan. Okay, so, here we are in our AsciiChan code. This is our line where we clear the cache. We don't want to do this anymore. Instead, we want the cache to just go ahead and update when we submit a new, a new piece of art. We're in our post function for set creating art. So the way I want to do it here, is I'm going to make a function, I'm going to make this function top_arts take a parameter called Update. And what this parameter is going to signify is that, if update is false, it's going to behave normally. But if update is true, we're going to update the cache, we're never going to read from the cache if update is true. So, I'm going to use that parameter here, if not update, so basically if update is false and the key is in the CACHE, return the CACHE, otherwise run the query. So basically if we set update to true, we'll always run the query. And then what we can do is we can go down, we don't need to change the reading, cause this basically says update false. We don't want to update the CACHE. Every time we don't want to force that update, we want to go down here instead of calling CACHE clear, we want to say top_arts true. This going to rerun the query and update the cache, so that means the user who does the submitting, triggers the re-running of the front page query. And any users who are reading at the same time, who are loading the front page at the same, won't ever hit the database. That means a page view will never hit the database. That's a very good quality to have. Let's go ahead, and make sure things still work. So, I reload the page, everything still works. So I look at the terminal. We see that there was a, a DB query that we just ran. Reload the page again. We see that there's no database query. Now let's go ahead, and submit a, a new piece of art. Okay, I'm going to submit a new piece of art. This is of the, the linux penguin tux. Now, when I submit this, what's happening is we're inserting the new piece of art into the database and updating the cache. Now we can see that the redirect the page reload worked and our, and our little tux was in fact submitted, and we go to our terminal we look at what happened. We can see the start of our query we've got this, this little error message from when we looked up the IP from that feature we had last week. We can see that in our console, we're printing DB Query in the POST request. This, these log lines aren't written until after the request is finished. So we're, we're writing tucks to the database. Then we're reading the database to get the most recent, the ten most recent items, and then we're redirecting the user, that's the 302. And then on our next front page request to get slash, there's no database write. So that means we're still doing the same number of database reads as we were doing before with the other solution, except the database read is triggered on submission, and not on page load. Which has a really nice property, and that there's no database read for the, the front page load ever unless the cache is completely empty. Okay, I'd like to go over each of the approaches we've talked about, and kind of the, the different properties they have. So the first approach was no caching and, and this meant on every page view, we we're doing a DB read, and when we submitted a new piece of art, there was no DB reads. Then we did this kind of what I would describe as the naive caching approach. Which was basically have the basic cache if the cache is empty, do the DB read, and if it's not, return the result. And what we'll, we'll add a, a third column on the edge here called Bugs. So the naive caching only does a DB read on a cache miss and doesn't do any reading on a submit, and is full of bugs. [LAUGH] Or at least has one bug, where the, the front page would become out of, out of date, the front page would become stale, so then, we started clearing the cache. This has the same property of doing a DB read on a page view, no DB read on a submit and no bugs. Then, we improve to the kind of the refreshing of the cache. And so this means we're no longer doing and DB reads on page views, or very rarely, basically only the first time our app turns on and the cache is empty and that first page view. Every other page view after that is cached, which is a really nice property to have. And we're doing one DB read per submission, and it works. Now, the difference between, between these two and this one, is the notion that a page view doesn't hit the database hardly ever and that's a really nice property to have. You should always be striving to have the situation where a normal, un-logged in, basic, you know, viewer of your website, doesn't touch the database. And I'm going to kind of condense that down to the notion that simple users shouldn't touch the database. Basically, you know, they're just lurkers, they're just reading. They're, they're not changing the site so they shouldn't be touching the database. Everything should be cached and ready to go for them. That makes the user experience better because the request will be faster and it makes, keeps your load down because you can add many, many of those users. And because they're just bouncing off the cache you don't have to do very much work to serve them. You don't actually have to hit the database now, there's a fourth approach that we didn't implement yet. Which is the most aggressive of all of these, and I'm going to kind of refer to this as distinct from refreshing the cache, I'm going to call it updating the cache. And I'll, and I'll talk about this approach in just a sec and we can get to the state where on a, on a page view, on a simple page view, we do zero DB reads ever and this is slightly better than rarely. And we don't do any database reads on submission either, and it works. This is a really nice property to have now of course, we still do our database right. You notice we haven't been optimizing rights at all, because you've got to store this, you've gotta store the submission at some point. But you can cut down on the data base reads lower them to both zero by keeping your cache completely up to date, and I'll show you how we might do that right now. Okay, we're going to look at this picture one more time here. We know all the pieces now, the user, the ASCIIchan the database, and our cache. We're going to talk about a new situation here. So let's talk about, let's pretend our cache is already warm. You know it's got some pictures in there, and reading the front page which hits our cache which you know, returns the result that we send back to the user. Nothing too complex there, we're not hitting the database because we're only doing reads. Now what happens is when we use a database write, we're going to send that right to the database, or simultaneously going to send that right to our cache as well. And so this, this gets a little bit more complex, we're going to send to write to the database, and instead of immediately rereading from the database to update our cache or clearing our cache, we're just going to update the cache. We're going to say okay, this affects the front page, so let's find that front page cache, insert our new piece of you know, ASCII art into the cache, and then from then on, that follow up request that, that redirects, that follow-up request to slash is basically going to bounce right off the cache again. So, we never did, we never did a database read during this whole process, we're just writing only. The only time we would do a database read is when we that start up the app for the first time and do the first request, or maybe we have a program that does that for us. So no user ever does a database read. This is exactly how we do it on Reddit now. Every listing you can look at is stored in it's own cache. And when you submit a link or do a vote we update all of the appropriate caches, all the different cache keys that may be affected. So, so it kind of introduced the trade-off here of complex inserts versus database reads. On reddit we actually do this, we have a different cache key for every listing you might look at, for every sorting, for every subreddit, etcetera, etcetera. And when you submit a link or you vote, we have to update all of, all of the possible listings that could be affected by that action. On the flipside, you know, users are pummeling the site all the time and they never read from the Database. And you know, so we have complex inserts plus speed, which is nice but, you know, complexity is complexity. On AsciiChan we probably don't need to do this right now our site just isn't at that scale. It doesn't, you know, a cache stampede isn't a realistic threat because we don't have that many users. But if we did, this is the kind of approach we'd want to take and, and so this is kind of the name of the game when caching. You know, if you want to keep this cache totally accurate without doing database rights, we're going to have to do, you know, complex code. So, one thing to keep in mind the more accurate the cache, the more complex the code. And these are the decisions you'll make as you build your website. And as you're scaling, you know, this is probably the ultimate solution you want to look to when you're kind of caching a database. You know, if the, if the solution works for you. Okay so uh,we've taking a fair amount of load off our database. Now if we were to go through that whole solution, we'd only be doing database right and we'd very rarely be doing a database read at all. And this is a big improvement over doing a database read on every page view. So lets go back to what our request does. And every request remember we, we process the request. You know, this was HTTP, URLs and all that stuff. We did the DB query, the database query. We collated the results, which for you know, ASCII Chan or the blog is, there's not really much involved in that at all. And then, we rendered the HTML. So, we've improved the database query, but what if we want to improve these other, other pieces. Yeah, we can use caching to render HTML. That's definitely a technique there, and we can actually use another technique for handling all three of these parts of the requests, which is adding additional app service and this looks something like this. To date conceptually we've basically had one program running, that handles all of our requests in your blog and an ASCII Chan. We've got the simple program you know, requests come in. Responses come back out, but if so many requests that one machine can't handle it. We can do is we can add multiple machines, to take up some of the load. So all of these extra requests can go to all of these machines, and these machines maybe interacting with the database. They may not be. Presumably they have their little caches that we just implemented that lives in our program and, and this helps so how do we get requests to multiple machines. Well, there's a piece of technology that sits between the user and all of your app servers called a load balancer. And this is a special machine, it's a physical machine just like your app server might be or just like your database server might be, that's optimized for doing one this, for spreading requests across multiple machines. So, what happens is, this load balancer has a list of all of the app servers that, that are in existence, and requests come in from the outside world, many, many, many of them. And the load balancer decides which app server to send the request to. Send one here, then send one here. Then send one here. And it can keep going to that process. And the reason this load balancer can handle all this traffic while the app servers can't, is the low balancer isn't doing anything other than taking in the request, choosing a server, and forwarding the connection along. It doesn't have to parse HTTP or it may only parse, parse minimal HTTP. It doesn't have to, it's not doing database queries, it's not rendering HTML, it's not, going to the cache it's, it's doing almost nothing at all, other than deciding which server to send a request to. You've probably won't ever have to write one of these, but it's good to know how they work. And when you're using App Engine, Google kind of does all of this for you. They'll automatically create new servers running your program and and scale. You can actually go into the app engine admin page and see how many servers they are using to host your app. Which is pretty cool. Normally this is a really challenging thing, and not knowing how to do it the first time, this took me a little while to figure out when we were scaling Reddit. That doesn't mean I'm not going to make you understand these things a little bit deeper. So, there are a couple algorithms a load balancer can use to determine which server to send traffic to. The simplest one is probably just to randomly choose a server. Now, a request comes into the load balancer and the load balancer just picks a server and sends a request there which will, you know, probably work pretty well. You know, over, over time, if you have enough requests, each server should get about the same amount of load. Other approach is round robin, and round robin just means a load balancer will choose one server at the time. You know, first this guy, then this guy, then this guy, then this guy, you know, just, in order. That's also a fairly simple algorithm. And then some of the balances are really smart and they know what the load is on each server, how many requests are outstanding at each server, and it may use some sort of load based algorithm just so you know. This guy's already handling like five requests and this guy's not doing anything so let's send, you know, future requests here until, you know, things even out. There's lots of approaches to doing this. What I'm going to ask you to do now in the form of a quiz is implement a basic round robin algorithm. Okay, here is our little load balancer simulator. I've give you a list of servers, servers 1, 2, 3, and 4. And I'd like you to implement the function get_server that returns which server we should send our connection to. It should return in order 1, 2, 3, 4 and then cycle back over to return 1. There are a number of ways of doing this in Python. I'll include some links in the instructor comments for some different approaches that might work. The way we'll test it is, we'll just call your function a bunch of times and see what it returns. So, good luck. Okay, here's my solution. So, what I'm doing is, I'm using a global variable, which is not a great habit to get into. But, it works in this simple case, to store the index into the list. Basically which server we're on. And I started at negative 1, so that the first time I incremented it, it increments to 0, so we'll be at position 0. I'm using the global keyword here, which basically tells Python to, use the global n. The n defined outside this function, instead of making a new variable called n. If I didn't have this global n, this line would raise an exception saying n is not defined. And then what I do, is I ref, I return the index into the list of servers the correct position. So and what we do is, we say, n modulo length of SERVERS. So length of SERVERS is 4. And if you don't know how the mod operator works, basically what it does is, it says, give me the remainder of doing the division. So, what this means is, we take n divided by length SERVERS and then we take the remainder of that. That's what modular does. So if its zero we say 4 goes into 0, 0 times. If n is 1 we say 4 goes into 0, or 4 goes into 1, 0 times with a remainder of 1. And so, so we get an x 1. And so as n increments, you know, when n is 5 we say, you know, link servers 4 goes into 5, one time, with the remainder of one again. So the loop is over. So if we get this a whirl, it would print out something like this. Okay, so if we go ahead and run this, we see our output SERVER 1, 2, 3, 4, 1. so, simple enough, that's our Round Robin little balancing works. Like I said, you probably want to have to implement this anytime soon. But, there you go. Okay, so back to this picture real quick. You know, I drew these little caches you know, these were the little caches you've already seen before. Remember our program ask each end presently right now is using a dictionary cache to store stuff. And when we have multiple app servers, this can create a problem. Because we have multiple caches. Which brings me to my next quiz. Why is our dictionary cache problematic with multiple app servers? It's not this is actually a trick question. Multiple app servers means multiple caches. How do we keep those caches in sync? Each app server may have to hit the database to update its cache. Or we'll caching data redundantly. Check all that apply. Okay, answer number one, it's not, this is a trick question. It's actually not a trick question. Multiple app servers means multiple caches, and so we have to keep them in sync. Yes, that is one source of problems we are going to face. You know, we have multiple app servers, let's draw a picture, and we've got our database. And say both of these guys have their little caches here, you know, let's say both of these caches are, are, both of these caches are one, they've got their stuff. Let's say, a database, you know, a POST comes in here that, the results in a database write, which results in a, in a refreshing of the cache. Now we got one up server with an up-to-date cache and another up server with an out-of-date cache. And so if the read comes in to here We're going to get stale cache. And that's no good. So we gotta figure figure out a way of keeping these caches in sync. Each app server may have to hit the database to update its cache. You know, this is a problem. Let's say the situation is neither, both of these caches are cold, they're empty. And two read requests come in, or many read requests come in. This is similar to the cache stampede problem, where Each of these app servers is going to want to update its cache which means it's going to have to hit the database. So that's problematic as well. Now of course we can alleviate, you know, some of these problems by updating the cache on writes, but we'd still have to find a way of, you know, keeping these guys in sync with one another which is a little tedious. And the final answer we'll be caching data redundantly. I'm not accepting that one in this quiz as a bad thing because very often you do cache data redundantly. That's kind of what a cache is. Right? You're storing data redundantly and, and I'm actually torn and, and whether this should be considered a down time or a plus side or kind of neutral. But, for our purposes, we want to focus on, on these problems, which is keeping these caches in sync and limiting the number of database requests we do. Now, the solution we're going to approach here is going to change this architecture a little bit. Instead of each app server having its own cache, we're going to move caching into its own process. And so now, both these app servers will use a shared cache. And so, this cache actually behaves very similar to the database except the queries are much simpler. They're just key value pairs, and it's probably only in memory, and there's technology designed. Specifically to solve this problem. Which is to be fast and used as a cache. Which is different from a database which is designed to you know run complex queries on huge amounts of data. This piece of technology is called memchached. And we're going to be spending basically the rest of this lecture learning how to use memchached. Memcached is a very fast in-memory cache. It was built by a company called Danja, to power a website called LiveJournal. And before Facebook took over the world, LiveJournal was a very popular site where people had you know, their own blogs. Kind of like Tumblr or Blogspot. I don't know a bunch of, a bunch of things have, have risen to take the, the place of LiveJournal. But LiveJournal was a very popular site back in the day. And when I say back in the day, I mean 2003 is when memcache was released. Now just about every website on the internet uses memcache these days. I don't know about Google but certainly it's used by Facebook. It's used by Reddit. You know, it's used by YouTube. Twitter, it is an essential piece of software when you're writing web applications. And in fact other than, than Linux itself memcache is probably the piece of software that's, most in common between every website online. It's, it's pretty astounding. It's very, very simple. And it's very, very effective at what it does. Okay. To draw a bigger version of that picture I did on the quiz, how memcached fits in, it looks something like this. Memcached is a process. Often you run it on its own machine. But you can also run it on the machines with your APP servers, and it's a very simple system. The algorithm doesn't change. A request comes in we check memcached. If a response is there, we send it back to the user. If it isn't there we check the database instead. And right to memcached, you know. As we've been doing, the algorithm should be pretty familiar to you by now. What's handy about it, is that all of these apps servers can interact with memcached. Memcached is fast enough and can support many, many sockets that it works very well in this scenario. Also most memcached libraries have built in towards this notion of having multiple memcached machines. Because memcached is just a key value store. Just, it's like basically a giant hash table. You can hash on the keys to decide which server to send your data to. And because it's a cache it's okay if you, you know, lose data from time to time because you'll just get it, you'll get the authoritative copy out of the database. And this distribution of keys over multiple servers is gnereally handled by the library. You know, sometimes you have to do it yourself. But most libraries and the Python library we'll be using, and this class this abstracts all of this for you so you don't have to deal with it. It's very common to actually run a little memcache server on each machine, and then have each app server you know, communicate to all the caches. You kind of get this big ball of this big ball of connections. But everything works out okay so. And mem cache is a very simple protocol and the operations it does are very simple. So, ultimately we're going to be storing you know keys to values. Where the keys and values are both strings. And the operations look something like this. We've got set and this takes a key and a value. And we've got get, this takes a key and returns a value. And we've got delete, which takes a key and deletes the key. There are other operations and there are actually a few other parameters here. But these are the basic ones, and you can see what these three main operations, set, get, and delete, we could actually implement all of the caching we've been doing in ASCIIchan in a system that will scale a lot better than having, you know, just a dictionary in our process. It also means that if, the advantage you get from using memcaches if our process restarts, we don't have an empty dictionary anymore, we have our memcached and, and our content lives on. So, what I'd like you to do first, is implement a fake version of memcached. Okay, so, in this quiz we're going to pretend that you're at Redi Memcached and at the heart of Memcached there's a dictionary. It's a big hash table. So, what I'd like you to do is implement these four main Memcache functions. We just talked about three of them, set, get and delete and I'd also, also like you to write flush. Let's go through what each of these should. So, set takes two parameters, key and value. And it sets the value of key in cash to equal value, and it returns true after setting the data. The importance will become apparent in the next quiz. Get takes a key and if the value is in the cash it returns the value, and if it's not in the cash, it returns none. Delete takes a key and it deletes that key from the cache. And flush takes no parameters, and clears the entire cache. And so, the behavior you should see after you've implemented this, so if you were to set x to one, it would return true. If you were to get x, it would return one. Because we just set at the one, if we were to get y which doesn't exist, we would see none. And if we were to delete x and then get it, we would see none. None of these functions should be particularly complicated, go ahead and give that a try. Okay, here are my answers. As you can see basically, you know, mem cache got's the hash table and dictionaries in Python are hash tables as well. The semantics line up really nicely. So all of these functions are very simple. Set cache key to value. No problem return true. To get, we actually can use the get function that's built in the Python dictionaries, which is basically says get key. And if the key is not there, it will return none. If we've typed something like this, this would raise an exception. If, if the key isn't in the cache, Python would complain. And the get function is used to avoid that problem. Deleting a key in the cache. So, first of all what we would do is, if the key is in the cache, then delete it. And this is the Python syntax for deleting something from a dictionary. Another way of doing this would be, to use the pop function. Which is built in the Python and what basi, basically this says is, find the key in, in the dictionary. And if it's there, return it, otherwise return false. And if you don't have this false, this will raise an exception. I find this approach to be a little bit more readable, however. So which is why I did it that way. And of course flushing a cache is easy. You just call clear on the dictionary. And let's give all these a run real quick to see if they work. I'm going to go down to my test little test harness here. And uncomment all these operations and then we'll give this a run. And we can see that things work. We set x to 1. And we get back true, which is what we expected, we get x. And we can see that the value is one. We get y. The value is none, because y is not in the cache. And then we delete x and then try to get it. And we see that x is now none. Okay. So our basic cache is working. Good job on that. And let's move on to some more advanced mem-cache. Okay. So one of the handy properties of memcached, and one of the things that makes a difference from a normal data base is, it stores everything in memory. That's why it's so fast because reading from memory is very fast. Reading from disk can be very slow. Which, which gives memcached a couple of properties. One is that it's fast. Two is that if you restart memcached, you lose all your data. So it's not durable. You know, if you have to restart that machine or restart memcached, the data isn't on disk. It's just in memory, and it's, and it's, and it disappears. So, you need to keep that in mind, that memcached is really just for caching, not for storing permanent data. Finally, the amount of data we can store in, in, in a particular instance of memechached is limited by how much memory that machine has. Or maybe you have a system of machines and your memcached library is bouncing over them. You can still only store so much data. So what happens when you try to store more data than there is memory available? And let's do this in the form of a quiz. Now, I know I haven't told you the answer to this, but see if you can figure it out. One of these answers is correct, and I'll explain after you give it a shot. Okay, and the answer is memcached just throws away data that is least recently used. So as you insert more and more keys in the memcached. If there's not enough room, keys that you haven't accessed in, in the longest amount of time just get purged from the cache automatically. So the cache automatically has the most recently accessed things. Let's talk about some of these other answers. It doesn't throw an error. Now if this was a database, it should throw an error because you want your database. You, you rely on your database to store your data and if it's not going to be the store, it should tell you. It shouldn't just silently, you know, you know, accept new data and throw away all data or something like that. But memcached it's not an error to store too much data. It can, it can only store so much. The next answer, throw away data that is least frequently used. This commonly referred to as an LFU cache, least frequently used. This is the common way of doing caches, but memcached doesn't do it that way. They use what's called an LRU cache, which you know, is least recently used. You know, least frequently used implies some sort of notion of keeping track of how many times each key is accessed. You know, it's a little bit harder to implement than least recently used, which is just a simple sort. You know, just throw the, throw the key add the key to the front of the list. And the final answer write the extra data to disk. As we said memcached is entirely in memory. There are variations of memcached that write extra data to disk. But, you know, writing to disk means, you know it's a performance tradeoff. Writing to disk is slow, reading from disk is slow. If you want to be writing data to disk, memcache probably isn't the right solution for you You know you can use a database or you can use some other piece of technology that's you know, kind of splits the difference, you know, sacrifices a little speed for a little bit more durability or space or what not. Okay, the next thing we're going to do, is add let's replace our dictionary cache in ASCII Chan with memcached. Okay, here we are in ASCII Chan. fortunately, memcached is, there's a, there's a version built into the App Engine that you run on your local machine, so you can develop against it. And then when you deploy your machine on App Engine, Google has memcache already spread out for you across many machines and you don't have to deal with it. So, that's a very nice convenience. First what we do, is we import it which is just, it's in the Google App Engine API memcache. So we do that. And now let's replace our dictionary cache with memcache. Which should be pretty straightforward, since the two behave very similarly. Okay, the first thing we could get rid of is this cache line, we don't need that any more. So, we got rid of our cache dictionary, let's use the memcache library now. Now, this syntax here, key in CACHE, and all that stuff, is specific to Python dictionaries, so we need to get rid of that. Instead let's try to look up arts up out of memcache. So it is going to be arts equals memcache.get key. In memchache in the official protocol, both keys and values need to be strings. In this library values can be Python DataTypes in the Memcache library. That Google provides, we'll convert your Python Data Type into a string. And then when you fetch the data out of the cache, it will convert it back into your Python Data Type. So we can still store our our objects directly in the CACHE but the keys need to be strings and so we're going to use top as our key. Now, we're going to change this if statement a little bit because now, we just looked up arts out of memCache. And if it's not in the cache Arts will be none. So let's structure this like so; If Arts is none or update, round the query and we don't need that other line. Now, so the query doesn't change, we need to change this line to set the key in the Cache. Which is memCache.set key, arts and that should do it. Okay, so let's go ahead and try this out on our browser we, we're in our page now. If I reload this page, we can go to our terminal and we can see that we ran a DB query on our GET request, and if we were to run another, if we were to reload that page again, I reloaded it. You would see that moved onto a DB Query, pretty cool huh. I want to show you something built in the App Engine is an Admin tool. If you are running App Engine you can go _aah/admin/memcache. You can actually view the memcache thing, if I reload this page, it says we have one item in our Cache. If I were to click Flush Cache, we can actually clear the Cache and if I were to reload this page and then check out our console. You can see that we ran a database query again, and if I go back to our page here and reload it, we can see that we have one item in our Cache, cause we just loaded it. This is kind of neat you can type in a, a k, key here and click Display and it'll show you the value, in that Cache. And in this case it as top is pickled. Pickled is the, Python library for converting a Python Object in to a string. And then the Google memcache library is automatically doing that for us. So, yeah pretty neat handy tool here. If you want to test your caching you can sit here and flush it and you can see how many items are in the Cache and manipulate it that way. Anyway that's how you implement ad memcache to your App. Once you understand the algorithm for caching, you know check the Cache, return the value, hit the deviant. You know that sort of thing, using memcache is a sinch. Okay, so adding Memcache to Ascii Chan gave us two new properties that are really nice. One is that our cache survives restarts. Before when we're using that dictionary cache, if we updated our code, either locally or in production, our cache gets cleared. That's not a good quality. Or if, you know, in production if Google for some reason. Moves us a different machine or something like that. What's going to happen, our cache would get cleared. Which is also you know, it's not a good property, especially if you have a lot of traffic. And our app is now stateless, which is the key to scaling. What stateless means is our app between any two requests, stores no state. And that means we ca, that, that a, a number of, a number of properties come from this. You know, there's no state between requests. Which means our apps are now interchangeable. Which means we can have multiple apps without any drama. You know, we have our load balancer, we have our Memcached. And in between those two pieces of technology are as many app servers as we need. You know, adding more app servers is easy. likewise, removing an app server is also easy and, and not painful. And it means our apps can be scaled independently of. Our cache and our database. So we've got our app servers. You know, we've got our, our database, and you know we've got our cache. And if we find ourselves needing more app servers, we can add one. Let's add our load balancer in here for good measure. So now I've got all these pieces. We need another app server we add one. If we need another Memcache, we add one. Having lots of caches means we won't have to scale our database quite so fast, but if we need more database, we talked about this in unit three. You know, we can go with replication or we can go with sharding. But now you're starting to see the the kind of the bigger picture of how a website might grow. If you're really data heavy. You have lots of databases and maybe lots of caches. You know, if your database is, is very read heavy but not [UNKNOWN] it's not actually not a lot of data you would have more caches. If your, if your application is very computationally intensive, maybe you have lots of app servers and you don't need so much database support or not so much cache support. But what we want to do, is we want to make sure that all of these different pieces can grow independently. And that's kind of what scaling is all about, is putting yourself in a position so that when your app is constrained in different ways, you can grow each part kind of independent of the others. And now that our app is stateless, it's really easy to do that. And Memcache helps a lot because all of the, all of the state is either stored in cookies, the DB or Memcache, but not the apps. And that's really handy. I'd like to talk about some advanced cache updates. Say we have this problem where multiple people submit posts to Ascii Chan at the same time, or submit to your blog at the exact same time. You know, let's say they hit multiple app servers, or different app servers. They both write to the database at the same time, and then they both update the cache at the same time. Overwriting each other. This can happen. This is a type of race condition where you know, two updates come in at the same time, and we don't know what order to handle them in and they both squawk them, basically one tramples the other. If we to draw this in a picture, it looks something like this. Say we've got two apps servers. Here's an example of the problem. And we've got our database. And we've got our cache. And say we've got el, elements in our database. We're going to call them one and two. And these app servers are both going to get requests from the user to, to submit a new entry into our database, you know, our new piece of art for ASCIIchan. And this happens at the same time. So this guy may submit element three. And this guy may submit element four. So our database is, you know, in sync because databases enforce these constraints. You know, you can insert as many things as you want at the same time the database will order it all for you. But here's the problem. Let's start with version one of this problem which is. Each of these app servers is manipulated in the cache directly. So this guy inserts element 3, and so he writes to the cache and he says, the database looks like this. And just as he does this, this app server finishes inserting item 4 into the database and he is not communicating with this app. He overwrites the cache to instead look like this. 1,2,4. Because this app server, remember we're not doing another query form the database, we're just manipulating the cache direectly. This app server squashed the other app server's update. That's, that's a problem. Now, let's look at another way this problem can ahppen. Say we were using the the first approach we talked about where we, when we write to the database we immediately do a read from the database and update our cache that way. We can still have this problem. First, this App server inserts element 3 into the data base. And then it says okay you know, let's, let's rerun the query, so we, so we can update the cache. But at the same time, this other App server Inserts element four into the database, and it also wants to rerun the query. So, each of these, you know, has a view of the database. This first app server thinks it's 1, 2, 3, and this other guy thinks it's 1, 2, 3, 4. Now, there's no guarantee this first app server will write to the cache for this one. because, things can happen out of order. Your app server can have a slight delay, you know, there can be a network glitch. There's going to be any number of reasons why this app server might run. You know might have a little hiccup and this guy writes you know, or, or, or this guys gets the right to the cache first. 1,2,3,4. And this other guy comes in and tramples on top of him. So there are a handful of ways where these app servers can you know, overwrite each other and if we, if, if we are redirecting the user to our front page to do the cache update that way. The, the odds of this happening is even more likely because it's not going to happen quite so fast, we've gotta go all the way to the user and back before we update our cache. So, that's the problem, you know, multiple app servers overriding each other in the cache because the cache doesn't have any transactions, it doesn't have any of the fancy stuff that the data base has. You know on that base we juts say insert this element but on the cache we say the list of elements is this so we can't just answer it at the front of it let me introduce one solution to this problem. So memcache has a way of avoiding this problem and actually has a couple of ways. And the first thing we are going to about is called CAS, which basically stands for Check and Set. And this basically makes two different it adds two commands to the protocol. One is called gets and this takes a key. And this is inside of get. And what this returns is, the value plus what they call a unique. Which is basically just like a hash of the value or a counter, it's, it's some value that's unique specific to this, to this value in memcached. And there's another command called cas, which takes a key, a value, just like set would. And also a unique and basically, the way this function works is for the key that you're setting. If the unique matches the unique that came out of memcached, overwrite it with a value and return, basically True. But if you don't pass any unique, or the key isn't in the cache, or the unique has changed. Don't set it and return False. So basically, what this allows you to do is, it gives you these two commands that prevents you from, from two people overriding the same key in the cache. So if, if we have two app servers. So if they both run this memcache.gets on a particular key at the same time. You know, they'll get two return values. They'll get the value, I'm going to call that v. And the unique, we'll call that u. And the fun of these app servers updates key. By calling cas, he wants to update key to the variable stored in y, using the unique u. This will succeed and it will return True. And if this guy tries to do the same thing, only, memcache will only accept one right at a time. It does it very, very fast but it'll only do one right at a time. So if this guy tries to run the exact same code, mc.cas. We are going to set key to a variable sort of y, passing in u. This one will return False. Because this, this app server got there first. And, and of the unique value stored in memcache changed. You know, what both of these app servers would really do, is that the, the code would look something like this. You know r equals and then like while r equals False. You have like, u, v equals mc.gets, r equals mc.cas k, y, u. So you have this loop where you basically, you know, get the new, get the new unique out of the memcached and then try to set it. And then once you're setting the unique that you got out of memcached. Or that is the unique that's stored in memcache now, matches the one that you got out, you know, that you made the correct edit. Now, generally you only use this when you're doing kind of a destructive operation to the cache. Like you're updating a list. You know, if you're just over writing something, you don't need to worry about it. But if you're kind of manipulating an object and the order of manipulation matters, you can use something like cas. And so what I'd like you to do is go ahead and implement these functions in our fake memcached. Okay. What I'd like you to do is implement the functions gets and cas. I'm in the file with our toy memcached. We've got our other functions set, get, delete. And cache is just a dictionary, which, whose behavior mimics memcached for the most part. What I'd like you to do is implement gets and cas. So, gets takes one parameter called key, and it returns a tuple of the value stored in the cache and a hash to that value. A simple hash we can use, is you can use the built-in Python function hash on the built-in function called repr on the value. Repr turns any Python object into a string representation of it, which will work for our little test case here. And hash just returns a simple hash of that, of that string. And if the value is not in the cache, you just return none. Now, cas is the more complicated function. This sets the key to equal value in our cache, and return true if the cas unique matches the hash of the value that's already in the cache. If the cas unique does not match the hash we don't set anything and we return false. If you look down here, we've got our test functions. The top few are the same ones before and down here you can see what we've, what, what we've got. So, here's setting x to two. And then we print gets x and this is going to print two and then a hash. It's not going to print the word hash. It's going to print a number. And then we're going to call cas try to set x to three. And in this case, I'm going to send in just zero, which I know won't be the hash and the cache would return false. And then if we run cas again with the correct hash, the one that was returned from gets, we should update the cache and return true. And if we print, get x, we should see the value of four, because that's what we set it to here. Okay, good luck with this. Okay, and the solution is like so. Gets is pretty simple. First we just call normal get on the cache, and if there was a value, return that value plus hash repr v which will just return a nice hash to the value for us. Now, here's the cas function. First we call gets. And if the value is actually in the cache. We have our value in our unique and then we compare the unique we got from our cache to the unique that was passed in and if they match, we call set and we return the value of set which in our case always returns true. Otherwise, we return false. Simple enough. Let's go ahead and give this a test. Okay, first off I'm going to run the basic functions. No, it should print through one, none, none and then a [UNKNOWN] of two and our hash which in this case is this number here and then it should print false. Because we tried to overwrite x with the value three giving it the wrong hash. In this case zero. And now that we have our hash. Let's go ahead and paste that into here and see if these next two statements run. Okay, so I click run again and we can see that we're printing all the original command still run, the hash is still the same. This cas command here, set x to three, with cache val, cache unique value zero, prints false. Because unique doesn't match, what it, what the unique should be is this value here. And when we try to set x to four we see true. And we get x we can see that it was probably set to four. So that's how gets in cas works. They are built in the mem cache, you won't ever have to implement them but now that you know how they work. You'll be able to use them in production that much better. And you have another tool in your toolbox for dealing with complicated caching issues. Okay, so after all of that, that leads us into a new quiz. Which is, why do we separate our services? Check all that apply. Is it so that they can be scaled independently? Is it to increase the fault tolerance? Is it so that two very different processes aren't competing for resources on the same machine? Or is it so they can be updated independently? And the answer is all the above. As we just spoke about, it's nice when you have a separate app server, database, cache, all of the, all of those separate pieces because different web applications have different needs and over time you may add features that strain the system in different ways. So having all of these separate systems means they can be scaled and operated independently. Increasing fault tolerance is a great reason. You know you don't want to have, the fact that your caches are bad, to ruin you know, all the parts of your website, you know maybe parts of your application don't need the database, so don't need the cache, there's no reason why one system should you know, ruin another. Or if you lose them you know, one cache machine, you shouldn't lose the ability to handle app server requests as well. So two different processes aren't competing for resources, whenever we talk about this one, but you know we've got an apps server and a database on the same machine. They use your computer in very different ways and having two machines running one an app server and one a database. And ma-, many cases under high load will actually doubly out perform a single machine. Because you've got the machine can make use of its own caching. You know, the processor cache and the OS cache and all that sort of stuff. That will be constantly being trampled by, you know, your app server tramping, your database caching and vice versa. So separating processes that behave wildly differently from each other onto separate physical machines makes a lot of sense. And also so these systems can be updated independently. Say you want to switch from PostgreSQL to MySQL or you want to switch from Memcache to Redis or something like that. Well, there is no reason why you need to take down the rest of your site to do that. You can update these pieces one at a time you know as, as you need to. So, these are all reasons why you want to separate your services and it's good even if you have all these services on the same machine initially that there's some kind of walls between them. So that, you know, have them communicate over tcp or communicate over some other sub system such that when you switch to having separate machines, you don't have to rewrite your whole web application, you know you don't have to re architect everything, you just kind of moving different programs around. So that's kind of one of the big keys to scaling. So that's kind of it for the main portion of this lecture. there, there's not going to be another quiz. But I just want to show you some more pieces and, and, and what would be a, a, a kind of a full web stack for a major website. That we haven't really talked about yet. So we've spent a lot of time in this lecture talking about the app servers and databases and cache. And the relationship between all these things. We also mentioned briefly a load balancer. There's some more pieces in here that a large website may have. So right now requests go from the Load Balancer to the Apps servers, who then go to the DBs, or to the Cache. What if we get so much traffic that one Load Balancer can't handle it? Well then we can add a second Load Balancer. But what load balances the Load Balancer? Well generally you something called DNS round robin. And what this means is DNS is the system that converts a domain name into a IP address, and that generally doesn't happen on your machines. Or that's rather, that's cached all over the internet. There are DNS machines all over the internet that all cache each other's information. So what you would do is you would give, you know, a website like udacity.com instead of mapping to, you know, one IP, it may map to, you know, multiple IPs, one for each load balancer. And then different machines in different parts of the world or different times of day or different requests might get sent to different load balancers. And that's one way to vary, vary high level to spread huge amounts of traffic across multiple load balancers. Another thing you may have either behind your load balancers or in front of them is another cache. And the, and this is like basically a just a, just an HTML cache. And this cache may, in, intercept requests before they even get to the app server. And this may cache HTML and images you know, all sorts of stuff that we know are not going to change for this user. Say, say it's a, a request comes in with no cookie, so no, the user isn't logged in. We don't have to do any dynamic request, we don't have to do anything special, well, we can just cache the entire result of the page. You know, the, all, all of the HTML we're going to turn not just the database query. Some examples of this technology are Varnish is a really popular one. We use this at a, Reddit and Hitmunk, it's really nice. Squid is another one. And a lot of people build their own because if you're at this scale you prob you, there's a high likelihood that you need a custom solution here. But you can have, basically more caches in front of your app server. Another thing you can do is use what's called a CDN. And say you, you know, you have got the whole internet here and CDN is basically a content delivery network. And these are usually third party companies that you would pay to cache your content all over the internet. So they would intercept your DNS requests. You know, they have, they have machines all over the world. You have your you basically have your DNS instead of pointing at your load balancers, point at the CDN. And it may point at, you know, may-, maybe do some round robin thing to different machines and that sort of thing. But basically these machines are just big caches, just kind of like this varnish cache here that say, okay, before I even send that request to my customer, do I already have it cached and these are basically just a big cache. So the name of the game is caching and the question is you know at what level do you cache and we've only been talking about caching DB requests but you can also cache you know, entire responses or you can pay somebody else to cache the entire response all over the internet and a lot of the biggest websites do this. You know Reddit pays a third party company to do so you know, Facebook and Google have data centers all over the world. And so, they do it themselves. But you know, as you grow and grow and grow, the challenges, you know, how much of this content actually is different on every request and how much is the same. And content that is the same can be cached. And you push that cache further and further away from you and closer and closer to your customer to get higher and higher speeds. And, when the content can't be cached, you know, you need to add lots of app servers and internal caches and internal, you know, custom systems for dealing with this type of load. So, that's kind of how the whole picture may look, you know, once you're at a huge scale. So, I hope you enjoyed this lecture. A lot of the stuff in this lecture I kind of learned the heard way, on Reddit, doing you know, starting with one machine, and then. Two machines and splitting apart the services on all of that. We made a lot of mistakes along the way and actually in unit seven is, is when I'll talk specifically about the process we went through of going from one machine to many machines as we were growing. Welcome to Lesson Seven. This lesson's going to be a little bit different from the previous lessons in that it's mostly going to be me and a couple other engineers sharing with you our real world experiences. So we'll start with how Reddit is architected today. So, when I started Reddit I knew not much more than you know right now, and over the years, we've had to scale Reddit to quite a big size. And I'm going to talk with Neil Williams, who's the current lead engineer at Reddit. And we're going to discuss Reddit's architecture, and how it serves billions of pages per month. It's quite a bit different from the sort of stuff we've been working so far in this class. But you'll see how we got there. And then I'm going to spend some time talking with Chris Chew, who's one of the Udacity engineers. And Udacity actually uses App Engine to serve their entire website. Just like you, I was new to Udacity a few months ago, and I've basically learned as I've gone through this course. And I've actually really learned to love it, and so has Chris at Udacity. So, we're going to discuss some of the real-world problems they've had to face that we haven't yet had to encounter. Now, nothing in this lesson is required for your final exam. So, it's just sit back and learn, and we'll have a good time. Unit 7--this unit is going to be kind of a grab bag of things I didn't get to cover in this class and lectures up until now. Basically, it's going to be real-world issues and some decisions-- what I look for in a web framework, how we host our stuff-- things like that and some of the decision-making process. And we also spent a lot of time talking about Reddit. How we grew it to the extent that we can explain that and how we grew the architecture. And we'll also do a couple of interviews, one with my friend Neil, who is the lead engineer at Reddit now. Another one with Udacity, the engineers at Udacity, who will explain how they use App Engine in the real world. Now, I've only use App Engine really in the context of teaching this course, and built a number of small toy websites now. But, these guys can actually talk about what is like to use App Engine in production on a site with thousands of users. There will be no quizzes. This is just for you to sit back and watch. If these things don't interest you, just skip ahead to the homework. If these things do interest you, welcome. It should be fun. One thing that's come up a lot in this class --a question I've seen a lot on the forums-- is how do I organize code. You don't want to keep all your stuff in one Python file. What's the correct way to organize things. The first thing I had to say is there is no correct answer. Code organization--whether you're writing web apps or any other type of software-- is something that comes from experience and you can develop your own style. When I'm building a web app, generally things start off in one file, and in this file we probably have a section for handlers. These are the classes that define what we do when a particular URL is hit. Almost every framework I've worked in has this notion of a handler. It also has this notion of a URL mapping. This maps a URL to a particular handler. We've dealt with this a lot in this lecture. There is also some DB stuff, some objects, the models, the things we're actually working on-- blog posts, pieces of art from ASCII Chan, links and comments, and that sort of thing. Then almost immediately I have separate files for static content-- things like CSS, JavaScript. We haven't done any JavaScript in this class really. Images I store separately. You could encode them into your file, but that doesn't make sense. You just store them separately. Generally you serve them separately as well. App Engine makes it easy to do that. Another thing that's almost always separate from the beginning are templates. I almost always separate templates from the beginning. I didn't teach them from the beginning in this class because I didn't want to explain HTML and new Python and also this new mini-language of templates all at the same time. I've never actually taught templates directly in this class, although most of you seem to be using them at this point. You've found the documentation. People have talked about them in forums. These are always separate. As things grow, this file here is actually my main file. It's actually often called main.py, at least for me. The first thing I do is I pull out the DB models. I generally have one file if it's required. We don't need this in App Engine. Refer to it as the ORM. I almost always write my own ORM. I don't really like the home-brewed ones. ORM stands for oject-relational mapping. This is a piece of code that basically maps your Python objects to the relational database. Often it'll have a little query language that compiles into SQL--that sort of thing. We haven't had to deal with any of that in this class, because the App Engine provides it to us. The db.model thing we've been using to interact with the Google datastore-- that's basically an ORM. The data model underlying it isn't strictly relational. Effectively what it's doing is taking your Python objects and abstracting away querying and cursoring and all of that stuff you have to do to get stuff in and out of the database. I generally have a separate file for each type of data. In our case, we've been talking about posts and art. As our systems grow and you have more datatypes and users , I generally pull those apart into different files and have a bunch of class-specific functions in each of these--password hashing and all that stuff would go in a users file. Functions to get the top post and top arts would go in those separate files. I kind of pull all of that out. The next thing I almost always have is some sort of utils. I usually have a utils file or utils module --a series of files in a directory-- that basically have all the random stuff --things like makesecureval and makesalt and randomstring. Handy things. Generally, I want to put as much into utils as I can--just a list of flat functions that have no dependencies on any other part of the project. The reason I do this is so that I can test these things. These are often little helpful files that any piece of the project can manage. I have a lot of date manipulation stuff in these files, a lot of string manipulation, escaping stuff --all those sort of functions that I write I usually put in a file. It usually starts out called utils.py. It's really important that it's always a one-way inheritance. Handlers can import from utils. Databases can import from utils. Anything can import from utils, but utils never brings in other parts of the project. That just kind of keeps things simple, and if you think about it that way, you'll have this nice, clean file with a bunch of handy functions. If you look at Reddit's source code, there is maybe about 100 handy little functions that we use all over the code. I usually throw that in one spot. Then the final thing I do, and this usually takes more time as the project grows is I take handlers out of main.py. You might have separate files for each type of handler. For the homeworks I may have a separate file for just the blog, a separate file for ASCII Chan, a separate file for those Unit 2 ones--the rot13 stuff, and then main.py is basically the url mapping and then a bunch of imports. Then these guys would import whatever database pieces they need. It kind of keeps things separate. Sometimes it's really hard to enforce this, and you can have what's called a circular import where one file--rot13 may depend on some generic files that are defined in main.py, which depends on the actual handlers in rot13 itself. You get this kind of circular import. Generally when you start having circular imports that means it's time to pull some common piece of functionality out so the inheritance only goes one way. For example, I have that generic handler --I think I've been calling it blog_handler in my homework solutions--that just kind of has all that helpful stuff on it. That would get pulled out into its own file so that main.py could import it, if it needs it at all. The big groups of handlers can import from there as well. This is basically how I organize things. I'm going to draw a slight different picture of how the file system might look. We'll leave it at that. Now, again, this may not apply to you, but this is what's worked for me. Usually at my top level I have /main.py. I probably have some sort of common file that's called like handlers.py or something of that nature that basically has the generic handler-- things that happen on every single request. Then I'll probably have a directory called /lib that might have some of the DB stuff, which may have all of my models. I may have utils.py and any of the specific stuff that we're doing. Got that generic handlers.py. It might have the other handler as the blog.py, the rot13.py--that sort of thing. The bulk of the code is either in handlers.py or in each of these specific things. These are the pieces that import from all the other parts of my projects. That's generally kind of how I start. Things grow from there. Of course, I have directories for templates and static. I'll keep things organized that way. If we need subdirectories in either of this, I may add them. But actually generally for me my templates directory is just a monster pile of templates. Of course, as you get more advanced with templates, these can start inheriting from each other. I almost always have something like a base.html. Then most of my main templates will inherit from this. There you go. I hope that helps. Many of you have been asking. Let's move onto the next piece. So another kind of big classic questions I've been seeing in the forum's lecture is hosting. Specifically people want to know if you're not using Google App Engine, what else should I do? Or why should you use Google App Engine instead of the alternatives. So let's talk about each of those. The first option is to run your website locally. And this basically means run this out of a machine that's in your house, or in your dorm room, or it's your everyday computer--the same machine you might be developing, which works fine for this class. Basically, the website doesn't have to be on all the time. It just has to be on while your submitting your homeworks and that's it. For almost every other use case, it doesn't really make sense. Some of the big drawbacks are--it's not always on. The Internet doesn't go to sleep neither should your website. It's not always accessible. By that, I mean your Internet may be broken or power goes down. There's lots of--you're running in the house. It's not a data center. So there's lots of things that can go wrong. Your IP may change. Depending on your hosting provider, you may need to pay extra for what's called a static IP, and this is an IP that you have to pay extra for so your IP address. Basically, the location of your machine on the Internet doesn't change. Because you want to have a name for your website--domain name-- and that domain matches to an IP. If your IP changes all the time, which it does with most Internet connections, it won't work out. Now there's technologies to work around this but probably won't have a static IP. The next thing you can do is you can co-locate. Basically, this means buying space in a rack in a data center. So, you still buy your own machines and you install them in this data center or maybe you buy a whole rack or you buy a whole cage but basically a lot of websites do this. The biggest ones have their own data centers. The biggest reason you do this is you have control over the machines. You can build whatever machines you want, configure them however you want, and wire them together however you want. They're your machines, and you're renting the space. Generally, you pay for things like rent to have your space, and then you pay for power and bandwidth. You pay for 30 amps or 60 amps to power a couple of machines in a rack, or you may pay for many more to have a whole cage of machines and you pay for how much bandwidth to use. You maybe only need 10 megs a second or maybe you need 10 gigs. It all depends and you have control over all of this. Downside is there's a high amount of work. You have to actually administer these machines. You have to install software. You have to maintain them. If they break, you have to replace them. It's a lot of effort. So, if you're not good at sysadmining--system administration--doing all that sort of thing colocation is a tough option. If you like doing that sort of thing, you can save some money by co-locating or if you're a big website with highly specialized needs, data centers are the way to go. Few large websites don't control their own machines. Another option is this kind of manage posting. This kind of industry is changing right now. It used to be the case just a few years ago that you would rent machines from a data center, like, these machines would already be installed and configured and you could just, you know, rent five of them. Could do all of this online. And the industry's changed a little bit. This is kind of new system of dealing with this which is basically kind of this match hosting cloud set up. And that's, that's what I'm going to focus on here, because the kind of in between guys aren't nearly as popular as they used to be. So these are players like AWS. Rackspace, Linode, I think, kind of does this sort of thing. They're all those, these are the ones I've hear of. Reddit and Hitmonth both use AWS, it's my personal favorite. Generally the idea is you are renting machines. In the case of Amazon, I can't speak for others, you rent machines by the hour. So we pay $.10 an hour or something for our machines on Amazon. You don't have to think too much about bandwidth and power. You don't think about power at all. Bandwidth you generally pay some amount for. You can install the operating system if you want. More likely you're just configuring the OS, not installing it. You're in the system where your machines can just kind of disappear. If your machines fail, the hosts may bring up a new machine for you or they may notify you or you can write scripts to automate this whole thing. This is the area where I like to live personally. Still get control over your machines in the sense that you can, you know exactly what software is installed, what versions are installed, what kernel is installed, all of that stuff. But you don't have to deal with actually installing this machines in a rack and replacing them by hand and doing the physical work. It's all virtual. I've never seen the service that host Reddit and Hitmonth. With Reddit we started out renting a few machines from this manage hostings provider, kind of pre-Amazon pre-Rackspace seven years ago. Then we started co-locating our own machines and then when Amazon, AWS, Amazon Web Services came out, that's when Reddit switched to Amazon. In the office, in the Reddit office, there's a bunch of physical machines sitting under a desk that used to actually run Reddit. 20, 30 machines, whatever there were. There is this new setup--a new level of existing, which is like the Google App Engine/Heroku model, which is completely managed. You don't even really think the concept of machines. With Google App Engine, you just upload your code. You don't think about OS. You don't think about anything. You just give it a wad of Python, and they just run it. They run machines with databases. They do the charting. They do the replication on this basically zero sysadmin, which is a great way to get started and depending on how you like to work on your technical sophistication, on the complexity of your website, this may work fine. A lot of big websites have been built in this system. Udacity, being one of them, runs on Google App Engine, but it also means when you want to customize things, it's really difficult to do things that the providers of these services haven't thought of ahead of time for you. And that's kind of the continuum of setups. There is no penalty for choosing wrong when you start because you can always switch in between. It's not always easy--when we switched from colocation to AWS, Reddit was a fairly large website at that time, so that was a little bit tricky. We had two infrastructures and slowly migrated traffic from one to the other at a very high level, which actually worked okay. I'd suggest when you feel like you've outgrown Google App Engine or you want to do something that App Engine won't quite allow you to do take a look at some of these other services and see if they get the job done right and then maybe as you should get really, really big you hire a dedicated sysadmins, and maybe you want to have your own machines because it's a little bit cheaper and bandwidth requirements are higher than what Amazon can do, for example, or your storage requirements or data needs, you need more, more, more. That's when you start thinking about having your own cage or having your own data center. Another thing you guys have asked about a lot is, is how you choose between web frameworks. Now, remember the framework is generally the key step that sits between your program and the internet. Now, in this class we've been using the Google App engine frame work, which is basically called Web App 2, which I found really nice. This handles, basically, basic HTTP, kind of the scheduling, like the threading issues, you know, handling multiple requests at once. Parsing basic headers, basically looking for things out of the GET request or the POST request and putting them into these, like, request objects. Turning your response object into the appropriate HTTP to send to the browser. The URL mapping and all of that stuff is really helpful. Various degrees of web framework that give you more or less control and require you to do more or less work. The level that we've been working on in webapp2 is the level where I, I really like to be. The things that I, I really like about it are that we have direct access to GET and POST. Some frameworks kind of hide this from you, and I think it's really important that you are explicit about which method you're handling a GET or a POST. If you're thinking about the web in that way, your websites will generally make more sense. You won't make the mistakes of having, or you won't as easily make mistakes as having your, you know, your GETs modify the database and then getting cached weird and, you know, your forms not submitting properly. Understanding webs and web applications at the kind of method level, I think, is very, very important. We've got direct access to the request. You know, this means things like headers. Yes, there are convenience functions for setting cookies and getting cookies, but you can also manipulate the headers directly. Sometimes you'll want to do something funky with content type or content length. Then if the web framework don't let you do that, it can be really frustrating. You can't build the site the way you want to. So I find this kind of low level stuff is really helpful. But it's not so low that you're dealing with, like, HTTP versions and host headers unless you really want to. There are kind of features that a lot of frameworks do that I think that are non-important. This is strictly in my opinion. Things like sessions, caching, some have automatic forums, database ORM stuff. I don't like working with these because I find every time I use something like this, it's very soon after that I need a custom behavior. I want to handle sessions differently, or I want to cache things differently, or my forms don't fit the way the author thinks forms should work. Or, you know, the ORM can't express queries that I want to express, or won't let me cache the way I want to cache certain queries. So I find this sort of stuff is a little too high level for me and I always end up rewriting it anyway. To me, the important things are basic HTTP, having access to headers, and GET and POST. I almost never use pre-built session things, and caching, forms, and database stuff. In every experience I've had, in the long run, I end up getting frustrated and I have to rewrite something that would have just been simpler to do in the first place. I generally don't like magic. When you look at some code and it just seems too magical, like it did all of this stuff for you and you're so far away from the request that you don't actually know what happened, that's a terrible way to write web software. You're not going to be able to scale it properly. You're not going to know why something breaks when it inevitably does. And it's going to take you, I think ultimately it will cost you more work than just thinking through each of these problems on your own. Sometimes, it's a good way to get started. Something I didn't discuss here are the notion of templates. Template languages come in all varieties. I am partial to one on Python called Mako. What we've been using in this class is Ginja 2, and Ginja's also been great. I think that the discipline here when you're using templates is making sure you separate code from templates. A lot of these template systems allow you to put arbitrary code in them or complicated logical structures, if and for and while. Try to keep it to the, the amount of code in templates to a minimum. You've got this whole language you know, in our case, Python. That's a very, very powerful langauge, you can do all sorts of things. Why would you use a broken subset of that in your templates? Any complexities should be actually in your Python code and not in your template code. Didn't come up much in this class because most of the rendering code we're using was fairly simple. It's really easy to just throw complete objects and big data structures and unwind them and, and navigate them in your template code. And that's something that's just really difficult to maintain. I wouldn't recommend doing that. Templates are great, but use them with care. Use them for just generating your HTML. Or just generating your CSS. Or whatever you're using it for. And try to keep the code in the actual programming language. One thing I like to mention really quick is how I work, in terms of what things I have open. This is something that I always try to get guys who work with me, at, I'd rather not have a month to do. Got your browser, you're running your things in it. And you've got your editor with your code in it. Your browsers got some pictures and some text. If your screen is big enough, I like to have them side by side, but sometimes that's not the case. Something people often neglect is having your terminal nearby. I almost always, like when I'm doing app engine or my own stuff, run the app server auto terminal so you can see the logs. If you're developing, without being able to see your logs, there's so much stuff you're going to miss. I find many, many bugs just by using my website as in developing, and watching how the, how the logs goes. Because many times there's an error that you're not even aware of that could be a big deal in production. You could have fixed it in five seconds if you had just noticed the logs scrolling weird. An, another important thing, and this is one of my frustrations in App Engine right now, is it's critical if you're writing code that writes to a database, but the queries that you're running are printed to the log. I've kind of tried different strategies of hacking my app engine to print every time it runs a query, because if you've got some complicated setup with your database and your cache, and your mem cache, and maybe a local cache, and all sorts of things, you want to make sure it's working. And I know when I'm developing I often introduce bugs that has somehow prevent something from being cached properly. And if I am browsing along and I see all these database queries scrolling by that shouldn't be, that's a sign that something is broken. And I want to make sure generally that every page I run doesn't hit the database unless absolutely required. If I see a query running that shouldn't be, you know, I can catch it by just having the log open. Try to get in the habit of when your switch from your editor to your browser that you instead switch from your editor to your browser plus a terminal, so you can see things working. You start to get a sense for how the logs scrolls when your website's working normally, so when it deviates, you can detect it faster. You'll save yourself a lot of heartache doing it that way. Now, I'd like to move on to how we actually built some of these websites that I've been referring to. We will spend a lot of time in this class referring to Reddit. You know, we've used it as database examples, I refer to the system architecture, things we did, and I've referred the mistakes I've made over the years on Reddit. I'm going to kind of take from the top how we built Reddit and how we grew it over the years and then I'm going to talk with Neil, who is the current lead engineer of Reddit, and he is going to talk about how they taken over since I've left, which is a couple of years ago now, and continued to grow all the site as it has grown tremendously. So we started in June 2005-- me and my co-founder, my college roommate, his name is Alexis Ohanian. I was the engineer and Alexis was our kind of everything-else guy. He paid the rent. He did the business-guy stuff. He did the marketing things. He was my sounding board for future ideas. He did design work for Reddit. Him and I basically lived Reddit for the first 2 years, the two of us. When we started, the first vision of Reddit was written in Lisp, which is an actually very old programming language, one of the first ones. I think it was originally invented in '50s. It is still one of those powerful languages. It is very fun to develop in. One of the other professors here in Udacity, Peter Norvig, is one of the world's Lisp experts and a couple of his books are extremely good on the topic of Lisp. It is more popular out set universities than it is in the real world, it's really need to working. During this time, we had variable traffic, but everything was in Lisp-- our Handlers, as you'd expect. Our HTML was all generated by Lisp. Our CSS was all generated by Lisp. Javascript. Lisp is a language that lands itself to generating other languages and other pieces of code really, really nicely. I'm not to get in to the details of it, but Lisp was all we had. We had Lisp plus Postgres. We didn't have any memcached at that time. I've just stored everything in an in-memory hash table. The architecture originally looked something like this --we basically had one machine that we were renting from this company--I'm not even going to mention their name, they're so bad. I'll try to only mention companies I like. But we are renting one machine and let's basically ran this, and this is all of Reddit. We're also running post quiz on this machine and that was it. We didn't have any fancy caching. I just used in-memory hash tables. The database had a fairly guessable structure. We had a table for links, we had a table for votes, and a table for users. That may have been it to begin with. There wasn't a whole lot to Reddit. We didn't have any comments for a long while, and the links and votes tables were basically kind of as I represented them in this lecture. These had things like score, title, URL. Vote basically had a length ID, a direction. User had a name and a password. Notice I didn't say password hash-- I actually stored the password and told you that story how I'd gotten trouble as a result of doing that. We actually did a lot of joins--this lasted probably about for 6 months or so. After 6 months, we hired a couple guys --well, we kind of merged our company with another company called Infogami and that brought us another engineer named Aaron Swartz and we hired Chris Slowe who was doing a PHD at the time. So the four of us--me, Alexis, Aaron and Chris-- worked on Reddit then. And the first change that Aaron and I made together was we reroute Reddit from Lisp to Python. And then at about the same time, we pulled the database out of that one machine and put it on the second machine, and so now we had two machines with this hosting company--our app server and our DB. And the switch from Lisp to Python was kind of performance agnostic. Lisp was a faster language but our rewrite of Python was better, so the code actually run at about the same speed. Going from one machine to two machines gave us something on the order of 4x speed improvement. Remember how I talked in the last lecture about separation of services--separating our app server from our database gave us a tremendous speed improvement because these two pieces of software run totally different --use computers in a totally different way. That was the first architecture change we made. I think we upgraded this machine once or twice to like a more beefy machine. At the time we are still plagued by downtime, whether it was our Lisp or a Python program, it would occasionally just crash and we'd have to get notified--more often I'd just get called. I would check the site or somebody would call me to tell me the site was down and I'd bring it back up. There's so many easy ways to avoid this scenario. It makes me cringe when I think about how much time and stress I spent on not knowing whether our website was running. The way we do it now is we use a piece of software called Supervise, which we integrated shortly thereafter. Basically what supervise does is that it watches a program. It runs a program, and if that program crashes, it restarts it. And that's really a nice setup to have, and we actually got to the point where we'd run two Python programs on one machine and then we had a little mini load balancer kind of running on that machine as well that would send traffic to both of these Pythons and if one of them died, Supervisor bring it back up. And so unless the whole machine died--luckily, it never actually happened to us. On the website would stay running. At that time, we still only had one database machine. We were very lucky, and we're very lucky that neither of these machines ever died Because if you lost this machine, the website would have been down until we could get a new one, and our hosting provider was very slow--it would've been very difficult. And if we had lost this one, our database machine, we would've lost the data--like forever. We weren't doing good backups back then and it was really fortunate that Reddit turned into a popular thing, and it's really cool that we still have those archived as a result of luck that we didn't lose those because you will lose machines. Machines die all the time. This is kind of a fact of life. I mean you're running these machines around the clock, high load, hard disk can fell, memory can fell--there's lots of things that can go wrong if you use a machine constantly on high load. The next thing we did to increase the speed of the site was we added another database, and this was using a piece of software called Slony, I believe, to replicate our database. We still only had one app server at this time, and we made lots of database requests. Our caching was not nearly as advanced. We had some basic caching, it was just at the application level. This machine was hitting both of these Postgres machines. This is the first time we ran into the notion of replication lag, because we have these two separate machines, and Slony would normally keep them in sync, but sometimes, the slave machine could lag by about 5 seconds or so. If you had just submitted the link and then we redirected you to the permalink, and then we'd hit the slave machine that didn't have the permalink we would send the user a 404, which is really annoying right after you submitted a piece of content. That's when we started thinking about writing to our cache at the same time as writing to our database. We also had the issue with these two processes of keeping these caches in sync. We weren't using memcached yet--the way we kept our caches in sync was we used the library called Spread, and Spread is this network library that basically says if you send a message to one host, it will send it to all of these other hosts. Around this time was when we added our second app server that was running Python on as well, and we used Spread to keep the two hash tables that we were using as our cache kind of in sync. This worked sort of okay in terms of keeping these two caches in sync, but it wasn't going to scale very well, because eventually, we would add a couple of more app servers to deal with more load and Spread like every time one of these app servers would update its cache, you would have to tell all of the other app servers about it and so turned in to the huge mess, a lot of network traffic keeping all of these caches in sync. It was a total mess, and so eventually, we would switch to memcached, but that was not before we rewrote our database. Shortly after we switched a couple of machines and a couple of databases, we added comments, and the first version of comments--it was just another database table. There's nothing complicated about it--it had a link ID of what link it was on and had some contents, author ID--you can kind of guess the columns it would have, and we still did lots of joins--it was a relational database. We changed around this time to a more flexible database architecture, or at least a more flexible table design, because the challenge we had was every time we added a new feature, you might have to add a new table or you might add a new column to one of these tables. Adding a column would take time, and we might have to do a data migration or update an index and add all these load--it was just a total pain. We felt like the rate at which we could add features was limited by our ability to update our database and to do these big migrations. We switched to a thing called Thing DB. I think it's still called TDB in the Reddit code. If you find any code that's called TDB or TDB2, I think, this one was the second version of the Thing DB that I wrote at some point, this is what it's referring to, instead of having a table that looked like this--a link table with a bunch of different columns on it for different things--we would instead do something like this, we would have a table that just had a couple of properties on it, a couple of properties that everything had. Let me see if I can remember these things. Everything has a score, an author, and a date. There might be a few other fields like ups and downs, kind of encapsulated in the score, but basically, everything whether it's a link, whether it's a comment, whether it's a subreddit, anything has these fixed columns. It's not useful for all of them. It's pretty common enough. This was called the thing table, and we had a separate table that every data type had called the data table, and the data table basically had three columns. It had the thing ID, which thing are we referring to, and it had a key and a value. For a particular data type--for a link, for example--a link might be represented like this, we'd have an entry in the thing table, it might have a score of 5 and of course it has an ID 1, an author of 0, that was my user ID, a date when it was submitted and then it might have a data table. It may have a bunch of rows in the data table. It would have 1 row that would be like thing ID 1 equal the URL and another row thing ID 1 title. So, for every property of a thing that wasn't common across all of the things, we would have a row in the data table, and these are actually different database tables. They could be on different machines. This allowed us to add features much quicker. Because if we wanted to add a new data type to links, the new links would start getting that new row. We wouldn't have to go fiddle around with adding it for all the old links. We could just keep our code. The difference of the link doesn't have this property pretended it has a default value, and this was really cool. It also allows us to add all sorts of features without having to get the data types right way in advance. It also allows us to add all these new data types. For example, down the road, we'd add subreddits, so users can make their own kind of categories--their own Reddits--and that's just a thing. It made our development process a lot simpler, and I wrote this whole layer that would kind of map our Python objects to these data tables. So we had these app servers that were all running their own caches, and then we had a couple databases that were all replicas of each other. At this point we added a load balancer, and this load balancer probably actually ran. It was probably a program running on one of these app machines, and these guys were still keeping their caches in sync using interacting with the databases directly. And we had a limit ot how many app servers we can have because we had this complicated caching spread thing. The next thing we added was the memcache layer. So instead of these app services containing their end memory cache, they would communicate via memcache. So instead of having to keep their cache in sync, we just had 1 cache that was just shared among all of our app servers. I'm sad it took us so long to figure this out because memcache existed when we started reddit, and we should have been using it from the beginning. This is what allowed us to get all of that state, all of that cache, out of the apps and into memcached and allowed us to add apps arbitrarily. Once we had that going, that allowed us to scale our apps and they stayed in sync, and so we can add an app, lose an app. We didn't have to worry about it. The next thing we had to start dealing with was the database load. So we're already replicating for kind of durability and for performance reasons, so we can spread our reads across multiple machines as we started segmenting on type. So we'd have a database for just links; then we could separate comments out into its own database. And so these would still replicate to each other, but if you're only submitting a link, you only have to touch this database, and if you're only, like, reading a comment, for example, you only have to touch this database. And this is actually still basically the general setup reddit has today in terms of how the database is scaled. And we never wrote sharding in the beginning, and I really regret that. When I rewrote the ThingDB, the second version of it, I had in the back of my head, you know, I should add sharding, because we're going to need that someday. And then I just wanted to get the damn thing into production so I stopped. The big lession I've learned is when you're writing a big system like that, if you don't do the hard parts up front, you may never get another opportunity to them, because now the database is so big, that if we wanted to bolt on sharding, that's a huge project. It's easier right now to just add bigger machines and more caching. It's not going to work forever, and somebody's going to have to bite the bullet and do that. And it would have been a lot easier to do it at the time. Since all of our queries, we stopped using joins when we switched to ThingDB, sharding's actually fairly straightforward if you kind of do it right from the beginning. Over time some of the software on these app servers changed so we've always been using Python. I don't remember what app server we used originally. We switched from whatever we used initially to web.py, which is a framework that we wrote at reddit. Aaron was basically the main author of that, and it's still out there on the Internet somewhere. And this is where the first time I recall seeing a framework that had kind of the notion of a handler class and then functions for get and post, and I've become kind of addicted to thinking of web applications that way. Actually the Google app engine, the webapp2 framework, inherited a lot of that design from web.py, which is nice. Nice for me, at least, is that design decision has kind of stuck around for a little while so I think that means it was a good one. Now Python uses a web framer called Pylons, but it uses a very old version of Pylons. And basically when we switched to Pylons, Aaron had stopped maintaining web.py. I didn't want to maintain it. We switched to something else maintained by somebody else. And then we basically shredded most of it and made it function just like web.py. In hindsight we probably should have just written our own because that's effectively what we did, but we did it on top of Pylons. So if you want to use the reddit version of Pylons, it's open source. It's online. But it doesn't resemble anything like the actual Pylons web framework at this point. And to my knowledge, that's still what they use today, this hacked up version of Pylons. One of the other big architecture pieces we've added to help us scale was this notion of a precomputed cache. We found ourselves running these queries to generate the hot page for Reddit over and over and over again. You may cache it for a minute but then once that minute expired we had to recalculate it. We had a job--a kind of job that would run and just compute it and then put the stored value in memcached-- that worked okay but then we had to do it, we had all of our users pages. Every user had their own listings of things they've submitted and liked and their top things, and every Reddit had a new page and a hot page and a bunch of different sorts So we stared precomputing everything. The way we did that is that we have this whole other database stack. These are the replicas of the link database--basically, more link databases. They could lag a little bit. It wasn't a big deal. Every time a vote would come in, we put in this queue--queue is just a list of things to be done-- and we have this machine that basically manages huge list of things, and we had a couple of other machines that we called the precompute servers. What these things would do is they take jobs off the queue. This link has been voted on. Actually, what the apps would do is when a link was voted on, they would add a number of jobs to the queue. The jobs might be to recompute Reddit's front page, recompute this user's liked page, recompute this user's top page, recompute Reddit's top page. There are all sorts of different listings that are affected by a particular vote. These machines would pull off these jobs and then they would run those queries against the database. They would just mercilessly as fast as they could take a job off the queue run the query against these databases. These databases were really, really hot and had no real-time requests. No request from the Internet actually ever touched these precompute machines. It's only these guys, these precompute servers would touch these preocompute databases. When the job was done running, we would take the results and store them to memcached. That way almost every page you looked at on Reddit would be fetched out from memcached. There are very few things you could do on Reddit that would actually directly manipulate a database. Once we got to that point of scaling, things got a lot easier. These are really just kind of the last resort primary sources of data, but any data you can access on Reddit in real time is actually served out of memcache. Every single listing is precomputed and stored in memcached for Reddit on the whole site. This is the reason why now you can't go back beyond about a thousand links on any particular listing. It used to be, you can go to Reddit's front page and hit next, next, next, next, next and then go all the way back to the beginning of time, which will just really, really trounce our databases, do a lot of damage, slow the site down, etc, etc--you can't do that anymore. We only store the top thousand for each sort, which is one of the limitations of doing this precompute thing, but on the upside the cycle is very, very fast. There are very few legitimate reasons to go all the way back to the beginning of time on Reddit anyway. This worked out really nicely, and the site to this day still has this general structure, although a lot of the technologies have changed, and that's what we're going to talk to Neil about. Hey everybody. We are joined right now by my friend Neil Williams, who is currently the lead engineer at Reddit. Maybe you can tell them a little bit about what your job entails these days. Well, I basically focus first on fixing anything if it's broken, and otherwise I try to figure out what's, what's the path for the site, like what's becoming a bottleneck and then try and fix that and make the site fast again. How much traffic does Reddit get these days? Last month we got 2.7 billion page views. That's billion with a b. And I think when I left Reddit, which was in 2009, we were nowhere close to that amount of traffic. I don't remember specifically but I think it's like 10x difference. I thought Reddit was pretty big when I left, and it was, but it's a lot bigger now and, and Neil and his team are basically the guys responsible for keeping the site fast, online and functional. Which, you know, over the course of Reddit's history, has that always been the case? We try. Yeah, you know, you guys do a very good job. It's a very impressive job. So what we're going to do in this, in this interview here, is I'm going to kind of, I'll, I'll start off by describing how things worked with Reddit before I left. And then as we said, traffic increased dramatically. And Neil will show which parts of the system are gone and what they're doing now towards the future because a lot of things have, have really changed. You know when a site grows, grows by huge, huge amounts you, you have to keep adjusting. So so the way things were when I left if I recall, Neil will jump in it's been a few years for me. The first piece of infrastructure we had was the load balancer, and we talked about load balancers in unit six. The one we used was called HA proxy, and you guys still use HA proxy, is that right? Yes we do. Yeah, it's fast, it never breaks and works for us all the time. I remember the day I found HA proxy. It was probably in 2007 and for, god, I mean even after I left for a while I, is this still the case, do you have, you have multiple HA proxys now, right? Yes. Like we were for a long time, like we had this super scalable architecture and one HA proxy. We had one machine running one HA proxy and that handled millions of requests a day. It was pretty incredible. So of course, outside of HA proxy is the internet and all of the Redditors, the unwashed masses of the world, users of the site. We also used Akamai. Yes. Do you guys still use Akamai? Yes we do. Remember we talked about CDN's, Content Delivery Networks in the, in the last unit. Basically these are third-party caches. So Reddit pays Akamai to ping the site periodically, cache the content and deliver it to users who, can view cached content. We use that for logged out users only. Since everybody has their own personal page if they're logged in. But logged out users all see. The same content. The same stuff. So, so logged out users hit Akamai. And logged in users who have custom content, you know their username, their votes, all that stuff come in via the internet, and hit HA proxy directly. Behind HAProxy we actually get into the meat of Reddit's infrastructure. We had a bunch of app servers. These are physical machines that are running Python programs like you've been working on in this class. When I left I think we had maybe 20 of these. It wasn't that many. How many do you guys have now? 180. Okay. That's pretty significant. They went from 20 when Reddit was a big site to 180 when Reddit became a huge site. Now, these are running Python. They're using a web framework that I talked about previously in this unit called Pylons. Do you guys still use Pylons? Yes. This handled just about every request. I don't recall if we had special web servers for static content. Do you guys have special web servers now for static content? We use S3. S3 for static content. Oh, yes. We just transitioned to that at some point before I left. Everything we do is on Amazon AWS. Basically you rent machines from Amazon, and one of the systems in AWS is S3. Maybe you could explain what S3 is an how it works. Sure. S3 is a simple storage service, and it's basically a distributed file storage thing in "the cloud." Amazon lets you put objects into the buckets, and it's literally just a key value store of these files, and other people can hit a URL and grab the object. We store all of our static content like CSS and JavaScript on S3. When you're hitting the site, you're actually going via Akamai to S3 instead of our infrastructure. So for static content, a user never even hits HAProxy or the app servers or anything at all. Yes, for the most part. And we can get away with that because the content never changes. Right. So I know in the early days of Reddit--and certainly in the applications we've been building in this class--all of the content, static or not, gets served from these app servers. As you grow, there is no reason why you need to waste all these resources handling connections for JavaScript and CSS and images. For a while we were using EngineX for the static content. I think we were just in transition when I left. Some of the static was on S3. We just moved all of the CSS and stuff in October. We were using EngineX and it got to the point where the one EngineX server doing all of the static content couldn't handle it anymore when we changed the content. Everybody's caches were invalidated. So we would do a deploy of new code, and there would be this static content change, and all of a sudden that EngineX would get overloaded and everybody would be getting completely unstyled Reddit. Okay, I've seen that happen a few times. So EngineX is just a web server. Back in the early days of the internet, almost all the content online was static. It was served by these things called web servers which basically take HTTP requests, find the file that was in the URL-- like the actual file name mapped directly to a file on the web server-- and they would serve it. That was basically almost the entire Internet. Over the last 15 years, the content online has changed from basically being 100% static to almost 100% dynamic. In fact, when I started teaching this course, in Unit 1 I was trying to think of a website that was 100% static, and I can't think of one. Do you have any ideas of one off the top of your head? There has actually been a resurgence of static in the form of websites that get compiled from files, and so there is actually a lot of blogs out there now that are purely static served but are generated from files dynamically. We're going to talk about how much content Reddit precomputes as like a for of this--we talked about in Unit 6 this notion of caching. You can wait to cache something until it's needed or you can cache it ahead of time, so that the user never actually touches the database. What you're getting at is like an extreme form of that. Yeah. You only compile it when you need to, when you change it. So you build up your whole blog, I guess, with static content. Static content--the whole thing is its really easy to serve, because it's the same for everybody. Having static content in S3 or in EngineX, even when Reddit was pretty big when I left, we could get away with one web server there, because Akamai handled most of the load. Akamai is pretty clever about this piece of content is about to expire. I'll go ahead and fetch it in advance to keep the users from all slipping through Akamai and pounding this guy. Beyond the app servers, we had our database. Now, we just talked about how funky a database setup we had, but it was still Postgres, and we'll still use the industry-standard cylinders for representing our databases, and we had a couple of verticals-- I think we stored links on one, votes on another, comments were on one, and then we had like a miscellaneous one. Did we store subreddits and users on the same one or something like that? Subreddits were with comments, users were with links. When we first built the system, it was all on one machine, and we had different tables for each data type. And so a natural way to grow was to split apart the data types, because remember, I talked about how if you don't do joins, scaling is a lot easier-- This is an example of that. You have to think a little bit harder about what your queries are going to be, but you can start splitting things apart. You know how many comments are in the comment's database now? Something in the order of like 250 million. 250 million comments. When I left, I don't remember how many. There was a lot and it wasn't fitting on one machine with links. All these databases were replicated. We used Londiste, I think. Do you guys still use Londiste? Yes we do. Londiste is a third-party tool made by Skype. Basically what this does is-- I think it is a log shipping right? No, so when you write to the master, it hits a trigger, which then inserts the same query into a queue and that's replicated to all the slaves. The same inserts will run all the slaves. Okay. So, it just actually replays the exact commands Yes. Obviously, things like random get precalculated. Okay. So all these machines were replicated using Londiste, and Londiste is really cool, and it might be a Londis-te, I don't know. It's a problem with web technologies is right, you read about the technology, like I don't know. Some people I think called this HAProxy, but it's the first guy in the office who discovers the piece of technology, he gets this is how it pronounced for the rest of the company. We replicate all of this machines both for durability, and also if we lost the machine, we wouldn't lose our data. In Reddit, if we lost your comment history, you'd be mad. And for load, which spread our reads across all these machines. Now, remember we talked about replication lag, and I learned this lesson the hard way and it was really hard for me to figure out the first time because I've never heard of replication lag, and we had to really subtle bugs as a result. The way we got around replication lag was by having memcached. I think at the time-- Did we run memcached on the app servers or that there is separate memcached boxes? I don't know back then until very recently there was no memcached on the servers. Okay. There is memcached on servers now? Yes.There is render cache on the servers actually. Okay. Okay. Now, there is a stable cache. Okay. So, we transitioned, I think, over time. I think when we started of memcached was on each app server, and then we started adding more and more app servers, and the configuration got a little weird because we'd bring up a new app server and do you want to bring up new memcached server also re-distribute the keys, so I think when I left we had a bunch of memcaches that were a separate cluster and these are the memcaches. We use memcaches at Reddit for everything. It is like the Swiss Army knife of systems. I think we used it definitely to avoid replication lag. We'd write to the database and memcached at the same time so that when you do an immediate redirect to a permalink page or something like that the data is good to go, if your read would've otherwise hit the slave. The other big system we had and I think this is kind of the final big system. is we had what was called as the precompute system. Doing real time queries against database was too slow to generate our listing pages. So, we had a whole separate database cluster called the precompute cluster, which if I recall was just mirrored version of all these machines, and whenever you would submit a link to Reddit or vote, we would submit a job to this Q. The job would be something like update the front page or update this person's liked page, or all these different things like a vote can--affects the front page, it affects the new page, it affects your liked listing, all that sort of stuff. We put this job in the Q and then what the Q would do is it would say recompute that listing's front page or recompute that listing's rising page or recompute that users' liked page. Some of them can be done in place without actually hitting the database. If you submit a link, we just put it at the top of your submitted page. You don't have to do anything fancy but it also affects the htoness of that link, etc, etc., and we had a separate set of memcaches that were actually running a technology called memcache DB, and memcache DB is just like memcache but instead of being totally in memory it had a little disk datastore so it was like kind of fast like memcache because its mostly memory but also would persist. Data that got recomputed would be put in memcache DB as kind of this middle-layer cache, so we can avoid running queries on these databases. That was basically the state of the system when I left. Lots of replicated databases--this really complicated precompute cluster. We had this whole separate set of databases that we could just run queries on as hard as we could just one after another. These machines were really sad all the time. Actually, more specifically, they were literally on fire all the time like these machines are hot. Right. Because no query that the user would see would actually hit these machines so we could just beat the hell out of them, and when the result is done, it hit this memcache DB that's where we'd store the data, and the users will only hit this, so we would lose nodes here all the time because we're abusing them. We could add more. They can be slow. It didn't matter. It was out of the actual request loop. That took a lot of load off the whole system. Let's take it from which of these pieces don't exist anymore. All right. After you left but before I started, memcachedb hit a scaling wall, and it just would not go any further, the writes just were too fast for it. Did you guys try adding more memcachedb boxes? I don't know actually. You went there for that. Yeah. Memcachedb is not designed for the heavy load we were throwing at it. It's basically--it was the memcache code bolted on top of Berkeley db, which is kind of neat, but it wasn't really kind of design to work at kind of our scale or use case, which is just basically sending as many queries at it as you could. So you guys got rid of this? Right. And replace it with Cassandra. It's a distributed, NoSQL database. The way it works is you have rows, and a row is sharded by it's key to somewhere in the ring of servers so you get automatic sharding across this entire ring when a row has columns inside of it and that's where the actual data is stored. This moves to Cassandra and was pretty similar. I'll let you draw Cassandra there and I'll explain a little bit more about-- Remember we talked about with database as you can replicate them where you send the same data to multiple machines, which helps for load and durability--this kind of picture here or you can shard them which is you send some chunk of data to one machine and another chunk of data to another. Let's say we are talking about--in this case, we started using this for the precompute stuff first? Yeah. You've got these listings--every subreddit has like a hot page and that will be precomputed so you can store hot pages for some Reddits on this node and some hot pages for Reddits on this node and all around. So, each node is not an exact copy of every other node. Right. Now, is there some overlap? Right. It's configurable, but in our case, we're using a replication factor of 3, which means that if a piece of data lives on this node, it is also on this one and this one and that happens all around the ring. And why do you do that? Simultaneously a read can be serviced from any one of the 3 if we allow it to be, which means that if one node is going slow, we don't go really slow, and also it means that if anyone one node just cease to exist, we wouldn't lose all data for that segment of the data. Let's say you have content on this guy, this guy, and this guy, and you lose this node, does the content get redistributed? No. They're assigned a key space and you have to move tokens if you want to rebalance the ring. Okay. That's something that you as a developer have to do? Yeah, that's an operational thing Or systems? Yeah. One of the things that happens as the team grows too, as people's role has changed. When you're a small website, you are the designer, developer, sysadmin, all in one, and you guys have a whole team of operations guys. Two. Yeah. Okay. You have a team of two--they're very good, from what I've heard. They're extraordinarily good. When I left, it was me and David who now works with me at Hipmunk basically developers and OPs guys, and we're better developers than we were OPs guys, so that explains some of this. You replace memcachedb with Cassandra for the precompute stuff? That solved the right contention issue. At that point, Every listing has a lock --you have to lock around. So you have this listing, which is a set of IDs of all of the links in a subreddit, right? And you have to modify that. You have to lock around that item, and that's at the subreddit level. If a lot of people are hanging out in one subreddit, that thing will have a lot of locking going on. We talked a little bit just in the office hours I think for Unit 4, somebody had asked about in datastore, if two users tried to register the same username at the same time, and datastore doesn't enforce any uniqueness constraints on a field in the database. How do you manage that? And my answer was you can either use transactions in the datastore, which I don't fully understand, because I'm new to a datastore, or you can use memcache, which is one of the 101 uses of memcache, it has this global lock. So you guys are moving away from that? Yes. When you use memcache as a locking service, the problem is if you lose a single memcache node, then you lose the site, because you can't throw away that node without potentially, say half the apps can't see a memcache node, and the others can. So the ones that don't see it decide that they're not gonna talk to that guy anymore, and they try to lock on a different set of servers. When we store data on multiple nodes of Cassandra. It's different from how we store data across different nodes of memcache, which is--correct me if I'm wrong--when you distribute across memcache, you basically hash your key to a particular memcache box, and there's no notion of replication. Yeah, it's similar in Cassandra. This node has a key space, and it just happens to go +1 and -1. And you can do the same. You can do replication like that in memcache, as well. Now, were you guys using-- when I left, we were using a naive memcache library that basically took a key and said, which box is this hashed to, and would store it on that box. If you lost that box, it would effect the hashing of every other key. Losing a memcache box was really painful. So we'd replicate memcaches for mostly space. We had more space--things wouldn't expire out of the cache fast enough or would expire out of the cache too fast. But that had the big balance setup that we lost a single memcache box all of the keys would get rearranged. Right. Module hashing. We are using consistent hashing now. The way that works is it basically builds up this ring similar to this, and instead of mapping keys 1 through 1,000 to this box, it actually sort of assigns them to a place on a circle and finds the nearest server on that circle. When this node fails, it will just go to the next one. We have 10 nodes, we lose 1. Only 1/10th of your keys get redistributed. If you're using consistent hashing, a key might hash to this space on a circle. And if you lose this guy, the key still goes in that space, but all of the keys over here stay in the same spot. When you're using modular hashing-- remember we talked about modular in unit 6-- that's a really naive way to distribute keys. But all of a sudden you go from modular 10, because you have 10 servers, to modular 9. Instead of losing 1/10th of your keys, you lose 9/10th of your keys; that's a big problem. We actually had this happen a couple of times while I was there. You lose one memcache box, or more likely, you misconfigure it, and the app service doesn't see it anymore-- All of the sudden, your cache is not warm anymore, and you've got users who are just like hitting the databases, pummeling the hard cache or the memchache. We call it the hard cache. And all of a sudden, your load profile completely changes, and everything explodes. That was a really nice improvement. You're changing the way you're doing locking, however. Right. For the same reason a single node failing means that we lose the entire site because of the locking. Moving locking into something called Zookeeper, which implements a tree system with guaranteed order of operations on those and with that, you build locking. And the main advantage of Zookeeper is that it has much higher availabilities. If we lose a Zookeeper node, we should be able to come back within 200 milliseconds, as opposed to whenever somebody notices the cache is down and replaces it. Yes. In generally, an engineer cannot respond at 200 milliseconds. Yes. Even the best. Zookeeper is a new system, and this is a separate system? Right. Yeah. It's an Apache project, like Cassandra is. Is there one Zookeeper box, is there a bunch of Zookeeper boxes? So they form an ensemble and the way it works is there's a master and the others are sort of read replicants and if the master fails, it'll automatically elect a new leader among the ensemble. Okay. So do all the request go to one machine? No. You write to any of them so your client could reconnect to any one of them. Okay. And they automatically figure out who to talk to. Cool. Now is Zookeeper just for locking or does it do-- We're also going to be moving dynamic configuration type stuff in the Zookeeper and the Zookeeper provides watches on the nodes so the apps can actually get notification when something changes in the Zookeeper. We can say we're going to change the add on the front page. We just set something in Zookeeper and all the apps update themselves. That reminds me of one thing that was always a challenge, and I don't know the answer to this one already is when we had all these app servers, the app servers had all the configuration. A lot of the configuration was basically part of the code. One example would be how many memcache boxes you have, because the memcache library would exist on the app servers and that's where the hashing would happen, for example. If you're deploying a new configuration, once you have more than a couple app servers often deploys take time--where I think still happen at the same time. Right! And so all of a sudden, you've got half your app servers with a different configuration. That gets weird--let's say you're adding a new memcache and all of a sudden you've got half your machines accessing one set of machines and half of the machines accessing another set of machines, static files hashed-- like everything is weird. Have you guys improved that at all? No. That will be the Zookeeper. Zookeeper will help? Yeah. You can put like what database is there and all that kind of stuff. And the reason you don't want to just do that in like memcache, for example, is that you would need to fetch that from memcache on every request because there's no way to know that it changed. Because memcache is--all the queries are initiated from the apps. Yes. Set this, get this--Zookeeper will actually push that ability. Yes. That's cool. I never look at Zookeeper, so may be it's something I should get smart about. So the other thing you mentioned to me that you're improving is this notion of, like, memcache ejection. Right. So the memcache plant library has the ability to notice that a memcache node has gone down and decide that it's not going to try to talk to it anymore. It's kind of a heuristic. It notices, like, a number of failures happen so it just decides to back off, and it will basically, at that point, just treat the ring as if there's one fewer node. And we can not use that until the locking is gone, but once we've done that, memcache will automatically heal itself. So we can have self-healing memcache, not the one memcache dies, and the whole site gets a little wonky. Right. And we probably could do with more memcache right now, but we don't want to add more because it increases our risk of failure. Yes. That was something I remember, too. We're always-- Sometimes we wouldn't add a memcache because we didn't want to redistribute the keys. Right. Just the simple act of redistributing the keys was kind of a scary thought. Yeah. And right now, even with consistent hashing, if we add one memcache, like in the middle of the night, the database slaves will actually be kind of unhappy for maybe an hour or two. And that's just one server. One thing I used to do, this is kind of a hacky thing. I can feel people losing respect for me as I describe this up. Whenever we'd bring up a new database slave, I would actually go into the database, and I would have an app server that would connect only to that machine, and then I would hit all the most popular pages. I knew they were the most popular. I'd do it by hand. I'd got to reddit hot, funny hot, pics hot. And I would just load all those queries to make sure that the cache, everything, was all up to date and warm and the database was good, because when you bring up a new database slave, it hasn't run any queries yet so nothing's been cached. One of the things that Postgres does really, really nice is it manages the kind of disk memory dichotomy. You know, some of the data's on disk. No, all the data's on disk but only some of it fits in the memory. And you need to kind of basically tell Postgres this is the data I want in memory now. And so we have to run these queries to get these data machines up, because the first few times we bring up a new read slave, we turn it on and all of a sudden, it was performing at, like one-tenth the speed of the master, and you get monster, like, lag issues. It's a bad situation. Yeah, and I mean, heating it up is great because then you don't have to worry about, like, the piling on effect. Yes. Yeah. We talked about in unit 6 that cache stampede. That shows up in a lot of different flavors. You know, if your cache isn't warm, a bunch of people are probably trying to do that query at the same time, and it may take 1 second for one person, but if ten people ask at the same time, it's not going to take 10 seconds. It might never finish because they might all be slowing each other down trying to, like, bring this data in and out of the cache, and things start thrashing. It's nasty. Sounds like the system is getting better there. Now, my understanding is this rat's nest of computers is also gone. Right. So in the process of moving to Cassandra, the system for the precomputed queries became --a lot more of them were mutated in place. What the app will do when say, you remove something from your saved links it has to be taken out of your saved page. Is it will fetch from Cassandra the precomputed list of your saved page, remove the item from it that you didn't want anymore, and then put it back into Cassandra, and it has to lock around that. But the advantage there is it doesn't have to just re-run the entire query because it will only making one little change. So, instead of sending this complex query to a machine that's already doing a lots of complex queries, You just smartly update the--. Right. The ultimate product of this is a cache. Yes. So you just update the cache directly? Right. There are a few types of queries that that's not possible with and those are things like your top links of this hour. So this all goes away? Yes. Yes. I'm just going to make this go away. We do still use "Q." We still have a "Q". But not for this stuff. Okay. The top links of this hour that kind of stuff instead is recomputed enmasse for the entire site using MapReduce, and what that does is it will dump every link that was submitted in the last hour and it like groups them up and figures out where they should go and them just completely overwrites those listings every 10-15 minutes. We haven't talked about MapReduce yet. The first question I have for you is the data that you're mapping over, where is that stored? It's coming out of Postgres. So you have a job that takes that out of Postgres and then runs the big job on it? Right. Now, is this the same set of machines that you would use for-- We have one slave for links dedicated. Okay. So, there's like another little replica that is only read for dumps. Yeah. Now, what about the comments and votes in these other guys? There is no actual queries that need that. Ah. Good point, good point. There is this special links thing and then you run MapReduce jobs on this ever so often and than that get stored in Cassandra. MapReduce--for those of you who aren't familiar, it's basically this programming technique for doing batch jobs across a huge amount of data. There's two functions, if you programming functionally, map and reduce. Map basically says given this list of things, apply this function to it. And then reduce basically says given these two things, apply this function to it and combine it into one thing. So if you're working over a huge chunk of data-- Google made MapReduce famous building their indices for the web. Basically, they take all the webpages on the Internet and you can apply this function to it which is basically find the words in this document. And then you can reduce on that to basically reduce that content down to the kind of target output you want. After I left I think David--David is the mysterious person who is not here. He wrote the MapReduce system by hand. Is that correct? Yes. And you guys are now replacing that with--? We're switching over to Hadoop using a language called Pig or Pig Latin. Hadoop is a MapReduce system, and it has the advantage of handling all the details of distributing these mappers and reducers across a cluster of nodes, and we're actually using Amazon's elastic MapReduce, which has hosted Hadoop to make our lives simpler. So one of the cool things about Amazon--we talked previously in this lecture about AWS--the Amazon Web Services. As Amazon has built-in not just machines but this whole Hadoop clusters that you can commission and pay for. So you guys are moving to that direction and use those at Hipmunk now too for our log analysis. It's really cool, because you can just basically put in queries and say here's my data-- we actually store our data in S3 in these big text files, and we just say run this query using 20 machines over all this data and you can basically say, how long do I want to wait. and Amazon will bring up all the machines, load your data in, run the job, output it, and then shut all the machines down. Yeah. It's pretty great. So you guys are going to be running MapReduce constantly though. Right right. Like every 15 minutes or something? Yeah. That's an interesting question of how to do that with EMR. I mean, you can do it. You just need to say that right. Okay, so you're still kind of figuring out how that's--. Yeah. And that's going to compute the hot pages for every Reddit? It's mostly user pages but there are are few other things. It's stuff like your top links of this hour--that kind of stuff. Okay. Okay. Yes, so that was one thing that was interesting that we learned on Reddit over the years. In the beginning it just had a small amount of content, but as we grew the content kind of turned into two flavors. Not just hot versus saved but was kind of new versus old. If you go to your profile page, that content isn't accessed very often. Before we did the precomputing thing, the hot pages were highly optimized. The queries were fast. Everything worked nicely. It was cached perfectly. But somebody will hit a user page that hadn't been accessed in a month. All of a sudden it's just stale, cold data, it's not in the cache and the whole system just like chugs to bring that out. That's when we started precomputing those and you guys are taking it to the next level. Right. One thing that we actually do there is there's a special-- comment is the really bad one. There's just so many comments, so much data and those databases get overloaded, especially when you pull up an old comment page from two years ago, and nobody's seen it in like 3 months and it has to load 500 comments and that's a disk hit for every one of those. We actually have a dedicated comment slave that is just for the likes of Google. This a whole separate stack for Google, right? Yeah, and it's read-only. Yeah. I would draw a picture, but basically--I think we started adding this just as I was leaving. There's a whole separate set of databases and app servers, maybe one app server-- Two or three. A couple of app servers that's just for Google, because Google will come through and index everything. Reddit gets a lot of traffic these days from Google. You can take any two or more combination of the front page of Reddit. Do a Google search for it and it will be in the top 10. And enough of those, Google is just murdering Reddit. So we had to build a whole separate infrastructure just for Google, because they hit the site in a completely different way from users in a way that it's really hard to cache for. I think we've covered most of the big things. Is there anything that you guys kind of working on now? We have this queue system still and a lot of the actions, like doing a vote, when you actually hit the APIN point, all it does is insert an item into the queue and doesn't do any work on it and that happens in the background. If one of the database is going slow and it's taking too long to write, it doesn't affect the user. And we use that for a lot of stuff now, and we're trying to move more towards that. The queuing architecture is nice. Yes. And you're using AMQP? Yeah. And, we're using RabbitMQ when I left. I remember just as I was leaving, I remember going this is a really nice architecture. They should do more of this, so I'm glad to see that that's working out. Anything else? Lock contention is a big thing for us right now. As I was saying with this Cassandra stuff-- Whenever you vote on a link in a popular subreddit, it has to lock on that subreddit's listing. An example of that biting us recently-- we have these queue processors, and all they do is they get that queue item that says that somebody's cast a vote. So you basically have a set of machines that are reading from this. Right. So all these apps are writing what happened to the queue? Right. Then you've got a bunch of machines that are reading from the queue. And what they do is, they sit there. They pull that out, and then they say, okay, that means I have to update these listings, and I have to record the vote in postscribes and cassandra. And they go through all of this stuff, and that involves a lot of the locking in here right now. And so we had a lot of these queue processors up for votes, and we get a lot of votes simultaneously, so we need a lot of them, but we had too many, it turned out, and they were all fighting each other for those locks. Just having the number of those queue processors actually sped up queue processing in general. You need enough queue processors to actually handle the depth of the queue, but if you have too many, they spend too much time fighting each other. And one of the ways we're working on that is we're getting rid of the locking in the cassandra stuff. And we're trying to get rid of locks as much as possible in general. Locking-- It's a common theme. In python itself when we first switched to Amazon we had this weird issue where Python's multi-threading--running two threads at once, running two pieces of your program at the same time, is not state of the art-- would be a nice way of putting it. Python was spending so much time locking its data structures so two threads could access the same data structure at the same time that it was actually slowing down the computer's ability read traffic over the network, which was causing it to spend more time switching between threads. It created this weird network/CPU thrashing issue. Where the way we solved that at the time was we just made python single threaded, and we'd only handle one request at the same time. I think you guys are probably still doing that. Yeah, we very rarely use threaded processes. The ad servers use threads, but other than that we just have lots of separate processes. You guys use lots of processes on 1 machine, and the OS then can do the task switching for you. The OS is Linux; these days, is pretty good at it. And they spend a lot of their time waiting for something in the back end. Well, this is really great. Thank you so much for coming. One thing I'd like to point out is that everything we've talked about here, the main things-- memcache, Zookeeper, Cassandra, Hadoop, AMQP, NGINX, HAProxy-- This is all free software. It's pretty wild how far you can get without paying for anything. The things that you have to pay for are the computers to run this stuff, but all of the software and all of the code behind all of the software is online and free. Also, the vast majority of reddit's code is also open source and online, so if you wanna look at this stuff-- What's the URL for that? Github.com/reddit. I'm gonna make a hole right in the middle of our picture here. If you go into this code, we switched to git at some point, and my name isn't on a lot of this code anymore, but if you go in there, you will see a lot of the code we've written in this class for hashing and passwords and all of that stuff-- It exists in reddit somewhere. It's really common stuff. It's cool, and you can see all of this stuff's also on the reddit mailing list, where people discuss these architecture changes and that sort of thing. Thanks again. Good job. Watching you guys grow Reddit has been really cool. There were some dark days, and you guys have really done an amazing job growing that site. It's really impressive. Well, it wouldn't be where it is without you. All right guys, thanks very much for watching, and we'll see you in the next one. Now that you've got a pretty good idea of the architecture decisions we made on Reddit and how we kind of grew the site and stored data differently over time, what I'd like to talk about is now we actually grew the site from a social point of view-- how we got users and how we maintained the feel that Reddit has. It's hard for me or anybody to really take credit for growing Reddit, because it's a social thing and even if Alexis and I started over today knowing everything we know now, it'd be very hard to get a site like Reddit off the ground. Social websites require a little bit of magic to work, and we were fortunate enough to have it. We did a lot of very important things that I think helped, one of which was in the beginning Alexis and I submitted all the content. If you go to our Reddit submission page now, it basically boils down to two fields. In the early days it was just two fields. You basically had a field called "URL," which is the URL of the site you were submitting, and "Title," which was the title of that site, and that would be the link you submitted to Reddit. If Alexis and I went to the page we had a third field called "User," and we could type in a name here, and when we hit submit, we would automatically register this user if that name didn't exist and submit the content as that user. You'd go to Reddit in the early days, the first couple of months, and there'd be tons of content. I shouldn't say "fake content," but it was fake users. It was really all just Alexis and I. That did two things, and I think this is important to any site where you want to have a community feel. The first thing it did was it set the tone. Websites have this kind of inertia, and we submitted content that we would be interested in seeing. That meant the content on Reddit, at least for us and for our peer group, it was good, interesting stuff. We wanted a site with the most interesting content online, and s owe did our best to find it and then we submitted that content ourselves. So when you show up to Reddit, you kind of know what the site is all about. The other thing it did was it made the site feel alive. Users like to feel a part of something. If they showed up to the website and the front page was blank, it just looks like a ghost town. You don't want to live in a ghost town. You'd rather live in New York City. Most people would. That's why New York City is so big and ghost towns, by definition, aren't. That was really fortunate, and I don't know what made us do this. In hindsight it's really easy to say this was how it happened, but at the time I think we were just embarrassed to have an empty website, so we submitted the content, and it worked. I remember the first day a few months in when we didn't have to submit any content, and that was such a magical day for us, because then we knew the site was working on its own. It was really, really cool. It took a while to get there. We really kind of had to will this into existence. Another thing about the site is it didn't have any comments to begin with. I don't know that this helped or hindered us. It was just we didn't get around to writing it. I think the only thing I want to say here is that people look at Reddit, and if you get into it you quickly realize that the comments are what makes Reddit work. That's where the really incredible community lives. And Reddit grew quite a bit before we even had a comment system. That came later, and it just kind of goes to show how it's not always obvious what the most important part of a site is, and it's better just to kind of get something online and start experimenting with it than to build the whole system out and have it fail. We didn't have any categorization. What we wanted users to do was submit links. We didn't want them to have to think about categories, think about tags. Those are all decisions, and the more decisions you have the harder it is to interact with the site. We had categorization on the site--I should say--for about one day. I added it one night, and Alexis took all the links that had ever been submitted to Reddit and categorized them, so when users came the next morning everything would be ready to go. One of our first investors and advisers was like why did you add categorization. That ruined everything. Get rid of it, so we did. Alexis ended up--he wasted all of that time, but that was really good advice. Not having categorization meant users could just show up and submit content. The serendipity of the front page was really interesting. Another thing we did was we didn't collect emails. Every site on there had this signup process where you'd have to like enter your email address and then confirm an email-- all those sets you have to do. One of those steps involves you actually leaving your browser to go to your email program or go to Gmail or whatever just to become a member. If you want members and you want submissions, why would you add all the barriers like required email addresses? We figured we're not going to spam people. We don't have any emails to send. Why would we need their email addresses? So we didn't collect them. That allowed users to register that much faster, I think, was a contributing factor to our ability to grow. Another big thing we did was no censorship. We didn't care what content was submitted to Reddit. Unless it was like overtly racist, we just let it be, especially if it was critical to us. That created this kind of sense of community, this sense of trust. That's what ultimately, I think, allowed Reddit to grow to this tremendous size is the users believed in us and wanted to be a part of this community. When we made mistakes, even when I goofed one the password hashing thing, for example, they would stick with us because they realized our heart was in the right place. We just wanted to make a site that was new and interesting . We didn't want to sell our users. We didn't want to ruin the site. We just wanted to have good content. So one other thing we spent almost no time on in the beginning and a lot of time on now is spam prevention. So you think on a site like reddit, where it's like the Wild West, there's no rules, like anybody can submit anything, that it would just be quickly overrun with spam. You'd be surprised. Now that reddit is big, yes. Reddit receives lots of spam. But at the time you kind of--If you understand spammers' motivations, it's really easy to prevent. A spammer's motivation is basically they want links, but an easy way to prevent their links from providing any value is to add an attribute to your anchor tag that looks like this. So if you have a link with this extra attribute, rel=nofollow, it basically tells Google this link shouldn't be followed for search quality purposes. Because the way Google works, right, is it looks at a given page and however many pages elsewhere on the Internet link to that page gives that page some authority. And you can basically say I don't want to give this link any authority. So every link on reddit has rel=nofollow until it has a certain number of points, because we didn't want to put rel=nofollow on all links because we like the way the Internet works. And we figured if a link was good on reddit, that link should have some authority. Understanding that spammers all they really want are links to increase the authority of their page to get more traffic there really helps. So this is one thing we did. Another thing we did was...Spam is rarely cemented by an individual by hand. There's almost always automated tools. Looking at the behaviors of these bots that were submitting contents to reddit. They always had these kind of gaps, behavior gaps, that humans would never do. For example, a bunch of users will all use the same password. Before we were hashing passwords, it was really easy for us to tell. They were all using the same passwords. If there were 100 users all submitting crap but they had the same password, it was all spam, and we could just remove it. And that worked out really nice. Eventually we started, you know, hashing passwords, and we lost that ability. But we had learned some other tricks along the way. One is that the users didn't understand the site. They would always submit a link and then comment on their own link. And users, legitimate users, rarely commented on their own link as the first comment. And so we would just look for links that had 1 comment by the same author and mark it as spammers. Spammers on a community site that behaves differently from other sites online, noticing that these peopel use the site in weird ways was enough to catch most spam. We didn't have to do any fancy, like, look for Viagra or look for suspicious-looking links. A lot of these behavior heuristics worked really, really well. Submissionary. This is another heuristic. Legitimate users didn't submit that often. Or if they did, the time between submissions was stagnated, and spammers would often just submit a bunch of links at the same time. We look for those signs and ban the links. The most important thing that reddit did, and still does, is don't let them know when they're caught. When we'd ban a submission on reddit, that user would still see their submission on our hot page or on their user page. If their vote doesn't count, it would still look like it would count, and if you try to figure out on reddit if you vote counts or not, it's really difficult to tell because on reddit there's a delay between when you click that button and when we update the score. I'm not going to get into the details, but suffice it to say, it's really, really hard. And we've done this, we've spent a lot of time, making it so that users don't know when they're caught. And I've had to do this on ASCII Chan and on my blog as well because a lot of you guys have submitted a bunch of crap to ASCII Chan and my blog that I didn't want to appear. A lot of that stuff is just sitting in memcache and only you see it, but if you were to change computers, you would find that that submission disappears. I think being subtle about when you've detected that somebody is spamming is really, really important. It's not the only solution, but security through obscurity works really, really well if you keep things obscure enough. That's a lot about some kinds of specific things we did on Reddit over the years that I thought you might find interesting, kind of ways to think about problems. You guys have throughout this course I think learn the major pieces of how web applications fit together-- your application servers, your databases, cookies, hashes and how HTTP works and with that knowledge, you can build quite a few things. There are still a few concepts we haven't really talked about. If you're working on your own, that will be good. A lot of it revolves around front-end technologies. CSS, I have kind of alluded to, and I provided CSS in my examples and things like that. This is for controlling how your HTML looks. So it doesn't look kind of ugly and black and white. It can be complicated, and it's a little bit of an exact science, laying out a webpage, but this is a technology worthunderstanding--as well as JavaScript. JavaScript is a programming language that runs in the browser. The web browser shifts this code to the browser and then the browser actually runs it, and this can manipulate your HTML, it can manipulate your JavaScript, and it can actually make more requests to your server for small pieces of data and insert those into the page. Doing that is called AJAX stands for asynchronous JavaScript, basically making HTTP calls in the background to your web server to update the page dynamically, and many, many websites use AJAX now. A good example on Reddit is the voting--click that vote, it doesn't reload the whole page or submit a form, it just sends that vote to the server and then the server records it. These are some technologies that would good for you guys to learn, and you can start making your web pages more dynamic, look better, and more interactive. So, there's one last thing we are going to do in this unit, which is talk to Udacity about how they use Google App Engine in production, so you can get a sense for troubles they've encountered and some of the solutions they found running a large production site on Google App Engine. Okay so, welcome to this interview. We are talking with Chris Chew, who is one of the Udacity engineers, and he's been working on App Engine. And we're going to talk a little bit today about how Udacity uses App Engine in production, and some of the things that are different from writing toy apps. You know, we've been writing these simple things, and Udacity actually has thousands of users, and so it's a much different problem that they are solving. So we spoke before about how when you, when you came to Udacity, you were skeptical about App Engine and, and you expected to try to have to convert people. And how, how has your experience been so far? And yeah, actually, and it's, it's been interesting. I think a lot of people, especially the more engineering experience you have, the more skeptical you tend to be about something that makes claims as big as App Engine's claims. And, you know, everything always has trade-offs, and App Engine has trade-offs. But, you know, I really did come to Udacity thinking that I would be able to talk everybody out of moving to something different, where we'd have a little bit more control. And I think the opposite has actually happened. I'm, I've been a little converted the other way, and I think, you know, App Engine's really the perfect spot for Udacity, and Udacity really does run on App Engine. We really do have a lot of traffic, and there's even some larger websites that have way more traffic than we do that run successfully on App Engine. Okay, actually so I had, I had the same thought. You know, we decided to use App Engine because, you know, I thought it would be easy to get up, get up and online for students, so they wouldn't have to do sys admin things. But, you know, I have always done my own thing as well, and not used App Engine, so I was highly skeptical, and I've had a similar, similar change of heart. So what are some of the things that App Engine does that, that make it so nice to work in, that you would otherwise have to do on your own? The big one it always boils to, they provide a lot of infrastructure caching highly replicated data stores. They force you to address what consistency means in your application, you know, and does, you know, the same, does a name have to be updated everywhere immediately or can, can things be a little bit slower to update. You know, things like that that building a simple app you just, you know, you don't have to think and then all of sudden you get really big and then you have to scramble to try and redefine, you know, how those sorts of things are going to work in your system. The queuing, is actually really powerful. It was really smooth, it seems very reliable and you know, allows you to build, you know, tasks, and really focus on the tasks, as opposed to the infrastructure to get the tasks delivered. The login infrastructure by and large works actually really well. It may, it works really well considering the scale of logging statements you can put through it. You, you mentioned the queuing which is funny, cause we actually just spent a lot of time in the previous interview with Neil from Reddit, talking about all of the infrastructure Reddit has built around the, the queues and the pre-computing cache and that sort of stuff. It was actually really tough for us to build. and, and there's a lot of things that I think were really tough for us to build. I wonder if you can mention talk a little bit about how the, the version handling works in App Engine and how that kind of fits in the bigger picture? Versions are actually really interesting in App Engine. They, they're different than what I expected and it, so they actually allow you to upload a totally different code base really, but going against the same data store and the same services. And you can use that I guess in a couple of different ways effectively. One thing is that it enables what we call AB testing. So, kind of like two versions of a site are running at the same time. And there's actually an AB testing, some administration there that allows you to kind of blend, you know, percentage of users in, in a somewhat sticky manner. So that, you know, you can roll out new features to some users and test them, and, and as they're more successful, migrate all the users to the new features. Things like that. The other thing is that they kind of provide you a way to have, I think of it as like aspects into a system. You can actually, you know, you could have a version of an app that is for mainly administrative tasks, or for purely testing, or for monitoring. Or and then what you know, your, your normal users would see in, in the site and they're all running simultaneously and you know, against the same you know, data storing services but it allows you to kind of, you know, partition your logic and so you could still reuse models and things between them And it's it's, it's really, it was a surprising feature that, in there, and it seems to be really handy. Cool. So we just spent our last unit, unit 6, talking about scaling and basically 101 uses of memcache. Now, a lot of the things that we talked about in scaling, you know, adding new app servers and adding more memcaches and scaling the DB horizontally and through sharding App Engine does for you. And have you guys been taking advantages of those features? Has that worked out for you in production? Absolutely. The auto-scaling is probably the best feature of it. It works really smoothly. It's very transparent. And, our traffic definitely has peaks and valleys. You know, there's been a lot of press, and that brings a lot of traffic, and with course launches there's a lot of traffic. There's a lot of traffic as, you know, homework deadlines come up, things like that. And we can handle that without thinking about it. Some of the--I wasn't there, but I've heard some stories from the early classes and the early AI prototype from the fall, and Mike pretty much was spinning up servers nonstop. You know, he didn't sleep for a couple of weeks. He was doing nothing but spinning up new virtuals. And we don't have to do that. We don't have to think about it. And we just, you know, check each day to see how many instances we have running. There was a time where we accidentally DDoS'd ourselves with a bug that was sending way too many requests back to the server, some Ajax requests, and when we spun up to a couple hundred instances, you know, everything was fine. Our users were still able to continue, and every site that's learning how to scale has made that mistake. But most of those other sites took themselves down for the day while they figured out what was going on, and we were able to figure out what was going on without going down. So, I think that was just an instance of, you know, kind of proof where it really does work well. Cool. It's funny to me that you mention on App Engine, you know, checking how many app servers you have in the morning because on reddit and Hipmunk that's a number we are really familiar with. You know, adding a new app server is something we do deliberately and especially, I know it is with reddit, something with a lot of deliberation beforehand. You know, how is this going to fit in the architecture? How is this going to change things, you know, with regards to caching and what not? And on App Engine, you know, you're working in a different-- You have to kind of develop things in a different style as a result of this nature, And I wonder if you can comment on kind of how App Engine was designed and how it kind of fits the way you've done things in the past? It's really become clear to me in my time that I've been working with it that it was designed by people that had been through that several times with different kinds of apps because the solutions and the things that they provide you kind of has those characteristics of if you were building something over again just the way you'd do it. Like if, for example, the queing can get really complex, and their queing system, you know, well, you create a task; you give it some properties. The properties that they give you that you can kind of tune are exactly the ones that you'd want to tune. And then the trigger is just a simple, like, a web hook callback. And so your worker logic is just like any other request handler, and it's just very simple, you know, kind of like the least common denominator sort of mentality. So trying to just simplify things is definitely something that really comes to mind. Cool. It's not all perfect and easier and improved. Maybe we could talk about some of kind of the downsides, the things that are a little more difficult in App Engine as a result of how it's set up and how it's designed. The happy path is paved with concrete, and it has chains along the side, and so you really can't leave the happy path. So that's something you have to keep in mind. And there are failures from time to time. A query can work just fine, and then all of a sudden the next time you make exactly the same call, it doesn't work. And those are just things that you get in a big, eventually consistent kind of amorphous sort of machine. And so you have to deal with those, and so you start to a lot of times kind of want to do a looping sort of query where you're willing to do the query 3 times. And within the 3 times, you'll probably get the result, and the first one might fail. You just re-perform the same query before you let your request handler send an error response back to the user, which is actually kind of a good pattern because distributed computing, you're going to encounter failures. And you need to program defensively for those, like, system sort of failures, so being ready to do an issue and a retry and putting that into your normal call stack or your framework, I guess. It's easy to do, but it is something that when you really want your app to start running smoothly. And those are the sorts of things Udacity is dealing with or learning about now-- to do the retries on things like queries. You have to be cognizant of how long a long-running task on a back end is going to take. You get a limit of--I think it's 10 minutes, which seems like a long time, but on a highly virtualized system, you can actually have a 10-minute long-running task. So you have to be prepared to shut it off early and then be ready to pick it back up with a subsequent request. One of the other things, I guess, would be a lot of people, when you get a bigger Python system, you want to have C modules pre-compiled, and you don't get that. So you kind of forget about those sorts of things. And then the biggest one, which I know that Google is addressing-- and they have a beta program, and I'm very hopeful that it happens soon-- is better SSL certificate support, especially for the custom domain. You get SSL on domain.appspot.com, but if you point a custom domain to it, you don't get SSL support for that, which is a big drawback, and it's something they obviously recognize and they are fixing. So hopefully in time--please, Google--that will be there. So one thing that I was skeptical about coming in is the database and how much access you have to your own data. Are there any limitations there that need to be thought about? Definitely. It's something that's probably worthy of a whole unit in a course about going deeper with App Engine. There are a few things that you kind of have to come to terms with, and they're trade-offs. Every life is trade-offs, especially with scaling a website. And for a lot. You have to put up with things like all queries have a limit of 1000 records. And that's before paging, which kind of sucks. So you could potentially pull out a result set that was 1000, none of--with just empty records. And then you have to page to the next one to get the 3 that match depending on how it is that the indexing and your collections or your model is structured. The backup and restore thing is real awkward. There's some backup and restore utilities built in but not if you wanted to just take the data on a nightly basis and sync it to a testing kind of QA, sort of, like a Prod-QA sort of version of your app. There are some tools out there that basically allow you to export the data as Python code, and then you could run it and import it into another app. But in the back of your head-- On the one hand, it's nice to have some transparent costs. We can tell you pretty much exactly how much every one of our queries costs, which is great. The downside is that when you're doing something like a backup, in the back of your mind you're going, "Man, this is costing a lot of money." And so it's things you can get around but not as smoothly as just taking a hot backup of your local files on a MySQL database or something like that. The other one is that there's no real great data viewer. There are times when you're troubleshooting you really don't know what's going on. You want to just issue some SQL queries or some Mongo queries directly against the data to see what the data looks like. There is a data viewer on the dashboard, but it's not that great, and it only works with certain kinds of data types, and you can't really update anything. So if you really just need to flip some field--the status of something-- and that way you can keep processing and then you can work on fixing your bug and getting it out later that day or tomorrow or whatever, you can't do that, which is frustrating. But on the other hand, it might force you to build some more administrative kind of features that if you can fix things easily with some duct tape, you end up kind of not really building a good administrative interface. So sometimes the only way you can do it is by building an administrative interface. Okay, yeah. So some of those limitations seem to not be without reason, but they are limitations. Yeah. It was funny when we were talking before this. Some of the Udacity guys had mentioned that if they were building a website that needed to scale to many, many users, App Engine would be a great choice. And then I kind of mentioned if I was building a toy website, App Engine would be my first go-to so I don't have to deal with any of that crud of installing databases and memcached and app service and frameworks and all that stuff. Setting up a deploy process, all that. Oh yeah. Deployment--man, that's something we haven't touched on in this or in any of my units is when you start having multiple machines, deploying code across multiple machines is something that you have to think about. And there's different strategies, and the versioning stuff is cool in App Engine. So I want to thank you for doing this with us. This is really cool. I've learned a lot from talking to you guys about how App Engine works, and I hope the students have got some better perspective on whether App Engine is the right choice for them. Absolutely. Thank you for having me, and thank you for your class. We've had really great feedback, and it's been fun having this sort of class. Cool. Glad to hear it. And so that wraps it up for Unit 7, which wraps it up for the whole course. So thank you, everybody, for participating this far. If you made it this far, you are a champion of web applications. And the only thing left for you is the final, which we'll get to next. Alright everybody, this is going to be Office Hours for Unit 1. Thank you all for participating so far in taking the class. I hope its been informative for you so far, were going to  that was the easy stuff. So after this you know were going to get into some of the tricky things. So Johns found some questions from the forums that were going to go through that you guys have all had. So, lets go. Okay, well the first question is about Google App Engine and people had a lot of questions about Google App Engine. How it works? How to get it running? Problems they had. Whether we were going to need to use it? So just if we could go over all of that stuff real quick. Okay, so to answer your question first or to take it from the top basically. We chose Google App Engine because we thought it would be the Engine because we thought it would be the website online. Believe it or not, even after reading the forums I still believe its the easiest way to get something online. That said, if you dont want to use it, you dont have to. All of the homeworks are going to be structured with the same basic format which is submit a URL that does X. So if you can get a URL online that does X, great. So if you want to run this off your local machine, use Apache, whatever, youre allowed to do that. But I am going to be teaching all the lessons using Google App Engine, that will be what Ill  thats what Ill be demoing in the class, thats what Ill be working from and thats generally what Ill be talking about. So the way Google App Engine works, the idea is youre just writing these Python files, and youve got two options of running and distributing your code. You can either use the launcher program, which its got a little play button that will allow you to start up your app once you add it to the launcher. And that requires, Google App Engine itself doesnt ship with Python. You need to have Python installed on your machine and that seems to be where a lot of the trouble is. Google App Engine  theres two versions of it. One will work with Python 2.7 and one will work with Python 2.5. Nothing in this course requires 2.5 or 2.7 specifically. So just get one of them working and go from there. Now once youve got your app running locally, then you can either use the launcher to upload the app or you can use the console utility. Personally I use the console utility, you just say, I think app config update and you point it at the directory where your files are and then it churns for a little while and then you can go to your accountname.appspot.com and see your app. So if you have any specific troubles, post them in the forum. Other students have been really helpful with specific sysadmining answers and that sort of thing. So keep asking, keep working at it. This first homework is basically just get this thing online and I know that can be a pain on some of your machines. So lets just get this thing online so we can move onward with the course. And if you want to use something else, knock yourself out, were not going to be able to help you but youre free to learn and try it on your own. Okay. The next question is from Brian Y and he wants to know, what are some useful things to .know about frontend web app development? Okay, cool. So, good question, because were not going to be spending a whole lot of time on frontend web app development in this class. The main pieces of technology you want to know would be JavaScript and CSS. JavaScript is a separate programming language that runs in the browser and you serve JavaScript just like you would serve HTML and you can manipulate your HTML, you can manipulate CSS and that sort of stuff. Google for a JavaScript tutorial and you will have plenty of resources to learn from. And CSS, thats basically another type of file you would serve from your web server and that controls the styling, the colors, the font sizes, the layout of your HTML. Ill use CSS in this class and Ill provide you when we start getting into some of the more complex websites youre going to be building like when we start doing the blog stuff, Ill point to where my CSS is so you can download that and use it if you want. But for the most part, you know, the way were doing the grading on all of these homeworks is were going to have our own piece of software thats basically manipulating your website and its really hard for us to see if your website even looks right, so the appearance of things is not something we can really grade anyway, but if you have some professional pride and want to make things look nice, JavaScript and CSS are the technologies you want to learn and you can use those on your own if you want to learn in this class, its not going to affect how we grade homeworks or anything like that. So, good question. Okay. Brian Y has a number of additional questions. Okay. And one of them is, is Google App Engine a good solution for large scale projects and are there any unforeseen difficulties? What costs involved with that? Sure, well there are costs, there are literal costs. Google App Engine is free at a small scale, so it will work for all of our homeworks but if you want to run it at a larger scale youve got to pay for the bandwidth you use and how much data you store and that sort of things. I personally havent used App Engine in production, but udacity.com itself runs on Udacity. So many people do use it in production. Its a great way to get started and the things Ill be focusing on this class you can take with you outside of App Engine. I am basically going to be talking about high level concepts. Theres a lot of things that App Engine provides that well actually be building ourselves. So when we start doing user registration and cookies and that sort of stuff, were just going to take that from the top anyway because I want you to understand the technologies and it won't be specific to App Engine or what other framework youd like to use. So the short answer is, yes you can use it for large scale projects. I personally dont have a lot of experience doing that, so if youve got more specific questions, hit up the forums. Great. Another question that Brian Y had was what kind of challenges you ran into when . developing Reddit and Hipmunk?. Okay, so thats actually basically what this whole course is about. So I am not going to answer that specifically here. I could perhaps do a seven- lecture series about things I learned doing Reddit and Hipmunk. But specifically Unit 7 is going to be about those types of problems. Unit 7 is how to build websites in the real world and some of the other things youll have to think about. How to deal with like large numbers of users, customer service and all those kind of little things that we had to think about getting Reddit off the ground or getting Hipmunk off the ground. Well Ill spend a whole lot of time talking about that unit, in Unit 7, so if you hang with me until then, youll get your answer. Okay. The next question is from I-n-sa and she wants to know how were going to be graded. In 101 quizzes werent graded, homework was and the final counted for half, I believe, and she was wondering what exactly is going to be the structure of this? Okay, sure. So in this class there isnt going to be a final. There are going to be homeworks at the end of each unit that basically involve you getting your website online that does things. So the homeworks are the most important thing. If you can pass those homeworks you know how to build basic websites and thats the goal of this class. Thats what I want you to leave this class being able to do. So the in-lecture quizzes, those dont count towards your grade. Those are basically to keep you engaged, to keep you paying attention and to sometimes introduce some new concepts, but those arent required; the homeworks are. So its important that you figure those out and get those online. Now you dont actually have to have those homeworks working each week. Its my understanding that we can test those any time. So at the homework due date after which well post the solutions, but the solutions arent going to be  when building websites a lot of the challenge isnt knowing what code to write, its how to get this thing online, how to get the pieces to fit together. So youre still going to have to figure that out and get these things online and thats where your grade is going to come from. Thats it for Office Hours. I want to thank everybody whos been hanging out in the forums answering questions, its been really, really helpful. I know this stuff can be frustrating getting things working. Sean here will be in the forums to help. Hes kind of my guy on the ground making sure everything is going smoothly. So if youre stuck hang out in the forums. Ill be in IRC as well if you want to chat with me during the day and good luck with the rest of the course. Real quick, what is the IRC channel because some of our students might not know that? Yes, okay. Its on freenode, and I believe it is ##udacity-cs253 and there should be some information about how to get in there on the forums. Okay, great. Alright, guys. Good luck. Hi! Welcome to Office Hours for Unit 2. Unfortunately, Steve couldn't be here this week. He is at a wedding rehearsal right now. So I'm going to handle your questions for him. I already talked to him about them, and let's just dive right in. We had a lot of great questions, and there was a lot of overlap with them. So the first one that I'm going to talk about is about html templates: what they are, how to use them, when you should use them, and all of that. The html templates we're using are called "Jinja". That's a templating engine. It's included in AppEngine, which is nice because you don't have to install anything extra. Django templating engine is also included if you'd like to try that out-- at least according to the docs it's included in the templating engine. We haven't used that, and we're not going to be going over that. We weren't planning on going over templates a whole lot, but it sounds like there is quite a bit of demand for that, so we'll try to put something together. I'm going to link to the Jinja docs in the supplementary material under the videos. So by the time you see this, they should be there. Templates are a way to organize your html in a way that's easier than string substitution. String substitution can get a little hairy once you get very large html files, and this helps you manage them--put them into separate files and folders-- and Jinja is basically glorified string substitution except that it helps you handle separating those out into multiple files and folders so that you don't have to worry about it as much. But we're going to be going into that in more depth later on. So to everyone who asked that, thank you. Apparently, there is a lot of interest. In addition to the questions on templates, we also got a lot of questions about separating your data and your Python information and your app handlers into multiple files. Right now, we're basically doing everything in main.py, which is okay because our web applications are small enough that it doesn't really matter. But if you're going to be writing something for production for everyone potentially to be using, then that doesn't really work anymore. Once you start getting into thousands or tens of thousands or even more lines of code, it's just unfeasible. So there are a lot of ways you can do that depending on what language you're using and what template engines you're using. The template editors we're going to be talking about in another video. With Python it's actually pretty simple. Any Python files in the same folder you just say, "import [the name of the file]" except for the file extension, .py, and that's really about it. It's very simple to use. I will be linking to the docs on that, too, but that's essentially all you have to do for it. And I would recommend if you're doing production web application design or any kind of serious web application design, that you want to start separating that into logical chunks so that it is easier for you to maintain, and other people to maintain, too, if you're working with other people. We also had questions about other ways to host your web app. Right now we're using Google AppEngine, but there are plenty of other alternatives, and some of them are Amazon AWS, Linode, Rackspace-- if you Google web application hosting services, you should probably find many, many options. Amazon AWS is what Steve uses for Hipmunk. I believe it's what he used for Reddit as well, and he really likes AWS, and he would recommend it. There are plenty of other options, though, and plenty of other options where you can use Python. Migrating it from one service to another can be a little bit complicated. And depending on the size of your web application, it can be worth it, or it can be something that you really don't want to do just because it would take your application offline, or it'd just be too much complication to deal with at the time. We're going to be talking about that a lot more in Unit 7. Unit 7 is basically going to be about the problems that Steve has run into himself in building web applications and the solutions he came up with, the solutions he wished he came up with, and things like that. There were a lot of questions related to that: how to migrate from one service to another, how to come up with an idea and pitch it to people, how to make sure that lots of people see your site and can find your site. So we'll be going over all those kinds of questions in Unit 7. So stick around! We had a question from Bonnie Monson on classes and what they are, and classes are part of something called object-oriented programming. It's a really big topic. You could easily spend an entire course or 2 or 3 on just object-oriented programming. Steve just recommended you look at the docs. We'll link to the docs. A lot of people weren't satisfied with that. There's really not any way for us to deal with object-oriented programming in any kind of complete way in this course. Basically, a class is a way to organize variables, functions, and other pieces of data in Python or another object-oriented programming language such that you can pass them around and that you have different spaces of names so that you don't have multiple variables with the same name conflicting with each other. There is a lot more to it, but we don't think that we're going to have to deal with that that much, and you shouldn't have to know too much about it. Again, we're going to link to the docs. If you really want to know about it, I would recommend reading them. They're not too bad. They might be beyond some of you depending on what your background is, but we're hopefully going to be offering some more material on that in future courses, so if you'd like to know more about that, I'd recommend sticking around for that. Dom L. asked what are the advantages and disadvantages of a web application over a native application? And that is a big question. There are a lot of things you could say about that. There are a lot of potential advantages and disadvantages. If you ask multiple people, you might not come up with the same answers. Some of the potential advantages of a web application are that you don't have to ship new versions when you come out with a new version. You can update it on the fly on your web server automatically to all of your users, which is potentially a pretty huge success. There's also portability. You don't have to have versions for Windows, for Macintosh, for Linux or whatever you're supporting. A lot of people had issues, and there were different issues for when we were installing Google App Engine depending on what operating system they had. With a web application, you don't have to worry about that. At least, you don't have to worry about it too much. Certain browsers have quirks and handle things a little differently, but for the basics, it's fairly browser agnostic, which can be a big win if you don't want to have to deal with multiple versions of the same software or you simply don't have the resources to build multiple versions of the same software. You also have potentially thousands of computers in a data center somewhere that your web application is running on instead of a single computer that your user is running locally, so it's much easier to diagnose problems. It's much easier to fix them on the fly. It's much more--it's much quicker to improve your product in that way and make sure that your user can receive an improved experience. Some of the disadvantages might be some of the problems associated with an online application like performance. If you're running a highly processor-intense 3D game off of a web application, that might not work so well because you need to be able to respond very quickly, in potentially milliseconds. The other problem is that you have to deal with internet availability. Depending on the area, that might not be a problem, but some areas don't have regular internet access, and you would be losing out on users if you don't take that into consideration. Welcome to Office Hours. The first thing I'm going to talk about is homework 3. There was a lot of confusion on how to do the permalink part, which is mostly my fault. I will explain what I intended for you to do using this handy-dandy whiteboard. Okay, the first thing you need to do when you store an object, you're going to make a post, and it's going to look something like this. You're going to be making this post object, and it has a title and some contents. I think that was it, but that's not the important part. Most of you figured this out. When you put the post in the database in Google App Engine, you use the put() command to do so. That actually stores the post in the database. Once you've stored it in the database, that's when Google App Engine assigns that post an ID. You can also include an ID in this constructor here when you build it, but generally it's best just to let the database do it itself, because otherwise you have to keep track of which IDs you've used, which ones you haven't used--that sort of thing. We'll let Google set the ID. We'll put it in the database, and then what we need to do is redirect the user to the permalink page for that post, and by permalink, I just mean link to that post. We need to get this post ID. The way we do that is just say p.key(). Key() is Google App Engine's full representation of this object, and this is whole long string. You can turn this into an integer by calling ID on it. This is the integer representation of that post, and we'll convert it into a str--pardon my indentation here. We'll assign this to a variable. What we'll do then is we'll redirect the user to a URL with this variable in it. It'll look something like this. Then we're going to use our string substitutions to include a little string here. This should redirect the user to /blog/ the ID of this post. That's the first part of the problem. The key thing here that you need to know is how to get the idea of a post you just submitted. Now, let me erase this and then the second part of this problem is how do you actually look up that blog post. Now, you've got your URL mappers. All the URL mappers that we've done in the class are basically static URLs. They have the format of something like--remember these are tuples at the bottom of that file. It might look like '/blog/' and this maps to a handler that just draws a blog. In my code, I think it's just called main page, which is the Google default for that first one. Now, we want to do is we want to make a special one for linking to permalinks. These strings here that represent the URL are not just strings. They're actually regular expressions. We had some regular expressions in Unit 2 when we were validating usernames and passwords and that sort of thing. Well, what we want to have here is a regular expression to capture a URL with an integer after it. That looks something like this. This is all just normal string. In a regular expression you can just have anything that's just kind of regular text just matches that text exactly. Now, after here we use parentheses to basically say whatever goes in here will be passed as a parameter to our handler function. We can do something like this: [0-9]+. What this means is the square brackets say match any character between these square brackets. You can use ranges like this. This basically says find any number 0 through 9, and the plus means find one or more of them. This will basically match any URL that starts with /blog/ and then any number, and we'll map that to some handler for our permalink page, which I think in my code I may have called "post handler," but you can call that whatever you want. That's step 2. It's basically do this URL handler. May I have the eraser, please? Then we'll talk about step 3, which is fairly straightforward. There we go. You have your handler, so we'll have something that looks like this, and this inherits from that webapp2 handler or the global handler, whichever you're using. Then here you have a function that looks something like this: definite get-- this handles get requests. Normally, this just takes one parameter called "self." In this case, we had parentheses in the URL mapper, which means it's going to match whatever is in those parentheses and pass it as a parameter to here. In this case it's going to be our post ID. One quick thing to note. I never call variables ID in Python because ID is actually a function. It's a reserved function, and it's really easy to create really subtle bugs if you start using the word ID. All my variables that refer to IDs always are something_id. Now what we want to is get our post out of the database. In App Engine this just looks something like this: p = Post-- this is our class that we defined that's the actual data model. You can say getbyid(post_id). That'll do a database query to look up the post with ID out of the database. Then all you need to do is if p, and then you can render it however you planned on doing that. If p doesn't exist you can just return a 404. That's how you do the permalink portion of the homework. I hope you guys manage to get all this working. I'm sorry. I probably should have covered getbyid in the lecture, but that's the fun of teaching for the first time. Good luck everybody and thanks for sticking with us so far. With this office hours we had a lot of questions about MySQL and PostgreSQL and why you prefer Postgres to MySQL, why other people MySQL a lot of the time. If you could answer some of those, it'd be great. Yes, yes. We'll start with the first question, which is why I prefer Postgres over MySQL. This is a two-part answer. Back in 2005 when we started Reddit, I was basically where you are now, which is just learning how web apps work. I was trying to install all this stuff on my computer, and I was trying to install MySQL and Postgres, and MySQL wouldn't compile on my Mac and Postgres would. That's a good reason. I mean, actually to be fair, it says a lot about a project. Like if it builds on my Mac it'll probably build just about anywhere, because at the time OSX was still fairly new. That's how we started with Postgres. MySQL at the time was still very popular--far more popular than Postgres, but it had a reputation for being a little lossy with data. This may be the right word--a little inconsistent. Postgres--the documentation was better, they would sacrifice functionality over stability and consistency and adherence to kind of the SQL standard. Some queries that we did on Reddit that kind of pushed the limits of these databases ran much, much faster in Postgres than in MySQL, so I've just been loyal ever since. These days feature-for-feature they're basically the same. MySQL is not nearly so cavalier with your data and a lot of people use MySQL. At this point, whichever you prefer. Maybe go back to whichever compiles easier on your computer is a perfectly acceptable reason these days, I think. We also had some questions about other types of databases, why NoSQL databases were popular, why a lot of companies are moving to that. You mentioned that Facebook uses MySQL, I believe, and we had some questions about them using NoSQL as well. Okay, sure. NoSQL is basically a reaction to the difficulties of developing with SQL databases. One of the challenges of SQL databases is you have define your tables ahead of time. You have to know your coms are going to be. You have to know what the type are. When you're writing web software, one of the advantages of writing web software is you don't have to think everything through in advance. You can get something working. You can put it online. You can see how users react to it. You can kind of iterate from there--add new features, take features away--whatever you want to do. The challenge is when you have databases and a large amount of data, you have to sometimes add a new column or add a new index or add a bunch of new datatypes. When you have a database in production that has thousands or millions of users, this can be really painful. These NoSQL databases--generally, they try to solve that problem. Another way to describe them would be schema-less databases. The databases don't have a schema. That is they don't have a formal description of columns and datatypes, and it's neat. On Reddit, we kind of built our own kind of schema-less system on top of Postgres. We actually do the same thing again at Hipmunk. It's a nice way of working. The challenge right now with a lot of these schema-less databases is they're not very good. They're brand new technology. Databases are really hard. They have stability problems. Documentation is lacking. Not very many of them are used in the wild in production, so you don't have good support and people to lean on and that sort of thing. In my opinion it's still wise, especially when it comes to data, especially if you care about your data, to stick with something that's proven, that works, that you know how to scale. Everybody has worked with Postgres and MySQL for a long time now, so those things work very, very well. Now, as for Facebook--I don't work at Facebook, so I'm not an authority on the subject-- but I know they use a lot of MySQL. They've actually made a lot of improvements to MySQL. They also wrote their own NoSQL system, called Cassandra, which my understanding--although I don't know for sure--is they don't actually use anymore. Reddit uses Cassandra, incidentally. They started using that after I left, however. I can't say with a clear conscious that I condone that decision, but apparently it's working for them in production. Your mileage may vary. Personally, I'm happy with Postgres. I know how to scale it these days, and you can get away with kind of schema-less behaviors in Postgres by just storing one column that's like a big wad of JSON, for example. That actually works really well, depending on what problems you're solving. Anyway, that's a long answer to a simple question, but that's my opinion. Great. Another question we had about relational databases were about joins. Specifically, how you do a lot of more complicated queries without joins, because that seems pretty fundamental to a lot of database administrators. Yes. Joins are fundamental to databases and particularly SQL databases, and I said don't use joins. Now, a lot of this is opinion, but it's based on experience. The reason I say don't use joins is because joins don't scale very well. If you're writing a typical web problem where you think you're going to have lots of data, and that data is going to eventually need to be spread across multiple machines, running queries that involve multiple tables joining these two large pieces of data together, or potentially more than two, across multiple machines is very, very difficult. There's a lot of research going on to make that possible, but with the consumer tools, it's not going to work very well for you. You're going to have to figure out something on your own. Now, if you structure your data in such a way that everything is independent, you don't have to worry about that. Things scale a lot nicer. You have to take this into account when you start, though. You need to think of your databases as basically these large key value stores, and you're not going to be able to do complex queries. You're going to look up things by ID or maybe look up things by single coms, but you're not going to be joining things together. Now, one of the things you have to do there then is store some redundant data. If you have your data nice and normalized-- that is, all of the table for a particular type is in a table for that type-- and you join everything together at query time, that's a nice-looking database, but as soon as you break things apart you might need to store-- effectively kind of cache other pieces of data in other tables. On Reddit, we store a users karma, I think, on a link they submit it, so we have that piece of data handy, so we don't have to fetch the user and the lnk and all that sort of stuff. It means there's some more maintenance overhead. When you do an insert--when you update a particular field--you may have to update it in a couple places, but that to me is easier--a little bit more easy to manage than trying to figure out how do you run joins across large datasets across multiple machines. Now, if you have a small dataset and if it's on one machine, great. Use joins. Do what works for you. On Hipmunk, for example we have a database of hotels. It's 300,000 entries long. It's not getting any bigger, because that's about how many hotels there are in the world. We use joins in that database. It makes the problem easier. But on Reddit, we have databases of links and comments and votes. Those tables can have more than 1 billion rows. We're not doing joins on those tables. Those are spread across many machines just to make the queries work. Again, use what makes sense. If you're going to be storing lots of data, try to think about how you store data in individual tables. Okay. Some of you have been asking about syntax I've used in Python basically with these asterisks in function definitions and in function calls. I'll just show you some Python syntax that I've been using that is pretty helpful. One of the things we can do when we have a function definition--we'll call this function foo-- it can take a variable number of arguments. This is a handy thing you can do in Python. The way you do this is you say " * ", and then you give it a variable name. Generally you say " * a". This basically says take all of the arguments passed into this function, all the unnamed arguments--we'll come back to the named arguments in a second-- and store them in a tuple, and we'll call it "a." That means in this function foo we have a variable a, and if I were to return a and call foo, it would look something like this. If I called foo with no arguments, it would return just an empty tuple. If I were to call foo with the arguments (1, 2, 3), it would return a tuple of (1, 2, 3). If I were to change this to return a [0], and I were to call foo with (1, 2, 3) again, It would just return the number 1. This is a handy way of making a function that can take any number of arguments. Now, I used this in class in unit 3 when we were pulling a link out of the database-- When we were pulling a link out of that SQL lite database in the IDE. What you get when you pull something out of the database is just a tuple of all the columns. I can pass that tuple into the link constructor to make a link object. That's what I was doing there. Now, something you've seen in my code looks something like this. I often have a function--I think in my code I have something that's like this--def render. Oops. No paren there. It may take *a and **kw--oops, two stars. In sketchpad, they edit all these mistakes out. Generally when you see this kind of construct in Python--*a, **kw-- that means they're writing a function that adds a little bit of behavior to another function. So I have another function. I think it's some sort of Jinja rendering thing. Oh, I actually I think what we say is template. We have a template name. It's probably another argument in the function. We may say like t.render( *a, **kw ). Basically all this is doing is just taking the arguments from this function, the unnamed arguments and the named arguments-- an named argument would be like x = 1 versus an unnamed argument would just be 1-- and I'm passing those directly into another function. Probably what I did here in my render function in my code is I modified this kw argument. I added some parameters to it--that sort of thing. Basically now I have this function render, which does exactly what t.render does, except I've added more parameters to kw. Now, there are two uses of stars and star-star. One is in the function definition, which we talked about before, and the other is in the function call. If you have a tuple or a dictionary, and you put them in a function call with a star and a **kw, it breaks those data structures apart and passes them in as parameters, which is really handy. In a function definition, it basically takes all the parameters and puts them into a tuple. In a function call, it takes a tuple and turns them into function parameters. So it's a handy thing in Python. You see it all the time. Generally a and kw are the variable names you would use. But you can use whatever you want, and you can use them in other contexts like we did with the link database. I hope that helps. There is also, I believe, links on the forum to Python function calls that explain the syntax for you as well. Okay, we also had questions about various web frameworks. What exactly is a web framework, what makes something a web framework, and what are some of the other popular web frameworks for Python and popular web frameworks in general? Sure. A web framework is basically the piece of your program that is speaking HTTP, parsing URLs into a path, into a query, and passing that into some handier functions that you define. A web framework can do more or less things. The type of web framework we're using in Google App Engine actually, its lineage kind of dates back to a web framework we built at Reddit. It's about the level of detail that I like to work at, which is I don't think we should be implementing HTTP, but it's nice to be aware what the headers are, of what the query parameters are, and having direct control over the URLs. Some frameworks--a very popular one on Python is called Django. It does a little bit more. It'll add on sessions and user handling and form control and all sorts of stuff like that. It's not very good for this class because I'm trying to teach you how that stuff works. Now, with an understanding of how those things work that I think you can get out of this class, knowing you'll have better understanding of the tradeoffs those frameworks make, and what they're hiding from you and what they're exposing to you, Some of which is convenient, some of which can be tedious when you're trying to do something custom. Outside of Python, really popular frameworks-- Ruby on Rails is probably one of the most popular ones. Ruby on Rails and Django are actually fairly similar in that they do a lot of stuff for you. They hide a lot of the HTTP and a lot of the URL handling and parsing and all that stuff. I don't like to work at quite that high a level, because I feel like when you writing web applications it should to be so simple. Tou should be close to it, because then you can do some neat stuff when you're setting your own headers and fiddling with your own cookies and hashing your own things. There are lots of frameworks out there. I think the Google App Engine is really kind of a nice layer for teaching. It's actually the layer that I work in or that we used at Reddit and Hipmunk in terms of the design of that framework. A lot of people were having questions about YAML files. People had problems getting the YAML files configured correctly. Could you go on to what exactly that is and what you need in it? Sure. To the extent that I can. I, like you, am also a little bit new to Goggle App Engine. A YAML file is just this configuration file that App Engine uses. It defines what the main file of your app is going to be. Like what file is going to load first Python. What libraries need to be loaded. App Engine runs in this kind of sandbox situation. That might not be the right word. But basically libraries that you have installed on your system aren't necessarily accessible, and libraries that ship with App Engine aren't necessarily accessible in App Engine unless you tell the YAML file, "Hey I want to use this library." This helps Google, presumably, deploy your code properly when they deploy it on their machines. So it's not a difficult piece of technology. Basically, if you don't know, I would ask in the forums. I've been doing a lot of googling myself to get my YAML file in order. That's sort of the nature of the business. Try to stay out of these configuration files as much as you can. When we make my cut available, I'll include the YAML file that I've been using which is very simple. I just based it on the "hello, world!" examples from the App Engine website. Okay. A final question we've had is about project management and keeping your code somewhat manageable and not into a crazy ball. Sure, sure. The code I've been writing--ASCII Chan and whatnot--actually resembles a crazy ball, which is fine when you're starting out, but as your project starts to grow, yes, you need to add some more organization. I generally have a directory with all my templates in it. I have another directory that'll have all my static files--my CSS, my JavaScript. In this class, I've given you the little bit of CSS that we've used. Then the rest of the Python files, I generally have one main file that is my controller. It's basically the URL mapping and then the classes that those URLs map to, what their basic handler is. I try to put all of the database stuff in a separate files. If I have a datatype for--in ASCII chan we have a datatype for art. That would be in its own file that has a functions related to art. I generally have a utilities file that has things like generating random strings and creating hash values and secure values and all that stuff you're going to see in the next lecture. Just like when you're organizing any large programming project, pulling things apart. It's easy to pull things apart into separate files. Sometimes you get some weird dependency issues with tricky imports-- one file depend another, depends on the same file. That generally means you did something wrong. But you'll kind of learn over time how to structure things so it makes sense. Lots of files is good. It keeps things clean. It keeps each file sane. You know where to look for things and that sort of problem. In the class, however, I've been working in the same file so you can see it all in one place, but if the projects were getting much bigger than what I was working on now, I would and I would encourage you as well to start separating things out and organizing them a little bit better. Okay. I think that's about all the questions we have for this time. Is there anything else you want to add on at the end? Just a quick thank you to everybody in the forums who has been helping us out, explaining things. I know the permalink thing was tricky for a lot of you. A lot of that is my fault so those of you who figured it out or already knew what I was getting at, thank you very much for explaining that. It's been really helpful. And thank you, Sean, for hanging out in the forums and keeping things going smoothly. It's really helpful. This is my first time teaching a class. I'm kind of learning along with you guys what works and what doesn't. I think we're starting to trend in the right direction. It's been pretty fun so far, and I think you'll enjoy Unit 4. That was one of my favorites. Welcome to office hours for week 4. Before we get into your questions, there's a little issue I'd like to mention with regard to the homeworks. Some of you have been asking about how to delete cookies. The way I had intended for you to do this for the logout portion of the homework-- deleting cookies is how you log out-- was for you to basically just set an empty cookie. Unbeknownst to me--but now I've learned--webapp 2, the framework we're using that's built into App Engine, also has a delete cookie method that you can use to delete a cookie. And all that does is it sets the cookie to blank, just like you would do by hand if you were manipulating the header. Both should work fine. Delete cookie is probably a little bit easier. But not all frameworks have that sort of thing built in, and I wasn't really looking for it. If you read the docs and you find that sort of thing, good for you. It should work fine. Okay. Okay. So let's-- What have you got for me? Okay. First off, we've got some questions on authentication and when we should roll our own authentication libraries, when we should use ones that are provided, and if we could go into more professional authentication libraries like OAuth, for example, a little bit in depth. Okay. Authentication is a tricky issue. If you get it wrong, it can be a painful process. I told you that story about how I got it wrong during Reddit, and it was a painful process. So the decision whether to roll your own or use what's built in, it's almost the same thing, because if you're going to use what's built in, you need to understand how it works so you can decide whether you're better off rolling your own. The one that's built into webapp2, I looked into it in response to this question, and what I found is that they basically have almost the exact same algorithm that we discussed in the lecture-- having the password, creating a random salt, hashing the whole thing together and storing that. By default they use SHA1, and you can specify whatever hashing system you would like. I mentioned in the lecture if you have the option, you should use bcrypt. Somebody else on the forums mentioned scrypt. I'm not super familiar with scrypt. It seems like the same concept but a little bit better. The whole idea of bcrypt versus one of the SHA hashing systems is SHA and MD5 and those guys were designed to be fast, mostly for message authentication, and bcrypt is designed deliberately to be slow so that if somebody wants to hash all of your passwords, it's going to take a while. Now, with regard to things like Google's built-in authentication based on Google users, if that fits your app, use it, by all means. It's kind of a neat thing, but if you want users to have passwords and custom behavior, you're going to have to build your own thing or use another library. But if just logging in with Google suffices, yeah, great. The next part of the question was about OAuth. OAuth is a protocol for authenticating with third party websites. I wouldn't use it if you can avoid it. There's a successor to OAuth called OAuth 2 which works a lot better. If you try to implement OAuth, you will be grumpy for weeks. I'm still getting over it. OAuth 2 is much more straightforward, and it's basically, if you want to integrate with-- I think Twitter and Google has an OAuth 2 integration. Facebook does as well. You basically sign up for them, you get an API key, some credentials, and there's a little kind of back and forth message exchange that basically says, "I am this developer, and you agreed to give me access." So it's not just random access, and you don't have to worry about passwords. It's a little bit more complicated. There's all these tokens and timeouts and stuff like that to deal with, but there are OAuth 2 libraries in Python that work just fine. So long story short, use what fits your app. You'll find yourself rolling your own very often. At Reddit and Hipmunk we rolled our own both times. But if the Google login works for you, great. And if you need OAuth 2, good luck. [chuckles] The next question we had was about database constraints and people had some issues with user names not being unique in the Google Datastore and how to enforce that and when you need to enforce that. Okay, sure. So the database consistency issue, that's a great question, and it's been lurking in the back of my mind ever since I started teaching you guys about Datastore. There's kind of 2 main ways to approach this problem. The first would be using transactions. I'm not super familiar with how transactions work in Datastore, which is why I haven't spent a whole lot of time on it. And I'm not going to spend a whole lot of time on it now, but the general idea is most database systems, Datastore included and also PostgreSQL and MySQL and all the SQL ones, have this notion of a transaction where you basically say, "Begin transaction," and then you can do all sorts of operations. You can do some selects, you can do updates, you can do inserts. And then you commit that transaction. And if any of those queries fail for whatever reason, the whole transaction fails. And so you can turn a bunch of operations into 1 cohesive unit. So that's 1 way of solving this problem. And actually, most of the SQL databases allow you to have constraints on the tables as well. So you can just say, "This field is supposed to be unique." Now, Datastore doesn't allow those constraints, at least to my knowledge. So the way I would solve it in Datastore, not understanding the transactions super well, is to use Memcached. Memcached is an external system. We'll be talking about it in Unit 6, largely from the point of view of caching so you don't have to hit the database on every request because Memcached is very fast. It's basically a giant shared key value store. Memcached can be used to basically behave as a shared locking system. So for the user concurrency issue, the way I would do it probably is let's say you have 2 people trying to register the same user name at the same time. The first case is that user already exists. Both of those queries from separate requests are going to say, "Does this user exist?" and they'll both fail because the user exists. If the user doesn't exist, the problem can arise that both queries hit the database at the same time and it says, "Oh, great, the user doesn't exist," and then allows 2 registrations to happen at the same time, and then that user name gets inserted twice. The way you would work around that is both queries hit the database, return to the app server as false, the user doesn't exist, and then you would have them both write to Memcached. Memcached has an operation called Add which basically says, "Put this item in the cache if it doesn't already exist." And if they both try to add that user name to the cache at the same time, one of them will fail because it's an atomic operation. So they'll both try to add it, one will fail, and he'll return to the user, "User already exists," or, "I can't register this name right now," and the other one will go ahead with the registration process and then, when the registration process is complete, delete that value from the cache or it will expire on its own--that sort of thing. In summary, I would use Memcached. You basically need some shared state between all of your application servers, and that's one of the tricky things when you're scaling, because the more shared state you have, the harder it is to scale. And Memcached is a good place to store this sort of thing. So I hope that helps. Okay. What's next? Okay. So we had a question about storing static files, storing data files that you're serving through Lynx or whatever on your site and where to put them and how to organize them. Okay, great. So the easy answer is just look at the code that I've put up for the homework solutions 2 and 3 at this point. Both have a static directory. And in App Engine you can basically define app.yaml. You can give it a directory specifically for this purpose. In my case, I've just called it Static. And then you can put whatever file you want in there, and your URLs will be whatever you define in your app.yaml. So mine is /static/ and then whatever file. When you're operating on a bigger scale, often what you do is you have a web server dedicated to only serving static files. So you'd probably still put all of your static files under 1 path in your URLs. Very often it's /static. And then you have a whole subsystem designed that's optimized for serving static files and caching them very aggressively and doing all of that stuff. But for our purposes right here, for little stuff, just look at the example code I have in my app.yaml for defining the static directory. And then I just put files in that directory in my project, and it should work just fine for you. Okay. So, possibly embarrassing but probably not, we had a note that Select * is not the only thing that's allowed in Datastore queries and GQL queries. So could you talk a little about that and why you mentioned that? Sure. I mentioned in the lecture for Unit 3 that in Datastore you can only do queries that are of the nature of Select * from 1 table. And it turns out that by the time that lecture aired, that is no longer a true statement. Google released an update to App Engine to allow you to do more complex select queries. So you can select 1 column or multiple columns or *--whatever you want. So that's an improvement to App Engine. We're teaching a little bit to a moving target, so no big deal there. If you want to use those fancy select statements, knock yourself out. You don't really need to use them in any of the homeworks I'm doing in this class. But Google App Engine gets a little bit better every day, and this is an example of it. A little bit of unfortunate timing, but that's how it goes sometimes. The final question we had was about infrastructure and how you go about planning how to build your infrastructure and grow your infrastructure when you're designing your app. Okay. Designing your infrastructure ahead of time is important, and this is actually mostly what we talk about in Unit 6. You don't need to scale ahead of time. That definitely would kind of fall under premature optimization-- making things too complex when all you're writing is a simple blog or ASCII Chan or something like that. But it's good to have in mind the approach you're going to take so you don't shut any doors that you may need to go through later. Generally, what I do is-- So I've been working on Amazon for years now. Both Reddit and Hipmunk use Amazon service. And the way Amazon service works is you just rent machines from them-- physical machines. You never get to see these machines, but you have access to them. So we'll have a couple machines for our database and a couple machines for our app servers. Always whenever I have a database, I always replicate it at least once. Especially an Amazon system, machines can come and go. But even if you're running your own machines, a machine can fail. A hard drive will die, bad memory, power failure. There's lots of reasons you'll lose a machine. So I always replicate a database at least once--usually twice-- so that even if we lose one of our machines, if we lose our master database, even if the site goes down for a little bit as a result-- maybe we're not very good at automatically switching over to our slaves-- we want to make sure we don't actually lose the data. There's a couple classes of failures. Users will forgive you for having a little bit of downtime; they're not so friendly when you actually lose their data. So no matter how small a system I'm working on, I at least replicate the database once. If that's not a can of worms you want to open if you're really running a small thing for yourself, I'd suggest at the minimum at least dumping your database every day, maybe every couple of hours, and uploading that to a third party service. We would use Amazon's S3. Google has data storage. Dropbox, downloading, it doesn't matter. Just make sure you store that data somewhere else so that if that machine dies, you lose it, it gets stolen, whatever, your data is safe. That's usually the most important thing. And then of course as your system gets bigger, you can start being a little bit more thoughtful about how you store huge amounts of data in a reliable way. One of the advantages of using Google's Datastore is they do all that for you. If you're running your own machine, you have to do all of this yourself. Amazon is kind of in the middle where you're still getting your own machines but you have this really nice infrastructure. In the Datastore, you don't even really deal with the notion of machines and replication. Google just handles it. And that's one of the reasons we're using it in this class, so you don't have to think about that stuff right now. Okay. I think that's all for this time. Anything you want to add or any comments you want to make for the upcoming weeks? Sure. I haven't seen a whole lot of questions in the forums or in the office hours about Unit 4 stuff, so that makes me think you all either figured it out or quit. Good job. It sounds like everybody is doing well. Thanks again to everybody that's been helping out in the forums. Sean and I do the best we can in terms of trying to find questions that are easy to grade, but you guys always come up with creative solutions that are technically correct but then fit exactly what we're asking. So thanks for being patient with us. We try to work with you. And if you have those answers you think are correct and our grading scripts don't think it's so, it's perfectly reasonable--and you guys have been doing so--to just let us know and we'll adapt accordingly. Best of luck in Unit 5. That one should be a little bit simpler and a lot of fun. So we'll see you there. See you. Okay. Welcome to Unit 5 Office Hours. We had a lot of great questions in the forums. Before we get into those, I think you wanted to mention something about memcache that you-- eah. --you were worried you weren't too clear on. Sure. Yeah. Somebody asked me a question I received this morning that made me think. There's a 10-second piece of advice I can give you that'll make the homework or Unit 6 actually a lot easier, which you should be working on right about now. We're using memcache basically to store strings and integers. In your code you can say something like memcache.set. I realized as I was writing this stuff I'm trying not to speak while I'm writing so they can edit it. But anyway, you can say memcache.set and then you give it a key. It'll just be a string. It's always a string. That's the memcache protocol. And in the memcache protocol it says the value has to be a string as well. However, we're using this library--this Python memcache library that Google provides and most Python memcache libraries have the same behavior which is you can put just about anything as the value. The value can be another string. It can also be just an integer. Or it can even be a Python data structure. You can give it a little dictionary. What might be useful in the homework you'll find would be a tuple with maybe a time stamp and another string. Something like that perhaps. We'll see. But you can store this value and then when you get the value back out of memcache the library will take the encoded string and convert it back into your Python data structure. So as long as there are simple things in here and by simple things I basically mean lists, dictionaries, primitive data types, you can get away with some objects but they have to be picklable. That's the Python library they're using called "pickle," which converts a Python object into a string. Most simple objects will work as well. Everything we do in this class should be memcacheable without any trouble. Data for entities can be memcached with no trouble, so you can actually store whatever you like. So that should help with the homework. The first question we had was about debugging and logging and how to make the development process a little bit smoother and any advice you had about that. Ok. Yeah. That's a good question. Ok. So, testing and debugging. Let's start with debugging first cause this one I actually do know how to do. First thing you want to do is in your file. You can take import logging. And this is the Python standard logging library, and it's already configured so throughout your code, you can basically say logging debug and just give this a string, and it will print that in the console whenever this line is running if you're in the bug mode. Now, there is another series of lines that I'm not going to write here, but if you look at the homework exams that I put up basically at the top of all my source files I have this line that's basically DEBUG, and basically what it does is it looks at the environment to see if I'm running an app engine debug mode or in production. In production, this would be false, and in development, this value would be true. And this basically triggers all of these statements. In production, we don't log all these debug statements, but in development we log--everything that gets called by .debug gets printed to the console. Now you could also say .error, logging.error, and this will print in production and in development, and so this is really handy. If there is a case where something went wrong, the database did not load right or some user error happened that you want to be aware of, even if it's happening in production, you can call logging dot error, and then you can go into the admin console, which, in app engine, you go to appengine.com and you can see all your admin stuff. You can actually look at all of your logs, and it'll include everything from error, but it won't include the stuff from debug. That's really helpful kind of way of seeing what's going on in your program. Of course, it's always print. It is really helpful as well. Now, using things like the actual Python debugger, is really hard with web apps because you're not running this module. This is whole framework around it. There are more complicated setups, but I found over the years that just having a really good output to your console, you can go a long way. Now, for how to test--testing is really, really hard on web apps. There's a whole Udacity course on how to do testing. And a lot of your modules, a lot of the stuff that I would put in a utils file like the hashing and the cookies and salting and all that stuff, you can just write functions to test that--there's a whole course. Now, for actually testing the behavior of your web app that's a lot harder. What we used to do at Reddit is we would deploy our code on one server, and we'd have an error log that was constantly scrolling in real time of all of our errors across all of the app servers, and if that starts scrolling faster, we know there's a bug we just pushed into production, and we take that machine out of rotation and investigate. That's I would say not the most professional way of doing things. However, I have on good authority that that many of the largest websites from the world actually do things that way because testing website is fairly non-deterministic. You just don't know what the errors are going to be. It was very hard to know what the errors are going to be. Another strategy we used in Reddit a lot is we would take before doing a big deployment, we would capture the last 10,000 requests or so, and we would store those, and we'd re-played them against our new app servers or in development. We just ran all of those requests against the development app server. If that produced an error, then we'd go investigate. That works really well, because we figured if the error is serious, we're going to see it immediately. If it's not something we see immediately, it's probably not serious. That's basically how we've done our testing. Every once in a while something bad sneaks through. Fortunately, we've never lost data or really corrupted any data, because we try to do the best we can locally, but it's still a real challenge. And every website is a little different, so it's something you need to think pretty hard about. What can go wrong and what happens if this piece of data is null or is full of malicious text. As long as you kind of think through that way, you can catch the most errors while you're developing. I hope that helps--it's an inexact science I've met but that's the way we've gotten by in a pretty large website. The next question we had was about security--cross-site scripting attacks, DDoSs, SQL injection, how to deal with those, what those are-- really kind of a big question. Sure. Actually, I wanted to almost spend--I could probably spend an entire lecture on this. We can talk for a few minutes about some of the high-level stuff right now. Great. Security--this is a really big concept. When I was originally doing the notes for this class, I really wanted to spent a lot of time talking about a couple of major vulnerabilities, but I was getting the sense that it wouldn't fit in very well with the level of knowledge you guys had at the time. But I can't talk about a few of the high-level things now that you should get smart about. The first is XXS or cross-site scripting. This basically when you accept data from a user, and you're displaying it in your webpage, and you're not escaping it. We did talk about escaping, and we quizzed you on escaping. But say you had take some data from a user, and then you return it to the user in a text area. In here goes whatever the user typed in. Maybe you're editing a blog entry, and this is the old blog entry. Well, if the code they actually typed in has some HTML in it-- in particular if it uses the script tag, which we haven't talked about at all in this class. This is how you would include some JavaScript. They can actually put code in here that might fetch all of your cookies, using document.cookie-- remember we saw that in Unit 4, I think-- and make a request to another URL, sending your cookie there. If I view this page--if me, Steve, loaded this page that has this other content, it could cause a browser to load my cookies and send it to some other site. That guy could then look at that request, put his cookies in his browser, and then start browsing the site as me. This is the basis for cross-site scripting. If you escape your HTML, you don't have to worry about it. There are cases, however, where you don't want to escape the HTML. For example, in a blog. If you trust your users and you want them to be able to enter HTML-- for example, if they want to put in links and that sort of thing, then you've got to think carefully. Do I trust the user? Or do I want to write some fancy escaping that escapes some HTML, like it allows links for example. That's a big tradeoff. On Reddit, we use a piece of technology called markdown, which is a simplified language good for allowing users to leave comments and that sort of thing. It's got syntax for leaving links and images, but not just random HTML. Actually what we did is we allowed links and image, and then we broke all other HTML. Basically, the name of the game for preventing cross-site scripting is escaping HTML. There's another classes of attacks we haven't talked about, and they haven't come upin this class, which is SQL Injection. What's happening here--this is very similar to cross-site scripting. There's another--well, let's talk about SQL injection first. If you have a piece of SQL--select * from link--where id = %s. This is why you shouldn't use %s in SQL statements. In App Engine they've been using that colon syntax, which is really nice, because they do the escaping for you. If you were to generate some SQL in Python using the string substitution syntax, where you just put in this id variable, and maybe this id comes from the URL or from the user. If this is a number, this works fine. But what if this were the string quote, semicolon, this makes a comment. I'm forgetting some of my SQL here, but effectively you put in a drop table. It's just like cross-site scripting where if you allow them to put in arbitrary HTML, they can close your old tag--through some syntax it's often a closing quote and a semicolon or dash-dash basically means comment. Some combination of things here allows you to just put in arbitrary SQL into the database. Generally, you want to make sure you're always using a wrapper around your SQL. App Engine provides that using their GQL query object that we've been using in this class. Another really popular library I use all the time in Python is called SQLAlchemy. It is spelled like this maybe. SQLAlchemy is one of my favorite libraries. In its simplest use case, the way I've always used it, it's basically got a procedural language for generating SQL, much like the way App Engine has that language where you can say .all and .filter and that sort of stuff. SQLAlchemy provides a very similar interface. It goes one step further and has what's called a ORM, which is an object relational mapping, Which basically converts a Python object into SQL so you don't have to think about SQL, but I hate using these things because it disconnects you from the queries you're running, the queries are what cause your web application often to be slow, and if you don't have direct control of your queries, you're not going to be able to scale quite as consistently. But SQLAlchemy is a really nice library. Just like this SQL injection, you can just as easily have memcached injection. If you're taking input from the user and you're converting that into like a cache key, depending on what memcacher library you're using, if it's not validating the key, they could put something in a URL or something for example that would finish the memcache statement and create a new one and pollute your cache with stuff. We had a really clever guy try to do that to us at Reddit once. Fortunately, he was a friend, and he told us. There is one other huge class of attacks, and this is actually a relatively modern thing. It's called CSRF. This one's really fun. The general idea is remember how we talked about forms. Forms have an action attribute that is where you want to submit the form. We've always been doing things like slash or not specifying it, which submits the current URL. But you could put a full URL in here, and this could just have a completely different site-- ASCII Chan, which Incidentally has this vulnerability in it. Or it could be forums.udacity.com, which also has this vulnerability in it. You could build a webpage on your own domain. Let's say you're at badguy.com, and you made a hidden form, use CSS to hide it, and then you have some JavaScript that automatically submits this form, what's going to happen is a user will load your page, their browser will render this form, and then you'll submit it for them, sneakily. This will submit to some other URL. ASCII Chan won't be able to detect that the request is coming from badguy.com. They'll see that as coming from this user's browser with their IP and with their cookies. CSRF what's happening here is you are doing something on behalf of a user. They've got their cookies that basically identify them. You're logged in as spez. So somebody can trick my browser into making a request to another site as me. They can do things like submit a form as me or vote up on a story as me or enter a bunch of bogus content in the forums as me, which is really frustrating. If you're enterprising enough and can trick me into clicking on a link that you control, You can make me submit something to ASCII Chan, or you could make me submit something to the Udacity forums. If you do that, we'll reward you or something. Now, the way you prevent against this is one your own site you have to include basically hashes or some sort of secret in your own forms. If I've got a URL, let's say it's a new page. This is my blog submitting URL. The handler for this URL needs to look for a hidden input that only exists on the form itself. It's going to be hard to explain this in this format, so what I would advise you to do is just Google for CSRF, but you already understand the concepts required to implement the solution to this, which is basically hashing and secrets. You need to include some secret that is only included on new page, so that when some guy at badguy.com submits a form directly to this URL, they don't have the secret, and the secret would have to come along with the rest of the data. CSRF--it's a really fun attack. You can find it on just about every website online--not Reddit anymore, but there was a time--the way I learned about this is somebody made a link on Reddit that when you clicked it would automatically vote up on that link for who as looking at the page. All of a sudden this link just skyrocketed to the front of our page, and it was like freelimosines.info or something like that. We were like, hmmm. Something's fishy. That's when I learned about this attack. Hopefully, you can learn about it in not quite so public of a fashion. Anyway, those are the major security issues. There's a whole lot to do there. Maybe we can do like an extra one-off lecture at some point where we break the Udacity forums, but this is enough to get you started right now. Our next question was about external APIs and relying on them and the dangers and pit falls of that. For example, for Hipmunk, you parse Amtrak's website and what if they redesign that, how screwed are you? Sure. Well, its true. If Amtrak changes their website, our parsing of Amtrak also breaks and thats basically how it goes. Its not really a big deal, thats just kind the way it goes. The harder decision you have to make there is how you want to actually parse the website for websites that don't have an API or websites whose API is so bad, youd rather just script the HTML. You can do it by hand. I showed you some regular expression examples in the lecture. Those work if the website isn't changing very often. Basically whatever works--parsing HTML is really tough because HTML is often invalid and malformed and all those sort of issues, so basically play whatever works and-- Yeah. And-- Just do what you can. Yeah. Things break and then you fix on them and thats how it goes. Okay. Great. The next question we had was about internationalization and localization. A lot of our students are all across the world. How do we support something on that scale? It's actually not that hard. The hardest part is doing the translation. There's a package you can use called gettext, and this is built into Python in most major languages. Basically what you do is in your templates, you either put all of your strings in one place, in one module, and in your templates, and in that module you-- I think in Python, the function that we use looks like an underscore, and you just put all your strings inside this underscore function. Then you just have a separate file that's a database of all of the--for in our case, English language strings to whatever language and then your website just kind of works. Well, you'll basically say, "Here's the language I want to use, and here is where I store all my translation files." And then everything will just kind of translate on its own. Basically, Google for gettext Python, and you will see a whole bunch of information. And we'll include some links on that in the office hours instructor comments just to help you guys out. Great. Great. That's why he's here. We also have a question on SOAP and when to use it? Why you do use it sometimes? Just clarifying everything about it. I thought I was clear about on this lecture but maybe I completely misspoke. We don't use SOAP ever at Reddit or Hipmunk and-- Well, I'll just say some of the providers use SOAP for Hipmunk because we integrate with lots of lots of people. It's a nightmare. SOAP is awful. It's a Microsoft technology, so don't use it if you can avoid it. I think the question was like "Why would you use SOAP over XML or JSON?" I don't know. You wouldn't. Use XML or JSON. It's a lot easier. Everybody can parse it. You don't have to do all these complicated Microsoft stuff. Don't use SOAP. The next question was about handling the final slash because it's technically a different URL and what the best way to handle that is. Ending URLs in slash--honestly, I don't know the correct answer. I usually make my websites not care. You've seen in my URL mapping I have a regular expression that looks like this--/blog/?. And what this basically says is this will map the URL/blog, and then it will also match it that has the trailing slash, which I think it's what most friendly way to do it, because some browsers will automatically add the slash or users will add a slash. They have a way of creeping up, and you don't want to have like /blogwork/44 or vice versa because you make a lot of people hates it, so I just make it optional. Now, you can do this thing--sometimes, and I've been working on this on the final project where the URLs are going to be a little bit more dynamic. I usually have regular a expression that looks something like this: /+ or it's like .../+ or // or something like that. Basically, I detect the situation where URL ends in a bunch of slashes. And then I have this go to some handler that automatically redirects with single-slash version or redirects to a zero-slash version. Depending on your websites, that's kind of handy. The question that somebody asked, they basically proposed, "Should I do it this way? or "Should I have a redirect way?. The answer is, it depends on web app. Do whatever feels right, but it's a great question to ask, because it is something you should think about. You should try to make both versions work. It could be the case that /blog is the blog and / has got more content. It's kind of a hierarchical view your website--that's fine--but think about it, and it is pretty easy. Generally, you just add a question mark and forget about it. I hope that helps. In Unit 4, you mentioned that you would tend to store the secret key in a completely separate machine from the one you were developing on and you mentioned the concept of a production machine. Some of our students were wondering if you could go into that a bit more of that. Sure. Sure. We can definitely talk about that--there's a few little edge cases, nothing major, that we'll just talk about here on the white board and it should help you out. How to have a distinction between production and development. The way we've always structured stuff on my project is we'll have a file. Usually we call it like--production.py, and depending on the framework we're using, sometimes this kind of notion is built in--when you launch your program locally you say something like dev_app whatever--I don't know--let's not complete it and you can give a bunch of configuration options. Often you can give it a configuration file as well. This isn't always the case--sometimes what we do is in a simple case we just have production.py and we'll have the devel.py. These are both basically have a bunch of global variables--things like secret keys that you're going to use for your cookies or the passwords--that sort of thing. We'll have one that's only use in production and one that's only used in development. And this one maybe included in our repository and this one may only exist in our servers, or you know may exist in our repository but generally we don't like that stuff getting shared around, especially if it's open source. For example, Reddit's open source, so we don't include production.py publicly, but I think we do included devel.py for you guys to use locally. And then when we deploy code on our own machines, we just symlink to config.py whichever one we want--so I think our apps by default, look for devel.py and-- and if it's not there, uses config.py which may symlink to like production.py. We also have a bunch of different configuration files--if whether you're an app server or whether you're a database or--because we have all these different machine that serve different purposes--so I put all my stuff in one module and then we have this-- complicated symlink set up when we do deployment that basically says this app server is doing this job, therefore it should use this file and you can copy to place the symlink that you can do all sorts of clever stuff. Sometimes, it's built into the framework. At Hipmunk, it's built into the framework. We just say ff.py is the name of our main executable and I can just say-- dash dash dash dash config equals and always specify one of these files and that was great. There's no easy correct answer or simple thing. Store your globals and different files if you want to keep them secret and when you're deploying it kind of figure it out how to decide which value you want to use--hope that helps. Our last question was basically our next steps. I mean we've learned a lot of service side technology, introduction of programming-type things, Where do our students go from here and what would you recommend they learn next? Sure. So I would start getting good at two main technologies. One is JavaScript, which is a completely separate programing language from anything we've talked about in this class in that it runs in the browser, and so you can make your web page do fancier things. The other is CSS--I've had some CSS in the homeworks and in the lectures but I've never quizzed you guys on it because we don't know how to even grade the CSS yet. And this is how you described what your pages look like-- colors and font sizes and boxes and layouts and all that sort of stuff. Basically everything you've learned in the class, you can make a pretty substantial website with everything you've learned in this class up until this point. And JavaScript and CSS, you can make your website look more professional, look more like a website, but functionally, you can do all the major things. JavaScript and CSS--if you learned those, you'll have a lot of tools in your toolbox. Okay. Great! I think that's all the questions we had. Unit 6 and homework 6 has just been posted--anything you want to say about that or about week 7 and the final? Unit 6 is caching, basically 101 ways to use memcache. That should be a fun one--the homework should be pretty straightforward I think.. And in Unit 7, no more quizzes in Unit 7. It's basically we're just going to talk about a lot of the real world stuff we did with growing Reddit, and we'll talk to some of the Udacity engineers about how they app engine in production. Then the final is basically going to be building another website similar to your blog but this time all at once and we''ll talk all about that in Unit 7. One last question I just remembered was how to prep for the final, and I would recommend personally that you just make sure you have all the homework done and you understand it. If you have those things done, I would say the final really shouldn't be bad. Yeah! If you've done the homeworks, the final shouldn't be any problem. In fact, after I wrote the final code, about two-thirds of that code is from homeworks. The user a registration stuff, the caching stuff-it's all--you'll find yourself when you're writing any web application a lot about that--a lot of that code will get reused over and over again. That why we taught it. If you can do the homework, you shouldn't have any problem with the finals. Okay. Great! Well, see you in class. Right. Bye guys! Okay, so for your first homework, what I'd like you to do is get a basic web app online. This is going to be the foundation for what we're doing in the rest of this class. So step 1 will be install Google App Engine. We'll include documentation in the course notes for how to do this, and you can also use Google's own instructions online. And we want to install the Python version. Put online a basic app. All it has to do is print out the words, "Hello, Udacity!" Nothing fancy. Just basically get this thing online, and when you've got that working, submit the URL here. I'll show you what it looks like on my browser, or my version of it. Here we are. This is what I've installed. You can see it's running on appspot.com, which is Google App Engine's domain by default. All it does is has a simple webpage that prints out, Hello, Udacity! This is the entire homework. If you get this working, you have succeeded. For some of you, this should only take 15 minutes or so, but I realize that installing web apps and packages and things like this can sometimes be troublesome. So once we've got this working, we'll have a good foundation to build on for the rest of the course. Okay, good luck! Okay guys, I'm going to walk you through the solution to Homework 1, which is basically just getting Google App Engine online. The first thing I do is I got to Chrome. Let's see, we're going to download-- we can go to Google--the Google App Engine page. I'm going to assume you've signed up to App Engine. And then we basically go to the getting started for-- I'm using Python 2.7. Some of you may have more success with 5. I'm going to use this Hello, World example. And we're going to create these two files. One is called helloworld.py, and the other will be called app.yml. So let's start with the first one. We'll copy this. I'll go to my editor, paste this. We're going to make this say Udacity, if I recall--Udacity. Let's go ahead and save this. So I've saved this file. I'm going to make the other file. We can just take the contents from the getting started document here-- app.yml--we'll put this in a new file, and we'll go ahead and save this. Okay, all is well. We'll go to my terminal, and we'll go to that directory. I called it Unit 1 Homework; it's where I save these two files. You see, there they are. And then to run it locally, it always says we run div_appserver. This is the console way of running Google App Engine code. Many of you are probably using a GUI. I prefer to use the console version. It makes it a little bit easier. You don't have to add projects and that sort of stuff. I'm going to run it on a different port. That's what the P command is for, because I share this machine with other instructors and somebody is already using the default 8080. And then we just run it in the current directory. That's what period does. Okay, so this starts up. It complains a little bit about some missing APIs. We're not using the image API, so it doesn't matter. And then we go to our browser, and we can go to local host 8888, and there we see it. Hello, Udacity. So all is moving. We can play around with things a little bit. If I wanted to change the text here, I can change it, save it, go to Chrome, reload, more exclamation marks--pretty cool. Now, when I want to put this online, all I do is instead of using div_appserver, what I use instead is update app cfg update, and I can run it in my current directory, and this will upload the app. I'm not actually going to run this for you because this would override my other homeworks that are already online that are--you guys can use for demos. But basically all I do is I hit Enter here, and it chatters at me for a little while, and then we're done. The homework was intended to be very simple, but I realize that actually getting App Engine running on different platforms can be troublesome, and getting the Python versions in synch can be troublesome. I hope you guys have worked through all those things. And that's it for Homework 1. All I wanted to do was get this basic website online. There it is in my local machine. And if I were to go to where I've already got it uploaded-- I think I can go to udacitycs253appspot.com, where I've uploaded it prevoiusly, and there it is--Hello, Udacity. So all is well. Good job, if you got that. Hi, I'm Sean Bennett, and I'll be TAing Steve's course on Web Application Engineering, where--by the end of the course-- you'll have a Web app--up and running-- on Google App Engine. This is my first term at Udacity, and I'm really excited to help everyone out. I'm going to be helping you get Google App Engine up and running, and I'll also be there to talk with everyone in the forum, in case you have any questions. Thanks, and I can't wait to see you in class. Hey, guys--so today we're going to go over how to install Python and then install Google App Engine so that you can get going on the homework. That's really the main point of this homework-- to get you up and running, so that-- for the rest of the homeworks-- you actually have a good handle on how to start, and we can just go over how to actually start building some Real World Web Applications. So okay--let's start out. So here, I'm at: www.python.org. Go ahead and go there, and then you'll get this link and go down to: download Python now. The good thing is that if you're on Mac or Linux, then you probably already have Python installed. You shouldn't need to get anything. If you do, then you can go ahead and install it from here. So down here what you want to click on is-- if you're installing Windows, then either a 64-bit system, down here, or 32-bit-- you simply click on there and install it like you would normally on a Windows system. Same thing with the Mac system. On Linux, you can install a source tarbal-- but, honestly, you probably already have it, and there's an easier way to do that with your package manager. I'll have a list of instructions for some of the more common package managers for Linux up in the forums. So we're not going to go over that right now. But go ahead and open it, for example--right there-- and then install it as you normally would. It shouldn't take more than a few minutes. And after that--once we have Python installed, we have everything we need for Google App Engine. So let's go ahead and install that. Now, Google App Engine is right here. If you don't want to type all of this in, just Google App Engine and it should be the first option on the search results page. So before we go ahead and sign up, we're going to install the software development environment and it's pretty easy to use, for the most part. So we're going to go over here to Downloads. We're going to want the Python Version of it, so either the Windows, the Mac or the Linux-- depending on what platform you're on. Don't worry about the MapReduce Bundle. That's not something we need to worry about right now. So go ahead and open up whichever one is appropriate for your system. All of them are super simple to install. Once you've got it installed, we're going to open up Google App Engine and it opens into this screen right here, okay? Now what we need to do is open up a new application. So go to File>New Application, and then that should open up this, right here. We'll go ahead and install it under, let's say: hello-udacity. Great. And there we go. Okay. So there are a couple things to look at. Now we can open up the files that this automatically creates. So go to the Path, which you see right here, and there's really only 1 file you need to worry about-- and that's: main.pi. There are a few other files in that directory. We're not going to worry about them right now. We'll explain it later. There's not much to it, really. Here's your main file for your Web application: hello-udacity. So open main.pi, and it's really a pretty short file. And now you change this to print out: hello-udacity. We can run this. You see that it's running on Port 8081. Steve talked about Ports early in the course. So what we're going to do is open up localhost.8081-- and you see: Hello world! Now, you're going to have to change this to print out: hello-udacity. But the hard part--the part we're really interested in-- is actually installing this so you're ready for other homework assignments later on, when we're building--well, some Web applications with some actual content. Now we've got it running on our local system. But, obviously--well, hopefully, we can't see your local system. So we need to actually sign up for Google App Engine. So let's go back to the main page that we were at before, sign up for an account with them--it's very simple, and once you have all of your information there, then all you have to do to put this up online is deploy it to your account and password, sign in, and it will automatically load all these things. And then, once you're done, you should be able to go to the Google App Engine Web site and check out your Web app. Now, I haven't loaded this on yet, but once you do, you should get the same results from there that you do from your local host. And that's about it. All you have to do is change this to: hello-udacity and then load up the URL, whatever this happens to be-- this is hello-udacity in mine; in yours, it would be whatever this is-- and put that in for the homework assignment, and you should be good to go! Okay, so homework 1--what I'd like you to do is make a web page with a form on it that let's you ROT 13 some text. First, I'll explain what ROT 13 is. Okay, so ROT 13 is a simple cipher to run a simple encryption algorithm on some text. So it looks something like this. Okay, if I were to take this string 'Hello' and apply ROT 13 to it, it would look like this--Uryyb. What I've done is I've incremented every letter by 13. So H becomes U. E becomes r. L becomes y. L becomes y, and o becomes b. So if I had an alphabet like so-- if I were to convert each letter, I increment them by 13. So 'a' moves 13 spaces and becomes 'n' or 'h' moves 13 spaces and becomes 'u'. 'z' wraps around moving 13 spaces and becomes 'm'. So is you were to apply a Caesar cipher to itself, you get the string you originally typed in. It's not the fanciest cipher in the world, but I'm not trying to test your cryptography skills. There's another class for that. I'm just trying to test your web handling skills. Let me show you what this should look like when it's all working. Okay, so here's the app running on my appspot account at /unit2/ROT13. If I type some text in this field and click submit, it rerenders this form with my text in the text box, and if I were to hit submit again, it converts it back to 'Hello". Okay, this is what I'd like you to build. A couple things to notice--1 is that it preserved case, so the capital H became a capital U and the lowercase 'ello' became the lowercase 'ryyb'. I'd also like you to preserve punctuation. So I've expanded my text here to have an exclamation mark and a question mark. When I ROT 13 this, it preserves the exclamation mark and the question mark, and everything else becomes ROT 13. You know it's working because when you run it again, you get the original text. I'd also like you to preserve whitespace, okay? I've added some whitespace and another exclamation mark and everything worked. And, here's one thing to look out for. Remember you might need to escape some HTML. Now this box here--this box for the text is using an element we haven't talked about. It's called a text area, and it's another form element for entering large pieces of text. If I were to include this in my text field and not escape it properly, we could have problems. But as you can see, I have escaped my less thans and greater thans properly, so everything works. I can go back to text area, and all is well. Now this is running online, so you can verify what my expectations are by playing around with my own version at this URL. You can also if you want view the source of this page to see the HTML I was using to draw the bigger box and that sort of thing. It's fine if you want to use that. What I want you to do is implement the backend part, and once you have it working, I'd like you to enter the full URL where it's running here. Now when we grade this, it's a little challenging. Obviously, we're not going to be able to grade how it looks. We're going to have an automated script that submits some data and looks at the response. Make sure you follow the notes below to have the correct input name, so when I submit directly to your form, I can find my text in the result. Okay, good luck! For your next homework what I'd like you to do is make a signup page that validates a user's input. It should ask for 4 things--a name, a password, verify the password, and an email address, which will be optional. If the user submits something that's invalid, it should print out an error message, and if it is valid, it should redirect to a welcome page. I'll give you a demo of this now. Here's my signup page. It's running at this URL. If I were to type in a valid username and passwords and an email and click submit, watch the URL. We get redirected to Welcome--username equals spez-- where it prints out Welcome, spez! Now a couple things that this should do. If you don't enter a username and you submit, we should get an error message. Likewise, if we don't enter a password, you should get an error message. If we submit an invalid username--this one's invalid because it has a space in it, and I'll include in the notes what a valid username is-- we should still get an error message. If I include 2 passwords that do not match, I'll also get an error message. Now notice that when we included an invalid username, we kept the username in the form, but when we included an invalid password, we blanked the passwords. That is intentional. The email address is optional. I can type in 2 matching passwords. I can make this a valid username. When I submit this form, it says Welcome. Okay, all is well. If I type in an invalid email address, and I'll include for you what makes an email address valid for our purposes, we should get an error message on that field as well. That's not a valid email. Be sure to read the notes, and when you've got this all working, please enter the URL here. Good luck! These are going to be the solutions for the Unit 2 homework. Remember, we had 2 parts to this. We had the ROT13 tool, and then we had the sign up page that tested for errors and that sort of thing. I'll show you quickly my versions working, and then I'll show you the code, so let's start with the ROT13. Okay, here's my ROT13 running on my local machine here. I could type in some text, and if I submit, it gets ROT13'd inside the text box, and if I submit again, it gets changed back to the original text, and that's how you know it's working. It escapes properly. We can see that by typing in our closed text area there, and it's preserving everything. All right, so let's take a peek at the code. So, I'm in an appengine.py file. This is the base ROT13 handler that I wrote. It inherits from this base handler class, the ROT13 class does. That added some convenience functions. First, I have a write function, and this is short hand, so I can say self.write instead of self.response.out.write. I'll just save some typing. And then I started using something called templates, and I'm going to spend a little bit more time on templates in Unit 3. It saves me the effort of having to type in all of the string substitutions that you probably did for this homework if you didn't already get tired of that and figure out templates. My base page--well, let's look at the URL handler first. We've got /unit2/rot13 maps to the Rot13 class, and so we come up here to our Rot13 class, and it's got 2 functions. It's got a get function, and all this does is it renders this file called rot13-form.html. Now, your version, you may have printed a whole string. This accomplishes that same thing, and I'll go ahead and show you that file. It's right here. We want to get in the habit going forward of starting to separate these things, and I apologize for putting you through that heartache of writing out long strings first, but you'll appreciate the niceness of this once you've done it the hard way. This just returns some HTML. It's got our title. It's got an h2, which makes some big text at the top of the page. Here's our form. Its method is post. And it's got a text area. The text area has a name of text. I added a little styling here to make it a little bigger. This is just some basic CSS. You're free to copy this from my demo when I put this source stuff online. This syntax here, again, we'll talk about this more in the next lesson, but instead of doing the string substitution, this substitutes the variable text passed into the template, and it automatically escapes it for me so I don't have to deal with that, and this closes the text area, and then there's a submit button. That's pretty simple. If I were to turn off the auto escaping ability, which is set by this parameter here, let me show you the behavior of that. Okay, so here we've got some text in here. Remember, I disabled the texting--I'm sorry. I disabled the escaping, so let's see what happens when we submit this. It works the first time, but the second time the text jumps outside the box. Why did that happen? Well, when we turn that ROT13 text area back into a closing text area, it actually closed our text area in the HTML and then put this text outside it. If I were to view the source of this file, which you can do in Chrome easily, we can see what happened. You can see my template, and then you can see my text area gets closed by the unescaped version of that text and then "escapes properly" gets put outside the text area. And then here is the closing text area for my template, so we want to make sure if we go back to our editor here and I turn on escaping again--this is something you're probably doing by hand, which is how we learned to do it initially--and if I were to go to Chrome and then reload this page--reload, that's going to confirm the form submission-- we can see that my text area actually got escaped. And so this is what the template has, and this is how it renders. Now, what's interesting to note is that even though our HTML has the escaped version of less than and greater than, it renders as less than and greater than, and when we submit the form, it's as less than and greater than. It's not as the escaped version, so hopefully you had a chance to kind of experiment that and see for yourself, but that's how that works. Now the second homework assignment here was a signup page. Here's my signup page, and the idea was you could type in a user name and a password and an optional email if you want and then click submit, and it would take you to a welcome page. Now, if you leave your passwords blank, you get an error message. If you don't enter both passwords in, it complains that they didn't match. If you give an invalid name, which in my case I made it be a minimum of 3 characters, it complains that it's not a valid name, and an email is optional, but if I type in something that's not a valid email, it complains. If I type in an email--I'm going to type in some valid stuff and hit submit-- we get to the welcome page. Okay, let's look at the code for this real quick. One last thing I did I should show you. I double check to make sure the user name is valid here too, so if you put in an invalid name in the URL, it will automatically redirect you to the signup page. Okay, let's take a peek at the code. Here is the portion of the code where we are doing the signup handler. You can see my URLs down here. I've got unit2/signup goes to the class signup, and unit2/welcome goes to the class welcome, and the signup page, if you just get it, it renders the empty signup form, which is another template that I'm using. I'll show you here. This is just HTML. Now, again, you could have used a big string, and most of you probably did. Here is my HTML. You can see it's got a form method post. I used the table to lay out the form. You don't have to do that. We didn't grade on the appearance of it. I just used the table to make my columns line up nice. The important part was we've got an input type text. Name is username, and the value, this is another template variable, and then the error. Here's another template variable. This could just as easily be %s in the way that you learned how to do it. We've got input type password, name password. Value is blank. The value is blank here because whenever there's an error, I don't put the passwords back in the form field. If there's an error with the passwords, or if there's an error with anything, we make them retype their passwords. The password error field. The verify, input type password, name verify. That's for verifying the password, and an error for that one, and then we've got our email, email optional, type text, name email, value email. If there's an error with it, we'll leave it in there so they can update it. And then the error message for that field and input type = submit, and let's take a peek at the code for this guy. When you post to here--and what I did is I have a variable called have_error, and if we make it through this whole function and this is still false, then we've rendered the success page. Otherwise, we render the error page. First I get the parameters. I get the username, password, verify, email out of the request. Request.get fetches those parameters. Then what I do is I run it through these functions that I've written, validusername, validpassword, and valid_email. I've defined regular expressions. I believe we gave these to you for each of these, so a username is just a through z, 0 through 9. It basically has to be between 3 and 20 characters. We provided this to you, and I think we showed you how to use regular expressions as well. This function is very simple. If there is a user name, basically if it's not blank and it matches this regular expression, true. Password is a similar thing, basically any characters between the length 3 and 20. If there's a password and it matches this regular expression, return true, and the email, the actual email regular expression to validate an email is comically long. It's thousands of characters. I use a simpler version, which is basically a bunch of characters, an @ sign, a bunch of characters, a period, and then a bunch of characters. I find that works pretty well. If you try to get more complicated than that, there's a good chance you'll reject what would otherwise be a valid email so I usually let-- if we're going to send emails to people, I let whatever tool I'm using to send the email--that can break if the email is not valid. This gets us close enough. In fact, I think Reddit uses this regular expression still, and it's always worked fine. I think there's some limits to the length of this, but one more thing. I make this dictionary called "params," and these are params I'm going to send back in to rendering. This would be similar to if you're using the string substitution to draw your HTML. You're basically going to build up this dictionary of the variables that you want to substitute in. I'm always going to send back the username and email if it's a bad, bad form. If the username wasn't valid, I add the error_username to this params dictionary, and I set have_error = true. If the password isn't valid, here's the password error. Have_error = true. If the password is valid and it doesn't equal the verify variable from the request, we say that the passwords don't match and have_error = true, and then email. A valid email, if you look, is different from the other ones. These ones say "return password and." This one says "return not email or," so what this is saying is either they don't specify an email or it has to match this regular expression. Everybody else says they have to give a password and it has to match the regular expression. That's how we handle the email is optional case, and then basically if we have an error, I just render the signup form again with our error messages, and if we don't have an error, I redirect to this URL and put in a username into the URL as a get parameter. When we handle unit2/welcome, we come to this handler here, welcome. And we get the username out of the request using request.get, and then if it's a valid username, render the welcome HTML template, username = username, or redirect back to the signup page, and the welcome HTML template is pretty short. All it is is just basic HTML, and it says "Welcome," and then it includes the username, and that's that. So, that was Homework 2. I hope you managed to figure everything out. I hope you now--after seeing my solution with the templates and your solution with the string substitutions-- are eager to start using these templates on your own. I'm not going to teach you how to use them specifically, but there's plenty of documentation on the Google App Engine site, and I'm sure in the forums there will be lots of activity as well. And also, we can provide these few lines here and this base class if you all would find that helpful. Okay, good job everybody, and on to Unit 3. Okay! Unit 3 homework. We've only got to do 1 thing in this homework, and it is build a blog. [Chuckle] Specifically, we want a front page that lists your entries-- it doesn't need to list all of the entries, but it should list at least the 10 most recent or so-- a form to submit new blog entries--this needs to check for errors to make sure both fields--a title and a blog body--are present, and if it is successful, it should redirect to a permalink page for the entries. This is just--a permalink is just a link to a specific entry. And that's that! Let me give you a demo of what I'm expecting. Here is Udacity-cs253.appspot.com/blog. This is a blog I've made. I only have 1 entry, and in this particular case, it's just "The Raven". We can go to /newpost if we want to enter a new post. I can type in a title. If I were to submit this form without a body, I would get an error message that requests both a title and a body, and if I were to click submit with a title and a body, I would get redirected to the permalink page, which just appears at some URL. And we can see my title and the body, and I can go back to the front page--/blog--and see, in my particular case, the 10 most recent entries. So, this is what I'd like you to build. We've got more details in the description for this homework in terms of form parameters and all of the redirection handling things we're expecting, and when you're done, submit the URL of your blog here. Okay! Good luck! This is the solution to homework 3. Homework 3 was basically built the shell of the blog. This is my local blog running on this local machine. If you recall, I wanted you to make a URL that would list some blog posts. Then I wanted you to make another URL, new post, which allows you to enter a new post. And posts have a subject which you enter there and a body that we enter here. Then when we submit this page, we get redirected to a permalink-- a permalink is just a link to a specific post. In this case, it's /2, which is the ID of this blog entry. Then if we were to go back to just blog, we would see all of our blog posts. Actually, not all of our blog posts--the ten most recent blog posts sorted with the newest one first. Let me show you the code that I wrote to make this work. Here we are in the main source file. This is the source file I've been working from for all of these homeworks. A lot of this should look familiar. We've got the template-loading code here. That just basically says I'm going to have a directory called "templates," and we're going to put those templates in there. Again I know we haven't discussed templates specifically in this class, because they're not required, but it does make life a little bit easier when you start generating more and more HTML. I'll walk you through all the templates that I've used. I've got my main handler I call bloghandler, and this adds just a few convenience functions. We've seen these before--write and render_str and render. Write just keeps me from having to type self.response.out all the time. Render_str takes a template name and some dictionary, basically, of parameters-- things to substitute into the template. Render calls write and render_str to print out a template. Here is homework 1's solution. Now we get down to the actual solution here. A couple things I've had to do. This function--we didn't talk about this in the lecture--this is for the datastore. Basically, when you store things in Google's datastore, they need to have some sort of--well, they don't have to have a parent, but for organizing the data I found it's convenient to have a parent. This basically defines this is the blog key. This is going to be the value of the blog's parent. The parent is normally another element, but in our case we just give it a key for an element that doesn't even exist. I've kind of set the stage here for having multiple blogs even though we're not going to do that in this course. It takes a name parameter. By default the name just equals default. Here we get to something that you probably have to do, which is define the actual post entry or define the post class. Basically, all the this is is a list of the properties that a blog has or a blog entry has. It has a subject, which is a string property. It's required. It has content, which is a text property, which is required. Remember the difference between a string property and a text property is a string property has to be less than 500 characters, and text properties can be greater than 500 characters. Also, a string property can be indexed while a text property cannot. In theory I could have used text properties for both of these. I tried to stick to what was most appropriate, which would be which would be string for the subject and text for the body. Text also can have new lines in it, which obviously you want in a blog entry. Then we've got two time stamps. The first one is a date-time property of when the blog entry was created. This parameter autonowadd basically says automatically make this property the current time when you create an object, so we don't have to set it, which is really convenient. Even more convenient is this auto_now function. What this does is every time we update the objects, it sets this property, last_mod, to be the time that we just updated an entry. If we were listing our blog, and we wanted to sort by creation time but also display when the last time they were updated. This property would let us do that and with this auto_now parameter equal True, the Google datastore will keep that property up-to-date, which is pretty handy. Now, I've added a function on the post object called render, which will basically render that blog entry. One thing it does is we're going to be rendering this in HTML but the user doesn't type in HTML for the most part. We want them to just be able to type in text with new lines in the text field, but we want to render it with a bunch of new lines. What this does is this replaces new lines in the input next into HTML line breaks. If we didn't do this--actually, I'll go ahead and show you want it looks like if we don't do this. I'm just going to comment out the rest of this line where we replace new lines with line breaks and then we'll see how this works in the browser. I've entered a basic blog entry--a little subject and some contents with multiple lines in it. I'm going to go ahead and submit this blog entry, and you can see that it brought us to this page--we see my subject and we see my body, and the contents of the blog entry are all on one line. Remember, this is because HTML takes all white space, spaces and new lines and tabs, and merges them into one space. That's all we get is one space. If we were to look at the source for this file, we'll see that the contents are actually rendered with multiple lines just like I typed them in the HTML, but when the browser renders that HTML, we just get the one line. The way we fix that is we replace all those new lines with line breaks. Let's go ahead and give this a whirl again with this string replacement on. I'll reload the page, and we see our new lines appear as we intended. If we look at the source, we can see that we've replaced our new lines with line breaks. That's what's causing our blog to display nicely. Now, we cold require the user to enter in actual line breaks as their typing the blog entry, but that's a little tedious. Although I still want them to be able to put other HTML in. Blogs have links and that sort of thing. It just makes it slightly easier. You didn't have to do this. I just wanted to show you how all that works. Back to the code. That's our post object. Let's get to the actual main handler. Blog front is the handler for just /blog. The first thing we do is we look up all of the posts. This is blog front. This is our handler for the main blog URL. The first thing it does--actually there's some leftover development code here. Let's get rid of that. The first thing this does is looks up all of the posts. We've been using GQL to do queries against the Google datastore. I was playing around here, and I used Google's procedural language for writing a query. This looks at all of the posts ordered by creation time and stores them in the post object. We could have done GQL just as easily to get our posts. I was playing around with something new. That's what I did here. This renders the front HTML template with this query, the result of this query, and the variable posts. I'll show you all of the templates when we're done. I can also show you what the GQL for this line would look like. Let me go ahead and give that a try. I've changed that line to use GQL--the SQL that we've been playing around with. That just looks something like this--select * from Post order by created descending. Actually, I think I said 10 most recent, so it would be limit 10 as the SQL for doing a limit of 10. Let's go ahead and give this a try in the browser to make sure it behaves the same. I'll reload this page, and it does. Okay, cool. We used front.html to render our posts. Let's move onto the next one. This next handler is the PostPage. This is the page for a particular post. The way you look up the particular post in the Google datastore, is you first make a key, and in this case I used the from_path() function. It says find the post with the ID post_id, which gets passed in from the URL-- I'll show you that in the handler definition--whose parent is blog_key(). Now you don't need to do this parent part. Because I create the blog with the parent, I have to look it up with the parent as well. This is how I did it--we called db.get(), which is how you look up a particular item. We stored that in post. Now we see if there's not a post just return 404. Basically, if the user typed in garbage in the URL If there is a post, return permalink.html with post equals post. There's a lot there. Let's talk about how post ID gets into this function first. If we go down to the bottom past homework 2. You can see I have defined a couple of URL handlers. The main one blog is simple. It goes to BlogFront. /Blog/newpost goes to the NewPost handler. We haven't talked that yet, but that's all fairly straightforward. /Blog/ and then a number, 0-9+, this is a regular expression for how to describe basically an integer. This goes to the PostPage handler. This is how in App Engine you pass a parameter into the PostPage handler. You may have done this differently, but this is how I've done it. This basically says anything in parentheses here will be passed as a parameter into either the get or post function for PostPage. If we go back up to PostPage, a string representing that number gets passed in. That's why I call int on it. I turn that into key, and then I do the lookup. Then we call permalink.html. Let's see how that looks in practice. Here I've gone on blog/3, which was the ID of the last post we just entered. This 3 gets sent into our function as post_ID. We convert it into an integer. We make a key, and then we look up that key. If I were to type in an ID that doesn't exist here, I get an error page. Now this is a 404, but Chrome is using this error page, because I didn't send any content. You can make a special 404 page, but I haven't done that, so this is what we see. If I were to type other junk that's not an integer, we get this different 404 page. Now, why did we get two different 404 pages? Well, because it went through two different 404 handlers. I'll show you that here in our editor. If we go down to our URL handler, this regular expression only matches numbers-- 0 through 9 and then 1 or more of them. That's what the plus means. That means that's going to go to PostPage. Now, when I just typed in the letters, this URL didn't match at all, and this whole block of code kind of fell through. None of these URLs matched. The WSGI application, the kind of webapp2 handler--the default handler, printed their 404 page, which says "404 Not Found." We'll go up to my 404 handler. If an integer is passed into the URL, we'll make it this far, and we won't be able to look up a post. Instead we'll just return error 404, but with no content. That's why we saw that empty Chrome page. Normally, we'd probably have a function called send 404 or something that has a prettier 404 with an image or that sort of thing. We'll go through all the templates at once. Our last handler is NewPost handler. This actually should look fairly familiar to you. This kind of has the general kind of form submission error handling process we've been using before. If you just do a get on that page /newpost, we return the newpost.html. If you post to it, we try to verify the forms. The first thing to do is we get the two parameters out of the request--subject and content. Those are the name of the form fields. If we don't have a subject and content, we will do this clause first. We create an error message "subject and content please," and we render the form again with the user's entered subject, content, and error. Newpost.html expects these parameters. If they did enter a good subject and content we create a new post. I set my parent. Again, you don't have to set a parent. It might make future organization easier. I was learning data store myself. I set the subject equal to subject that the user entered and I set the content to be the content that the user entered. Remember the two date parameters created and last modified would be set automatically. We call p.put to store this element in the database. Then I redirect the user to /blog/ the ID of the element, and this is how you get an object's ID and datastore. Let's see this in action in the browser one more time now that we know what all the pieces are. Here we are in the new post again. Let's submit this form without a subject and body. You can see that we have the error message "subject and content please." We'll enter a subject and a little body, and when we click submit, we get redirected to /blog/4, which is the ID of this post. You can see our subject and our body, and if we go back to our blog's front page, you can see all of our entries. That's the homework. Let's go ahead and I'll walk you through the templates--all the different HTML I used there, and we'll be done. Front.html--this is the template for the front of the blog. I'm using some more advanced template features. Again, you don't have to do this. We didn't teach it, but this is how I did it. There's something to learn from here, I think. This extends base.html. The template language we're using, Jinja 2, allows you to have this kind of template inheritance, so you don't have to write the same HTML over and over again. I'll show you base.html. This has the main structure of our document. It's got our doc type and our head with our title, and it includes the CSS I've been using to make the blog look a little prettier. Then it's got the main body, which basically draws a title. This is the main text at the top of the page that I've been clicking on. This just links to the front. Then we've got this div for our content. Inside here we can create a block, and this is what the other templates override. All of our templates that extend from base html can use this main wrapper html for the actual document. Front says replace that content and base html with this content. This is some basic Python code inside this template, which says, for p in posts, call p.render--remember we say that function in blog. Every post has a render function, which renders post html with that blog entry. That gets put here. Jinja has a syntax called "safe." Normally, all of the HTML is automatically escaped. If I didn't have this safe here, Jinja 2 would automatically--because of the way I configured it when we set it up--would escape everything. If I were to get rid of this piece of code here, and we were to reload our blog, it would look something like this--a bunch of escaped HTML blog entries. So in the escape syntax, what we're telling Jinja is we know what this HTML is. It's safe. You can just include it verbatim. That makes our blog entry look like actual rendered HTML and not this. If we were to look at the source for this page, you can see what we typed in has all been escaped using HTML escaping, which is not exactly what we intended. We can tell Jinja this is safe. You can include it verbatim, and it will render fine. That's the front HTML. This is basically the front page. For a particular blog entry, we use post.html. This is the HTML for a particular post. I have a class that wraps the whole thing called post. I have a div, rather, whose class is post wrapping the whole thing. I have another div, which is just the heading. This includes the subject of the post in a div. That also includes the date the post was written in another div. Using the strftime is a handy function when you have a data-time object in Python, and you want to print a human readable version of it, you can use strftime. This is a format string--if you Google for "Python strftime" you can see all the different types of format strings you can use for printing dates. That's really handy. This won't be the last time you use strftime in this class. I suggest you give that a peek. Then we have the actual content. The content is included--I remember I called it render_text on the object. I did that so I could replace the new lines with the breaks without actually modifying the object. This is included with pipe safe. That means we can enter HTML in our blog entries, but we want to be able to include HTML in our blog, so you can type in lists and have links and images--all of your fancy HTML formatting. Generally you want to escape content when we don't trust it. In the case of a blog users would have to register, or maybe it's only your blog and you're the only one who can submit, you generally trust the content. What a lot of sites do is they only trust certain types of HTML. They may say list and links are okay, but background colors and marques and that stuff is not okay. I didn't want to get into that sort of parsing and stuff, so I just made it all safe, which allows you guys to enter in all sorts of junk on my blog, which is fine. Our next template is for a permalink. This was the page that showed just one blog entry. It inherits some base HTML, and it redefines the content block to basically render one blog. Post.render--that calls that function we defined in Python and include it on escaped. Those are the main templates I used. We'll give you all this code so you can reference it in future stuff. Then here is the CSS I used to actually style the whole page. We don't cover much CSS in this class, but you can learn from what I've done here. On the body tag, I basically set the font to be Helvetica, font size 14. I set the width to be 800, this margin--basically, this is the trick for centering content-- added a little padding, make the color slightly off black--333 instead of 000. We define when we use h2 we set it at font size 24, bold, some space on the bottom. That's what margin bottom does. Errors are red. Labels--we can make it a block element with font size 20. This says if a label follows another label, put some space in between them--20 pixels. This input type text formats our text box. We make it width 500 pixels, font size 20, a little padding inside the box that just kind of spaces things out a little bit. I used a monospace font. It makes it look like you're writing on typewriter or something. Text area--again, I make it 500 pixels so it matches the input. I make it 400 pixels tall so we get a nice actual box, 17 pixel font. I make our submit button a little bigger. This is the main title of the page where it says CS253. That's size 40 text. It's bold. It's centered. It's got some space below it. And it's actually a link to the front of the blog, but I don't want an underline there, which is what HTML does by default when you have links, so we can say text decoration None, which turns off that underline. This says 15 pixels between two blog posts. Post heading--now, this is the actual title of a particular blog post. We've got that name. This adds that border, that line on the bottom. Position relative is used for something else, which I'll show you in a sec. Title--bold, 24 pixels tall. The date the blog was submitted--this is position absolute. What position absolute lets you say is we want to position this 0 pixels from the right edge of our parent, if that parent is position relative, which is why we have position relative here, and 0 pixels from the bottom of that parent. In this case we're making it color 999, which is kind of grey. If we were to go back into our browser, this whole thing is the blog heading. This is the title, and this is that created data, which is position absolute, which is position 0 pixels from the right and 0 pixels from the bottom. That's how we position that over here nicely on the right. It's color 999, which is grey. That's just some basic CSS. I think there's just a little bit more. The post content has 5 pixels on the top. That separates it from its heading a little bit. You can see we've got that big text here. When I mouse over it you can see my curser turns into a little hand, which means it's a link, but I got rid of that underline. Then you can see all the fonts we used here and the border bottom we added here to make this line, and then the text in each of these posts. You know, you don't have to understand that. You don't need to do it in any of our homeworks, because we can't grade easily the appearance of your things, but I like to do it so it looks slightly nicer. So I figured I would show you how I did that. That is it for homework 3. That was actually quite a bit. If you made it this far, good job. You are writing some serious web applications now. All right. Unit 4 homework time. We are going to be adding user accounts, and there is going to be three parts to this.. The first part is going to be registration with a valid cookie. Let's take a look at my working solution online and show you what I'm expecting. So here we are in my form. It's at \signup. This is the same form we used in unit 2, and it has the same validation. If I type in some junk or forget to validate my passwords, I get an error message. If I were to type in valid data and hit submit, it takes me to a welcome page. Notice this time there is no user in the welcome. That's because it set a cookie. What that did is registered my user, I did the whole password hashing salting thing. It's hard for us to test that, but what we can test is that after we log in, the page we get redirected to should have the user name in it, and we should have a cookie. I've installed this edit this cookie extension in Chrome, which is really handy for this sort of thing, to let me view a cookie, and we can see we have a cookie named userID. It's value is 2001 pipe and then a hash, which should look familiar from this lesson. If I were to change this to a different user ID and then reload this welcome page, it would redirect me to the signup page, because the cookie is no longer valid. That is the first part of this homework--implement this signup page, have a form that still checks for errors like unit 2, and then if the user registers it redirects you to the welcome page. If the user already exists, it should give an error that says that user already exists. Okay, when you're done with that, submit the URL with that behavior here, and we will check it. Okay. Good luck. We'll included, of course, more detailed description in the text description of this homework. All of those form values and the form names and stuff that we'll be testing will be clear. Okay. Good luck. The next question on this homework is to implement login. Let me give you a demo of what this is going to look like. I am at this URL\login. After doing the register portion of this homework, the first part, this is going to be very simple. Basically, it's a similar form to the registration except it only has a username and password. If you type in a valid username and password and hit submit, it redirects you to the welcome page. It sets the cookie, and it takes you to the welcome page. If you were to type in an invalid password or a username that doesn't exist, you get an error message that says invalid login. Only when you type in a valid username and password do you get redirected to the welcome page. Mm-kay? Cool. This welcome page has the same cookie that I had before. That gets set on a successful login. When you have this working, submit the URL here. Good luck with this one. Okay. Our final homework question for this unit is to implement logout. Logout is very simple. Let me give you a demo of this. We are at our welcome page here, and if I reload this welcome page, it continues to say "Welcome, spez!" because my cookie is linked to the spez user. I want you to implement a URL "logout," and when we visit it, it redirects you to the signup page and it clears the any cookies. You can see the user ID cookie here is empty, which is basically how you delete a cookie. You set that cookie to empty. If I were to go back to that welcome page, it would redirect me back to signup, because I don't have a valid cookie. Logout--all you do is delete the cookie and redirect to signup. When you have that working, enter the URL here. Once you've gotten this working, you are a master of user accounts, and you should be proud of yourself. Good luck. Okay, this is the unit 4 homework solution. To recap, the first thing I wanted to do is make a registration page. This should look basically like the homework 2, where we made the form. So if you type in some junk, we get the same error messages, and if you type in a valid username and password, and you submit, you get redirected to this welcome page, that says, welcome and then has the username in it, and the username this time is not included as a get parameter. It's actually included in a cookie, and I'm using this little cookie extension in Chrome so I can see the cookies, and in this case, you can see it included. This is supposed to be the user id 5. That is the hash of that as we discuss that technique in the lesson. So let's look at the code for the first problem. Once you solve this first registration part of the homework, the other 2 parts of the problem are very easy because they just kind of build on the same code, so we're going to be going through a lot of code here for this first part. The first thing I have is I have a secret, which is just this random string that we're going to use as our hash secret for cookies. Normally I wouldn't store this in the same file as my code, I'd probably store it in some other module that's only on the production machines or something like that, but for our purposes, it's fine just to stick it in here. Again, a lot of this code you've seen before, template directory stuff. Here are 2 functions. You basically had quiz problems in the lesson for generating these functions for making a secure val, which takes a val and just returns that value--a pipe, and then the hmac of that val. We did this in the lesson, so you should be familiar with this. and then the function for taking one of those secure vals and making sure it's valid. We split on the pipe. If a call makes a secure val on the value we pulled out of the string, if it matches that string itself, it's valid. You've seen this functions. We did them in quizzes and we're going to be using them in here. Here is this bloghandler. This is the class I've been using, kind of a parent class for all of my handlers. I added some more functions. Write, render, stern, render--those are old. I've added a function called setsecurecookie, which basically sets a cookie whose name is name and whose value is val. All it does is it basically gets the secure, calls makesecureval on this val, and then it stores that in a cookie. and we store a cookie by just using 'Set-Cookie' header, and say name = val. Path = /. We could also include an expires time, but I didn't here so by default these cookies are going to expire when we close the browser, which is fine for our purposes. Then we have another function for reading a secure cookie. You give it a name, and if finds that cookie in the request. If that cookie exists, and that cookie passes checksecureval, we return cookie_val, In Python you can use this kind of shortcut notation for saying, it's the equivalent of writing, if cookieval and checksecureval, return cookieval. If 1 of these is false, we just return false or none or whatever. We've got this function login. This will be used for the second part of the homework for actually doing logins, and this just sets the cookie, and we've got a function logout, which I believe is the third homework question. We'll come back to these. I added this function initialize. You don't strictly need this. Google App Engine is a function that gets called before every request, and so what I have it do is check for the user cookie, which was called user_id. If it exists, store in self.user the actual user object, which we'll get to this in a second. Now you don't have to do this, but I kind of did the more complicated route where you have to login to enter things into the blog, and it keeps track of all the blog pages where the user is and that sort of thing, so if you're going to have that structure where once you're logged in every page is a little bit different, it's handy to have some sort of function like this that gets run on every request and just checks to see if the user is logged in or not. That's what this initialize function does, and this function is called by the App Engine framework. So we still have some of our blog stuff. I've been doing all the homeworks on the same file, so you'll see some of the other homeworks in here. We have this function make_salt. This was a quiz function, just to make a string of 5 letters. So that's what this does. This makes our salt. This function was also a quiz function, I believe, for making a password hash. It takes a username and a password and an optional parameter for salt, and then returns the salt, the hash version of the name, password, and salt. This is what we store in the database. Then we have this other function, also a quiz question from the lecture of how to verify a password. So it takes a name and a password and the value in the database, and it makes sure the hash from the database matches the new hash created based on what the user entered in. Again, quiz question. You've seen that before. Users_key--this creates the ancestor element in the database to store all of our users. Again, you don't have to do this. I like to have things a little bit organized, so again, I gave it a parameter and thinking maybe I'll have user groups in the future. I don't right now. That's just how I did it. Okay, so now we get to some interesting code. This is our user objects that we'll be storing in the database. so it inherits from db_model that's what makes it a data store object. and it has three parameters: it has a name, which is a string property, required, a password hash, which is a string property, also required, and an e-mail, which is a string property, but not required. Now, remember, we don't actually store passwords in the database, we just store hash of the password. We can't grade that, we can't tell how you're storing stuff in the database, well, we could, but you would have to write some other handlers or something... But this is how I'm doing it. And then I added a couple of functions on this class. They are kind of convenience functions. The syntax here, @classmethod this is called a decorator. I'm not going to get into exactly what decorators are, but what classmethod does, is it says: you can call this method, on this object. It doesn't have to be instance of this object. So normally you would say the first parameter on a method on a class itself, that's referring to yourself, that instance. In this case I call it "cls" for "class", which means it's referring to this class user, not an actual instance of a user, these are objects So we can just say, user.byid, give it an ID, and then we'll call this getbyid function to load the user on to the database. Getbyid is built into the datastore. If you recall from a previous homework, I had this kind of "make key" thing, and just called the "get" function, but that was before I learned about this getbyid function, which is a more convenient way of doing what we are doing now. I have another function called by_name, which looks up a user by its name. I'm using the datastore procedural code again for doing the database look up, instead of the GQL, because I prefer typing this, I think it's a little bit easier to read, and all you do is, you say, filter(name =', and then you can give it another parameter, so this basically says, "select * from user, where name = name." We call "get" on that, which returns the first instance, It returns that. Another function I've added is this method called register, which takes a name, a password, and and e-mail, and creates a new user object. So the first thing it does is create a password hash for that name and password, and then it creates a user object. The parent is that user key, not required for you guys, name = name, pwhash = pwhash email = email. So that creates the user. It doesn't actually store it in the database yet. It just creates the object. And here's another one, called "login". We'll come back to this one, but it's fairly self-explanatory, for the future homework. So now, let's go down to the handlers. You can see I've added three handlers for each of these three homework problems. The first one we'll talk about is "signup", so /signup goes to the register handler, let's take a look at that. Now, the register handler here inherits from the class "Signup". "Signup" is actually up here, and it's identical to what I had or, nearly identical to what I had for the homework 2. Since I'm working in the same file I didn't want to rewrite this whole class again. We are still rendering signup form, like we were before. We are still, I'm not going to go through this in great detail, but we still get all the values out of the request, we still check to see if they are all valid, and if there is an error, we re-render the form, with the error messages and the values, just like we did before, and if there's not an error, I call self.done, which in this class "Signup", doesn't do anything, it just raises an error. And then I have two other classes that inherit from "Signup" and overwrite this function "done". The first one is the Unit 2 "Signup" page, and all that one does is, it redirects this /unit2welcome with the "get" parameter. That's how we did the Unit 2 homework. The "register" one overwrites "done" to have different behavior. First, what it does, there's an extra error that can occur in this one, in that the user can already exist, so what I do is I look up to see, "does that username already exist?" And if it does, send an error message and I re-render that form. error_username = msg, so I probably could have done this a little bit more cleanly, but this is kind of just tax on an extra message, so this doesn't appear to preserve the parameters if you enter in a different username. It's a little bit less than ideal, I probably could have put some more things in there, but that's how we have it. Otherwise, if that error doesn't exist we register the user, which creates a user object, and we actually store it in the database here. And then, what I do is, I call my "Login" function, all the "Login" function does is set the cookies. So, for the first homework we may not have a "Login" function, you may actually just set the cookie here, and then we redirect it to the welcome page. But then I generalized it, when I did the "Login" version, and just made this work, this "login" function that multiple handlers can use, because we will have both the Sign up page for registering and signing in, and then we'll have just the "Login page", not for creating a new user, but signing into an old one, and they can both use this "Login" function, and we'll go over that in a second. We redirect to /unit3welcome, which is down here, this handler, Unit3Welcome, and all this does is, it checks to see if self.user, and remember self.user gets set up in that initialize function, that's where it reads the cookie and makes sure that the cookie is valid and sets the user on the handler, and since this Unit3Welcome inherits from BlogHandler, it has access to that user, we render our Welcome HTML, you can probably guess what's in there. With username = self.user.name, Otherwise, we redirect to the Signup. Let's see that working one more time, again, now that you've seen the code. Okay, so if we enter a username and a password, we should actually get an error message that this username already exists. And we do. And it cleared the form, because I was a little bit lazy on this one, and didn't preserve all those parameters. Although I easily could have, so, let's type a new username, and submit the form, and it worked! And if I were to, on this page, modify this cookie, change it to user id 5, which is what we had before, and I were to reload this page, we get redirected to the signup page, because the value in that cookie doesn't match the hash in that cookie, therefore is invalid, and we get bounced to the signup page. So that is the first question in this homework. The next homework problem was "Log in" which generated a form like this and it had a couple of properties. If you type in a name that doesn't exist and an invalid password and click "Submit," you get an error message. But if you type in a name that does exist and a valid password, you get redirected to that same Welcome page. So let's talk about the code that makes this work. It's actually going to be 90% of the code we just saw for user registration, so it should be pretty quick. We have slash Login which goes to the Login Handler. Let's look at that. Okay. So if you go to Get, it does Login from that HTML. I'm sure you can imagine what that looks like. It's just the basic form with the one error field and fields for user name and password. Nothing magical there. Out of the request we get the user name and the password. Then what we do is we call this function "Login" on the user objects. We'll go look at that in a sec. Basically it returns the user, if this is a valid user name and password combination, and "none" if it's not. So if you recall the login function, which we'll look at also in a sec, which sets the cookie just like it does for "Register." You can actually see the "Register" code up here. We log in the user and we redirect to the "Welcome page." If it's not, if there is no "U," we rerun to the form with an error message.that says "Invalid Login." Let's look at this Login function here on the User Object, and then the Login function here on the Log Handler. And I realize I probably could have named those a little better so they're not quite so confusing. But these are actually different functions even though they have the same name. First is the User Object. So here's the User Object and it has a class method called Login. So we can say "User dot Login." And what this does is it says Class By Name which just refers to itself. It refers to the User Class so it's actually going to call this Function. The reason we say Class by Name here and not User by Name is so that we can overwrite this function later. You can actually see I haven't been consistent about that. This should really be Class. All of these should be CLS and not Upper Case User. Since I haven't inherited this Class it's not a big deal, but that's a bug waiting to happen. So now you get to see how bugs happen in the real world. We call it By Name, which calls this function By Name which looks for a user of that name. If it exists and it's a valid password, which is the Quiz Function we wrote before, If the name and password entered in match the password hash, from the object with that name in the database, we return the user. So that's that first login function which basically checks to see, is this name and password combination valid? If it is, we go up here to our Handler and we call this Login function. Remember, down before we called Self that login? Well, this is what it refers to--this function here. And all this function does is it sets a secure cookie, user ID, and it equals the user's ID. And this is how you get the user's ID and datastore. Remember on our next request to the Welcome page, we're going to call Initialize, as every request calls Initialize. What this does is read a secure cookie called user ID and, if that is valid, it sets Self dot User to dot User. That's how Login works. Here we are on that Welcome page. If I reload this page, we keep seeing the same thing. The last thing I asked you to do was implement "Log out" So this URL, when you go to it, redirects you to the "Sign up" page. If I were to go back to the "Welcome page" and reload this, it redirects us to the "Sign up" page because our cookie has been deleted. The way you log somebody out is you delete that cookie. I didn't say that in the lecture. Hopefully you managed to figure that out. Let's go ahead and see that in action again. Let's log in. You can see we have a cookie. The user ID cookie equals 5. That's the user ID for spez in this machine. If I go to logout, and we go look at our cookie again, we can see that the user ID is the user ID cookie. It's just blank. There is the user ID cookie. There's nothing in it. That's how "Logout" works. Let's look at the code for this. The first thing we have is our "Logout" handler. So I map slash logout to the logout handler. When we look at the "logout handler" you can see it calls "self dot logout" which is the Find up on Blog Handler and it redirects the Signup. Let's look at this Logout function. Here it is. Remember we are in Class Blog Handler where I've put all this helpful generic stuff that other Handlers may use. All Logoff does is it sets the cookie User ID to nothing. Instead of setting Cookie = Value, we just set Cookie = Nothing and we keep the same path so we're setting and overwriting the same cookie. If we didn't have these path variables here, or this path parameter here on the cookie, we would actually overwrite the--well, we might set the cookie on slash login or slash signup to default where you're on, and then when you go to the Welcome page you wouldn't be logged in. That would cause problems so we make sure we set the cookie on path slash and we delete the cookie off of path slash. And that's how Logout works. If you got all that you did a very good job. One of the more complicated things you do when you're writing web apps is all this kind of cookie and hashing and all that manipulation, but you can also start doing some really clever things. While a lot of frameworks do a lot of this for you, I think it's really important to understand how it works because you'll often find yourself in a situation where you need to hide some data in a cookie or maybe have a special type of hash that represents some piece of information and that sort of thing. We do that on Reddit all the time for anti-cheating stuff. Knowing how this all fits together I think is really important. That's why I made you do all this. Okay, homework 5 should be pretty straightforward. I'd like your blog to output JSON instead of HTML, or rather in addition to HTML when the URL ends with .json. Let's see how this looks in real life. Here is the blog online and showing the 10 most recent entries. If I were to add .json to this URL and load this URL, I would get a wall of text. You can see in here there is some JSON. It's a list of dictionaries, and each of these dictionaries is one entry. We'll look at the JSON for one entry so it's a little more clear. If we were to go to blog entry 1002, which just is this short little entry, add JSON to this. We do that and it returns just the dictionary. The key is "content" equals "what a great body," "created" equals this date, "last_modified" equals this date, and "subject" equals "what a great title." We'll be looking for content and subject in your response. You should try to also include the dates. Keep in mind that this date is not built into the JSON library in Python. You're going to have to actually encode this yourself. Remember when we talked about that strftime function in one of the previous homeworks? Well, that's a good use of the strftime function to create this little date stream. Remember that JSON data types don't include dates. They just include integers, floats, strings, booleans, and a null. You'll have to figure that out. I'd like you to have .json on both the permalink URL for the blog entry, and on the entire blog itself. Of course, you should also have new post continue to work. If we were to enter a new post in here and submit this, if we were to go to the JSON for this post, we would see the JSON representation. Here is our JSON. One last thing I'd like to point out to you. If I were to open up our little debugger in Chrome here and reload this page, if we were to inspect this request, the response has a content type of application/json_charset=utf-8. It's important to get the content type right here. We're not sending HTML anymore. We're sending JSON. This is the appropriate content type to use when you're sending JSON. Make sure you set this header as well. When you have all that working enter your URL here. For homework 5, what I asked you to do is add .json to the URLs and have the response return JSON. You can see here we've got the JSON response for the first entry-- content and created, and it's got our date and last_modified and subject. It's got the text in there. If we were to go to a permalink for a particular blog entry and add JSON to that, we'd see JSON for that one entry. Let's take a look at the code that makes all this work. Here we are in our code. We're in the URL handler portion of things. I've changed our two URL handlers for blog to look for .json at the end of the URL. There are a couple ways of doing this, of checking to see. You could have made special handlers for JSON urls. That's fine. I chose to do it this way, and this is just some regular expression syntax to-- basically the parentheses say look for this group of things, but this question mark colon says, and don't send it as a parameter into the handler like this set of parentheses does--remember--for the permalinks. This just says match /blog/ a number and optionally it can end in .json. We did that also on this one. This says match /blog/--that last slash is optional. That's what that question mark does. Then optionally the string .json. Actually, what this matches is any character JSON. These regular expressions should actually have slashes in them. Probably nobody will notice, and it's a bug that doesn't really hurt anybody. Anyway--there it is. Another bug in the wild. Anyway, let's look at the changes to the handlers that I needed to make. So remember we have blog handler. This is our class that is kind of the super class for all of our handlers that has all this handy stuff in it. I changed this initialized function. It's still looking up the users as before from the previous homework. Now I check to see if the request URL ends with .json. We're going to set on itself the format is JSON. Otherwise the format is going to be HTML. There are certainly better ways to do this if you had a much more complicated site where every page can be in HTML and JSON, but for our purposes for this homework, this'll work just fine. Then we go into our blog handlers where we're actually outputting the blog, and we need to just check out what the format should be. Another thing I added is on the post objects, we've got our render function, which returns the post in HTML. This is what we had before, using the templates. We don't need templates for JSON. What I do here is instead I create a dictionary representation of the post itself. This is a format string--this variable here, %c--which basically says print the date nicely and whatever locale you're in. We use that down here for the created and last_modified fields in this dictionary. Created equals self.created.strftime and then that time format string. We could put in lots of different format strings to make this date printout however you like. I just used %c. That's quick. Then I'll, of course, include the subject and the content in this dictionary. Why do we convert it to a dictionary? Because the JSON library in Python expects datatypes that it knows how to convert into JSON, which are lists, dictionaries, integers, floats, strings--that sort of thing. Actually the JSON library in Python doesn't know what a post object is. It doesn't know how to convert that to JSON. We create a dictionary representation of our object first, and then we can pass that into JSON later. If we come down here to the front page of our blog handler where we look up all the posts, I have a function now called get_posts(), which does some fancy things to prevent you guys from filling by blog with spam. I'm trying to avoid showing you that code. This used to be the sequel query. Here we check to see if the format is HTML, we call the front page template. This is old code. Otherwise, we assume it's JSON. This could probably be else if to be safe. We're going to call this render_json() function, which is defined above, and I'll show you that in a moment. Basically what it does is it takes a list of each post p, for p in "post," as a dictionary, calling this as_dict() function on each post. Then we'll render JSON. Here we are in the permalink handler for a particular blog post. We call that PostPage. This takes a parameter called "post_id." That comes in from the URL. We saw this in the previous homework. We just look up the post. If the post isn't there, we 404. If its format is basically else--if it's format HTML--use the HTML template. Otherwise, call self.render_json(), that post as a dictionary. Simple enough. The only function we haven't talked about yet is render_json(), and let's go find that. That's up above. Here we are in our blog handler again. One function I forgot to point out I added. We've got our write and our render_str and our render function, which is for rendering a template or for sending a template over the wire. I also added a render_json(), and what this does is this takes a d-- I meant to kind of refer to dictionary, but actually in this case sometimes it's a dictionary and sometimes it's a list. It could be anything that is valid JSON. We use the JSON library in Python. We just imported that with import JSON. We get the JSON representation of this Python data structure by calling dumps. You did this in some of the quiz problems. Then we set the content type to application/json, and then we render our JSON text. And that's it. That's the homework. Not actually a whole lot of code, but a lot of little things you needed to figure out. I kind of realized after doing the solutions for homework 3 and 4 that maybe you needed a more straightforward one. There you go--now your blog supports HTML and other people can download JSON versions of your blog if they want to write little tools on top of it, which would be pretty cool. Good job, and we'll see you next week. The first thing I'd like you to do in Homework 6 is add some caching to your blog. Specifically, I'd like you to cache the front page and display on the front page somewhere, how long ago you ran that query that generated the front page. Let me give you a little demo on my site of what this looks like. So here we are at udacity-cs253.com/blog. If I reload this page--let's go down to the bottom-- you will see that this query, this page was generated 159 seconds ago. If I were to reload this page again, you could see that it's incrementing every time I reload the page. Okay. So obviously, I'm storing this in the cache somewhere and that's what I would like you to do. When you have this working, submit the URL to your blog here. The next thing I'd like you to do is add the same caching to the permalink pages. Specifically the same way we did on the front page, display the age of the query that generated that page on the page somewhere. I'll give you a demo on how this works on my site. If we go to one of these posts, we can see that this was recorded 0 seconds ago. As I reload this page, this timer increments. That's how it should work and if I'd already click on a--I'd probably go to a different post we see that this one is 0 seconds ago. And as I reload this page, this one increments as well. Now, in order for us to test this, we're probably going to submit some new posts. I'll make sure "/newpost" still works. And my net made it so--so you have to log in as spez to submit your posts, so you guys would quit submitting spam to my site, but the rest of you should make this accessible. If we submit a new post like so, this redirects to the permalink page where we see we are 0 seconds old. And when we go to the front page, we see our post here. If we scroll down, we can see how old our caches, which is 55 seconds, which is about how much time it took me to go out and ask Shawn to stop submitting spam to my blog while I'm recording. If we go back to this permalink, we can see that it updates accordingly. When you've got that working, submit a URL to your blog here. The final thing I'd like to ask you to do in this homework is create a URL that flushes your cache and that should behave something like this. Okay! So I'm looking at the blog and if you scroll down to the bottom, you can see there's some age of the query. And if I already go to /flush and we can see when we reload this front page, it is 0 seconds old. Now I made my /flush delete the cache and then redirect to the blog page I think that's probably the simplest way to do it, although we won't be checking the redirect itself. We'll just run it and then reload your pages and see what the query time is. And If I've to go to any of these permanent links that I just clicked on, we can see that they all reset to 0 seconds ago as well. So, when you've got that working, submit the URL to the flush URL here. And thanks and good luck! Okay, so Homework 6 solution: I asked you to do a couple things. I asked you to add to the bottom of the blog page how long ago we ran the query-- and if we reload this page we can see this time incrementing-- and I also asked you to do this on permalink pages. So if I were to look on a particular permalink, I can see the age of its query, and I can also tell when I create a new post-- create this new post--and when I submit it I get redirected to a permalink page whose query time increments, and when I go back to the front of the blog, I see my post on top with a nice, new low query time and finally I asked you to implement a URL that clears the cache. In mine, I called it flush, which just redirects right back to blog but it resets the cache, which causes the query to run again. So that's what I asked you to do, and now let's take a look at the code. Okay. So the couple of things I needed to do: I needed to use timedelta and datetime to help compute the age of my posts, and I also needed to import memcache just to cache things. Now I added a bunch of functions that are kind of handy. I added this one function called age_set which basically is a wraparound memcache set, but instead of setting just the value it looks up the current time using datetime.utcnow, and it stores that time along with the value in a tuple. And then I made another function called age_get. What this does is-- It's just like a memcache get, but it returns both the value and the age of the item as a tuple. So the first thing we do is we run the memcache.get on just the key. If it exists, the value and the time we saved it are in R. So we break those apart and then we compute the actual age in seconds, which is we take the current time minus the time we saved it and then we can call total_seconds on that, which is a function that's included on timedelta. Otherwise, if there's nothing in the cache, we just set val and age to be none and zero respectively, and then we return them. These are just handy functions, and I use them a couple places. Now I've got a function that I run every time a new post gets submitted, and this stores the post in the database, and it takes an IP parameter which is unused. I used to use this IP parameter on my previous antispamming version so that you guys could still submit to the blog and see it working, but it wouldn't store it in the database. I was actually just storing it in memcached, and I got rid of that. Now you just have to be logged in as me to submit to the blog. It runs this get_posts function, which is defined here, and this basically runs the database query with update = True. You saw me do this in the lecture. This is my technique for overwriting the cache with the new value. Now, there's still erase conditions. Remember we spent a lot of time talking about gets and casts? I didn't use those here. And then it returns the ID. Get_posts--this is the function that runs the database query for me. You saw me write something like this for ASCII Chan, and here it is in the blog. This is my query, and I'm using the procedural language again to look up all the posts. This is still an extra variable that's in there. I don't remember why. Code grows organically like that sometimes. Here's the memcache key I'm using. I'm just calling the string blogs. I usually start a memcache key I'm using in a variable, especially when I'm referencing it multiple times in case I want to change it or just avoid typos and that sort of thing. It's a good habit to get into. So first I call age_get, which does the memcache lookup for that key and gives me posts and the age, and if update is true or posts is none-- so basically update is true or the posts aren't in the cache-- run the query, and then set mc_key to the value posts and then return the age. I've added another function called age_str, which basically takes an age-- which in this point is a floating point of seconds-- and it returns the string replaced-- or queried--0 seconds ago, 1 second ago, that sort of thing. So it converts it to an integer. If the value is 1, we replace "seconds" with "second" so it's grammatically correct, and then we return that string. And I use this function in my templates to print that string at the bottom of my pages. And on my blog's front page, I call get_posts-- remember, this returns the posts and the age-- and I pass in the age to my template. I convert age and I run the age_str function on it so I can include it in my template-- and then on a permalink page we do something similar. We cache each request. So this is the key for our particular post. It's the string post with post_id. I usually prepend-- When I'm looking up by ID, I usually prepend a string to the memcache key so that if I want to change it later I can just change this string and everything expires. We check to see if that post is already in the cache, and if it is we have the age. If it's not, we have to look it up from the database, and that's how we do it. And then we set it to the cache, and we set the age to 0, and then I return the permalink html, My template now takes an age parameter, which is that age string. So that's all the changes there. I'll show you the templates really quick. Front that html. It just has a new class at the bottom called age, and that includes that age string that was passed in, and permalink html has the same thing at the bottom-- a class called age with that string that we passed in. And in our CSS file I added one little thing to the bottom, which is this age class, and this says position absolute, which basically says position this anywhere. Zero pixels on the bottom. Zero pixels from the right. Make it gray, and make the font size 12 pixels. So that's how I put it, down in the lower right. Obviously we're not gonna grade for that, but that's just how I did it. And that's the solution to Homework 6! I hope you figured it out on your own. Welcome to our last Office Hours. This is basically just kind of a wrap up and any last questions that we saw that we felt needed to be answered before we ended the course. Right? Yep, yep. Okay. Let's just jump right in. First question was if you were building Reddit or Hipmunk today, would you build it on Google App Engine or would you go ahead and-- That's a really good question, and the short answer is: I'm not sure. I think we could build Reddit or Hipmunk on Google App Engine. Probably definitely Hipmunk, a site that I know is--because it's a travel site-- it's never going to be at the scale that Reddit is, because even the biggest travel sites aren't anywhere near the scale that Reddit is. Yeah, so I would have no problem doing that. Now, Reddit--it's funny, because when I started Reddit we didn't expect it to be a big site. I was actually--my level of knowledge was less than where yours is now. App Engine would have saved us a lot of heartache. Now, for the scale that Reddit is now, I don't know if App Engine would work. Because it's at such a large scale we need to have control over a lot of little pieces, but I think for the first couple of years of Reddit's life absolutely it would've worked just fine. Over Reddit's existence, we've rewritten it probably 5 or 6 times and moved a couple data centers and we moved from our own machines to our first data center to now we're on Amazon Web Services. Each of those was a pretty major architecture change. I imagine we'd consider starting the App Engine and then probably migrate to our own more custom setup down the road. Okay, the next question was about larger applications where you inherently have to deal with more than one table. Earlier in the course you mentioned that doing joins was a very bad idea and could be very expensive. How do you get around that when you inherently are dealing with difficult types of data. That's another interesting question, and the answer isn't super simple. In App Engine you can't do joins, but you can also store complicated objects that have nest structures, so you can have lists, for example, as a property in your App Engine object. You can actually get around a lot of the need for joins by using that sort of thing. But let's say you're just using SQL and you want to scale it across many machines. Joins are really tough, which means having these foreign relationships in your database are really tough. The way it was phrased in the question was basically like do we store data in multiple places to to avoid multiple queries? The answer is sometimes yes. Other times you do multiple queries. What I usually do when I'm writing this sort of thing is I cache the bejesus out of all of my queries. I try to structure all of my queries to have generally the same structure, which is look up something by ID or by a few constraints. For example, if we're loading Reddit's front page, I'll do a query for each of the Reddits to get the top post in each Reddit, and then I'll merge them, and that'll be cached. >From them on, I'll just pull from that cache. Then there's all these extra little properties that link can have per user. Did you like it? Did you up vote it? Did you down vote it? Did you save it? Did you submit it. All those things. I'd probably do another query to a separate table to get all that information for that user and then I would cache that so that in the future most of that stuff is just bouncing off memcached. On the first version of Reddit, we actually did a big join there and it became too slow. The users table of all this information--uploads and downloads and all that stuff-- moved to its own machine, so we couldn't do joins easily anymore. Yeah, it turned into multiple queries, sometimes storing extra little pieces of information in different places, so it makes your writes more expensive and a little bit more complex, but it makes your reads, while more numerous, simpler and easier to cache. Because if you keep your queries to key value, those queries are very, very fast, and they're also very easy to cache. Just key to value. It mirrors what you're cache is doing. It's actually a complicated question with a complicated answer. What you just need to be thinking is what makes sense in that particular situation. There is certainly a situation where the features is never going to be a big-scale, and you can just put everything in one database and use joins and do it that way if you want. You just need to kind of have in mind how big this is going to be and how many of these decisions do I need to make right now versus just getting it working. I hope that helps. There isn't an easy answer to that because every problem is a little bit different. Do what works best. Do what works for now. If you have to scale it later, good luck. Congratulations. Another question we've had, and we've had it a lot, is more information about the whole ancestor thing, how the ancestor part of a query works, what it means, and how to work with it. Okay, yes, I have seen that question a lot and I'll do my best to answer it. It's Google App Engine specific--the notion of ancestor paths and ancestor queries-- but it has a couple of neat things. The question in the forums was about ASCII Chan in particular. We had a line that looks like this--db.key.from_path. Then from_path can take a couple of parameters. It can actually take, I think, as many as you want, but in this particular example, I just used two. It said like ASCII Chane--I'll just abbreviate it "AC"-- and then I think I had the string "arts." So what this does is this actually creates a data store key for an object that doesn't exist. What I basically said is all of my arts are going to have this parent, and when I created arts--I think when I said something like a = Art, and then you'd have all those properties-- I guess I should spell them out here. We have title. What did I call it? Actually like the content of the art. There are probably another parameter called "parent. Parents equals whatever this key. We'll call that k. I think it was a function call. What this does is this just store the art in a database, and it basically says its parent is this key. The parent is supposed to be another object, but in this case the object hasn't actually been created. It's just kind of reference to this fake object. This is purely for organizational purposes. There are a couple handy things you can do with this. The first is what I was doing in ASCII Chan, which is when you're doing a query, you can say--you have your select statement or you can be doing it procedurally. You know how to run queries at this point. You store this is a string and you run it. Whatever. Select * from Arts, and then one of the constraints on this query is where ancestor equals something. In this case, where ancestor equals this k, this key. What that does is it gives you this property in datastore that the query will be consistent. That means when you've inserted with this parent and then you immediately do a select *, if I didn't have this where ancestor equals k, there's a chance I might not actually get the element I just inserted, because of the way datastore works with possibly being stored over multiple machines and sharded and all of that. What Google is doing there isn't entirely transparent to us, but one of the things they say in their docs is that if you include this constraint, ancestor equals something and that happens to be an ancestor of the object you're looking for, the query will be consistent. That's all I was doing there. If you look at the datastore docs, if you go to that "hello, world" example in the datastore docs, it'll actually explain that a little bit, and that's what I was basing this on. Now, this came up again in the final for doing the wiki. One of the ways that I decided to do the history is I made every page, every path--basically URL path, like every wiki page in my program-- basically be its own path here. I would basically just say from path, I think I called it wiki, and then I would actually have the URL. Then each version of the page was another object with that parent. So when I did a wiki page--if you're just viewing the page, I would just say, okay, get me all of the children of this parent, and I'll take the most recent one to actually show the page, and then when you click on the history view, I just say, give me all the children of this parent. That's how I did the version history thing, and that actually made it really easy to do, using datastore. This is a concept that only exists in datastore, though. This whole parent ancestor query is where you specify the ancestor thing. So it's actually as new to me as it is to you. But it helps you work around a few constraints that datastore has. I hope that helps. There is plenty of information in the Google datastore docs. That's what I'm basing most of what I'm telling you on, anyway, so I would suggest you check that out. Okay, so we also have a question about AJAX, what exactly is it, and how important is it to know AJAX and use AJAX? Sure. What AJAX is is basically a request you make from the browser in JavaScript . It's an HTTP request, but basically it happens within the page. You can use this for loading just part of a page without reloading, basically without changing the URL. You can have extra little snippets. For example, the voting on Reddit--when you click one of those up arrows and the color just changes, we make an AJAX request to the server that says such-and-such just voted on this link, and then we just update it in the client using JavaScript. It is really handy. It's really common across just about all website these days. But it's not required. Actually, I found that once you start thinking in AJAX, it's really hard to design things kind of properly, it's hard to decide when should I actually have a new page and when shouldn't i. I hope I did you a favor in terms of form validation and that sort of thing, so you can see how you do it the old fashioned way, before you reach the AJAX. AJAX isn't always the right tool. But as I just kind of alluded tool, form validation--when you type in all those things-- just hitting submit and then getting your errors without reloading the whole page is a really common use of Ajax. But you still need to validate things when you submit the form for real, so you're going to have to do everything I just showed you anyway. As for how to learn that, just Google for it. It's on every website. It's extremely popular. Knowing what you know now in terms of requests and Git and posts in HTTP and all that it should be a pretty easy concept for you to digest. There we go. We had another question that was on version control and what it is and which ones you should use, because there are quite a few out there. Okay, sure. This is purely subjective answer, but that's why you're here, I guess, right? I use get. I would recommended everybody use Git. It's really, really nice. I used CVS back in the day and then Subversion replaced that. Then Mecurio replaced that and now I use Git and that's great. Basically the whole notion is you have the source directory and you're making changes to files and you can log what those changes are, what they were for, you can go back in history, you can merge changes together, you can be working with multiple people and merge your changes together. So it's a great way to share code between multiple computers. It's a great way to keep track of your development. I do it. For example, in Udacity I've got a Git project for all the files I'm using for you guys, for my blog. Occasionally I have these different branches for different homework, so I can be recording unit 6 and then working on homework 3. I can switch between those two states of the code really easily, and then I can check out the homework 3 branch and tar it up and put it online for you guys. Then I can go back into the future to homework 6, that sort of thing. It's really handy, and it's very fast. It's really good. It was written by a Linus Torvalds who also wrote Linux. He's a pretty competent guy. Probably. I would suggest Git. You can use Git Hub. Git Hub is like a third-party cipher storing a code if you want to store it in a remote location. We use Git Hub for Hipmunk, for example, and Reddit, incidentally. There you go. Short answer is Git. If somebody tells you different, raise an eyebrow. Great. Our last question was about cookies. This person had an interesting point about whether or not storing the session info in the database was actually better or not. In the general case, the answer is no. If you're storing sessions in the database, that probably means you're hitting the database on every page request. Because sessions kind of by definition only last the session. If it's not permanent data, if it's just are you logged in, obviously you have to store are you logged in in a a cookie, because that's how you are logged in. Things like user preferences--my feeling is if the user is anonymous and you allow anonymous users to have preferences and a little bit of state, trying to store it in the cookie first. Because you don't want anonymous users to hit your database. Say your website gets popular and they write about it in the New York times or something, and you get thousands and thousands of users before you were prepared. If all of a sudden you've got a thousand people--I shouldn't say a thousand-- thousands and thousands of people writing temporary stuff into your databast, that's going to hurt. Now, maybe registered users, of course, you store them in the database, but I still try to store as much temporary stuff in cookies as possible, because that's the key to is stateless, getting the database out of the request, hiding your database reads behind a cache, hiding your database writes behind a queue, which is something we really only talked about in unit 7. That's the key to scaling, storing temporary data in cookies, which are designed for that purpose, is a very important part of that. Okay, I think that's about it. Yes, I know we said good bye a couple of times. Now this one is for real. First, Shawn, I'd like to thank you. This course wouldn't have happened without you. Thank you, and thank you. You did an excellent job. I know you kept apologizing that this is your first time teaching, but I think all of our students will agree you did a great job doing it. Thank you. It's been a lot of fun and a really cool experience. I'm still hanging out in the IRC. There's still a group of people who do that. Come join us if you want to talk about web apps or whatever. Shawn I think is TAing a bunch of stuff. The forums for 253 will still be around for ever, basically. There are a lot of great students, your co-students, in the forums still helping out. and a lot of people have posted a lot of great projects that they've done in addition or just a completely different projects after what they learned in this course. So congratulations to you guys. Good luck out there and drop me a note, drop Shawn a note if you have any trouble or want to share what you're working on. That'd be really cool. Thanks, Shawn. Thank you guys. We'll see you around. Yeah. See ya.