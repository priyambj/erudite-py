Hi, I'm Ilya Grigorik, developer advocate, and web performance engineer at Google. Which is to say, I like to make things fast. And I'm Cameron Pittman. I'm a course developer here at Udacity. Pretty new to web development, which means I've made a few pages in the past, but never optimized any of them for speed. Developing a great website requires that you understand your users and what they want to achieve, but also how the browser works, so you can build a fast and great experience. Right. You know, I recently ran my page through PageSpeed Insights. And I, well, my score was pretty low, and I got some suggestions I didn't quite understand. Like, for instance, how do I remove render blocking JavaScript, and what are asynchronous scripts? You know what, those are great questions. And you're definitely not the only one. Both of the optimizations that you've asked about have to do with critical rendering path, which is the sequence of steps the browser goes through to render the page. And I think a lot of us take it for granted that the browser does all the work, but once you understand how the browser constructs dom, the cssom subject model layout and paint, you can reliably build pages that rendered in less than one second. Wow. One second. That is awesome. I would love to have all my pages rendered in less than a second. What do I need to get started? Well, to start how about an hour of your time. We're going to take a ground up view of how the browser constructs the page and once you know that I think you'll be in great shape to answer your own questions about how to optimize your own page. Awesome. Let's do it. Actually, one more thing before we get started. I want you to write down some thoughts about what you want to get out of this course and what you would like to learn. Okay. We're going to have a final project in this course where you're going to have a chance to apply everything that you've learned to a sample web site. By the time you're done, you should be able to take that web site to a Page Speed score of 90 or higher. We'll have the project up on GitHub and you can find the instructions for how to get that setup in the instructor notes. Also, when you're working on a portfolio, don't just leave my information in there. Customize it to show off your own projects. You can find instructions for how to customize it also within the Instructor notes. We're going to be using Google Chrome and Google Chrome developer tools or dev tools, throughout this course. And I recommend that you actually use Chrome Canary. Which has all of the latest and greatest development tools built in. And one more thing, when we capture all of our traces. I recommend that you use your phone, to actually capture the profiling data. Mm. Well, that makes sense. But, how do I capture this data with my phone? Great question. For the remainder of this lesson, you're going to get some instructions from Peter Lovers, on how to set up mobile debugging. And if you're already familiar, feel free to skip ahead The set up is simple. All you need is an Android device, a USB cable, and your development machine. Let's take a look. Before you get started you need to turn on the Developer Mode in your Android device. This may be different on any given device and you can check your device's manual on how to do this. In many cases though, you need to go to your device's settings, click on About Device and then click on Build Number seven times. Seriously. Next you'll want to turn on USB debugging Again, this varies slightly on your given device, but this is usually located in the developer options. We also need to make sure we have the right tools [UNKNOWN]. On my laptop, I have Chrome Canary and on my mobile device, I have Chrome Beta installed. Now that we have everything set up the way we need, open Chrome on your development machine and go to Chrome inspect. Make sure the site you want to debug is open on your mobile device and then connect your laptop to your mobile device via USB. Then confirm that you want to allow USB debugging. Back in our development machine, we can see a list of the attached devices and the Chrome tabs that are open on the devices. You can even open other tabs. We can also focus on specific tabs, you can reload them And you can even close a tab. The best part of course is that you can inspect the pages that are running on your mobile device, from your development machine let's take a look. One of my favorite new features is the new screen cast mode. This allows you to drive the experience on your mobile device from your development machine. You can click on links, and see them update simultaneously on the device. As well as on your desktop. As you can see, you have all the familiar features from the development tools available for mobile now. Now, that was really easy and it's also possible to do this on mobile Safari with the web inspector using the iOS web kit debug proxy. Now, that's a little bit harder to set up, so check out the link below for more information. Let me show you, how we're going to be using Developer tools in this course. I'm running Chrome Canary. And I have my phone connected. Which I have just on the side here with me. You can see that I have the udacity side open. Let's inspect that. With the Developers tool's open, let's navigate to the Timeline [UNKNOWN]. This is where we're going to be spending most of our time, in this course. Next, you can actually enable, the Screencast feature, if you have your phone connected. So let's click, on that. And you can see a preview of. What's actually on my screen. And as you can see, it's the same picture. To record a trace, we're just going to hit reload and, wait for Chrome to capture the full trace. Once the page is done, we have the full trace here. And you can extend and view all of the activity, here as well. This is the view that we're going to be using for, most of the course. Wow, that's pretty awesome. But what if I don't have a phone handy? I definitely recommend using Mobile Debugging if you have a phone handy. But if you don't, you can record the same Timeline data, directly on your computer. Check the instructor notes, for a quick how-to. [BLANK_AUDIO] Ilya you mentioned the Critical Rendering Path. It sounds pretty important. It is. The Critical Rendering Path is the sequence of steps that the browser goes through to convert the HTML, CSS, and JavaScript into actual pixels on the screen. And, if we can optimize that, then we can make our pages render fast, which makes for happier users. Cool. So what's involved in it? So, this diagram captures all of the essentials. First we grab the HTML and we start building the document object model. We then have to fetch the CSS and build the CSS object model. We combine those two to create the Render Tree. Then we have to figure out where everything goes on the page, which is the Layout step. And then finally we can paint pixels on the actual screen. Wait a second though, you only talked about HTML and CSS, what about JavaScript? right, yeah, so that's a big important part of the performance puzzle. But before we get there let's talk about, how we construct a document object model, the CSS object model, and then we'll talk about how JavaScript affects the actual rendering pipeline. Okay, that sounds great. When you request a URL and hit Enter, the browser sends a request to the server. For example, we can simulate this right on the command line. Once the browser receives the response, which is the HTML we see here, it must somehow convert all of the markup into something that we see on the screen here. Ever wonder how that happens? You know, now that you mention it, it does feel a little bit like magic. It's not magic. The browser follows a well-defined set of steps and it all starts with processing the HTML and building the DOM. The HTML specification contains a set of rules for how we should process the received data. For example, the text contained within the angle brackets has special meaning in HTML and it's set to be a tag. As a result, whenever we encounter a tag, the browser emits a token. In this case, it is the start tag HTML token. Next, we would get the StartTag, head token, and so on. This entire process is done by the tokenizer, and while the tokenizer is doing this work, there's another process that is consuming these tokens and is converting them to node objects. For example, we convert the first HTML token and create the HTML node. Then we consume the next token and create that node. Is there a relationship between the nodes? Yes, notice that the tokenizer emits start and end tokens, which tells us the relationship between the nodes. The StartTag head token comes before EndTag html token, which tells that the head token is a child of html. Similarly, the meta and link nodes are children of the head node and so on. Eventually, once we consume all of the tokens, we arrive at the document object model, or simply DOM, which is a tree structure that captures the content and properties of the HTML and all the relationships between the nodes. Cool, so we've converted the HTML to the Document Object Model. It's pretty easy to see why it's called the DOM tree. Yeah, also note that these objects contain all of their properties. For example, the image node has a source attribute and this node right here would also have the same property. The DOM is the full parts presentation of the HTML markup. Okay, so we downloaded all the HTML and built a DOM. Got it. All right, what's next? Actually, the browser constructs a DOM incrementally and you can take advantage of this to speed up the rendering of your pages. In fact, this is something that the Google search pages do really, really well. Let me show you. Whenever you send a search request to Google, the server actually does something really, really clever. Before the server even knows what the search results are, it immediately returns the header of the page, which is what you see here, and this header is the same for all users. This allows the browser to start processing the response and begin constructing the DOM incrementally, and potentially even render the header. Then, once the search results are ready, the rest of the HTML arrives, and the browser parses that and displays the content. As you can see, the browser doesn't have to wait for all of the HTML to arrive before processing, and neither should your server. In fact, returning [UNKNOWN] HTML can be a really nice performance optimization. Incremental HTML delivery. Very clever. Out of curiosity, how do the engineers at Google measure and optimize the performance of their pages? Believe it or not, they all use the same tools, Chrome developer tools and mobile debugging. Let me show you. As you can see, I have a search page open on my phone. Let's go to Timeline and record a trace. Okay. Now, let's take a look at what we have here. First, notice that we see an event for the HTML Request. Then, the server responds and we get the Response event. From there, the HTML is streaming in and the parse is processing each chunk, by following the same steps we just described. Tokenizing the data, converting tokens into nodes, and building a [UNKNOWN]. Hm. Nice. So the timeline gives us a pretty low level view into what the browser's doing as it loads a page. Yes, exactly. And it can be a bit overwhelming at first. There's a lot of different events in here. But don't worry, we're going to cover most of them. That said, I think it's a good idea for you to just try and record a few different traces on, on your own. Pick a couple of favorite sites, record a few traces. See if you can spot some interesting patterns. Once you're done, click this checkbox, to hit continue. So, I decided to take a look at cnn.com, a popular news site. To get started, I opened up dev tools by pressing Cmd + Opt + I. You can see the dev tools here, here is the HTML. So we're in the timeline now. I want to see what happens when the page loads. So, I'm going to press Cmd+ Shift+ R, reload the page and we can see all of the events of the page load. Laid out in the timeline here. Well, this is cool for desktop, but I wonder what it looks like on mobile. Luckily, Chrome gives us the option of seeing what it looks like on mobile. I'm going to press this button to open up the console, there we go, and we can see that there's a tab up here, emulation. So, I click on this, I see the Google Nexus five, and I press emulate. So now, we're looking at CNN.com from a mobile perspective. Bu,t this looks weird. I'm going to fix the screen a little bit. [BLANK_AUDIO] And, I'm going to refresh the page, by doing command shift r. And now, we see the mobile version of CNN on the left. And our timeline on the right. Let me get rid of this bottom part by pressing escape. And move the screen over to give ourselves a little more room. And let's take a look at the timeline. So, I've selected about the first second or so of events. Let me see them in a little bit more detail. Alright, so we see the request here for a page cnn.com/, so I'm going to click on this and open up the details, click on cnn.com, and we should see what this file is. Scrolling down. This should look pretty familiar. It's just an HTML document. Going back to the Timeline, let's get rid of some of these details. We can see a lot of events up here. We click on this Filter button, it lets us get rid of some of them so we can just look at what we want. I just want to see the loading events, so we'll get rid of scripting, rendering, and painting. And now, we can see the request for the home page, and the response as we're receiving data. CNN.com finishes loading, we get that HTML file, and then we start to parse the HTML. And, it looks like in parsing it by opening up this step, we see that we requested CSS and JavaScript. After that, scrolling down, we can see more requests for all of the scripts. Images and CSS files, that are needed to load the page. All right. We just went through the process of turning HTML into the document object model. As an exercise, I want you to mark the possible steps of building the DOM you see here, as either true or false. Be careful, some of these are pretty tricky and good luck. Okay, so this is what I think. HTML response turns into Tokens which turns into Nodes which turn into the DOM Tree. That one is true. That's the process we just learned. In this one, each token like startTag and endTag get converted into DOM nodes. This is in fact false. A single DOM node will start with a startTag token and end with an endTag token. Between the startTag and endTag tokens come other tokens which will define one DOM node. In this one, Nodes contain all relevant information about the HTML element. This is true. The information will be described using tokens. And the last one, Nodes are connected into a DOM tree based on token hierarchy. This one is true. If another set of startTag and endTag tokens come between startTag and endTag, you have a node inside a node, and this is how we define the hierarchy of the DOM tree. Lastly, it's also worth noting that DOM construction is incremental. [BLANK_AUDIO] All right. So the DOM captures the content of the page. But we also need to know how to display the actual page itself. And to do that, we need to build a CSS Object Model. Mm. And judging by its name, I guess it's similar to the DOM? It's very close. Let's take a look. Ok. Let's say we've received the following CSS. The first thing the browser has to do is identify the correct tokens. But there's no angle brackets here, right? Yeah. CSS has its own set of rules for how to identify valid tokens. The details are not that important. If you're curious, you can check out the CSS specification link in the instructor notes. The important part is that the parser would convert the tokens to nodes, and in this case, the first would be the body, with its font size property. Next, we would get the paragraph node, and this is the important part. It is a child of body because all of visible content is part of body. Wait- Is that some CSS specification rule? Yeah. Exactly. Also note that the children of the body node, inherit it's parent's styling rules of sixteen pixel font size. This is what we mean by cascading rules and cascading style sheets. Interesting. So it's similar to, but not quite the same as, the DOM construction because CSS rules cascade down. Hm curious. Let's see I got a style sheet with a lot of rules. Could we also apply the same incremental processing trick, like we do with HTML, to make the page display faster? That's a great question. Unfortunately, we can't. We can't use a partial CSS tree. Let me show you why. Let's say we just received the first view bites of our CSS and it contains the two rules we have here. So, we go ahead and build the CSS object model. It's tempting to use this tree to render a page, but there's a problem. Let's say we now get the next chunk of CSS and it contains more rules. In this case, we have the paragraph font weight normal. CSS allows us to redefine and refine the style properties. This is perfectly valid. But notice that this rule would allow us to change our CSS on tree. And make the text in paragraph node display with normal weight. So that's a gotcha. So, you're saying we can't really use a partial C-S-S on tree. Because then it could lead us to use the wrong styles when we render the page. Exactly, the browser blocks page rendering, until it receives and processes all of the CSS. CSS is render blocking. Let's say we have a simple page fragment with this HTML and two CSS rules on the left that we need to match. I've also drawn the CSS object model on the right that corresponds to these two rules. Do you think there's any difference in how much work the browser would have to do to match these two rules against the DOM? Also, while you think about that, write a sentence or two in the box about why you picked your answer. Well, let's take a look. Your intuition may be telling you that the second rule, which is more specific, should be faster because well, it's more precise, but actually the opposite is true. The first rule tells us that whenever we encounter an h1 tag, we should set the font size to 16 pixels. Pretty simple. The second rule is trickier. First, it says that we should match any paragraph tag, like the one we have here. But then, once we find the paragraph tag, we should walk up the DOM tree and only apply this rule if there's a div element as its parent. As a result, this more specific tag actually requires more work from the browser. Hm, oh wow, so the more specific rule is more expensive because it has to traverse more nodes in the DOM tree. That's right. Exactly. That said, before you go all crazy and rewrite all of your rules, measure first. Chances are selector matching is not your performance model link. So, I shouldn't worry about it? Well, I didn't say that. Measure first, optimize second. And speaking of measure, let's take a look at def tools. Okay, I have loaded a timeline trace I have saved from an earlier session. Wait, wait. You can save timeline traces? Oh yeah. It's a pretty awesome feature. You can just right click on the timeline and save any trace. Similarly, you can load a trace from a previous session in the same way. This is a really useful feature whenever you're debugging a site, and want to keep it for further analysis or if you need to share it with someone. Hm. Wow. All right, I've been taking screen shots. Really wish I'd known about his early. Yeah, traces are definitely better than screen shots. I've put a link to the trace we're looking at here in the instructor notes. Why don't you download it and open it on your machine to follow along. I'll wait a few seconds. [BLANK_AUDIO] Okay. Let's look for some CSS events in this trace. First, you can see the CSS requests going out. Note that it happens after the first trunk of HTML, is received. This is where the parser finds the link tag and initiates the CSS request. Then we wait to get the css bites and finally a bit later we see the re-calculus style event which is were we convert the css response into the css object model. In this particular case the css is tiny so it only takes a few milliseconds to do the conversion, but for larger style sheets this could definitely take much longer. Okay, so before I rewrite all of my css rules. I should probably record the timeline and check out how long this stuff is taking, right? That's right. Measure first then optimize as needed. [BLANK_AUDIO] Okay. So, the DOM contains all the content of the page. The CSSOM contains all the styles of the page. So how do we take the content and styles and turn them onto pixels on the screen? I feel like we're missing an intermediate step. That's good intuition. Now we need to combine the DOM and the CSSOM trees into the render tree which will capture exactly what you described. One of the most important properties of the render tree is that it only captures visible content. And to see this in action, let's work through the simple example we have in front of us. At the top, we have the DOM tree and at the bottom the CSSOM object model. To construct the render tree, we start at the root of the DOM tree, which in this case is the paragraph node and check if there is any CSS rules. That match it. In this case, we see that we do have a matching rule that makes all the text render in 16 pixel font size and in bold. So we copy the paragraph node to our render tree alongside with its CSS properties. Okay. We're done with the paragraph node. Let's walk down the tree. Next, we see, hello, which is just a text node. So we copy that through our render tree. Next we arrive at the span node. We have a matching CSS rule for it. We have a span and it is indeed a child of the paragraph node. But notice that one of the properties in this rule is that it's marked as display none, which tells us that the contents of this span should not be rendered. And since as we said the render tree only captures visible content. We can skip it and its children. We skip the children, because display,none cascades down, right? Exactly. And as a result, we can skip all the children nodes of the span node and go to the next node, which in this case is just another text node. And we copy that to our render tree once over. So the render tree captures both the content and the styles. Right. Now let's take a look at our Hello World page. Okay, here we have the dom and CSS trees for our Hello World page. To build a render tree we start at the HTML node in the dom tree. The HTML and the head sections don't contain any visible information. So we can just quickly prune them out of our render tree. Next, we have the body node. Let's copy that over. This left part of the tree should look familiar. This is what we just built. So let's copy that over as well. Finally, we have the div and the image nodes. Both of these contain visible content, so we also copy them over, and their styles, into our render tree. With that done, compare this render tree to what we have on the screen. Huh. Yeah. The render tree is a pretty good representation. The unnecessary text is gone. I can see that there should be an image on the screen and it should be displayed on the right. So, are we all done now? Not quite. We still have to do layout. But first a quick quiz. Say we have a simple DOM tree and a few CSS rules. Imagine we parse these CSS rules and combine them with the DOM to build the render tree. What text would you expect to be visible? Write your answer here and, while you're at it, figure out which color these texts should be displayed in. Okay, let's try to apply the CSS rules to our DOM tree. The first div rule would set the text color to red, which is a property that cascades down to the Hello text. This next rule makes the paragraph contents to be displayed in black and here's the font part. The rule applies to all paragraph nodes regardless of its parent. Hence we change the color of the text to black for Hello and world. Finally, we get to our last rule, which tells us that any paragraph node that has a div as its parent should be hidden from the render tree. As a result, we can prune this branch from our render tree and all we're left with is world. So, the final answer is world and the text color is black. Alright, I feel like the finish line is in sight. We've got our render tree. Can we put pixels on the screen now? We're definitely very close, but there's one more step. We still need to figure out where and how all the elements are positioned on the page. And that's the layout step. Let's take a look. To show a layout in action I've come up with a simple render tree. Here's what the final result will look like. Note that if we rotate the phone, the dimensions of the boxes change. But their proportions stay the same. Let's see if we can figure out what the browser is doing here. Let's start at the top. We set the background on the body element to gray. That makes sense. That's exactly what we saw. And we set its width to 100%. Wait, that's 100% of what exactly? It's 100% of the layout viewport size. If you paid attention, our hello world examples contained an extra meta tag. Oh yeah, I was reading the web fundamentals guide on responsive design. And it said that I should always have this tag. But I never really understood what it was for. It is a bit cryptic, but let's try to make sense of it. What it's doing is telling the browser that the width of the layout viewport should be equal to the device width. So, let's say that the device width is 320 pixels. Then, if this meta viewport tag is present, the browser will set the layout viewport to 320 pixels and that will be our 100%. Oh, I see. But what happens if I don't provide this tag? Then the browser will use the default viewport width, which is typically 980 pixels. And it's optimized for large screens. You know how sometimes, sites render zoomed out and you have to zoom to navigate and read the text. That's because they're not setting delay at viewport. Oh that makes sense. I am definitely not a big fan of those sites. Neither am I. To build great mobile experience, you should always set them at a viewport. But getting back to our example. If the device with this 320 pixels, then the body will be 320 pixels wide. Next, we have the divnote at 50% of the width. And it is a child of body, so its width is relative to its parent. And 50% of 320 pixels is 160 pixels. And, for paragraph, the width is 50% of its parent. Giving us the width of 80 pixels. And, with that, we're done. That's layout. Now, how about you give it a try? Here's a render tree and let's say our layout view port is 320 pixels wide. That means the body is 320 pixels wide. Can you calculate the width of the remaining nodes? Okay 50% of 320 pixels is going to be 160 pixels. Next, we have the paragraph node which is 100% of its parent, so that's also going to be 160 pixels. The em is 50% of its parent, so that's going to be 80 pixels. And finally, span is 25% of its parent, so that's going to make it 40 pixels. Yep. Great job. Layout dependent on the size of my browser, right? What happens if I rotate my phone? If the dimensions of the layout viewpoint change, the browser has to rerun the layout step. That's what happens every time you rotate your phone or, for that matter, resize your browser. Hm, I see. So our examples are pretty simple but could this possibly a performance bottle neck? Yep, let's take a look at their tools. I've captured a trace of gizmodo.com which is a popular new site. If you're curious you can grab this trace from the instructor notes and follow along. Let's take a look. First of all, there's a turn of events here. Since we're only interested in layout, let's filter out the loading, scripting, and painting events. Okay, here's the first layout event. Check it out. It took 145 milliseconds. Wow! That's a long time. Yeah, as you can see there are over 1400 nodes. In the tree. Huh. but there are other layout events in here. What's going on? That's a great question. Recall that any time we update the render tree, either by modifying styles or the content, there's a good chance we have to rerun layout. And in this case, it looks like that's exactly what's happening. The page is adding new content and modifying styles, and hence, we need to run layout a few more times. Hm. I see. So how do you go about optimizing for that? It really depends on the site, but a good rule of thumb is to batch updates to avoid having multiple layout events. As an exercise, try profiling some of your favorite sites, and identify ones that have Expensive Layout. Then share your findings on the forum. I'm curious which sites have the slowest layout. And for bonus points, try to figure out why, and what's causing it. Hm, sites with the slowest layout, this could be fun. I'm curious what everybody finds out. So, when I decided to take a look at what websites had a slow layout. I came to nbcnews.com. This website has different stories laid out in sort of a grid on the screen. Let's see what happens if we change the size of the grid. And, we can see that the stories, instead of being stacked next to each other are now stacked on top of each other. Let's make this full screen again. And, we can see that the stories moved out to their original horizontal orientation. Let's take a look at what this looks like in Dev Tools. I'll Cmd+Option+i to open up dev tools. Alright, where I have the HTML, let's go over to the timeline. And, I'm going to hit the record button, and start changing the size of the screen and watching what happens with layout. We'll make it small. Okay, it looks like the stories have moved. Let me go ahead and make it full screen again. Cool. And, I can go ahead and stop the recording. Alright. So, we have quite a bit of data here in the timeline. I'm not sure what we exactly we need to look at, so let's go ahead, well instead of searching through, just filter out what we don't want. Layout happens in Rendering, so let's get rid of Painting, Scripting and Loading. We only see these purple events here. Let's go ahead and take a look at this section, we can see a few Layout events. Clicking on this one we can see that it took 113 milliseconds, which is definitely a noticeable amount of time. [BLANK_AUDIO] So, we know everything's going to be on the page now. We just need to paint the pixels, right? Yeah, except just paint the pixels is not as simple or as easy as it sounds. Yeah, I had a feeling you'd say that. Let's do a quick quiz to test your intuition. Imagine we give the browser these two nodes from the render tree. Do you think there's any difference in how quickly we can paint their content? Write a sentence or two to explain your answer. Well, this is an obvious one, isn't it? The first thing to look for is the size of the area we have to paint. In this case, both divs are 100 by 100 pixels. Now, let's look at what we're painting. The second div is just a square filled with white pixels. Now compare this to the first div. Here we have a transparent background and we also need to render an inset shadow. As a result, the second div is definitely cheaper and faster to paint. I guess not all pixels cost the same to paint on the page. I should really pay attention to what affects I'm applying and everything else I'm doing. Yep, exactly. Although remember the cardinal rule of web performance? Let me think measure first then optimize. Exactly, let's take a look. Okay, we're looking at a trace of the New York Times homepage. We want to look at Paint events, so let's filter out the rest. As you can see, there are many Paint events, but let me show you a handy trick. We can select a time range that we want to show on the timeline by dragging the sliders at the top here. Notice that as we do this, the pie chart on the bottom is updated with the total times. Yep, and also while we're here lets identify some expensive things. For example, this one took eight milliseconds. Hmm. So, let me see. We said that anytime we want to update the render tree, there's a good chance we'll have to run layout, and I'm guessing the same applies for painting, right? That's right. The browser applies a lot of smarts and tried to repaint the minimum required area. But really it all depends on what kind of updates are being applied to the render tree. Let's take a second to walk through the steps to render the simple page you see on the screen here. Using numbers one through six, number the steps in the order that the browser will have to take to render this page. Put one next to the first step, two for the second, and so on. Good luck. Okay, first things first. Once we've started to receive this HTML, we'll be parsing it as we get it. So that's step one. DOM construction can be incremental, and the response may not arrive all at once. So, we may not finish constructing it all at once. In the head, we'll find links to CSS and JavaScript, so then we'll fire off those requests. That's step two. But there's a gotcha. The script is synchronous, and we can't execute it until we have the CSSOM. So we'll need to create the CSSOM as soon as possible. Completing the CSSOM will unblock the JavaScript engine, so we'll be able to execute JavaScript as soon as we've received it. Once the JavaScript is finished, we can resume and finish constructing the DOM. Once we have the DOM and CSSOM, we'll merge the two and build the Render Tree. After that, we run layout and paint the page. Alright, we've looked at all of the individual pieces of the critical rendering path. Now, let's take a look at an end to end view and see how the timeline comes together. Awesome, that's exactly what I need. To keep things manageable we'll use our hello world page that has a few inline CSS styles, some text, and image. Let's refresh to capture the full trace. Okay, let's see what's going on here. As you would expect, first we see the request go out for the HTML document. Next, we get an event showing that the server returned some response headers, followed by some data. That's our HTML. Next up, the browser begins parsing the HTML. This is where the browser is converting the received bytes to the DOM tree, and in fact, if we expand this note, you can see that our document parser. Finds the embedded image reference and initiates the request. Once that is done, it continues to parse the HTML and once it gets to the end it constructs the CSS object model. In this example our CSS was inline directly into the page. So, there are no CSS requests. Next, the browser builds the render tree and computes all the styles for the content that should be visible. On the screen. That's what this recalculate style event indicates. Once that's done, we continue to layout, which as you know now, is where compute the location and the size of the render tree elements. Finally, once done, we issue a paint event and our page is rendered on the screen. You know, when we first started looking at everything, it felt really confusing. But this is actually pretty straight forward. This is pretty awesome. Glad to hear Tell you what, Ilia. How about I go to a page, record a timeline trace, save it, and find a couple places to optimize? Afterwards, I'll send it to you. That's a great idea. However, instead of just sending it to me, why don't you share your findings on the forum with other students? Let's see if you can identify some common performance problems. Yeah, it sounds like fun. What kind of website do you think I should check out? Doesn't matter. Pick some favorites. Let's see what we can find. Cool. So I decided to take a look at one of my favorite websites, Netflix. I'm going to open up dev tools by pressing Cmd+Option+I. Turn on emulation. And go into the timeline. I'll do a hard reload by doing Cmd+Shift+R. We can see the events that happen as the page is loading. Let's take a look at the first couple. We could see we send a request for the homepage here. This is the HTML file that we need to load the page. Let's scroll down. We can see that when the HTML file finishes loading, we then parse the HTML. Let's open this up. And we see a request for two different files, both called include. Clicking on the first one gives us this CSS file. Scrolling down, I think we can pick out two pretty obvious optimizations just looking at this file. The first optimization is to minify the CSS or get rid of all the white space. The white space in the file only helps us read it. It doesn't help the browser parse the file. So in fact, if we got rid of all the white space, we would remove a significant amount of bytes from our data. The second optimization is to inline critical CSS and we wouldn't have to send out another request for this CSS file to style this page This Critical Rendering Path was not nearly as daunting as I was afraid it was at first. Now that we've gone through it end to end, I'm feeling really great. It's definitely not magic. what's next? Well, now we get into the fun stuff, the optimizations. And there's a lot to say here, but you know what, now that you know, the Critical Rendering Path and how it works, I think a lot of the piece speed optimization will be obvious. Great, I am really excited to get started optimizing my portfolio page. See you next lesson. [BLANK_AUDIO] All right. Now we're on to the fun stuff. Can we start optimizing now? Yep. Let's just focus on the steps before the render tree construction, so, the DOM and CSSOM, because those are usually the steps that are the worst offenders and make your page. Render very slowly. Well, we did talk about streaming HTML to the client as fast as possible so the browser can start building the DOM. Is there anything else? So that's definitely one. What about the size of the HTML? Hm. Well, I'm going to go ahead and guess we should keep it as small as possible. Yep. That's another good one. Let's take a look at some strategies that will help us with this. Let's say we want to optimize the HTML file in front of us. The first thing to notice is that we have CSS comments, HTML comments, and JavaScript comments. Now, these comments are very helpful for developers. But guess what the browser's going to do when it encounters them. It's going to ignore them. Exactly. There's no point in even shipping them to the browser. We can minify the file and reduce its size. To learn more about minification check the link in the instructor notes. Once you've done that you should also compress the file and make sure they are cached by the browser. Once again, check the instructor notes. To optimize the CSS [UNKNOWN] construction we want to remove unnecessary styles, minify, compress and cache it. Is that right? Yep, those are all good ones, but if I remember correctly, I think when you run PHP on your site it also recommended that we look in to render blocking CSS. Oh yeah. What's that about? Well, let's take a look. Let's say we have a simple page with one CSS file. The browser downloads the HTML, and then this covers and fetches the CSS. What is the earliest point where the browser could paint the page? Is it a, once the browser has built a DOM? Or ist it B, once the Browser has downloaded the CSS and built the CSS object model? The answer is B. Recall that in order to paint the page, we need to construct the render tree. And to build a render tree, we need both the DOM and the CSSOM trees. As a result, the browser will have to wait until it fetches the CSS before it can paint the page. Right. We don't want to paint an unstyled page, hence the render blocking CSS. So, is there anything we can do to optimize this? Yep. Let's take a look. CSS allows us to scope styles to particular conditions. For example, consider the file we have in front of us. The body rule applies in all conditions. However, when the device is in landscape mode, we apply a special rule to float the menu on the right. Similarly, if someone decides to print the page, we resize the text to use a smaller font size. Yeah, media queries are important for a responsive web design, but how does this help us optimize a critical rendering path? Great question. First of all, check out the link in the instructor notes to learn about media queries. The web fundamentals slide has a great and detailed explanation of how they work. And to answer your actual question, let's say I'm rendering a page that's using this CSS file. We noted the browser would block rendering until it parses all of these styles but intuitively do you think it should block rendering on the parentherials? Mm, well, I guess if we're not printing the page then there's really no reason to block rendering, right? Exactly. This is why it makes sense to sometimes split the CSS into multiple files. Let's give this a try. Our first step is to move our print styles into separate file. Let's call it Style Print CSS. Next, we add an extra link to our HTML mark up. And here's the important part, by default the browser assumes that each specified style sheet is render blocking. However, we can also tell the browser when the style sheet should be applied by adding a media attribute with the media query. In this case, sense style-print.css is only used for print, we add media-print. Oh, so now when the browser sees a style sheet it knows that it only needs to apply it for printing and hence it doesn't need to block rendering when we're loading on the phone. You got it. The browser still downloads both style sheets, but it wouldn't block rendering on style-print.css. And in this particular case it just means that the browser has to download less data for style.css which would help with the download speed. That makes sense. But this is a pretty trivial example. Let's say I've got a much more complicated set of styles with multiple break points. Would this technique help here as well? Absolutely, you can specify any media query on the link attribute, and the browser will do the right thing. Once again, check out the article in the instructor notes for directions on how to use media queries. Okay, now the page feed recommendations about reducing the number of critical CSS elements makes a lot more sense. Glad to hear. Lets do a quick quiz to test your understanding. If we`re rendering a page on a mobile phone in portrait orientation, which of the following stylesheets will block rendering? Recall that by default, the browser assumes that css is blocking, hence the first link tag will block rendering. The screen query will evaluate the true, since we are rendering the content on the screen and hence it will also block rendering. The third declaration depends on the orientation of the device. In this particular case because the handset is in portrait orientation. It won't be a render blocking resource. Finally, the last declaration is only applied when the page is being printed. Hence, it is not render blocking when the page is first being loaded in the browser. Nice. So, only two of the four are render blocking. I can feel the pages getting faster already. [BLANK_AUDIO] Okay, so I think I have a handle on optimizing HTML and CSS. So, are we moving on to the render tree? Almost, we haven't really talked about JavaScript, and obviously that's an important step, so let's take a look at that. Okay, well let me guess, minify it, compress it and cache it? Yup. All of those are good strategies. But for JavaScript you may have seen piece bit insighs also complain about parser blocking scripts. Let's take a look at what that means and how we can optimize it. I've extended our hello world page with a simple inline script at the bottom. Let's walk through it. First of all, we reach into the DOM and look for the first span element. Which, as you can see, contains the web performance text. Next, we modify the DOM element by changing its inner text and also changing its CSS properties. Seems simple enough. Yeah, this shows that JavaScript can manipulate both the DOM and the CSS Object Model. It's a very powerful tool. And it gets a bit more interesting from here. Next, we create a new div element, set its text content. CSS caller property, and append it to the page. Let's try to load this page on our phone. Notice that the text now says, Hello interactive students instead of Hello web performance students. And we also have our new element right below it. Right, as expected. So is there anything here we can do to optimize performance? Definitely, optimizing JavaScript could be an entire course. But, in this particular example, it's not really the code, but how it's included on the page. Let's take a step back and think about how the browser would go about building this page Let's say the browser is processing the following document fragment. If we were to render this in a browser, what text would you expect to see on the screen? If you're not familiar with document.write, check the documentation link in the instructor notes. First, the document parser creates a paragraph node and adds the text fragment. Then it encounters the script tag, at which point it pauses DOM construction and waits for JavaScript engine to execute the script. The script appends with JavaScript and exits. At which point, you resume DOM construction and append is awesome text fragment. As a result, we get awesome page with JavaScript is awesome. Indeed, it is awesome. But, how does this affect performance? Well. Note the sequence of steps here. When we encounter the script tag, we have to pause DOM construction and let JavaScript run before we could continue. JavaScript is said to be. Parser blocking, because it blocks, DOM construction when we encounter the script tag. I see, but that doesn't seem like that big of a deal. JavaScript is pretty fast, right? It is, but, let me make a slight modification. Instead of using an inline script, like what we have here on the bottom. Let's say, we move the script content into an external file. Like, what we have here. What would you expect to happen now? Hm, well, same as before, the parser finds the script tag, fetches the file and executes it. Oh wait, oh, I see. This fetch could take awhile, right? And while the browser's fetching this file, the browser's blocked and can't continue constructing the DOM. Which would in turn, slow down the critical rendering path. Exactly. The script tag blocks the parser from proceeding, and we're stuck waiting, [SOUND] for this file. Not a good outcome. So, if external JavaScript always blocks the parser, it sounds like I should just inline all of my JavaScript. Well, yes and no. You're right in that, inlining the JavaScript would help limit the requests. But, there's some downsides as well. For example, if you use the same code on multiple pages, then that will be redundant code in all those pages. So there are tradeoffs here. All right. But, for code that's specific to one page, that seems like a pretty good strategy. Yeah, that's reasonable. But, let's take a look at some of the tradeoffs and the gotchas word associated with them. Same document fragment as before, except we've now added a CSS style sheet at the top that renders all paragraph text in black. Now, consider what happens when we try to execute our inline JavaScript. We region to the document and find all the paragraph tags. Grab the first one and set up it's CSS on color style to red. The style sheet says that all paragraphs should be rendered with black text. What if this CSS style sheet arrives after the script is already executed and sets the color to red? Would the browser be smart enough to figure out which color to use? Yes, it would. Here's a quick diagram that illustrates what actually happens. The browser requests the HTML, and as soon as it gets the response, it starts building the DOM. It then discovers the CSS and sends the request. Then, the person continues and finds the script tag, at which point it has to block. It doesn't know what the script is going to do because the script may want to try accessing the CSS properties. So, it blocks script execution until the css arrives and we build the css object model. Only then can we run the JavaScript and then finish building the DOM. Wow, so CSS blocks rendering and it blocks JavaScript execution. Exactly, which is, once again why optimizing your css is so important. On that note, I have a quick quiz for you. Any ideas for what we could do to optimize the Critical Rendering Path of this page? Don't rush. There are quite a few things going on in here. In fact, you may want to discuss this one with other students on the forum. Cameron, any ideas? Well, the inline script would block on CSS, so anything we can do to make the CSS faster would help. In fact, what if we just inline the CSS? Yeah, that would remove an extra request and that could definitely help. What about the JavaScript itself? Do you think it should block rendering? Now that you ask, I don't think so. It's reporting a visit to some analytic service and there's no reason for it to block rendering, right? You just made a very important observation. Some scripts don't modify the DOM or the CSSOM. And really, they shouldn't block rendering. And Analytics is a great example. Yeah. I wish we had some way to tell the browser exactly that. Actually, we can. One strategy would be to load the script after the page is loaded. So when the browser fires the onload event. And we could execute the script then. All right, how would I do that? The browser fires an on load event when the page is is finished loading. And you can wait for that and then execute your script then. Check the instructor notes for instructions on how to do that. Okay, will do. Is there anything else? Yeah, the on load technique is a good one to have in your back pocket, but there's actually an even simpler strategy that we could use. All we need is an extra attribute on the script tag. Let me show you. Cool. I've pulled out our analytics code into a separate file and added the async attribute to the script tag. This attribute has two important properties. First, it tells the browser that it does not have to block dump construction. When it encounters the script side. As a result, the browser dispatches the script request, and continues parsing the DOM. Second, the execution of the script does not block on the CSS Object Module. So, if the script is available before the CSS Object Module is ready. It can still be executed right there and then. Oh wow, that's handy. So async basically means that the script does not block the critical routing path. Exactly. The browser will download and execute the script but it won't block the parcer, and it won't block on CSS. What about inline scripts? Can I put an async attribute on an inline script? Unfortunately that wouldn't work. Inline scripts will always block on the CSS Object Model. Well, with one exception. If you put your JavaScript above your CSS, then it will execute without blocking on CSS. To learn more about this pattern and async scripts, check out the link in the instructor notes. Let's do a quick exercise to see if you can spot the difference between these patterns. I've recorded three different traces of the same page. The only difference is how I've included the JavaScript. In one of these traces, I've used the blocking script tag. In another, I've inlined the script, and in the last one, I've used the script tag with the async attribute. Take a look at the sequence of the events here and try to figure out which is which. Once you know the answer, just write down blocking, inline, or async in the boxes below. This one was pretty tricky. For the first one, we get the HTML and send request for style.css and timing.js. So, we can rule out the inline option. Next, we get timing.js and execute it and css arrives afterwards. This tells me this must be the async script, because if it weren't. We'd have to block and wait for CSS. Great job! Next one? Okay. So, we get the HTML. Send request for style.css. I don't see any request for JavaScript. But then, when we finish loading the CSS we run the script. So, this must be the inline case. Yup. Inline scripts, block, and CSS. And, in this last one, we have request for CSS and JavaScript, and JavaScript arrives first. But then, we block and wait untill CSS is available. So, this must be blocking script tag. Alright, we've covered a lot of ground. Easily a dozen performance rules. Yeah, to be honest, it's a bit overwhelming. There's a lot to keep in mind. I think I can help you with that. There are a lot of different rules, but really, there are three buckets into which we can place most of them. So what do you mean? Well, let's take a look. First, we talked about minifying, compression, and caching. All three techniques apply to HTML, CSS, and JavaScript. Next, we know that some resources, namely CSS, will block rendering. To optimize this, we talked about two strategies. Use media queries on link to unblock rendering, and inline CSS. Finally, we also saw that Javascript blocks the document parser, which is something we want to avoid. To fix that, we can defer Javascript execution, or use the async attribute on the script tag. So, looking at these, can you spot some patterns? Hm, let's see. Minify, compress, cache, and minimizing the amount of HTML, CSS, and Javascript. It's all about reducing the amount of data we have to send down the wire, right? Spot on, that's the first bucket, minimize the number of bytes. The fewer bytes we need to download, the faster the browser can get the data and start processing to render the page. Any other patterns? Hm, okay, so this one and this one. Are all about removing files from the critical rendering path. For CSS there's the media query stuff, and for JavaScript we have the asyntac word. Exactly. There are many cases where we need CSS and JavaScript, but there really shouldn't block rendering of a page. Things like print style sheets and analytics JavaScript code are both great examples. Our second bucket is to reduce the number of critical resources. Right, not all resources are critical. So I guess we should play close attention to CSS and JavaScript in particular. What's the third bucket? I don't see anything left here. Right. The last one is, is to shorten the critical rendering path length. Wait, what do you mean by length? Good question. Let's work through some hands-on examples. Let's construct the critical rendering paths for our hello world page here. At time zero, we request the HTML. Once the response arrives, sometime later at time 1. We parse the HTML and construct the DOM. And then we render the page to the screen. Note that there's no CSS or JavaScript. So as soon as we have the DOM, we can render the page. We do have an image in this page, but it doesn't block the critical rendering path. That seems pretty straightforward. Yeah, fair enough. We'll make it more interesting in a second, but first, let's analyze the first page against our three buckets. First, how many critical path resources do we have here? Well, there's only one HTML file, and obviously we need that to render the page, so. Just one? Yup. We have one critical resource on this page. Now, how many critical bytes do we have here? Well the HTML's five kilobytes, so five kilobytes? Right again. We have five kilobytes. Now, the last one. In the best case, how many round trips between the browser and the server do we need to render this page? Hm, I'm guessing also one. We send the requests to the server, and we get the response, and I think with that we're good. You're right this time. The HTML file is small then we only need one route trip to fetch all the data. As a result, the best case critical path length is also 1. I remember PHP insight said that my page should ideally be under 14 kilobytes. Is this why? Yes, exactly. And of course if the page is larger the page will still render, but if the file is large, it'll take more round trips to fetch the data. And this is pretty low level stuff, but it can make a big difference in how quickly the page takes to render. So, check the instructor notes if you want to learn more. Wait, did you write a book on this? Actually yes, yes I did, and it's available online and it's free. So if you're curious about this topic you can learn more about it. Check the Instructor Notes. Cool, yeah, will do. All right. Let's make things a bit more interesting. Same page as before, but now with an external CSS file. This time around we get the HTML response and start building DOM. We then discover the link tag and send the request for the CSS. In the meantime, we continue parsing the HTML and constructing the DOM, but note that we can't render the page just yet because we're still blocked and waiting for the CSS. Once the CSS does arrive and we finish building the CCS Object Model, we can paint the page. Gotcha. Now, I want you to figure out the critical path metrics. Filling the right answers for the critical path matrix in the boxes here. Both the HTML, and the CSS are critical resources. So this is 2. We had to get, both resources. Yep. 5 kilobytes for the HTML and 4 kilobytes for the CSS. so that's, a 9, total kilobytes. And critical path length. Hm. Let's see, best case scenario, I think there are two round trips. One round trip to get the HTML and then receive its response. And then another round trip to get the CSS and receive its response. So I think the critical path length is 2. Correct. Great stuff. This is really interesting. I guess the fact the we have these three buckets, the number of critical resources, the number of critical bytes and path points, illustrates that there's really no one golden rule. For example, if I eliminate the number of critical resources, I would also probably also reduce the number of bytes. And likewise if I started compressing, caching and minifying, I can also produce a number of bytes. Exactly. I couldn't have said it better myself. I think you're really starting to get a hang of this. Let's try a few more examples. Okay same page but now with CSS and JavaScript. Once again we get the HTML and let's cover CSS and JavaScript resources and initiate those requests. Note that the JavaScript file is a bit smaller than the CSS so it may arrive sooner. Which other script is blocked on this CSS on being created, right? Correct, once the CSS arrives the browser builds this CSS object model which unblocks java script and allows it to execute. Once the java script is executed, the DOM parser becomes unblocked which means a complete DOM construction. And finally we have both the DOM and the CSS object model which means that we can render the page. As you can see, even a simple page such as this one has a lot of dependencies that slow down the critical path. Yeah, no kidding. Why don't you try calculating the critical, rendering path metrics again? Let's see how JavaScript changes things. All right, I'm going to give this a shot. Let's start with number of critical resources. We've got HTML, CSS, and JavaScript, so that seems like there are three critical resources. Okay. Total critical bytes. We've got 5 Kilobytes for HTML, 4 for CSS, and 2 for JavaScript, so that's going to be 11 total Kilobytes. And then minimum critical path length or round trips. Let's see, hm. Is it going to be two or three? Can the browser download both the CSS and JavaScript in parallel? It's two. The browser can download both files in parallel. Note that the number of critical resources and the total number of Kilobytes has increased, but the critical pathlength stayed the same. Now as an exercisem imagine that each round trip took one full second because you're on a really slow connection. How long do you think it would take for us to render something on the screen? 2 round trips. 1 second each. 2 seconds or so. Yep. Now, imagine you're on the latest, super fast fiber connection, with 50 millisecond round-trip time. Seriously, now you're asking what's 2 times 50 milliseconds. Yeah, it's going to be 100 milliseconds. It's a good exercise. Now you have a good approximation for how long the page will take to render. And it only took a minimal amount of analysis. You know, I think I'm starting to get a hang of this. In fact, looking at the diagram, I can also think of several strategies that we could use to optimize this page. Can I give it a shot? Go for it. What optimizations do you want to try? Write your thoughts in the box. Well, first of all, we have an external CSS file which we need to construct the CSSOM. So, if I inline that, then that could save a lot of time. Same goes for JavaScript. If I inline that, then we can skip the request. And in fact, if I inline both, then that's even better because my critical path length will be one. As soon as I have my HTML file, I have everything I need. Yep, that's right. Those are definitely good strategies. Just be careful when you apply them. Remember that inlining a lot of JavaScript and CSS, especially when those resources can be used between multiple pages, can lead to a lot of overhead. Right. Right. Good point. Alright, speaking of which, I guess, I don't know if this applies to this exact case, but if I knew what was inside the CSS and JavaScript files, then I could also consider adding a media type to the CSS or making the script async. Yep, you got it. Just to confirm though, what would you look for in the CSS and JavaScript files? Well, for CSS, I'd want to make sure the styles are actually required to render the page. If they're not being used, I could add an appropriate media tag to attribute and unblock rendering. Also, it's pretty much the same idea for JavaScript. If the script is not manipulating or accessing the DOM or CSSOM, then I could add an async attribute, which would unblock DOM construction. Yep. That's awesome. I think you're on a roll. Let's do one more example. Same page as before, but with one small optimization. We have an asynchronous script. Let's see if figure out the critical rendering path metrics just by looking at the HTML. Of course, you're welcome to draw the diagram yourself, but I'm guessing you won't need it. Give it a try. All right, well, the HTML is a critical resource. And the CSS style sheet inside is also going to be render blocking. The image doesn't block, the critical rendering path. And this JavaScript file at the end is also asynchronous and it won't block rendering. So in total, that's going to be two critical resources, the HTML and the CSS. You nailed it. Now, I didn't ask you about the number of critical bytes, but any idea how you would go about figuring that out? Simple. I just need to know the size of the HTML and the CSS files. Yup, exactly. Now, what about the critical path length? So, let's see, the HTML file is 1. We have another round trip to get to CSS. And then, because this JavaScript file is async, it's not going to block rendering. So, the best case is going to be two, as our critical path length. That's right. Cameron, why don't you try drawing the critical rendering path diagram for this example? Sure. Let's see. First things first. We request this HTML. Then we start to build the DOM and come across this CSS file, which of course we have to request. We continue to build the DOM and then immediately encounter app.js, which is parser blocking. So we halt construction of the DOM, request, and wait for the file. When we finally get the CSS and have built the CSSOM, we can run app.js and then continue to build the DOM. And then we hit the next script, timing.js, so we block parsing on the download. Does that sound right? Yep, that's right. However, this could take quite a while. First we block on app.js and wait for it to arrive. Then on timing.js, and wait for that to arrive. To optimize this particular case, the browser has a special process called a preload scanner, which peaks ahead in the document, and tries to discover critical CSS and JavaScript files, like timing.js. Well that's clever, so even though the parser is blocked, we can discover timing.js and initiate downloads for critical resources? Yeah, exactly, so instead of waiting to build the CSS object model, and run app.js before requesting. timing.js. The preload scanner finds timing.js and requests it while the parser is blocked. Cool. Well, that's pretty interesting. Where can I learn more about the preload scanner? Check out the instructor notes. You'll find a couple of good resources there that will help explain why the preload scanner exists and how it operates. One of the best things about doing the critical memory path analysis is you can get a pretty good estimate for how long the page will take to render. Yeah, it's pretty awesome. Once I have my critical rendering path diagram I don't even have to profile my page. Well, I do need to profile my page for other bottlenecks, but what I mean is that I can see all the dependencies in my critical rendering path diagram and get a good idea of how long my page is going to take to render. Exactly. With a little bit of practice you can just take a look at the SML and figure out what the critical rendering path is. And you know what, that's actually a great exercise. I'm going to give you a couple of files which you can find in the instructor notes, and why don't you analyze those, draw the diagrams, and come up with the CRP metrics. So should I draw a diagram like the ones we've been seeing in the examples? Yep, exactly. And don't worry about making it pretty. Use whatever tools you like. Pen and paper is good, and then post it on the forum. Alright, so I'll make sure I've got the three critical rendering path metrics too. The critical path length the number of critical resources, and the number of critical bytes. Yep. Exactly. Cool, so I'll go ahead and post it on the forums. I decided to do example number two. First off, we request the page and start receiving the HTML. We start parsing it immediately and building the DOM. We come across two style sheets. Style.css and print.css with a media query for print. We aren't printing, so print.css isn't a part of the critical rendering path. We only have to send out a request for style.css. And then we continue parsing the DOM. We run into two script tags at the end of the body. One for app.js and another for analytics.js. analytics.js is async, so it's not a part of the critical rendering path. We fire off a request for app.js and halt building the DOM while we wait for CSS to arrive and the CSSOM to be built. Now that we have the CSSOM, the job script engine is unblocked, so we can run app.js, finish building the DOM and then render the page. That wasn't to bad. Let's do one more, critical rendering path diagram, but this time I want you to create, the diagram for a real website. If you have your own site, I want you to analyze that, and, if you don't, you can analyze any site you want. But, be careful, lots of sites, especially the large ones, have long and complicated, critical rendering paths. I recommend analysing a simple or a static page. I have included a couple of links in the instructor notes for you to try. Cool. And let me guess, you want us to post our diagrams on the forums? Uh-huh. Along with the three CRP metrics. You got it. And, don't forget to tell us what you're page you're actually analyzing. That sounds like fun. I can't wait to comparing CRP diagrams for all kinds of websites. Yeah, this will be a fun exercise. Also, in addition to analysing your own site, take a look at what other students have found, and, provide feedback. Good luck. So for my diagram project, I decided to look at the mobile version of reddit.com. And I started by opening up the HTML. This is a cleaned up version. Everything starts by requesting the HTML. When we receive, we immediately start building and parsing the DOM. In the head of the file, we find this CSS file, compact.css. So we fire off a request for it and continue parsing the DOM. In the next line down we find this script for Google Analytics but it's marked async so it's not part of the critical rendering path and we can ignore it for this exercise. Here we've requesting jQuery, so we fire off the request and block the parser. At this point the preload scanner kicks in, which looks down the HTML for other resources it can start downloading. It finds reddit-init.js in the header, and it finds another script, mobile.js in the body and immediately starts their downloads. When the CSS arrives, we build the CSSOM, which unblocks jQuery.js and reddit-init.js, which gets run right here. Then, we continue building the DOM. We'll then render the last job script file, mobile.js which we can actually find down inside the body of the script down here, which finally lets us render the page. Looking at the metrics of the page, this leaves us with five critical resources: the HTML, the CSS file, and the three Java script files. To find the number of critical bytes, we just need to add up the sizes of all of our critical resources. Which gives us 99.6 kilobites. And in the best case scenario, it's going to take five round trips to collect all the files that we need for the site. So, I guess you could sum up optimizing the critical rendering path, as having three main objectives. Reducing the number of critical bytes. Reducing the number of critical resources. And shortening the critical path length. Exactly, so your job is to make the critical rendering path as small and as short as possible. Definitely, okay so I'm going to go back and run my page through [UNKNOWN] again and this time I'll get some recommendations I can act on and I can't wait to start optimizing my site. Awesome, I'm glad to hear that. Web performance is a big topic and there's a lot more to learn. So when you go through PHP Insights, make sure you follow the links to learn about other things. It all adds up in the end. Are you ready to do the final project? Yeah, of course. Alright, now that we've taken the full tour through the critical rendering path, I think you've got all the tools you need to make. The site render as fast as possible, ideally in under one second. And Cameron's portfolio site needs a lot of work. If we run it through PageSpeed Insights, we see that it's scoring pretty low. As a final challenge, use what you've learned in this class to help me optimize my site. Your goal is to improve the PageSpeed Insight score above a 90. Right, and to do this you'll need to do a few things. First, fork the projects [UNKNOWN] repo. You can find a link to it in the instructor notes. Then analyze it using the techniques like drawing the critical rendering path diagram and diagnosing the. Protocol path metrics. Then apply the optimizations. And publish it on GitHub pages. If you're not familiar with GitHub, you can find some links in the instructor notes helping you fork the repo and publish your site on GitHub. Once you finish your optimizations. Run your new and improved portfolio through the PageSpeed Insights. You'll see all sorts of suggestions that should make some sense now, like optimized CSS delivery and removed render blocking JavaScript. When you think you've done all the optimization you can, post what changes you made on the forums along with the URL of your portfolio and the new PageSpeed Insights score. And while you're at it, why don't you make the portfolio page your own? You can use it to showcase the projects you're proud of. We've got a link in the instructor notes to help you out. Good luck. Okay, this exercise is definitely for bonus points. Let's say we want to transfer a 64 kilobyte file, over a new [UNKNOWN] connection. The round trip time is a 100 milliseconds. The Packet size is 1460 bytes. And the initial congestion window is 10 packets. How long would it take to download this file? Check the instructor notes below for a walk through on how to compute the answer. Good luck, this was a tricky one. Alright, let's see if we can make some sense of this. First, we convert 64 kilobytes into bytes by multiplying by 1,024 bytes, which is 65,536 bytes. Next we convert this number into the number of packets by dividing by the size of the packet, and that turns out to be approximately 45 packets. Next we can plug in the numbers that we have into the formula that we have here. We know that the roundtrip time is 100 milliseconds. We have 45 packets that we need to transfer, and the initial congestion window is 10 packets. Now, this actually simplifies to three, so what we actually have is 100 milliseconds times three, or approximately 300 milliseconds. But Ilia, I have a question for you. Why do these brackets look weird? This is actually the ceiling function, which means you need to round up the number to the next greatest integer once you figure out the answer to this log function. Oh, thank you. So, the final answer is 300 milliseconds, which is quite a bit of time. That's said, note that this is only true for new speed connections. Check the link in instructor notes for more details.