Welcome to introduction to relational data bases, relational data bases are one of the back end developer's most powerful tools. By the end of this course, you'll be able to organize and store your application's data in a relational data base. You'll practice the basics of SQL, the language for querying and populating databases, and you'll be able to write Python code to serve a web app backed by a data base. And to use the database as a tool for answering new questions. Let's talk about what we're going to in each lesson of this course. In the first lesson you'll learn some concepts about how we organize data in relational databases. In the second, you'll learn how to use SQL to fetch data out of a database, and insert new data into it. The third lesson will cover the Python database API, which lets you hook your Python code up to a database server, and you'll be adapting a web application to use a database. The fourth lesson will deal with defining new tables and performing more advanced queries. And finally we'll pull it altogether into a project using a database to plan a game tournament. When you've written code before, you've used data structures such as variables, lists, dictionaries, and objects. These all let you store information while your program is running. You can build up a complex data structure like a list of dictionaries of objects, and when your program exits, that structure will be gone from memory. You've probably worked with files, for instance, the files containing your own code. If you edit code in a text editor and save it, then quit the editor, your code doesn't vanish the way a variable does, when the program exits. The file is persistent, or durable, whereas in memory data is ephemeral, or temporary. Programs can read and write files just fine, so why bother with databases? Well, there are several different kinds of databases, but what they all have in common is that they give us both persistence, like a file, as well as data structures for storing and searching our data, usually much faster and easier than we could search a flat file. They also make it possible for multiple programs or users to access, and modify data at the same time without stepping on each other's toes, or accidentally undoing each other's changes. That's generally not possible with flat files. If two programs write a new version of a file at the same time, then one will overwrite the other. So these other sorts of databases do all that, but relational databases do even more. Aside from storing your data, relational databases also offer very flexible tools for querying and summarizing data. If we're doing comparisons, and if we're drawing connections between related pieces of information. They also let us set up constraints which are rules to ensure the changes to our data are consistent. We'll see more about those later in the course. Now, let's see how relational data bases store data. In a relational database, we store all our data in the form of tables. So, here's a table with some data in it. You probably already know how to answer a lot of questions using data and tables. Database tables aren't all that different from tables you might find in an infographic or reference book. Looking at a table like this, you can tell things like, say, the population of Brazil or the literacy rate in Argentina. So, even before we get into databases in any kind of detail, you can probably already answer some questions about how tables work. Don't worry about getting these questions right or wrong, but take a moment to think about your answers before we go on. So first, when we look across a row like this one, what do these values have in common? And second, when we look down a column like this one, what do the values there have in common? The more that I think about it, is that all of the values in a row, are part of the same sentence describing something. For instance, describing the country of Columbia. Columbia has a population of 47 million and the literacy rate of 94%. And all of the values in a column, are ones that have the same role or place, in different sentences. So, this number, describes about Brazil, the same sort of a fact, that this number describes about Colombia. They're both population figures, but for different countries. Here's another table. This one has some people's heights and weights in it. Each row of this table contains the same sort of data about a different person. As programmers, we're familiar with the idea of data types. A string, like Alan, is a different type from a numerical value like 188. But 188 is the same type as 72 even though they represent values with different meanings. One is a height in centimeters and the other is a weight in kilograms. Every column in a database table will have some type associated with it. All the values in that column will be of the same type, but moreover, they'll also have the same kind of meaning. We wouldn't mix centimeters and kilograms in the same column. The database system itself doesn't know which numbers are centimeters and which numbers are kilograms. We have to keep track of that for ourselves when we write code. Here's another example. Georgia is a string, a piece of text. But a string that represents the name of a country, like Georgia, does not have the same kind of a meaning as a string that represents a U.S. state, like Georgia, or the font Georgia, or someone's first name, like Georgia O'Keeffe. And the number 413 means something different if it's a hotel room number, or an amount of money, or the telephone area code for western Massachusetts. To think about this more clearly, let's have a quiz. Here are five pieces of data. Think about what type each of these is, and mark the check boxes next to two pieces of data that definitely have the same type. So 413 is some kind of numeric value, in Python or C we'd say it's int. In SQL, we'd use the whole word integer. Georgia here is a string, or a piece of text, we don't know which Georgia it means, but it's definitely a string. 15 comma negative 5 down here, that could be a pair of two numbers, or we could call it a geometric point, or 2D coordinates. Ursus arctos over here is a text string, that's the genus and species of brown bears, by the way. And 127.0.0.1 is an ip address, in some systems that might the same type as a number, but it can be treated very differently too. So Georgia and ursus arctos are both strings. They don't have the same sort of meaning, but they definitely have the same type. Let's now think about the meaning of data as distinct from its type. Here are four pieces of data. All of them have the same type. They are all strings. Jones. Tanaka. Mary J Washington. And Muller. But which one does not have the same kind of meaning as the others? So, Jones, Tanaka and Muller are all family names. I got them from a database, of common family names in different countries. Jones is one of the most common family names in the U.S. and in England, and Wales. Tanaka is one of the most common family names in Japan. And Muller, is one of the most common family names in Germany and Austria. But Mary J.Washington, isn't a family name, it's a person's full name. We wouldn't expect to see a single database column, that held full names for some rows, and just family names for other rows. So Mary J.Washington is the correct answer. So here we've seen that when we think about pieces of data that might be in a database, we have to think not only about their type, but also their meaning, what they represent in the real world. Oh, hey there. well, it would be a lot easier to keep track of all these animals, if we had a database of them. You know, I'll bet real zoo's do that too. Keep records of all of the animals that live there, and what they need to eat, and so on. And if they're not using a relational database for that, well, I think they should. So, let's see how they might do that. This table is about individual animals that live at a particular zoo. The first row says that the zoo has a gorilla named Max, who was born on April 13th of 2001. That's three pieces of data that are all related, and that there all about the same gorilla. Every row has three pieces of data fitting the same pattern. Notice that it's totally possible for two animals to have the same name. Max the gorilla isn't the same animal as Max the moose. When we create a table in a database, we'll give the table a name. This one's named animals. The name of the table and the names and types of the columns, make up what's called the table header. These aren't values in the table, they just tell us what the data in the table means. The body of the table consists of any number of rows, and each row contains a value for each column. Let's see a little more of the table and do a bit of a quiz. Okay, so using the data in this animals table, try answering these questions. If you don't think a question can be answered using the data in this table, leave it blank. So to answer the first question, we need to look for the birth date column, in the row that talks about Max the Moose, not Max the Gorilla though. And there it is. Max the Moose was born on February 20th, 2012. Next we want to know if there were any llamas born between 1995 and 1998. Well here are all the animals whose species is llama. And we can scan through these, to see if any of the birth dates are between those years. And sure enough, here's Alison. So the answer is yes. Number three, which gorilla was George's mother? Nothing in this table tells us anything about the family relationships between gorillas or any of the other animals. So we can't tell which gorilla was George's mother. You might guess that it was Sue, but we don't know, so this should be left blank. And finally, how many gorillas are there? This question's a little bit trickier. Obviously as humans we can answer this question just by counting rows. But in turns out that a database can do that too. Whenever we look for an answer that combines the values from several rows. Whether by counting them, or adding up numerical values, or finding the average, we're doing what's called an aggregation. Counting is about the simplest aggregation there is, and in this case the answer is there are three gorillas. So in the last quiz, you saw one example of an aggregation, a database operation that summarises multiple rows into a single row. Counting up the number of gorillas in the animals table, was a count aggregation. It takes several rows, each representing one gorilla, and turns them into one gorilla representing the count. Any time we want to compute a single result from a set of values, that's an aggregation. Here are some of the most common aggregation functions in SQL. Count is different from the other ones, in that it takes values of any type, and returns a number. Most of the other aggregations only work on numbers. For instance, you can't the average of a column of string values, because only numbers have an average. We'll see a lot more about aggregations in the next lesson. Earlier, I told you that database tables were a lot like the tables you might see in an infographic or a reference book. There are some differences though. One of these is important when there are multiple answers to a question, which will often be the case just before we use a count or another aggregation. This table is about animals and what they eat. Unlike some tables we've seen before, this one sometimes has the same value in some of the cells with different values over here. This is how we say things like brown bears eat fish and meat and plants in a database table. We split that sentence out into multiple sentences, which make multiple rows in the table. Why don't we just make multiple columns or put several values in one column separated with commas or something? There are lots of reasons not to do that. If we tried using multiple columns for the different foods each animal eats, we wouldn't know how many columns to make in advance. Some animals do eat a lot more kinds of foods than others after all. And what's more, we want to be able to use counts and other aggregations. And those will only work if we have our data separated out into rows, not jammed together. Now let's take a look at a real database query against this table. Select food from diet where species equals orangutan. This looks almost like ordinary English, but this is actually an SQL database query. It's asking the database to return particular data from the diet table. In a moment, we'll run this query using an actual database. But before we do, can you figure out which rows and which columns from this table it will return? So, here's what's going on in this query. Select means that we are fetching data out of the database rather than inserting or updating rows or doing something else. The next thing we see is food. That's the set of columns. In this case, just one column that we want to see in the result. So, that's the answer to which columns we want. >From diet just says what table we're talking about. Here, it's just one table. And where species equals orangutan is called a restriction. It says what rows we want. Specifically we want the rows, where species has the value orangutan, which means we want these two rows. Now that we've seen some sorts of information that we can store in a database table, let's talk about how our code talks to a database. When our code fetches data out of a database it does this by sending a query, in response, the database will send us a result containing a new table with the data that we asked for. Depending on the specifics of our environment our code might be talking to the database over the network, or it might just be calling a library that keeps a database on local disk. Those design details would be important later but for now we can actually ignore them. The basics of databases work the same no matter what the implementation is. So let's take a look at running some queries in SQL against an actual database. Don't worry about the syntax right now, we'll see that in the next lesson. Okay, so here's a query we saw before, select food from diet where species equals orangutan. And when we run it, here is the result. Now, something to notice about the result is that it's a table. It has two rows, even says two rows down underneath the table, and it has one column, the food column that we asked for. So running a query against the database isn't like returning a single value from a function, it's more like returning a list, even if there might only be one element. In fact, even if we ask the database for 2 plus 2 like this. The answer is still actually a table with one column and one row. If we ask the database for the answers to three arithmetic problems at once then we'll get back a table with a single row and three columns, each one of them giving one of the answers. You might have noticed that these columns have rather unusual names, they all are question marks column question mark. If we want to give them more descriptive names we can do that, by using as sum here we get back still a table still with one row and one column, but now the column has a more descriptive name of sum instead of question mark column, question mark. Okay. Well, here's a hard problem. Which of all of these animals is the cutest? The bear, or the tiger, or the porcupine fish, or the mantis shrimp? Everybody's got a different opinion. Have you ever seen the website, kittenwar.com? It's a site where people can upload pictures of their cats, and then vote on which kitten is the cutest. Well, why don't we do the same thing for these zoo animals? Let's take a look at what a database for that might look like. So a database, will usually have several tables in it. Here's how we might start for our image voting app. The first table represents pictures that people have uploaded of animals. The second represents people's votes. Fluffy, Monster, and George are all animals, whose pictures someone has uploaded. Because, we might have two animals with the same name. We give each one a numeric id here. The pictures tables says that Fluffy has id 1. Monster has id 2. George has id 3. And so on. The votes table says, which images have been displayed together for voting, and which one the user picked as the cutest. Here, the app displayed monster, ID 2, and George, ID 3, and the user voted for George. 2 and 3 were matched up, and 3 was the winner. Note that in the votes table, the columns are called left, right, and winner. But they match up, to the column called id in the pictures table. You can read every row as a sentence. In the pictures table, the sentences say Fluffy has id number 1, and the filename fluffsocute.jpg, Monster has id number 2, and filename monstie-basket.png and so forth. In the votes table, the sentences are picture 2 and picture 3, were displayed and the user voted for picture 3. Picture 1 and picture 3 were displayed, and the user voted for picture 1 and so on. So this 3 and this 3, refer to the same thing, a cute critter with id number 3. But they're in different tables, and the columns have different names, because they play different roles in different sentences. Over here we're saying, which picture has which id? And over here we're saying, which ones have been displayed together, and who got the vote? So this is the kind of sentence that this table actually represents. If you wanted to come up with sentences like Monster was shown to Fluffy, and Fluffy got the vote instead of 2 was shown with 1, and 1 got the vote for this row here. We would have to connect rows from this table, with rows from that table. That's something we can do with a database query as well. Queries that do this are called joins, and we'll be seeing a lot of them later on in the course. For now, just remember that a value with the same meaning, can occur in different tables and have different column names, and that we can derive new tables by linking up existing tables using joins. In a lot of databases, we're talking about unique entities out in the world, like individual people or locations, or email accounts, cities, or gorillas. If something is unique, there can't be two of them. So for instance, names aren't unique, not even full names. There are a lot of people in the world named Jennifer Smith. But a particular person named Jennifer Smith is still a unique individual. You wouldn't want to give one person another person's grades, or their parking tickets, just because they share the same name. Whenever we want to unambiguously relate a row of one table to a row of another, to see they are about the same person or thing out in the world. We have to have a unique value to talk about that thing. In the cutest animals database, we used a numerical ID for each animal picture, which we used to relate the votes table to it. That's a pretty common choice. Just make up a unique number for your database. It's so common that most database systems can do it for you. User IDs, comment IDs on forums and so on, are all examples of this. In database terminology, a column and a table that uniquely identifies rows on that table, can be called a primary key. Sometimes the world gives us a natural primary key for a table. For instance, if you have a table of countries and their capital cities, you can be confident that there aren't two countries named France. So in that case, you can safely use the name of the country as a key. You don't have to call it country number 29. But you have to make sure that a key really is unique. For instance, in the US, there are several states with a city named Springfield. There's Springfield, Massachusetts, Springfield, Illinois, and a whole bunch of others. So it's obvious that the name Springfield isn't unique by itself. Now, you might be tempted to think that city plus state is unique, but it turns out that that's not true either. In the state of Wisconsin, there are five different towns named Springfield, and there are three in New Jersey, and two in Texas. Doh! And that's why most countries use postal codes, or what we call zip codes in the US. Just like saying that somebody is player number three or user 1,723, instead of using their name. Using a made up number like 54028, or 54659, instead of Springfield, Wisconsin, guarantees uniqueness. Let's think about uniqueness. Imagine you're creating a database to track students grades in a college course. Which of these pieces of data would be valid choices for a primary key, in the student's table. Mark every choice that could used to uniquely identify students, not just the one you think would be the best choice. A college-issued ID number is a good example of a primary key. It's a unique identifier that somebody has issued for just this purpose. As long as everyone in the course is an enrolled student, they will have a unique ID. Home mailing address is not a valid primary key. What would happen if you had two students taking the course who live in the same house? Students' email address might be an okay primary key. College students don't share email addresses with each other, so this is a correct choice. But it isn't a great primary key though, because people sometimes change their email addresses and that can be annoying to work around in your application. Date of birth is not a valid primary key. There's a famous math example called the birthday problem that proves that you only need 23 people in a room to have a 50/50 chance of two people in the room sharing a birthday. Also, college students are frequently around the same age, so there's a good chance that two students will share the same date of birth. In any event, a primary key shouldn't just be maybe unique. It has to be definitely unique. Finally, driver's license numbers are unique, at least if you also include what state or country the driver's license is from. The problem with this though, is that not everyone has a driver's license. Some people don't drive. And so, some students could have no value at all for this column and that would make it not a valid primary key Okay, so let's go back to the zoo with the gorillas and llamas. Remember these tables? In this one, we have animals' names, species and birthdates. In this other one, we have species and the foods that they eat. Suppose that we wanted to find out, how many individual animals eat fish. Well, that's a how many question. So we'd need a count aggregation, but, what are we aggregating? The animals table doesn't talk about food and the food table doesn't say how many of each species we have. But suppose that we could get a table that added the food column, to the animals table. Then we would have something that we could count up. We saw earlier that we can derive a new result table from existing tables by doing a join between those tables. That will give us something like this. Select animals.name, animals.species, diet.food from animals join diet, on animals.species equals diet.species. But we just want the animals that eat fish. We saw earlier, that we can ask the database for just rows matching a particular criterion, with a row restriction like this one. The same query, but now it ends with, where food equals fish. So to answer the question, how many individual animals eat fish? Our query will have to do three things. First, it will join animals with diet, using species as the match. Then, it will do a restriction, selecting only rows where food equals fish. And finally, we'll do an aggregation to count the rows, something to think about, how many rows will be in each of these tables? Just as the tables are related to each other, so too are the row counts. Let's imagine that we have 100 animals in the zoo and that the final answer that we get from our query, is that 20 of them eat fish. Remember that every result we get back from a database query, is a table. That includes the result of this count aggregation. The count table has just one row and one column and it contains the number 20. Well that means that the result of filtering for food equals fish. Must have had 20 rows. Now we don't actually know how many rows this join has, but it's got to be at least 100 rows, since each animal, eats at least one kind of food. But some animals eat more than one, like bears which eat fish, and meat, and fruit, too. And we don't know how many rows the diet table has, but it'll be at least as many as the number of distinct species in the animals table. Again, that's because each species, eats at least one kind of food. Okay, let's do a quiz. Our zoo, it turns out, needs a database to keep track of all the people who have donated money to the zoo. One of our programmers has come up with an object oriented description of a donor class. It has attributes for a person's name, and their favorite animal, and their phone numbers. That way for instance, when there's a new born baby gorilla in the zoo, the zoo keepers can call Mary up, and tell her about it. For phone numbers, a person might have more than one. So we'll support home and mobile, and work phone numbers. So if we want to store this information in a relational database, instead of just in objects in memory, how many tables do you think we'll need? Oh, wait, not that kind of tables. This kind of table. Because a person can have more than one phone number, we're going to want to have one table for donors, and one for donor's phone numbers. This is the same sort of situation, as when we had animals that eat multiple different kinds of food. Now, what's going to go in these tables? First, what columns do you think might go in these tables? And second, how would you represent Mary and her two phone numbers in these columns? Fill in the column names in the top of each table, and then the values that you'd put in them in the table body. Okay, so the first thing we're going to need is an ID column, because nothing else here is unique. We'll relate donors to their phone numbers, using the donor's ID. The ID is arbitrary, as long as the one here equals the one down here, but we'll just put 1, because Mary is the first donor. The second thing we know about a donor is their name. And we know their favorite animal. Now, Mary has two phones, so there will be two rows in donor phones with Mary's id in them. And Mary has two kinds of phone, one is a home phone and one is a mobile. We'll call that column phone type. And finally we know Mary's phone numbers. So there you have it, you've taken all the data from this object oriented record and structured it into database tables. In this lesson, you've learned a lot of concepts that we'll be applying in this course. Concepts about structuring data into tables, extracting data that we want, counting rows with aggregations and linking tables together using primary keys and joins. In the next lesson, you'll apply these concepts using SQL, sending queries to a live database server and interpreting the results. See you then. I don't remember what this elephant is here for, but she remembers why we're here. In this lesson, we're going to jump right into something practical. You've seen a few database queries in SQL last lesson, but now it's time to start talking to a live database. Here's how this is going to work, I'll show you how you can write SQL queries right in your browser using our zoo database. Then we'll explore some of the different things that you can do with SQL. Also, if you're allergic to all these animals, don't worry, the next lesson will be zoo-free. Databases aren't just for zoo animals, after all. Just ahead in this lesson we're going to see an interface like this. This is just the audacity code editor. And here's just a python source code file containing a SQL query. You can put anything you like in this query variable here. And when you press the test run button your query will run on the zoo database. If the database understands your query, it will give you back a table. Just go ahead and try it. We'll be doing a lot of these in the rest of this course. So, check out the results we got. You know, my ASCII art isn't the greatest, but you can see here that this part is the table header with the names of the result columns. And down here is the data. And speaking of data, next up, let's talk about data types in SQL. You saw a lot of examples of data types in lesson one. It may come as no surprise that data types are kind of complicated in SQL. Types in SQL often have different names from types in Python or other languages. And sometimes, there are distinctions made in SQL that other languages don't make. We'll be working with only a few of these types in this course though. For a whole bunch more types and links to some documentation with even more types, see the next page. SQL has several different string types. In this course, we'll just use the text type, which is basically the same as a Python string. Same goes for numbers. SQL has number types for many different purposes. But in this course, we'll mainly be using the integer type, which is roughly the same as Python's int. And how about our animals' birth dates? SQL has date and time types as well. We'll be using date columns for birth dates since we don't care about the time of day. One thing that's really important to keep in mind about date and time values in SQL is that you have to put single quotes around them as if they were strings. If you write 2012-11-23 inside single quotes, SQL can interpret that as a date or as a piece of text. But if you write 2012-11-23 with no quotes around it, it can only interpret it as an integer expression. It will think you mean 2,012 minus 11 minus 23, which equals 1,978, which is probably not what you wanted. So here's the same query you saw earlier. Now let's break it down a little bit. Like we saw before, whenever we want to fetch data out of the database, we'll begin our query with the keyword select. Then we say, which columns we want to see in the result? And then what tables they're going to come from? Then we have this where thing at the end. That's the restriction, and it says what kind of rows we want to see. Here, we only want to see rows where the species is gorilla, but what if we want to restrict on more than one thing? We can do that. SQL supports the boolean and. Just like python does. If we want to find out the birth date of Max the gorilla, we can do it like this. SQL also supports the or and not operators, also like in python. So given what we've just seen, how might we find the names of all of the animals that are not gorillas, and are not named Max? Try that on the next page. So we wanted to find all of the animals that are not gorillas and also not named Max. So we could do it this way. Select name from animals where not species equals gorilla, and not name equals Max. Or here's another way we can do it. There's a logic rule called Demorgans law, that lets us switch not X and not Y into not X or Y. So we can say select name from animals where not parenthesis species equals gorilla or name equals max. That will do the same thing. Or hey, here's a third way. SQL supports the not equals or bang equals operator, just like python does. So we can say, select name from animals, where species not equals gorilla, and name not equals Max. Any one of those three will work just fine. They'll all produce the same results. So we can do restrictions other than just equals and not equals. All of these comparison operators work pretty much the same in SQL as they do in Python. Equals, less than, greater than, less than or equal to, greater than or equal to, and not equal to. And here's one of the questions we answered manually by looking at a table in lesson one. On the next page see if you can figure out how to get the database to do if for you. Make sure to fetch the name column, so we can make sure we got the right animals. And remember to put single quotes around dates, since we don't want the database to treat them as arithmetic. So here is the question you were asked to answer, and here is one possible answer. Select name from animals where species equals llama, and birthdate is greater than or equal to the beginning of 1995, January 1, 1995. And birthdate is less than or equal to December 31, 1998. So, just as when you did this manually, your query should have found one llama, Allison the llama. Now we can have the database find our llamas for us, instead of doing it by hand. This is a pretty big help if we have lots and lots of llamas. There are a bunch of different tables in our zoo database. I'd like to just have the database tell you about them, but weirdly enough, there isn't one standard way to do that in SQL. If you want to know what tables are in a database, or what columns are in a table, well, each database system supports doing that, but they all do it in different ways. And in most of them, you can't do any of these from your code itself, only from the database console, or special administrative software. Yeah, that kind of sucks. It's as if SQL was designed back in the days when you had to plan out your whole application with flowcharts and stuff, before you were allowed to touch a computer and ask it any questions. Oh wait, it was. So in order to save you a bunch of time and frustration, I've put a list of all the tables in our zoo database, in the instructor notes below. You might want to copy that, and put it somewhere you can easily read it while you do the rest of this lesson. Okay. Now that you've got a list of all of their tables and all of their columns, I want to give you a chance to mess around with them. On the next page, you can run whatever queries you like, using the zoo database. You'll see a bunch of queries commented out in the editor. Try uncommenting each of them and running it. Some of them use features you haven't seen yet. Try to figure out what each of those features does. There's no right or wrong here, whatever you put in the query variable will run against the database, when you press test run, and you'll see the results. Once you go on to the next page feel free to bookmark it, so you can come back later, any time you want to test out some SQL syntax. Once you're done use the submit button to move on. So did you try out all those different queries? If you did, you've seen several modifiers that you can put on select statements, these are called select clauses. Where is one of them too. Limit offset is what you'd use if you wanted to make several pages of results, it takes two numbers. The limit number tells how many results go on one page, and the offset, tells how far into the results to start. So if you wanted ten rows from your table starting with the 151st row, you'd use limit 10 offset 150. Another clause is order by, order by lets you say how you'd like your results to be sorted. That'll usually be by one or more columns. If you want them sorted from the largest to the smallest, that is, in descending order, then you add desc to the end, for descending. So if you wanted to do a query against the animals table sorted first by species. And then within each species by name, you'd say, order by species, name. A clause that works a little bit differently is group by. You'll only ever use it with aggregations like count, or sum. What group by does is to say instead of aggregating over all the rows, just aggregate the ones that share some column value. LIke if you wanted to find out how common different names are in the zoo, you might do this. Here we use as, to give the count column a name. Here the name is num. So here's a quiz. Here are three different situations. Find the ten oldest gorillas. List all the animals, in alphabetical order, ten per page. And find out which one species we have the most animals of. For each of these situations, which ones of these select clauses would you use? Where, limit, offset, order by, or group by. Check all of the boxes that fit. So we have these three different situations. For the first one find the ten oldest gorillas. Well, we're going to need, where, in order to select out only gorillas. We're going to need to find the oldest, so means we need to put them in order by their birthdates. And we want to find the top ten so that's going to be a limit. For the second one, list all the animals in alphabetical order, ten per page. We're listing all of the animals, not some of them. So we, don't actually need where on this query. We're listing them in alphabetical order though, so we're going to need order by. Since we want to get them ten per page, we're going to need limit and offset to put them into separate pages. For the third situation, find out which one species we have the most of. First we're going to need group by, to bin all the animals by species using account aggregation. Then we're going to need order by, to sort by the result of that count, and limit to get just the top one. There's actually another way to do this using a different SQL feature called subselects, but with what you've seen so far, this is how to do it. A lot of folks when they hear about SQL features like order by, or limit and offset, ask the question, why do that in the database? I already know how to sort a list in Python, and I already know how to do slices. Why don't I just fetch the data back to my application code unsorted, and do the work there? And it's true that count is an awful lot like length. And limit 100 offset ten is an awful lot like taking a slice from elements ten to a 110 of the result list. And order by column is an awful lot like, sorting by a a key that's actually kind of complicated, but there are a couple of big differences. Speed and space. The database can generally do these things a lot faster than Python can. Especially when you get to tables with lots of rows or complicated queues that join several tables. And you can easily have a table with millions of rows, sorting a million items in Python can take around a second. If you're writing a web app, that's a second that you're user is staring at their browser, wondering why your app is so freaking slow, and it's taking up memory to do that too. In contrast, a database can generally do these operations much faster. There are a number of tricks you can use to make it faster still. The big one is called indexing. We won't deal with indexing directly in this course, but later on there will be some notes on how to apply it. In any event, doing restrictions and aggregations in the database, instead of in Python, is a good practice to get in to. So let's do more of that. In the last quiz, you figured out which select clauses you'd need to do some particular queries. Now let's do one of those queries in SQL. It's time to take attendance at the zoo. We need to know how many of each species we have, and it would be a big help if we had the most popular species listed first. Because, they'll take the most time for the zookeepers to count. We've put a cheat sheet of all the select clauses we've seen so far, in the instructor notes below the editor on the next page. But, you have to put them together correctly, into a query that makes sense. Feel free to take a few tries, using the test round button. You'll see the result table down below. When you've got it, press Submit, and your query will be tested against a larger database. So here's the problem. Write a query that returns all the species in the zoo, and how many animals of each species there are, sorted with the most populous species at the top. And here's an example, if the zoo had 4 gorillas, 2 alpaca, 1 brown bear and no other animals, then we'd get a result like this. So here is the question again. We're trying to write a query that returns all the species in the zoo, along with their populations. And here is one possible answer. Select count of star as num, species from animals. Group by species. Order by num descending, or desc for short. And here's what's going on in that query. Count star as num, and species are the columns that we want to return. Animals is the table that we're going to select from. We're aggregating by species and aggregation is the count. And then we're ordering, by that count column num descending. By answering this quiz, we've put together the count aggregation, grouping and ordering. The query for this exercise did not require the where clause at all, because we didn't want to exclude any rows from the census. Happy birthday! The zoo has some new-born baby possums. Let's add them to the database. To do that, we need a different SQL statement, the insert statement. Insert adds a row to a table. When you write an insert, you tell the database, what values to put into the columns of that table. If the new values aren't in the same order, as the table's columns,. Then you also have to tell it what columns they go into. On the next page, you'll see two queries in the editor. One of them is the select query and the other is an insert. Your job is to fill in the second query, with the right insert statement. When you press the test run or submit button, you'll see the results of the select before the insert, and then the results after the insert. And here's what we'd like to do. Find the opossums that are already in the table, and add the newborn opossum to the table. So this is one possible answer. Insert into animals values wibble, which is just the name I gave the possum. You can call it whatever you like. The species, and then the birthdate. Here's another option, we could explicitly say what columns we're inserting into. Even though these are in the same order, it's still okay to do this. And by the way, that's pretty much all there is to the insert statement. It's a lot simpler than the select statement. Select queries can express arbitrary complicated searches and aggregations of data, but inserts are just add this row to this table. Holy wow, that's a lot of fish. Fortunately, we've got a lot of animals that eat fish. We talked about that briefly in lesson one, but now we can put together an actual query to find them. See if we can put it together without looking back there. Trouble is, the animals table tells us nothing about what each individual animal eats, and the diet table doesn't list any individual animals. It only lists their species. Wait a minute though. That species column is in both of those tables. That means it must be join time. So, if we join animals against diet, we should be to get the answer that we're looking for. Now, we saw one syntax for joins in lesson one, but it turns out there's also a shortcut syntax we can use here. The shortcut syntax won't actually use the word join when it lists the joined tables, but this form is actually probably more common in real code. If we want to join two tables to match up rows where the column target in table T equals the column match in table S, we can do it like this. So on the next page, write a query to answer this problem. You can use either kind of join, but your query should only return the name column, not the species or the word fish itself. So here is one possible answer, using the older join format. Select animal set name, from animals join diet, on animals.species equals diet.species, where food equals fish. And here's one using the new simple join syntax. Select name, from animals comma diet. Where animals.species equals diet.species. And, diet.food equals fish. So here, not only do we find all of the fish eating animals. We also found out that the columns that you use in a join, in either form, don't actually have to be among the columns that you asked for in the query result. Which species does the zoo have only one of? That seems like a pretty straightforward question, but it turns out that you can't answer it like this. The reason is that where, applies to the rows of the underlying table before count is performed. There's no nom column in the animals table. And you can't use where after a group by anyway. If you tried this query out, you'd get a big error, but if we change just one word, we can make this right, whereas where filters the source table, animals, having filters the result table. So having applies after the group BI aggregation. And we'll get the right answer. Again, there is another way of answering this question, using a more complicated sort of query called a subselect. But this is the easy way to do it. So now for a different sort of question and a quiz. Which food is eaten by only one animal? Not just by one species, but only one individual animal in the whole zoo? To answer this, you'll have to use both the having clause, and a join that we've seen before. So for this question there was just one answer. The unusual food, was snakes. The zoo has only one animal, that eats snakes and that's our mongoose, Ricky. And that's a good thing too, because we've got some python, coming up in the next lesson, and we wouldn't want it to be eaten up by a bunch of mongooses. Or is it mongeese? Or mongosslings? Okay, so here are two other tables in the zoo database. The first one, taxonomy, gives the scientific names for all our animal species. We've been using the common names like brown bear in our other tables. This table gives not quite the full taxonomic name but a lot of it. The brown bear is genus Ursus. Species arctos. And the family Ursidae. And the oder Carnivora. We have to call this column t_order instead of order, because order is a reserved word in SQL for order buy. The t is for taxonomy. And if we look in this table over here, we'll see the common names for all of the orders. Bats belong in the order Chiroptera and lizards and snakes belong to the order Squamata. and llamas and moose and warthogs all belong to the order Artiodactyla. Okay, okay, so really these tables are just here to give you more stuff to join. Big surprise. This time we want to find out which orders have the most individual animals in the zoo, and we want to give their common names like monotremes, instead of their scientific names like monotremata. So you'll probably need to use both of those tables, the taxonomy and the order names table, plus the animals table with the individual animals in it. So the problem is, to list the taxonomic orders by their common names, sorted by how many individual animals we have of each order in the zoo. To see the full schemas the tables, take a look at the instructor notes. Okay, so if you look at the top of your table, you'll see that we have even more even toed ungulates or tridactyla than any other order. Even the carnivores don't come close. And if you scroll way down to the bottom of the output you saw, now the dolphins and whales. And what exactly is a narwhal doing in a zoo anyway? Wow, that was a lot of stuff, and too many animals. Next lesson, we'll get out of the zoo and get back on the web, without bringing any exotic spiders with us. In this lesson, you've seen the basics of two SQL statements, select for fetching data from the database, and insert for adding rows to the database. You've applied joins and aggregations to answer a variety of questions. In lesson three, you'll be connecting your database powers to your python programming skills, by adapting an existing web service to use a back end database. You're going to be running that service on your own computer. So before we go on, you'll need to download the database software, and an environment to run it in. I've put a link about how to do that, in the instructor notes below. Once you have that software downloaded and installed, I'll see you again in less than three. Welcome back, in this lesson you'll learn how to connect Python code into an SQL database. You'll be running a miniature web forum on your own machine, and adapting it's code to use a database backend. Then you'll be finding and fixing some of the most common and serious bugs, affecting database backed web applications, and fixing the damage that they can cause to your database. By the end of this lesson, you'll know not only how to use SQL from Python, but how to use it in a way that's secure and reliable. Let's get to it. So far in this course, when you've written SQL queries in the web-based editor, we've hidden away the mechanism that actually connects to a database and runs your queries. Some place back here, there's actually a database running those queries. Now let's open up this box and see how it actually works. Behind our web server, we're running Python code that connects to a SQLite database using DB-API calls. The Python DB-API isn't the library. It's a standard for Python libraries that lets your code connect to databases. There are dozens of different libraries for different database systems that follow this standard. The standard specifies what functions you'll call to connect to a database, to send queries, and to get results. So, if you learn the DB-API functions, you can apply that knowledge with any database system. Although the details of what each database can do are different, adapting Python code from one to another is quite straightforward. But each database system has its own library. And as you can see, some of the library names are a little bit different from the names of the database systems that we work with. For exercises in the browser, we use the sqlite3 library. When you run database code on your own machine for this course though, you'll be using the psycopg2 library, which lets your code talk to the PostgreSQL database. Here's an example of a Python program that uses a DB-API Library to query a database. Everytime you use DB-API from your code, you're going to have the following steps. First, we have import sqlite3, that's the library for the database we're using. If we were using postgreSQL here, we would import psyco-pg instead. Next, connect to the database. The string cookies here, is the name of the database to connect to. Yes, there's a reason I've put the name cookies in this example. I'll tell you at the end of the video, I promise. If you were using a database system over a network, instead you might have to specify the host name, username, password and other information here. The connect function returns a connection object, which is good until you close that connection. Next, your code will make an object called a cursor. The cursor is what actually runs queries and fetches results. It's called a cursor because when the database gives you results. You use the cursor to scan through the results, kind of like a text cursor in an editor. You can see here that we execute a query using a cursor, and then fetch all the results from that query also using the cursor. Another possibility is to fetch the results one at a time using the fetchone method on cursors. Now, if you were doing an insert query instead of a select, you'd need to commit the insertion here, or if something went wrong, roll back. Same if you were doing some other query that changes the database. Commit and roll back are methods on connection. In this case, we're doing a select, so we don't need to. I'll tell you more about commits and roll backs a little later, along with doing inserts and DBAPI. Finally, when you're done, you close the connection. It's important to always close connections when we're done with them, especially if this code were running inside of a loop. We wouldn't want to have a bunch of stale connections sitting around, taking up resources. By the way, I mentioned that cookies here isn't just to be silly. If you were to run this exact code against the cookies file from a Chrome web browser, it would tell you some of the web servers you have cookies from. Both Chrome and Firefox use an SQLite database to store cookies and web history. So, let's take a look at some DB-API code in the editor. On the next page, you'll see a short Python script that fetches student records out of our pretend database. When you go to the next page, try running that code as it is with the test run button. Then look through the results printed out below. This will give you some more idea of what the various functions in the DB-API do and of how the DB-API returns data to your Python code. When you're done with that, I'd like you to make one change. Make the script sort the student records alphabetically by the students' name. So, the SQL change there was small, but significant. Add order by name to the query. I hope that looking at this code and what it printed out, gave you a better idea of how the DB-API works. When you want to insert data into a table from your code, there's one more step you have to do after executing your insert queries. You have to commit your changes to the database. Why do we have this extra step? Well imagine that we were writing an accounting system. And we wanting to debit some money out of one account, and credit it to another account. That might even be changes to two different tables. But, we want them both to take affect at the same time, or if something goes wrong, we would want neither to take affect. And if some other user was accessing the database at the same time that we were, we wouldn't ever want them to see one change and not the other. This is one of the big ideas of databases. When we make changes such as inserts, they go into what's called a transaction in the database. When we call commit, the transaction actually takes effect. If we close the connection without committing, our changes will get rolled back. On the next page, there's some python code that tries to insert a row into a table, but it doesn't commit. It then reconnects and tries to find that row, but that row has been rolled back. Try running the code as it is, and then add the commit call in the right place to make the changes get saved. So the right place to put the commit, is immediately after the execute in this particular code. By adding commit, you can make sure that your changes get saved. By the way, one nice thing about transactions and rollbacks, is that if your code crashes in the middle of a database transaction, you can be sure that it won't have written half-finished changes. This is an important database principle called atomicity. Atomicity means that either a change happens as a whole, atomically or it happens not at all. On the next page, we'll be switching gears a bit. Remember that software I asked you to install at the end of Lesson two? I hope it hasn't had time to get dusty, because you're going to use that next. For the rest of this lesson, you are going to be working on Python code that should already be in the forum sub-directory of your vagrant directory. You can edit this code with your favorite text editor on your computer, and when you save it, those changes will be visible from inside the virtual machine. So, what is this code? It's a web forum, just not a very good one yet. You could run it like any Python program from the command line. And once it starts up, it'll tell you it's listening on port 8000 and then you can access it at http://localhost:8000 in your web browser. And when you do, you'll see something like this. Hm, it's pretty empty. Let's put some posts in it. Now, if we go back to our terminal, and kill the web server with Ctrl C, and then restart it and go back to the web browser and reload all our posts are gone. What's going on there? Now, if we look over in the source code for this module that forum.py is using, we'll, see, it's not actually using a database at all. It's faking it with plain old variables which go away when the program exits. So for the next few exercises, you're going to be adapting this code to use a database to make posts persistent. First off, let's say hello to the database system that we're going to use, PostgreSQL. The post crest ql database server, has already been installed on your virtual machine. The psql program, lets you log into the database and do queries interactively. Here, let's look at the database for the forum. If you're on psql forum, look at a database prompt like this. Now you can run select statements like this one, and that's something we saw back in lesson one actually. But, how about this. Okay huh, looks like an empty table, zero rows. Yeah, your VM came with an empty table, for you to connect the forum app too. That's just because we're not covering creating new tables until the next lesson. Now if we look at what types these columns are, it looks like, content is text. Time is some sort of time stamp, and ID is an integer, plus something weird. We'll see more about that later on. For right now, the ones of these that we really need to focus on, are content and time. We'll use the text column, content to store the contents of user's forum posts. And we'll use the time column to store the time they posted, so we can put them in order with the most recent first. You can press q to go back to the psql prompt. Now let's dig into the forum code and do it. So, here we are in the text editor working on forum.py. We've got some HTML down here, and we've got some web server code down here, and back up at the top it looks like there's actually another module, forumdb, for the database code. So if we look over at forumDB.py, we'll actually see rather a lack of database code. It looks like we're currently using just a Python list to store the posts. No wonder they went away when we restarted the server. So this AddPost function, inserts a topple into our database list. And the GetAllPosts function, transforms the list into a list of dictionaries. Where the content key points to the post content. And the time key points to the time it was posted. Over in forum.py, if we look in the view function, we'll see where forumdb.GetAllPosts is called. And then down in the post function, we'll see where AddPost is called. We don't need to edit any of the forum.py code, because everything that talks about the database is over in forum.db. So what we need to do is change this database code up here, to actually use a real database. So on the next page, you're going to do exactly that. So, here's one approach to fixing up this code that you might have taken. This code here actually has a bad bug that we'll be looking into next. So, please don't go copying this into all your production apps. So, whenever we want to read or write to database, we first connect to it. Then establish a cursor. Then we do an execute. In the case of GetAllPosts, we execute a SELECT statement. And then we fetch all the results and reformat them into the dictionary that our code expects. And of course, we close the connection and return the posts. In the case of AddPost, we still connect to the database just the same. We execute an INSERT query, substituting in the post content into the query string. Commit the change and close. Now, this seems to work, but I did just say this has a bad bug, and we're going to see that right up ahead. Now in adapting our form DB code to use a real database, you might have written something that looks a lot like this. In the get all posts function, you connect to a database, make a cursor, execute a SELECT statement, format the results appropriately, close the connection return the posts. But then to add a post, connect to the database, make a cursor. Execute an INSERT that substitutes in the post content, commit that to the database and close. Now, this looks good, but it isn't quite. If you're writing a bunch of different forum app. Are there any posts that don't seem to work quite right? Say what? Wait a minute. That looked like a perfectly good post. Why are we getting this weird error from it? Let's go back to our terminal. Oh, look at this. We have a trace back from python. It says programming error. Syntax error at or near t. And there's out INSERT statement VALUES. I can't find a problem. Let's look back at the code. So, here's where the post content, gets sent to the database. It just gets added into a SQL statement. Inside single quotes. Because, we put SQL strings inside single quotes. But the database, sees the quote from the post, and it thinks that's the end of a string, and that t is something it doesn't understand. By the way, if your code didn't have this bug, congratulations, that's awesome. But stay tuned, because there's more to this bug than might first appear. Despite the fact that we had a little problem, we can still post things. As long as they don't have single quotes in them. But here's something to try. Single quote. Close param. Semi colon. Don't retype this from what I'm saying. Copy it from the instructor notes, and put them into your forum. Delete from posts. Semi colon. Double dash. Post this. Wait, all, all of our posts are gone. I thought we had a database here. Hey, wait a minute. I thought I saw this one on the webcomic XKCD. What we have here is a security hole called an SQL injection attack. Some of the post's text is being treated as a database command, namely delete from posts. Which as it happens, means delete every row from the posts table. Well, that stinks. All those brilliant test posts we wrote are gone, and we have a famous security bug in our code. How are we going to fix this? Well, we might not be able to get all those great posts back, but we should be able to at least keep it from happening again. The problem with our code is that user input gets put into a database query in an unsafe way. Some text submitted in the forum ended up being considered as SQL code instead of as a text value. But there's another way to do our query that's safe. When we execute a query, we can put a %s in the query text, and then after it, a tuple parameter to the execute call. The database library will substitute this into the query in a way that's safe so this problem will never happen again. Using what you've just learned, you can now update forumdb.py to execute insert queries safely using query parameters. Test your work by checking that you can now make posts with single quotes in them and that the SQL injection attack query doesn't delete the whole forum anymore. When you're done, press Submit, then Continue to go on. So here's where we're executing the insert query and the AddPost function. And now if we change this to just have a comma and a tuple after here, after this percent s, and make sure to have enough parentheses, we should have a forum that's safe against the SQL injection attack. Let's try it out. And here's a test post that has a single quote in it, and sure enough, that worked. Let's try the attack query again. Single quote, paren, semicolon, delete from posts, semicolon, dash, dash. And this time, we're successfully treating that as just text and not a piece of SQL. Awesome. With that simple change, we foiled one of the most infamous security holes a database-backed web app can have. Just remember that whenever you execute an insert query, make sure to use query parameters instead of string substitution. In case you forget, here's what the Psycopg 2 documentation has to say on the matter. Warning, never, never, never use Python string concatenation, plus, or string parameters interpolation, percent, to pass variables to an SQL query string, not even at gunpoint. And they give the same format that we just used. Now personally, I don't think we really need to have documentation that tells us what to do at gunpoint, but we all do have a right to secure code. SQL injection attacks are a common security problem with code that uses a database without being careful enough. But they're not the only one. Here's another exciting opportunity to mess with your forum app. Copy the text from the instructor notes, and put it into a forum post, like so, and hit the Post button. Oh, no. Spam, and more spam, and even more spam. Where's all this spam coming from? Every time the forum page loads, our web browser is submitting spam messages back into the forum. Remember back in lesson one when I asked you to think about the meaning of data in particular columns? Well here is a case where that's not an abstract concern at all. The forum program is treating each post as if it's just a piece of text. But your browser on the other hand, your browser is interpreting it with a different meaning, as a piece of code. This is another security problem a web app can have, it's called a script injection attack. And this is why real web forums don't allow users to put arbitrary JavaScript code in their comments. Okay, so how do we fix it? Let's put an end to this spam nonsense. We need to make sure that the data in the content column will always be treated as having the same meaning, as text, not as JavaScript code. As it turns out, there's a really good Python library for doing this called bleach. It's installed on your VM already, so you can import it right into your code. Have a read through the bleach documentation, which is linked in the instructor notes. Once you do that, you can use bleach to stop unsafe HTML from ever getting from an attacker through your database back to a user. Go ahead and make that change to the forum code, but here's something to think about when you do, do you think it would be better to clean bad stuff out of posts before we store them in the data base? Or should we store whatever the user sends us and then clean the bad stuff out before we display those posts in the forum? So before you made that change, I asked you to think about whether it would be better to clean bad stuff out of posts as soon as the user sends them, before we put them in the database or whether we should put them into the database as they are and clean them up before we display them. It turns out that there are arguments both ways. Usually you'll hear programmers talk about input sanitization, meaning that we clean bad stuff out of user input, before we do anything at all with it, that way if someone later displays the stored posts using another app. They don't have to worry about bad stuff hiding, in the database. But on the other hand, if we wanted an accurate record of what users have sent to us, maybe we want to preserve bad input in the database, and do output sanitization instead. People have different opinions, about which of these is best. Right now, since we already have live bad stuff in the database, we definitely need to sanitize output. But we could sanitize input as well. Well, now we have fixed our web app so users can't post JavaScript into it and create endless spam. But all of that spam is still in the database. How do we clean it up? Or for that matter, if some user of our forum posted something awful into it, how would we get rid of that post? We have a couple of options here. First, let's try replacing the spam post to something innocuous like, say, the word Cheese! We can do that from the psql database console, but to do it, we're going to need a new SQL command, the update command. Update is the SQL command for changing values in existing rows. Unlike insert, it doesn't create new rows. Instead, it replaces the value of a named column with a new value in each row where this restriction is true. The where restriction on update works like the one on select, but if you leave it off entirely, the update will apply to every row in the table, which is usually not what you want. But you can always do a select first with that restriction to make sure that your update affects the right rows. But how are we going to find the right posts? It would be a big pain to have to type out the whole spam post contents so we can match it with the equals operator. Here's a more fitting operator, the like operator. Like takes a value, usually a text column, on the left side and a pattern on the right. And just because you really needed one more meaning for the percent sign, SQL patterns use it to mean any string can go here. So, now in the psql console, use the update command to replace all the horrible spam posts in your database with something innocuous like cheese. To check your work, reload the forum page or do select star from posts in psql and check that all the spam has been replaced. How did you decide which posts are spam? Here's one way, all of the spam posts contain the word spam. So if we replace all those with cheese, well, it's definitely an improvement. Instead of a lot of spam, we now have a lot of cheese. But still that's really a lot of cheese in our forum, what should we do now? So maybe it updating was the wrong thing here. We got rid of the spam, but now we have way too much cheese. Let's find out how to get rid of the cheesy posts entirely. Remember how bobby tables deleted all of our posts once? It was with the delete statement, but delete can be used for good as well as for evil. We just need to be a little selective with it. Just like select and update, the delete statement can take a where restriction. And just as with update, you can task that where restriction by using it in the select, before you go deleting anything. And now you can probably clean all of the cheese out of your database with a single command. When you're done, reload the forum and see that all the cheese posts have gone. So the post that we want to delete are the ones whose content is just the word cheese. But before you go deleting anything, you can check that your where clause does the right thing and then if that looks right then delete away. Wow, I really gave you a piece of lousy code there, didn't I? But you cleaned that code up. You learned about sanitizing user data, and you picked up a couple more SQL statements on the way, awesome. In the next lesson, we'll talk about something that we've kind of skipped over so far, creating tables, and declaring the data types and relationships in them. So you can build your own tables from scratch. See you then. So far in this course, you've worked with databases and tables that were already created. In this lesson, you'll learn to define new tables and declare the relationships between them. We'll begin by revisiting some of what you already know about table structure, and we'll build on that with the SQL syntax for creating tables and linking them together. Then you'll learn some powerful tricks for doing things using SQL that you might otherwise do in your python code. This can help your code run faster and more reliably. Let's get started. Back in lesson one and two, one of the tables in the zoo database we talked about, was the diet table which describes which foods each species eats. We looked at three ways we could store multiple foods, for a single species. As multiple food columns and one row per species, as a single column with foods separated by commas. And has separate rows, for each food comma species pair and I mentioned that this form, has some big advantages over the other two. It works better with drawings, it works better in comparisons and you don't have to know in advance how many foods there are, and we also looked at these two tables of donors to the zoo and their phone numbers. In order to avoid duplication, we split the information that was in one object or it's record, into two separate tables. In database jargon, these are called normalized forms and the others are denormalized forms. Normalization is the central idea in database design. Normalizing involves making the relationships among the tables in your database, match the relationships that are really there amongst the various pieces of data. There's a bunch of database theory behind this idea. I put a link in the instructor notes to a paper with lots of details about it. Up ahead, I'll just tell you the most relevant highlights. So our first rule for our normalized table, will be that every row has the same number of columns. A column can be empty or zero, but we can't have two columns in some rows and three columns in another row. That just doesn't make sense in a relational database. In fact, that's pretty much the same thing that's going on, when we had the food one, food two, and food three columns. If you have two values with the same meaning for a given key, they're going to need to end up in separate rows, like this. Second rule, some one or more columns of the table are the key, which identify what thing each row is telling us about, like an animal, a species, a bank account number, a website user. In a simple table, like majors, it may be that all of the columns are part of the key. Any other columns in the table besides the key have to describe something about the key. In any row, the key provides the topic of the sentence that the rest of the row says something about. Rule 3, in a normalized table, the non-key columns describe the key. They don't describe other non-key columns. So if you had a table of items and how many there are, and what location their in and the street address of that location. To normalize that you don't split out the mapping from location to address from the rest of the table, like so. That way you can talk about a location without talking about a particular item. It's not as if the street address is specific to a particular item after all. Lastly, in a normalized table, the rows don't imply relationships among the data that don't actually exist. This is something to watch out for, especially when you have multiple rows about the same entity and multiple facts you want to record about it. Suppose that you have some information about some people's work skills, including the languages that they know. Here Annabel knows Databases and and Linux and Data Science, and English, and French and Arabic. And Leon knows Data Science and Windows, and English and Kurdish. But Databases don't have anything particularly to do with English, not Linux with French. But these rows make it look like they do. They make it look like Annabel's Linux skill has something to do with her French language ability, and that's almost certainly wrong. So the mapping from people to their technology skills, and the mapping of people to the languages they know belong in separate tables. So there are four rules for normalizing tables. There's a lot more to learn about this topic, though. I've put some links in the instructor notes, that you might want to read. Okay, so now it's time for a quiz. Here are four different groups of database tables that might be used to store information about students in a school, and their grades in several courses. I'd like you to check the check box for each one of these that is normalized. In the first group up here, we have one table, this table has a student's name, the teacher's name, and the grade. In the second group, we also have one table, we have a student ID, student's name, a course ID and the grade. In the third group down here, we have two tables, this one has the student's ID and the student's name. This one has the student's ID, the course ID, and the grade. And in the fourth group, we also have two tables, we have student's ID, student's name, student's birth date. And then in the second table we have the student's ID, the course ID, and the grade. So again, I'd like you to check the check box for which ever groups of tables you think are normalized. So in this first case, we have three columns, student name, teacher name, and the student's grade. One of the rules for normalization is that we have to have a unique key, that says what each row is about, but names aren't unique. If we have two students named Jake Smith, or Pavel Ivanov, or something else, this isn't going to do very well. Also, if a student is taking two courses taught by the same teacher like, maybe a CS and a math course. We'll have problems there, too. So this is not normalized. Over here, we also have a single table. Here we've given each student a unique id number. And we're also using a unique id for courses, instead of just the teacher's name. But, we're storing facts that don't have to do with each other in the same table. Like student 23 is always Jake Smith, regardless of what course he's taking. This really ought to be split into two tables, so this is also not normalized. And splitting it into two tables, is exactly what we've done in this third group. One table that gives the relationship between each student id and their name. And the other gives the grade for each course they take. If all we know is a student's name, we can join this against that to find their courses. But, if there are two students with the same name, we will get both. Nonetheless, this is normalized. And the fourth group, the only difference between this one and that one, is that here, we're also keeping track of students' birth dates. But a person only has one birth date. And the birth date, doesn't have anything to do with their grades. So adding this column to this table, doesn't make this any less normalized than this one. So this and this, are both normalized. You can add a new empty table to your database with the create table command. When you create a table, you'll give the name of the table, and the names and the types of each column. You can also set constraints on each column and on the row as a whole. We'll talk about constraints shortly, but for now, let's focus on types. Here's the simplest form of the create table command that doesn't have any constraints, only columns with their types, and gives the table a name. Now, we've dealt with text and integer types previously, and back in lesson two, I gave you a big, long list of lots and lots of types that SQL supports. The exact set of types that you can use will vary from system to system though. If you're working with a database system that doesn't natively support the type you need, there's usually a way to work around it. For instance, PostgreSQL has a specific type for IP addresses, but MySQL does not. MySQL programmers usually use an integer or a text string to store IP addresses. Of the databases we've used in this course, PostgreSQL has a proper type for dates and times, but SQLite actually just stores dates as strings. Database systems will often give you shortcuts to declare a particular kind of column. For instance, in PostgreSQL, you can have a column that stores the time and date along with the time zone so you can do comparisons of data recorded in different places around the world. The full SQL standard name for that column type is timestamp with time zone, but PostgreSQL lets us abbreviate it as timestamptz. Normally, if you're creating a database for a new application, you'll set up the database upfront as part of the installation procedure. It's technically possible to send create table commands from your app code, but it's usually a bad idea to do that outside of initial setup. Your database design is really a part of your app's code. It's just a part written in SQL instead of in Python. So, creating tables isn't like creating values in your program's variables. It's more like having your app rewrite its own code. That's not something that's very common. When you want to use a database in your application, first you need to create the database and give it a name. You'll use the create database thread for this. The name you give it here, is the same name you'll use to connect to the database from your code. The opposite of create in SQL is drop. I'm not sure why. Maybe database programmers used to be really clumsy. Anyway, the way to remove a data base, is drop database. And the way to remove a table is drop table. All of these commands have options, you can look up in the documentation if you ever need them. When you drop a data base or a table, there's no confirmation, no did you really mean to do that warning. So don't do it, if you don't really mean it. Once you've created a database in psql, you'll want to connect to it. You can do that using the backslash C command, followed by the database's name. By the way, you can't drop a database that you're connected to. Try these commands on your own in your VM using psql. First, create a new database called fishies, or whatever you'd like. Once you've created it, switch psql's connection over to that database, with \c fishies. Then create a table, make one of the columns a text column, one of the columns a serial column. Then try inserting some values with the text column and selecting some rows from the table. What do you think will happen in the serial column, when you insert a row that doesn't give it a value? Try it in psql. What was it that actually happened? Then after that, try finding a description of this behavior in the post SQL documentation. It turns out that serial isn't really a data type at all, it's shorthand for the integer type, plus a special default value. When we create a serial column, the database does a bunch of work for us to make sure that column gets populated correctly. It makes something called a sequence, which is an internal data structure and sets that as the default value for the column. That's what you saw when you looked at the ID column for the forums post table in the last lesson, by the way. So way back in lesson one, I told you about the idea of a primary key, a column or columns that uniquely identify whatever it is the table is about. Remember the bit about U.S. city and state not being unique, because there are five Springfield's in Wisconsin. If we want a primary key for places, we have to use something like a postal code or coordinates or something. In SQL, we need to tell the database that something is a primary key if we want to explicitly relate other tables to it. And here's how to do that. If you have a single column primary key, just put primary key after the column's type when you create the table. Whereas if you have a multi column primary key, you put it after all the columns in the table. For instance, postal codes don't have to be unique around the world, since two different countries could use similar numbering systems. The US, Germany, and Indonesia among others all use five digit postal codes. This means that if we wanted to have a table of places that we can mail packages to, we'd want to have both the postal code and the country as parts of the primary key. Remember, primary keys are meant to uniquely identify the thing that a row is about. What do you think your SQL database will do, if you try to insert a duplicate value into a primary key column? In fact, let's make that a quiz. What should the database do, when a user asks it to insert a second student with an ID number that is the same as another student's? In other words, a duplicate primary key. Should it insert the new row anyway? Should it signal an error like an exception in Python? Should it silently drop the new row? Or should it overwrite the old row? So what will actually happen is if you try to insert a duplicate value into a primary key column, the database will signal an error, in Python code, you'll see that as an exception. If your code does that using cycle PG, you'll have to roll back using the roll back method on your database connection, before you can do more with that database connection. So the correct answer is that the database will signal an error. When we assign types to columns, we're restricting what sorts of values can later be put into them. If we say that a column is an integer, we shouldn't be able to put the word pies in it. That's important, because if we later want to take the sum or something, we can't add the string pies to some numbers. But that's not the only sort of restriction we might want to put onto a column. Imagine that we're building a database for a retail store. In one table, we have a list of all the products that we have for sale. In another, we have all the sales that we've made. Whenever we sell something, we insert a new row into the sales table. By the way, the name S-K-U or sku on these columns, is just a name for stock keeping unit, which is an ID number or code that's commonly used for products in stores and warehouses and so forth. We'd expect that every SKU in the sales tables, would refer to one over in the products table. But what if we inserted a row in the sales table, that didn't match any row on the products table. It wouldn't make any sense. We don't have a product number 23, inserting this row must be a mistake. And its a mistake that the database can catch, but only if we tell it to. When we create a table, we can tell the database that a particular column should only have values that refer to the key of another table. To do this, we use the references keyword. Create table sales, sku text references products. If the name of the column is the same in both tables, then we can just use, the name of the table over here. Otherwise, we would use the name of the table followed by the column and parenthesis. In this case, this is actually unnecessary, so we don't need to use it. So a references constraint, is a little bit like type checking. It catches bugs that might lead to our database not making sense any more. In database terminology, we'd say that references constraints help us maintain referential integrity. Which is our assurance that values in a column over here, will always refer to values in a column over here. In database terminology, a column with a references constraint on it, is also called a foreign key. Now this has always sounded like a bit of a weird term to me, like it was the key to a lock from far across the sea, but a foreign key is just a column or a set of columns in one table, that uniquely identifies a row in another table. It's possible for a table to have two or more foreign keys, actually that's really common. For instance, consider a database of students grades in various courses. Here we've got a table of students names and their ID numbers. And the ID is a primary key because names aren't unique. And we have a table of courses, with course names and course IDs as well. And then we have the grades table, which has foreign keys into both of those tables. Here are the same tables, but this time drawn out. Usually a foreign key will point to the primary key of the referenced table. That's because the whole point of a foreign key is to uniquely identify a row in the referenced table, and the table's primary key does that. Now here's a quiz. These tables are for a more complex forum app than the one you worked on last lesson. This app allows users to log in and post comments, and also vote on other people's posts. Take a look at these tables, and see if you can figure out which columns should be primary keys, and which columns should be foreign keys referencing them. In the users table, we have a username or handle or alias, and the user's full name. In this posts table, we have the post content, the author's username, and an ID number for the post. And in the votes table, we have the id number of a post, the username of somebody who voted on that post, and a 1 or minus 1 for whether they liked it or disliked it. So for each one of these columns, if it should be a primary key of that table, put a P in that box. If it should be a foreign key, put an F. If it shouldn't be either one, leave the box empty. Also, although there's no check boxes for them, think about if any of these tables should have primary keys with more than one column. First, let's looks at the users table. A person's full name isn't unique, but the user name on the form should be. So that can serve as a primary key. Next, the posts table. Each post has a unique id, and that's the primary key. And author here, seems to refer to the users tables, username column. So that's a foreign key. Lastly, there's the votes table. Post_id here seems to refer to the id column in posts, which would make that a foreign key. In the voter column, refers to the username in the user's column. So that's also a foreign key. But one more thing, since each user should only be allowed to vote once on each post. The pair of columns post id comma voter in the votes table, should also be a primary key. It talks about, for instance, user Prince Utena's vote on post_id number 2. Earlier in this course, we've used Joins to derive new tables, from two or more existing tables. But there are also cases, where you want to join a table to it's self. For instance to find pairs of entries that have something in common. Doing this in the database is generally a lot faster than pulling that data in to your python code and scanning it there. Here is an example. This is a table of students living, in the residence halls of a college. Student ID is the primary key, and then we have the name of the residence building and the room number. These are actually some of the names of dormitories at my college. Now suppose, we want to find out which students are roommates. In other words they live in the same building, and have the same room number. Joining the table to itself is how we do this. This exact query isn't quite right, but it's close. Try it out on the next page, then see if you can fix it. When you ran this query, what was it that wasn't right about it? Well, it seems to think that each student is his or her own roommate, and it lists each pair of roommates twice in alternating order. There are a lot of ways to fix this, but here's just one of them. By asking only for the rows where this id, is less than that id. We eliminate the rows where they're equal, in other words the same student. And, we eliminate one out of each pair of duplicates. Here's something that kind of surprises many people when they learn SQL. So far, whenever you've done a select, you've selected from either a table or a few joined tables. There's another thing you can select from as well, namely the results of a select query. This is one form of something called a subquery or sometimes a subselect. Remember back in lesson one when I mentioned that the result of a query is always a table? This is why. Since the result of a query is a table, you can select from it, join it, aggregate it, and so on. Here is a table that lists mooseball players, and what team they're on, and the number of points they scored in the last season. And here's a query that will find the highest-scoring player's score for each team. This uses the max aggregation, grouping by team to find the highest score. But suppose that we want to know what the average score of a highest scorer is. To do this, we can take this whole query and stick it inside of another query. The outside query gives the average of the inside query's results. The syntax of SQL requires that we give the subquery result table a name, maxes here, even though we don't actually use that word anyplace in the query. It's just required. There are several other ways you can use subqueries as well, which are beyond the scope of this course, but can still be very useful. You can read about another use case, subquery operations in the where clause, in the PostgreSQL documentation linked in the instructor notes. On the next page, you'll see a piece of Python code that does two database queries. First, it does an aggregation to find the average weight of moose ball players, and then it uses that average to find all the moose ball players who weigh less than the average. But using a subquery, this can actually be done in only one query. It's easy to state this in English, but how about in SQL? This is a tricky puzzle, and it goes beyond what a lot of database programmers are accustomed to doing with SQL. Take some time trying different approaches and see if you can come up with one query that does it all. So, here's one possible answer. Inside these parentheses, is a select statement that returns the average weight. We call this table subQ, because SQL makes us give it some name, even though we don't use that name. And then we're joining that back to player's table, and then doing a where restriction for rows where the player's weight, is less than the computed average. Let's look at that in more detail. First, start with the sub query. It does an average aggregation. Producing this little one by one table called a subq. Then, that gets joined to the players table. Making this one. This then gets filtered, for entries where weight is less than average. Finally, we just take the name and the weight columns. You've probably noticed that SQL queries can get pretty complicated once the clauses and sub-queries start to stack up. As programmers, when we're writing code and a function starts to get too complex, we look for ways to re-factor it into smaller functions. Well we can do that in SQL too. Every select query returns a table. So, we can have the database remember a select query for us, and make it available to later queries. When we do this, it's called a view. Here's the syntax for the create view command. Views are really useful with aggregations like counts or sums. For instance, if we have a table of students enrolled in courses, and we want to know how many students are in each course, we can find that out with an aggregation. But then if we're going to use that query a lot, we can store it in a view. Using a view instead of making a subquery, is kind of like using a function call instead of copying code. Another use of views is to display only particular columns, from a table that has a lot of columns. If you have a table with 20 columns, and you have a lot of queries that only refer to four of them, making a view can make your code a lot more clear. Here's something to think about. Do you think that a database system like PostgreSQL, should let us update and delete rows in a view? Whether you can update or delete from views at all, depends on the database system. In SQLite, you just can't. It doesn't support it. But in PostqreSQL, you can update or delete on simple views, like ones that select just particular rows or columns from a large table. But not from views that use drawing, aggregations, or other functions. The change to the view will effect the underlying table that it's a view of. So, the answer is that yes, you can update or delete rows from some views but not others. So now you've learned the basics of database design, building normalized tables to represent various relationships amongst data. And you spent some time at the PostgreSQL and Python DB API documentation. So you're prepared to refer to them in your future database work. In the next lesson, you'll bring together all those skills to build a database backed tool to solve a particular problem. Running a game tournament that's both fair and challenging for all its players. For the final project in this course, you're going to build databased backed software to run a particular kind of game or sporting tournament. In a Swiss style game tournament, players aren't eliminated when they lose a match, every player, gets to play in every round. And in each round, each player plays against someone with about the same number of wins and losses that they have, which means that each player is likely to be matched against an opponent with about equal strength. Ties are broken by looking at how well the tied players' opponents have done. After all beating two strong opponents counts for more than beating two weak opponents. This system was invented in Zurich, Switzerland in 1895 for chess. But it is now used for a wide variety of games and sports around the world. And keeping track of such a complicated tournament is a good job for a database. In this lesson, you'll be writing a python module that uses the PSQL database, to pair up players in each round of a tournament and record their results. In designing your code, it's important to understand the problem that you're solving. So, let's think a bit about the math of tournaments. If you'd like to skip straight ahead to the code, feel free, but working through this may be helpful. In an elimination style tournament, each round eliminates half of the players from contention. That means if you start out with n players, it takes log to the base 2 n rounds to find a champion. And the total number of matches played is n minus 1. Like in this tournament here, there are eight entrants, A, B, C, D, E, F, G, H. And finding a champion takes three rounds. And sure enough, the binary log of 8 is 3. There are four matches in the first round, two in the second, and only one match in the third for a total of seven matches. But how about in the non-elimination Swiss system? For a given number of entrants, how many rounds does it take to find a champion and how many total matches are played? Let's take a specific example for a quiz. Suppose there are 16 players. How many rounds and how many matches will have to be played? So, the question was in the Swiss system, if there are 16 players, how many rounds does it take to find a champion, and how many total matches will be played? Even though players aren't eliminated from the tournament by losing a match, one loss means they can't become the unbeaten champion. In fact, if we look at this subgraph, of this Swiss system tournament, it looks an awful lot like this elimination tournament. This means that the Swiss tournament takes the same number of rounds, as the elimination tournament to find a champion. So if there are 16 players, it would take four rounds. In the total number of matches, it's just the number of rounds multiplied by the pairs of players in each graph. Since no players are eliminated, each of the 16 players are in each round. 16 players is eight pairs and multiplying this by four rounds, tells us there are 32 total matches played. The first step in your project should be to think about the database schema. Remember to write your create table statements in a file called tournament.sql. You'll be submitting this along with your code as part of your final project. Remember that after you've created your database, if you decide you've made a mistake, you can always drop a table, or the whole database and recreate it. And if you need to clear out the data in a table, you can use delete. Remember that drop table will remove the table completely, and you will have to recreate it using the recreate table command. Whereas delete from that table will just remove the rows leaving the column definitions, constraints, and so forth. Intact. A few more things to keep in mind. When players are added to a tournament the database should assign each player a unique ID. You've seen how to do that using the serial type. There's an extra credit option, where you can extend the project to support multiple tournaments. If you do that you'll want unique IDs for those too. Second, remember that you can use SQL aggregations, when you want to count things or add them up. If you find yourself pulling lots of rows from the database into your code, and then using len to count them, or using a loop to add them up, trying doing that in the database query instead. Last, if you notice your queries start to get really complicated, don't forget about views. Views work nicely with aggregations, when you want to present summary data quickly. If you use views, make sure to put your create view statements into tournament.sql, along with your create tables. With that, it's time to get into designing your database and writing your code. On the next page, you'll find a full description of the project, and an outline of the functions you'll be writing. If your code passes all the tests, congratulations! This has been a pretty major project. You've mastered some serious skills in data base programing. If it's not quite there yet, don't give up. It's normal for projects to go through a lot of revisions before they're feature complete. Chat with your fellow students on the forums, or consult with your coach on things that might have you stuck. When you're done, take a moment to reflect on what you've accomplished in this project. Are there any aspects of the design or implementation that ended up surprising you? Things that you looked up in the documentation, or things that you discovered? If you like, write down a surprising fact you've discovered here. Thanks for your response. And now that you're done, go visit the forums and share your insights with your peers. Then, maybe take a break and play some games yourself. Congratulations, you've reached the end of this introduction to relational databases. You now know the basic operations of SQL and elementary database design, and you've beaten some of the biggest bugs in the area of database backed websites. Relational databases are a big field and there are a lot of next steps you can take. If you're into math, you might want to look into the relational algebra. If you are more interested in production systems, there's a lot to be learned about building bigger and more reliable databases. If you are looking to learn more about database baked web applications in Python, we have some other awesome courses that you could check out next. I put some links to them in the instructor notes below. I hope you enjoyed this course, see you around.