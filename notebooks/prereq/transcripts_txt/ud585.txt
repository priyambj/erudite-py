Welcome to iOS development. I'm Rod, and I'm going to be your instructor for this course. In the first part of this course, we're going to build an app that lets you record your voice and play it back with sound effects. This course assumes you're familiar with basic programming concepts, like if statements, loops and classes. You don't need to have written any iOS apps, or any experience with Swift. We'll cover everything you need to know as you go through this course. Developing for iOS is a lot of fun. You get to write apps that you can carry right in your pocket. Let's start by looking at the steps we'll take to build this app. In this class we'll build a Pitch Perfect App which lets you record your voice and play it back with changes to the pitch. This lesson is an introduction to where we explore and get comfortable with Xcode, Apple's development environment. You can use Xcode to create apps for any of Apple's platforms. >From the watch to AppleTV To iOS and even the Mac. This lesson is all about getting comfortable with Xcode. In Lesson 2 we'll set up the basic structure of the app, learning how to connect UI elements, such as buttons, to our code. In Lesson 3 we're going to step it up a notch, add multiple views to the Pitch Perfect app, as well as adding the code to record audio. Towards the end, in lessons 4 and 5 you'll learn how to play back your own voice with the pitch perfect app with various alterations to the pitch. You'll also learn how to deploy pitch perfect on your iOS device. As you progress this course, we'll be introducing the Swift And iOS concepts you need to know in order to build pitch perfect. After that in UIkit fundamentals will go into much further depth in both swift, and iOS. Follow the links below to download Xcode and begin your adventure in iOS development. Let me show you the app we're going to create in this lesson called Pitch Perfect. Pitch Perfect allows you to record your voice and play it back with various sound effects. Including changes to speed, pitch, and even reverb and echo. Let's run it on the iOS Simulator so that I can show it to you. The first screen simply prompts you to record your voice. Hear at Udacity, we believe that asking questions is one of the best ways to learn. Judge a man by his questions rather than his answers. Now you can see Pitch Perfect has moved us to the playback view where we can choose to playback my voice using a variety of different sound effects. Let's try listening to it really fast. Judge a man by his questions. Rather than his answers. How about what I would sound like as Darth Vader. Judge a man by his questions. Rather than his answers. This app is a lot of fun to play with. But more importantly, you will learn key iOS development concepts along your way. It will also be the start of your journey as an iOS developer. We have a full course on Swift syntax. If you're new to the Swift programming language, I highly recommend going through it. For now, I'm going to attempt to give you a quick intro into Swift in under five minutes. It is just the basics that you need to know. And it assumes you've seen some programming language concepts before. There are just four key concepts to understand before we can start coding, variables, control flow, classes, and functions. Hopefully, you're watching this video as Xcode downloads. Ready? Here we go. Variables, if you want to declare a variable in Swift, the var keyword lets you do that. As an example, here we have a variable called x of type Int, and we're setting its value to 42. Note the semi-colons are not needed. Do you see something else that's a bit odd? That's right. The type of this variable comes after the variable name, different than most other languages. The reason for this is that Swift can infer the type of the variable, so in most cases, you can leave the type completely off. For example, here I could just make x equal to 42. Now something else you're going to encounter in your code is a constant. For example, here we have y that is a constant of type int with a value of 100. Swift has inferred the type int because we're setting it to an int value. The next type of variable that you need to deal with are strings. They're easy, too. Let me show you an example. Here we have a variable of type string, and I'm setting its value to Hello. Moving on to control flow, the only item that you need to know for control flow is if statements. If statements can determine what branch or path your code should take. As an example, if i put something like this, we can take one path if x is less than 50 and a different path if x is greater than or equal to 50. If we want to see what path is chosen, we can open the debug console and take a look at that. That's this middle button here on the upper right. We're going to cover loops and the powerful switch statements in the later part of this course. Classes are objects which allow you to store values and have functions that operate on those values. The really interesting part of classes is that they have inheritance. And therefore, they can carry forward any values and functionalities from their parent, called a superclass. If we look at this view controller definition here, we can see that it inherits from UIViewController. And any instances or class functions that I have would go here in the middle, where I have these two green comment lines. You can declare class variables that live in the class and functions that exist in every instance of that class. Just remember two things about classes in Swift. Everything in between the curly braces for the class is inside the class and available to any function in the class. And the UIViewController here is what this class inherits from. And it will be our hint where to look for for built in functionality, that is, what functionality our ViewController class inherits from its parent UIViewController. Functions are a way to encompass code and make it more reusable. Functions start with the keyword func, followed by a name, then any parameters, and the return type. Here's an example of the most basic function. It takes no parameters, and it returns nothing. It just prints out Hello. We can call this function by doing something like this. We can see Hello here is printed out in the debug console. We can also have functions that take a parameter. For example, if you wanted to print Hello in many languages, we could write a function like this. printHelloMessage that takes in a hello message string. Here we just simply called it helloString. It's of type string. And then we print that message. To call this function, we'd simply do something like this. printHelloMessage, and pass it the message that we want it to send, in this case, a hello greeting in Portuguese. So here we have the hello greeting in English with the regular function, taking in no parameters, returning nothing. And we have the Portuguese greeting, for the function it takes in one parameter string, it also doesn't return anything. Just simply runs the print command. That's just a little bit of Swift that you need to know before we dive into Xcode in iOS development. I've included a link below on our Swift refresher and other resources if you want to learn more. Hopefully you'll finish downloading and installing Xcode. When you're ready, let's go about creating your first iOS app. All right, so in creating your Hello World Swift iOS app in Xcode, let's go to File, New, and Project. We're going to select Single View Application, we're going to make sure we have the application section selected under iOS and click Next. We're going to type in the name of our product. Now this iOS app is your first iOS app, let's call it PitchPerfect. You can put in whatever organization name you would like and identifier we're going to cover that in a little bit. Make sure the language selected is Swift, that it's set to Universal, and you don't need to use Core Data right now. We're going to use it in a later project. With that, click Next. Select a location that you'd like to put it. For me here I'm just going to put it straight in the Desktop. Go ahead and click Create. Xcode will now create a new iOS app called PitchPerfect and automatically create some needed files and settings for you. Here, you can see the iOS app that Xcode has automatically created for you. It has an AppDelegate class that will listen to system events such as being called when your app starts, when you get a memory warning, and when your app is sent to the background. There is also a view controller and an empty view. We'll add more to those soon. For now you can add a single line into the app delegate to a function that gets called when the app launches called applicationDidFinishLaunchingWithOpti- ons. This one line of code will print out Hello World to the console. So here we are here, and we can see that in green Xcode has highlighted comments for us. And this function that we're talking about here is the one where we want to add a line. In the AppDelegate, inside the application didFinishLaunchingWithOptions functions we're going to add the line, print("Hello world"). Now if you click the Run button right up here on the top left, we're actually going to run this in the iPhone simulator. You can see our brand new app showing an all white background. In the console you see the words Hello World. Five minutes and you've already created an iOS app. Although it won't win any Apple design awards just yet. We're going to work to build it and improve it throughout this course. First let's take a closer look at Xcode. Here is a view of Xcode showing our PitchPerfect apt. I'm going to go over some of the basic parts of Xcode. And we'll be diving into the coat in just a moment. On the left side, you can see the navigator panels starting with the Project Navigator. On the middle is the content area, and it's currently showing the settings for a pitch perfect project. On the right side, you have the utility area, with the inspector panels with a file inspector panel currently open. On the bottom, you can see the debug and console windows. Unlike other IDEs and editors you may have used in the past, Xcode requires only a single click to select a file or an item. Starting with a navigator panel on the left, there are many different ways to view the files and other parts of your project. There are even ways to move through these panels with just a keyboard. As an example, you can use command zero to toggle the navigator's panel on and off. If like me, you need to find more screen space from time to time. On the right side we have the inspectors panel and the number available depends on the content or items you have selected. In the case of this project setting we can see file in quick help inspectors. As you progress with your app you'll be able to see other inspectors. Much like the navigator panels you can toggle the inspector panels by using keyboard shortcuts to move through them. This is especially useful if you're in need of more space to view your content. At Udacity we have a saying that content is king. And with Xcode that is also true. The code and even your user interface in storyboards are always in the center of view here and the prime spot in the content editor. On the bottom right we have the library and at the very bottom of the screen you can see the debug and console panels. The console panel is where you see the Hello World printed. The Exco content editor is where you going to spend a lot of your time as an iOS developer. It can. Adapt to help you edit any part of your project. >From project settings, to code, to user interface elements. Knowing that the editor is contact sensitive can help a lot when you're looking for how to change a particular setting in Xcode. With a Pitch Perfect project, which is a little blue icon here on the top of the project navigator we can see the settings for the entire project. We can see the version that iOS is targeting, and we can see that the interface file is called Main for Main story board. We can also use this decide what orientation to support, and to launch it. Here you can see we're supporting the portrait orientation, as well as Landscape Left and Landscape Right. If we select the AppDelegate Swift file, we can see that the Xcode editor panel changes to let us modify the Swift source code. You can see that Xcode automatically highlights the code to make it easier to read. Remember that main storyboard selection back in the project settings? That's referring to this file, main.storyboard. If you select it in a project navigator with a single click. The X Code editor changes to show you the user interface for this application. You can use two finger pinch to zoom out of it so you can see the entire thing. This is the view we're going to use to set up. Any UI elements for our IOS apps, including pitch perfect. I know it may seem like a lot but we'll walk you through step by step and touch every part of Xcode by the time you've completed this course. Xcode is a very powerful integrated development environment and it may feel a bit overwhelming at first. That's okay. Let me show you one of the features of the interface builder part of Xcode. That'll make your life a little easier. It's called the document outline. Here, I'm looking at the completed pitch perfect. Just so you can see the document outline in full. Your pitch perfect cap won't have any of these UI elements just yet. Here, I have Xcode open to the main.story board file. And the document outline is not visible. See this little button here? This is what shows or hides the document outline. Clicking on it causes a document outline to open. In this document outline, we can see our record sounds view controller. The view and all of the UI elements inside that view. Sometimes you may need to click on this disclosure triangle to see the items inside of it. If you're looking for an easy way to find and work with your ui elements, the document outline is the place to go. This is especially true once your app starts to have more than just a few buttons and labels. Before we move into writing the code for pitch perfect, I want to cover a softer pattern that'll be really useful in your time as an iOS developer. Let me introduce the MVC pattern to you. We're going to build the pitch perfect up using this pattern, so knowing it will be really handy to figure out where we are, and where we need to be. The model view controller pattern hails back from the Mac development days of the 80s. And it's still as useful today as it was then. You'll see it called model view controller or MVC for short. We can think of our pitch perfect cap as having three parts. The view, which the user sees with the buttons, the model, which is what was stored to recorded audio file, and the controller, which we used to store and retrieve data from the model and show it in the view. Think of the data your app contains. For pitch perfect this is just an audio file. But as you progress as an IOS developer, you will build ever more complicated apps. Which you need to store a lot more data. All of the costs involved with storing and maintaining this data can be referred to as the model. On the other side of the diagram we have the view. The view is what the user sees on screen and how they interact with the app. The view does not know anything about the data itself or the model as we call it here. It only knows how to display the subset of data that it's given. It is just your user interface. In between them, and in charge of providing the view with data and the model with any actions from the view. Is the Controller. When the user action happens on the view, the Controller is notified. If needed, it updates the Model. When the Model is changed by some external event, it notifies the Controller, which can update the View if needed. Maybe you're thinking. Why not just embed all of the model data code. Inside the view. What's often the case that you need to have multiple different views. To show some parts of the same data. What would you do then? Copy and pasting the code would quickly turn this project into what one of my colleagues refers to as copy pasta. Great to eat but horrible to have in your code. Having a division in responsibility between the model. The view and the controller in between makes your code easy to maintain, easy to understand, and reusable. As we start building pitch perfect together, you're going to see the model, the view, and the controller parts, and how they communicate. Students have found it really handy to have this pattern and thought in the back of their minds. As they are developing for iOS. It helps to keep your app structured and easier to develop. This lesson set up the foundation for the parts of Xcode and Swift that you need to know to start building the Pitch Perfect app. In the next lesson, you'll learn how to create a label and a button and how to connect them with a code in your app. You'll dive further into the NBC pattern and start implementing it with Pitch Perfect. The fun parts of iOS development are coming up just ahead. See you in the next lesson. In this lesson you're going to learn how to add and work with user interface elements in iOS. You're going to build the first part of the Pitch Perfect app with the ability to add buttons and connect those buttons to code in your app. We're going to be working with two parts of the NVC diagram, the view and the controller. Our controller is called the view controller and the view, for now, is just called the view. We won't see the code behind a view classes just yet, as we're going to be using the view classes that Apple provides, namely UIView, UILabel, and UIButton. We call that the controller part of the NVC parent, is where we handle events from the view. And we're going to be using the view controller that Xcode has already started for us, the ViewController.swift class. This is where the code, which will be called by the buttons, will reside. At the moment our view controller is just named view controller. But in a later lesson we'll name it to something more meaningful record view controller. User interfaces are one of the key ways your users will interact with your app. Let's get started. In your pitch perfect Xcode project select the main doc storyboard file. This is your storyboard, the place where you'll set up your entire user interface. Here you will eventually see the entire interface, all of the interface elements, and the view controllers associated with interfaces. You can see this app only has one interface and one view controller, named ViewController. A couple of key things to notice, the first is the light gray arrow on the left side of this view. This signifies that this is the initial view controller for the storyboard and in fact for the application. When the user starts this app, this is the first view controller and view that will load. On the bottom right side you can see the library selector would different types of user interface elements we can drag in. If you don't see the library make sure the third icon from the left is selected, the one that looks like two concentric circles. You can hide the debug area as well as the navigator panel to give us some more screen real estate as I’ve done here. Before we can drag a button then this view needs to be at 100% zoomed in. Double click on the header here to do that. Let's start by dragging in a button to this user interface element. On the bottom right scroll and select a button or search for it by typing UI button. Drag the button to the center of the screen using the two blue bar guidelines to center it horizontally and vertically. Now we come to the first problem most beginning iOS developers face. The background of this button is white. The UI view behind it is also white. If you click away, how can you tell how big the button is? One trick that I use is to temporarily change the background of the button so you can easily see how big it is and where it is on the view. This is also a great chance for you to play around a little bit with the attributes inspector. With the button selected, here on the left, click on the attributes inspector and scroll down until you see background. Select the drop down and pick a color. I've chosen bright green color for the background of this button. The more visible the better. You're not going for aesthetics just yet. Now we can see our button is pretty small. And we can easily see what would happen if you re-size it. Double click on the button and change the text to record. Go ahead and grab the button and drag it out, so you can see the entire word being displayed. While we're at it, here's another tip. If you had a hard time selecting the button, you can use the document outline view in interface builder part of Xcode to find the UI button and select it. That's this view here, on the left. You can hide and show the document outline by clicking on this button here on the bottom left. The next step is to set up the layout for the button. And for that we've got to talk briefly about auto layout. iOS now includes a new system for positioning UI elements on screen, called Auto Layout. You can think of Auto Layout as a simple adaptive system to help iOS figure out how to size and position your user interface element. You can use it to ensure that your UI elements are sized and positioned correctly, from the smallest iPhone to the largest iPad. In this course, we're going to go further in-depth on Auto Layout. And in particular, constraints. How to use constraints on user interface elements and views. Auto Layout is very powerful. But it takes a little bit of practice for it to become second nature. Right now, you're just starting. Remember, it's okay to be frustrated and not to get it right on the first few tries. Keep on it. And with very little time, you will become comfortable with this powerful and flexible system for positioning and sizing UI elements. Think about the single button that we want to place on screen. I've drawn the button here in green, and the view in blue. Let's assume we want it on the center of the screen, regardless if our app is running on an iPhone or an iPad Pro. The button should always be in the center, even when the app is on different device orientations, from portrait to landscape. Constraints are the rules that tell iOS how to position inside this particular UI element. So, if we were to think of placing the record button on the center, we need a distance from the top, the distance from the bottom, distance from the leading, and finally, the distance from the trailing edges of the view. If you're following along, you're thinking, okay, four constraints. And it would be correct except most user interface elements have what we call, an intrinsic size. That is they have a built-in height and width. In the button's case, this height and width is automatically calculated based on the text and font size you selected for the button's text. If iOS knows the height and width of a UI element, like a record button, then it only needs half the constraints to size and position it. That is to say, if I tell iOS how far from the top of the screen the button will be, then it can automatically calculate how far from the bottom it needs to be. If we tell it the leading constraint, iOS can automatically calculate the trending constraint, based on the width of our green button. So, the rule goes as follows, you need a minimum of two constraints in each dimension or axis, x and y, to properly size and layout a UI element. Except, if that UI element has an intrinsic size, then you only need one constraint for each dimension or axis, x and y. iOS can figure out the other constraint based on the intrinsic size. Last thing to remember, when sending a constraint, we're always comparing one thing to another. The record button placement is relative to the UI view it's contained in, in other words, its parent. I've represented the UI view by this blue rectangle outline. Right now, the UI view is full screen. But if we make it a different size, the record button will be still centered in that view. Let's test your knowledge of how to lay out. What if I want to place the record button here, on the lower right of the screen? What constraints would we need? Write your answer below. Remember, if you're in doubt, add the button and next code and play around with adding and removing constraints until you get it to appear correctly in the bottom right corner of the iOS simulator. The correct answer is to set up two auto layout constraints because the record button has an intrinsic size. I've used the trailing edge of the button to the trailing margin for the x coordinate and I've used the bottom of the record button to the bottom layout guide for the y coordinate. You can use different constraints as long as you have one for the x axis and one for the y axis. The recording button has an intrinsic size because there is an image associated with it and that image has a height and width. The button could also have an intrinsic size If it only had text, since the text title would be using a particular font and font size. So it would have a height and width. Okay, so you saw that the UI button has an intrinsic size based on the text and image it may contain. That means we only need two constraints to center this button on our view. One for the x coordinate, and one for the y coordinate. There are two ways to add these constraints, and I'll cover both here. With the record button selected, you can click on the align button that looks like a bar graph. If you're having trouble finding the record button, remember to use you document outline here and select it there. With the record button selected, click on the align button, which looks like a bar graph here, and then select these two options on the bottom to center it horizontally and vertically in the container. And then select add two constraints. We can now see both constraints in the record button in the document outline. You can expand these triangles if you want to see them actually here. And, if you're like me, you may have encountered the first on a layout issue, which is these orange lines that you see here, or this yellow disclosure here that you can see at the top. Now, let's fix that first before we run it. So if you click on this tiny arrow, we can see that Xcode expects that our button be on X of 276, width of 29 and height of 30, and its height is 32. So if we expand this out a little bit and click on this one, we can get it to fix the frame. That is to fix the size of the button so it matches the constraints that we've declared. We'll do that. We can see it's trimmed a record button to fit just the text or just intrinsic size of our button. Let's see if adding these constraints works. Let's select the iPhone 6s here on the simulator drop down, and press the run button, or hit command and r on your keyboard. We should see the record button on the center of the screen. With the iPhone simulator selected, press and hold down the command key, and then use the right or left arrows to rotate the simulator. I'm going to use the right arrow here to rotate it to landscape right. And I can use the left arrow to rotate back to portrait. In both orientations, we can see that our button stayed in the center. Now let's try it on an iPad Air 2 which is a lot larger than iPhone 6s. If I move this to the side, we can go back into Xcode, and press the stop button. We can here in the drop-down select an iPad Air 2 and hit run. Now we have a record button, but it looks like our iPad simulator is too big to fit on our screen. What do we do? We could go out and buy a large tunnel of display, and I would recommend that. We could petition Johnny Ive to bring back the 17 inch Macbook Pro laptop. Well, there's an easier option. With the iPhone simulator selected, let's go in to window, and then scale. And you can choose a different size here. For example, let's do 33%. That makes our iPad a lot smaller. And we can see it. We can use the command keys to jump around between those sizes, too. For example, Cmd+3 will get us a little bit bigger, Cmd+2 will get us even bigger and now it's, again, offscreen. So let's stick with Cmd+3. Here you can see the record button is still in the center of the screen, even if I use Cmd and arrow keys to rotate the iPad to landscape right, or back to landscape left. By the way, these options just scale down the size of the ioS simulator as a whole to what you're seeing. For your app, everything is still the same size. I've mentioned before there are two ways to add the constraints to our record button. There's another way if you don't want to use the align button I’ve shown you previously. This is just to show you another way to accomplish the same auto layout task, you don't have to do this step. First, I’m going to delete these two constraints by highlighting them and pressing the delete key. Then, with the record button selected, I'm going to hold down the control key, and drag diagonally here into the view. Now if I hold down the shift key I can select center horizontally, center vertically in container, and then press the add constraints button. This adds the exact same constraints we did earlier using the align button. I know this may seem like a bit of work just to start understanding auto layout and to get the button to be in the center of the screen, but as the saying goes you have to learn to crawl before you can walk. In the next section we're going to wire up our button to the code in the viewcontroller.swift file and make the record button actually do something. So far, you added a record button that is perfectly centered on screen, on both an iPhone and an iPad. This is in the view of the viewController.swift class. Now we need a way to connect the record button to the code in the view controller. Since we need to work with both the view and the view controller at the same time, we need a way to show them both simultaneously in Xcode. There's a great way to do this in Xcode called the assistant editor. To switch to it, first make sure that we've selected the main.storyboard file as you can see here, and it's showing in the content editor. Then click the assistant editor button here on the top right. It's the one that looks like two circles, intertwined. Then, make sure that we have the view controller selected here. Things are getting a bit crowded in our Xcode window. Let's close out the inspectors window for now with the key shortcut, Cmd+Opt+0. Let's also hide the debug area for now by pressing the button here to hide it. We're going to use something called an ib action to link the button to the view controller. It links to pressing of the button to a function inside the view controller. This is known as a target action. The target is the view controller, and the action is the function we are about to create. Select the record button. You can do it here in the document outline and then holding down the Ctrl key, drag it over until it's right above the last curly brace inside the ViewController.swift file. Let go and then from the drop down, select Action. Let's give this action a name, such as recordAudio. And then click the Connect button. You can see Xcode has created a function for us called recordAudio, and has connected this button to this function in the viewController class. We can see this function is connected because it has this filled in circle here on the left side of the bar. This filled in circle indicates that this is a special type of function, called an IB action, that has a button or other UI element connected to it. Now every time the user presses the record button, this function is going to get called. A good practice in software development is to test your code often. Our pitch perfect app is no exception. Let's add a line of what I like to call caveman debugging to this function, to print out to the console that the button was pressed. Inside this function let's add a print command. So that we can just print out, record button was pressed, every time the user presses this button. Let's press the run button and test this app out. In my case I've selected the iPhone 6S as the simulator to use. Now when I press the record button, I can see the record button pressed is showing in the console. Press it again, I can see that it's happening there. It's listing here on the right. Why do i call it caveman debugging? Well, it's the oldest and simplest form of debugging your code, just by logging something to the console. Later in these courses, you're going to learn some really powerful ways to watch, debug, and step into the execution of your code. For now, we can be content with using caveman debugging to ensure that the record audio function is getting called. This is great. Now you have your record audio function executing every time the user presses the record audio button. This is an example of going from user interface element, in this case the record button, to your code using an IP action. What about going to the other way, from code to user interface element? Maybe we want to enable or disable a button, or we want to change the text of a label. When you go from code to UI element, you use a connection called an IB outlet, otherwise known as an outlet from code to UI element. Let's add that one of those in. To start with, let's open back the inspector's panel by clicking this button here on the top right. Make sure that library's selected here on the right. In addition, for a moment, I'm going to come out of the assistant editor just to give me more screen real estate. There we go. Now I can see my interface. I'm going to drag over a label and a button. To start with, I'm going to search for a label. Found the one. I'm going to drag one here. And I'm going to name this label Tap to Record. And I'm going to reposition it back in the middle. And then, I'm going to search for a button. I'm going to drag another button on here. Try to center it as best as I can in the center of the screen. Double-click inside, and type in Stop Recording for the button's text. Don't worry about the layout yet. We're going to tackle that in just a bit. Now, pay attention, because here comes the unintuitive part. We want to make a connection from code to UI element, in this case the Tap to Record lable. >From the document outline, find our Tap to Record label as you can see highlight here. Hold down the Ctrl key, and drag it into our ViewController class. Select outlet, and name this recording label. You can now see Xcode's created an outlet for us linking the UI element into code, or, as we're going to use it, an outlet from code, where we can change the UI element. Let's use this IB outlet. Let's make the text change after the record button has been pressed. So, what we want here is we want the text of the recording label to change when the record button is pressed. You already know which code gets called when the recording button is pressed, that's the function we wrote earlier as an IB action, right here. We can add the following line to the recordAudio function. If you run the app now, and press on the Record audio button, you should be able to see the text change to Recording in progress. We can see that our label and button are not positioned correctly. That's okay. If we press this button, we should see this change from Tap to Record into Recording in progress. So, we've used an IB action to receive an interaction, even on a button. And then, we used an IB outlet to reach back from code to UI element, in this case, the label and change this text. Let's make sure you recall which is which. How would you explain IBAction and IBOutlets to someone? How would you describe the differences? What are these round circles used for? And what does it mean for them to be empty or filled? IBActions and IBOutlets are just connections between UI element and code and vice versa. IBOutlets are what we use to reach from code into UI elements. IBActions are what we used to go from UI element into our code, executing the code inside the view controller from a vent in the UI, like a button press. These filled in circles indicate that the IBOutlet's and IBAction's are connected to a UI element. The next step now, is to have a way to turn off the recording once you've started recording something. For that, we will need, you guessed it. Our stop recording button. We'll also need an IP-action from the stop recording button to the view controller code. Make sure you are on the assistant view with the storyboard and the view controller files open. Control drag from this button into the view controller and select the option to create an IB action. Let's name this IB action stopped recording. In this action, let's add a line to print out when this button was pressed by adding the following code. We should be able to run the pitch perfect app now. And if we press the stop recording button, we'll see our caveman debugging output in the Xcode console. Let's give it a try. We're almost there. The next step is to add the constraints to our new label and button and then to wire up some IBOutlets so that the Recording and Stop Recording buttons are not both enabled at the same time. This time we make sure that the new recording label and stop button stay in the correct position and size, at all times. Much like the original record button, we need to add constraints to these two interface elements. First we have to think about what we want, which is three UI elements, one beneath the other, centered on screen. They should always be in the center, regardless if we're running the app on a small iPhone or the new iPad Pro. We already have a recording button centered on the main UI View over our View Controller so we can anchor the other two views off the recording button. Let's start with the recording label. The recording label is this one here that says tap to record. With it selected, let's control drag diagonally to the record button. The menu that comes up is context sensitive to the direction of the drag. If you just do a straight up and down or left to right drag, you only get a subset of the constrained options. With the shift key held down, select vertical spacing and centered horizontally, then click add constraints. This means that we want to maintain the vertical spacing from the recording button to this label, and then we want to label to be centered horizontally to the record button. So how does auto layout know where the label needs to be on screen? It checks to see where the record button is and placed this label, based on that, using the two constraints that you've just setup. If you're remembering back to earlier, how I mentioned that there are two constraints needed for each axis, two for the x and two for the y, you're correct. However the label, much like the UIButton, has an intrinsic size. So auto layout can figure out the height and width of the label based on the text and font of the label. So all we need to provide is where to place it along the x and y-axis. In other words, just one constraint for the x and one constraint for the y. Let's set up the constraints of the stop recording button against the tap to record label. Once more, drag the agony from to stop recording button to the tap to record label. With the shift key pressed down, select vertical spacing and center horizontally, then click add constraints. We should be able to see six constraints under the constraints section of the document outline. Your number here inside these constraints may vary a little bit from 20 to 21 to 23 and they may be a little different than mine and that's ok. They're based on where you placed your UI elements in the storyboards when you dragged them in. Let's see if this worked. Click run or press command R and you should see the Pitch Perfect app running on the iOS simulator. Let's try different screen orientations to see if they stay centered. You can see here that they stay center of the landscape and would see the same if we switch to different iOS simulators such as the iPad air. We should see here, that our three buttons are always centered on screen. Remember it may seem frustrating now, that's okay. You're just learning and this is likely one of the first times you've tried auto layout. Keep at it and it'll become second nature in no time. Congratulations, while it may not seem like much, you've gotten quite far already. You learned how to connect user interface element to the code with IB actions, and use IB outlets to change the state of UI elements from the code within your view controller. You've also taken your first steps into auto layout and, of course, in developing for iOS using Swift. Let's take a moment and discuss where these UILabels and UIButtons come from. In developing for iOS, Apple wanted to make it easier for us to create interactive elements. To that end, much as it is on the Mac, they've developed a series of frameworks that we can use in building our iOS app. The main framework you're going to be using in this iOS development is called UIkit. Any classes that start with UI are from the UIkit framework. And these include UILabel, UIButton, UIView, and even UIViewController. We've not talked about UIViewController as much yet, but we're going to go into much more detail in the next lesson. There we'll provide the logic behind a view and what connects it to the model which has all the data. Sound familiar? Yep, it's the model view controller pattern we discussed earlier. There are many many classes inside the UIkit framework, ranging from labels to buttons, all the way to table views. In addition to UIKit, there are many other powerful frameworks in iOS, from audio, to rendering, to web services, to even gathering data from the GPS, gyroscope and accelerometer. We're going to cover quite a lot of them in this course and give you a solid understanding and practice in iOS development. In the next lesson, we're going to take Pitch Perfect and add multiple views. We're going to set the groundwork so it can record audio. A little while ago, you started this course by grabbing x code, and learning a little bit about the swift programming language. In lesson two, you created the first part of the pitch perfect app. Added labels and buttons, and wired them up to code in your view controller. You even took some time to learn about the model view controller pattern. In this lesson we're going to learn how to play audio from the app and navigate between two screens in the iOS app. Let's get started. In the last lesson, you saw how Xcode can automatically create a view controller and wire it up for you. You even added a code to this view controller. At this point you might be wondering what is a view controller and how do I know what methods to override in it? As we're going to see, the documentation will be our guide. The view controller is a special kind of class that, as the name implies, controls a view and handles all of the actions required by that view. In iOS development, this means that this class is usually a subclass of UIViewController. Inherited from the UIkit framework. The view controller is called by a OS when certain events happen to it or your app overall. In the beginning, your app is not running as soon as the icon is pressed in moves through the inactive state and immediately into the active state. When an event happens, maybe a phone call or the user decides to go to another app, your app will transition to the inactive state and then to the background. >From the background state, after a few seconds it will go to the suspended state. What happens when the user wants to go back to your app? If your app is in the background, it will go through the inactive state to being active. Last but not least, if iOS needs more memory and your app is in suspended state and may be moved off memory entirely, and we're back to the beginning of this diagram to the not running state. How do I know or functions UIV controllers has that I should override? How do I know which functions get called and then the what events in this state diagram? It's all in the documentation and it's always the first place you should look. Now, it's a good time to learn how to open up documentation in Xcode. Let's open up the ViewController.swift file, and navigate to the top. Here, you can see the line this shows that the ViewController class inherits from UIViewController. If you hold down the option key, you can see that the cursor changes to a question mark when we go over a class. In this example, UIViewController. If we click once, we can see a contextual manual come up showing us all the information about the UIViewController class. Clicking anywhere else dismisses this contextual menu. If you click anywhere you can dismiss the documentation pop up. Another way to see the full documentation is to hold down the option key but this time double click on the UIViewController class. This will show you the documentation window and open it in full screen. Showing us UIViewController. Another way to view the documentation window is to go under help and choose documentation and API reference. You can also get this window to come up by using the key combination Shift+Cmd+0 anywhere within Xcode. Take a moment now to look for viewDidLoad under the UI view controller documentation. I hope you took a few minutes to look over the documentation for UIViewController. Don't worry if a bit of it seems strange now. You will know this class inside and out by the end of this course. Here's a quick question to test your knowledge. Which one of these is called first in the life cycle of our UIViewController, viewWillAppear or viewDidLoad? The correct answer here is viewDidLoad. viewDidLoad is first called when your ID controller is first loaded into memory, even before it's shown on screen. viewWillAppear is only called when a view controller is about to be presented on screen, but before it is actually on screen. Previously you've seen the view did load gets called, when the view controller class is loaded into memory. This diagram illustrates the view and view controller life cycle. When the view in view controller are changing states, these functions, if you have implemented them, will get called. In iOS, the will functions always get called before the did functions. If YouWill appear, gets called before the view controller in its view are onscreen. If YouDid appear, gets called right after the view and view controller are on screen. This is really useful if you want something to happen right before or right after a view controller's view appears. If you override these functions in your view controller, they will get called. Otherwise, their default in empty implementations in the UI view controller class, will get called instead. The last point bears repeating, as it is a common error I've seen many times. If you mistyped the function name it's not the same function. For example, view will appear as you see here. Has an extra P, into IOS it is a completely different function than the one it's looking for. So I would never call this function, even though, our code would compile. Remember, programming is an exercise in trying to be as precise as possible. Don't worry too much though, Xcode autocomplete will help you in filling out the names of these functions. The viewDidLoad function can be very useful for running code once our ViewController is loaded in to memory. What about running some code right before the view appears on screen? For that, there are two functions we can use. The viewWillAppear and viewDidAppear. WillAppear happens right before the view and ViewController appear on screen. And didAppear gets called immediately after the view and ViewController appear on screen. Remember, that the view and ViewController are linked. A UI ViewController and any subclasses of it have at least one IBOutlet that always goes to a UI view. Here, we're going to use auto complete to help us out. In the ViewController.swift file move right to the bottom in the space directly above the last closing curly brake. Start typing viewWill. You can see Xcode's auto complete showing us the viewWillAppear function. It knows that ViewController is a subclass of UI ViewController. It also knows in UI ViewController there's a function you can override called viewWillAppear. Clicking on this function fills it in for us. Auto complete makes sure that the function name and parameters are correct and that there's no typos. See the highlighted text here that says code? Click on it. This is where we're going to type our code. For now let's add the line, viewWillAppear called. If we run this app by pressing the run button we can see the print statement being called when our ViewController appears on screen. There it is. At this point, we need to figure out how to reach from our code to UI elements. The recording and stop recording buttons. Need to be able to disable the stop recording button right before the view appears on screen, which should also disable the recording button while the recording is in progress. What do we use for going from code to UI element? And ib outlet, let's wire up an ib outlet to the stop recording button and another ib outlet to the recording button. Follow the instructions below to add an ib outlet to the stop recording and recording buttons. Now is also a good time to add the images for the record and stop recording button. Adding images of different sizes is easy with the next code and it can make your iOS app look a whole lot better. To start, click on the assets catalog, this blue icon here in the project navigator. We're going to add a new image set by clicking on this plus button here on the bottom of the screen, and selecting a new image set. Let's name this record button by single clicking on this newly created image set. Now we need images for 1x, 2x, and 3x. We're going to explain, one x, two x, and three x in full detail in the UI kit fundamentals lesson later in this course. For now, just know that we need different sizes for different iPhones and iPads. Our graphic designers have already created those icons for us. So I just need to drag them over from the finder folder to the corresponding Xcode box. Let's drag the record 100 into the one x box. The record 200 into the two x box. And then the record 300 into the three x box. Back in may not storyboard, we can select a record button in document outline and under image, we can select our record button image. Note that our button now has both an image and a text. We can remove the record text since the image does that work for us. And attach record label further explains it. Select a record field here under the title and clear it. And then hit return for it to take effect. Now, since the button has changed, our outer layer constraints are incorrect. We can fix this issue easily with the help of Xcode. Click on the yellow disclosure button here to see our auto layout issues. We see three auto layout issues. One with the Recording Label. One with the Stop Recording Button. And one with the Record Button. Remember that everything on the screen is positioned off the Record Button. So we need to fix it first. Select it here by pressing the CLO disclosure triangle, and choose update frames. Press fix misplacement. This has adjusted the frame on the record button so that it fits the image. For these other two issues we're going to choose update frames as well. Let's first fix the recording label. Update frames and fix misplacement, and do the same for the stop recording button. Update frames and fix misplacement. Now they're all correct and properly positioned off of the recording button. One last thing, let's turn off the screen background. Let's go back into the document outlined here, select a recording button. Scroll down to the background and instead of green. Let's choose the transparent one. That's it, our recording button looks much better. Below you going to find the steps for adding the icons for the stop recording button, so it can look good as well. What we need to do now is to figure out how to disable the stop recording button, when we're recording. We know that the stop recording button is a UIButton. Look at the documentation and see if you can find the function or property to enable or disable the stop recording button. Remember that when you look at documentation for a class like UIButton, you should always check what functions and properties that class inherits from its parent class. UI button inherits from UI control. And UI control has an enabled property that we can set to true or false. Setting this property to false allows us to disable the stop recording button. Let's update the view will appear function so that the stop recording button is disabled right from the start. Take out the print line and now the following to view will appear. Let's make the stop recording button disabled by default. Now we need to wait to enable the stop recording button and at the same time disable the record button. There are two functions you wrote earlier that can help us here, in the record audio function, we can add the following two lines. One line to enable the stop recording button and the second line to disable the record button. Finally in the stop recording function, we can add the following three lines. We can set the record button back to enable, we can disable the recording button, and we can reset the text on the recording label. Let's test it. We can run that by clicking the run button up here or pressing command r on your keyboard. We can see right away that the stop recording button has been disabled when the view loads. If you click record we can see the label has changed and now the stop recording buttons enabled. At the same time the recording button is disabled because we're actually recording. If we hit stop this button is unable to get in and the label has changed back to Tap to Record. Congratulations, you've made it through the first hurdle in iOS development. You have UI elements, and you've wired them up to call your code with IB actions. And you've reach back to the UI using IB outlets. In the second part of this lesson, you're going to learn how to set up multiple views, so that you can go between two different view controllers. No more single view applications for you. Most iOS applications you will be developing will venture further than a single screen. In order to use multiple view controllers, you will need another class, that lets you navigate between them. There are two common classes to use for handling multiple view controllers in iOS. UI navigation controller and, UI tab are controller. Both of these are covered in depth when you get to UI kit fundamentals in the next module. For now let's just discuss the basics of a UINavigation Navigation controller. The UINavigation Controller is a class that handles a stack of multiple view controllers. Like any other stack in computer science or real life, you can insert and remove items from the stack. In the UINavigation Controller you start out with a single view controller, called the rootViewController. You can add as many of your controllers on top of it as you'd like. In pitch perfect we're going to have just two view controllers. One for recording, and one for playback. So our use UINavigationController, will be just for those two screens. Before we can run, we need to walk. Currently our app have the view controller named ViewController as a start of the app. With the main story board opened selected. Notice the little gray arrow here that indicates that this is the initial view controller. If you have multiple view controllers, you can drag this arrow to change which view controller to storyboard, and therefore your app, will start with. This arrow is also driven by the checkbox titled is initial view controller here in the attribute inspector. If you uncheck this arrow, the storyboard won't know what view controller to start the app with and you'll get a runtime crash. Make sure the is initial view controller is checked. With the view controller selected, the orange circle here in the document outline, go into the editor menu and select embed in navigation controller. You can see that x code has created a UInavigation controller to start the app, and that our view controller is the root view controller of that navigation controller. Now you're ready to add more view controllers to pitch perfect. Now we get to add a second view controller to our app. Adding another screen and view controller to manage that screen is just what we need to turn pitch perfect into the app we want. Open the library panel here on the bottom right. If you don't see the library panel, make sure you have the objects library button selected. It's the third one from the left here. Drug our view controller onto the storyboard, like this. You may want to position it as I have here to the right of the records view controller. Let's make it clear we're going to the new screen. We can use our old trick of changing the background color of the new view controllers view so that it's something other than white. Here I've selected the view controller and it's view. You can see Storyboard has automatically zoomed in to the second view controller. With this view selected, I'm going to change the background color to something other than white, in my case, green. Set it to whichever color you prefer just so that it's something other than white. Now, we need to make storyboard transition from our recording view controller, which is just called view controller, to our new view controller. For now, what I want is to connect it to the stop recording button. First, select the stop recording button here in the document outline. Then you can hold down the control key and drag directly from it to the new view controller. Select the show segue. You should see the new symbol with the arrow connecting the two view controllers, seen here. This is called a segue. Remember we previously wired up the stop recording button to the stop recording function, VN IB action. It means the stop recording button is doing two things. It will call the code in our recording view controller and it will also cause the segue to occur, moving us to the next view controller. Now you may be thinking yourself, wait a minute, where is the code for that green view controller? We never created any class. You're correct. Storyboard is using the default UI view controller, not a subclass that you wrote. And there's just a plain UI view of which we've changed the background color. Let's run this app and see. If we click Tap to Record and then Stop the Recording, we can see that the Ui navigation controller has transitioned us to the second view controller, that's green. Take a moment to notice the new bar, called a navigation bar, and the back button labeled Back. This is a pre-built back button that will return us to the previous view controller, a sort of breadcrumb if you will. We have just scratched the surface of UI Navigation Controller. Because that is all we need for now in order to build out the pitch perfect app. In UI fundamentals you're going to learn about UI Navigation Controller in much further detail. Before we go any further, let's just do a quick little quiz. You learned that UINavigationController is a class that helps us manage the stack of UI View Controllers. We'd often get asked this in class. How many View Controllers can you have in your app managed by a single UINavigationController? 1, 1 to 2, 1 to 256 or 1 to as many as you need? The UINavigationController manages a stack of UI View Controllers. As such, you can have as many View Controllers as your app needs. You need at least one View Controller, and you can add as many as it makes sense for your app. You can always add and remove View Controllers from a UI View Controller stack. Note that this is in stark contrast to the UI tab bar controller you will learn about later in the course, that manages a fixed set of UI View controllers. Segues are used to transition from one view controller to another in the story board. There are many types, for now we're going to use the show segue to display a new view controller and its view on top of the existing view controller. We've got a couple more steps until Pitch Perfect is ready for the app store. We have to set up the playback view, and for that I'm going to show you an amazing new tool called stack views, that will make your life with other layout constraints a lot easier. In addition, we have to actually record the audio in the first view controller, and pass that along to the second one. Luckily, in iOS, that's but a few lines of code to use with the segue you just created. It may seem like a lot of steps, but so far, you've created the foundation of your first iOS app. You built the beginning of two screens, and you're ready to add in audio with the help of another iOS framework called AV Foundation. Take a breather, and when you're ready I'll be there in the next section. You have met a lot of new classes and iOS features in this lesson, from using the storyboard to segues to the UI navigation controller. It was just a short time ago when you started your journey in iOS development. Before going further it helps a lot to recap what you've learned. Write in the area below, in your own words, what you have learned in this lesson. I hope you made some good progress on both of these tasks. Ask us questions on the discussion forum, if you are stuck some place. In this and the next video, I will highlight some common constraints related issues that students in this class have been having. So I changed the image for this button and it now looks like a rabbit. I also want to make sure that it lines up well with the other button, so I will move it around and use these blue dotted lines as my guide. There. Now, to add constraints to this button, I can hold down the Ctrl key on my keyboard, and add a constraint to the top space. After that, I can add a constraint to the trailing space also. Now, I want to make sure that the leading space here, is equal to the trailing space here. To do that, what I can do, is select this constraint and drag out the utility area, and under size inspector, I can see that the value of this constraint is a constant 30 points. So I can now select the other constraint, the trailing space constraint, and change its value to 30 also. Finally for the star button, let me scroll down a bit so we can see it properly, I can add a constraint so that we center it horizontally. And I can also make sure that it is pinned at a constant distance away from the bottom of the phone. Okay, let me run this project and see how it looks. I'm going to go to the second screen, and there it is. All three buttons are showing up in the correct location, although, it seems these two buttons are way too close to each other. I will let you play around with the leading constraint here and the trailing constraint here, so that these two buttons look evenly spaced on the screen. In this lesson, I'm going to introduce you to another great framework called AVFoundation. The AV stands for audio and video. It is the audio part we're going to look at in more detail. In particular, we're going to use a class called AVAudioEngine. That'll let us record audio, mix and alter it, and play it back. Here, we can see our application, Pitch Perfect, on the top of the stack. On the bottom is the Audio Hardware, that's going to record and play back the audio. To use it, we're going to go through the AVFoundation framework, and in particular, the AVAudioEngine class. Ready? Let's get to recording some audio. There is a very useful class inside of AV foundation that focuses on recording audio called AVAudioRecorder. We're going to utilize this class for, you guessed it recording the audio. One important skill in iOS development is being able to read code that you have never seen before. I'm going to show you a bit of code, and ask you to get a gist of what it's doing. We're going to be taking a closer look at this code, and see if you can tell what's going on. This is the first time you've seen the code for AVAudioRecorder. There are a lot of other features in Swift here that we've not covered yet. In your path to becoming an iOS developer it's useful to be able to read someone else's code, and derive some understanding of what it does. Look over this code. What does it do? Here, we see a function called record audio. In it, we see a directory path and an audio file name. Following that, we see an audio session getting created with something called AV audio session category being set to PlayAndRecord. After that we see an initializer for the AVAudioRecorder taking in the filePath. Finally we see the AVAudioRecorder preparing and recording. Don't worry if not all of it made sense just yet, we're going to be going over the AVAudioRecorder code in detail next. Also we're going to cover optionals, the little exclamation marks that you see in the UI kit fundamentals part of this course. There's a lot going on here and some of it we have not discussed before. As an example, the exclamation marks indicate these are implicitly unwrapped optionals. A concept in swift that you'll learn in the UI kit fundamentals lesson in a later part of the course. Let's break down the audio recorder code piece by piece. You can see we first import AVFoundation, the framework that has AV audio recorder. Without this import, Xcode won't know about any AVFoundation classes, and our IOS app won't compile. If we scroll down to the record audio function, here, we see what looks like the code to get the directory path and build a full path, including the file name. In the essence, this grabs the pitch perfect's document directory and stores it as a string in the dirPath constant. Later in this course, when we get to persistence, you'll learn the various directories and storage locations available in IOS. For now, we just need a place to store the audio recording and the documents directory will work just fine. A few lines down, we make an array with the directory path and the file name. Join those together and create a URL to use with AVAudioRecorder. We also print out the path so you can see it in the console. Next up, we grab the AVAudioSession and set up the category to play and record. In order to either record or playback audio, we need an audio session. There's just one that exists for the entire time your app is running and we grab it with a shared instance method. The AV audio session class is basically an abstraction over the audio hardware. Since there's only one audio hardware, there's only one instance of AVAudioSession. You grab the shared instance that's used by all apps on the iOS device. This is a common pattern you will find in cocoa touch. When you reach into the iOS API and grab a singleton, it is usually a function called shared instance. So with the AVAudioSession set up, we can set up the AVAudioRecorder. Here we see the line with AVAudioRecorder inside of a try statement, without handling if it fails. We will cover error handling later in this course. For now, we can just assume it will work. We tell it to prepare recording and start recording. That's it, AVAudioRecorder is now recording audio. Before we go any further. It would be great if our view controller where the recording happens was called something other than just view controller. In writing your app, there are times when you might want to rename your classes. And it takes just a minute. Let me show you. To rename our view controller, we're going to do three steps. We want to change the name of the view controller to Record Sounds View Controller. First, in the project navigator S=select a viewcontroller.swift file and single click. Change the name to record sounds view controller. Open the class we just renamed and change the name in the comments and in the class decoration to record sounds view controller. You can press command s to save this file. One last step, we have to tell the main.storyboard that the view controller for this view, is no longer called ViewController.swift, but it's now called RecordSoundsViewController. Open the main.storyboards file and select a view controller for a first view. Switch to the identity inspector and change its name to RecordSoundsViewController. Press return to make this take effect, that's all it takes to change in name of a class. Next, let's add the AV audio recorder code you saw earlier. Now that you understand AVAudioRecorder, it's time to get that code into PitchPerfect. In Xcode, open up the RecordSoundsViewController.swift file. Let's start by adding in the import statement for AVFoundation right here, underneath where it says import UIKit. Inside the RecordSoundsViewController class, let's add our variable to BD AVAudioRecorder. I'm going to add it hear underneath IBOutlet and call it AudioRecorder. Scroll down to the recordAudio function. In here we're going to add the lines for creating the audio session, and telling AVAudioRecorder to start recording audio. You can find all the code I've typed here directly under this video. At this point our code is able to record the audio and save it to the recorded voice .wav file. What about when we want to stop recording? That is handled when the stop recording button is pressed. And you wired up that button to fire up the function stopRecording in the previous lesson. Let's go there. In the stopRecording function, let's add these three lines to stop the recording. We'll tell the audio recorder to stop, and then we'll close out the session. That's all it takes. PitchPerfect is now able to record your voice. If you run it and press record, you'll see the file name and path in the debug console. So far so good, but we need to figure out a couple of things. Mainly dealing with sending the audio to our second view controller, which you're about to build. If we think about this, we have two problems on hand. The first is we need a way to pass the audio file from the first view controller to the second one, so it can be played back. The second issue that we have, is what happens when we record a large file and transition before it has been written out to flash storage. In other words, we need to only move from the first view controller to the second view controller, once AV audio recorder has finished writing out the recorded voice, that way file. Let's fix the issue of determining when we should transition to the second view controller. We can do this by changing the segue to only be called from code, and not to directly by the storyboard when we pressed the stop recording button. We know that we're recording our voice that records sounds view controller. Once recording is finished, we need to send that file over to the second scene. The play sounds view controller. How do we change the current segue to be called just by code and not from a UI button? If you look in the main dot storyboard file here, we can see the two scenes are connected via a segue. In particular this segue's wired up to the stop recording button, every time this button is pressed, Storyboard will perform the segue. What we really want is to be able to call this segue programmatically, once we know that the AV audio recorder has finished writing out the file. This is easy to do, let me walk you through it now. Let's start by deleting the current segue, select the segue here in the document outline, and press the delete key. Xcode will complain that the second scene is unreachable since we have no way to segue into it from anywhere else in the storyboard. You can see that warning in the Xcode status bar here, to fix the warning and set up a segue that we can control programmatically. I'll hold Control key and drag from the first View Controller to the second View Controller. The easiest way to do this is from the document outline. I'll expand the view controller scene here so that I can see both view controllers. >From the record sound view controller, with the control key held down, I'll drag into the view controller and select show segue. Now that these two scenes are connected via segue, we can have the storyboard perform the segue by calling a function named perform seg. We'll set up the perform seg call shortly, but in order to distinguish this segue from any other one, we need to give it a unique name. Select the segue here in the document outline, and in the Attributes Inspector, let's give it a unique identifier. I've given it the name stopRecording, these names are case sensitive by the way. Make sure you spell it correctly. Next we need to know when AV Audio Recorder has finished writing out the recorded voice file. To do that we need to use a concept called delegation. Okay, we have just introduced a lot of new concepts. What comes to mind when you hear the word delegate? What if I want to delegate something from class A to class B? Write below what you think delegation means in iOS. A common answer we've heard from our students when we asked them about the word delegate is that it made him think of a relationship between a manager and an employee, or parent and a child. Perhaps you've also experienced a situation where work has been passed on or delegated to you. In iOS delegation works much the same way. But it can be between any types of objects. It really just means getting one object do the work for the other. In the case of AV audio recorder it does not know anything about our view controllers or even your app. It does know that once it finishes recording it can inform the other class, our record view controller that it's finished. The delegate, the record view controller, could then do the work of whatever needs to be done with the recorded audio. In this way you can use AV audio recorder as a tool to just record the audio and it calls out to its delegates. The record view controller to do something with it. Let's add delegation to the record sounds view controller. First we have to tell Xcode that our record sounds view controller conforms to the AVAudioRecorder delegate protocol. That is to say. we'll implementing a function described in that delegate protocol, and our view controller can act as the delegate for AVAudioRecorder. And the RecordSoundsViewController.swift file, go to the class declaration and indicate that we conform to the AV audio recorder delegate, by adding it here after UIViewController. A class in Swift can only inherit from a single superclass, but it can conform to as many protocols as you want. You just have to list them here separated by a comma. Next we have to tell the a.v. audio recorder that the record sound view controller can act as its delegate. In the record audio function we can set our view controller self as a delegate to the a.v. Audio recorder with this line. Scroll down to the bottom of the record sounds view controller.swift file. Because we've already informed Xcode. That our record sounds view controller conforms to the AVAudioRecorder delegate. If we start typing. We can see that Xcode autocomplete automatically shows us. The functions available in the AVAudioRecorder delegate. Including AudioRecorder did finish recording. If you hit the return key, Xcode will fill this function out for us. This is the function we're going to use to call the stop recording segue that we set up earlier, and move to the audio playback scene. For now let's just add a print statement to let us know when AV audio recorder is finished, right here where it says code. You've learned a bit about delegation and AVAudioRecorder. Before we go any further, it is good to reflect on delegation. Take a few minutes to summarize what you've learned about delegation. How can AVAudioRecorder know that we have implemented the audioRecorderDidFinishRecording function inside of our class? Where is that function defined? AVAudioRecorder knows that it can call the audio recorder did finish recording function in our code because our class conforms to the AVAudioRecorderDelegate protocol. We can take a closer look at this protocol by choosing it here in the class definition, right-clicking, and selecting jump to definition. Here you can see some a declaration code for the AVAudioRecorderDelegate protocol and that function that we're talking about audioRecorderDidFinishRecording. To go back you can select any of your classes here in the project navigator or just hit this back button up here on the top. Let's summarize what we need to do. The AV audio recorder is going to call out the record sounds view controller once the recording is complete. And the file is saved right to this function here. We need to den call the stop recording segway and so on along with it the path to the recorded sound. If we had this line to the audio recorder did finish recording function that you see here. We can call the stop recording segway and send it the URL for the recording file is located. Notice something here, the audio recorder did finish recording function, receives a flag, indicating if saving the recording was successful or not. We should read that flag and if saving the recording failed, we can print out a message to the console. I'm going to switch out the single call here. For an if statement. If the flag is true then I'm going to perform the segue. And if it's false, I'm going to print out saving of the recording failed out to the console. Now we just need a way to inform the play sound's view controller it just received the URL of the recorded audio. Lucky for us, UI Kit makes that fairly simple as I'll show you in the next step. So far. We have been using a generic UIViewController. For a playback scene. You had just set the generic UIViewController's UIView. To have a green background. UIViewController is a great class. But we cannot add any code to it directly. In order to do audio playback. We need a UIViewController subclass. That we can add our play by code to. I'm going to show you how to create this new class, which we will call the Play Sounds View Controller. With the Pitch Perfect project open in Xcode, let's choose File > New File. Select Source under iOS, and then Cocoa Touch Class. Click Next. For the class name, let's call it PlaySoundsViewController. Set it to be a subclass of UIViewController, and make sure, also create NIB file is unchecked. Even though it's written as XIB we still call it a NIB file for old historical purposes. Make sure the language is Swift and click next. Here we can just make sure that it's part of our project, and that our project is selected as the target and click create. We can see our new PlaySoundsViewController.swift file in the project navigator. There is one more step. The storyboard does not know we want to use this file for the second view controller. Let's walk through changing that. Open the main doc storyboard, and select the second view controller scene. Be sure to click on the orange view controller circle. Open the inspectors panel by clicking on the top right button here. Select the identity inspector as the third one from the left. In the drop down for the class let's select, play sounds view controller. Press Return for it to take effect. That's it. Now storyboard knows to use our new play sounds View Controller class instead of just a generic UI View Controller. When we just ran the Pitch Perfect app, we saw that the segue is getting cold. But that the play sounds view controller still does not know the path of the recorded audio. When the segue is called, there's a function that's triggered on the existing view controller to help it prepare for segue. It is called, prepare for seg. Remember this is on the existing view controller, not the one we're going to. So let's open up record sounds view controller and scroll towards the bottom. If we start typing prepare, we see that auto complete fills our prepare for interface or prepare for segue. Let's choose prepare for segue. In the prepare for segue function, we need to add a few lines of code. First we check that this is a segue that we want. That it has the stop recording identifier. Then we can grab the play sounds view controller from the handy property destination view controller. Because this property is of type UI view controller, but we know it's a play sounds view controller, we can downcast it. As you see here with the as! Next we grab the sender, which is where we pack URL. And finally, we set the record audio property of the play sound view controller to that URL. Now, the play sounds view controller is receiving the recorded audio file URL and is set for playback. We've covered a lot of ground in the session. >From a quick intro to protocols and delegation, to learning and implementing AV audio recorder. We're almost the last step in having a finished pitch perfect app. Your app can now record sounds and pass them over to the play sounds View Controller. In the next lesson, we're going to cover how to play back audio, what changes the pitch, and how to more easily position interface elements using stock fuse. When you're ready, I'll be waiting for you at the next lesson. We've come to the end of this course. And this is a great opportunity for us to pause and reflect on the things that we've learned together. Take a moment to think about what you've learned in this course and write it down. You can either draw an image using pen and paper, then take a picture of it. And share it with us, using Twitter, LinkedIn, or Facebook. Or if you want to keep your work private, you can write down everything that you've learned in this text box. Welcome to the final lesson in creating your pitch perfect app. We have covered a lot of ground, and you have a solid foundation in iOS development. You've learned about Xcode, the Swift programming language, how to use a view controller, IBActions and outlets, UI buttons, and UI labels and even UI navigation controller, and having two view controllers in the same app. In this final lesson, we'll be adding audio playback and learning about Stack Views, which will greatly simplify your use of auto layout constraints. Ready? Let's dive into Stack Views. Stack views are a new UI element. Introduced in IOS 9 and as the name suggests, they make it easy to stack views. You can have any UI view sub-class inside a UI stack view. In PagePerfect, we're going to place our play back buttons inside a set of stacked views. Stack views can have either a horizontal or vertical orientation. You can control the alignment, distribution and spacing of a stack view. Stack views can be nested inside each other. Here you can see a vertical stack view for the entire screen with horizontal stack views nested inside for each row of buttons. The real beauty in using stack views is that you only need to create our layout constraints for the stack views. What about all the UI elements inside the stack view, like are buttons in PagePerfect? The stack views create their own outer layout constraints for all the UI elements contained in them based on the alignment, distribution and spacing settings you provide. Let that sink in for a second. Instead of having to create our layout constraints for all these buttons we can just embed them in UI stock views and let them do the work. Let's add stack views to Pitch Perfect. Open the storyboard file and navigate to our place sound view controller scene. Let's start by changing the background of the view back to white. Select the view in the document outline, and then, in the attributes inspector, select white as the background color. Okay, now to add the stack views. In Pitch Perfect, we're going to have a vertical stack view as the base with horizontal stack views embedded inside of it. Make sure the object library is open here, on the bottom right, and put in the word stack into the search box. You should see horizontal and vertical stack views. Drag a vertical stack view onto the view. You should see it underneath the view in the document outline, here on the left side. Drag diagonally from the vertical stack view back to the view. With the shift-key held down, select Leading Space to Container, Trailing Space to Container, Vertical Spacing to Top Layout guide, Vertical Spacing to Bottom Layout guide and select Add Constraints. This will add the constraints we need, but the stack field is still the wrong size. The reason is that Xcode has put in constants in the constraints to keep the stack view at the size you see here. We really should move those and make it the same size as the view. To do that, go into each of the four constraints and set the constant to zero. As you do this, you'll notice that the stack view will start to look correctly. Once you finish setting all the constants to zero, the stack view will be the same size as the view for our play sounds view controller. Let's make sure the main vertical stack view has the correct fill and distribution properties. Select a vertical stack view from the document outline. In the attributes inspector, choose Fill for the Alignment, and Fill Equally for the Distribution. Make sure spacing is set to zero as you see here. For this next step, Xcode is going to display a few auto layout warnings while we drag the new stack view onto our scene. Don't be alarmed, the warnings will be there while the stack view's empty. Once we had buttons to it, the stack view will know how to size itself and the outer layout warnings will disappear. >From the object library, search for the word stack, drag a horizontal stack view underneath a vertical stack view. Select the horizontal stack view, and in the attributes inspector make sure alignment is set to Fill, and distribution is set to Fill Equally. In the next step, we're going to add the buttons for slow and fast audio playback. Now we need to add the buttons for the slow and fast playback of the audio. For this we're going to use two UI buttons. With the main story board open and the play sounds view control selected, let's search for button in the object library in the bottom right. Drag that UI button to the document outline directly under the horizontal Stack View. In the attributes inspector remove the word button underneath the title. In the image drop down select the SnailButton. In the document outline single click to select this button and let's rename it to the SnailButton. Now let's set the RabbitButton with the same steps. Drag a UI button under the horizontal Stack View underneath the SnailButton. In the attributes inspector for this button, let's erase the title and for the image, let's select the Rabbit. Finally, single click on this button to select it and let's change the name to RabbitButton. That's all it takes to add buttons into a Stack View. Next, we'll add the buttons for Darth Vader and squirrel sound effects, as well as another horizontal Stack View. The next step is to add a second horizontal stack view. So that it can hold a chipmunk and Darth Vader sound effect buttons. With the main storyboard file open and the play sounds viewer controller selected, open the main storyboard file, and select the play sounds view controller. Let's search for stack view here in the objects library. Drag a horizontal stock for you from the object library into the document outline. Make sure that it's embedded inside the vertical stack view, our outer most stack view here in the document outline. The easiest way is to drag it above the first horizontal stack view and reorder them here in the document outline. Your document outline should look similar to what you see here. One more thing, with this new horizontal stuff you selected, change the distribution setting in the attribution specter to fill equally. Xcode may be warning you about auto layout constraints because this new horizontal stack view does not have any UI elements inside it. A search for buttons here, I'm going to drag one under our Neo horizontal stack view. In the actually inspector I'm going to remove the text for this buttons title and changes image to chipmunk. I'm going to rename it here in a document outline, the chipmunk button. We need to follow the same steps to create the Darth Vader button. We'll drag a button from the object library underneath the new horizontal stack view, remove the text from the title and this time change the image to Darth Vader. We need to make sure that these buttons are on the same level. That is, they're inside this horizontal stack view. We can do that by toggling this disclosure triangle here. That was easy, now we have four buttons in this view perfectly aligned and we have not had to add a single auto layer constraint. It is time to wire up the buttons. This will allow us to start the audio playback and change the state of the buttons. Remember that when reaching from code to UI element we'll use IBOutlets. And from UI element to call our code we'll use an IBAction. We're going to start with IBOutlets. Instead of dragging each button and using the assistant editor, an easier way is to write out the IBOutlets in code and then just connect them via Interface Builder. Open the PlaySoundsViewController.swift file and add the following lines here inside the class. These are the IBOutlets for the six playback buttons and the stop button. Now we just need to connect these IBOutlets. Open the Main.storyboard file and select the play sounds view controller scene. Make sure the document outline is open and that you can see all the buttons. With the Ctrl key held down, drag from the Play Sounds View Controller down to the SnailButton and select the SnailButton as the outlet. This has connected the ID outlet named SnailButton to the actual snail UI button. Let's do the same for the other buttons. With the Ctrl key held down, connect the RabbitButton, the ChipmunkButton, the DarthVaderButton, the EchoButton, the ReverbButton, and the StopButton. Now our view controller code can reach out to all of the UI button using these IBOutlets. The next step is to connect the buttons to an IBAction so that when you press a button, the code inside our PlaySoundsViewController will run. >From what you've learned so far, you might be thinking we need to create seven IBAction functions, one for each button. There's a better way, with less duplication of code and I'm going to show you that here. We're going to create two IBAction functions. One to handle all six playback buttons and one to handle the stop button. Open the PlaysSoundsViewController.swift file. Underneath the IBOutlets you have just created, add these two functions. We have an IBAction function to play the sound, and we have an IBAction function to stop playing sound. Now we just need to connect the six playback buttons to the playSoundForButton IBAction. We also need to connect the stop button to the stopButtonPressed IBAction. Let's go back to the Main.storyboard file and select the Play Sounds View Controller scene. For this step, it helps to have all the buttons visible in the document outline. You may need to open the disclosure triangles as I've done here. With the Ctrl key held down, select the snail button and drag into the Play Sounds View Controller. Select the playSoundForButton function from the pop-up. Let's do the same for the rabbit button. With the Ctrl key held down, drag to the Play Sounds View Controller and select play sound for button. Follow these steps for the chipmunk button, the Darth Vader button, echo button, and reverb button. All six play buttons are calling the same IBAction function. For the stop button, we need connect it to the stopButtonPressed IBAction. Let's run and see if everything is wired up correctly. Press the run button here to start Pitch Perfect on the iOS simulator. Let's just quickly record and stop so that we can transition to the Play Sounds View Controller. If we press on the snail playback button, we can see the playSoundForButton function is getting called here in the console. Let's try it for the other five buttons. Lastly, let's check that the stop button is wired up by pressing on it as well. That was a bit of work. But now we can reach into all of the buttons from our view controller using IBOutlets and have the button call our code using the IBActions. Now that our user interface is set up, we can start writing our audio playback code. Audio playback using AVAudioEngine involves setting up audio player notes with content. We will also be using the AVAudioUnitTimePitch class to make changes to the pitch of the audio output. In order to make your audio playback code a little easier, we've included the functions you need in a class extension file that you can import into pitch perfect. Class extensions allows us to add code to the PlaySoundsViewController class, even though this code resides in another file. This is going to provide you with a black box to play back the audio but don't worry, you can see all the code inside a black box. And I'll cover it, line by line, a little later in this lesson. In the PlaySoundsViewController.swift file add the following instance variables enum after the IB outlets. Now, we can bring in the class extension. It is a file called PlaySoundsViewControllerPlusAudio.swift and you can find it in the resources for this lesson. I have it here on this folder and I'll just drag it into Xcode. Make sure, Copy Item if needed, is checked and that the PitchPerfect target is also checked. Click, Finish. I'm going to walk you through the code you've just added line by line, a little later in this lesson. For now, we can concentrate on just calling out to it and having the audio playback. First, we want to add a call to the setup audio function in the viewDidLoad so that the AVAudioEngine is properly setup. This is one of the functions that is included in the extension you've just added into Pitch Perfect. Add the line to call set up audio here in the viewDidLoad function. Next, let's configure the UI, so that the stop button is disabled when this view first appears. As the app won't be playing any sound until the user presses one of the six playback buttons. In the extension file you just drag in, there's a convenience function to reset the buttons to the proper state when playing or not playing music. We need to set them to not playing right before the view first appears on screen. Now, what function can we use for that? If you're thinking viewWillAppear, you're right. Let's add the viewWillAppear function to the PlaySoundsViewController. In viewWillAppear, add a call to the configure UI function telling it to set the buttons to the not playing state. One step left before Pitch Perfect can play back the audio and that is what we're going to be covering next. You have built the user interface and imported the extension to the PlaySoundsViewController. We're in the final step to getting pitch perfect to playback the audio. Let me walk you through what we need to set up. If you think back to earlier in this lesson, we wired up all six sound effect buttons to call the play sound for button function. What we need now is a way to distinguish between each of these buttons. And then call the appropriate function in our extension to play that sound effect. There are several ways to distinguish one UI button from another. But the easiest is using the tag property of the button. This is just an integer value we can assign the UI button. And then later query in the play sound for button function. With a button selected, in the attributes inspector open, you can scroll down to the view section and see the tag here, on the bottom right. The default tag value is 0. Therefore, all of our UI buttons have 0 as their tag value. Time to change that. The snail button is the first button. So it can have a tag of 0, but we should change it for the other five buttons. Open the main.storyboard and select the place sounds view controller scene, as I've done here. Select the rabbit button, scroll down to the tag, and set it to 1. Now select the chipmunk button and in the attributes inspector, set the tag to 2. For the Darth Vader button, set the tag to 3. For the EchoButton, set the tag to 4. Finally for the ReverbButton, set the tag to 4. Now we have different tag values for each playback button from 0 to 5. The next step is to change the play sound for button function. So it does a different audio playback depending on what button was pressed. Let's go to that function in the PlaySoundsViewController.swift file. To make more space, we can use Cmd+Option+0 to close the right side. Remember the enumeration you added earlier here for values from 0 to 5? We can use them in the switch statement to call the playSound function differently for each of the buttons. Add the code for the switch statements that appears as you can see here. If the slow or fast button is pressed, we'll play the sound at a different rate. If the chipmunk or Darth Vader voices are selected, we'll alter the pitch. If echo or reverb sound effects are selected, we'll pass the settings onward to the playSound function. While playing audio was great, it would be nice if we could stop playback when we want to. We do have a stop button and it's already wired up to call the stop button press function in our playSoundsViewController. All we need to do is to add a call to the stop audio function that is in the class extension. And they'll do the work of calling out every audio engine to stop the playback. If you follow along to this point, we should be able to test the Pitch Perfect app. You should be able to record yourself and hear the playback with a variety of sound effects. Let's try it. Swift is great. Swift is great. In the very short amount of time, you got pitch perfect built from the ground up. A fun iOS app that can record and playback audio with sound effects. If you're curious about the calls to AV audio engine, I'm going to go over that next. For now, pat yourself on the back. You are already an iOS developer Let's walk through the play sounds view controller plus audio class extension to understand exactly what this code is doing. Open the play sounds view controller plus audio swift file and navigate to the top. The first thing you see here is a struct of alert messages. This is just a convenient way to have the alert messages in a single place. If you have strings or other static items that you want to use throughout your app, this is a good practice to follow. Below that, you see the playing state enum, which will be used by the configure UI function to set the button states depending if we're playing or not playing any audio. Next up is the set up audio function, which is where we try to load the audio recording file passed in from the record sounds view controller. If loading the audio file fails, we present an alert message to the user. By the way, did you notice these MARK statements here in the comments? These are to make it easier for you to jump around in your code. When you pull down the function listing in the editor toolbar, you can see the section headers in bold. It makes it easier for you to jump to the relevant section. The play sound function is the main function in this extension. As the name suggests, it carries out playing back the audio. This function has something you have not seen before, that is, optional parameters. See the question mark here, after rates float type? It indicates that rate is an optional parameter and if you don't pass it in it'll be set to nil. The same is true for pitch. The first part of the function is to grab the AVAudioEngine and create an AVAudioPlayerNode. Next, we check if the rate or the pitch parameters were passed in, since there're optional. The way we do this check may look a little weird at first as we're doing a value binding inside an if statement. See the line here, if let pitch = pitch. You really should read it as, if the pitch variable is not nil, then execute this pitch statement. If pitch is nil, we'll skip over this code. Likewise, if rate is nil, we'll skip over this code too. The concept of value binding is covered in UI fundamentals in the next lesson. Next, we create an echo and reverb notes, but we will only use them if either the echo or reverb parameters were passed in and set to true. We can either have an echo and reverb, just echo, just reverb, or neither. Lastly we tell audio player to stop playing any current audio, and schedule our recorded audio for playback. This ensures that the recorded audio is in memory, and ready to be played. This part here that looks like another function, is actually a trailing closure. The schedule file function takes in a completion closure that it runs when the audio file is ready to start playing. This code here sets a timer to fire when the audio is done playing that resets the button to the not playing state. Now that everything is set up, we try to start the audio engine and the audio node playback. At this point, the audio would be playing. Connect audio nodes is just a helper function to connect a set of audio nodes together in the audio engine. As with most helper functions, this just cuts down on the duplication of code in the play sound function. The stop audio function is in charge of stopping the audio. Remember that timer we set back in the play sound function? We don't want it to fire as we're stopping the sound here. So the first if statement invalidates or cancels that timer. The next few lines stop the audio player node and the audio engine, itself. Next, we come to the UI functions, which are really just in charge of enabling and disabling in the six playback buttons and the stop button. These are helper functions and they help us by avoiding duplication of code. We just have one place to enable or disable the buttons, depending on if we are playing or not playing audio. You can see that configureUI itself uses another helper function to toggle the playback buttons. If you pass in false, they all get disabled and if you pass in true, they will all be enabled. Last step is the showAlert function which simply displays an alert to the user using UIAlertController if something goes wrong. That it. I've taken you through the black box class extension that allows all the audio to be played back with changes to pitch, rate, with echo, and even revert. Remember that there's no harm in playing around with this code. You should feel free to experiment and changing the settings and more. Congratulations, you've made it through the lessons on pitch perfect. You added to your knowledge of UIkit and view controllers by getting comfortable with stack views. You even got to see how iOS can play back audio, including changes to pitch. This is just the beginning of your journey, in the next set of lessons you learn more about swift, UIkit, networking, concurrency and even persistence. Before jumping ahead, it's good to reflect on what you've learned in these lessons. We have a challenge for you after reaching the end of Pitch Perfect. Draw an image using pen and paper that highlights everything that you have learned about iOS development, so far. Take a picture of it. Share it via Twitter, LinkedIn, Facebook, or upload it to our forum. Use the hashtag, #learningswift and reference our Udacity account. If you want to keep your work private, write down everything that comes to mind in this text box.