Hey there and welcome to Networking For Web Developers. In this course you'll learn a bunch about how the internet works and how applying that working knowledge can help you make your web apps better. As a web developer you may already know a bit about HTTP, but you might not yet know what it's built out of. This course gives you a basic understanding of the workings of internet protocols. Focused on the protocols that underlie HTTP. To get the most out of this course, you should already be familiar with HTTP itself, and also with using the Linux shell, SSH and command line programs. If you need a bit of a refresher on those, take a look back at the Audacity courses in Linux Command Line Basics, Configuring Linux Web Servers, and Designing RESTful API's. To do this course, you'll need to log in to a Linux system. If you're taking this course as part of a Udacity nanodegree program, you can use the development instance that we've set up for you. In case you lost track of it, there's a link to it in the instruction notes. Otherwise, you can use a real Linux server, or you can set up a virtual machine that runs on your regular computer. See the instructor notes for a link on how to do that. Next up, I'm going to give you some written instructions on how to install the tools you'll need for this course on your Linux system. Now that you've got the software installed and have logged in, here's some commands to try out. Don't worry about what they mean yet, just give a few of them a try. You'll see them all again later. If there are a few things here that look familiar to you, cool. If not, don't worry. By the end of the course, these will all be old friends. By the end of this course, you'll know how to use all of these tools. All of these things are actually really useful for understanding the network and finding out what's going on under the hood of the web and for debugging various sorts of network problems that might affect your web app. Let's pull just one of these commands out to start. 8.8.8.8 is the address of a particular service at Google. And ping is a command for testing whether your computer can send and receive network traffic with that address. And -c3 means to send three test messages, then quit and print results. All traffic on the Internet is split up into messages called packets. A packet is just a short message sent from one computer to another with the addresses of the sender and the recipient on it. You can imagine that network traffic is made up of a stream of little postcards going back and forth, carried over the various media like Wi-Fi, and ethernet, and cable modems and so on. The ping command sends and receives individual packets to test whether traffic can get from one address to another and back. So if you ran ping -c3 8.8.8.8, pinging this service at Google. And you got results that looked like these, specifically, 3 packets transmitted, 3 received, 0% packet loss. Which of the following conclusions seem reasonable? One, that your computer has Internet access. Two, that the computer at 8.8.8.8 is up and running. Three, that there is a website you could access at http:// 8.8.8.8. Four, that your computer is directly on Google's network. Or five, that your ISP knows how to send traffic towards Google. Check whichever ones of these apply. So the first, second and fifth of these are probably true. Unless you work at google your computer is probably not directly on their network. And just because computers is up and running doesn't mean that it has a web server running on it. For instance the machine that you're using to watch this course has an IP address. But it only has a web server if you've started one on it. But it's on some network, and that network is somehow connected through to Google's. The reason that we know this is that ping sent some traffic to this address, 8.8.8.8, and it got responses back. So that means not only that we're on a network and that they're on a network, but that we're on a network that can talk to theirs. So you've probably heard of this cloud thing before. Network diagrams such as this one are actually where the term, the cloud, to mean Internet services, comes from. The idea is that we don't need to know what's going on inside this cloud. It's hidden from us. All we need to know is what service we're talking to at the other end and that the network will get our message all the way from us to them. If this is us over here with a Chrome web browser, and they're over there with an Apache web server, we can do an HTTP request and get a web page back, even though the network in the middle doesn't even need to know that web pages are a thing. The ping program, on the other hand, is a little unusual for a network program. The message that it sends, called an Echo request, is received by the destination system's operating system. In an application protocol like HTP or SSH, there's a server program that composes a response and sends it back. But with ping, there's no ping server. The Echo request just goes to the operating system on the receiving end, which sends a response back. Every operating system that supports Internet access supports ping as well. So regardless of what system we're using, we could ping a system running any operating system. Could be Linux, or Windows, or Mac OS, or BSD, or something else. There is something to keep in mind is that although ping is simpler than HTTP, HTTP is not based on ping. So let's see what HTTP is built on. By this point in your web dev education, you already know aboutt HTTP verbs like get and post. And sending requests to web servers. If not, check out the link in the instructor notes. Likely you've done that from your own code and you've run web services that accept and handle these requests. And you also know about port numbers which let servers on the internet distinguish one service like HTTP and port 80. >From another one like SSH and port 22. So what happens if on your Linux machine you run this command, printf HEAD / HTTP/1.1\r\n Host: en.wikipedia.org \r\n\r\n. Pipe to nc en.wikipedia.org port 80. Describe the output of this command in your own words. What do you think is happening? By the way, don't retype this, copy it from the instructor notes. So here we go, / HTTP/1.1\r\nHost: en.wikipidia.org port 80. So here we go. It looks like we get some information sent back from the server at Wikipedia. Specifically, this is an HTTP header. Here's the status code, and here's a bunch of header fields and cookies and so on. So, let's take a closer look at this command. Print f is a shock command for printing formatted strings. If I run it on its own, it just prints out what I've put here, which is an HTTP request. You can Printf anything like this, it's kind of like echo, but it's a little smarter. You can do things like turn into a line break. Whereas echo would just print out the \n's by themselves. And nc stands for net cat nd it's a handy tool for mentally talking to internet services. Here I'm giving a command that will connect to the Wikipedia web server but nc doesn't know anything about HTTP in particular instead of Wikipedia. I can use it to say hello to the local host SSH server on port 22. I can't speak SSH personally but I can see what it says. Or we could use it to say hello to an email server such as Gmail's. We get a little greeting here from google.com SMTP, which is the email protocol. So we'll be using and see your netcat as a sort of network Swiss army knife to connect to various servers. And later even to act as a server itself. Now let's take another look at this here in the middle. The vertical bar here is a pipe. It's the standard UNIX way to say. Take the output of this program and feed it in as the input of that program So we're taking the output of printf, which is a string that forms an HTTP request and we're using that as the input to nc. Nc picks that input and sends it over the network to the address and port that we tell it to and displays the output. So this command has the host name en.wikipedia.org in it in two different places. Now, the second one is telling Netcat what address to connect to. We want to connect to the server with the address en.wikipedia.org. And the first one is printed out into that connection. Sent by a printf to Netcat. Through the pipe. As part of an http header. It says what the host name is of the web page that we want to fetch. But suppose we wanted to access a different page. Like instead of Wikipedia Lets access google. To do that try changing the host header and the nc destination from Wikipedia to google or from en.wikipedia.org to www.google.com. And in the output look for the server header which tells you what kind of web server Google uses. So here we go. We'll change the address that Netcat is connecting to to www.google.com, and we'll also change the host of the web page that it's requesting to www.google.com. Send that request, and here's the HTTP header of the response. If we look through it, we'll see 200 OK, see the date. Here we go, Server: gws. That tells us that Google uses a web server called gws or gws. Now you might not be at all surprised to know that this stands for Google Web Server. And so that is the answer to this quiz is gws. So, why is it a big deal that we can get HTTP responses with Netcat and printf? It's a big deal, because printf doesn't know anything about the network. And Netcat doesn't know anything about forming HTTP requests. All Netcat is doing is, connecting to a port and sending a string over it. To the web server, that string happens to look like an HTTP request and so, the server responds. Now, NetCat is a lower level tool than something like Curl or web app a.p.i for that matter. What we've done here is to separate out two different layers of activity. The text of the issue to p request and the connect to a port transmit some data and get some results part. In everyday software, the http layer is implemented by programs such as web browsers and servers. Whereas the lower layer, TCP is implemented in the operating system. The NC command is a thin wrapper over TCP. Now, there are several different layer models for talking about network protocols. In this course, we'll be using the IETF model, which looks like this. The top layer is the application layer. Protocol such as htp or SSH are application protocols. Concepts we see at this layer are things like, URL's, passwords, the head command, server headers, web pages. Things that make sense to specific applications, such as web browsers or SSH clans. Application protocols are based on protocols with a transport layer, like TCP and UDP. These provide things like port numbers. Transport layer protocols are based on the internet layer, which is basically the same as the one single protocol IP. It's at this layer, that we start talking about things like IP addresses and routes. And IP in turn, runs on top of different kinds of hardware, like wi-fi or ethernet or DSL lines. Layers above this, don't need to worry about things like, how strong is my wireless signal. Each of these layers depends on the one below it and provides particular guarantees to the layers above it. You can think of them as offering and using api's, separating out specific concerns and making it possible to reuse features. Like both http and ssh have some of the same needs. They need the idea of making a connection to a server and those needs are bundled into the TCP layer. Now this layer model isn't perfect, there are a bunch of network protocols that don't exactly fit into any of these layers. But even with these added to the picture, you can notice that all of these things above depend on IP. An IP can depend on various things underneath it. IP itself, is the only thing on its layer. Some folks refer to this is the narrow waste of the internet protocol stack, because everything above and below, goes through IP Now you have probably used web browsers a lot. And if you're taking this course as part of a Udacity Nanodegree program, you've set up your own web server for a previous project. But what is a server? What does a program do in order to be a server? We can investigate this a bit with Netcat. On your Linux box, bring up the nc manual page with man nc, and skim it for a general idea. Then read the section client/server model closely. And using that, how would you get nc to listen on port 3456? Put the command you'd use here. Don't worry about the details of what listening on a port is yet, just take a look at the manual and see if you can find out how to do it. So here's the nc manual, and here's an example of a command line to listen on a port. This is a lowercase, l, for listen. And the command to listen on port 3456 would be nc -l 3456. So, what's all this listening on a port business? Well, it's like waiting for a phone call. There's a particular phone number that will reach you, not just anyone at your address, but you personally. That's how a port number distinguishes different server programs running on the same computer, like SSH on port 22, or HTTP on port 80. Let's see what port's available for me to listen on. Okay, here's port 3456, I'm going to listen on that port now. Just like NC-L3456. [NOISE] Hello. Yes this is net cat. All of these other phones, are ports that no server is listening on. If someone calls them, they're not going to get an answer, instead, they'll get the equivalent of, this number is disconnected, which is an error message called a reset packet or RST for short. So listening on a port is a very simple sort of being a server. A program that listens on a TCP port is waiting for another program to connect to that port. Once that happens, the two programs can send data back and forth. Here's a quick and easy demonstration. Open up a couple of SSH sessions to your Linux box. In one of them, run nc -l for listen, 3456. Okay, that doesn't do very much yet. Now in the other one, run nc localhost 3456. Still not very much, but what if we type some stuff? Hey, check it out. Whatever we type in here comes out over there. Switch back and forth. Whatever we put in on one side comes out over on the other side and vice versa. In this case there's no HTTP involved. This isn't a web server. It's one layer below that, it's a plain TCP server. The nc in this terminal is talking to the nc over in this other terminal, just over plain TCP, with no other layer between it and the network, and both sides can send to each other. A TCP session is like a two-way road. Although it's hard for me to show here because I only have the one keyboard, it's possible for both ends of a TCP session to be sending at the same time. Now you try it. With two terminals SSH'ed into your Linux box, on one of them, set an nc process listening on a port. You can pick whatever port number you want. You don't have to use 3456. And then in another terminal, connect to it with nc localhost 3456. Try typing into each one. And then when you're done, figure out how to disconnect them without just closing the SSH session. Now only the client can initiate a connection, but either end can drop a connection. For instance a very simple HTTP server would drop your connection if it has nothing else to send you. Modern web servers don't quite do this, they wait for you to ask for another page. But the client can also tear down a connection. With Netcat. The standard way to tear down a connection is to use the Unix end of input signal, which is control d. We can find this out from the NCMN page. Port numbers distinguish different applications and sessions on the same host. Normally a server has a well known port for its application, like 80 for HTTP or 22 for SSH. A client initiates a connection and the client end is associated with an arbitrary port on its end. The OS can then distinguish incoming traffic by looking at the addresses and port numbers on it. And let's do some experimentation. Using Netcat, see if you can find out what is the highest port that you can listen on? Is it 100, or 9999, or 10240? Or 65535, or 128000, or is there no limit at all? And then what's the lowest port you can listen on? Is it 1, or 100, or 512, or 1024, or negative infinity, or is it 0.000023? So we wanted to find out what was the highest and lowest ports so we could listen on using Netcat. Let's start with the lowest. Let's try 2048. It looks like listening on port 2048 works just fine. Let's try a much lower port 100, permission denied, okay, that's interesting. If we do a little searching in this direction, we'll find out that we can't listen on port 1023 but we can listen on port 1024, cool. What happens in the other direction? Suppose we'd heard listening on port 9999 Looks like that works. How about port 65535? That works, too. How about 128000? Says here nc, port number too large, when we went to connect to it. So regardless of what happened over here, it doesn't look like we're actually able to usefully listen on port 128000. If we kept on experimenting, we'd find that actually 65535 is the largest port number we can listen on usefully. But it's interesting that the error that we got at 65536 and the error that we got at 1023 were not the same. They didn't even show up in the same window. Plus, with this 1023 being too low, that's kind of odd because we know that the SSH server in the web server listen on ports below 1024, like 22 and 80. So how come they can but nc can't? Let's look into that. So the highest port number is 65,535. That's not an arbitrary limit by the way. But there were a few more things we should talk about before getting into that. We'll talk about it in more detail in the next lesson. On most systems the lowest 1,024 ports from 0 up to 1,023, are reserved for programs that are started by the system superuser account or root on Unix. It's like those ports are reserved parking spots. That's why when you start up a web server which runs on port 80 you have to do it as root or with the sudo command. For security a web server gets rid of its root privileges once it starts up. But it needs to start with them so it can listen on port 80. So if you use sudo to run nc as root, it can listen on port 1,000 just fine. But what happens if you tell it to listen on a port where your SSH server's already listening or if you tell two different ncs to listen on port 2,000 for that matter? Mark whichever of these you think is a reasonable outcome. Is it that the program that was previously listening for instance the SSH daemon will exit? Is it that netcat will give you an error message? Is it that both can listen at the same time? Is it that your computer crashes, or is it that the internet explodes? By the way, the result you get may be different if you run netcat on an OS other than Linux. Try this out on your Linux system to see the intended result here. So let's try it out. We'll run an nc on port 2000 and then in another window on the same machine. We'll run another nc, also listening on port 2000 and there we go. We got an an error, nc, address already in use. That's a networky way of saying, some other process is already listening on that port. So the correct answer here is, that nc gives you an error message but the internet does not explode. Normally, only one program can listen on a given port on a machine at a time. But once a program starts, it can run threads or child processes that handle incoming connections on a port, or a loop between several connections and handle all of them. That's what a web server does to be able to handle more than one connection at a time. NC-L doesn't do that. It's not really a full server as such just sort of a listener that only accepts a single connection. There's a standard Linux program that you can use to find out which programs are listening or otherwise, using network connections. The lsof program, name stands for list open files, and it has an option -i, to make it list internet sockets specifically. You'll have to run it using sudo to give it root privileges. Try that now on your Linux box. Use sudo lsof-i and in its output, look for the names of programs that are listening. They'll say, LISTEN, in all capitals and write them here. So we're looking for the names or programs that are listening on the network. We use, sudo lsof -i. And we see a couple of different command names. Here's sshd.. And here's dhclient. Wonder what that is. But it's not listening. Of these two program, sshd is the only one that's listening. Your answers might be different. But for my system, the answer here is the sshd. Even though nc -l can only handle a single connection, you can still do some pretty entertaining things with it. Earlier in the lesson, we used it to send HTTP requests to a web server and got HTTP responses back. But how about the other way around? Let's take a look at what happens if we use nc to listen for a connection from a web browser. Here I'm having nc listen on port 2345. And then I'll tell my browser to access that port on my machine. The browser isn't getting anything interesting. But look at what nc is getting. It's got the HTTP requests and all the headers that the browser sent. Okay, cool. But how about if we send some HTTP back? What do you think will happen if you run a printf statement outputting an HTTP response with HTTP/1.1 302 Moved\r\nLocation: https://www.eff.org. All of that in single quotes, piped to nc -l 2345. And then point your web browser at your IP address, port 2345. You can copy this string from below. Do you think that your browser will display the eff.org home page? Do you think that nc will print your browser's request on the terminal? Do you think that nc will exit? Or maybe some combination of these. Mark all of them that you think will happen. Okay, so let's set this up. We're going to issue a 302 redirect to https://www.eff.org. And we're going to set that up on an nc listener, listening on board 2345. And then pull our ye olde web browser, put in my IP address and port number. And sure enough, we get redirected to the EFF's home page. But just like before, the initial request from the browser does get displayed by nc. This is what nc received in response to which it sent this redirect, which sent our browser over to the EFF. Net Cat gives us a simple model of a program using the network. But it's a lot simpler than the way that a standard web browser and server use the network. Browsers and servers don't just handle a single request or a few requests one after the other. They also work on several requests at the same time. When your browser loads a web page from a server. It usually has to load a lot of different files. The HTML itself, plus images, scripts, CSS, and other data. The more that it can do this in parallel the faster it can render that page onto your screen. Or imagine that you're in charge of the server that's sending this video to your browser. You're probably not the only person watching it right now. You might be near the end of the video while someone else is just starting to watch it. So the data that the server is sending to you isn't in sync with what it's sending to that other person's browser. And there are a lot of different ways that programs can handle multiple connections at once. One of the most basic ones is what early web servers did. And what many programs such as SSHD still do. Whenever a new connection comes in, the server process forks, it asks the operating system to split it in two, like a cell dividing. A different model that many more recent servers use is to create a pool of processes or threads, each of which can handle one connection at a time. And this is faster than starting new processes. But it does have the downside that there's a limit to how many requests may be handled at once before things start to slow down. And finally a third model is to have a single process that quickly switches between handling requests as they become available. There are a few different facilities and operating systems for doing this efficiently, such as the epole function in Linux. But before your server can handle a request, the client has to know how to get in touch with your server. Up ahead, we'll take a look at DMS, the directory system for internet hosts. Now you've seen IP addresses before like 50.116.54.191 or 8.8.8.8. An IP address is used to designate a particular destination on the Internet, typically a particular machine. And every message that travels over the Internet, a web request, an email, a ping, or what have you. Is split into packets, and every one of these packets has the IP address of the machine it came from and where it's going to. Now a point about terminology, in this lesson in the rest of the course, you'll hear me talk about hosts a lot. A host is just a machine on the Internet, particularly one that might host services. You'll also hear me talk about the endpoints of a connection, those are just the two machines or programs that are communicating over that connection. Okay, let's get started. First off, let's take another look at something you've definitely seen before, Ping. In the last lesson you saw the ping command. Here's something else that it does. If you take the name of a host, say a website like yahoo.com, and ping it, you'll see an IP address along with the ping results. The ping command has to look up the IP address of the host first before it can actually send it a ping message. Now ping keeps running forever until you stop it with Ctrl+C. Alternately, as we saw before, you can tell it how many pings to do with a -c option. For instance, -c 7 will have it send just 7 pings and then exit. So now for an experiment. Run ping google.com to see how long it takes to get to a well-known host at Google. Type CTRL+C to exit ping. What IP address is your ping using for Google? And do you expect that everyone who's doing this quiz is getting the same answer? Yes or no. So you might have gotten any number of answers to this question. In fact, if you run it twice on two different computers or two different times, you might get different addresses. Here, it is trying it twice and happened to get the same address twice in a row. But about the address you see is not the same one as this. It turns out that there isn't actually a single host of the single address behind google.com. They actually have more than one computer there. Surprise, surprise. Mild understatement. When your browser goes to look up google.com, it can get a bunch of different addresses. Which helps Google balance load amongst all their different data centers. But how do we get from a host name to an IP address, anyway? Let's look at that next. So when your users access your web apps they don't type in your IP address. They put in a name like www.example.net, a web address with a hostname in it. The way that your hostname gets translated into an IP address is through the Domain Name System, or DNS. DNS is a worldwide distributed directory of network information. It stores a wide variety of records but the best known kind of DNS record is the A record. A for address, which maps a name like www.example.net to an IPv4 address. Client programs such as web browsers look up these records in order to find the address of a web site or another service. As the creator of a website you need to set up DNS records for it so that users can access it by name. Usually that will involve registering the domain with a registrar and pointing the DNS records at the web servers IP addresses so that users will be able to reach them. A little later in this lesson you'll have a chance to do exactly that. A DNS turns out to be really important for websites. If your DNS goes down, your site can't be reached by most users. A number of big sites including Google and Microsoft have had embarrassing outages caused by their DNS records expiring. DNS domains are also used as part of the security mechanisms for HTTP, including SSL encryption and cookie privacy. The DNS client code which is called the resolver, is built into every operating system. Programs such as NC or ping, or web browsers can just use it. To test out DNS, we'll use a couple of handy shell utilities called Host and Dig. The host command is a basic utility for looking up records in DNS. It will query your OS name service. Which usually ends up sending a request to whatever DNS server your computer's configured to use. If you're running it on an easy to instance like I am here. It will send a query to Amazon DNS server which can in turn retrieve records from other servers on the Internet. There are lots of kinds of DNS records but the default one for looking up the addresses of IPv4 hosts is an a type of record for address. You can use the host command and to look up a DNS name such as google.com, and get back an IP address. Take a quick look through the beginning of the manual page for host or man host and then try it out yourself. Use the host command to look up the IP address for any website of your choice and here, you put what site you chose and in here what results you got from the host command. So let's say we chose the site www.udacity.com. And we do host www.udacity.com. We get back something a little bit interesting and different from what we got for Google. The first part says that this name, www.udacity.com, is an alias for this big long name hosted at Amazon AWS. And then the second part says that that name has reps over the end of the line, but it's three different IP addresses, 54.200.240.37, and 52.25., to 84.3, and 52.88 to 72.242. Now if we did host -t a, we could actually do the same thing. There's another tool that provides the same kind of information as host does, but in a more technical and complete form. So the host tool shows more human readable information, spelled out in English sentences like, such and so name is an alias for this other name. Or this name has address 52.25.84.3. The dig tool shows the same information more or less. But in a form that's more readable for scripts and is closer to the way that it's stored in the DNS server's configuration file. Let's take a look. So here I did dig www.udacity.com, and here we see a question section that says, what is the request that we sent to the DNS system? And an answer section that says what we got back. See, here's the name that host says was an alias. We can see as we saw before alias is done with CNAME. And here's the name that host said it was an alias too. And likewise, these names have A records with the IP addresses. But dig also gives us other information. It tells us what server answered our query. It tells us some metadata like, when the query was answered. And it also includes some other fields that say how the query worked. We won't go into those in this course. But it's worth noting that you can get a lot of information out of DNS this way. But there are many different types of DNS records. Literally, there are dozens of them. A records, the ones we use to look up the IPv4 address of another host or just one of them. Take out your favorite search engine and see if you can find out what each of these other record types is for. First the CNAME type. Does CNAME stand for common name, or category name, or canonical name. Second, the quad-A record type. Which is spelled A-A-A-A. Does a quad-A record stand for a cluster address, an IPv6 address, or an encryption key? And lastly the NS record type. Does that stand for a DNA name server? Does that stand for an Ethernet switch? Or does it stand for a network socket? So, if you look this up using your favorite search engine or online encyclopedia or other reference work, these are the answers you should find. A CNAME record is what's used to make an alias from one name to another, and it actually stands for canonical name. It means that the canonical or official name for this name is actually something else it's an alias. Now an AAAA record is the IPv6 equivalent of an a record. It's an address, it's just an IPv6 address. The name is kind of a joke, since v6 addresses are four times longer than v4 addresses. That's how I always think of this. And lastly, the NS record type is a DNS name server. An NS record for a particular domain says what DNS servers have the records for that domain. DNS is a distributed directory. Around the world there are several root servers which direct requests to top level domain servers, like for dot com, which in turn direct requests to the servers for particular domains. This means that no one DNS server needs to know all the records for all the names and domains in the world. The records for a particular domain, like an A record for www.greenspaceghost.com, will be found in the authoritative name servers for that domain. Like the nameserver for greenspaceghost.com, which are listed in NS records for the higher level zone. So the NS record for greenspaceghost.com will reside in the nameservers for com or dot com, either way. com and org and edu and net and a few others are global top-level domains, or gTLD's. And their NS records are stored in the root servers. To make it faster, and more complicated, the DNS server that the client to resolve talks to isn't some sort of global master server. Resolvers normally talk to a nearby caching DNS server. For a home user, that might be the local home router, or it might be run by their ISP, or it could be a well known DNS service like Google Public DNS. When that catching server receives a query from a client, first it consults its local cache. If the cache doesn't know what the record is, the caching server recursively resolves the query, forwarding to the appropriate nameservers. Possibly first at the root and then at the top level domain, and then at the lower level domain until eventually it gets back an answer. Then it stores that result in its cache so it doesn't have to run the same query over and over again every time you look up audacity.com or google.com or whatever. And finally, it's able to return that result to the client. But caching can cause problems. If you want to move your site from one IP address to another, like if you're moving your website from Google to Amazon, and some DNS cache has the old address, then clients who use that cache will see the old address instead of the new one. To cut down on this kind of thing DNS records have a time to live, or TTL, which tells caches how long to cache them for. For instance, these records that I just used dig to get for udacity.com have a time to live of 60 seconds. If I look them up from the cache later, the time to live is reduced. Now it's down to 22 seconds, and 14. And after the TTL expires, caching servers have to go back to the authoritative server again, look the record up, to make sure that their information is fresh. Domain names are also essential to several HTTP features, including cookie security and SSL.. A single web server can handle requests from multiple sites which it tells apart by their domain names. Apache calls this a virtual host configuration. NGiNX calls it having multiple server blocks. No matter what you call it, it's why your HTTP requests have a host header in them. You have to tell that web server what host name, really what domain name, you're expecting to talk to. As you saw earlier in the course, the host header is a required part of HTTP requests. When a web app sets a cookie, it sets that cookie for a particular domain name, and further requests to that demand will get that cookie sent back. And SSL encryption certificates are issued for particular domains. SSL serves several different security purposes. By encrypting the traffic between browser and server, it prevents networks in the middle from reading private data. But it also lets the user's browser verify that the site they're getting data from is actually the site that they expect, that when you go to google.com, you're actually talking to Google, and not to some bad guy who's pretending to be Google. DNS domains are structured as a tree. Domains such as google.com and udacity.com do share something, the com top-level domain. There's actually a collection of servers who are responsible for storing all of the records for domains in com, and in org and edu and each other top-level domain, including country code demands like uk and il and ua [INAUDIBLE]. Now, www.example.com Is a subdomain of example.com. And test.www.example.com is a subdomain of that. Now, there's no rule that you can't have hosts at any level of these subdomains. You can have a host with an IP address and an A record on one domain and then have a subdomain of that with a different host on it. Now, early in the history of the web it was common for an institution whose domain was, let's say, stanford.edu to have its web server at www.stanford.edu. And that would have typically been a single machine that was the web server representing the institution. But these days, since so many domains are used almost entirely for web traffic, many organizations skip the www and just point their domain directly to a web server. Like github.com for instance. The name www.github.com is a C-Name, an alias, for the A record, github .com. Whether to use bare domains like GitHub does or www domains like Udacity does is pretty much a style and branding preference. There's little technical difference. For computers within an organization, it's pretty common for them to also have a configured search domain. This tells the resolver on that computer to look up hosts inside that domain first. Like if you're on the network of the university, example.edu, you might have that in your search domain. Then when you look up the DNS name www, the resolver will look for www.example.edu first. If you've taken Udacity's course on configuring Linux web servers, you set up an Apache web server on your development machine. Otherwise, you might have experimented with setting up a web app on your own computer or another computer. Then, you probably found yourself typing an IP address into your browser, so you could access your app. But real web sites have to domain names. You don't type any Udacity's IP address when you want to watch this course. By setting up a domain, you make it easier to show off the web apps that you create. Plus, domain names cost money, so this is a totally optional exercise. If you register a new dot com domain name with Google, as of today, it'll cost you US$12 per year. Other domains and other registrars have different pricing. If you don't feel like paying that, just skip this exercise. That's totally okay. Unfortunately, I can't make domain registration free. But if you're up for it, you can get some live experience in another aspect of running a real service on the network. If you'd like to do this, just go to domains.google.com, and follow the instructions there to set up a DNS domain. Or you can use any other DNS registrar. Google works just fine though, so that's what I'll use. They're not paying me to tell you that, by the way. So, here's me setting up a domain with Google. First, I have to pick a domain name. I want one that's actually new and available, not one that somebody wants to sell me for a few thousand bucks. Here we go. My new website is going to be greenspaceghost.com. Okay, I've got to fill out this form with my name and address. But I'm going to set this option of make my info private, so my name and address and phone number and all aren't publicly listed. I don't want any more email from Google. Now, it's asking me if I really want to buy greenspaceghost.com, and I'll say yes. Now, I'm in my domain and I select configure DNS. And then, go down to custom resource records. I'm going to put in a record for www, and put my IPv4 address in there, which is going to be this, and add that record. It says successfully saved. And now, if I go to www.greenspaceghost.com, I get my website. So, here's the exercise and again, this is totally optional. Go to domains.google.com or any other DNS registrar, and register a new domain, then add an A record pointing at the IPv4 address for your development server. If you do, put your A record's name here, and we'll check it out. If you don't want to, just mark this box instead. Again, this might cost you about US$12. If it costs much more than that, try a different domain. So my A record is at www.greenspaceghost.com and since I created that record, I'm now able to access my website at this domain. The IP addresses we've seen so far in this course are specifically IP version 4 four addresses. There are two major versions of the Internet protocol in use today, v4 and v6. v4 is the older one that the majority of Internet traffic is using today. We'll talk about v6 more in the next lesson. For now. Just be aware that there are both of these kinds of IP addresses out there. And that they look pretty different when we write them. And there you're going to be seeing these more and more. Right now the ones we're talking about are these. The IPv4 addresses are usually written as dotted quads. That's four numbers separated by dots. Each of these four numbers is one byte or octet, or 8-bits, which means that mathematically it could be a value from 0 to 255. Wait a minute, why 255? Where did 255 come from? If you already know the answer to that, feel free to skip the remainder of this lesson and pick up again with lesson three. But if you're not quite sure why 255 is an interesting number, keep watching. You probably already know that computers represent numbers in binary, or base two internally. The value of computer memory is literally represented as a sequence of 1 and 0 bits. But when you're writing code in a language like Python or JavaScript, you don't normally see the binary. Numeric values are normally displayed in decimal, and other values such as strings or Booleans hide the actual binary representation away from the programmer and the user. The letter a can be encoded as 01100001. But you don't need to know that to print the word apple. The binary representation is available to you when you need it. But IP addresses are one of those places that the binary becomes a little bit more obvious. All of the information that's transmitted over a network link travels in the form of a long stream of bits. It's divided up into messages called packets, and each packet carries with it the IP addresses of the sender and the recipient, and these are each a binary number. An IP address is a 32-bit value or 4 bytes. Networking people will often said that it's four octets instead of bytes because some old computers use different sizes of bytes. An octet is specifically eight bits. This binary or this hexadecimal representation make up the same IP address that in decimal we write as 241.10.27.53. Writing the bytes or octets separated with dots makes them a lot easier to read, than if we ran them together in plain decimal. Besides IP addresses, we'll see several other binary values that occur in packets which have different lengths and bits. In networking, the width of a field tells how many bits are in that field. We'll say, for instance, that an IPv4 address has a bit width of 32 or it's 32-bits wide. Meaning 32 bits are used to represent that value. When we use numbers as network addresses, we don't care about adding or subtracting them. You never multiply one address by another. Just like street addresses or postal codes, they may be numbers but they don't really represent quantities or amounts. Rather, IP addresses, like these other sorts of addresses, represent difference. Each address has to be different from every other address on the same network. With a given number of bits you can only make a certain number of distinct values. Like with one bit, you can only make two distinct values, 0 and 1. With two bits you can make four values, and with three bits, you can make eight. So if you had a network that only had three bit long addresses, you could only have as many as eight machines on the network. So okay. How about four bits? How many distinct four bit values are there? Put your answer here. So with 3 bits you could have 8 distinct values, but with 4 you can have 16, which is the answer to this quiz. Each additional bit could be a 1 or a 0, so it doubles the number of possible values there are. Remember how in the last lesson you discovered that the highest port number you could use with NC was 65535? Well this tells us something about how port numbers work. The reason you can't connect to a port number higher than that is that the space for port numbers in a packet header is only a certain number of bits wide. Now, given what you've seen about binary representations in this lesson, I'll bet you can figure out how many bits that is. So based on the fact that port numbers only go up to 65,535, figure out how many bits are used to represent a port number. So 62,535 is the biggest integer that can be represented with two octets or 16 bits. If you have a one in each one of the 16 positions here, it's going to sum up to 65,535. So that strongly suggests that port numbers are represented as 16-bit values. Which indeed, they are. So now you know a lot more about how IP addresses work and how they're used along with DNS to get users to your website. In the next lesson, we'll see how addresses are grouped together into networks and how the world is coping with the ongoing shortage of IPv4 addresses. So far in this course, you've learned quite a lot about how the network functions. We've gone from HTTP down through TCP ports, domain names, and the binary values used to write addresses and port numbers. But the rabbit hole goes deeper. In this lesson, we'll look at IP network blocks, routers, and network address translation. Some things that many Internet users use every day usually without even noticing, but soon you'll notice them all the time. An IPv4 address is actually a 32-bit or 4 octet value, which we usually write as a dotted quad. But writing an IP address as four decimal numbers is just a convention to make it easier to read. When it's used between computers it's just a 32 bit long string of bits. However, not all of the possible 32 bit values are used for real addresses. Some of them are reserved for special protocols. Some of them are reserved for internal private networks. Some of them are for testing or for documentation. In fact, just over one-eighth of all possible IPv4 addresses, are set aside for something other than addressing public hosts. But as you'll see, even if we did use all 32 bit addresses to represent public hosts that still wouldn't really be enough. Even though not every 32-bit number represents a real public IPv4 address that can be assigned to a host, most of them do. So knowing that, around how many IPv4 addresses do you think there are? Here are four options. Pick the one you think is closest. Are there around a thousand public IPv4 addresses? Are there a few hundred million, nearer to the population of the United States? Are there more than a billion but less than the number of people on Earth? Or are there hundreds of billions, more than the number of stars in the galaxy? Okay, so we know that IPv4 addresses are represented as 32 bit integers. So with 32 bits, the biggest number that can be represented is 2 to the 32nd minus 1, which is slightly smaller than 4.3 billion. And there are 7 billion people on the planet. So the correct answer is that there are more than a billion IPv4 addresses, but fewer than the number of people on the planet. That means that everybody wants one. There aren't going to be enough to go around. Oops. So, you might have noticed that computers that are on the same network, like an individual home or business or school, usually have IP addresses that are similar to each other. To be more specific about it, all of the addresses on a specific network block share a particular prefix. They all start the same and only differ after some particular bit position. And computers that are on the same network block, can communicate with each other without going through a router. But not all networks are the same size. So when we talk about a particular network, we have to talk not only about its network prefix but the length of that prefix. A network with a longer prefix has less of the 32-bit address left over to distinguish particular hosts, and a network with a shorter prefix has more addresses for hosts, so it's a larger network. The network prefix length is something that has to be chosen when the network is set up, and it's usually configured by whatever process assigns addresses to the computers. For instance, if you have a network with a 24-bit prefix, that means there's eight bits left over for the host part of addresses, we would conventionally write this as /24. For instance 198.51.100.0/24 network block. But if the network prefix is shorter, say 22-bits, then there will be 10-bits left over for host addressing, this would be a /22 network. And you can't tell how long the prefix is just by looking at the addresses. For these addresses, either a 22 or 24 network would be a possibility. So how many hosts can fit on one of these networks? Well 10-bits of host address means two to the tenth power addresses, which would be a 1024, except that the top and the bottom addresses of a network block are reserved and the first address is usually the router. So 1021 addresses are available for hosts. Similarly in a /24 network, there would be 256 addresses but minus those three, they're usually about 253 addresses that remain for hosts. And why does this matter? Sometimes misconfiguration can cause some pretty weird problems on a server network especially. Things like one machine thinks that it can talk to another machine directly, but the other thinks that it has to talk back through a router. And that can cause very strange communications problems. Getting a good grasp of how this stuff works can save you a lot of trouble if you're ever setting up a server network. There's another way to write a network size, which is often used in network configuration. This is a subnet mask, which is a binary number made of ones on the left and zeroes on the right, to indicate the size of the network. You'll often see subnet masks in network configurations on hosts. Now like IPv4 addresses, subnet masks are 32-bit values that are usually written as decimal dotted quads. The mask for a /24 network in binary, is 24 ones followed by eight zeroes. Now since an octet full of ones makes the number 255, and an octet full of zeroes makes the number 0, that means that the subnet mask for a /24 netblock in dotted quad notation is 255.255.255.0. Now you will occasionally see some systems that spell out their subnet masks in hexadecimal instead of in decimal. In that case the same subnet mask would appear as ff, ff ff, 00. Now knowing what you just saw, what's the decimal subnet mask for a /16 network? So 24 and 16 are both divisible by 8. So the dotted decimal version of a /16 subnet mask will also be made out of just 255s and 0s. In fact, it'll be 255.255.0.0. And there was two examples, you saw subnet masks for /24 and a /16 network. Both of those being multiples of eight bits, which meant that the subnet mask decimal form, had only 255 octets and 0 octets in it. But prefixes do not have to be whole octets. Networks can be allocated in lots of different sizes. An organizations can split their assigned net block into chunks or subnets to make management easier and control traffic. For instance, a network with 22 bits of network part and 10 bits of host part still adding up to 32 Is a /22 network. Slash 22 doesn't evenly divided by eight. Or here's another example. 171.64.0.0/14 is a net block assigned to Stanford University. The /14 is less than two octets of network part. So while all the addresses on this network will have the same first eight bits, so they'll all start with 171, only six bits of the second octet will be fixed. And two bits of that second octet will be free. Meaning there are four different values that will occur in that octet. Specifically, all addresses starting with 171.64 or 171.65 or .66 or .67 will all be in this /14 netblock. So here's a quiz. What's the decimal subnet mask for a /14 network like Stanford's? And about how many addresses are on that network? Are there around 2,500, or around 25,000, or are there around 250,000, or is it around 25 million? So, a /14 network is going to have a subnet mask that starts with 14 bits of ones for the network part. Followed by 18 bits of zeroes for the host part, for a total of 32 bits as usual. If we divide this up into octets, we'll see that the first 8 bits are all ones so that octet has the value of 255. And last two octets are all zeros. So we'll have the value 0. It's the second one that's different. And the second octet is going to be 255 minus 3 in the value of 11 in binary, making it 255.252.0.0. And to figure out how many addresses, we'll just note that an 18 bit host part Is two the eighteenth power addresses, which is just over two hundred fifty thousand. So that's the right answer here. Okay, this is getting to be a lot of stuff about IP addresses, why do we care so much about them anyway? So, all traffic on the Internet is split up into messages called packets. And each packet has the addresses of its source or sender and it's destination or intended recipient on it. When you use Ping, you're sending a steady stream of packets to a particular destination and hopefully, you're getting a steady stream back. So each server or other host that you want to talk to, it needs to have a distinct IP address. Now, that would be fine, but there aren't enough IP addresses for all the computers today. Remember, there's about 4 billion IPv4 addresses available for hosts, and there's 7 billion people on the planet. To make it worse, big institutions that have been on the internet since forever are using way more than their fair share of addresses. And the addresses to people ratio in the US is actually a lot higher than the rest of the world, especially Latin America, Asia, and Africa. At the end of this lesson I'll tell you more about how we're fixing this problem. But before we get there I have to confess that I've been lying to you about something. So far in this course I've been treating addresses as if they belong to hosts. Well, they kind of do, but it's more accurate to say that addresses don't belong to hosts so much as they belong to interfaces. A host, like this laptop, can have multiple network interfaces and each interface can have zero or more addresses. For example, this laptop might have a wired Ethernet interface and a WiFi interface, and every machine also has a loop back interface which can be used for talking to itself. And there are other kinds of interfaces as well, for example you might have a tunnel to another part of the network. Or if you bring up a VM on a system, like Virtual box for instance, there can be a virtual machine interface connecting the host operating system and the guest operating system. And on Linux you can find out what interfaces your machine has with the command ip addr show. In this case showing that this machine has a loopback interface and eth0 interface, lo and eth0, and here are their IPv4 addresses. There are other commands that can do this as well. For instance on a Mac or other Unix system, might use the ifconfig command. And on Mac OS 10 you'll find that a system has an awful lot of interfaces, many of which aren't used for Internet traffic but for other things like finding printers. You can compare the addresses you see here against your network configuration in the GUI to find out what interface you're actually using. A little bit more about that LOOPBACK interface. The LOOPBACK is a special interface that almost always has the IP address 127.0.0.1 and the host name localhost and allows programs to use the network stack to talk to other programs on the same host. Whenever you've made connections to local host or 127.0.0.1 before, those are going over the loopback interface. So, think about a typical home router. It has one interface that goes to your ISP, and then one or more interfaces that are local, maybe an Ethernet or probably a wi-fi access point. Now, the local network, or LAN, is where your computers and devices are. Whereas the outward facing wide area network, or WAN, is the interface that connects towards the rest of the internet. How many interfaces does your Linux box have? What are their names? You can use ip add or show or ifconfig to see them. So as we saw before, you probably have at least two interfaces. Lo, which is the loopback interface with the IPV4 address 127.0.0.1 and eth0, an ethernet interface. Depending on the system you're using, you may have more than those, or they may have different names. But on the system I'm using, the answer is a lo and eth0. A home router is a teeny tiny example of a router. An ISP or a datacenter might have a router that looks like a big chunky box with a lot of cables going into it. In general, a router is a device that connects two different IP networks. It acts as a gateway. Hosts on one network that want to send traffic to the other one, forward that traffic through the router. While most hosts might have only one interface with an interesting IPv4 address on it, a router will have two or more. The host on a local network knows about a default gateway, which is a router that's connected toward the rest of the Internet. Computers that are attached to the same switch or WiFi access point or other network hardware are normally local to each other. They can directly send packets to one another without going through a different network. And as we saw before they have IP addresses on the same net block. But here is Alice over here at 192.0.2.104. And here's Chandra over here at 198.51.100.17. Those aren't on the same local network. So if this host wants to send traffic over here, it has to pass through this router. That default gateway may also have a default gateway itself. But eventually as you go toward the rest of the Internet, you'll eventually reach the defaultless part. Where routers on major transit ISPs know about the global routing table, the directory of all public IP networks. Routers up there don't have default gateways. You can find your default gateway with the command. Ip route. Show default. On Linux or net stat dash and are a multiple different unix like systems. In the latter case you may have to look around a bit in the output depending on how many interfaces your system has So give it a try. What's your gateway's IPv4 address? Put it here. And then try pinging it. How fast is the ping time to that address? Let's give it a try ip route show default. And here we see the ipv address of the default gateway for this machine. If we use netstat-nr. See this address also there. If we try pinging it. Looks like the ping time is about 0.3 0.4 millisecond since pretty fast. Earlier in the course you found out that there aren't enough addresses to go around. There are actually fewer IPv4 addresses than there are people in the world, and some of us use way more than one address. I mean, every sensible person carries five computers with them at all times, right? The major workaround has been for ISPs to assign only one address to each household, office, or other customer. And if you had a one computer household, it would obvious how this would work. One host, one IP address. But as people have lots of different computers and devices in their house today, they all have to hide behind this one IP address and from the outside world have to look just like a single machine with a single address. Well, how does this work? Let's take the example of a home network. Maybe they've got a desktop computer, and a laptop, and a smart TV, and some phones, and all of these talk to the internet through a router, which acts as their default gateway. The router connects to their ISP and gets a single real public IP address, and then it assigns private addresses to all of these devices. Private IP addresses come off of one of three reserved IP address netblocks. The most common private IP addresses found on home routers are in the network 192.168.0.0/24. With the default gateway of 192.168.0.1, this is only one of very many private IP address possibilities. If you ever need to look these up, they're specified in an internet standard called RFC 1918. Private IP addresses are used with a system called NAT or network address translation. The way that it works is that whenever traffic goes between the private network behind the router and the public internet, the router has to rewrite or translate to the network addresses on it. The router maintains a map of which inside addresses and ports are connected to what public internet addresses and ports. Now most likely your own home or office network is using NAT, but NAT is really a workaround not a solution to address shortage. It creates some pretty serious problems. It makes it much harder, sometimes impossible, for end users to run servers that other people can access. That makes it hard to write and debug network applications that are going to run on end user machines. The router has to keep track of all the connections going through it, and because your computer doesn't know it's real public address, applications on it can't easily say things like forward all my internet phone calls to this address without hacky extra protocol arrangements. And more moving parts makes them more error prone. No private addresses aren't private in the sense of being secret or personal. They're private, because they're only any good on the local network. They can't be used to directly on the public internet, because they're not actually unique. Thousands or maybe millions of people in the world are using IP addresses in the 192.168 range, but each one of these is behind a different NAT router. Once again, there are three different blocks of IP addresses which are reserved for this private use. By design, these addresses should never be used on the public internet. They're used inside homes, offices, data centers, on mobile networks and so on. If you're using a private address on your computer, there's still a public address being used on the other side of your router or your mobile provider or the like. Web servers and other internet services don't see your private address. They see the public address, whatever it is. There are number of ways you can find out your public address and services that look at what address they see on your request and respond with what you say. Search engines including, Google, Bing and many others will all tell you your public IP address if you search for the term my ip address. Now, let's try it out. First, look in your network configuration and find your computer's assigned IPv4 address. Is that IP address a private one? Yes or no. If it is, what's your public address? So if your computer's IP address is in one of those three net blocks, it's a private address. Here's the one my computer is using, and that is a private address. And it looks like my public address as confirmed by multiple search engines is 198.91.103.86. So NAT is not a super great solution to the shortage of addresses in IPv4. It's a workaround. But the real solution has already been built. And the world is kind of in the middle of deploying it. That solution is IPv6. IPv6 is the successor to IPv4. We're going from 4 directly to 6 because protocol version 5 was an experiment that didn't work out. IPv6 fixes the address shortage problem by having much longer addresses, 128 bits or 16 octets long. That's 4 times as long as an IPv4 address. 2 to the 128th power is really a colossally huge number of addresses. Billions and billions of times bigger than the v4 address space. In fact, the smallest block of addresses that can be assigned to an end user. Like a home in v6, is a /64 network which is much larger than the whole v4 address space. But that means that IPv6 addresses are kind of long. Like for instance here's one of Google's addresses. Now fortunately, the conventional way of writing these 6 addresses, lets a skip writing these zeros here. Okay, that's better, a little. Anyway, you might notice that these don't look much like the four addresses. They're written in hex digits instead of in decimal. In blocks of 2 bytes separated by colons instead of dots. But remember this is just the human readable format. The network actually sends these addresses as strings of 128 bits. Just like v4, we designate the size of a network block with a decimal number of bits in the network prefix. Google has all of 2607.f8b0/32. And many other V6 locks as well. Remember on IPv4, a /32 means a single address. Whereas on IPv6, it's a large network with 96 bits of subnet and host address in it. So the world doesn't need nat with V6. There's enough addresses for every device to get a unique public address. And IPv6 adoption started out very slow but it's been growing strong for several years. Between mid 2012 and the end of 2015, Google's measurement of V6 traffic they received increased from about half a percent of all traffic to about 10% of all traffic. And it's higher on weekends because more home and mobile users have V6 than business and office users. So that's IPv6. Look for it in your near future or maybe even in your present. For most of the rest of this course, we'll be in IPv4, which is a little bit more widely used today. Also, our hosting provider doesn't natively support the v6 just yet. But almost everything we talk about, except the addresses, will apply to v6 as well. However, if you're building apps today that care about IP addresses, even for things like logging user requests, you've got to expect them to be deployed in a world with v6 present. You can't expect that addresses are 32 bits long, or that their printed representation looks like a classic v4 dotted quad. To see if you have IPv6, go to test-ipv6.com, which is a site for testing whether your computer has IPv6 access. If you have a smartphone, try it there as well, and then mark whichever one of these options is true. Either that you've tested your devices and at least one does have IPv6. Or you've tested them and none have IPv6 yet. So here's my results at test-ipv6.com. We don't have IPv6 yet on the Audacity Office Network, but I do have it on my phone. And yes the addresses are really that long. Congratulations, you now know more about IP networks than most software engineers do. In the next lesson, we'll revisit an idea that we talked about briefly before. The layers of protocols involved in connecting a program on your computer to one somewhere else. Wow that last lesson got pretty deep. Now the kind of connection that you've seen in Netcat is a TCP Session which lets two programs send strings of bytes back and forth over the network. TCP is kind of the middle layer of a stack of networking protocols or protocol stack which supports all sorts of different internet applications. HTTP and other applications are built on top of TCP. And TCP is built on top of IP, the Internet Protocol. In this lesson, we'll take a closer look at how these layers work together. As we do, keep an eye out for two things, how each layer depends on behavior or guarantees made by the layer below. And also how it hides the details of the lower layer, giving programmers a simpler interface. As you saw earlier in the course, protocol stacks are made of layers. For each layer depends on abstractions provided by the layer below. Let's take another look up and down that stack to see where we are. As a developer, you're usually working at one particular layer of abstraction at a time. But it's important to know about the lower layers, because the way they work affects the way they can fail, and what strange things can happen to your application. Web applications rely on HTTP to send requests about resources and get responses. You use libraries like Flask or requests to build HTTP applications. Some ideas that are visible at the HTTP layer include URLs for resources and methods, cookies, HTTP verbs. Any misbehavior of lower layers is mostly visible at the HTTP layer as errors and high latency. Requests that fail, or the take unreasonably long to complete. HTTP is implemented in browsers and in web servers, as well as in proxies and firewalls, and some other tools like that. That code uses TCP. But the code that says in order to send an HTTP request, connect to the server on port 80 and transmit the following bytes is part of the web browser. And the corresponding code for understanding HTTP requests and sending responses is part of the web server. Web apps don't need to reinvent that. They just make use of the features the browser and server already implement. But the browser up here doesn't tell your Wi-Fi or ethernet adapter down here exactly what to transmit to your router. The browser makes use of the TCP networking services that your operating system provides. Connecting to a server on a port and having a reliable stream of bytes between that client and server is a feature provided by your OS's TCP implementation. Whether you're on Mac or Windows or Linux or something else. Modern OSs provide TCP built in. User program such as browsers just have to use them. Within the OSs networking code TCP in turn relies on the lower level protocol IP to deliver packets between hosts. And to pass them through the intermediate hops, the routers. An IP in turn, relies on hardware like Wi-Fi or ethernet and device drivers to physically shift data between devices on the same physical network. Now, not all network applications use TCP. Ping uses ICMP. DNS primarily uses UDP as to a number of other things like the network time protocol that keeps your time and date in sync. But all of these underlying protocols are provided by the operating system. We'll see a lot more about these in this lesson. One more thing, be careful what layer you're talking about. There are a lot of terms in common between them. For example, a Wi-Fi connection or associating with a particular Wi-Fi access point has nothing particularly to do with a TCP connection, also known as a session. And a TCP session has nothing particularly to do with a web user session, identified by, for instance, session cookies on a logged in user. So in lesson one, you use the pin tool to test connectivity between your machine and another network host. But what's ping actually doing? There's a tool you can use to display quite a bit of detail about network traffic between hosts and networks. It's called TCP dump, and that's slightly misnamed. You can actually look at any network traffic, not just TCP. You already installed it on your machine back in lesson one. So let's take a look at the manual for it. Holy wow, that's a lot of options. Okay, we're going to ignore most of these. The important part is that we need to tell TCP Dump what traffic we want. It has its own little language for this, called the PKep filter syntax. You can look at the pcap-filter man page for more about it. But for now, I'll just give you a really straightforward command to catch traffic that's going between your host and the host at 8.8.8.8. It's going to be sudo tcpdump -n host 8.8.8.8. Now let's run tcpdump over here and run ping again over here. Hey, look. Packets. Now for each ping over here. Which there are three. We see two packet records over here. Two messages appear from tcpdump, one after the other. Each one of these records is a description of one of the packets that ping is sending over to that machine or one that's coming back. See here's 8.8.8.8 and here's the IP address of my machine, and here it says that, this record is an ICMP echo request, that's a ping request, and then coming back as an echo reply. Like a request is the message the ping sense, an echo reply is the one coming back, other things agree too. For instance the ping program tells us that ii got 64 bytes, and sure enough there's length 64 to exit TCPDUMP we'll type control c. You can use tcpdump to monitor traffic for any network application. Like for instance if you wanted to see all the DNS requests your machine sends, you'd need to know what port DNS uses, which is port 53 by the way, and then you'd compose a line like this, Sudo tcpdump -n port 53. Then if you do anything that causes a DNS lookup, like say pinging a machine by host name, you'd see the DNS traffic like so. If you look closely, here's my IP address and here's the IP address of the DNS server that I'm using, and since I pinged Yahoo.com, here's an A query, or A request, question mark for query, for Yahoo.com. And then here comes back the response on the next line, with an A response. The first ip address sent at being 206.190.36.45. Which is the ip address that ping is using to ping Yahoo took a moment to try this yourself. Don't worry about all the other bits the TCP non temperance up, but do get a sense of where the traffic you're looking out is coming from and going to. Now tcpdump can look at a lot more than just pings in DNS requests. For instance, we can use it to look at the packets that your machine uses to talk to a web server. And we can use that to get a little better sense of what's going on in TCP. So, for instance, there's a web server at example.net that serves an example web page. And we can use nc in our secret knowledge of HTTP headers to send it a request while we have a tcpdump watching port 80. Hey, look. We have some things. What are these things? Well, I'm going to stop tcpdump with Ctrl+C and we can look at them. If we look here, looks a lot similar to what we just saw with DNS. We see a timestamp, we see IP address of the web server and of our machine. And then what's all this? Flags, ack, win, options, nop, nob. We're going to need to look closer at this. In total, there are ten records of output here from tcpdump, and each one of them, just as with ping, represents a single packet. In case you weren't able to get this to work, I've put a copy of the tcpdump output that I got into a file that you can download. The timestamps, addresses, and some of these fiddly details will be different. But the structure should be the same. I'm going to copy this tcpdump data into a file right now. Now something to notice right away is that no place here do we see the contents of the network traffic, that HTTP HEAD request isn't anywhere here. What we're seeing is data from the headers of the packets. The metadata. Next up, we'll be looking in detail at what's going on here. What actually happens at the TCP level when a client requests a web resource from a server. But first, give it a try yourself. Run tcpdump in one window and netcat in the other, and copy and save the results to a file so we can analyze them. Or, if that doesn't work, download the saved version from when I ran it. So once you have some tcpdump data, either your own or mine, let's move on to analyzing it. So first thing you probably notice about tcpdump data is that there's a lot of details here. What is all this options sack stuff? We're not going to look at that in this course. I'm going to wave my magic wand to make it go away. I know it's kind of silly to say, but don't panic about the fact that this output probably looks like a big pile of weird. Some parts of it may jump out at you as already saying something, and if not right now, maybe by the end of this video. So there are some things in here you might already recognize. If you're using your own data, you'll see your machine's IP address here. Here's mine. Notice the just as we saw with ping, sometimes it shows up to the left of this little angle bracket and sometimes it shows up to the right. That's because some of these packets are going from our machine to example.net and some of them are coming back. Likewise, here's the IP address for example.net. If you want to check that, you can use the host command to look it up in the DNS. Now let's look at something that differs across these packets. At the end of each record, there's a length field that's telling us how much data was sent in that packet. That's just the payload, the actual HTTP, data as opposed to all the TCP overhead, like addresses, import numbers, and such. So the interesting thing here is that out of all of these packets, only a few of them even have any payload data. For most of them, the length value is 0. This is an important fact about TCP. Even before the client and server get to exchange any real data, they've got some set up to do to bring up the connection. And after they're done with the real data, they have some tear down to do. So looking at the first of these that has any real data, it says length 38, and the only other one has length 321. Well, where did those numbers come from? Well, let's look back at what data we actually sent. Here's our HTTP request, and if you count these newline characters at the end of each line as only one, as the backslash doesn't really count, it's going to come out to exactly 38 bytes. Which means that this record in the tcpdump data exactly represents the transmission of the HTTP request from our client, the example.net server. Now it's your turn. Which of these three packets in this tcpdump capture represents the response data from the server back to our client? Of these three packets, there's one of them that has two things the others don't. It's this one, the second one, here's why. First, it was sent from the example.net IP address, port 80, to our client IP address. And second, it has a link that's not zero. In fact, if we count up all the bytes in the response we got from the server, we'd see that it was exactly 321 bytes long, which perfectly matches what we see here from tcpdump. In order to talk about what's going on in network protocols, it helps to have a bit of a visual language. Just as we might use a line graph to depict a financial trend or a histogram to show the distribution of a variable, there's a particular kind of chart that's useful for illustrating network protocols. It's called a sequence diagram and here's an example. This is a diagram of an HTTP connection using keep-alive. These two lines on the left and right are timelines, with time advancing from the top to the bottom. The line on the left represents the client's view of the world. The line on the right is the server's view of the world. And these arrows between them represent messages sent from the client to the server or from the server to the client. You'll sometimes see them drawn at an angle, which serves to remind you that messages are never instantaneous, there's always latency or lag time between when the client sends something and the server receives it or vice versa. But conventionally, they're drawn straight and we just have to remember that time never goes backwards. Now because we haven't invented time travel, anything that either end does at any point in time, can only be affected by things that that end has already seen. Like if the client sends two requests and the server starts responding to the first one as soon as it sees it, the server can't change its first response on the basis of the second request. It hasn't seen that second one yet. Sequence diagrams remind us to keep things in order and to make sure that our notions of what's going on in the network don't assume that servers can see the future. So, here's what's going on in this diagram. The client since an HTTP GET request with a connection keep alive header. The server sends a response and once a client has received that response it can send another request over the same connection and so on. Here's the thing, though, a sequence diagram always represents some particular level of a protocol. Like here's a diagram for just one request at the HTTP layer with a HTTP GET and a response. But this doesn't show individual IP packets. And I assure you that if that response is a download of a six megabyte file, it's not going to happen as simply as just one arrow suggests. When we look deeper into the stack, we'll find that one exchange on the HTTP level may be a shorthand for a bunch of exchanges on a lower level. In fact, let's take a closer look at that right now. What's actually happening when a TCP connection opens? Well what has to happen? The two endpoints, the client and server, have to get into agreement that a connection exists. Well what information has to be exchanged in order for that to happen? Before anything happens, the client knows the server's IP address and port number, but the server doesn't know anything about the client. So the client has to send the server a message with, among other things, its IP address and port number, saying that it wants to connect to the server on its IP and port. But TCP does more than that. It also keeps track of the data that each end point is sent. And make sure that the other end point has received it, and make sure that the application sees that data in order even if the underlying network reorders the packets. The way that it does this is by putting a sequence number on each packet. Each endpoint sends an acknowledgement indicating when its received a particular sequence number, and if a packet goes missing the other end point will notice there's no acknowledgement and will re-transmit it. Also, sequence numbers start out at a random number so they're very unlikely to get confused between one connection and another. So when the client sends this first packet, it has a sequence number on it like number one two three four five. And when the server sends back its first response that has a different sequence number, like nine, eight, seven, six, it also contains an acknowledgement, saying that the server has received packets up to but not including number one, two, three, four, six. And then subsequently each packet either end sends has an acknowledgement or ack for short. That indicates one more than the greatest sequence number. For which it knows it doesn't need anything re sent. When the client sends the packet containing its request. The server acknowledges that request even before it sends the response. Then it will send the response and the client will acknowledge each packet that's used to send then. For a realistically sized file there will be many, many more of these before we're done. And since there will be many more of these it's not just that the server will be sending a lot of data to the client. The client will also be sending an Ack back to the server for each packet of that data. And because that data is going to be broken up into a lot of packets each with its own sequence number on it there are going to be a lot of ack's flowing back. Even though the client isn't transmitting any application data back. All those packets will have data length zero. They'll still be telling the server how much data has been successfully received. So what's up with all this sequence number business? What is it about the network that makes it necessary for TCP to put sequence numbers on everything? Well, for one thing the network can fail to deliver a packet. If we want to talk about whether a particular chunk of data has been received, we have to have a way to refer to it. But second, the network can also deliver packets out of order. Not going to go into all the ways that can happen. And that's honestly not as common as packets getting dropped. But if one end to sense. h.t.t.p.. And the other one gets t.p.h. t.. That's not going to work out very well for the application level. So how does this actually work. Well, each end point in the operating system. Not in the browser or a web server or other application keeps a space in memory that it fits the incoming data into. And it uses the sequence numbers as positions, like positions. Just like in a big string or array into that space. So here's a quiz. Rearrange these packets into the proper order. These numbers are sequence numbers. And this is the buffer space into which you can reassemble them. Then put the message that you find here. Note that packets may be retransmitted or overlap. So yeah, okay. This is a silly quiz. The password is always swordfish. As you probably noticed, a couple of these packets were retransmitted, and a few of them overlap. That can happen in the real world. It's rare, but it can. So TCP has all of these provisions to deal with packet loss and other failures. But why do these ever happen in the first place? Why don't networks just be super reliable, so nothing ever gets dropped? Well, that's not always an option. Imagine that you have two machines, A and B attached to two different fast networks. But those fast networks are connected by a slow network in the middle. Like maybe these are two offices with gigabit ethernet, and the connection between them is only 10 megabit. That's 100 times slower. Then Host A tries to send a big pile of data over to Host B, let's say a gigabyte of data. Because its own network interface is very fast, in theory, Host A could transmit this data as far as its nearby router, in about 8 seconds. But that data also has to travel over this slow link, and because that's 100 times slower, over that 10 megabit network, it's going to take 13 minutes. Where does the data have to live in the mean time? If Host A were allowed to just push that big pile of data onto the network, in order for it to get through, this router would have to buffer it in memory and trickle it out over this slow link over the next 13 minutes. And meanwhile, nobody else on this network would be able to send anything. This link would be saturated, completely full. That wouldn't be a very good outcome. So TCP and routers don't actually do it that way. Instead TCP doesn't start sending data at full blast. It starts out slowly, only increasing speed when the other end shows it can keep up by sending acknowledgements back. If packets are dropped, it slows down, and then gradually it speeds up again. And routers work with this by dropping packets if the link they're trying to send on is too busy. The result of this is that the endpoints and the routers in the middle collaborate to move data at close to an optimal speed. But this only works because routers are willing to drop packets in order to signal congestion. And endpoints are willing to slow down in response. If the router just let everything queue up, the whole connection would eventually time out. This is called TCP Congestion Control, and that's one of the most important performance features of TCP. Okay, get out your tcpdump again and ask it to show you traffic to and from some made up port like 12345. And then use nc to connect to that port on a machine that actually exists, say www.udacity.com. Now when you do that, what do you see in nc and in tcpdump? Is it that tcpdump shows several packets sent to that host, but slower and slower, but then after a long delay nc exits? Is it that tcpdump shows one packet sent to the chosen host and a connection refused error after which nc immediately exits. Or is it that tcpdump shows nothing being sent and nc crashes? Depending on what address you chose, you might see some different results. But for www.udacity.com, or Google, or a bunch of other sites, it's going to to be the first option. What's happening is that NC tells the operating system, connect to that address. And the OS is trying, trying very hard, but it can't get through because that port's not open. All that traffic is just getting dropped. But as it's trying to get through, it sends these packets slower and slower until finally it gives up. The reason for the slowing down is because one of the common causes of packet loss is congestion. And the one thing you don't want to do in case of congestion is send faster. So the answer we observed here is number one. So what happens if you just make up an IP address and port and try to NC to it? Well, depending on the address you pick you might get any of several different results. NC might exit immediately. Or, it might just sit there and do nothing for a while and then eventually exit with an error saying that it timed out. You might have sometimes seen similar errors from a web browser, talking about a connection timeout. TCP has a number of built in timers. If it takes too long to hear back from the server we're trying to connect to, TCP will abandon the attempt to make a connection and give an error to the application. There's another different timeout from when our end has sent some data but the other end hasn't yet responded. So when you're building applications up at the web level that's something to keep in mind. Sometimes you'll send a query to another endpoint and you won't get anything back. And whether the default behavior is reasonable depends on an application. That's why various libraries, such as Python's requests library, have the ability to set a timeout on queries and notice when that timeout has elapsed. So given what you've seen so far both in this course and in your own experience of using the internet and web services. Which of the following problems do you think might cause a TCP session to time out for instance between a browser and a web server? First, could a timeout because the host at the other end is powered off suddenly? Second, could a timeout because a windstorm blows down the cable between you and your ISP? Third, could it timeout because your DNS server has stopped working? Four, could a timeout because you're connecting to a server that doesn't exist? Or five, could it timeout because you're using a Windows PC for instance, to watch this course, but Microsoft's website is down? So again the question is which of these five problems could cause a TCP session to time out, for instance between your browser and a server that you're connecting to. So the first one, the other host is powered off suddenly. If the computer at the other end of your connection is shut down properly, then programs running on it including web servers will be able to close down any connections they have open. But if it's just powered off suddenly, yes, that can cause those connections to time out for the other end. So this one is true. Number two, a windstorm blows down the cable between you and your ISP. If a windstorm takes out your internet connection, that means that any traffic you try to send will be dropped by your router. So, yes this can certainly produce time outs, although some routers and operating systems will come up with a more useful error message than that. But basically number two is true. Number three, your DNS server stops working. Keeping a TCP session open doesn't rely on the DNS. A client uses DNS to look up a server's IP address before connecting, but after that, it's normally not needed. So the DNS server breaking should not cause open TCP sessions to timeout. Number four, you're connecting to a server that doesn't exist. If you try to access a server that doesn't exist, you might get a timeout, or you might get a different error. We saw it earlier in the lesson. Since you might get a timeout, we'll call that true. Number five, you're using a Windows PC to watch this course, and Microsoft's website is down. But a Windows PC is not going to lose its network clues just because the vendor's website is down. You might get errors accessing Windows software updates, but microsoft.com having an outage is not going to cause random Windows PCs to time out the network connections to other sites like Udacity or YouTube. So number five is false. So the correct answers here are the first, second, and the fourth ones. Network problems and other failures are something that we've just got to live with. What's more, when we design applications, we have to take into account that failures can happen. And that's important at all different levels, at the application level as well as at the network level. Here's a story from a system i used to work on several years before coming to Udacity. I'm going to leave off the names and numbers to protect the not so innocent. My team system was the back-end data service that a number of other services depended on. It was also really busy. It got thousands of requests every second. And almost all of them it handled just fine. But when it got overloaded, our system would fail some requests That sometimes the best thing a system can do. To shed load and make sure it can stay up at all. Unfortunately, one of the services that used ours responded to failures by retrying each request up to three times. So when things started to get overloaded, and our system dropped a few requests, that other server started sending more and more requests, making the overload problem very much worse, very quickly. Fortunately it didn't take us very long to track down the owners of other service and politely inform them that they would be stopping this little retard behavior now please. In the next lesson you'll see a bit about how TCP handles heavy network load without falling over. But don't forget the network can't save you from buggy applications. Design your error handling with care. In this lesson we're going to to take a look at some of the ways that network speed and other properties affect your users experience of your web apps. Networks are not infinitely fast. It takes time for traffic to get from here to there and sometimes it takes way too long. If you're building or maintaining a web application you're probably going to care about this because as a rule users hate waiting. Even if you put clever sayings on the loading screen. You'd still rather be watching the course right? And slowness isn't the only way the network can get in the way of your users. Middle boxes or devices that block or alter network traffic such as fire walls. Can create really puzzling problems between your users and you. Earlier we talked about how the cloud of the internet is held together by routers that forward packets from their source to their destination. Each forward from one machine to another is called a hop. And you can see all of the hops involved in getting your traffic from you to a distant server by using a traceroute tool. Now the most common traceroute tool is called just that, traceroute. You can give it a host name or an IP address and it will display the route all the IP addresses of all the routers that it took for traffic to get there. There are more advanced traceroute tools such as MTR which will repeatedly trace and can sometimes show you different routes the traffic may take. Try it out yourself, use traceroute to list the hops between your Linux host and some other host such as a website. What side did you choose, and how many hops did it take for traffic to reach that site? Here's a bit of trivia about how network people think of their systems. If you do a traceroute and look through the host names of some of the hops between you and some other site, you may often see three letter codes like, sea, here, or, sjc lax, here. These are not arbitrary names, they're airport codes. Network operators often name large nodes of their network after nearby airports. It makes it easier to keep track of them geographically. When you've used Ping, it's given your numbers for the round trip time between you and the machine you're pinging. But what exactly is a round trip time? It's pretty much what it sounds like. Your machine can't tell how long it takes for a packet to get from it to the other end. But it can tell how much time has elapsed between when it sent that packet and when it received a response. That's the round trip involved. So there's this famous book about a ping traveling out from its host to a destination and going through all these hops in the middle and eventually coming back to where it started taking a long round trip. Okay actually this book is about a duck but Pings are kind of like ducks. They usually move in groups all in a row just like those pings that we saw in the terminal were just like these famous ducks in Boston. Round trip time is an important measurement of closeness on the network. But Ping time, as it's often called, isn't the only measurement of performance across a network. We'll see some other ones later in this lesson. So okay, ping is pretty simple, but how do you think traceroute works? I'm not going to make this a quiz because it really is pretty tricky. The ability to trace out packet paths wasn't intentionally built into the Internet protocols. Rather, a clever engineer named Van Jacobson discovered that a safety feature that was made to prevent infinite loops made it possible to do traceroute as well. Here's the safety feature traceroute makes use of. Every packet has a time to live or TTL field, which starts at some large number and is reduced by one each time that packet hits a router. As it moves through the network, each router reduces the TTL on the packet by one as it passes it on, all the way until it finally gets to its destination. This means that if routers are misconfigured so that packets flow around in an infinite loop, eventually the time to live on each packet will drop to zero, and it will expire. This helps keep momentary loops from crashing large parts of the network with an overload of traffic. When a packet's TTL expires, the router that last received it, sends a tiny error message back to the packet's original sender. And that message says that the packet's TTL expired, and it gives the address of the router that saw that packet die. So given that idea, now can you think of how traceroute might work? The TTL mechanism means that if a program sends a packet with TTL0, it will be immediately killed, and an error message will come back. If it sends a packet with TTL1, it'll go one hop, land on the first router, get decremented to 0, killed, and an error will come back. Then with TTL2, it'll go two hops to the destination before it gets killed. So sending packets to a destination with progressively increasing TTLs starting at one, the traceroute program gets an error message back from each router on the way to that destination. And it can use those error messages to reconstruct the path which is just the list of those routers in order that a packet takes to get to that destination. So in the last lesson, you saw this example network. Hosts A and B are attached to fast networks, but the link between them is slow. If one of them tried to send to the other at the speed of the local fast network, they'd congest the link between them. The router would have to drop traffic in order to get anything through. And TCP is smart enough to do slow start to avoid congesting intermediate network links. But here's a more realistic example of a network. Here we have some servers in a data center with an internal network that's very fast, a 10Gbit ethernet. And the data center network is attached to the Internet with a link that's pretty fast too, 1 Gbit. And here are all the users. There are really a lot of users, each of whom have internet connections that are slow by comparison. Now the capacity of a network link or of a multilink path to carry data in terms of bits per second is its bandwidth. And we can talk about the bandwidth of a link here, but we can also talk about the bandwidth available from this user to this server across multiple links. Now that's generally going to be the minimum of the bandwidths of those links. If your server network is very fast, that means that your servers can talk to each other at that high speed. But if your users' home networks are very slow, upgrading your server network will probably not have any effect on the speed that your users see. This may seem obvious but this concept of a limiting factor turns out to be really important in a lot of server administration situations. But if you have a large number of simultaneous users, each of whom was on a slow network, all of those slows may add up to more than a fast. That's one reason server networks are typically a lot faster than end user networks. And this has some pretty significant implications. If you know how much traffic a typical user makes and you know how many simultaneous users you have, you can tell how fast this connection needs to be. Or on the scary side of things, if all of these users started hitting your service as hard as they could, you could tell how fat this pipe would have to be in order to hold up. Bandwidth and latency are the two networky things that people often mean when they refer to speed of a network connection. Or rather, low bandwidth and high latency can both feel like slowness. This is a map of the world. Well actually, it's just a map of the Northern hemisphere. But that's okay. It'll do for this example. Here are a few places around the world. Here's Alice. Alice lives in California. Alice clicks a button in your web app. The app performs a query to your web server. But Alice is here. And your web server's over here in Riga Latvia, many hops away. Maybe traffic has to go to Chicago, to New York, over the ocean to London, down into France, bum around in like the middle of Europe for a while, eventually get to Latvia. And then your server itself consults an API server that's back in let's say Paris. And that takes some time to respond. By the time the response gets all the way back to Alice, it's been a few seconds. So the app's response to Alice's mouse click doesn't feel instantaneous. It feels laggy. That's high latency. Now here's Bob. Bob's computer is from 1997, and he's using an old dial up modem to connect to his ISP. Bob goes to your website. And his browser starts downloading your site's logo which is 100 kilobytes in size. Over the next 15 seconds, your logo slowly appears on Bob's screen. That's low bandwidth. Now one of the biggest contributors to latency on the network is just plain old distance and number of hops. Internet signals are bound by the speed of light. And the routers that move them around the globe take some time to switch their signals around. When you're done with this video, I suggest you go watch Admiral Grace Hopper's video entitled Nanoseconds, which is on YouTube, to get an idea of just how far things can travel in those short periods of time. Now depending on what your app does and how your users use it, bandwidth may not matter much at all. If you're serving big photos or video, of course it will. If you're serving mostly text and small images, your site can be fast even for people on very low bandwidth networks. Today that's less likely to mean old modems, and more likely to mean maybe slow cell phones, which are actually not all that much faster than dial up. Okay, here's a problem to think about that might seem a little bit fanciful, but it's a good way to get intuition about bandwidth and latency. This is a problem about computing the bandwidth delay product of a network link. Which is just what you get when you multiply bandwidth, measured in bits per second, times latency, measured in seconds. If you multiply the bits per second, times seconds, you get a result in bits. And that has a real physical meaning, it's the amount of data in bits that can be in transit, across the link at any moment. The amount that can have been sent by one end, but not yet received by the other. If you think of the network link as being like a water-pipe, the bandwidth is the flow rate of water through the pipe, for instance in liters per second. And the delay or latency is the amount of time it takes to get through the pipe, from one end to the other, in seconds. And in that case, their product is the volume of the pipe in liters the amount of water that's inside of it. Now let's imagine that we have a station on the moon that we'd like to send a lot of data to. We are beaming data to the moon using a laser transmitter that can send one gigabit per second. Now the distance from the earth to the moon is around 384,000 kilometers. And the speed of light, the speed of that laser connection, is 300,000 kilometers per second. So any given bit that we send to the moon travels at that speed. Now, if we're sending at full speed all the time, because the rabbits in the moon really like Udacity courses, how much data is in transit between the earth and the moon at any moment? That is, what's the bandwidth delay product of our earth moon network link? So we're looking for the bandwidth-delay product of the Earth-Moon network link. In other words, at any moment, how much data is in the pipe having been sent by the earth endpoint but not yet received at the moon endpoint? Okay, so it's 384,000 kilometers to the moon, and in one second our laser signal travels 300,000 kilometers, and we're sending at a rate of 1 gigabit per second. Doing a little bit of algebra here, the kilometers cancel, the seconds cancel, and we end up with a value in gigabits that's 384,000 divided by 300,000 and that works out to 1.28 Gigabits. That's the amount of data that's floating in between the earth and the moon. But what happens when several projects all want to send data to the moon? At each end of our laser uplink there's a router whose job it is to decide what traffic needs to be sent through the depths of space. When there isn't enough bandwidth for everyone who wants to use it that's a condition of network congestion. And like we saw before, if an IP router has more traffic to send onto a link than can fit, it can drop packets. Routers can be set up to do this in different ways. For instance, to drop some traffic before other traffic or to try to split the pain fairly among all users. Now we've seen earlier that when a TCP endpoint notices that its packets are not getting through it retransmits the ones that are not acknowledged. Now if packet loss were mostly due to noisy lines or something that would be enough, but a lot of packet loss is due to congestion. Given that, what else do you think TCP should do when there's packet loss? Should it transmit two copies of each new packet? Should it transmit two copies of each new packet 50% of the time? Should it, when packets are dropped, send more slowly? Should it, when packets are dropped, close the connection with an error? Or should it give up on the Internet and invest in a goat farm? To answer this, you can ask yourself what would happen if everyone acted like this. If everyone started sending double copies of their traffic, congestion would just get worse and nobody's traffic would get through. But on the other hand, if we just dropped the connection at the first sign of imperial trouble, somebody would probably want to have us frozen in carbonite. And let's not talk about the goats. But on the other hand. If every end point slows down when there is congestion, the congestion will be relieved. And even though end points can't send as fast as they might want to, but these traffic will get through eventually. So let's say you're running a web app on your own site and some of your users are complaining that they can't get to it anymore. You want to figure out whether their access is being blocked by a firewall or a filter or something between them and you. Which of the following options do you think might be useful to check? First, can the user ping your site by IP address? Second, can the user access a different domain on the same server? Third, are you able to send them email from your Gmail account? Fourth, can they look up your server's host name using DNS, using a tool like host or dig? And fifth, are all of the users that report the problem located in the same country? So if someone in-between your user and your server wants to stop them from using your site, there are a lot of ways they could mess with you. So if the user can ping your IP address, that means the blockage is not just dropping all of their traffic to you. So that can be a useful thing to investigate. Can a user access a different domain on the same server? Well, if they can't that suggests their traffic isn't getting filtered by IP address because normally two different domains on the same server would be on the same interface and same IP address. They might be getting DNS hijacked, but this can definitely be a good thing to investigate. Can you send the email from your Gmail account? Well, when you send an email with a service such as Gmail, it's going to travel a very different path from the traffic between a user and your web server. So this option is not going to tell you very much. Can they look up your server's name using host or dig? In other words, can they look up your server's host name in DNS and get back the IP address? This can definitely distinguish certain kinds of problems with the DNS, so we should definitely investigate that. And are all of the users with the problem in the same country? Well, that might indicate that there is some kind of official filtering being done. So that's definitely a thing to investigate as well So if you're running a web app, knowing that there are NAT, some proxies out there, means you can't assume that all the traffic from particular IP address is coming from the same computer or the same person. For instance, if you want to know how many users are accessing your site, it won't do to just count the number of IP addresses you're getting traffic from. Because a single IP address could have many users behind it, especially in the case of carrier-grade NAT. So, how could a web app distinguish users who are behind the same public IP address? Mark all of these that you think would work. Could have used a logged in user identity, such as a user name. Could have used the speed of the user's network connection. Could have used session cookies. How about the ethernet or wi-fi MAC address? Could have used Geolocation. Or is it that none of these will work? So if your website has users log in that's one way to tell the traffic apart from each other even if your site has some users who are logged in and some users who aren't logged in as in the case of sites like Wikipedia or Google. You can still get a pretty good estimate this way. Now you can't tell much from the speed of the users network connection. And multiple users coming in from the same net are probably going to have the same speed anyway. Apps can assign the session cookie to a particular browser instance even if there's no logged in users identity. So that can work to distinguish different users that are behind the same net. Now a remote user's ethernet MAC address is not something that a web server can see so that won't work. And geolocation involves looking up the user's IP address in a table or service to find out where on the planet they are. But that relies on the public IP address, it's going to return the same answer from multiple users behind the knot. And because these two will work, it's not the case that none of these will work. There are ways you can find out how many users your site has, even if some of those users are behind the same public IP address. Congratulations, you've reached the end of this course. I hope that you find it interesting and informative. And that the behavior of the internet is a little less mysterious to you than once it might have been. I'm going to leave you with one more story about the importance of speed and network bandwidth to the users of a web application. I've put a link to it just below. It's a story from Chris Zacharias, a former YouTube developer. He tells about how reducing the size of YouTube's video viewing page made the site much more accessible. But also that it was hard at first to see the effect without careful measurement. This story is worth reading and thinking carefully about. For anyone who works on large websites or anything else bandwidth intensive. Thanks for your time and energy taking this course. See you around.