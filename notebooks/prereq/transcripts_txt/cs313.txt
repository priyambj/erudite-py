All right. Welcome to the final exam. Let's go ahead and start off with some questions about P vs NP. So, I'd like you to check the boxes here for the statements that you think are true. First, if any problem in NP is polynomial-time solvable, then P = NP. The second question is if any problem in NP provably requires exponential time to solve, then P ≠ NP. And finally, if P ≠ NP, then some problems solvable in polynomial time on a nondeterministic RAM will require exponential time to solve on a deterministic RAM. So, please check all that are true. Let's try a few more of these P vs. NP questions. And again, I'd like you to check whichever boxes you think correspond to true statements. The first one is--If P≠NP, then all problems solvable in polynomial time on a nondeterministic RAM will require exponential time on a deterministic RAM. The second one is-- If a problem requires exponential time to solve on a deterministic RAM, then a nondeterministic RAM can solve it in polynomial time. The final statement is-- Showing P≠NP would mean that all NP-complete problems effectively become solvable in practice. So, check whichever ones you feel are true statements. For this problem, we're going to be doing something similar to what we've done in a previous homework where you were given a magic function to use for a reduction. You're provided with a function solve<u>vc</u> which solves vertex cover for a given graph represented as an adjacency matrix, as we've seen previously. Now, it returns a minimum cover of the graph as a list of 0s and 1s where 1 means the corresponding vertex is in the cover, and 0 means that it is not. Now, what you should do here is use solve<u>vc</u> to write a function multisolve which takes as its inputs an adjacency matrix and a string. The adjacency matrix is simply a graph, and the string is either vertex cover, independent set, or clique, and it returns a list of 0s and 1s, which are assignments of the vertices where 1 means the corresponding vertex is in the solution to the corresponding problem, and 0 means that it is not. Now, you can feel free to use any additional functions you might feel are necessary. But to be graded correctly, you have to use solve<u>vc in the solution to your problem.</u> We've already done a lot of the steps required to solve the 3-SAT problem in this course. We've seen how to represent 3-SAT, the input that is. We've also seen how to apply preprocessing rules so that it's a bit easier to solve after that, and these are mainly in problem sets 2 and 4. Now, what we're going to do is construct a search tree to find if the given instance has a satisfying assignment. So, you're going to code up a function solve<u>3SAT</u> that should return none if the given instance of 3-SAT has no satisfying assignment, and otherwise it should return that satisfying assignment. Now, the search tree technique that we're going to use is as follows. When you take any clause that is not satisfied, and if all of the variables have already been set, then there is no possible solution anymore, so simply return none. Otherwise, we branch into at most 3 cases where in each case a different variable is set so that the clause can hopefully become satisfied. The first variable is set so that the clause becomes satisfied and we don't do anything with the other variables. The first variable is set so that the clause does not become satisfied, and the second one is set so that it becomes satisfied, and then we don't do anything with the third variable. Finally, the first and second variables are set so that the clause does not become satisfied, and the third one is set so that it does become satisfied. These are the 3 possible cases with 3 sets since there are at most 3 variables in any clause. Now, you can write any additional functions required to solve this problem or break this up into sub-parts, and I'd recommend doing that; it should make this much simpler because it can get to be quite a bit of code here. So, have fun solving 3-SAT. I know we've already done a lot of the steps. Let's say we have a variant of the SAT problem called MAX-SAT where instead of the question does the boolean formula have a satisfying assignment we'd rather like to know what is the maximum number of clauses in a given boolean formula that can be satisfied? Let's say we have an algorithm for deciding this, or rather, approximating it, where first we simply assign true or false randomly to all variables, and we count the number of satisfied clauses with this assignment. Then we invert the assignment of all variables, that is, we flip true to false and false to true for every variable, and finally, we count the number of satisfied clauses with this new inverted assignment. Now, my question to you is what is the approximation factor of this algorithm? And please enter the number in this box below. Now we've seen how useful preprocessing can be for a variety of problems. So, let's look at some possible preprocessing rules that we could use for the shortest tour problem. Now what I'd like you to tell me about each of the preprocessing rules is whether they are correct; that is, they don't change the solution outcome to something different than they would be if you didn't apply the rule, and are they effective, meaning they don't increase the size of the input and actually make your job harder. So the first possibility is that we could calculate the shortest path from each vertex to each other vertex, and then we remove all of the unused edges. The second possibility is that, as long as the graph stays connected, we could just remove the heaviest edges and repeat until the graph disconnects and don't remove that one. The third possibility is remove any edge that has a larger weight than the minimum spanning tree's weight. Finally, we could replace long paths by a single edge that has equal weight. So, go ahead and check which ones you think are correct and which rules you think are also effective. Now let's talk about decidability. I'd like you to tell me which of the following statements are actually decidable and check whichever ones are. The first one is given a program P and an input I, P produces I as its output. The second statement is given two programs, they will always produce the same output for a given input. The third is given a program P and input I, P uses at most 50KB of memory. Next, given a program P that takes 2 arbitrary integers as input, we determine if P outputs the sum of these numbers. Finally, given a graph with N vertices, determine if it has a clique of size at least k. Check all that you think are decidable. Say we have a decision problem, and let's call it Problem-X. Now since it's a decision problem, the solution to this problem is just either a yes or no answer. Now let's also say that we have figured out a randomized algorithm for this problem, and we know that the randomized algorithm returns the correct decision, yes or no, with a probability of 75 percent. Now let's say that the randomized algorithm runs in polynomial time and that the type of randomization it uses is basically just a coin flip. So at certain points in the code it just flips a coin, and decides to continue execution at one of two places at random. I'd like to know which of the following statements are true. That the algorithm can be used to produce a correct answer with 99 percent probability in polynomial time. That the algorithm can be modified to always produce a correct solution on a nondeterministic RAM in polynomial time. Rather that it can be modified in the same way to produce a correct solution on a deterministic RAM in exponential time. And finally I'd like to know if Problem-X is in NP and also if it's NP-complete. So check all that are true statements. This course is about really challenging computer problems, and the area of computer science that deals with these challenging problems is called theoretical computer science, or more specifically, complexity theory. In complexity theory, we ask the question of how hard certain problems are to solve for a computer. So how much time you really need to solve that problem. And at the end of this course, we'll even talk about deceptively simple problems that are impossible to solve for computers, and that area is called computability. I will assume that you know some basics about algorithms, programming, and mathematics. After taking this course, you will have an understanding of how to recognize, and actually, also solve, very challenging problems. Plus, theoretical computer science is a very rich and active field of research and this course will prepare you to dig deeper once you are infected by the fascinations of this field. Welcome to our course on dealing with challenging problems. First off, I should probably start by telling you what a challenging problem actually is. Normally, the situation is as follows: When you want to solve a problem with a computer, you write some program on your computer to tell it what you want to do with a certain input. Then you take your input, you feed it into the computer, and the computer will work on your problem. So it'll probably tell you to wait if you've written your program like this, might make some noises, and after a certain time the computer will be done, and it will produce your output. Now, you would think that computers today are powerful enough to basically do this for any problem for which you can write a program. But you might already know that sometimes this is not the case. So sometimes problems are so challenging to solve, even for a computer, even for a very, very fast computer, that you will not get the output. Instead, all that will happen is that the computer will tell you to wait. It might make noises again, and it will keep on telling you to wait. Might make more noise because it's working so hard. But no matter how long you wait, the computer is not able to produce an output because the problem that you're giving it is just too hard, even for a computer. This course is about exactly these challenging problems. Problems that are really, really tough for computers to solve. But it is also a course about what to do with those challenging problems. So how you can solve them using a computer despite them being very hard to solve. Now, the part of computer science that deals with challenging problems is called theoretical computer science. The first part of theoretical computer science that we will be looking at is called complexity theory. And complexity theory is the science of how much, or more specifically, how much resources. So time, or memory, and also other resources a computer will need to solve a given problem. The other part of theoretical computer science that we'll be looking at is called computability. And computability asks the more fundamental question. Computability asks, can a computer solve a given problem at all, given as much time and as much memory as you want? Now, this course will be mostly looking at complexity theory, but we'll also do computability for 2 reasons: First of all, it kind of belongs in the whole picture, to say what computers can do and cannot do. And the other reason is that many problems that fall into the area of computability are actually very relevant, and it's important to understand computability to know what is doable and what isn't. And it's also important to understand computability to know what's possible in general and what isn't. This course has, mainly, 3 goals. After having taken this course, you will be able to recognize what makes a problem challenging for a computer to solve. You will also have an understanding of why these problems are challenging. And through that understanding, I will show you a number of techniques that you can use to navigate around computational complexity. So this course will not only enable you to recognize and understand tough problems but also give you many tools and techniques that you can use to actually solve them in practice. And this is something that, in my experience, is not taught very often. So some people will be able to recognize that a problem is challenging; fewer people will understand what makes these problems challenging. But when it comes down to knowing the techniques that you can use to solve these challenging problems, despite their computational complexity, then my experience is that knowing these techniques can really make you stand out. During this course we will come across many algorithms especially when we study complexity theory, but this is not a course about algorithms in general. Rather, they will be a means to an end, to understand what makes problems hard, and, of course, also to navigate around computational complexity. So for taking this course you should have a basic understanding of algorithms, although we'll also cover the basics to make sure that you all start out on the same level. So to familiarize yourself with complexity theory and computability, here's our first quiz. As in any Udacity course, the quizzes are here to help you see if you have understood the content, and they do not count toward your final grade. So our first quiz will be about familiarizing yourself with the areas of computability and complexity theory. Here I have 3 questions that you could ask in theoretical computer science. So how fast can a computer find a way between 2 points on a map? Can a program decide if another program is malware? So, for example, a virus or trojan. And how much memory is needed to sort a given database? What I would like to know from you, for each of these 3 questions here, is if that question would be studied in computability or if that question would be studied in complexity theory. Please make your selection for each of these questions. And, of course, there's going to be more challenging quizzes here, but for a warmup I think it is very good to understand the difference between computability and complexity theory. The first question, how fast a computer can find a way between 2 points on a map, belongs in complexity theory because here it's a question of resources. So "how fast," that is a question about the time that a computer needs, and therefore, investigating this question belongs in complexity theory. Asking if a program can decide if another program is malware, that belongs in computability because we are not asking about any resources, we're just if it's possible in principle. We're asking, "Can a program do that?" We're not asking how fast or with how much memory it can do that. In the third question we are, again, asking about resources. We're asking about how much memory, and therefore, this 1 belongs in complexity theory. The question about memory is something we are not going to look at much in this course. Actually, I think we are not going to look at it at all. We're going to be concerned mostly with time, how fast a computer can solve a given problem, and, toward the end of this unit, we are going to pose the ultimate resource question and ask, "What are the limits of computation in general? This course has 7 units, and I'm now going to give you a brief overview of what we have planned. The first 3 units will introduce you to challenging problems, and I'm going to do this by telling you about some problems that are really relevant in practice, yet very, very hard to solve. We're also going to do a bit of the formal background of challenging problems through a concept known as NP-completeness. And I'm going to show you how to recognize NP-completeness so that you'll be able to develop an intuition when you encounter a challenging problem. So the first 3 units are basically about recognizing the hardness of a problem. In units 4 to 6 we are then going to discuss what to do if you encounter a hard problem, because, as I told you in the beginning, many people, once they've recognized that their problem is hard to solve, actually tend to stop. And these units here will give you various techniques for solving hard problems. Solving them very exactly using techniques such as optimized search trees and pre-processing, but also solving them almost optimally using techniques such as approximation and randomization. So this will give you an aresenal of tools that you can use to try and tackle any hard problem, should you encounter it. And then in the final unit we'll be going into computability and talk about unsolvable problems, problems that no computer can ever solve, and how you could solve them, nevertheless, if you come across them. In this unit I'm going to introduce you to 3 computer problems that will actually turn out to be quite challenging. And I'm going to do this by introducing you to 3 computer scientists, Alice, Bob, and Carol. All 3 haven't yet had the chance to learn theoretical computer science or about challenging problems. Maybe they just didn't have the time or didn't think it was useful to them. But they're all pretty good practical computer scientists. So they have experience in programming, and know their way around basic algorithms. That's also why all of them work in very high-profile jobs. Alice works in telecommunications; Bob works in biotech or bioinformatics, and Carol works in finance. Throughout this unit, you'll learn more about the problems that Alice, Bob, and Carol are working on, and you'll also meet some additional computer scientists throughout this course. But let's focus on Alice first. Alice is working for a global telecommunications company that owns a telecommunications network around the world. So the network of her company looks something like this. And, of course, this is just to give you an idea; in reality the network is much larger. But they basically have telecommunications centers that are spread out around the world. And these communication centers are connected through cables, something like this. And again, there's many more communication centers, and many more cables here, of course. But this is just to illustrate the problem to you that she is working on. So you see, not every communications center is connected to every other communications center, but they're selectively connected through these blue cables here. Now, of course, for the company that Alice is working for, it's very important to check the integrity of the whole network, which basically means that you have to check if every single cable here is working. Now, to do this, her company can install monitoring devices, which I'm going to draw with a green circle like this here. So the company could, for example, install a monitoring device here. And what that monitoring device does is, it checks the integrity of all cables that are connected to that communications center where you install the device. So it looks something like this. So installing a device here would allow you to monitor all these 5 cables that are drawn green here, and of course in order to monitor the whole network, you would need more than 1 device. But you would not need to install a device at every single communications center. So for example, if you install another device here, which monitors these cables here, and another device here, then this communications center right here does not need an additional device, because all the cables that are attached to it are already monitored by the other communications centers. Now, installing 1 of these devices is, of course, quite expensive. And that is why Alice has been asked by her employer, the telecommunications company, to figure out a way to monitor the whole network by installing as few devices as possible. And, as I said, the whole network is, of course, much more complex than this. So it contains about 500 communications centers, say, so she cannot do it manually. She definitely needs to write an algorithm to help her with this. Now, before we go deeper into the algorithm, let's just make sure that you understand the problem that Alice has to work on. So let's take this very simple communications network here, and what I would like you to do is to figure out the minimum number of devices that would need to be installed in this network in order to monitor the whole network. And please enter your answer as a number in here. There are a couple of different solutions for this, but all of these solutions will have in common that you need at least 4 monitoring devices to monitor the whole network, and I will show you one of these solutions. So you could install one here, which would monitor these cables here. You could install one here to monitor these cables, and then you need one here, or you could have one here. There are other possibilities, as I said, to monitor these 2 cables here. And then finally, you can install one here to monitor these 2. So this is one solution where you use 4 monitoring devices to monitor the whole network, and it's not possible with 3. So how can Alice approach her problem if there are lots of these communication centers? Certainly, she can't just do a random approach and trust that she's somehow going to find the best possible solution. So she needs some sort of algorithm to solve her problem. And one algorithm that would be guaranteed to find the best possible solution, or the minimum number of devices that you need, would be to just try all possibilities. So, for example, if you have a very simple network, such as this one here-- Well, first of all, let's have a look at the best possible solution, and we're going to do this as a little quiz. So I want you to tell me where to install the monitors so that each cable in this network is monitored. And I want you to do this by checking off the communication centers where we need to install monitoring devices. And the answer to that is that we only need to install 2 devices-- one up here and one down here. This one up here covers those 3 cables, and this one down here covers these 3 here, so this one is covered twice. But we need at least 2 devices to cover the whole network and actually, in this case, this is the only possible solution for this. But of course, a computer can't just see that 2 devices suffice. So Alice's algorithm 'trying all possibilities' would have to go through all of the possibilities that you could have of installing a device at a certain communication point or not installing one. So, in this case here, that would be 16 different possibilities if we give the communication points little letters here so we can better distinguish them. So Alice's algorithm 'trying all possibilities' would have to consider installing no device at all, which would of course not be a valid solution. It could try installing just a device at 'A' which, again, would not be a valid solution, and so on. And of course the algorithm would also find solutions that are valid but would use more than the minimum number of monitoring devices that are actually needed. But since the algorithm tries all possibilities, it will also find this solution here using just 2 devices. So to give you a more clear understanding about the algorithm that Alice is using, I'm going to write it down in a sort of pseudo-code. That means I'm not going to write real Python code or any other programming language that you're used to but, basically, do a more formal description of this 'trying all possibilities' algorithm. So the solution that we're looking for is going to be written into a variable called 'minimum devices.' And initially to start off the algorithm, we're going to set that variable to the number of communication centers because that is the maximum number of monitoring devices that you are going to need in any case. The algorithm then goes through each assignment of the values 0 and 1 to the communication centers. And what I mean by that is a value of 0 means that communication center does not get a monitoring device, and a 1 means that we are going to install a monitoring device at that communication center. The algorithm then checks if the assignment is valid. And what I mean by valid is that the communication centers that have a 1 in the assignment are monitoring all the cables in the network. If we have a valid assignment, the algorithm then computes how many devices we used in that assignment, which is simply summing all the 1's that are in the current assignment that we're working on. The algorithm then checks if the current assignment is a better solution than the best one we have found so far. And it does that by taking the minimum of the currently known best solution, which is 'minimum devices'--here--and the number of devices in the current assignment. If you're familiar with algorithms, you might already see a few issues-- even in this pseudo-code--with this algorithm. But we're going to go into that more deeply in Unit 3, actually. Right now, we're just going to work with this very simple version here. So once Alice has programmed this algorithm--here--she, of course, tests it. So she constructs small test instances that she can solve herself and runs them through this algorithm. Now, one thing I would like you to figure out-- now if she actually runs a small test instance through this algorithm-- is how many loops that algorithm goes through. And by 'loops' I mean how many times those lines--3 to 5, here--are executed for a certain network. So let's say that the network consists of 5 communication centers. So for a network with 5 communication centers, I want to know how often lines 3 to 5--this part here--are executed. And the solution to that is 32 because we have 5 communication centers, and for each communication center we have to construct a separate solution-- one where the communication center does receive a monitoring device, and one where it doesn't. So we have 2 possibilities for the first one, then 2 for the second one, and so on. And this is 2^5 which is 32. So let's see what happens if Alice is running her algorithm on a larger network. So, instead of 5 communication centers, she has 20 communication centers in her network. How often are the lines 3 to 5 executed in that case? So the answer here is that the lines are executed 1,048,576 times or just about a million times. And the way you calculate this is very similar to here above. So instead of 2^5, you now have to take 2^20 because-- for the 20 communication centers--you're trying all separate possibilities of having them with a monitoring device or not. So, you can see the general pattern here, and what you can see is that the number of times that lines 3 to 5 are executed grows very rapidly. So, for 5 communication centers it's just 32; for 20, it's already a million. Now, Alice's telecommunications company, of course, has lots more communication centers than that. So, let's assume they have about 500 communication centers. So, for 500 communication centers--if Alice runs her algorithm-- how often are the lines 3 to 5 executed in that case? More than a trillion times? More than a trillion trillion times? Or way more than that? And the correct answer here is 'way more than that.' It's 2^500, which is approximately 10^150. So, that's not even a number we have a sensible name for. So, Alice's algorithm, while being correct, does not offer any way of finding the solution for the problem that she's working on. And now, of course, the question is if this is just because Alice wasn't able to think of a better algorithm than this, here, or because the problem that she's working on is actually a hard problem to solve. Complexity theory deals a lot with problems and with algorithms, so we should say a little bit more about each one of the two. So, a problem normally consists of 3 parts. The first one is very simple. It's just a name that we give to the problem so that when we talk about it, we know how to reference it. In this case we're going to find a better name for that soon, but in this case, we'll just call the problem that Alice was working on 'Alice's problem.' For each problem, we also need to say something about the input that we're expecting for it. So in this case, here, it's a network of communication centers. And, of course, we also need to say something about the output that we are expecting. So in this case, here, it would be the minimum number of monitoring devices to cover all cables or all connections. Of course the most useful output would be to know not only the minimum number of monitoring devices, but where we should actually put them. But you're soon going to see that it doesn't really make much of a difference most of the time if we are just asking for the minimum number or if we are actually asking for the communication centers where we need to put those devices. Now, what Alice devised to solve this problem was a possible algorithm. Now, there's no really accepted definition of what an algorithm actually is. But, for us, it's enough to say that whenever we talk about an algorithm, we'll be talking about the description of a computer program that is able to solve the problem that we are given. Now the question that we want to answer for Alice's problem-- since the algorithm that she has found is not very good-- is if the problem that she's working on is a hard problem or an easy problem. And what we mean by that is if it's possible to find a more efficient algorithm for this problem. If that is the case, then we would call this problem an easy problem. Or, we will soon have a more precise definition of that, actually. And if it's not possible to find a better algorithm for the problem, then this would be considered a hard problem. Now, the hardness of a problem tells you how fast and with how many resources you can solve the problem. But, of course, that would require you to find the best possible algorithm for that problem. And 'best' is not a very scientific term, so we'll have to say a little bit more about the analysis of algorithms. In this course, we're going to do a considerable amount of algorithm analysis, which is why we're going to do an overview of the techniques and notations that we're going to use. If you've already had an algorithm course before and it terms like Big O-notation or RAM or a worst-case running time are already meaningful to you, then you might try and go directly for the quizzes for the respective sections. Let's try it out with a little quiz. What I want you think about is the various factors that we need to take into account when we are analyzing an algorithm or more precisely, when we are analyzing the running time of an algorithm because that would depend on the number of factors. What I would like you to think about is what factors can determine the running time of an algorithm. So here are six different possibilities. First the size of the input, secondly the content or structure of the input, third the type of computer that we are using for the algorithm, fourth the amount of memory the computer has, five how the algorithm is implemented, and six the programming language that we're using to implement the algorithm. I want you think of each of those six aspects and then make a check mark where you think that this aspect can influence the running time of an algorithm. The answer here is that all of these six factors can influence the running time of an algorithm. So the size of the input, I think that's a rather obvious one so in the example of Alice-- if she is running her algorithm on a very small network that takes much shorter time than if she is running it on the huge Python communication center network for example. The structure of the input can also influence the running time of an algorithm. So for example if the network was structured in a way that we find that it can be covered with one or two monitoring devices, then the algorithm could worked in a way that we could immediately stop and not need to look at more complex assignments. Finally, the type of computer that we're using that is also very obvious one. If you're using a computer that is much faster so say we're using a huge workstation instead of a super laptop, then the algorithm would run much faster. The amount of memory the computer has that can also be a very important factor, although it might not be obvious at first sight while the memory has to do with running time. Let's say the memory of your computer is not enough to keep all the data that the algorithm is using and it has to use the hard disk for example to do some of the work or the memory is not enough and the algorithm has to recalculate certain parts of the solution. Memory is also an important factor for running time. How the algorithm is implemented that is of course very important. So are you using an implementation that is very efficient or do you have unnecessary code or any data structures that are inefficient that can make a huge difference in the practice when we run an algorithm. And finally the programming language use that is of course a debate that many people like to have that it certainly a factor. So there are some programming languages that will make an algorithm run a lot faster than other programming languages. And so you need to think about if efficiency matters, they usually also use a programming language that is suited for that. That's quite a lot of factors to look at and actually, I think there are lots of other factors that would also determine the running time of an algorithm. So that's why when we talked about analyzing algorithms, we'll have to work with the number of simplifications to focus on what's really important and not have to take account of all these factors and all the countless others that you might think of. There's three simplifications that we'll introduce to make analyzing algorithms easier for us. The first one is we will talk about a way that we can analyze algorithms without actually having to implement them, which we already that a lot of times. The second simplification is going to be that we're not going to consider all possible inputs that an algorithm can be run on, but we're going to only consider the worst possible inputs and I'll say more about what that means too. And finally, I'll introduce a notation to you called Big O-notation that will allow us to ignore details that for now we'll call unnecessary, so that we can really focus on the parts that are important for an algorithm and ignore those that we're not interested in. What do these simplifications actually look like or how are we going to go about those simplifications. First of all, to analyze an algorithm without implementing, we're going to consider a special kind of computer, which is not really a computer but a model that comes pretty close and that model is called the RAM. Looking at the worst possible inputs is a concept called worst-case running time, and finally to be able to ignore all unnecessary details, we'll use a type of notation called Big O-notation or Landau notation. So let's start out with our theoretical computer called the RAM. The goal of working with a model computer instead of a real computer is that we want to have a machine, which is as easy as possible but still let us capture the main aspects of a real computer. And the reason why you want to have a simple computer is that a real computer contains lots of parts that are not really interesting when we want to analyze an algorithm and also you might have different computers that run at different speeds but actually that doesn't really say something about your algorithm. In the next year, when the faster computer model comes along, you can already run your algorithm a bit faster but that doesn't really say that your algorithm has become better. So our goal here is to strip down a computer that you used to to a model that is as simple as possible but still has basically the same capabilities as a real computer. So we will do this as a quiz and what I want you to think about is what are the essential components for having a minimal computer model. And what I mean by essential is that the computer must still be able to solve problems to perform any computation that this machine here could but also not anymore. So what I would like you do is to check off each of those boxes if you think that this component of a computer is essential to keep in a computer model. So do you need a memory to store your results in? Do you need a graphics card? Some sort of input and output? Do you need a mouse? Do you need a monitor? Some sort of file system? An operating system? Programming capabilities? Or a CD-ROM? And keep in mind that we are looking for a model that is as simple as possible. Now, of course, the answers to these are a little bit subjective depending on what you want to model, but I think that there are three components that are absolutely essential to keep. The first one is you need a memory for the computer because, otherwise, it will not really be able to perform any computations. The second one is you need some sort of input and some sort of output. It doesn't really have to be a graphical output or be displayed on the monitor, but you need to be able to tell the computer what the input is that it's suppose to work on and you need to have some way of reading the output once the computer is done. And you'll also need some sort of flexibility in the processing that the computer is doing, so we expect it to have certain programming capabilities. All the other components I think are not essential, so you do not necessarily need a graphic's card as long as you have a certain type of output. You certainly don't need a mouse to input anything. You don't need a monitor. You don't need a file system or operating system because if you really want that you can emulate that using the programming capabilities and you certainly also do not need a CD-ROM as long as you have some way of providing the input. As we saw in the quiz, there are three things that our basic machine model needs to have. One is the memory, the second one is some sort of input/output capabilities, and finally, we need to have certain programming capabilities. There's a lot of different models that have these capabilities, but in this course, we're going to use a model called the RAM, and RAM stands for Random Access Machine. So, there are many different ways of defining a Random Access Machine, and we'll use a model similar to the one defined by Steven Skiena and his book, The Algorithm Design Manual. The first thing that the RAM has is the memory and that memory can of course be used for input, for output, and for holding the program that the RAM is running on, but as simplification, we're going to split the memory into three parts. We're just going to use this memory here for intermediate results and output, and we're going to have a separate memory for the input and a separate memory to hold the program. And, these two memories here on the left side are read only meaning that the RAM cannot modify the input, it can only read the input, and the RAM can also not modify the program. It could only read the program, and usually, when we will talk about the memory requirements of an algorithm, what we will be talking about is how much of this memory here the RAM is using. Generally, there is no limit of how much of this memory here we have so we always have as much as we want, but the memory is divided into single cells, and each of these cells has a limited capacity so each of these cells cannot have arbitrarily large values, but there are as many cells as the algorithm needs. Now, if we're running a program on the RAM, what we're mainly interested in is the time that this program is going to run for a given input, and there are basically three rules for how long the RAM requires to execute a program. Simple operations such as adding two numbers, multiplying them, or executing an if or for. Those all take one time step. If you have a loop in your program such as a four-loop, this will count not as a simple operation but count as often as it runs. So, if you have a loop that executes a simple operation 100 times, that will count as 100 time steps, and finally, you' ll also get something for free accessing memory. So, reading a part of the input or writing something into a memory cell here, that is free. That means that actually takes zero time steps. And these three rules give us a simple way of determining the running time of an algorithm or program or also of comparing the running time of two programs because all we need to do is count the number of time steps that we expect the RAM to execute for a given input. Let's practice this for a little bit. We're going to practice this analysis as a number of quizzes. For the first quiz, we're going to start off with two simple lines of code and using these three rules up here, I want you to tell me the number of time steps that the RAM will need to execute these 2-lines of code. The answer is that the RAM is just going to take a single time step, one time step, to execute these 2-lines of code because for this line up here--this is just a memory access and we get memory access for free. That's 0 steps and down here, that is a simple operation, which takes one time step. So a total of one time steps. So now let's try a little more challenging example. It's not really challenging, but it's a bit more difficult than the first one. So this is a 3-line code and then I want you to tell me the number of time steps that this code will need on the run. For this, I should mention that we're going to count this operation here--the while and the comparison of s if it's greater than 0 as a simple operation. While we're recording these, actually we thought it wasn't a very challenging example and then we got it wrong about 4 times, but the correct answer here is that these three lines take 11 time steps to execute. The first line is free as in the first quiz and the second line is actually why we had to count a few times until we all got it right. This line here is executed 6 times--once for s=5 and then s is decreased by 1 each time this line down here is executed. So, s starts out as 5, 4, 3, 2, 1 and 0, which means this line here is executed 6 times whereas this line down here is only executed 5 times because once s is equal to 0 this line here is not executed anymore, which makes for a total of 11 time steps. As you can see, exactly counting the number of time steps even though we have a very simple model of just three rules and a code that doesn't even have a variable input is already quite tedious. We are going to introduce a number of additional simplifications that will give us a little more levy here so that we do not have to go through this exact counting process but still learns something about the algorithm. In general, the capabilities of the RAM closely matched what you would expect from your own computer but of course it is a simplification but nevertheless it is a rather solid model. It's difficult to design an algorithm that when you analyze it it will give you a very different idea about its performance that it would get on the RAM. Nevertheless, I think it's important to think about the differences between a RAM model and a normal computer, and we will do this as a quiz. Here are four main simplifications that I think the RAM is making. Here are four properties of the RAM. The first one is simple operations take only one time step. The second one is we assume that we have as much memory as we need. The third one is that memory access is considered to be free in terms of time. And the fourth one is that a unit of memory cannot hold an arbitrarily large number. And of course this is going to be subjective, but I would like you to tell me which of these four properties you think is realistic in the sense that it comes pretty close to a real computer and which of these you would consider unrealistic meaning of you were to run your algorithm on a real machine then there would be considerable differences and again the answers to these are subjective. If you get stuck or if you disagree with me just take next and see where our opinions differ. In my opinion, I would say that the assumption that simple operation take only one-time step is rather unrealistic because in real computer you have lots of differences between simple operations and also loops such as ifs and whys it can take very different amounts of time depending on where and when they are executed. The second one we have as much memory as we need that might be debatable for some cases given that memory is actually not that expensive anymore, but there's still lots of problems where you can run out of memory and so that is still a real issue. I would also say this is rather unrealistic. Memory access being free in terms of times that is very unrealistic because in the real computer, you really have to watch out what kind of memory you're using. For example, if you're using register and a processor that is memory that almost come for free that's very fast, but when you have to read and write to your hard disk that is going to take very long. Memory access being free is really unrealistic. Finally, a unit of memory not being able to hold an arbitrarily large number that is very realistic because your computer depending on how many bits each unit of memory can hold. If its 32 or 64 and there is always the limit of how much you can store in a single unit of memory and then you have to go to the next one. Given that there's lots of unrealistic aspects for the RAM, why are we using it in this course? Well, there's basically two reasons. The first reason is that its a very simple model to use. So, if we have to consider all of those aspect as well, our analysis would get even more complicated than in the simple example. And the second thing is that when we are running or analyzing algorithms on the RAM, the general behavior of the algorithm, how it behaves on various inputs, and how the running time changes with various types of inputs still is rather realistic even though we're not really taking into account these aspects. When you have to implement an algorithm, which is something that we're not doing in this course then of course, you have to take care of these things and see for example if the types of operation you're using is making your algorithm run faster or slower or if you need to take care of memory. As we've already seen for the algorithm that Alice was using, the running time of an algorithm can often very dramatically vary with the size of the input that the algorithm has given, but the running time can also change with the content or the structure of the input. And here's the simple example to show you this. So the algorithm takes as input a string s(0) to s(n-1), which means it's a string of length n, so n characters in the string and here's the algorithm. So the algorithm does something very simple given that string. It counts the number of times that the character a appears in that string. So it sets the counter to zero and then goes through all the characters in the string one by one. And if that character is equal to a then it will increase the counter. So as in the previous examples, we're going to take this line here as a simple operation meaning to take one time step each time it's executed. And we're also going to consider this one here as simple operation meaning also this whole line here is going to take one time step each time it's executed. Now, what I would like you to do as our next quiz is tell me the number of time steps this algorithm takes for a given string s. And to give you that answer, there are two things you need to know or two variables you have to take into account. One is n, the length of the string, and the other one as you're going to find out is a, and with a, we're just going to denote the number of times that the character a actually appears in that string. So your answer is going to be some formula that includes n and includes a, and I would like you to give me the running time by entering the coefficients in the following formula so it's going to be some number multiply by n plus some number multiply by a plus a constant. Please enter those two numbers. So not the result of the formula. It's the running time of this algorithm when it encounters a string of length n where the letter a occurs exactly a times. There's actually two correct answers here depending on how you think about it. Both answers in common that it's always 2<i>n+1<i>a, and depending on how you count this line here,</i></i> it's going to be either a 0 or a 1 and the reason for that is the following-- the first line again takes 0<i>6 as in all previous examples.</i> For the second line, it either takes n time steps if you assume that this for loop here goes exactly through each character of the string and then stops immediately or it takes n+1 loops if you assume that it's executed like a for loop or while loop. This again shows that it can be very annoying to do exact time counting. The next step though is always execute n times because the number of times this inter loop here is executed does not depend on the number of time steps it takes for this line here to end. And finally, the counter is always increased when the algorithm encounters an a, so this line here is executed exactly 8 times. And if you sum up all of these, you get 2n+1<i>a, and depending on how you count this line,</i> you either get a 0 or 1. Let's assume for now that the running time of this algorithm is 2n+a+1, so even for this simple algorithm, the running time depends on both the size of the inputs to the length of the string and the structure of the input, which in this case is the number of times the letter a occurs. And this is of course very problematic because on the one hand when we get more complicated algorithms, the formula here will get very, very complicated. And the second thing is that most of the time we don't even know what kinds of strings the algorithm will encounter, so we cannot get rid of this variable without making any assumptions. We want to avoid these complications and there's actually three different ways you could do that. The first one would be to have a very optimistic view and state the running time for the best possible input that this algorithm could receive. Basically saying this is the minimum running time of the algorithm and state that as its overall running time. You could, of course, also take the opposite view and say--we're going to state the running time as a worst-case view, so we're going to be very pessimistic almost like there was an adversary who is giving us the worst possible inputs and then state that as the running time. And then finally we can take an in between view and say--well, the usual input for the algorithm is not going to be your best case. It's also not going to be the worst case, so let's state some kind of average. I would like to do a little quiz with you here and have you tell me if I give this algorithm here the best possible input, what it's running time will be and again I would like you to state that the function of n, a and the constant and the same thing for the pessimistic view. If I give the algorithm the worst possible input that it can receive, what will be its running time. And I should also note that I haven't told you yet what the best and worst possible input for the algorithm will be but I'll have you figure that out. What would be the best possible input for the algorithm. The best possible input for the algorithm would be if we give it a string that does not contain the letter a at all because this rates at a to 0, so the overall running time will be 2<i>n+0<i>a+1,</i></i> which is this constant here. Now, in the worst case, the string will just consist of a's and this will set a equal to n because each of the letters in the string will be added, and so if a=n, then the overall running time is 3<i>2+0<i>a+1.</i></i> Now, the great thing about this here is that in both cases, both with a best-case view and with the worst-case view, we have eliminated the dependence on a, so we know that no matter what string the algorithm receives, the running time will always be between 2 and +1 and 3 and +1. Now, you could also say--why didn't we ask you to analyze the average running time or the running time for an average input and that is simply because it's very hard to define the notion of average. Does an average string, for example, contain only half of the letters as a or is it at end of sentence, in which case the number of a's will be very low. Unless we have a very precise view of the term average, the running time here would be very hard to define. As you just saw on the quiz, there's three kinds of view we can take with regard to running time. We can take a best-case view and assume that all the inputs that we're getting are the ones that make our algorithms run the fastest or we can take the very opposite view and say that the running time of our algorithm is going to be determined by the worst possible input that it can receive or we can define running time as the average time that our algorithm will take over a number of inputs. Which one of the three are we going to choose in this course? Best-case running time as you've seen in the previous quiz is often rather trivial or meaningless. So for example, if we use best-case running time for our algorithm that counts the number of As, it would only be valid for strings that contain no A at all so we're not going to take this. For the average-case view, actually that could be a very interesting view and practice because when we run the algorithm a couple of times we might not care about how much that algorithm runs on a single run but over many inputs. But as you've just seen in the quiz, it's actually quite hard to define what an average input looks like. And also when we do the analysis of an algorithm sometimes we might not even know what kinds of input the algorithm receives. Average-case analysis is very interesting sometimes. But here, it's actually not that suitable. Now, worst-case analysis. Well we always assume that the algorithm receives an input that makes it run as long as possible might seem a bit pessimistic to you. It's almost like we had a mean adversary who was trying to give us the worst possible inputs. But on the other hand, the advantage of worst-case analysis is that it offers guarantees. What I mean by that is when we take a worst-case view we know that our algorithm will not run longer than the worst-case analysis suggests no matter what happens. And this is actually what we're interested in in this course so we are going to use worst-case analysis. Meaning, we're always going to state the time of our algorithm for the worst possible input. Worst-case running time gives us guarantees and also it sounds like it's a very big simplification, but the thing is as long as we're still counting the number of time steps of the algorithm exactly even worst-case running time can get pretty tricky and I'll give you one example for this. Again, we're going to consider an algorithm that takes as input a string of length n. What this algorithm does is given the string of length n, it counts the number of times that the sequence ab appears in that string. So it will iterate over the length of the string and if it finds an a, it will look if the next character is a b and if that is the case, it will increase the counter here. What I would like you to consider for our next quiz is what a worst case and a bust case input for that algorithm would look like. Here we have the number of potential inputs and it doesn't really matter how long those inputs are. It's more about their structure and if the structure would cause the algorithm to behave as it would in the worst case or in the best case or something else, and what I would like you to do is for each of those strings, tell me if that string will cause the algorithm to go into a worst-case running time, a best-case running time, or something else. For each of those four strings, I would like you to tell me if those strings caused the algorithm to have the best possible running time or the worst possible running time or something in between, and it doesn't really matter how long those strings are. It's the structure that I want you to look at. To see how any of those strings make the algorithm behave, now let's have a closer look at it. The first three lines here are independent of the structure of the input. If you look at them, the counter is set to 0, we go through a range, and then we look if the letter that we're currently at is an 'a'. Those are independent of what kind of string we're looking at. We'll always be executing these parts of the code. But for those two parts here, that's kind of different. This line here, which is the fourth line, so this line here will only be executed if we have encountered an 'a'. And this line here will only be executed if we have encountered an 'a', then the next character is a 'b'. How often these two lines here are executed is dependent on the structure of the input. Now, in the worst case input, we would want these two lines to get executed as often as possible and in a best case scenario we would want them to get executed the least possible number of times. What we can already say is that a best case input will cause these two lines here to never be called and that only happens if the string does not contain the letter 'a' at all, which is the one down here. For the other strings, let's just go through the algorithm and count how many times this line here is executed and how many times this line down here is executed. If the string looks like ababab and so on, then every time that the algorithm encounters an 'a' it will execute this line down here and it will also execute this line down here because the next letter is a 'b'. Now, what if it encounters 'ab'? It will not execute this line, and it will not execute this line. And then it encounters an 'a' again, so this line will be executed and this line will be executed. And then again those two won't be. Then we have them both again. Then zero times and so on. Basically, for every two letters that it encounters, it will execute these two lines. So two lines per two letters makes one extra line per letter. Now for the second string, what happens is this. The algorithm encounters an 'a' so it will execute this line but the next letter is not a 'b' so it will not execute that line down here. And then it goes on to the next letter and again it encounters an 'a' so this line here will be executed but not this one down here because the next letter again is not an 'a'. So as the algorithm progresses, it executes one extra line per letter just as the string above. Now, finally, if the algorithm encounters acacac, what will happen is this. First, the algorithm encounters an 'a' so it executes this line down here. But then it does not encounter a 'b' so it will not go into this line. Next letter, the algorithm encounters a 'c' so it will not execute this line down here and so on. I think you get the picture. So this is not one extra line or letter but it will only be 0.5. It already tells us that the string here is not a worst case string but it's something in between. Now those two strings because they both require the same amount of time are either both worst case or they're both something in between. Now, this is something where you just have to look closely at the algorithm to see that a worst case input is among others one that contains as many times the letters 'a' 'b' as possible which is exactly this string. So there's no worse strings to encounter for this algorithm. So this one is a worst-case input. But surprisingly also this one down here although it doesn't contain the sequence ab at all it's also a worst-case input. Even now that we have introduced a number of simplifications. We have introduced the RAM as a simplified computer model to count the number if time steps and we've also said that we're just going to look at worst case running time you see that the analysis of algorithms can still be quite tedious. It's sometimes hard to identify what exactly a worst-case input will be. And even if we know the worst-case input, finding the exact formula for the running time is very difficult, which is why we're going to introduce another simplification to state running time and that simplification is known as big O notation. Big O notation is the final tool for analyzing algorithms that you need to know about before we can analyze Alice algorithm. As we've just seen even talking about worst-case running time can be a bit tricky if we're trying to be very precise. We have to identify the worst-case input in detail, which can be counter intuitive and then work through a lot of different cases. And also as we noticed it's annoying to have to count every single step an algorithm makes. So for example if you have two algorithms and one had a running time of 2n²+23 time steps and the other one had 2n²+27 time steps, you wouldn't really care about the 23 or the 27. You would say that essentially they have the same running time. So we are going to introduce a huge simplification to stating running times and that is called Big O-notation. If you've had an algorithm course before, you should already be familiar with this but we'll review it here just to make sure you understand. So let's say we have two algorithms, algorithm A and algorithm B, and algorithm A has a running time 3n²-n+10 for an input of size n, and algorithm B has a running time of 2^n-50n+256. So what I would like you think about is which of these two algorithms you would prefer if you don't know anything about the input other than that you're going to get different sizes. So no other structural assumptions or anything else that you know. And I would like you to check this box if you think it's algorithm A that if you take in general and this box if you think it's algorithm B. The answer is that in general I would think that algorithm A would be preferable to algorithm B because the running time of algorithm A is 3n² -n+10 and here we have 2ⁿ. So just ask what the algorithm of Alice, this function here would grow very fast if and increases, but of course this is only a very general statement. So in general you have to be a bit more careful about choosing algorithms even if the running times deviate like this because as we said before we are taking worst-case running time so maybe the average-case running time of algorithm B is much better than of algorithm A and also we might be dealing with very small inputs. So if you would know that n for example does not get much bigger than 10, then those 2 algorithms are almost equal or sometimes even algorithm B would be preferable, but in general, if you don't have any other information, I would go with algorithm A because the running time is much lower than the running time here as long as n is not very small. So when you just compared algorithm A with algorithm B, I guess there were certain parts of the running time that you did have a look at and that you based your comparison on and there were other parts that you ignored. So the parts that you probably ignored are the +10 and the +256 because those are just constants that we add to the running time function, and also when we compared function, we didn't really care about the -n or the -50n because we just look at the growth of the 2n versus 3n². And even the 3 here is not that important because if we had say 5n² here or 6n² or even 100n², 2n would still grow much faster. And this is why in theoretical computer science, we used a notation called Big O-notation that leads away all those things that we didn't really care about when comparing the algorithms. What did we just do when we determined that the running time of algorithm B grows much faster than the running time of algorithm A. Well first of all we said that there was some value of n. So some value for the size of the input where this running time function is always larger than this running time function. So the running time of algorithm A is some function f(n) and the running time of algorithm B is some function g(n). So if g(n) grows faster than f(n) then there must be some value of n for which g(n) is larger than f(n). And for any value larger than that, this must also be true and we are going to call that value n‘. And for that value n‘, we must have that g(n‘) is larger than f(n‘) because we're saying that g(n) grows faster than f(n) and of course this must hold true for all values larger than n‘ So we have a second condition here that for any value larger than n‘, we must also satisfy this condition here. Now we also said that we do not want to care about constants. So we do not want to care about if this here says 3n² or 5n². We would just say that this function basically grows depending on n². So in order to do that, we need another number in here and that number is a constant that would allow us to scale the function g(n) and I'm soon going to give you a few example to show what that means exactly. But in general it means that if we can multiply this function here with some number, let's call that constant c, so that it outgrows f(n) then we would be still be satisfied. Then we would still say that g(n) grows at least as fast as f(n). And this is all you need to know to understand big O notation because if those two conditions here are satisfied so there are some numbers n‘ and c so that c<i>g(n‘)≥f(n‘) so there's some point where</i> this function gets at least as large as this function and from any point onwards, this function continues to be at least at large then we would say that f(n) is contained in O(g(n)). So the big O means that g(n) is a function that grows at least as fast as f(n) and this is the O that gives big O notation its name. If the function f(n) is contained in O(g(n)), this means that g(n) grows at least as fast as f(n). Now this might sound a little more complicated that it actually is. Let's use some examples to see how functions outgrow each other. Here I have a graph and is on the x axis and I'm going to draw three functions on this graph. The first function is called f(n), the second function is called g(n), and the third function is called h(n). What I would like you to tell me know is which of the following statements is true. Is f(n) contained in O(g(n))? Is f(n) contained in O(h(n))? Is g(n) contained in O(f(n))? Is g(n) contained in O(h(n))? Is h(n) contained in O(f(n))? Or is h(n) contained in O(g(n))? So more than one of these is true and I would like you to check each one that is true. So every time that this function here outgrows the other function, I would like you to check this box. There are three statements here that are true. The first one is true because f(n) clearly grow slower than g(n), so g(n) grows at least as fast as f(n). The second one is also true because h(n) grows even faster, so it outgrows f(n) also. The f(n) here is the slowest growing function, so it does not outgrown g(n), but h(n) on the other hand that is the fastest growing function so it does outgrow g(n). This one here is true also, and since h(n) is the fastest growing function, it's neither in O(f(n)) or in O(g(n)). You can see the slowest growing function is always contained in O of the two faster-growing functions and the fastest growing function is not contained in either O(f(n)) or O(g(n)), which are growing slower. Big O notation is very useful because we can use it to concentrate just on the fastest growing part of the function and even without all the involved constants. I now want to show you a few examples to make this more concrete. So 3n+1 for example would be contained in O(n) because we do not care about the +1 and 3n grows at the same rate. It does grow at least as fast as n. The function 18n²-50 would be contained in O(n²) because again n² here is the fastest growing term. We do not care the minus 50 and we don't care about the constants. Now very similarly here, if you have 2ⁿ+30n⁶+123 that would be in O(2ⁿ). We do not care about the constant and those two terms here, they both depend on n but 2ⁿ outgrows the 30n⁶ and since we add those two terms here, 2ⁿ is really just the fastest growing part. Now if we don't add those two parts here but for example we multiply 2ⁿ<i>n²,</i> we need to include that into the O notation because just having 2ⁿ that grows slower than 2ⁿ<i>n².</i> We just have 2ⁿ here. That statement would not be true because 2ⁿ grows slower than 2ⁿ <i>n² .</i> So what about a statement like 3n+1 is contained in O of n² because n² really grows at least as fast as n. This one must also be true and it is true the only thing it would unusual to write this because usually we're trying to state this bound here as tight as possible. Similar down here, you could also say that 18n² -50 is contained in O of to the n³ but again this would be unusual to write because if we have a tighter bound that we can state, we would state this part over here. Enough with the examples, I'm going to let you figure out the rest as our next quiz. We have a number of statements here, and for each of those statements, I would like you to tell me two things. The first one is if the statement is correct and the second one is if the upper bound I'm giving you on the right side here is the best possible bound or the tightest bound that you can find. Please check all of the boxes that you think are correct. The first one, 4n²-300n+12 € O(n²) because n² is the fastest growing term. So it's correct. And it's also the best possible bound because we have n² here as the fastest growing term, which is exactly the same that we wrote here. The second one is also correct because n³ grows faster than n², but it's not the best possible bound we can give because we already found out that n² is the best possible bound that we can give. Now down here 3ⁿ+5n²-3ⁿ grows much faster than n² so this is not true and of course it cannot be the best possible bound if it's not a correct bound at all. In the next one, 3ⁿ is the fastest growing term and this is exactly what we're setting on the right here so it's correct and it's also the best possible bound that we can give. The next one, again, the bound is correct. This is similar to here when we compared n³ to n² so 4ⁿ grows much faster than 3ⁿ, but again, it's not the best possible bound because we already know that 3ⁿ is the best possible bound that we can give. This one down here is similar to one of the examples that I just showed you, so we can ignore the constant here and 2ⁿ(n²) grows faster than 2ⁿ so this is not correct. And since it's not correct, it cannot be the best possible bound. Now, this one down here is probably a little bit tricky because 2.1ⁿ indeed grows faster than 2ⁿ(n²) so if you plot those two functions you can see that 2.1ⁿ will outgrow this part here, 2ⁿ(n²), so it is a correct bound but it is not the best possible one because the best possible one would be 2ⁿ(n²) and not 2.1ⁿ, which grows much faster. So, as you can see, O notation is simply about looking at which part of the function grows the fastest and then it's a very convenient way of actually describing the growth of that function while ignoring details that are a bit distracting and not necessary for the analysis that we are going to do in this course. Now, there's one final note I should make. Some people instead of writing f(n) € O(g(n)) also write f(n) = O(g(n)) and sometimes but this is not very common people will also write it as if it were a subset. So they would use the symbol here and say subset contained in O(g(n)). This here is probably the most correct way to state it because O(g(n)) is actually a set of functions if you were to consider it mathematically. But this one appear = O(g(n)) is also a very common one that you can also find in many scientific papers and even teaching books. Big O-notation is also sometimes called Landau notation, named after the German mathematician--Edmund Landau. He didn't invent the notation, which was done several years before him by another German mathematician called Paul Bachman, but he popularized it in the 20th century. In a way, this is actually quite ironic that you should have popularized a notation that contains so much approximation as big O-notation because Edmund Landau was actually known as one of the most exact and pedantic mathematicians. His goal was to be uncompromisingly rigorous. In his lectures that he used to given, he even had an assistant who always attended his lectures and was instructed to interrupt him if he even omitted the slightest detail. It's interesting that he introduced a notation that omits all of the details. Now you can learn about the basics of analyzing algorithms, and we introduced three simplifications that make our life going forward much easier. The first one was the RAM model so that we can analyze algorithms without actually having to implement them. The second one was the concept of worst-case running time so only having to consider the worst possible inputs and not the best ones, not the average ones, such as really the bad ones, and finally, we introduced big O notation or Landau notation to be able to ignore all unnecessary details in the algorithm analysis. Let's go back to the example from before when we tried to count the number of times that the sequence a b appears in the string of length n using this algorithm down here. And as you remember from the quiz, this was actually quite painful because we had to figure out what is the wort-case input, and we noticed that this is actually not easy to figure out and even if you have this figured out. There is a lot of detailed counting that you need to do, and there are details you need to take care of such as how often is this line here actually executed and so on. So now that we have big O notation available, our task is much easier because we can just make two observations and will be able to state the running time. So the first observation you can make is that the algorithm will actually go through the string one by one by one, and since it always just looks at a single character and the next character, the algorithm will look at each character and again put string at most twice. And the second thing to notice is that each time the algorithm does consider a character so it starts out to zero, one, two, three and so on, it will perform a constant number of operations. So if it finds an a, it will do either one or two additional operations, and if it does not find an a, it will do zero additional operations. So for each character in the input string, a constant number of steps is performed and this is exactly advantage here because with big O notation, we can ignore constant. So overall, this means that if you have an input of length n, the algorithm will perform a number of steps that some constant times n plus some constant for all the rest of the operations, but using big O notation, we already know that this is O of n. So we do not need to care anymore about the detailed number of times this here is executed. We do not need to care about the detail such as how often this line here is executed. We can just say that the running time of this algorithm is O of n, which would also be referred to as a liner algorithm. Now, let's have you figure out the running time of another algorithm using Big O Notation. So, this is the algorithm that we are going to look at, it's just four lines and actually the algorithm does not perform any very useful function. The most important part is that it's interesting to analyze its running times. So, there's not really any value or at least none that I can see of actually producing this result down here. So, what I would like you to do is to figure out the running time as a function of this value n here, and I'm going to give you a number of choices for your answer. So, the first choice is O (n) so it would be a linear algorithm. The second one is O(n¹. ⁵). Next one is O(n²). And the final one is O(n³). So, I want you to check the box that states the correct running time of this algorithm expressed as a function of n, and I'm also going to give you a little hint, which is that if you add n + n-1+ n-2 and so on plus 2 plus 1 that is equal to n²+n/2. And once you analyzed the algorithm, you'll see that this hint is actually quite useful. The correct answer here is O(n²), and to see that, we just have to look at how many time steps of this I wouldn't requires other function within. As you remember, this line up here takes zero times steps because it's just a memory access and we said those were free. This one here, it depends again what you do with the end of the range here but it's going to be executed about n times, so it's either n or n + 1. That doesn't really make much difference here because now we can use big O notation. How often is this inner loop here executed? The first time, it's actually executed n times, then the next time it's executed, it's going to be executed on the n - 1 times, and so on and so on because this i here, this value here increases, and as this increases, this inner loop here is going to be executed less and less times. Here we have first time, we're going to have n times steps, the next time, we're going to have n - 1 times steps, the next time, we're going to have n - 2 times steps and so on, and the same basically also holds true for this inner loop here. So, if this is executed n times, then the inner loop here, again depending on how you count that is going to be executed n times or n - 1 times So, these two parts here, that is exactly where you need the hit. So, it's two times this part here, so it's two times n² + n over 2. So, the total here is n² + n. So, the total number of times steps is 0 + n + n² + n which is n² + 2n which is O(n²). Now, as you get more familiar with analyzing algorithms, you will actually see that having two inner loops usually leads with quadratic running time and you wouldn't even have needed this extracted here. So, with more practice, the analysis of algorithms becomes easier and easier and you will have to do less and less of the tedious single line counting. One final thing, of course, O(n³) is technically correct but as I already mentioned when discussing big O notation, you want to bound to be as tight as possible. This is really the only correct solution. Now that we have learned how to analyze algorithms let's look back to the algorithm that Alice was using to solve her problem which was the whole point of us learning about algorithm analysis in the first place. Here again is the algorithm that Alice was using. It's those five lines here. And although we already notice that it's a running time that grows exponentially we don't really yet have the precise running time stated in O notation. In order to do this, let's look at the individual lines and see how often they are executed. And then as a little quiz, I will ask you to figure out the running time of Alice algorithm using O notation. Let's start with line 1, and line 1 is just an assignment of a value. That's actually it takes zero times steps but we can also just say that it takes O(1), which just means that it's some constant although in this case the constant is zero but O(1) is a general notation to keep in mind. Anytime you want to state that an algorithm runs in constant time you can just write O(1). Now, line #2. When we have n communication centers. So N is going to be the size of the input in this case. Then we already figured out at the beginning that this line here is going to executed O(2^n) and I'm going to use this notation here, which you might not be familiar with to say that n here is the exponent. So what about line 3? So line 3 is going to be called each time that this loop here executes. So each time the loop of lines 2, 3, 4, and 5 executes we're going to call this function here. Now the question is how long does it take as to check if an assignment of 0 and 1 values is valid. So if you have a network that has n communication centers then in theory each communication center can be connected to any other communication center. So you have n communication centers and the question is how many connections can they have between each other? So this one could be connected to this one, this one here, this one here, and so on. And basically checking if an assignment of 0 and 1 values is valid means checking for each cable between two communication centers whether at least one of the communications centers is assigned a 1. The running time of checking if the whole assignment of 0 and 1 values is valid depends on the total number of cables. The question here is what is the maximum number of cables that we can have. And that is actually very similar to the running time of the algorithm that you analyzed in the quiz a few minutes ago because the first communication center can be connected to n-1 other communication centers and the second one is it can also be connected to n-1 other centers but of course we don't want to double count or actually it doesn't really matter if we double count or not because we're using O notation. But if we don't double count, then it's just n-2 cables here and this goes on and on and on. And from the algorithm that you analyzed before when we were discussing O notation, you already know that if you do the sum of n-1, n-2, n-3, and so on until you get down to 1 then that is O(n²). The worst case running time for checking if a given assignment is valid means going through O(n²) different cables and then for each of those cables checking if one of the communication centers that it is attached to has been assigned a 1. Now to figure out the running time of this line here, of course we first know it's O(n²) cables and then the question is how much time do we need to check an individual cable but for now I think without further discussion we can assume that it's constant time because it's just connected to two communication centers. There's probably an efficient way that we can implement this. If you were to prove the actual running time of course you would have to have a more detailed discussion here. But for now we'll just say each time this line here is executed it takes O(2^n) time. Now, what about line 4? Each time this line is executed, we have to do the sum of all the 1s in the assignment. And now the assignment concerns the communication centers. So we have to go through n communication centers and count how many 1s we find. So each time this line is executed, it will take O(n^2) time, which is linear time. And finally, line 5 is taking the minimum of the best possible solution we have found so far and the number of devices we have in the current solution to figure out if the current solution is a better solution than the one that we already have. But this of course takes only constant time because it does not depend on the size of the input. It always takes two values and produces a minimum. So as announced as our next quiz, I would like you to take this information and figure out what the overall running time of Alice's algorithm will be given a network of n communication centers. So which of these six possibilities is the correct running time of Alice's algorithm above? And the correct answer here is O(2n<i>n²) and the reason why this is correct is as follows--</i> so the first line here takes constant amount of times so that's not going to be relevant. Now, this loop here lines 2 to 5 are executed 2n<i>, so the question is each time this interloop here</i> lines 3 to 5 is executed, how much time does that take. So checking of the assignment is valid, takes O(2n²<i>), then if the assignment is valid,</i> we need an additional O(n)+O(1), so an additional O(n) time because this here is constant, so we can ignore it. So the maximum time that lines 3 to 5 take is O(n²)+O(n)+O(1), so the largest growing term here is O(n²)--so the interloop takes O(n²<i>) and that is executed 2n<i>.</i></i> So that's why the running time of Alice's algorithm is O(2n<i>n²),</i> and the good thing is that because we have our own notation, we could do this analysis without actually concretely stating how all of these algorithm is programmed. So as I hoped you see, it's quite a useful notation to have. Alice is facing the issue that her simple algorithm while it's correct does not show an acceptable running time so we should probably say a little bit more as to what we would consider an acceptable running time, like here and what we would consider an unacceptable running time. And in theoretical computer science or at least for the first units of this course, we're just making a distinction between two cases basically. The first case here is polynomial running time. And polynomial running time means that the algorithm has a running time that can be stated as some polynomial of the size of the input. So, polynomial time would be an algorithm that has a running time of O(n), O(n²), but even with an algorithm with a running time such as O(n¹⁰) or worse would be considered a polynomial time algorithm and we would say that the running time of this algorithm is more less acceptable. Now, exponential running time, those are algorithms that have n in the exponent of their running time. So, O(2ⁿ) would be an algorithm that's exponential running time. O(1.1ⁿ) would be an algorithm with exponential running time and also something really bad such as O(10ⁿ) that would also be an exponential running time. What about an algorithm such as O(3ⁿ<i>n²), that would also be called exponential running time</i> because as you saw in previous quizzes, the 3ⁿ is the fastest growing term here. So, the dominant term here is an exponential term. So, running times like this would also fall under exponential running time. Now, let's do a little quiz just to see that you can easily make the distinction between the polynomial and exponential running time. So I'm going to give you a couple of running times and I want you to tell me if this is a polynomial running time or an exponential running time. So we have O(2n<i>log(n)), O(2log(n)), O(1.00001n), n¹⁰⁰⁰, and then Alice's algorithm,</i> which you'll recall had a running time of O(2n<i>n²).</i> So please for each of these functions is that the function for a polynomial running time or for an exponential running time. So, here's the correct answers. The first one, 2^n<i>log(n).</i> That is clearly an exponential running time because 2^n is exponential. Now, what about the next one, 2^log(n). Well, 2^log(n) is actually O(n) because... So, having the logarithm and exponent, well, actually cancel out the exponents. So, that is O(n). So, although it might look exponential, if you don't look closely enough, that is actually a polynomial running time. Now, O(1.00001^n), that is going to be a very, very slowly growing function, but nevertheless, it's exponential. So, this is the correct answer, and n^1000, that's basically the opposite. It's a polynomial that will grow rapidly fast and you would never want an algorithm actually with that running time, but nevertheless, it is a polynomial running time. Now, this is algorithm--well, you already figured that out I guess because it's 2^n<i>n²,</i> that is an exponential running time algorithm, that's why it's really bad. Now, as you see with those two examples here, there's something to be said about saying that we consider polynomial running time to be acceptable and exponential running time to unacceptable, but in general, what you will find is that polynomial time algorithms tend to have a running time of n² or n³. So, there is not really any algorithm that I would know of, at least now that make sense that has a running time like this. So, it's kind of okay from empirical experience to call a polynomial time algorithm, actually one with an acceptable running time, and the same thing is with exponential running time. So, when you have an exponential time algorithm, you will not have one that has in the base of figure like 1.00001^n. For some algorithms, you might have 1.1 or 1.2, but even then, it's a fairly rapidly growing function. So, it's also okay to call exponential running time algorithms unacceptable in general. Now it's time for you to meet our second computer scientist Bob. Bob is working in biotechnology or bioinformatics and the problem that Bob is working on is he's doing gene analysis. He is looking at bunch of different genes such as this one here. Bob is basically trying to figure out how genes work together. Which groups of genes get activated, say when a cell develops a disease or when it's infected as oppose to the healthy cell. Bob will receive data from a laboratory that will tell him which genes work together or which get activated under a certain condition and which genes don't. For example these two genes here will get activated more or less under the same conditions. Also these two here, but these two here they appear to be kind of independent in laboratory research. Of course Bob does not only receive data on two genes but on a number of genes. And of course there are many more interactions so say group of genes that tends to work together quite a lot. And so since Bob is trying to figure out which groups of genes work together, what he is basically looking for is a collection of genes that are all connected to each other. I'll just give you one example. This here. These three genes are all connected to each other. This is kind of the type of group that he is looking for. What he would not be looking for is for example something like this. These four genes here. Most of them are connected to each other but not every single one of them is connected to every other. This gene here is not connected to that one. And the reason why he is looking for these clusters of genes is that when you find a group of genes where each gene displays a very similar behavior to every other gene, then you have a kind of functional cluster so a large set of genes that can be assumed to be involved in the same processes and you can then use this for drug targeting or figuring more out about the disease. This problem is a bit of a simplification of what you might encounter in the real biotechnology setting. For example you'd normally be content with these four genes here that are not all fully connected but looking for genes where every gene is connected to every other one is a bit more convenient to work with and actually it doesn't really make much of a difference from an algorithmic perspective so let's say it's realistic enough. For our first quiz, what I would like you to figure out for this genetics network here is the largest group of genes that you can select so that every selected gene is connected to every other selected gene. What is the largest group of genes where every gene is connected to every other gene. You've already seen that we can find a group of three genes where every gene is connected to every other gene, but may be you can find a larger one. The way I want you to answer this quiz is just to check off the genes that belong to this group. Which genes do we have to select so that we have the largest possible group of genes where every gene is connected to every other gene. The answer to that is we can find a group of four genes that are connected to each other by selecting this one here, this one here, this one here, and this one here and as you will see, this gene here is connected to those three. This gene here is connected to that one, that one, and that one. This one up here is also connected to this one, this one, and this one and similarly here the fourth one is also connected to the other three. That is actually the largest possible group of genes that you can find that are all connected to each other in this network. Now it should be noted that this problem is a bit of a simplification of what you might encounter in a real biotechnology setting. For example, normally in biotechnology you would be happy if you found a group of genes where most are connected to most others but here we'll be looking only for groups that are fully connected to each other so like this one here. The reason why we're doing that is that from an algorithmic perceptive, it doesn't really make much difference and it's just simply to work with the problem where we know we have to find groups of genes that are fully connected to each other rather than if we allow certain connections to be missing. Similar to Alice, Bob has been asked to design an algorithm that would find these large group of genes because as I'm sure you already have noticed in this quiz, it's rather difficult to find these large groups. You start out by finding small groups but once you have tried to extend them, often you'll find that one or two connections are missing and then you have to start all over again. This is a typical problem that you would like to use a computer to solve for you. How can Bob approach this problem. Well, actually, he could write an algorithm that is very similar to the one that Alice has used. We start out by setting the size of the largest group to zero because we haven't found any group yet, and then again we can try all assignments of the value 0 and 1 to the genes. A 1 meaning that we're considering this gene to be part of this large cluster of genes that are all connected to each other and an assignment of 0 and 1 to the genes is valid if all genes that have been assigned 1 are connected to each other. If that is the case, then the size of that group is again the sum of the number of genes where we have assigned a 1 and the largest group is the maximum of the largest group we have found so far and the size of the new group that we have just found. The main difference to Alice's algorithm are two things-- One is, it's a bit different which type of assignment we consider as valid and the other one is that now we're not looking for a group of genes or communication centers that is as small as possible, but now we are looking for a group of genes that is as large as possible. Since the algorithm is so similar to Alice's, I think it should be rather easy for you to figure out our next quiz and of course, that quiz is going to be to determine the running time of Bob's algorithm and of course, I would like to state that in big O-notation again. I'm going to reveal to you that the running time is going to be O of some number to the power of n times n to the power of some other number or the same number where an n is the number of genes in case you were wondering. And the correct answer here is that the running time of Bob's algorithm is 2^n n², which is just the same running time as the algorithm that Alice was using, and the reasons are also very similar. If you have n genes, then again there's 2^n assignments of 0 and 1 to the genes, and checking if an assignment is valid, so checking if all genes that have a 1 are connected will also take O(n²<i>).</i> That, of course, depends a bit on how many 1's there are in the assignment, but a worst-case analysis would be here that close to n genes have been assigned 1, so we need to check all of their connections which similar to Alice's algorithm, you already know there are about n² many of them. Bob, similar to Alice, has so far only found an algorithm that is totally impractical for the problem that he's trying to solve because it has exponential running time. What both Alice and Bob have so far been able to find is--they have found exponential time algorithms for their problem and they haven't been able to come up with anything better so far. The question of course is does the fact that Alice and Bob have not yet been able to come up with a polynomial time algorithm mean that the problems they are working on are only solvable in exponential time or could there be some sort of polynomial time algorithm that they haven't found yet and there's a special terminology for that. Problems or computer problems where you only have exponential time algorithms are called intractable problems, and those compute problems where you can't find a polynomial time algorithm--those are called tractable problems. And this is going to be a rather obvious question to some of you I hope-- does the fact that so far we only know exponential time algorithms for the problem that Alice was working on and the problem that Bob was working on. Does that mean that their problems are intractable or in other words, can we already say whether Alice's or Bob's problems are intractable or tractable, and I would like you to tell me if you think that is the case, so if we can already say that their problems are intractable or if there's probably more information that we need. The answer to that is we are not yet able to say if the problems that Alice and Bob are working on are tractable or intractable, and the reason for that is that we have only considered one single algorithm, but for a problem to be truly intractable, we would have to show that no matter what kind of algorithm we come up with, so if we don't use the simple algorithm like Alice and Bob were using but something more complicated, we would have to show that nevertheless, this algorithm still runs an exponential running time. Just by stating that there' s one algorithm for a problem that has exponential running time does not necessarily mean that the problem itself is hard; it could also mean that we just haven't felt long enough about designing an appropriate algorithm for that problem. The question I would now like you to think about for a moment and this is going to be our next quiz is if you have a computer problem and you want to know if this problem is tractable or intractable, then I would like you to think about which one is actually harder to show or if it's both equally hard to show. If you think that showing the problem to be tractable is easier than showing it to be intractable, then I want you to check this circle here. If you think that showing intractability, so showing that a problem belongs here is easier than showing that it belongs here, and I want you to check this circle here. And finally, if you think it hardly makes any difference, then I want you to check this circle here. The correct answer and again, this might be a little bit subjective, but I think in this case it's not very subjective. Is showing tractability is actually easier than showing intractability, and the reason for that is that if you want to show that a problem has a polynomial time algorithm, then all you need to do is come up with that algorithm. Now, that might be very hard, but nevertheless, once you have found a single algorithm for a problem that has polynomial running time, then you're done. You have shown that this problem is tractable. On the other hand, if you want to show that a problem is intractable--what you have to show is any possible algorithm, so not only the algorithms that you can come up with, not only the algorithms that somebody else can come up--any algorithm that somebody could come up with at any point in time must still have exponential running time. Just stating a single algorithm or even a hundred algorithms is not enough to show intractability. For that reason, I think show intractability is in a way much easier than showing intractability. Now, we already talked about the notion of polynomial running time being associated with tractability and exponential running time being associated with intractability can lead to some borderline cases where you would probably argue. For example, if you had an algorithm that had polynomial running time of O(n¹⁰) and you had an exponential running time algorithm with running time 1.01^n, then actually it would be very hard to decide which one of these algorithms to take. It would kind of depend on additional information. What other constant factors here and what is the size of the n. As I mentioned before, this hardly occurs in practice and this hardly occurs in practice as well. Tractable problems are usually really tractable and intractable problems tend to be intractable in general, but in later units, we'll actually see how you can deal with exponential running times. The question we're now dealing with is both for Alice's problem and Bob's problem. Are they intractable or can we find a polynomial time algorithm that would show us that these problems are tractable? So far Alice and Bob really don't have a good idea on how to tackle that problem. That's why they actually decides to get together and discuss with each other the problems that they are trying to solve, and to that meeting, they also invites a friend of theirs, and that friend of theirs is Carol because as they have learned Carol is also working on a problem that so far she has only found an exponential time algorithm for. Now it's time for you to meet Carol, and as I mentioned at the beginning of this course, Carol is working in finance and her job is to design algorithms that will optimize financial investments. Given recent market turmoils, her employer has asked her to come up with an algorithm that will help them design a secure portfolio of investments. The problem that Carol is looking at is actually quite similar to the one that Bob is looking at. She is looking at a number of investment opportunities for her company, for example, she could invest in precious metals such as gold, silver, or maybe even copper. She could also invest in stocks. So, for example, a copper mining company or in a silver and copper mining company or she could invest in an industrial manufacturer or also in some other bank. In order for the portfolio to be secured, she wants to spread her risk as much as possible. She does not want to invest in things that are too similar or too closely connected. For example, she wants to invest either in gold or in silver, but this line here basically tells us that she does not want to invest in both at the same time, and so she basically only wants to invest in one of those precious metal. If she invest in copper, she probably does not want to invest in the mining company because none of the copper price goes down so will the stock up the copper mining company. Similar here, this is a silver and copper mining, so either invest in this company or in those precious metals here. If the industrial manufacturer is actually a supplier to this company here, you probably wouldn't want to invest in both of them at the same and let's say that the bank down here is backing the two mining company, so you either invest in the bank or maybe also these two mining company separately but you definitely would not want to--well, actually lets just say you also didn't want to invest in two mining companies at the same time. In order to spread the risk as much as possible, Carol, of course, wants to find a portfolio that contains as many different items as possible because then she has spread out her risk, but at the same time, she must observe those rule. She cannot just select all of these possibilities but only possibilities that are not connected to each other. The way that is very similar to Bob's problem because Bob, when he was looking at the genes, he was looking for genes where every gene is connected to every other gene, and now Carol is looking for possible investments that are not connected at all to each other. What is the largest portfolio or how many items can Carol select at maximum so none of them are connected? I would like you to figure that out as our next quiz and I would like you to put your answer here in this box please. And there again several possible solutions here, but the maximum number of items that Carol can select is at most 3 and I'll give you one example of this. For example, she could decide to invest in the manufacturer, which means that she cannot invest in this mining company here. Then she could maybe decide to also invest in this bank, which means she cannot invest in this mining company here, and then she could also choose one of those methods here. Let's say she also decides that she is going to invest in silver, but that means that copper and gold are out of the question. Again, she could have also chosen one of the other possibilities here, but three is really the maximum number of items that she can select. Similar to the problem that Bob was working on, this is of course a bit of a simplification, so when you're working on real work finance problems, you usually have constraints that are a bit more complicate and also of course, your networks will be much larger, but in essence that's a sort of problem that you might encounter in financial modeling and optimization--only a simplified version of it. Now, Bob, Carol, and Alice who are going to come in later are finally having their meeting. Well, I should say something about Carol's algorithm, but Carol already has a bit more experience with algorithms than Bob or Alice. She has already figured out that a simple algorithm that you just try all the possibilities of selecting certain investment opportunities into her portfolio is just not going to cut it. Carol is really looking forward to meeting Bob and figuring out some new ideas. At the beginning of the meeting, Alice is not there yet. Bob and Carol started explaining their problems to each other. Bob is explaining to Carol how among a set of genes some of which are connected. He is looking for groups where every gene is connected to every other gene and Carol, of course, explains her problem where she is looking for potential investments that are not connected to each other. such as this one here. Now, in order to not have to talk about genes and investments anymore, we should use some common terminology for both of those problems and if you already have an algorithm's course, you might have come across a structure known as graphs. and graphs are basically just objects that are connected to each other. The network up here at would be called a graph and the network down here would also be called a graph. This here, the object would be called a vertex and of course, this, this, and all of these objects are vertices so this would also be a vertex, here, either the purple or the green ones and then the connections are called edges. All of the blue connections or some of those that I've colored green here every single one of them is an edge. An edge always connects to vertices and the whole structure is called a graph. And if you used that terminology, you can state the problems that Bob and Carol are working on using a similar language. Bob's problem is basically taking as input a graph with n vertices and the output that he is looking for is the largest set of vertices all connected to each other. What Carol is looking for, again the input is a graph with n vertices and the output is the largest set of vertices not all connected to each other that non-connected to each other. As you can see, once we use the common terminology, the problem that Bob is working on is actually very, very similar to the one that Carol is working on. The only difference is Bob is looking for a set of vertices where all are connected to each other and Carol is working on a problem where none of the vertices are connected to each other but everything else is the same. You are given a graph with n vertices, you are looking for the largest possible set, and all it's about is the connection that these vertices have to each other. In the future, to be better able to talk about these problems, we'll also give them names as we do with most problems Also, so that we don't always have to say this is Bob's problem and this is Carol's problem. What we will call Bob's problem is a problem named Clique because all of those vertices are very closely connected to each other just like in a clique of friends for example And we'll call Carol's problem independent set. Carol is basically looking for the opposite of a closely collected clique. Carol is looking for vertices that are not connected to each other. If those were friends, they wouldn't know of each other. Now, after Bob and Carol have explained their problems to each other and given them the name, they noticed since the only difference between clique and independent set is that in one we're looking for all vertices to be connected and on the other one we are looking for none of the vertices to be connected That problems are actually very, very closely related, and I will show you the idea that they come up with to figure out how similar these problems are. also from an algorithmic perspective. Let's try a graph here on this left side and then I'll have you figure out the largest possible clique that is in that network. It's going to be an easy example. Here you can check off these boxes and just make a check mark in each of the boxes that belong to the largest clique. The largest set of vertices that are all connected to each other. And it's easy to see that set is exactly 4 vertices, so it's this one here, this one here, this one and this one. We have 4 vertices that are all connected to each other. Now I'm going to draw a very similar--well, in a way very similar network for independent set. At least, I'm going to place the vertices at the same locations and we'll just how similar they are. And now, we're going to use similar quiz and this time, I would like you to check all vertices not that belong to the largest clique but to the largest independent set. Then you can make your check marks on each of the vertices that you think belong to the largest independent set. The solution here is that you can also find 4 vertices that form an independent set. This one here is rather obvious. You can also take this one in there, this one here. It's not connected to any of the other ones and this one here. Well, I've already placed the vertices in very similar locations, but as you can see, each vertex here has a corresponding vertex in the independent set, and of course, the way I've drawn this is not really by accident. There's a certain type of relationship between this network here and this network here. And to show you this relationship, I will do the following--for each of the edges that is blue over here I will draw in here and I will color them black and I'm going to do the same thing over here, so each edge that is blue over here I'm going to draw in black over here. Now, and I hope you can see it here even with my drawing that is not very similar, it turns out that this graph over here once I've added all the edges from this graph is the same as this graph here once I've added all the edges from that graph over here and this is exactly the connection between clique and independent set. If you have solved clique on a given graph, you take another graph where you draw exactly the opposite edges. Every pair of vertices that is connected by an edge in this network is not connected over here and vice versa but this means that finding the largest possible clique in one graph is basically the same as finding the largest possible independent set in the-- well you can call it an inversed graph where you connected exactly those vertices that where not connected over here and it's the same the other way around. If you have found an independent set in a graph that is as large as possible, then the same vertices will form a clique if you build the inverse graph. You connect all of the vertices that were not connected over here. This is actually a great news for Bob and for Carol because if Bob were to find a polynomial time algorithm for clique. If he were to determine that clique is tractable, then independent set would also be tractable because Carol could just take her network, build the inverse network, then have Bob solve clique on that network, take that same solution for her problem. Carol wanted to take independent set which she would basically do as she would start out with a graph then she would build the inverse graph and solve clique. That would give her the same solution as if she were looking for an independent set on the original graph. And it's the same for Bob here because if Carol finds a good algorithm for independent set, what he can do is he can take his graph, also build the inverse graph, and then solve independent set which means that either both clique and independent set are tractable or both of these problems are intractable but it cannot be the case that only one of them is tractable or intractable. Having figured this out, of course, Bob and Carol are both very, very happy-- not because they've actually solve their problem but now they know at least they can collaborate. They've basically double their chances, so if any one of them finds a bit algorithm for their problem, they will know they have a good polynomial time algorithm for both of their problems. Alice also arrives to the meeting, and of course, Alice is very excited to hear about their discovery that Bob and Carol have made. Alice, of course, is hoping that maybe she can also find a connection of her problem to Bob and Carol's problem or at least that they can help her find a good algorithm for her problem by brainstorming. Alice explains her problem using the graph terminology as well, so Alice's problem as you will remember is to find a set of vertices so that all of the edges are covered in a network here. For example if you take these three, then each edge has at least one endpoint in those set of green vertices here. The input for Alice's problem is again a graph with n vertices and the output is the smallest set of vertices such that all edges are covered, and of course, you know what I mean by covered. By covered I mean that each edge has at least one n point in the set of vertices. Then we should give that problem a name to refer to it such as Bob was working on clique and Carol was working on independent set. We have Alice working on her problem, and since she is using the vertices to cover the edges, we'll call her problem vertex cover. To see if the problem that Alice is working on where it takes cover has any relation to either clique or independent set, the first thing that we could do is just take the graphs where we previously solve clique and independent set on and find vertex covers for that. This is kind of a double quiz because I would like you to figure out the size of the smallest possible vertex cover for both this graph here and this graph over here. Please enter your answer for this graph over here in this box and your answer for this graph here in this box. And the solution that we hear is that you can do a vertex cover with just three vertices, so here's one example. You could select this one which would cover all of those edges here. Now we could select this one, covering all those edges. And, finally, we could select the one down here. So all edges are covered selecting just three vertices, and there are alternative solutions but none that contain less than three vertices. Now what about over here--here we can find a very small vertex cover using just two vertices. This vertex here, we just don't even need to care about because it has no edges that it's connected to. We can select this one here--it covers all of those edges. And we can select, for example, this one here. Or not only for example because this is actually the only possible smallest solution. So now we did this exercise to see if vertex cover could have any relation to clique or independent set. So let's have a look back at which vertices were contained in the largest possible clique in this network, and those were four vertices--it was this one here, this one here, this one, and this one. Not any really apparent relation between the two problems. This one over here, however, is more interesting because in the largest possible independent set, we had those four here. So it could seem like vertex cover--those two green vertices here-- is exactly the opposite of independent set, so if you have found the largest possible independent set, then you have found the smallest possible vertex cover. And, indeed, it's actually not that difficult to see that this is always the case. If you consider an independent set versus a vertex cover, what you have is the following. If you have the smallest possible vertex cover, that means you have selected a minimum number of vertices so that each edge is next to at least one of those vertices. If you were to remove those vertices from a graph, then no edges would remain because every edge is connected to at least one of those vertices of the vertex cover, so what remains is always an independent set. And since you've selected the smallest possible vertex cover, so the smallest number of vertices you need to remove, what remains must be the largest set or a largest set of independent vertices. And now that discovery is, of course, really great news for Alice, but it's also even better news for Carol whose smile gets a bit bigger, and, of course, also Bob because what they have now found out is this: clique and independent set are really closely connected. So if Bob discovers a good--or if any of them discovers a good algorithm for clique, then they have not only solved "clique" but also "independent set." So if just one of those two problems is solvable in polynomial time or, in other words, if just one of those two problems turns out to be tractable, then the other problem will be tractable as well. And now we have also connected vertex cover to independent set because we've basically figured out that finding the largest possible independent set for a graph is almost the same as looking for the smallest possible vertex cover. This also means that if you can find the smallest possible vertex cover, then you have found the largest possible independent set which we already know, through transforming the graph, lets you find the largest possible clique. So, actually, we can also draw this connection here because we already know about these two connections. What they have discovered is something that is commonly known as a reduction. And we'll get more deeply into that in the next unit. What a reduction is is basically a transformation between two problems so that if you find out that one of them is tractable, then the other one is tractable as well. So now the big question is, for clique, vertex cover, and independent set, are those three problems tractable--in which case Alice, Bob, and Carol would really keep smiling-- or will it turn out that all of these problems are intractable--in which case Bob, Alice, and Carol would tend to be rather unhappy? So which one is it going to be? Are all three going to end up very happy, are all three going to end up very sad, or is there maybe something in between? You can find out how that story continues in our next unit of our Introduction to Theoretical Computer Science. Plus, in the next unit, I will also tell you how you could quickly win a million dollars. Congratulation for completing Unit 1 of our introduction to theoretical computer science. We have introduced a lot of essential concepts and tools and you have managed to master them and now have them at your disposal. You know what a RAM. You know about O notation or big O notation. You know how to analyze algorithms and you've also learned to understand three very, very important problems in computer science known as clique, independent set and vertex cover. And while discussing these problems, you've also learned about the important concepts of polynomial time algorithms, exponential time algorithms, and the connected concepts of tractable problems and intractable problems. Having all of these concepts and tools at your disposal, you're ready to dive deeper into figuring out if we can make Alice, Bob and Carol happy by finding out that their problems are tractable or if we have to bring them bad news and show that their problems are intractable, but for now again congratulations. So welcome to Unit 2. In the last unit we encountered three computer scientists as I hope you'll remember, Alice, Bob, and Carol. And as you'll recall, all three were working on rather tough problems for which they weren't able to find an efficient algorithm. Alice was working in telecommunications, and her task was for the network of her employer to find the minimum number of monitoring devices that needed to be installed to monitor all cables in the telecommunications network. Bob was working in bioinformatics, and his job was to find clusters of data in genetic analysis. And finally, Carol was working in finance and she has been tasked with selecting a portfolio of assets that consists of as many assets as possible but it has to observe a number of restrictions, which assets she can put together in one portfolio. Now, at the end of the last unit, we stated these problems as problems on graphs and we're going to do a little recall quiz here to see if you remember which problems they were working on when we stated this as a graph problem. The three problems we're looking at were called independent set, clique, and vertex cover and all of those three problems took as input a graph with n vertices. For independent set, you were then looking for the maximum number of vertices where none of those vertices you have selected are connected to each other. For clique, you were looking for a maximum number of vertices where all of them are connected. And for vertex cover, we were looking for a minimum number of vertices to cover all edges meaning that every edge must have at least one endpoint in the set of vertices that we selected. So here's our first quiz and I would like to see if you remember which of these computer scientists, so Alice working in telecommunications, Bob working in bioinformatics, and Carol working in finance, which of these computer scientists were working on which of these problems here? And they way I want you to answer this is for each of the problems just select if that was the problem that Alice was working on, or the problem that Bob was working on, or the problem that Carol was working on. And the same here for clique and vertex cover. And the correct here is that Carol was working on independent sets because she had to find a number of investment opportunities that were independent of each other. Bob was working on clique because he was trying to find cluster of genes that are showing similar expression patterns or similar behaviors, and Alice finally was working on vertex cover because she was trying to find a way that her telecommunications company could monitor all of their network as efficiently as possible. The question that we are, for that matter, Alice, Bob, and Carol were stuck with at the end of the previous unit was that they had only been able to find exponential time algorithms for these 3 problems here, and those algorithms did not show any acceptable running time. So the question they were stuck with is, did they just not think hard enough to find good algorithms for their problems, or are their problems intractable, which would mean that it's not even possible or at least highly unlikely to find a polynomial time algorithm for those problems? And this is what we'll investigate further in this unit. And I'm not yet going to reveal the answer to you but what I am going to tell you is that without realizing it by asking this question, if their problems are tractable or intractable, Alice, Bob, and Carol are currently pondering what is by many seen as one of the toughest questions in computer science-- the famous P vs. NP problem. And in this unit, I want to show you 4 things. First, what these letters mean. Second, what the problem is actually all about. So what this here means. Third, what Alice, Bob, and Carol have actually to do with a P vs. NP problem. And then, last but not the least, how you could become an instant millionaire. That's not bad for one unit, is it? We're going to start off this unit with a small technical detail. When we considered our three problems, vertex cover, independent set, and clique, we always said that we were looking for the best possible solution. So, for example, for the largest independent set or the smallest vertex cover. This type of problem is known as an optimization problem because we're trying to maximize or minimize some value. In this unit, we're mostly going to work with a slightly different version of these problems called decision problems. So we're not going to ask, for example, what is the smallest possible vertex cover? But rather we're going to ask, does a graph have a vertex cover that is smaller than some number of k? And k is given to us in advance. So the main difference between an optimization problem and a decision problem is that for an optimization problem, we ask, find us the best possible solution? Or what's the best possible value that we can achieve? And in a decision problem, we have to ask, is it possible to achieve a value of k? And so up here the answer will be some number. And down here, the answer can only be yes or no. And there are two main reasons why we do this. First of all, it makes our lives much easier in some of the proofs that we're going to dive into. And secondly, it's also a little bit more accurate because when you talk about the P versus NP problem, although it's often stated for optimization problems such as those we have so far discussed, the whole theory has actually been developed for decision problems. Now, you're probably thinking what difference does it make to talk about an optimization problem versus a decision problem? Or is this going to make any significant difference, for example, with the question of tractability versus intractability and actually it doesn't really make that much of a difference, but I'll actually have you figure out the details here in our next quiz. And I would like you to think about four things and then give me your answer. So the first question is, if the optimization version of a problem turns out to be tractable, then what about the decision version of that problem? Do we know that decision versions for sure to be tractable, intractable, or can we really say? The second question I have for you is the same thing, only with intractability, so if we know the optimization version of a problem to be intractable, then what about the decision version, is that for sure, going to be tractable, intractable, or is this a case where we can't really make a clear statement having only this information here that the optimization version is intractable, and finally questions number 3 and 4 are exactly the other way around than questions 1 and 2, so here we have information about the decision version of a problem, so question number 3, if the decision version of a problem is tractable, then what about the optimization version? And question number 4, if the decision version of a problem is intractable, then what about the optimization version? So please give your answers here with one of each of the three possible choices here. The correct answer is, if we know the optimization version to be tractable, then the decision version is also tractable. If we know it to be intractable, then the decision version is also intractable. The same goes if we have the information about the decision version. You see, the tractability of an optimization version and of a decision version are closely related. Now, two of these answers I think are more obvious than two others ones. I think the answer to question #1 is rather obvious because if the optimization version is tractable so you can find the best possible solution in polynomial time, then with that solution you can also very easily answer a yes or no question about the solution. The same thing is true I think for answer #4 because if the decision version is intractable then the optimization version also has to be intractable or if you could easily solve the optimization version then it would also be easy to answer a yes or no question about the solution. The answers to question #2 and #3 I think are a little bit less obvious. If you know the optimization version to be intractable, then of course it could be the case that just having to say yes or no given the size of the solution that you're looking for could be easier, that could be tractable. So you would have to show in some way that if the decision version were tractable, then the optimization version would also be easy to solve, which is basically what I've asked you to think about in question #3 here. One way to show this is and this is not very precise but just to give you an idea here that if you have a tractable decision version then you could ask multiple questions about the solution and still remain in polynomial time. So for example if you're looking for the best possible solution for vertex cover, you could first ask the decision version say for n/2 as the value of k you're looking for and see if you can find a solution of this size. If that is the case, you can decrease k or if you cannot find a solution that is that small then you have to increase k and by solving the decision version often enough so searching for that optimum k you can also solve the optimization version. So this is not that obvious to see but for now you can keep in mind that optimization versions of a problem and decision versions of a problem behave more or less the same with respect to tractability or intractability. Now that we talked about the detail of optimization problems versus decision problems, we are ready to dive in. So how can we show that a problem is intractable? We already know how to show that a problem is tractable. We just have to find a polynomial time algorithm for it. But how do we find out if the problem is intractable? And there's actually two different ways we could go about this. The first way we could try to show intractability is by gathering evidence. What I mean by gathering evidence is this, we've already found out that Alice, Bob, and Carol were working on problems for which they weren't able to find a polynomial time algorithm, but all of their problems were connected, so if one of them managed to find a solution then all of their problems will be tractable, so one way we could be gathering evidence is if we just find more people working on more hard problems, and of course all of them are very smart people. If we could find more and more people who are also very smart working on very tough problems, but also no one of them finds a polynomial time algorithm. We could basically be saying, look, there are so many people who have looked at this problem, none of them has found out that the problem is tractable, so we think it must be intractable. Another way to go about this would be a mathematical proof. And what a mathematical proof would have to show is that no matter what kind of intricate, ingenious, sophisticated, complex algorithm we use for a problem, that algorithm will still need exponential time to solve the problem. So, what I would like you to think about for our next quiz is the advantages and disadvantages of each of these approaches here. And I would like you to think about two things. First of all, which of these approaches is probably easier to accomplish? And secondly, which of these two approaches here would you find more convincing to show that a problem is intractable? So please give me your two answers in these bubbles. The answer here, although it might be a little bit subjective, but I think it's rather objective actually is that in terms of difficulty, it's much easier to just gather evidence than accomplish a mathematical proof in my opinion. The reason for that is that in a mathematical proof you cannot only say well these 10 people or these 20 people haven't found a good algorithm for my problem, but you would really have to show that any algorithm that anybody could ever come up with would still require exponential time which does not allow you to give any examples or just state the number of algorithms, but you have to go about it in another way that is much more complicated as you'll also see in this unit. In terms of convincing this of course, the mathematical proof is more convincing than just gathering evidence because here we know that no matter what happens the problem is intractable whereas here we could just have another smart person coming in who finds a polynomial time algorithm and then it suddenly turns out that the problem is tractable. Now, before we continue, I would like to make one important point, and I don't know if this already occurred to you, but at least you might be inclined to think that it's rather obvious that the problem that Alice, Bob, and Carol are working on is intractable for one simple reason. Each of their problems has to look at an exponential number of solutions. For vertex cover, we have O(2^n) potential solutions that we have to look at because there are 2^n 0-1 assignments to the vertices for putting the vertices of a graph into a vertex cover. And the same thing is true for independent set and clique as we have seen in the last unit. Now, the question is does the fact that there is an exponential number of solutions already mean that the problem must be intractable. You could basically think this because having to consider an exponential number of solutions might mean that you have to look at each one of the solutions and that obviously is going to take exponential time. What I now want to show you is that this is not the correct intuition to have. Having many solutions does not mean that the problem is intractable. It can mean this, but it does not have to. To show you this, I'm going to give you one example where we have an exponential number of solutions but actually there is a polynomial time algorithm for our problem. What I would like you to tell me--in this graph here, how many different paths or how many different ways there are of getting from A to B if you cannot go backwards? You start out at A and once you've traveled across an edge you cannot go backwards. You always have to go forward, so how many ways are there to get from A to B? Of course this is a very simple warm up example. I'm going to draw a little arrows here just to make clear that we cannot go backwards. The answer here is, of course, that there's just two different ways to get from A to B-- either you go this way up here or you go this way down here. Now how about this little bit more complicated graph? Again, I would like you to figure out the number of paths or the number of different ways that you can take to get from A to B and the rules here are again the same-- you can only travel in this forward direction. I'm again going to draw the little arrows. So please enter your answer here into this box. The answer here is that there is actually four different ways of getting from A to B. This up here is the first one, then you could go this way, then you could go this way, or you can go this way, which is four in total. Now finally, I would like you to figure two more--this one down here and this one down here, and the rules again are the same. I'm not going to draw in the little errors just so that you can still see the image, but you still have to move in this direction here from A to B and the same down here. How many ways are their from A to B in this graph up here and how many ways are there to get from A to B in this graph down here. The answer is that up here there's 8 different possibilities and down here, there's 16 possibilities. Now, there's two ways to go about this. One is to just do the counting, which can get very tedious at least in the graph down here, or the other one is to figure out a general rule which could be quite helpful and that rule is that any time that you want to move forward you have two different choices that you can make. Once you start in A, there's two different choices. You can go either that way or that way. If your say in this vertex here, you have two choices. You can either stay up here or you can go down here. Likewise when you're down here, you can go either this way or that way. Each time you move forward, you can make one of two choices and since here, you can make one of two choices except for the last time. In the last move, you'll always have to end up at B, so here we have 1, 2, 3 times that we can make two choices and then we cannot make a choice here anymore. And 2³ is 8 and down here, it's basically the same thing. We just have one more of these layers here where we can make a choice and so that's going to be 2⁴ or 16. Now, let's try to find a general rule for the number of ways that you can get from A to B. The number of vertices in each of the graphs that I have drawn is 4, 6, 8 and 10. When we have four vertices, there are two different ways to get from A to B. When we have six, there are four different ways. When we have eight, there are eight different ways. And when we have 10 vertices, there are 16 different ways to get from A to B. Now my question to you is what if we had 20 vertices and please again give your answer down here in this box? The answer here is that there are 512 possibilities to get from A to B, and the way to figure this out is to notice that there's a general rule here. Each time that we add two vertices, the number of different ways that you can use to get from A to B doubles. We add 2 here, the number of ways to get from A to B multiplies by 2. We add 2 here and the number multiplies by 2 and so on and so on. To get from 10 to 20, we have to add two vertices 5 times, so we already know that there are 16 ways to get from A to B if we have 10 vertices. For 20 vertices, we add 2 five times, which means we multiply by 2 five times and that turns out to be 512. If you play around with this a little bit further, you can figure out a general rule here, and the general rule is that if you have n vertices then the number of different paths from A to B is two to the power of n half minus one. And the way you can see that this formula is correct is you can plug in the four here so it's four over two which is two minus one and 2¹ that is two. And in the quiz, we just saw that each time we add two vertices here, we have to multiply by 2, and this is exactly what happens here because if we add two vertices here then the exponent here will increase by one. And in this way, you can work your way up to larger and larger networks of this structure. So what you can see here is that the number of ways to get from A to B grows exponentially as these graphs here get more and more vertices. And I'm now going to ask in algorithmic question, and the algorithmic question is a very simple one and that is what is the fastest way to get from A to B or the shortest way to get from A to B. And if you have had an algorithm's class, you might know that this is a problem that can be solved in polynomial time. So there are many algorithms actually that can figure out in polynomial time. What the shortest way is to get from A to B? But this means that having many possible solutions cannot mean intractability because here's the case where we do have many possible solutions. There are exponentially many ways to get from A to B, but if we ask an algorithm to figure out the shortest one for us, it does obviously not have to consider an exponential number of solutions to come up with the answer because, otherwise, there would be no polynomial time algorithm to figure out shortest paths between two points A and B. And so for vertex cover, clique, and independent set, this means that if we want to show these problems to be intractable, it's not enough to point out that there's an exponential number of solutions because that does not mean that there can't be no polynomial time algorithm. So since finding a mathematical proof for showing the intractability of the problems that Alice, Bob, and Carol are working on seems to be rather hard, we're first going to start with gathering evidence that their problems might be intractable. Of course, we don't yet really know if their problems really are intractable because as we have just seen there are also arguments why their problems could actually be tractable because just having an exponential number of solutions does not necessarily mean that their problems are difficult but we're going to see how it turns out. So how can we gather evidence that the problems of Alice, Bob, and Carol could be intractable? One way could be what we have done in the last unit and that is if you recall in the last unit we showed that all of these three problems are either tractable or intractable. So one way to gather evidence that they are intractable is to find more and more problems for which we also don't know polynomial time algorithms and connect them to the problems that we know. So if we had this huge network of problems but we say if we find a polynomial time algorithm for just one of them, all of them would be solvable in polynomial time but nobody has yet found such an algorithm that would already be rather strong evidence that also clique, vertex cover, and independent set might be hard. So we might, for example, end up with thousands of highly relevant problems for which no one has so far found a polynomial time algorithm and if they're all connected that would be not a mathematical proof but it would be a somewhat convincing body of evidence for these problems' hardness. And in fact, I will introduce you to such a collection of problems at the end of this unit and we'll also have a closer look in the next units. But today actually, we're going to do something that is a little bolder. We're still not going to be able to achieve a mathematical proof of intractability but we're going to do something that I would say is somewhere in between gathering evidence and a mathematic proof. And the way we're going to do this is as follows. I'm going to introduce to you a type of computer that is extremely powerful. So powerful in fact that no one has ever conceived if it could actually be built. And then what I'll show you is that if there was a polynomial time algorithm for vertex cover or clique or independent set, that would be like having a blueprint for this super powerful computer. We won't be able to show that it's imposible to build such a computer, but it is pretty good evidence that those three problems up here are very tough problems to solve. So what makes this computer that I'm about to introduce to you so powerful? Well, roughly speaking, it's so powerful because it has the capability to guess things for us and it will guess them correctly but you're going to see in a minute what I mean by that. First of all, let's have a look once more at the three problems: click, vertex cover, and independent set. And have a look at how a machine that would be capable of guessing things for us could potentially make the solution to these problems very easy. And we're going to do this as a quiz and what I would like you to think about is what the three problems we have been talking about so far have in common. And I'm going to give you a number of choices and I would like you to tell me which ones of these you think are true and there can be more than one. So there's four possible choices here and again more than one of these can be true. So what do all of these three problems up here have in common? Choice #1, we have not found a polynomial time algorithm for them yet. Choice #2, they are not practically relevant. Choice #3, the simple algorithms that we have found so far go through an exponential number of solutions. And finally, for the simple algorithms, for any given 0 and 1 assignment to the vertices so we have already assigned the values of 0 and 1 to them, it is relatively easy to figure out if that assignment is a valid solution. And if it is a valid solution, how large that solution is? So please check all of these that are correct. So the first one is obviously correct. So far, we have not found a polynomial time algorithm for the three problems here. We've shown in the last unit that they are practically relevant or at least slightly simplified versions of highly relevant problems. All of the simple problems go through an exponential number of solutions. That's what made all of those simple algorithm so bad and their running time-- all led to the exponential running time, but the thing is going through that exponential number of 0-1 assignments is also what made those problems hard to solve. If you have given a certain assignment, checking if that is valid and how large it is-- for example, if it's better than a solution you have found so far--that is relatively easy. It's doable in polynomial time. Now, the answers to this quiz might seem rather obvious to you and you might be wondering what we're going to do with those answers, but I promise you it will all make sense very soon. So in the last unit, we talked about the simple algorithms for our three problems that have to go through an exponential number of solutions to try all possible assignments of 0 and 1 to the vertices. And now I haven't told you yet what this super powerful computer down here in the left corner is actually capable of and the ability that this computer here has is that it can help us figure out the best possible 0 and 1 assignment to the vertices without actually going through them. And the way this computer can help us is that it has a special instruction that a normal computer or even the RAM model does not have and that instruction is called if-better. And I'm going to explain to you in a second what that means. So the if-better function basically works like a normal if-else instruction on the RAM. So the normal if-else instruction is if this part here which I haven't specified yet is true then this part of the code not yet written is executed and otherwise this part down here is executed. The second property is that calling the if-better function will cost us polynomial time. So a normal if-else on the RAM just costs one time step or constant time and calling this function here will cost polynomial time. And now here comes the special property of this function. Normally when you have an if, you would have to specify some condition here so that if the condition is satisfied this part of the code is executed. And if it's not satisfied, then this part here is executed. Now the if-better is a function that will figure out by itself if it's better for us, and I'm going to show you in a minute what I mean by that, if it's better for us to execute this part up here or this part down here. It will always, if you will, guess correctly which part of the code to execute. Now, the first time you hear this, it takes a bit getting used to. So let me give you one example for our vertex cover how we could use this powerful function to solve vertex cover almost trivially. So we're working with the decision version of vertex cover here. So as an input, we're giving a graph G with n vertices and an integer k. And the output is "yes" if G has a vertex cover of size at most k and "no" otherwise. So the first time you see this kind of use of the if-better function it might still seem a bit strange to you so I'm going to explain to you what it does and how we're using it here. We're using this if-better function to guess for us which vertices to put into the vertex cover and which vertices we can leave out. Then we check if the assignment is valid although actually we wouldn't have to do that but I'll get into that in a minute and if the size of the assignment that we have found is at most k we say "yes, the graph has a vertex cover of size at most k and no otherwise." So as you can see, we're putting a lot of trust into this part here of the function because we're basically trusting the if-better to tell us correctly whether we should put a vertex into the vertex cover or whether we shouldn't do that. And that is why I basically said that the computer that has this function available is extremely powerful because if you can trust the if-better to do exactly what we want for us which is guess the best possible assignment then of course this significantly changes the running time of the algorithm here. So let's do a little quiz--what is the running time of this algorithm here for a graph with n vertices if we can trust the if-better function to perform as specified and guess the best possible assignment of 0s and 1s to the vertices. And the solution here is if we have the if<u>better function available, then we can solve</u> vertex cover in polynomial time because as we said the if<u>better function works in polynomial time</u> and we're calling it once for each vertex in the graph. So we're calling it n times it works in polynomial time so this part here of finding the best possible assignment of theirs and once to the vertices that works in polynomial time. And as you know from before, checking if an assignment is valid and checking the size of an assignment that's also doable in polynomial time. So the total running time of the algorithm is polynomial in n the number of vertices, and the right thing is that, although you shouldn't probably anthropomorphise this, the if<u>better function always knows what will help us.</u> So if we were trying to solve clique or independent set instead of vertex cover, the if<u>better function would somehow know this and give us a different assignment</u> of 0s and 1s to the vertices, which would however still be guaranteed to be optimal, and that is what make this function so extremely powerful. So now with that kind of magic function if-better we could solve all the three problems we have looked at so far in polynomial time. We could solve vertex cover, we could solve independent set, and we could solve clique in polynomial time. Now theoretical computer scientists like to divide problems into so-called complexity classes. And a complexity class basically contains all problems that can be solved on a given machine within a specified time or a specified memory or even both. But we're going to stick with time for now. So if we draw this as a matrix and put time here and the machine here then so far we learned about two different types of time. We have learned about polynomial time and we have learned about exponential time, and we have the normal RAM, the model that has basically the same capabilities as any computer that you know, and we have just learned about the RAM that has the if-better function available. Each of these fields here in the matrix is a complexity class. So this field here, for example, would contain all problems that can be solved in exponential time on a normal RAM. So vertex cover, independent set, and clique would all be contained in this class. But of course they can also be contained in other classes and I would actually like you to figure this out as our next quiz and the question is, in which other complexity classes, so this one here, this one here, or this one here, can we put our three problems vertex cover, independent set, and clique? And I would like you to make a check mark if you're sure that we can put these problems into that complexity class. If you're sure that we cannot do that or if we're not certain, I want you to leave that field blank. And the answer here is as follows--so first of all, it's important to notice that a RAM that has the if-better function available is at least as powerful as a normal RAM because all we're adding is this additional instruction but we can still do anything that we could do before. So this here is clearly a check mark. Vertex cover, independent set, and clique would be solvable in exponential time. Also, if we have this if-better function available. And the second thing is that in the well sort of programming example that we just had we also saw that the if-better function is so powerful that it will allow us to solve vertex cover, independent set, and clique in polynomial time if we have the if-better function available. And of course this one down here, that unfortunately has to stay blank but not because we're sure that these problems, vertex cover, independent set, and clique don't have a polynomial time algorithm but simply because we don't really know yet. We will come back to this matrix picture here in a minute. But let's turn our attention back to the RAM machine for a moment now. So, by now, we know two types of RAM machine. The first one here on the left is the one that we introduced in the first unit and it does not allow to use the if-better function. So, this is something that is although as we discussed it has some differences to your standard computer. It is more or less close to your normal computer. And here on the right side, we have the RAM with the if-better function and this of course is a much more powerful machine so as you can see it is buzzing with computational power here and this is totally unlike your standard computer because it has this guessing function about n and of course, if somebody asked us to build this sort of RAM machine at least I would turn them down immediately because it's not clear at all how we should write such a function. It seems far too powerful and at least to me frankly also a bit mysterious. So, that's also basically the difference between the two machines because here on the standard RAM, it's very clear what each of the functions that it has does. Actually, if you know what the machine is currently doing then you can always predict what it will do next because for every instruction it's very clear what it does given certain variables or inputs and not so with the RAM that uses if-better function above. Actually, most of the time unless this function is use, it's still clear what happens next but every time this function here is called, we don't really know what's going to happen next. It seems as if only this function here kind of knows. Or if you put it in another way, if you go through an algorithm that is written on a standard RAM then you can basically go through it step by step by step by hand and say how its going to behave. For this RAM over here, you could also go through it step, by step, by step but once you encounter this if-better function here, you could not really say what its going to do next. You would have to try different cases and so in order to better distinguish those two models, there is a special terminology in theoretical computer science called determinism and non-determinism. And this standard RAM machine because we always know what's going to happen next is called deterministic and surprise this one over here is called non-deterministic. Now, it's very important that you familiarize yourself with those two terms because we're going to use them a lot in this course, and just to make you think about them a little bit more, I would like to do a little quiz with you. So, what I would like you to think about is, if you're using the if-better function in a program and we run the same program code multiple times, can we get different solutions if we're running it on the same input or will we always get the same solution? So if you think that non-determinism can produce different solutions on the same input using the same code then please check yes, otherwise, check no. And the answer here is no. So a non-deterministic RAM. If it's running the same cod on the same input, it will always return the same solution because this if better function here, although we don't know what it's going to do. It still behaves in a consistent way and this is actually quite important because non-determinism is not the same thing as randomness. As you have seen, non-determinism is pretty powerful, so the question is, of course, could we actually build a non-deterministic RAM? And as I told you before, I have no idea how you would do that, so if somebody ask me to build a non-deterministic RAM, I would turn them down although if you could build one of these, you would certainly become quite rich and famous. The next best thing we can do to building a non-deterministic RAM though is simulating one. And of course you will be asking yourself, well, if he doesn't know how to build a non-deterministic RAM, how is he going to simulate one? Well, the answer is actually not that difficult but I'll have to warn you because the simulation will not be very satisfying or at least will have to pay quite a steep price for the simulation. So the first thing we should probably talk about when we want to simulate a non-deterministic RAM on a deterministic RAM is how would we simulate a deterministic RAM on a deterministic RAM? So basically, a picture like this, you have a deterministic RAM and of course, it's branded as a deterministic RAM and on that machine, you do a simulation of another deterministic RAM and this might look a little bit more complicated than it actually is. So, all it means is that if you have a program code that you run on a deterministic RAM, instead of running this code directly, you have another program and this program is basically going through your code and simulating what your code is doing. And this program here which would be the simulator is basically looking at the code and simulating what this code would actually do. Without running it directly on the machine, so it's running indirectly on this machine here. Another way you can look at the simulation is this diagram here, so you start out with a certain program that you want to simulate and of course you also start out not only with the program but also with a memory of that RAM and if you remember in the last unit, we said that the RAM had actually different kinds of memory, some memory for the input, some for the output, and so on but we'll just draw this as a single memory here. So, we start out at the first line of code and then because it's a deterministic RAM, that line of code specifies exactly what's going to happen next, so it specifies certain modifications that we make to the memory, so we might change this variable here or even change two variables although this is not often going to happen in one single line of code, but we make some modifications to the memory and we're still in the first line of code here, then, we're going to check if that line here actually is a statement that tells us that we are done. If that is the case, then the simulation would also be done, but let's say that this is not the case. We can then go to the next line of code in our simulation and again that line will also specify some other things that we are to do, so most of the time it's going to be again changing variables, maybe it's reading the variable, but let's say it's also changing additional variables, so we check again if we're done, we go to the next line of code and so on, until we're done. And the reason why this simulation works and it actually works rather efficiently I would say, is a determinism means that each line of code specifies exactly what's going to happen next. Now for our next quiz, I would like you to think a little bit about the cost of this simulation or the properties of this simulation, so I would like you to tell me if instead of executing a program directly or running it directly on a machine, we do a simulation of that code. What are the properties of that simulation? In other words, what does it caused us to do such a simulation? Obviously, it will take longer because we are wrapping some other code around the original program, but how much longer does it take? Does it take longer by a polynomial time factor and by a polynomial time factor, I mean, if for example, the original algorithm would run in O(n²) time, or O(n⁴) time, something like that. Does it take longer exponentially, maybe, so if the original run in O(n²) time, we would now run and say (2^n) time or (2^n) times and square time, and finally, if this sort of simulation robust, so will it always give us the same result that the original program would have given us, or is there a possibility that such a simulation can make a mistake? And there are two correct answers here. The first one is the simulation takes longer by a polynomial time factor. Now, it's a bit difficult if you wanted to specify exactly how much longer a simulation like this takes. In my point of view, you would not even take polynomially longer but only a constant factor, but polynomial is safe enough because in this course we're mostly differentiating between polynomial and exponential running time. Now, the reason why it only takes polynomial time longer is that, as I said before, once we're in the certain line of code, this line of code specifies exactly what is going to happen next. So it's mostly an overhead of simulating what this line here of code does, but as we said when we specify the RAM model, each line here is a simple operations, so it takes constant amount of time on the RAM. I think it's fair to say that it will only take polynomially more time if you simulate what it does. It doesn't do anything really complex. So the second answer here is wrong. The simulation is also always correct because there's no involvement of randomness or guessing and such. So if the simulator is programmed correctly, we will always get the same result that we would have originally gotten. It only takes longer time. So, how can we now simulate a non-deterministic RAM on a RAM? Because that is what we originally set out to do and it turns out, it's actually not that difficult once we have our deterministic RAM simulator because what happens if you're in a given line or code? There's two different things that can happen, one it's a normal instruction such as one you would find on a deterministic RAM and in this case, the simulator can just go on running the same way that it would have gone for the deterministic RAM. The only difference is if the simulator encounters this, if better, here then it has a problem because then simulating what this line of code does is not straight forward anymore. The if better might execute the first part of the code or the second part of the code around which it has written, so we have to work a little bit on this part here of the simulation. So, we have to distinguish two cases. One is if we have a normal instruction, then we'll just do a simulation, but if we have an if better, then we don't know how the machine continues so what our simulator would then do, is it will branch into two different possibilities. So it will start two new simulations. In one simulation, it will continue assuming the if better function executes the first part of the code, so the one that came directly after the if better. And then the other case, it will continue assuming that the if better function executes the second part of the code, so the part that comes after the else statement. And of course, once you have this branching, you don't have one single simulation anymore, but you have to continue with two simulations. One simulation makes this assumption here, the other one makes this assumption down here. And if you now encounter the if better statement, then again, you will have to branch into two possibilities up here and the same thing down here. If you continue the simulation with the assumption what happened the first time you encountered the if better function, and now you go on, then again, if you find, if better, again you will have to split into two different possibilities. And of course, running a simulation this way where you have to split into two possibilities all the time comes at a price which I'm sure you can figure out by now. And my question to you is, if we have a program that uses the if better function, and times, how many simulations or how many different simulations do we end up running? Is it n simulations, is it n² simulations, is it 2^n simulations, or something else? And the answer here is that we end up with 2^n simulations, because each time that we encounter if-better we have to split into two possibilities and then the next time, we encounter if-better we have to split each one of those two possibilities into two possibilities each and so we end up with an exponential growth. And that is why I told you in the beginning that simulating a non-deterministic RAM on a deterministic RAM is possible, but it's a very unsatisfying simulation because we pay for it with exponential time and what that means is, for example, for vertex cover, yes, we can solve vertex cover on a non-deterministic RAM in polynomial time. But if we do the stimulation of that non-deterministic code, we end up with exponential time again. Now of course the question would be, could you simulate a non-deterministic RAM more efficiently? For example, only using a polynomial number of simulations. So, in a way we're back where we started. We found out that we can not simulate a non-deterministic RAM, but that's going to take us exponential time. So the question remains, is there a better way to simulate non-determinism ideally with polynomial time or does simulating non-determinism on a deterministic RAM always lead to exponential time? So remember the 2 by 2 matrix that we drew a while ago. We'll now have a closer look at this matrix as promised. So what we just found out by the way is that this part here anything you can do on a non-deterministic RAM in polynomial time can also be one on a deterministic RAM in exponential time. So any problem that is in this part down here would also be in this part up here. But since we are mainly interested in polynomial time, let's focus on the bottom part of this matrix for now. You'll come back to the full matrix in later units when we talked about exponential time complexity classes and remember that each of these squares contains all of the problems that can be solved in polynomial time. The left one on a deterministic RAM, and the right one on a non-deterministic RAM, and now, we'll give these names. So we'll call this complexity class here P, because those are all problems that are solvable in polynomial time on a deterministic RAM. And we'll call this here NP, because those are all problems solvable in polynomial time on a non-deterministic RAM. Of course, it wouldn't have been more consistent to call this one down here DP or something like that, but this is the way we named it. And now, what we also know is that any problem that can be solved in polynomial time on a deterministic RAM can also be solved in polynomial time on a non-deterministic RAM. We should probably rather redraw these black lines here like this because any problem that is contained in P is automatically also contained in NP but of course not vice versa. Otherwise, we would know that there is a polynomial time algorithm for vertex cover and the two other problems. So P contains all the problems that we know are easy. So, for example, finding the shortest path between two points in the graph or looking up an entry in the database multiplying two numbers and thousands of problems more. So basically, any algorithm you'll have come across in an introductory algorithm scores will fall into this category. And again, there are some theoretical nitty-gritty regarding optimization and decision problems here, but we can ignore that for the time being. So let's do a little quiz to summarize what you know by now. So given all you have learned, what can you say about P and NP? So I would like you to check which of these statements are true. The first statement is every problem in P is also contained in NP. The second statement is that every problem in NP is also contained in P. The third one is that P and NP are in fact equivalent. The fourth one is that it seems like NP should contain more problems than P or be larger than P, but we can't really say for sure. The fifth one is that vertex cover, independent set, and clique are contained in P. And the finally one is that those three problems are contained in NP. So please check every statement which given what we know by now you should consider to be true. I think there are three statements where we can certainly say by now that they are true. We know that every problem that is in P is also contained in NP. This is why we drew the picture like this. So, that's obvious. If every problem in NP is also contained in P that would mean that we have a polynomial time algorithm for vertex cover, independent set, and clique. We do not know that to be true yet. Of course, we also don't know it to be false, but it's not something we can make a statement about. And since we can't make a statement about this here, we can also not to say that P and NP are equivalent or basically the same. Now, the fourth one is probably the most subjective one so of course it seems like NP should contain more problems than P simply for the reason that non-determinism is just so powerful that we would not expect that every problem that can be solved in polynomial time using non-determinism can also be solved in polynomial time on a deterministic RAM if you just think about how much time our simulation took and of course it might not be the best possible simulation but I think it's highly unlikely. We can't be sure, but that's why I wrote here it seems like NP should contain more problems and not stated it as a fact so that I can make a check mark here. Now, finally, vertex cover, independent set, and clique, if we knew that they were in P we would have a polynomial time algorithm. Can't really make that statement right now. And finally, vertex cover, independent set, and clique, yes they are in NP. We show that they can be solved in polynomial time if we have the wonderful and magic if better function available. So, let's say we have a problem that we know to be an NP but we're not sure if it is contained in P or not. In that case, there is actually only two things that could be true so either that problem is actually NP but we missed it so we simply haven't looked hard enough to find a good algorithm for it or that's the other possibility the problem is only contained in NP. So, no matter how hard we look, we will never find a polynomial time algorithm for it. The cool thing is that for some problems we know that they are closely related enough so that it's actually sufficient to decide this question here if we missed a polynomial time algorithm or if we just have no chance. It's actually sufficient to decide this question for only one of the problems. So for vertex cover, independent set, and clique, in the last unit, we found out that those problems were closely related. So, let's just do a little quiz to see if you remember how these problems were related to each other. So, let's assume we found a polynomial time algorithm for vertex cover. In that case, we would know for sure that vertex cover is contained in P. So what will be the case for independent set and clique? Would we also know these problems to be in P or would it not be possible to make such a statement? And the answer here, of course, is that if we had a polynomial time algorithm for vertex cover, then as we saw in the last unit we would also have a polynomial time algorithm for independent set and we would have one for clique because as we found out solving vertex cover on a graph is basically the same problem as solving independent set. And if you have a good algorithm or a polynomial time algorithm for independent set, then through an easy transformation of the graph you can also solve clique. So our three problems are so closely related that either all of them lie here in NP but not in P or all of them lie in P. We don't know which one it is but it can't be the case that, for example, we have just vertex cover in P and the other two problems here in NP. And how did we show that in the last unit? For clique and independent set, we showed that there was a polynomial time algorithm that could take a graph that was an input to independent set and transform that into a graph that we can use as an input for clique, and once we have solved the clique problem on the transformed graph, that same solution is also the best possible solution to independent set. So we have a polynomial time algorithm, so the algorithm transforms the input of one problem, say X, into an input of another problem, Y. So, for example, we take independent set and transform that graph into an input for clique and now you'll see one of the advantages of working with decision problems because the third condition is rather easy to state because we can now simply say that solving the problem Y on the transformed input yields the same answer as solving the original problem on the original input. So these three statements here are the same thing that you have seen in the last unit. So, we took an input which was a graph to independent set then transformed it into an input for clique and we found out that if we solve clique on that new input, then we would get the same answer that we would've gotten if we had solved independent set directly on the original input. And of course we also saw that the transformation works in the other way, so we could transform an input to clique into an input of independent set and now for a vertex cover and independent set, it was even easier because we didn't even have to transform the input, so basically the transformation was, we could keep the input as it is, the only thing is if we're working with the decision problem, of course, the answer will be a little bit different, so if we have a vertex cover of size k for a graph with N vertices, then for independent set, we must ask if we have an independent set of size n-k. But other than that, the transformation here is very easy. And this concept here of taking an input and transforming it in polynomial time into a new input for another problem so that you get the same solution is known as a polynomial time reduction. And if you want to be precise about what you're applying this reduction to, you can say that you have a polynomial time reduction from X to Y, so in other words, you can take a problem X and show that problem Y is powerful enough to solve problem X. So in order to help you wrap your head a little bit more around polynomial time reductions, we'll do a little quiz here. So I would like you to think about if we manage to reduce a problem X to another problem Y, what does that imply? And I'm going to give you 4 choices here, and I know it's easy to guess which one of those are correct, but you should really give this some thought first to make sure that you understand the concept of reductions because this is going to play a very important role in this unit and also in the next units. So I'll give you 4 choices here. Does reducing a problem X to a problem Y imply that: X is at least as hard to solve as Y, and by hardness, I mean the distinction between polynomial time and exponential time. So in this case here for example, if Y is only solvable in exponential time, does that mean that X can only be solved in exponential time as well or is it other way around? Does it imply that Y is at least as hard to solve as X? Does it mean that if X can be solved for the polynomial time, then so can Y or does it mean that if Y can be solved for the polynimial time, then so can X? So please check all of the answers here that are correct. And there are two correct answers here and that is the second answer and the fourth answer. And the reason for that is as follows. If you managed to have a polynomial time reduction from a problem X to a problem Y, that means that you can take any input to the problem X and then use Y to solve it. What it does not mean is that you can take very input for Y and use X to solve it. The reduction is only one way. But that means if you managed to reduce the problem X to a problem Y, then solving Y must require at least as much effort or power as solving X. So that means that Y is at least as hard to solve as X and not the other way around as I just said. Now on the other hand, since Y is at least as hard to solve as X that means if you find a way to solve Y in polynomial time then of course you can also solve X in polynomial time because this reduction here takes polynomial time and then solving that problem would also take polynomial time. On the other hand, if you can solve X in polynomial time, so this problem here, that doesn't really mean anything for Y because as we just said Y is at least as hard to solve as X but it doesn't have the same hardness or is easier in any way. This implication here does not hold true and those two are the only ones that are true. Now if this quiz confused you a little bit, I find a good way to memorize this what the reduction from the X to Y means is that if you have a reduction from X to Y that basically means that this problem X here must be able to fit into the problem Y and that is why this problem Y here is in a way larger or harder to solve than X so you take this problem X and put it into Y that is what the polynomial time reduction can be pictured as and at least from me that's very helpful. And of course I do hope that it is for you as well. Now that you know about polynomial time reductions, imagine that we had one problem in NP such that every other problem that is also in NP could be reduced to it. We would have vertex cover which could be reduced to that problem, we would have independent set which could be reduced to that problem, and also clique, of course. And any other problem in NP as well. No matter how complicated that problem as long as it's NP that means a non-deterministic RAM you can solve it in polynomial time-- there exist a polynomial time reduction to this ultimate problem. And such a problem actually has a name, so if you could find a problem in NP such that any other problem in NP is just as hard to solve or easier to solve, then that problem is called NP complete because in a way it represents all of the problems in NP because if it's a problem that any other problem can be reduced to, an NP complete problem is basically capable of solving or representing all other problems that are contained in NP. An NP complete problem is contained in NP and the important part here is that really any other problem in NP can be reduced to it. Not just vertex cover, not just independent set, not just clique but any problem that lies in NP can be reduced to that problem. Let's have a little quiz to familiarize yourself with the concept of NP completeness. I have three statements here about NP complete problems and I would like you to tell me which one of these is true. There can be more than one. The first statement, well you might be tempted to think that because I just called it the ultimate problem in NP, but actually when you look at the definition of an NP complete problem-- it just means that any other problem in NP can be reduced to it. There could be multiple NP complete problems as long as they have the same hardness. This here is not true. If you found a polynomial time algorithm for an NP complete problem, then what that would mean is that there would also be polynomial time algorithms for all other problems in NP, and the reason for that is that for an NP complete problem, we have said that any other problem in NP can be reduced to it and that can be done in polynomial time. If you can solve this problem in polynomial time as well, then you automatically have a polynomial time algorithm for any problem that you can find in NP. And finally, if vertex cover would be an NP complete problem, then clique would be an NP complete problem as well because we have shown that you can use polynomial time reductions to get from vertex cover to clique and vice versa. From a perspective of polynomial time versus exponential time hardness, these two problems are basically equally hard to solve. This one here is also true. So let's say now that you have a problem that you know to be an NP such as vertex cover, and there's basically two ways that you could show this problem to be NP-complete. The first one is, you could take another NP-complete problem and reduce it to your new problem. A second way would be to use the definition that we just had of NP-completeness and show that this problem here can be used to solve any other problem that is also solvable in NP, and by showing, I mean proving. That is the first way, and the other way would be to just use the definition of NP-completeness that we just looked at, so what you could also do is you could show, or in this way you would have to prove mathematically, that any problem in NP can be reduced to your problem. And the emphasis here is on any problem, because otherwise, it wouldn't be NP-complete. And those are the two possible ways you could show NP-completeness. I will call this here approach number one and this one up here approach number two. Now if you look at those two approaches, this one here sounds much easier in a way than this one here, because here we just have one problem where we have to have a reduction, and here we have to have any problem. Not even some problems, not even a million problems, but really any problem. But there's a little problem with the first approach here, and I hope you can tell me what that is. So what could be potential issues with approach number one? Could it be that this only works for some problems in NP? Could it be that before we can do approach number one, we must first have had success with approach number two for at least one problem in NP? Or could it be that approach number one is not always correct? So please check all of these statements which you believe are true. And the answer here is that, well, this approach, number one, it in principle works for any problem in NP, so that is not the issue with this approach, and this approach is, of course, is also always correct because if you can show that you can reduce an NP-complete problem to another problem, that problem here becomes NP-complete as well. The issue is that it's a bit of a chick in an egg problem, because in order to be able to use this approach, you must first have an NP-complete problem, and unless you have one NP-complete problem, this approach here will fail, so you need a kind of seed problem that you show to be NP-complete using this approach here before you can use the more convenient approach down here. So unfortunately, while we would always like to work with approach number one, we can only do so if we have had success with approach number two at least once. So the big question is here, how on earth are we going to do this? Because this seems extremely difficult to show, so we would have to find a problem for which we can prove that any other problem in NP can be reduced to it. Luckily for us or actually more luckily for me, this work has already been done about 40 years ago by showing a problem called Boolean satisfiability, or SAT for short, to be NP-complete, and this result is one of the most famous results in theoretical computer science, which is why we're going to investigate it in detail and also investigate the proof together. The result is called the Cook-Levin theorem. This theorem is named after Stephen Cook and Leonid Levin who discovered it independently of each other in the 1970s, and by showing that, they provided exactly this NP-complete seed problem, namely SAT, which could then be used to show that a number of other problems are NP-complete as well. And I'm then going to show you how Cook and Levin proved that SAT is NP-complete, and once we have shown that SAT is NP-complete, we can go back to the problems of Alice, Bob, and Carol and see if those problems are NP-complete. Before we go deeper into the SAT problem and proving the Cook-Levin theorem, here's one more quiz to make sure that you understand where we are going with this. So once we have shown that the SAT problem is NP-complete, how would we then show, or at least try to show, that the vertex cover problem, independent set, and clique are NP-complete? Would we have to show that any input for SAT, and I'll soon tell you what that input exactly is, can be transformed into an input for one of these problems, and by these problems, I mean vertex cover, independent set, or clique, or would we have to show that one of the three problems up here can be expressed as an input to SAT? Or would we have to show that all three problems can be expressed as an input to SAT? So please check all of these which are correct. And this time we only have one correct answer, which is this one up here. So once we know that SAT is NP-complete and we wanted to show that those three problems, vertex cover, independent SET, and clique are NP-complete as well, we would have to show that if we take any input for SAT, then we can transform it into one of those three problems up here and then solve that. Because that shows us that in a way vertex cover or independent SET or clique are at least as hard to solve as SAT. And because SAT is NP-complete, if one of these problems is at least as hard to solve, then that problem must be NP-complete as well. These two down here are the wrong way around because SAT is NP-complete, which means that this is one of the hardest problems that you will find in NP, so just showing that for example, you could take vertex cover and transform it into an input for SAT would only show you that SAT is at least as hard to solve as vertex cover, but that is the wrong way around, because we want to show that vertex cover is at least as hard to solve as SAT, so those two answers down here are not correct. So what is this mysterious SAT problem? So SAT stands for Boolean satisfiability, of course, that also doesn't tell you very much, but I'll soon get into what Boolean satisfiability is. You have to just note that SAT is one of the most famous and most studied problems in theoretical computer science, and it's the bases of many marked results, so it's always a good idea to familiarize yourself with what SAT is about and why SAT can be so hard to solve. So what is the Boolean satisfiability problem? The input for SAT is a so called Boolean formula, and that actually sounds much more intimidating than it is because Boolean formulas are very simple structures. They consist of only 4 building blocks. As any kind of formula, we have variables, and those variables I'll write in this course usually as X1, X2, X3, and so on. And the nice thing about these variables is so in a normal formula whenever you have X that can take a number of different values, but in a Boolean formula, a variable X can only take 2 different values. It can either be true, which is sometimes also written as a 1 or it can be false, which is sometimes also written as a 0. The second thing you can have in a Boolean formula is an operator called not. And how you write that is, if you say, have a variable X1, then this here would be not X1 or if you have X2, this here would be not X2, and what the not does is it turns a true into a false, and vice versus, so it also turns a false into a true. So for example, if X1 equals true, then not X1 equals false. So it basically just flips that variable. Then you have another operator, and that one is called and. And this and is usually written like this, and it works on 2 variables, so you have X1 and X2 or any other variable. And the way it works is that this expression here, X1 and X2 is true only if X1 is true and X2 is true. Otherwise, it's always false. So I'm going to write this as 1s and 0s here just to make it a bit shorter, but you know that 1 stands for true and 0 stands for false, so it's the same. So 0 and 0 equals 0, 0 and 1 equals 0, 1 and 0 equals 0, and only 1 and 1 equals 1. And the final component of a Boolean formula is another operator called or, and or is written just the other way around, so it's written like a flipped and. So it's X1 or X2, and as the name already suggests, that is set to true or set to 1 if at least 1 of these variables here is set to true, so 0 or 0, that will still be 0, but 0 or 1 will be 1, 1 or 0 will be 1, and 1 or 1 is also going to evaluate to 1. So let's practice this in a little quiz. Let's say you have the following Boolean formula. X1 or not X2 or X3 and not X1 or X2, and we're going to have that X1 is equal to true or 1, X2 is equal to true, and X3 is also set to true or 1. Is this whole formula equal to true or is it equal to false? So please select this button here if you think the whole formula is equal to false or 0, and please select this one here if the whole formula is equal to true or 1. So the answer here is 1 or true, and you can see that as follows: So X1 is equal to 1, not X2 is equal to 0, so 1 or 0 is equal to 1, so this whole part here is equal to 1, and actually X3 is also equal to 1. So we have that this whole part here is equal to 1, X3 is equal to 1, and 1 or 1 is 1 again, so this whole part here is equal to 1. And over here we have not X1, which is 0 or X2, but X2 is true or 1, and so the whole thing 0 or 1 is equal to 1, and so we have 1 and 1, which evaluates to 1. So now that you know about Boolean formulas, so what is the SAT problem? The SAT problem has as an input a Boolean formula with N variables, and I'm usually going to write them as X1, X2, and so on until you get to Xn, and the output or question since SAT is a decision problem is the following: And the question is, can you set the variables X1 to Xn to a combination of true or false so that the whole formula that you're given in the input becomes true? And the answer to that can, of course, only be yes or no, so again, SAT is a decision problem. So for example, if we're given a very simple Boolean formula such X1 and X2, and then the answer to SAT would be yes because you could set X1 to true and X2 to true, and then the whole formula would also evaluate to true because you have 1 and 1, which is true or 1. Let's do a little bit more challenging example. If you had a Boolean formula such as this, x1 and X2 or 1 and not X1 or X2, and what you can also see here is that you do not always have to put brackets around each or to signify in which order you evaluate the individual ones, so it's okay to write 2 or 3 or 4 or's or 2 or 3 or 4 and's or even more if you want to without doing those brackets. It really doesn't make a difference in the way that the formula evaluates. But let's come back to SAT. So does this Boolean formula here have a satisfying assignment, meaning can you set the variables to a combination of true and false so that the whole formula becomes true, and here the answer is again yes. X1, unfortunately, doesn't really help here. So if you set X1 to true for example, this would also be true. And here you have not X1, so X1 and not X1, that would evaluate to 0. If you set X1 to 0, then you have it the other way around, and then let's set X2 to 1 because then this whole thing here is 1, this stays at 0 no matter what we do, and this one also goes to 1, and then you have 1 or 0 or 1 so there's at least one 1 in here, and so the whole thing evaluates to 1, and the formula can be satisfied. So now let's see if you can figure out an even more challenging example yourself. So here's our Boolean formula, X1 or X3 and X1 and X2 or not X3, and the formula continues here, not X2 or not X3 and not X1 or not X2, and I'm going reveal to you that this formula indeed has an assignment of true and false to the variables X1, X2, and X3 so that the whole formula is satisfied, meaning it evaluates to true. What I want to know from you is how I have to set the variables to do this. So if I should set X1 to false, please check here. If I should set it to 2, please check here, and the same thing for the variables X2 and X3, please. And the answer here is that you should set X1 to true, X2 to false, and X3 to false, and the way to figure this out is, at least for me, it was the following: So you have to set X1 to true because otherwise this thing here will be false, and you see we have a number of N's, so if this evaluates to zero, the whole formula cannot be satisfied. So we already know this assignment here, which gives us a 1 here and a 0 here also. Now since we have a 0 here, we must make sure that not X2 evaluates to true, so we have to set it to false, and if we set it to false, we get a 1 here, get a 1 here, and a 0 here. And since this here has been set to 0, and again we need to make sure that these brackets evaluate to true. We also have to set X3 to false so that this here becomes a 1, which gives us a 1 here as well and a 0 here as well. And so for the whole thing, this here evaluates to 1, this here evaluates to 1 because this evaluates to 1, and this one here as well. This goes to 1, and this goes to 1 here as well. And so we have 1 and 1 and 1 and 1, which satisfies the whole formula. Now if you have paid attention so far, I hope you have noticed that I forgotten to mention one detail about the satisfiability problem so far, and I would like you to tell me what that is. So what do we still need to talk about? The length of the Boolean formula that we're given as an input to SAT? The number of variables or the number of times each variable occurs? So only one of them is true, and I would like you to check the one which is true. And the answer here is that we need to say something about the length of the formula, because as you know, we are measuring running time as a function of the size of the input. Now if you have N variables, I think it's very convenient to measure the running time as a function of N, but we can only do that if we know that the length of the formula is also some function of N or if the length of the formula is polynomial in N to be more precise. So just to be very precise, from now on we will always assume that the total length of this Boolean formula that we are given is polynomial in N, the number of variables. So now that you know what the SAT problem is, how do we actually show that SAT is NP-complete? So what was the main ideas that Cook and Levin used to prove this, because it still sounds quite difficult doesn't it? To show that SAT is NP-complete, what we basically have to show is that for any problem in NP there is a polynomial time reduction to SAT, and before we go into the details of this proof, I want to show you the 3 main ideas that are used to show this. So the first one is, well, it's not really an idea, it's the trivial definition of what it means that a problem lies in NP. If a problem lies in NP, that means it can be solved in polynomial time by a non-deterministic RAM. So why do we state this? Going back to the definition actually allows us to make a very useful observation, because if we can solve the problem in polynomial time on a non-deterministic RAM, then that means there must be some polynomial time algorithm. Of course, that algorithm is going to use if-better function because it's running on a non-deterministic RAM, but we know that if a problem is in NP, then even without explicitly having to come up with this algorithm, we know there must be one because otherwise this problem would not be in NP. Which brings us to the third point, and that is the main idea that Cook and Levin had, and that is instead of having to show that any problem in NP can be encoded as a Boolean formula, what they did is they showed that any algorithm can be encoded as a Boolean formula, because if you can show that, with certain constraints of course, but basically the idea is if you can show that any algorithm can be encoded as a Boolean formula, then you can also encode this polynomial time algorithm here as a Boolean formula, which can then be used to solve an NP-complete problem. So if you can encode any algorithm, then you can also encode any algorithm that will solve a problem in NP. And of course, we're going to go into the details, but that was their main observation. They showed that we should not look at the problems in NP, but we should actually look at the algorithms that solve those problems in NP, and we know there must always be such an algorithm because otherwise the problems wouldn’t be in NP. So how can we take an algorithm and put that into a Boolean formula? Well, that's where Cook and Levin had another ingenious idea, because they said you can look at an algorithm running on a RAM as a series of snapshots, and what I mean by this is the following: So assume you have an algorithm on a non-deterministic RAM that runs in polynomial time, so you have a point in time T equals 0, that's when your algorithm starts out, then you have T equals 1, T equals 2, so those are the time steps here. And the final time step is going to be some polynomial of N. That is clear because we're looking at an algorithm that solves a problem that lies in NP, So that means it only takes polynomial time on a non-deterministic RAM at least. Now if you look at what happens on the RAM in each time step, I can basically draw you the following picture. If you recall from unit one what the RAM looks like, the RAM has only a few components. The RAM has a read-only memory, the RAM has a program or the algorithm running, so this algorithm here is basically the program running, and just as I would write the algorithm line by line by line, I can also write it in this way, so this here would be the first line of code, then this would be the second line of code, and so on. And finally, the RAM had a reading and writing memory, so we had some memory cells here holding the variables, and those variables, of course, are changed by the program depending on what's here in the input. And now comes the neat part that Cook and Levin observed, because what they observed is that when you look at an algorithm working on the RAM, then you can depict that as a number of these snapshots, so if you say, add T equals 0, these are the contents of the read-only memory. This is, actually we need other information, we also needs to know where the program is at, but you can basically say, this is the input here, this is the program, and this is the line of the program that we're executing right now, and this here is the contents of the read/write memory. In the beginning this will be empty, but as the algorithm works, it will also put some content in here, and then, of course, the program moves on. It can also jump back and forth here, and of course, we will have more and more content in the memory, and at a certain point in time the program will say, I'm done, and it will hopefully have a certain output here. But since we're working with decision problems, actually it's only interesting to us if the program says, yes or no at the end. So for decision problems we don't even really care about what's in here, we would care about that if we were solving the optimization problem or want additional information, but actually for a decision problem, it would just be important for us to know at which line of code the algorithm finishes. If it finishes at a return statement that will return yes to us or a return statement that will return no to us. Now let's have a closer look at those snapshots, and we'll actually do that as a quiz. So this here is one snapshot. I would like you to tell me what we can say about a single snapshot and also about all of these snapshots here. So there are 3 statements, each of which I would like you to check this box if you think they are true and otherwise leave it blank. So the first claim you could make is that each snapshot has size polynomial in N, and N is the size of the input as always. Secondly, you could claim that there can be an exponential number of snapshots if we look at all of the time steps. And finally, one claim that I would like you to check out as well is all snapshots, if taken together, so this whole part here, have polynomial size, and by polynomial size, I again mean that it's some polynomial of the input size that we're always using. You should keep in mind that the algorithm that we're looking at is an algorithm for a problem in NP, and it runs on a non-deterministic RAM. So there's 2 true answers here, and I know this was a rather challenging question, but just imagine how challenging it must have been for Cook and Levin when they figured this out for the first time. So first of all, each snapshot has size polynomial and N. That is true, so why is that? Well, first of all, we said the size of the input is a polynomial of N or often times it is N, but sometimes it can also be a polynomial. So for example, when we are given a graph with N vertices, then there can be up to N squared edges, but in any case, the input is some polynomial of N. Now the size of the algorithm or program here, that is constant because the algorithm doesn't change with the input, so we can assume that this year has constant size no matter what kind of input we are given. And then finally, this is an interesting one, how much memory does our algorithm need? Well, it's an algorithm for a problem in NP, which means it takes only a polynomial number of time steps, and in each time step, it can only modify a constant amount of variables. So the total memory that it needs is some constant times the number of time steps, and since the number of time steps is a polynomial of N, the total space required here for the memory is also a polynomial of N. So you have a polynomial of N plus some constant plus a polynomial of N, so each single snapshot has size polynomial in N. Now the second one, I think that was the easiest one to find out, is of course not true because we said we're looking at a problem in NP, we should have even written it down here on the left side. So we said the number of time steps must be some polynomial, because otherwise, the problem wouldn't be an NP, and since we're running on a non-deterministic RAM, we can assume that the number of time steps here is bounded by some polynomial. So since there's only a polynomial number of time steps, there can also only be a polynomial number of snapshots, so there cannot be an exponential number of snapshots. But this, if you take it together, is-- well, I don't know it's pretty cool, but at least it's very useful for the proof that we're trying to do, because if each snapshot has a size that's polynomial in N and the total number of snapshots that we have is a polynomial, then you have a situation where you have a polynomial number of polynomial size snapshots, which means that the size of it all taken together is a polynomial times a polynomial, which again is a polynomial. So basically, a complete protocol of what this algorithm here is doing given this input and using this memory here, the complete protocol only takes up a polynomial amount of space. Polynomial and N, the size of the input. What I will now show you is how you can encode a single snapshot. So for example, this one here or this one here as a Boolean formula. To show you how we can encode a single single snap shot on the REM as a Boolean formula, I'm going to show you a little trick with the Boolean formula. So this Boolean formula-- it looks a bit intimidating, and it doesn't look fun. Well I'll just quickly explain it to you and then help you figure out the special property that it has. So the formula consists of 6 variables: X1, X2, X3 to X6 and it has 7 brackets, so as you can see, each of those brackets contains all of the 6 variables: X1, X2, X3, X4, X5, X6. Sometimes they're a bit mixed up, but every bracket here contains the 6 variables exactly once. They're all connected with an and here, and each one of them looks like this, so up here you have an or over all of those variables, and down here, each bracket has a very similar structure, so you have X1 or you have one of the variables and a not of that variable, or, and this is a very big not over off the other variables, and those are combined by or. Now probably it's a bit tough to figure out by yourself what the purpose of this formula is. I want you to figure it out, but I will give you a few choices. So what's special about this Boolean formula? Does it not have any satisfying assignment? Does it have several satisfying assignments? Can it only be satisfied if exactly one of those 6 variables is set to true, and finally, if you generalize this, so not 6 variables but any number n of variables, and then you do the same structure as you do here. That's the whole resulting formula, have size 0 (n squared) for n variables? So I think by now you're used to more than one of these answers can be true, so check all of these that are correct. And the answer here is not actually 3 of those statements, those 3 down here are correct. I'll explain them in a minute, and this one here is not correct. So the formula indeed does have a satisfying assignment. Not only one; it actually has several satisfying assignments, but each of those assignments has the property that exactly one variable is set to true, and I'll show you in a second how that works. And of course--I mean, the last thing was probably quite easy to figure out; as you see this already has kind of a square shape, so if we continue like this and add another variable here, then we would have to add another line down here, and each of those formulas grows by 1 and the whole thing grows by one of those brackets here for each variable that we add, so the size is O(n squared) for n variables. So let me explain this here to you. So there are several satisfying assignments, but each of those satisfying assignments has the property that exactly 1 variable is true. So for example, let's say that we set X1 to true, then what will happen is the following, so X1 is true; this means this one down here goes to 0. This one goes to 1, this one goes to 1, this one goes to 1, this one goes to 1, and this one is 1. So let's have a look here at this part of the formula. All of the variables here are connected by an or, so we have X1 or X3 or X4 or X5 or X6. This means if just one of the variables here is set to true, which it now is, then the whole bracket here, so from here to here will also evaluate to true, and then we take this very, very big not here, which means this will evaluate to 0. Now this very big not here evaluates to 0, then we have to make sure that this variable here evaluates to 1, because all of them are connected by an and, and we are looking for a satisfying assignment, so to do that, we have to set X2 to 0 so that this here evaluates to 1. Now for the next bracket, it works the same way, because again, we have X1 set to true, so the bracket evaluates to true, so the not evaluates to 0, and so again we have to set this to 1 which means X3 is 1 and we can go on through this the same way. So the formula forces us to set every variable except for X1 to false, and now the way that this formula is structured, of course, we could also have chosen to set X2 to true, but then if X2 is set to true, we have this here, so X2 here is 1, 1, 1, 1, which means in order to get these here to go to 1, so we need to have these here go to 1, because this here evaluates to 0, 0, 0, 0, 0, so we have to set all of these variables here to false. Yeah, finally, what about this one here? Well, since X2 is set to true, not X2 is set to false, but luckily, because we've set all of the variables to false, so we have 0, 0, 0, 0, 0. In this case, the large not here evaluates to true, so this bracket here also evaluates to true, and we have satisfied the Boolean formula. What this means is not for any given number of variables, we can write a Boolean formula that can be satisfied if and only if exactly what one of these variables is set to true, and we figure out that we can do this for any number of variables that we want. So now let's go back to snapshots and see what the Boolean formula that I just showed you has to do with these snapshots. Each snapshot, as we've said, basically consists of 3 components, so we have the read only number here, which is basically the input. We have program, and we have the read-write memory for immediate results and output. So now let's think back a moment of how we defined the RAM. When we defined the RAM in the last unit, what we said was the following. We said that whenever we're talking about memory, so this part here or this part here, then every single cell in the memory can not hold arbitrarily large variables, which means, for example, that this cell here could either be 0; it could be 1, it could be 2, and so on, but there's a certain limit of how large those values here can be, just as with your novel computer programs, too. They can carry very, very large numbers but there's a limit and that limit is some constant, so I'll just write c here, so if you have an 8-bit computer, that constant will be smaller, of course, than if you have a 16-bit computer and so on, but in any case, it will be some constant determined by the machine, and the same thing is going to be true all along the memory. So for each single memory cell that you have here, you have a constant number of possibilities for the values that this memory cell can take, so the size here is constant, and here, it's polynomial in n, as we figured out before. Now what about the program? So for the program, we said that, of course the size of the program of the algorithm does not change with the size of the input, so if you look at the program and your write it as we said, we've written the code from left to right, but normally, you'll write it from top to bottom, so if you took this code and wrote it like this, then you would have a constant number of lines in your program and that would be a certain position on where you are, so again here, there's a constant number of potential positions where you can be in the code, and of course, you just have one code, so there's no polynomial size here. It's just a constant number of code lines. And finally, over here fr the input; of course this is read only, but what I'm interested in is again the possible number of states that you can have in each of these memory cells, and that again is the same constant as over here, and here we have again a polynomial in n, so what does this have to do with the Boolean formula that I just showed you? Well, what we could do is turn this into a Boolean formula with a huge number of variables, but you will see that the number of variables is still polynomial. So what are my variables going to be? I'm going to have one variable for each of those black boxes here and also one variable for each of these here, and so on, and so on, and so on. I'm going to have one variable for all of the possibilities where I could be in my program code, and again here I'm going to do the same thing as I did here on the left side. I will have one Boolean variable for each of those possibilities, and what one of those Boolean variables means is basically--or what I want it to mean is if it's set to true, it tells me that a memory cell contains that value, so if this variable here is set to true, I want that memory cell up here to contain the value 0. If it's set to 1, I want this one here to contain the value 1. If it's set to 2, I want this one here to have the value 2, and so on. And now you see why the Boolean formula that I just showed you where you can force just exactly one single variable to be true is useful in this case, because if I put all of these variables here into such a Boolean formula, I would have a Boolean formula that can be satisfied if and only if exactly one of those variables here is true, so it tells me uniquely what goes into this memory cell here as long as it's satisfied, and the same thing over here, and over here, and over here. And now if I write this Boolean formula for this memory cell here, I write it for this memory cell here, here of course also, and so on, and if I combine all of those Boolean formulas, so I have a Boolean formula here, I have a Boolean formula here, I have one here, from this column, from this column, from this column, and so on. So I have Boolean formula, and then I do an and, and I have the next Boolean formula, and I have an and, and I have the next Boolean formula, and I continue doing this, and I will also do this here for the program. And of course, I will get a very, very, very large Boolean formula. And this is, I promise, going to be the most complicated part of this unit. Once you've understood this, you have understood how to prove the Cook-Levin theorums, so bear with me for another minute here. If we write this huge Boolean formula what I would like to ask you now is what properties this Boolean formula has. So if I write a big Boolean formula like this here, so the train that's exactly one variable here is set to true one here, one here, and so on and so on. What I would like you to think about is some of the properties that this Boolean formula will have. So there are 3 properties of 3 choices that I'm giving you. One is that the size of this Boolean formula here is polynomial in in. The second one is that this Boolean formula here has only a single satisfying assignment. And the third one is that every satisfying assignment of this Boolean formula presents a potential snapshot, so it kind of uniquely defines what the memory of the RAM looks like and where the program is at. Now of course, there's only 3 choices here; again, more than 1 can be true and you could make your way through by guessing, but before that, I'd encourage you to think through these statements, because once you understand this part, the rest of the Cook-Levin theory is actually quite easy. And there's 2 correct answers here. The first one is that the size of this huge Boolean formula here is polynomial in n, and I will show you why. First of all, how large is each one of these formulas that we're building? Well, there's a constant number of variables and as I showed you before, if you want to ensure that for a constant number of variables, only exactly one of them can be set to true, then the resulting formula is about the square of the number of variables that you have and since we have a constant number of variables, each formula here is about the size of the square of that constant, so we have-- it's kind of O of c squared, and c does not depend on the size of the inputs, so in a way, we can even write this as O of 1. Now we have a polynomial number of these Boolean formulas, so we have a polynomial n times the constant; this is again a polynomial of n, so we're fine on this side here. We're also fine on this side here, because the formulas again are of constant size; it can, of course, be a huge size, especially if you have a system that can carry very large variables, but nevertheless, it's a constant size, and that's all we care about; it does not depend on the size of the input, and we have a polynomial number of them again here. And finally, the code also has a constant number of lines, and so the Boolean formula resulting from that will also have constant size, so overall, this huge formula here has a size that is polynomial in n. Does this formula have only one satisfying assignment? No, it doesn't; it has a huge number of satisfying assignments, but each of those satisfying assginments will ensure that exactly one of the variables here is set to true and so on, and this gives us the third property, which means that this satisfying assignment defines a snapshot, because it will tell you exactly what's in this memory cell here and so on. It will tell you exactly where the program is at and it will also tell you exactly what's here in this memory. And once we have this, you have actually completed the most difficult step of this unit in my mind, and we are now ready to show that sat is np complete. So now our Boolean formula that we are building as it inputs to SAT is going to become even larger. So as you have seen before, the calculation that a non deterministic RAM makes for a given input can be represented as a polynomial number of snapshots, and I'm now going to draw the snapshots only like this; you know that represents the input, the program, the read-write memory, as well. We've already seen that the state of the non deterministic RAM at each point in time can be represented as a snapshot and that snapshot can be represented as the Boolean formula, so now that we found out how we can encode a snapshot into a Boolean formula, let's go back to our main mission, showing that any problem that can be solved on a non deterministic RAM can be encoded as a SAT formula. And the idea of this is to build a huge-- well, not that huge; it's all going to be polynomial size, but it's still going to be very large, so the idea is to build a very large Boolean formula as follows. each timestep of the algorithm is going to be represented as a snapshot. Then we're going to ensure that the first of these snapshots represents the memory of the RAM at t =0. What that means is that the program starts at the first line of execution and of course that memory contains the input that we're giving to that program or algorithm. Then thirdly, we have to ensure that the snapshots fit together. What I mean by that is even though it's a non deterministic RAM if at a certain point in time, say t = x, it is in a certain state, then at the next timestep, t at x plus 1, there's only a limited number of choices or potential states that machine can be in. So if we were having a deterministic RAM, actually as we already said, the state of the machine added time point x already clearly determines what state the machine will be in at point x plus 1. For a non deterministic RAM, if you use the if better operation then there can be 2 different states at the next time point. And then finally, we have to ensure that the Boolean formula that we're building has an input to SAT can only be satisfied if the algorithm returns yes at some point in time. Otherwise, because we have a decision problem, if the algorithm returns no, we do not want the Boolean formula to be satisfiable. We already know how to do the first part of this. We just have to write a Boolean formula for each single timestep. The second part is also not that difficult. If we are given an algorithm and an input of that algorithm, we already know what the first snapshot of the RAM is going to look like. The program will start at the first line of the program code, and the memory contains nothing but the input itself, so given the way that the Boolean formula is written, all we have to ensure that we enforce the variables for the first snapshots to represent that state that we already know, but we can ensure that, so for example, if in a Boolean formula, you want a variable x1 to be set to true, you would write it like this; you would have certain statements of the Boolean formula, and then you would just put the variable x1 here, and then continue the formula, and then you know it has to be set to true, so in this way, you can enforce the Boolean formula that represents the first snapshot to present the memory of the RAM exactly at time point t equals 0. The fourth one here that the Boolean formula can only be satisfied if the algorithm returns yes; that is also not that difficult to check, because again using a technique like this here all we have to do is ensure that at a certain point in time, the algorithm here is at the program line or the RAM executes the line of the algorithm here or one line of the algorithm here that says we return yes so that algorithm gives us the yes value. So the only part that requires a little more thought is the third part here, how we can ensure that various snapshots fit together. So let's take a quick look at where we are so far. What I first introduced to you is the concept of snapshots of the RAM, so you can look into the machine at any point in time that a polynomial time algorithm executes, and then you see exactly what state the RAM is at that certain point in time, so which line of the program it's executing and also what's in the memory. I've now also shown you that we can represent a snapshot as a Boolean formula. What that means is that I've shown you how to construct a Boolean formula so that when you have a satisfying assignment for this Boolean formula and there can be many. Then you can reconstruct this snapshot from the satisfying assignment. What we also know is the assignment of the variables for the first Boolean formula, so at time point zero, and the reason why we know that is that at the beginning, we know what the machine is doing, because in the memory there's the input, the algorithm starts at the first line, and in the memory where we have the output, and intermediate results, there's nothing in there, so here, we already know what the variables are going to be. Now why are we doing all of this? In the end, what we want to show is if we solve SAT for this huge Boolean formula that we're building and we're not done yet, if we solve SAT for this formula here, then we want to know what the machine is actually doing or in other words, what we want to get is a protocol of what the algorithm here has done. So each of the Boolean formulas here represents a snapshot, but now we need to ensure that they fit together, because once the machine starts out in this snapshot, it will move to the next one, and so we must make sure that if we have an assignment for the variables here that represent a snapshot, then the snapshot that is represented here must fit together with one, so that it's kind of a valid representation of what the RAM is doing here. And the way we're going to achieve this is, of course, more Boolean formulas so that we add to the game, and to do that, I would like you to think about some statements for a bit regarding how snapshots connected to each other. So what I would like you to tell me is which of the following statements is true? The first one is one a deterministic RAM, if we know what state that machine is in a time point to, we can clearly state what the state will be at time t plus 1. The second one is I want you to tell me if this here were true if instead of a deterministic RAM, we were talking about a non deterministic RAM. The third one is a non deterministic RAM behaves exactly like a deterministic RAM except when we use the if<u>better function,</u> and finally, if we use the if<u>better function,</u> there can be any number of next states, so not 1, not 2, not 3, but basically an arbitrarily large number of states, and we can not make any statement about that. So which of the following is true? Please check all of the boxes where the statements are true. So the first statement is clearly true, and we talked about this a couple of times in this unit. If you know the state of the deterministic RAM, that means you know whats in the memory and where the program is currently executing, then you can easily tell what the machine will do as a next step. The second one is of course not true, because we have the if-better function, and so if we know the state of a non deterministic RAM at time point t, and at that point in time, we call the if-better function, then we can not say what the state will be at time t plus 1. There are basically either the first part of the code is executed or the second part of the code is executed. And this gives us the answer for the last 3 statements here, so this one here is false, because a non deterministic RAM does not behave like a deterministic RAM, but there is actually only one case where it does this, and that is when if-better is called, so this statement here is true, and when the if-better is called, there can not be any number of next states. There can only be 2, because you'll remember, the if-better function works as follows. You call if-better, then there's some code here, and then you have an else statement, and there's some code here. Then there's only 2 possibilities, so it's not any number of states; it is actually just 2, so this is also false. Now we are almost there. What I would like you to do now is think about when you analyze an algorithm using pen and paper, how would you go about that? What you basically say is every program here and your variables here, so how do you get from here to here? So basically, it's a number of rules that look like this. If we are at a certain line of the code, so say we are here, and usually that line of code will also use some variables, but it doesn't have to, but usually it will of course, so certain variables are set to a given value. Then we know what the program is going to do next. For example, it's going to jump to the next line of code, and it's going to modify this variable here. So how many of these rules are there? Well, for a single line of code, it depends on the variables here, and let's assume that one line of code uses a maximum of 3 variables. If you were to count how many of the rules there are, it's the number of different values that one variable can take times the number of different values that the second variable can take times the number of values that the third variable can take. So for one line of code, that's actually just O of 1 as the constant. Why is that? Well, because we set that on the RAM variables can not get arbitrarily large, so there's only a constant number of different values that a variable can take, so even if we have 3 different variables and consider all of the combinations, it will be a huge number usually, but it will be a constant number for one line of code. Now if we're not looking at one line of code but all lines of code, then this actually doesn't change, because we have a constant number of possibilities for each line in the code and the program has constant size just as before. So there's a constant number of rules that will tell us exactly what the machine is going to do in the deterministic case. We're going to go to the non deterministic case in a minute, because there of course, as we just found out, the if-then rules don't work. So how the machine behaves is a large collection of rules that look like if the variables are set in a certain way, then this is what happens next. Now the question is can we use a Boolean formula to express an if-then statement? And I will actually let you figure that out in our next quiz. So I'm going to give you the following Boolean formula, x1 and x2 and x3. We're going to do a big not over this or x4 and x5 and x6. And I'm going to give you 4 cases now to look at, so we're going to look at this part here and this part here, and I'm not including this big not here, so I'm just looking at how x1, x2, and x3 evaluates; the not is not included. So there are 2 possibilities of course. It can be either true, or it can be false, and those variables over here, completely independent over here, they can of course also be true and false, so overall, we have 4 different cases, and what I would like you to quickly tell me is in which of these 4 cases here, the whole Boolean formula is satisfied. So the Boolean formula here is almost always satisfied. It's satisfied in this case over here. It's satisfied in this case over here and this one. The only one where it's not satisfied is this one here, and of course that's easy to evaluate, so if x1 and x2 and x3 evaluates to true, then we have the big not, which will make it go to 0 and 0 or 1 is equal to 1, so the Boolean formula is satisfied, but 0 or 0 evaluates to 0, so here the Boolean formula is not satisfied. For these 2 cases, the Boolean formula is simply satisfied, because if this goes to 0, then we have the big not over here, so it will go to 1 and 1 over 1, and 1 or 0 that also evaluates to 1. What is this have to do with an if-then? Well, it's actually quite simple. If this part here, x1 and x2 and x3 evaluates to 1, then this part over here must also be 1 in order to satisfied the Boolean formula. It does not work if this part over here is 0. In the other case where x1 and x2 and x3 evaluates to 0, then as you can see, we basically don't care what the other variables are doing, because the Boolean formula is already satisfied, and that is exactly how an if-then behaves. If the condition is satisfied, then we want something specific to happen. If the conditions are not satisfied, we don't really care what happens, or at least we're not really going to force anything to happen. So finally, what about non determinism? What if we're using the if-better function at a certain line in the code? Well, then the rules here are actually much simpler than for a normal line of code, because any time we use the if-better, our rule is going to be that the program either goes to 1 line of code or another one, because that's all the if-better does. The if-better does not modify any variables, it doesn't depend on any variables. It just goes to either one line of code or the other one. So this is a very simple rule that we can use to say what will happen if the program at time point t point to an if-better. So now it's time for us to put all of our building blocks together and we're just this close to showing that SAT is indeed NP complete. So we started out with a problem in NP and input fallout problem; of course, this here can be any problem in NP and this here can be any input fallout problem and what do we then do? We said if the problem is in NP, then there must be some algorithm for that problem which runs in polynomial time on a non deterministic RAM, so an algorithm or a program you can call it any way you want, so that will run in polynomial time, and the algorithm at some lines of the code either says yes or says no, but it's running in polynomial time in any case, and of course the input for the problem, well that is basically just the number of variables in the memory of the machine as it starts out. Then we took all this and of course it's a huge Boolean formula and you would probably never really want to write it out explicitly, but it exists and it contains a number of components that we have discussed. So one part of the Boolean formula encodes snapshots of the algorithm as it runs on the machine. Then we said we have to have 1 part that ensures that the first snapshot properly represents the starting conditions so that it properly the algorithm starting at line one and also the memory representing the input for the problem. Then what we just discussed is that through a number of rules that look like if-then, you can ensure that the snapshot is at a certain point in time t and at the following time point fit together, and then finally, since this here is a decision problem, we want to ensure that the Boolean formula can only be satisfied if at certain point in time the algorithm returns yes, so this is the last part we have to add to the Boolean formula, and this is actually quite easy to ensure, because once the algorithm reaches this line of the code, wherever it may be, and you can even have multiple lines where the algorithm returns yes, but once such line has been reached, the algorithm returns yes and stops, so this her is very easy to ensure. You just have to make sure that there's one snapshot where the algorithm is in a line that returns a yes. So once we have constructed this Boolean formula, what happens if we solve SAT for this formula? Then there's 2 cases that can happen, because SAT is also a decision problem, so either SAT returns yes or it returns no. What if it returns yes? If it returns yes, that means that there is a satisfying assignment for this Boolean formula, and a satisfying assignment will have the following property. First of all, it will encode valid snapshots of where the algorithm is and whats in the memory. Secondly, it will also ensure that the machine starts out in the right place, meaning it starts out at line 1 of the code and representing the input for the problem, it will ensure that all the snapshots that it has figured out will fit together and it can only return yes if the algorithm returns yes at some point in time. So if we have a yes here, we also know that this problem or the decision problem here is one where a non deterministic RAM would also answer yes. If it says no, on the other hand, what does that mean? Well, we know that we always can encode the snapshots, so it's not going to say no, because it can not encode a snapshot, because that's possible always. It also won't say no due to this property here, because well, we have ensured that the snapshot can properly encoded, so there's no mistake in the formula here, so it can not say no because of this here. It also can not say no because of this here, because the machine will always run and you can make the snapshots fit together. The only reason why there can be no satisfying assignment is if the algorithm does not return yes at a certain point in time and since this algorithm solve this problem here, if it can not reach yes, then this means that this decision problem here is also a no. So satisfiability only if this problem given this input here is a yes. So now that we have put it together, here's our final quiz for proving that SAT is NP complete, and what I would like you to do is to recap the properties of this Boolean formula here. First of all, what is the size of this Boolean formula for an input of size n and remember this algorithm here runs in polynomial time. So is this Boolean formula up here constant in size, polynomial in size, or exponential in size with respect to n? and then can this Boolean formula encode any algorithm at least for a problem that is an NP? Can it encode any input of size n that were given to that problem? Finally is this Boolean formula satisfiable if the input here is a yes to not decision problem here or are there any other cases where we could also have satisfiabilty. So please check all of these that are true. And of course, once you've gone through the proof, this was a rather easy quiz just for relaxation after all of these Boolean formulas and satisfiabilities. So of course, this formula has polynomial size, because when you constructed it, we took care of that. It can encode any algorithm. We did not make any special assumptions or restrictions on this algorithm here. It can also encode any input, because that basically just means whatever we're given, we encode it into memory and we know we can do that, and finally, of course, that was the purpose of the construction, this Boolean formula up here is only satisfiable if solving this problem for this input returns a yes; otherwise, if it's a no, you can not satisfy this formula. And this of course is the whole purpose of the construction, because what we have now shown is that solving SAT on this Boolean formula is the same as solving this problem for this input here, and what that means, of course also is if you can solve SAT on this Boolean formula here in polynomial time, then you have a polynomial time simulation of this algorithm here running on this input. So congratulations! We have now shown that any problem that is in NP of size n can be transformed into a SAT problem with size polynomial in n. And what that means is that SAT is NP complete. Now I know that it was a lot of work to prove this and you can be proud of yourself for staying along, and I actually have to thank Steven Cook and Leonid Levin, because thanks to their work, I already know how to do the proof. Just imagine what they must have gone through before they come up with this. Now the hardest part is done. We have a problem we know to be NP complete, and that problem SAT. So from now on, showing that other problems are NP complete will get a lot easier, because we don't have to go through this laborous process n coding machines anymore It will just suffice to show that SAT can be reduced the the problem we're looking at. So we can use SAT to show other problems to be NP complete now, and once we have shown these problems to be NP complete, we can use them as well to show again, other problems to be NP complete, so we are basically building this whole tree of NP complete problems using SAT as a c problem and it will just suffice to show these reductions here; we do not have to do the same tedious steps of Boolean formula n coding anymore, because we already know SAT to be NP complete now. So let's take 1 step back now with our next quiz. What happens if you show one NP complete problem to be solvable in polynomial time? And by solvable in polynomial time, of course, I mean on a deterministic RAM. Would that mean that some problems in an NP can be solved in polynomial time? Again, we're talking about a deterministic RAM here. Would it mean that all NP complete problems are solvable in polynomial time? Or would it mean that all problems in NP are solvable in polynomial time? And again, more than 1 of these answers here can be correct, so please check every statement that is correct. And the answer here is that all 3 statements are actually correct. So the strongest one is probably this one here, so if you just happen to show just one single NP complete problem to be solvable in polynomial time, then all NP complete problems are solvable in polynomial time on a deterministic RAM, so on your home computer, basically. If all NP complete problems are solvable in polynomial time, because they are NP complete that also means, of course, that all problems that are an NP are solvable in polynomial time. So this one here is true, as well. Some problems in NP can be solved in polynomial time, yeah. We already know that, and actually, that's the weakest of the 3 statements, so if all problems are solvable in polynomial time, yes, some problems are solvable in polynomial time. So now let's look at this statement in a slightly different way. What would happen if you showed 1 NP complete problem to be solvable only in exponential time. So it's not solvable in polynomial time, you show for 1 NP complete problem that requires exponential time to solve, on a deterministic RAM again, of course. So would that mean that some problems in NP are only solvable in exponential time? Would it mean that all NP complete problems are only solvable in exponential time? or would it mean that all problems in NP are only solvable in exponential time? So please, once more, check all of those that are correct. And this time not all statements are correct, but the strongest one of them is, so if you showed just one single NP complete problem requiring exponential time to be solved, then all NP problems will require exponential time to solve, and the reason for that is that all NP complete problems are connected to each other using polynomial time reductions, so if one of them requires exponential time and another one requires polynomial time, then that just can not be, because say if this problem here requires polynomial time, that would mean that you can SAT, for example, in polynomial time, which would then mean that you can solve this problem over here in polynomial time, and so on and so on. All problems that are NP complete are from a viewpoint of polynomial or exponential time equally hard to solve, which would also mean that the weaker statement here is true. Some problems in NP are only solvable in exponential time; yes, if all NP problems require exponential time, then there are problems in NP which require exponential time. Finally, this statement down here; that is not true. All problems in NP are only solvable in exponential time. That is not true. Not all problems in NP require exponential time. So remember our picture from before when we said that P is basically a subset of NP, so these problems here will still be solvable in polynomial time. It doesn't matter if there are some problems in here that require exponential time. It doesn't effect these problems here in NP. Now back to our initial question. What does all of this mean for Alice, Bob, and Carol? We have already seen that the problems they are trying to solve are contained in NP and so what we could now try is to show that their problems are actually NP complete. To do that, what we need to do is we need to reduce SAT to one of their problems, and we're going to do this with clique. It's also possible to do this with vertex cover or independent set, but clique is actually one of the easier ones to see. And now what we need to show is for any given instance of SAT, so for any Boolean formula, if you will, we can transform it into an input for the clique problem in polynomial time such that clique as a decision problem will say yes if the Boolean formula has a satisfying assignment and no otherwise, and once we achieve this, we know that clique is NP complete and since we have already seen there are polynomial time reductions between clique, vertex, and independent set, if clique is NP complete, then these 2 problems here are also NP complete which of course will mean that not only will Bob be very unhappy about this, but Alice and Carol will be in this together, as well. So we're trying to show that any Boolean formula can be transformed into a graph such that this graph has a large clique in that case only if the Boolean formula has a satisfying assignment, and here's one fact that's going to make our life a little bit easier: Every Boolean formula can be written like this, so you the brackets around variables that are only combined by or, so you have variable 1 or variable 2 or variable 3, and you can have more than 3 variables in here, but you have nothing else; you only have variables and or and between the brackets, you always have an and, so you have brackets of or and bracket of or and so on. This is known as the conjunctive normal form of a Boolean formula, and it can be shown that you can write any Boolean formula, no matter how complex in this form here, and it will not significantly change the size of the formula, so if you have n variables and your Boolean formula has size polynomial in n, it will stay that way if you to transform it into the conjunctive normal form, and if you have conjunctive normal form, then this part here in the brackets is known as a clause, so this here would also be a clause, and what you can see is the way that this is structured the Boolean formula, if it has a satisfying assignment, then each of these clauses needs to evaluate to true, because they're all connected by an and, so if one of these would evaluate to false, then the whole formula would not be satisfied. Now how how are we going to transform this into clique? So I'm just going to show you how to transform a Boolean formula that is written in this form into a graph, and then we'll discuss what this has to do with clique. So let's say we are starting out and I'm going to do is using an example. So let's say we start up with the following Boolean formula (x₁ or not-x₂ or x₃) and (not-x₁ or x₂) and ( not-x₂ or x₃) and the array we're going to transform this into a network is we're going to do groups of vertices for each clause. So for this clause here, for this one here, and for this one here. So, this is our first group of vertices and we're going to have one vertex for each variable in that clause. So, this vertex here is for the x₁. This vertex here is for the not-x₂. This one here is for the x₃. For this one here, we're going to do another group. This one here is for the not-x₁. This one here is for the x₂. And for that clause done here. We're going to do the same thing. So we have not-x₂ and here we have x₃. And now, we're going to draw a lot of edges. So from each vertex, we're going to draw edges to every vertex in the other groups with one exception. We're not going to draw an edge if we have the same variable, but 1 is the untouched variable and the other one has a not. So x₁ and x₂, we're going to draw an edge. x₁ and x₃, we're going to do an edge.. And x₁ and not-x₂ also but we're not going to do an edge here. And it works similarly for this one here. So not-x₂, not-x₁, that's something we don't care about. That's something where we draw an edge. no-x₂ and x₂. And then we have a not. Here, we do not have a not. So we don't draw an edge. And down here, that's fine. And here we have a case where we have not-x₂ and not-x₂. That's also fine. So we'll draw an edge here. It's early if we have a not and then here we don't have one. So for x₃, we can draw an edge down here. Down here. Again, those are the same. So we do draw an edge. That's fine and we're draw here. Now let's look at those here. So we already have all the edges all to these groups. So we only need to look down here and then the graph edges here and the same thing is going to happen here. So x₂, I'm not drawing an edge to this not-x₂ here and we're drawing an edge down here. And we've already drawn all the edges down here. So this is the network that we constructed. Now what about the size of the graph? So if the Boolean formula here has polynomial size, so we have n variables or in this case three variables and we said that we're going to have the total length of the Boolean formula. The polynomial and the number of variables. So, if this length here is polynomial, then the network also will have polynomial size because we have one vertex for each of the variables that occur here, so the size really doesn't change that much. We introduced edges but you already know that the number of edges is quadratic in the number of vertices that we have. So, the size stays polynomial which is already good for our reduction. But now I still need to show you what satisfiability has to do with clique. We're actually going to do this as a quiz. So let's say that the Boolean formula has m clauses. So in this case, m is 3 but you can consider the more general case here and then let's say that the graph that we have constructed has a clique of size m. So one clique of size m, for example here, because m is 3 would be this here. All vertices are connected to each other. There's others that you can find actually. So, if she can't find a clique of size m in a graph that was constructed this way, does that graph contain at least one vertex from each clause group and by clause group, I mean, the groups of vertices that we introduced for each of the clauses from our satisfiability formula. And what I would also like you to think about is if a clique can contain multiple vertices from one of this clause groups here. So if we could have a clique, say for example, that could contain these two vertices here or this two here or in the more general case, if we can have a clique that contains more than one vertex from each of these groups here. So please check those that are correct and leave the other ones blank. And here, only one statement is correct. This statement down here is not correct. The clique can not contain multiple vertices from one of these groups, and the reason why that is is that in a clique, all vertices, as you know must be connected to all other vertices, but this is not how we constructed the graph. When we constructed the graph, all we did was draw edges between vertices from different groups, but we did not allow any edges between vertices in that group, so if you find a clique that can only contain exactly one vertex from each of these groups here. So if the graph has a clique of size m, and the clique can not contain multiple vertices from a clause group, this means that you have to have exactly 1 vertex from each clause group in your clique. So this statement here is definitely true. It contains at least one vertex from each clause group. But actually, we can make an even stronger statement and say it contains exactly one vertex from each clause group. And now we're almost done with our reduction, because if you think about it, so we solved clique for this graph we have constructed here, and we asked the decision problem, does the graph have a clique of size m where m is the number of clauses? There's 2 cases here; so let's say the graph does have a clique the size of m, then what will happen is the following. So it contains exactly 1 vertex that corresponds to a variable in that clause, and what we also know is because we constructed the graph this way, that we can not have 2 vertices connected here in this graph where there's a conflict, so what we can not have in this graph, for example is 1 vertex that represent not x2 and another vertex that represents x2, because we avoided this in the construction but this directly shows us how we can satisfy this Boolean formula here, so if we have a not x2 here, we just set it to 0 so we could just set this one to false, so that not x2 becomes true, then this clause here is satisfied and also this one over here would be satisfied. And x1--that's a separate variable, so we can set it as we want, and we could set this one to false. So we have x2 and we can set that to false so not x2 becomes true. So that becomes true, that one becomes true, that one here is false. Over here, we have not x2 as well, so there's no conflict here. x1--we haven't yet talked about x1, but can just do the same thing; we can set x1 to false, so the whole thing not x1 becomes true. We have set it to false, and we haven't even looked at x3, but all of the clauses are already satisfied, and that's actually the cool thing to notice here. x3 is also not contained in the clique, so the vertices in the clique tell you how to set the variables so that the Boolean formula can be satisfied. So what if this graph here does not have a clique of size m? Well in this case, it means that we have 1 clause group which is not contained in the clique and if we have 1 clause group that is not contained in the clique, this means that there's no vertex in the clause group that has connections to all of the other vertices in the smaller clique that we're looking for, and that means, due to the way we constructed the graph, that every vertex has a conflict with another vertex in the clique so if there's no large clique, this means that every assignment of true and false of the variables will lead to a conflict such that at least 1 of the clauses can not be satisfied. So then the Boolean formula does not have a satisfying assignment. So now that we have this reduction, we know that clique is NP complete, which of course makes Bob a little unhappy. So now what about vertex independent set? Are those problems NP complete or are we not sure yet? Now that we have shown clique to be NP-complete, we can easily say that independent set is NP-complete because we can transform a graph for which you want to solve clique easily into a graph on which you can solve independent set, and then that will give you a solution for clique. So we already have that reduction down here, which of course will make Carol quite unhappy. And we also had the reduction from independent set to vertex cover because we showed that solving vertex cover on the graph is basically the same thing as solving independent set. So vertex cover is also NP-complete. So Alice is now unhappy as well. And what this means is the following: The problems that Alice, Bob, and Carol are trying to solve are as hard as any problem in NP can become. Any problem that you can solve in polynomial time, if you have had this magic "if-better" function available, would also be solvable in polynomial time if we found a polynomial-time algorithm for any of their problems. Or even, in other words, if you found a polynomial-time algorithm for vertex cover, independent set, clique or SAT, what this would mean is that you have found a way to simulate the if-better function in polynomial time. You can simulate a nondeterministic RAM on a deterministic RAM in polynomial time. So remember at the beginning of this unit when I introduced you to nondeterminism and the "if-better" function? And we also talked about simulating the if-better function and how this takes exponential time to do? And I imagine your first reaction to this might have been a mild version of "So what?" or even "This is ridiculous." But now, think what this means in the context of NP-completeness. If, for any NP-complete problem, you find a deterministic algorithm that runs in polynomial time, then you have also found a way to simulate a nondeterministic RAM in polynomial time, which would mean that a normal, deterministic RAM without the if-better function is just as powerful as one that has this function. Which, of course, seems a bit strange because our intuition, of course, tells us that having this if-better function is super, super powerful and should somehow make a difference. So the cool thing is, there's only 2 possibilities. Either all NP-complete problems can be solved in polynomial time, which would essentially mean that P=NP. So any problem that can be solved in polynomial time on a nondeterministic RAM can be solved in polynomial time on a deterministic RAM. Or, in other words, a deterministic RAM is just as powerful as a nondeterministic one. Or it could be the other case, and that is no NP-complete problem can be solved in polynomial time. So P≠NP. There are certain problems that you can solve in polynomial time if you have the if-better function available, but you can not solve them in polynomial time if you don't have this function. So basically, you'd say P≠NP is the same as saying that the if-better function is really powerful. So which one is it? And that question is the famous P vs NP problem. Because the thing is, we don't know. Nobody knows. Asking this question here, if P=NP or P≠NP, is a problem that is decades old, and yet nobody has been able to figure it out. Now, given how powerful this if-better function is, remember when I introduced it to you? It seemed like this magic function that could solve all of our problems. Many computer scientists nowaday believe that P≠NP, but nobody has been able to prove it. On the other hand, also nobody has been able to find a polynomial time algorithm for any single NP-complete problem, despite, literally, thousands of practically-relevant NP-complete problems being out there. Now let's think a little bit of how you could resolve this question. So how could you show that P=NP or P≠NP? And we'll do that as a quiz. So I'm going to give you a number of accomplishments or things that you could do, and I would like you to tell me what that would show. So, for example, if you found a polynomial-time algorithm for an NP-complete problem, would that show that P=NP, would that show that P≠NP, or would that show nothing interesting? And what if you found an algorithm that solves an NP-complete problem in polynomial time on average? So not worst-case running time, but average-case running time. And what about if you showed that the most efficient algorithm for clique requires exponential time, on the deterministic RAM, of course? Would that show that P=NP, P≠NP, or something else, or we don't know? What if you showed that the vertex cover problem has an exponential number of potential solutions that any algorithm has to go through? What if you were able to reduce the clique problem to the shortest path problem? So shortest path is finding the shortest path between 2 vertices in a graph. What if you were to reduce clique to the problem of finding the shortest path between 2 vertices in a graph? Or what if you could show that any shortest path problem in a graph can be solved by solving clique in a transformed graph? So please make your selection. Which ones are correct? So let's go through them 1 by 1. Finding a polynomial-time algorithm for an NP-compete problem, yes. That would show that P=NP because the problem is NP-complete. So it means it's among the hardest-to-solve problems in NP. So polynomial-time algorithm for this problem will solve any other NP-complete problem in polynomial time as well. Finding an algorithm that solves an NP-complete problem in polynomial time on average. Now, that's a very interesting one, because you might be inclined to think, "Well, if it solves an NP-complete problem in polynomial time on average, then probably that is sufficient." Well, it shows a lot of interesting things, but it doesn't show anything with respect to P being = to NP, or P being ≠ to NP. Now, showing that the most efficient algorithm for clique requires exponential time, that would show that P≠NP. Because clique is contained in NP, so if it requires exponential time, it means that there's at least 1 problem, namely clique, that is contained in NP but not in P. Of course, as nice as it would be to show this, of course, it would also be quite difficult to prove this because you would have to show that, again, no matter what algorithm you come up with, it always requires exponential time. That would be hard to do because you would have to consider any algorithm, even algorithms that haven't been invented yet, so to say. Now, showing that vertex cover has an exponential number of potential solutions, that is similar to the example I pointed out to you in the beginning of this unit, namely, that just having an exponential number of potential solutions does not mean that the problem is hard. It can mean that the problem is hard, but as you've seen in the case of shortest path, it's not necessarily so. Now, reducing clique to shortest path versus reducing shortest path to clique, then you have to remember again what reduction means. So if you reduce clique to shortest path, it means that solving the shortest path problem is also capable of also solving the clique problem. And since shortest path is solvable in polynomial time, if you manage to reduce clique to shortest path, that would show that P=NP. If, on the other hand, you manage to reduce shortest path to clique, that doesn't really have any implications because all you've shown is that shortest path is an easier problem than clique, which is something we already know. Now if you look at all of these solutions, well, of course, it's a bit of a subjective selection here, but what you'll see, that showing that P=NP in a way would be quite easy. All you have to do is find 1 single polynomial-time algorithm for an NP-complete problem. Then you have immediately shown that P=NP. On the other hand, if you want to show that P≠NP, then you have to put in a lot of work, because you have to consider any possible algorithm, no matter how complex, how intelligent, how sophisticated, and still somehow make the case that this algorithm is not able to solve a problem like clique in polynomial time. Generally, I would say that most computer scientist believe that P does not equal NP and there are basically two reasons for that. The first reason is the power of nondeterminism. The power of guessing correctly. It kind of seems strange that should be possible always on polynomial time and the second reason and unfortunately we'll only briefly touch that in this course is that there are problems that are believe to be even much harder than NP complete problems and P=NP will imply that also this much harder problems would be solvable in polynomial time. The high chances that P does not equal NP is of course what makes resolving the P versus NP question much harder because if we want to do show that P=NP then all we would have to find is one single polynomial time algorithm for an NP complete problem but if we want to show that P does not equal NP then we'll have to construct some mathematical proof that takes into account any conceivable algorithm no matter how sophisticated or thoughtful or advanced as long as that algorithm runs in polynomial time, we must show that it cannot solve an NP complete problem. Now as famous as the P versus NP question is there is some heated debate on whether that would actually have any practical consequences. On theoretical level of course, it would be a fantastic result and the person who manages to resolve P versus NP would become quite famous but on a practical level there is two things to consider. One is that polynomial time doesn't always mean efficiency. So as we have seen, that the NP completeness proof of SAT, the polynomials involved quickly get very large and of course a polynomial time algorithm with a time of say n²⁰ would not really be practical, and on the other hand because NP complete problems are so important in practice, there's lots of techniques that have been developed to actually deal with them and we'll learn some of them in this course of course. In any case if you want to spark a heated debate between theoretical computer scientist should you ever have the opportunity to do so then just ask them whether resolving P versus NP would have any practical consequences. Now, the question of course is should you try to solve P versus NP? There's a web page called the P versus NP page and that page lists a lot of re-attempts that have been made to settle the P versus NP question. The list which you find on this web page as you can see is very, very, very long. The list contains almost a hundred papers, of which when I checked that the last time, 41 claimed that P equals NP and 46 claimed that P does not equal NP. So, we already know that half of these proofs are wrong, but of course, none of them is accepted in any way. None of them has ever been published in a scientific journal so we can almost safely assume that proofs not these papers all claim to have do not hold up against scientific scrutiny and some of those proofs are actually quite huge. For example, there was a recent attempt to show that P does not equal NP which used up 102 pages which is almost a full Udacity course and you know why it didn't work out, a flaw on page 67 and it is for these reasons that, in fact, many computer scientist will nowadays refuse to even look at your proof of P equals NP or P does not equal NP unless you can convince them that you have a new insight that hasn't been discussed before. So, the status of P versus NP is this. Despite over 40 years of research and a million dollar price and many computer science heavyweights having attempted to resolve P versus NP so far there've been no solution and that has even been shown and unfortunately, we can't go deeper into that, that some common mathematical tools that are used in theoretical computer science are not capable of solving this question. So, not only do you need to have a good idea for proof, but you also need to invent new techniques for theoretical computer science. So, I do not want to discourage you from thinking about P versus NP, but don't quit your day job to attempt to resolve this question. So, let's do our final quiz in this unit. Under what circumstances should you try to settle the P versus NP question? Is it when you think who had a brilliant insight. Is it when you had a brilliant insight and you have made sure that this hasn't been tried before Or is it when you have a brilliant insight that you have made sure that no one has tried before and you know that your proof technique is actually capable of settling the P versus NP question Or is it when you are a seasoned and respected computer scientist with nothing to lose and enough money or savings to sustain yourself So, please check all of the correct ones. I think the only time that you should try to settle the P versus NP question is either when you've had brilliant insight that hasn't be tried before and you've invented a new proof technique that no one has shown is incapable of setting the P versus NP question, and of course if you're seasoned and respected computer scientist with nothing to lose and enough money. I, of course, don't want to keep you from pondering this question here. Congratulations. You have now learned some very fundamental concepts of computer science, and you understand the issue of P vs NP. We've also shown that the problems that Alice, Bob, and Carol were working on are among the hardest problems in NP. They are NP-complete; so nobody knows if there's a polynomial-time algorithm for those problems, and actually finding 1 would be a sensation. Now, the question, of course, is what does that mean for Alice, Bob, and Carol? Should they just give up? Should they ask their bosses to give them a new problem? Or should they make their bosses watch this Udacity course? In the next unit, we'll be looking at 2 things: The first 1 is how to recognize that a problem is NP-complete. And we'll then turn our attention to what to do when you encounter an NP-complete problem. Because, well, there will not only be good news, but as it turns out, there's still some options available. It is possible to poke loopholes into the laws of NP-completeness. So there's still hope for Alice, Bob and Carol. So see you next time. In the previous unit, we have introduced the notion of NP completeness and seen that a myriad of practically relevant problem is NP complete. So, we think there is no polynomial time algorithm for these problems. Now, the question last time we left off was what does this mean for Alice, Bob, and Carol--the three computer scientists we were following? Should they just give up? Should they ask for a new problem? And I think that is something they might do, arguing that the problems are NP-complete, but actually they could do much better, using some of the techniques that you are about to learn in this unit and the following units. Because what we will now be investigating is techniques to actually solve problems despite their NP-completeness. Now, this will not always work, but it will be much better than just giving up, because there are so many NP-complete problems out there that are just too practically relevant to leave them alone. In the previous unit, we have introduced the notion of NP-completeness. We have seen that many practically relevant problems fall into this category, such as vertex cover, clique, independent set, and of course the SAT problem that we got to know in the last unit. Now, since the famous P versus NP problem is unsolved, there is no algorithm for any of these problems that is guaranteed to run in polynomial time. Now, in the first unit, we met three computer scientists who were working on these problems, and they did not know that their problems were NP-complete. So, in this unit, what I would like to teach you is how you can detect that a problem is NP-complete. Then in the following units, we'll be dealing with counter measures. Once you have found out that your problem is NP-complete what can you do about it? So, in order that you save a little time compared to Alice, Bob, and Carol, our first quiz this unit is going to be what should you do when you can't find and polynomial time algorithm for some important problem that you're working on. Here are your options when you can't find a polynomial time algorithm for a problem you're working on. You can do some research on the problem. You can try to show that your problem is NP complete. You can give up right away. You can discuss the problem with friends and possibly also experts if they are available to you, and you might also think about settling for a suboptimal algorithm-- some algorithm that works but probably doesn't produce the best possible solution, at least if the stakes aren't high. So, which of these options do you think could be recommended in general? All options except for giving up immediately are viable options depending on the situation. So it's always a good idea to do research on the problem that you're working on because many problems that occur in practice have occurred elsewhere before. So it's likely that there will be some research on this problem, and that can help you a lot potentially. Of course, you can also try to show NP-completeness for your problem because if you manage to show this, then you know your problem is going to be hard. This is not an excuse to give up right away, but you basically just know what you're dealing with. It's always a good idea to discuss the problem you're working on with friends and experts, of course, because they might have a new insight that helps you. And finally, settling for a suboptimal algorithm--and we're going to talk more about this in later units--can sometimes also be a good option if the stakes aren't high. So, for example, Alice working on vertex cover--if her company is happy with installing a few more monitoring devices than the absolute minimum, then she can possibly find another algorithm or just maybe even solve it by hand if she wants to. In this unit, we're going to focus on this aspect here-- showing you how you can prove NP-completeness for a problem. We have already done this a couple of times, but it's worth to practice this technique. And then how you can do some research on your problem. So I'll give you some example problems that often occur in practice so that you know the names; and when you come across them, then you'll have an easier time to find out more about the problem that you're trying to solve. In principle, of course, you know by now how to show that a problem is NP-complete because we have already shown this in the last unit for 4 different problems. We have shown the NP-completeness for vertex cover, we have shown the NP-completeness for clique, we have shown the NP-completeness for independent set, and then for SAT, the mother of all NP-complete problems if you will. So for showing NP-completeness, there is always 2 steps. First you have to show that your problem is in NP, which means that a nondeterministic RAM can solve your problem in polynomial time, and later in this course we will meet some problems actually that are worse than NP-complete problems, so it's often a very simple step, but it's one that you have to go through because you might be dealing with even harder problems although that is unlikely. And the second step was finding a polynomial time reduction from another problem that is known to be NP-complete using the ideas that Cook and Levin had for their famous Cook-Levin theorem. Then we showed that clique is NP-complete by reducing SAT to clique. And then from our first unit, we already knew that clique, vertex cover, and independent set are all very closely connected to each other. So you can basically reduce these problems to each other in any order or way that you want because they are so closely related. I would like to do a brief quiz with you, which is a little bit subjective although I think you'll likely agree with me, and what I would like you to tell me is how difficult you found those reductions that we have encountered so far. So showing that SAT is NP-complete, showing that clique is NP-complete, and then showing that vertex cover and independent set are NP-complete, and I would like you to rank these 3 reductions that we have had so far by difficulty where 1 means easiest, 3 means most difficult, and you can guess what 2 means. So please rank the difficulty of those reductions that we have encountered so far. Now, of course, this is a little bit subjective, but to me, it's clear that showing that SAT is NP-complete was the hardest thing that we had to do because we didn't know any other problem to be NP-complete, so we had to go through a lot of effort to show that any problem in NP can be expressed as a boolean formula for SAT. Then I think that showing clique to be NP-complete was the next difficult thing because it's not really obvious how you can reduce SAT to clique because SAT is a problem on boolean formulas; clique is a problem on graphs. And so we had to find a good idea to show how SAT can be reduced to clique. And then, in the first unit, it still took some thought, but showing how vertex cover, clique, and independent set are related wasn't that difficult because all three problems were asking questions about graphs, and they were asking mostly very similar questions, especially clique and independent set. Vertex cover--yeah, we had to give it a little thought, but I still think it was much easier than coming up with the idea of how to encode a boolean formula into a graph that is then an input for clique. So the good news is the hardest part is over, but, of course, as you've seen with SAT and clique, showing NP-completeness can still be tough. And that is why I would like to show you one more example of a reduction for a quite-famous NP-complete problem that you don't know yet and then give you some more general strategies on how you can show NP-completeness for other problems. And to introduce that problem to you, I would like you to meet Dave. So Dave is also a computer scientist just like Alice, Bob, and Carol, and he is working in Logistics, and the problem that he is working on is optimizing the delivery routes for the mail trucks of his company. So basically, the problem that Dave has to solve each day is the following: Here's the headquarter of his company where each day, the mail arrives, so maybe the mail arrives by an airplane, and that airplane delivers letters each day, and then this delivery truck here has to deliver those letters to all of the houses that receive mail that day. So let's say it's those 7 houses here where this truck has to deliver the mail. Now of course, the roads that connect the houses, so not every house is connected to each other house directly, and the roads also have different length, and I'm going to specify this in minutes, so if I write a 40 here, it means you need 40 minutes to get from this house to this house, and then 14 from this house to this house, and 13 from this house to this house, and so on. So you can already see that this looks very much like a graph except that the edges now have a certain distance or time attached to them. Now the problem that Dave has to solve is a problem that we will call shortest tour. We will say that as an optimization problem for now, we will later work with the decision problem to show NP completeness of this problem. The truck starts out here at the headquarters, and then, Dave is supposed to figure out the fastest way for the truck to visit all houses and then get back to the base, so it starts out here, has to visit all houses. It can visit a house more than once, in case you're wondering, and then it has to get back to base. So let's say the truck starts here and let's say the first road it takes down is this one here. What I would like you to tell me is in which order should the truck visit the other houses? So this is the first house that the truck is visiting, and I want you to enter a 2, 3, 4, 5, 6, and 7 here, so if the house travels from House 1 to House 2 then to House 2 and so on, it's taking the fastest possible route to visit all houses. And luckily there's not many houses here, so a bit of playing around, I think you can get it. So first, you have to take this long road over here, because any other way to travel over here is much longer and then you still need to go back, so with a bit of playing around, you can find out you can find out that the next house to visit is this one here. Then it's almost obvious that you should go up here. Now here, you can choose to take the fast way to this house up here or the one that takes a bit longer; actually, it's better here to go down, because otherwise, you'll have to visit some of these houses multiple times. Then you can go back up here, and then you go over here, and then it's almost obvious, because you have to drive to base, anyway. That--this is the last one you have to visit, and then you go back to base, and the total time for this is, and I calculated this for you as a service, 167 minutes. So Dave has the same problem that Alice, Bob, and Carol also had. If he uses a simple or a naive algorithm to solve shortest tour, then this algorithm will not deliver an acceptable running time, because what a simple algorithm would do to solve shortest tour is that algorithm would simply try all possible orderings for the houses. So, what I just asked you to fill out in the last quiz, the computer would just go through all possibilities of saying this is the first house to visit, this is the second house to visit, and then go to the following house as the 3rd house, and so on. So we have not even needed to go deep into the details to see that this algorithm will quickly fail once the number of houses grows, because the number of possible orderings here will grow enormously with n where n is the number of houses. So, let's do a little quiz to make this more explicit. So, what I would like you to tell me is if we had 5 houses to visit, not counting the base we start from and get back to, but 5 houses where we can decide in which order to visit them, how many ways are there to visit 5 houses, and then how many different ways are there to visit 10 houses. You are going to need a program or calculator for figuring out at least the second one; the first one you can probably do in your head, but for this one you already need the computer to calculate the number. So the answer here is, there are already 120 possibilities to visit 5 houses. The way you calculate this is there are 5 possibilities for the first house, times 4 possibilities for the second house, times 3 for the third one, times 2, times 1. So it's the same as a factorial of 5, if you are familiar with that terminology, which is 120. For the second one, the number in different ways of which you can visit 10 houses, it's a factorial of 10, which is precisely 3,628,800. As you can see this number here grows enormously. Just to give you one more example. If we were to visit 15 houses, then the number of possibilities would be 1,307,674,368,000, which, as I'm sure you'll agree, is quite a lot. Even for a computer to handle. Now as you'll remember from the last unit, just having a huge number of potential solutions of course does not show that your problem is NP complete. But it can be an indicator if you cannot come up with any substantially better algorithm. Dave currently cannot come up with a substantially better algorithm, so he wonders could his problem of shortest tour also be NP-complete? That's why, together with Dave, we will now try to show that indeed shortest tour is NP-complete. To do that we will go through these 2 standard steps here. First of all, we have to show that the problem of shortest tour is in NP. To do that, as you'll remember from the last time, we actually have to state this problem as a decision problem. So here's our next quiz for you. How can Dave state his problem of shortest tour as a decision problem? Given a graph with distances, what is the shortest tour? That visits all vertices of course. The second option would be, given a graph with distances and a number d, is there a tour of length at most d? Given the graph with distances, how long is the shortest tour? Please check the problem statement that states shortest tour as a decision problem. As you'll remember from the last unit, a decision problem states a problem in a way that the answer is either yes or no. It cannot be the first one, because what is the shortest tour would actually have to specify that tour. It can also not be the third one, because given a graph with distances, how long is the shortest tour, that asks for a number. The only yes/no question is the second one here. In order to state shortest tour as a decision problem, we have the graph wtih distances as an input and a number d, in order to be able to ask if there is a tour of length at most d. This one here is correct. So now that we have shown how shortest tour can be stated as a decision problem, we still need to show that that problem is in NP, and for shortest tour, while it's not really that difficult, but it's actually a little bit of a hassle, so let's do another quiz here. Why is shortest tour in NP? So basically the question is: If we have nondeterminism, why can shortest tour then be solved in polynomial time? Is it because we can use nondeterminism to guess which vertices to put into the shortest tour? Is it because once once a shortest tour has been guessed using nondeterminism, the length of that tour can be checked in polynomial time? Is it because nondeterminism can guess a shortest tour, and by that I mean that we can use the better function to guess the tour here, so you would have something like this: if better visit vertex A, else visit another vertex next. Or, do we even have to show this? Because, actually, it's quite obvious. So, more than one can be correct. Please tell me which ones are. And there are 2 correct answers here. One is that we can use non determinism to guess a shortest tour. It's not totally obvious how to do that, because the if-better function always can only do 2 distinctions, so you have to find a clever way to use that function to guess how to construct a shortest tour, but it's possible in the way that I've showed you here. Then once the shortest tour has been guessed, checking if the length is shorter than D, and as you'll remember, D was the maximum length that we allow for it, because we are having shortest tour in the decision problem. Once the shortest tour has been guessed, it's easy to check if the length of that tour is smaller than D, so by easy, I mean it's possible in polynomial time, so this one here is also correct. Non determinism can be used to guess which vertices to put in the tour is--obviously doesn't make sense, because all vertices are part of the tour. It's the order of the vertices that matters for solving shortest tour. And then the final one, of course, that was easy to see that it's not really a viable answer, but I wanted to point out to you that even though it might sometimes be obvious, you should always make sure to explicitly show that the problem is in NP, and we'll actually, later in this course, come across some problems where you might initially think that they are in NP but actually they're much harder than problems that are in NP. So now, we have completed the first step. We know that shortest tour is in NP and now consider finding a polynomial time reduction from an NP complete problem to show shortest tour is NP complete. Now, before we actually do step two, let's have a brief review of what step two actually means. So, to show that shortest tour is NP-hard, which would then make it NP-complete, because we've already shown that it is in NP, what do we need to show? Do we need to show that the input for some NP-complete problem can be transformed into an input for shortest tour. And, of course, if this input here is a yes for this NP-complete problem, then it has to be yes for shortest tour here as well. If it's the no it's has to be a no. Or do we need to show that the input for shortest tour can be transformed into an input for some other NP-complete problem? Basically, I would like you to review here which direction these transformations work. Of course, we'll always make the assumption that the transformation is in polynomial time. And the correct answer, if you remember right from the last unit, is that we need to take some NP-complete problem and show that we can use shortest tour to solve that problem, so, this one up here is correct because, as I told you, a reduction basically means that we show that this NP-complete problem here, and we still have to choose a good one, kind of fits into shortest tour, so shortest tour is at least as hard to solve as this one up here. If it were the other way around, then you would just show that this NP-complete problem is at least as hard to solve as shortest tour, but that doesn't give you any statement about shortest tour, so this is the way we need to do the reduction. Now, it says some NP-complete problem here, so the question of course is: Which one is it going to be? Later in this unit, I'm going to show you a bunch of resources that you can use to find suitable NP-complete problems to do your reduction, because when you have a very similar problem, and that's what you've seen with vertex cover and independent set, then the reduction becomes much easier to do. We saw with SAT and clique, for example, that, if you have problems that are a bit different, then you might run into trouble. So, I'll give you those resources, but here's a general rule. If you don't find an NP-complete problem that is very similar to the one where you're trying to prove that it is NP-complete, then usually it's a good idea to start with SAT because SAT is in a way a very flexible and very universal NP-complete problem, so that's exactly what we're going to do here as well. We're going to try to reduce SAT to shortest tour. So how would we go about to reduce SAT to shortest tour, or how do you generally go about showing NP-completeness when the 2 problems that you have are not related to each other? So let's briefly just restate what the SAT problem is and the shortest tour problem, and then let's try to relate the 2 to each other. SAT was a problem where you were given as input a Boolean formula, and the output or question was, does the formula have a satisfying assignment? And of course that is a yes or no question because we're dealing with a decision problem here. And shortest tour, that's easy to remember because we talked about it a lot so far in this course. The input was a graph with distances, and we said we need a number d in order to make this a decision problem, and the question here was, is there a tour of length at most d? And by tour we mean that we want to visit all vertices at least once, but we can visit them more than once. So now comes the creative part. How on earth are we going to take a Boolean formula and turn this into a problem related to mail delivery? And it's not obvious. So what I always find useful to do in these cases is to just write down all the properties that a Boolean formula has, that a satisfying assignment has-- so anything I can think of for SAT-- and then write down properties of the shortest tour problem and see if I can find a certain relationship between them, because oftentimes that will give me an idea of how to accomplish a reduction like this. So let's see. Properties of SAT. The first one is each variable is set to either true or false but not both. So it's either true or false. And these are all trivial properties, but let's see if they help us. And actually, deciding whether a variable should be true or false is what makes this problem hard. So I can also write that down. So deciding this true or false for each variable is what makes SAT hard. Then what you will also remember is that when we talk about a Boolean formula, then we can write it in conjunctive normal form, which is this form here where we have a bunch of variables that are combined by an or and then brackets around that, then comes an and and then comes again a series of ors and then comes an and and so on. This part here we learned in the last unit was called a clause. So first of all, if there is a satisfying assignment, each clause must be satisfied. So how do you satisfy a clause? Since in a clause, as you remember, we just have ors between the variables, this means that 1 single variable, if it's set in the right way-- so either to true or to false if we have a variable with a not-- then setting 1 single variable the right way is enough to satisfy that clause. And so we should probably also write that down. One variable is enough to satisfy a clause. Let's see if we can do the same thing for shortest tour. What are some properties of a shortest tour? First of all, every city must be visited at least once because otherwise it's not a valid tour. The main decision we need to make is of course in which order we visit the city. And once we have visited a city, we can visit it again but we don't have to. And the final thing is we don't visit a city more than once on purpose. So at a certain point in time we might want to visit a city once more because it's beneficial, but in the shortest tour we wouldn't visit a city more than once unless it's necessary. So I'm going to phrase this as we don't visit a city more than once on purpose. Now, you might be wondering why I have left the numberings here blank, and that is because we are now going to have a little quiz here, because what I would like you to think about is here we have 4 different properties of SAT and here we have 4 different properties of shortest tour. I would like you to find out which properties of shortest tour are most closely related to these properties here of SAT. This is a bit tricky and subjective, but I think it's very valuable to learn this style of thinking. So before you hit Next out of frustration, please at least spend a little bit of time trying to figure this out, and then enter here the number that you think most closely corresponds over here. So if I were to say that deciding true or false is what makes SAT hard is a close analogy to every city visited at least once, I would enter a 2 here. But this is actually not a correct answer. And also I have structured it so that each number here will only appear once. So how are these 2 related? As I compare these 2, I would say that Every city is visited at least once sounds like each clause must be satisfied, so we must basically ensure that our satisfying assignment satisfies it at least once, so I think this one here is closely related to this one down here. The main decision is the order in which to visit the cities. That is what makes this problem hard and the analogous decision that you have to make for SAT is deciding which variables to set to true or to false, so I think these 2 are quite closely related. Then being able to visit a city more than once but not having to do so. I think that is closely related to number 4, because what we have here is one variable is enough to satisfy a clause, but of course, we can use more than one variable to satisfy the clause; it doesn't hurt if there's more variables here that will evaluate to true, so we can satisfy a clause in multiple ways, but we don't have to; one single variable is enough. And ten finally, saying that each variable is either true or false. I think--and this is probably the hardest one to figure out-- and that is actually quite closely related to saying that you don't visit a city more than once on purpose. It means you basically have to make a decision what city to visit next, and that is, in my mind, more or less close to saying I'm setting a variable to either true or false. Once you go along the shortest tour, you're always on your way to a new city, but again, I realize this might be a bit subjective here. Let's use this relationship to try and reduce SAT to shortest tour, and I think we should start out with this relation here. Deciding true or false is what makes SAT hard. The main decision is the order in which to visit the cities. So the important insight here is that if we should try and find some way to represent true or false as an order in which cities are visited and to assure through that order also that you cannot have ambiguous assignment of true or false, so basically, you have to make a decision in which order you visit the cities and that much represent either true or false and to figure this out, of course, that takes a lot of playing around with different networks, so even though I had learned the proof, I didn't quite remember how to do it, and it took me 15 or 20 minutes to play around on a piece of paper with a pen to find out how it could represent true or false variables as an order in which cities are visited, and there's many possibilities, but I'll show you what I came up with and then explain that to you. So, I'll start out with a very simple graph here. Let's say in this graph you wanted to get from A to B. I've purposefully not added any distances to the edges here, because we will just assume that the length of each edge is 1. Now, if you wanted to get from A to B, what would be the length of the shortest path from A to B that visits all vertices. Please enter your answer here. And the answer here is 7, so one example would be 1, 2, 3, 4, 5, 6, 7. Now, how many different shortest paths are there from A to B? Please, again, enter your answer here in this box. The answer here is that there are 2 different shortest paths from A to B. Starting out at A you can either go up here, then down here, then up here, then down here, then up here, or you can go down here, up here, down here, up here, down here. There is no other possibility of getting from A to B while visiting all vertices and only taking up 7 edges. Now let's draw this a little bit longer. Again I'm going to ask you 2 questions here. The first one is again that I would like to know from you the length of a shortest path from A to B that visits all vertices. Please enter this here in this box. I would also like to know from you how many different shortest paths there are from A to B. I would like you to enter your number here in this box. And the answers here are that the shortest path from A to B has length 10, so, for example here, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, and the number of shortest paths from A to B is still 2. If you start on A, and once you've made the decision to go up here, the only way to continue the shortest path is like this, because otherwise he would be visiting a city more than once, and then the path gets longer than 10 edges. If, on the other hand, you start out by going down, then there is no other way to go along the shortest path than this here. So again there's 2 diffferent possibilities of going from A to B along the shortest path that visits all vertices, and the length of that shortest path is 10. Now I am very sure that you have figured out a pattern by now, so let's draw a really long one. Of course, I'm going to ask you the same questions, but this is the last time I'm going to ask you those two questions. So, please once more, what is length of the shortest path from A to B? And what is the number of shortest paths from A to B? By shortest path, I mean one that visits all vertices, as in the examples before. The answer here is that the shortest path from A to B that visits all vertices has length 19, so 1, 2, 3, 4, 5, 6, and so on. You can recount if you don't trust me by now. The number of shortest path from A to B, that again is 2. So having these 2 possibilities of a shortest path that visits all vertices from A to B either going this way or going this way. That is in some way very similar to setting a variable to true or false, isn't it? Because, if I want you to go from A to B as quickly as possible while visiting all vertices, then there are only 2 choices that you have. The interesting thing is that, in one of those choices you always take the edge that goes from bottom left to top right, so this one here, this one here, this one here, and so on. If you start out by going down right, then this is what you will do at any other edge here as well. There's no shortest path between A and B that mixes up these 2 possibilities, so that takes some of these edges here and some of these edges here, and this is exactly what we're going to use to represent a variable being set to true or false. So what I'm now going to do is--I'm going to take the structure here, make it a bit smaller like this and take away the NP here, and we are going to reappear in a minute. What I'm now going to do is I'm going to put a bunch of these structures together. So connect this one edge, connect this one edge, and we're also going to do one here and now call this one A and this one B. Now, what you see here is that I have taken three structures like these and put them between A and B. I'm going to do this more generally now. Imagine that instead of an edge here, I could have more of these structures. I'll just write three dots here and these will represent additional copies of this structure being in between here. So in total, I will have n copies of the structure--n times this structure here appears between A and B. And now my question is, how many shortest paths between A and B can you have that visit all of the vertices here. If you have n copies of that structure, is that n², is that 2^n, or is that 2n. The answer here is that if you have n copies of this structure here in a row like this then there are 2^n different shortest paths from A to B that visit all vertices. And the reason why that is is that each time you encounter this structure here there is the two possibilities that we talked about. You can either go this way up here or you can either go this way down here and then you have to continue this way until you get to one of these edges here and then you can redecide if you want to go up or you want to go down. There's two possibilities for the first one, two possibilities for the second one, and so on and so on and so on, and two possibilities for the last one. Two multiplied by itself n times is 2^n. And this actually doesn't look too bad, does it? Because each of these gadgets, if you will, that I've drawn here could now represent a variable in a Boolean formula and each shortest path between A and B is kind of a true-false assignment to those variables. We could say for example that whenever we choose our path from A to B to go up here and then like this, this structure here or this way to do the path. Now that represents setting the variable to true so this here which represents x₁ for example so then going this way would mean x₁ is true. Going the other way, so down, would represent false. This would be a way to represent assignments of true and false to the variables x₁, x₂, and so on through xn. Now of course choosing the path between A and B is still totally arbitrary. What we are missing is the clauses of the Boolean formula. And again it takes a bit of playing around to find out how we can represent clauses here in this picture. To figure this out, let's have a look back at our picture from before. We said that in a set formula each clause must be satisfied and set this is kind of similar to the requirement that each city must be visited at least once. This would suggest to add some additional vertices to the picture that represent clauses. So let's say we have one vertex here that represents clause #1 and another vertex here for clause #2 and so on. What we could say is that visiting this vertex here represent satisfying that clause and then of course, we need to make sure that we can only visit the city here if the corresponding variable or if one of the corresponding variables of that clause is satisfied in the right way. What about a construction that looks like this--I connect the vertex that represents the clause to this one here and I connect it to this vertex here and I connect it to this vertex here. What I would like you to think about now is the following, there are 2^n shortest paths between A and B if we do not regard this vertex here. If we do not have clause 1 and I realize it's not the best name for that vertex but that's okay. If we have to visit this vertex here, so it's now become part of our graph. How many shortest paths from A to B do you have then that visit all vertices. Is it still 2^n, is is 2^n⁺¹, or is it 2^n⁻¹. Now comes the interesting part because the answer is 2^n⁻¹. The important thing to notice here is the following. You still have two possibilities of visiting this part here. So there's still two possibilities. And you also have two possibilities for this part here and all of the other ones in between as well. But here something interesting happens. If we choose to travel up here then down here then it cost us one extra edge to visit clause #1 as opposed to if we had gone from this vertex here to this one directly. Just one extra edge. Now what would happen if we go down here? If we were to visit this vertex immediately then we are over here, which means we haven't yet visited these two vertices here so we need to go backwards, then up here, and then back. Something like that--so this is not going to be a false path because we're starting to visit cities multiple times and even if we tried to do it another way so maybe just visit this here first then we can't go down here again because then we would again visit cities twice. Also going over here, then up here, then backwards through this and also revisit this city here twice. What you can see is that on a shortest path if we want to visit this vertex down here then we must take this route. If we do not have to visit this vertex, then we don't have to take this route then we can still chose arbitrarily. The number of shortest paths between A and B, if we have to visit that vertex, has been reduced and that is pretty neat because that means we can only visit this vertex here on a shortest tour if we are going the right way and now you can already see the relationship. If we connect this clause here to this part here, which represents a variable in the right way so that we can only visit this city if the variable is set in the right way because we said going up here means true, going down here means false, then we can ensure that a shortest path from A to B visits this vertex here, which means that we can also have a satisfying assignment for this clause here. And I'll illustrate this for you in more detail. Let's say we build a graph like this. We have a structure that represents the variable x₁. We have a structure that represents the variable x₂ and a structure that represents the variable x₃ here, and we have a clause that say, it goes like this--x₁ or not x₂ or x₃. And what we said with regards to the past between A and B, we said that going this way means true and going this way means false. So what we'll do now is we have x₁ here in this clause, we will connect this vertex over here and over here. What that means is that we can visit this vertex here for just one extra edge as long as we're taking the path--that means x₁ is true. Here, this is not right because we have not x₂, so we have to connect it in another way-- we have to connect it in exactly the reverse way because then when we take the path that means x₂ is set to false, then not x₂ becomes true and again, in that case, we would want to be able to visit this vertex here for just one extra edge. Now, my question to you is--how would I have to connect this vertex here to this part here of the graph that represents x₃. Would I have to connect it in this way or would I have to connect it in this way. Please check the one that is correct. This case here is correct for the following reasons, x₃ is just as it is--there's not a not. What that means is that if we take the path that signifies x₃ is set to true and we know that is the path that goes like this. Then we want to be able to visit this vertex here by paying so to say just one extra edge, so that's exactly this one here. If we had not x3 here, then this answer here would have been correct. It seems like this is actually a good idea to show that any Boolean formula can be transformed into a graph such that the shortest path between A and B tells us whether the original Boolean formula had a satisfying assignment or not, but of course we haven't proved it yet and that is why we will now have to go into gory details in order to actually prove that we can reduced SAT to shortest tour. We started with an input to SAT, and that is going to be a lean formula with n variables and these are going to be as always x₁, x₂ and so on until you reach xn. And we are also going to specify the number of clauses and I'm just going to use the letter m here so we're going to say we have m clauses and I'm also going to give them names so I'm going to call them C₁, C₂ and so on until you reach Cm. We're now going to construct a graph that represents or encodes this Boolean Formula here and we are going to do this just as we have done before. So, this part here is going to represent X₁. This part over here is going to represent X₂ and so on and this one here Xn. Now, the question of course is how long these parts for each X need to be, and that depends on the number of clauses because we're going to attach clauses to the variables here. In order to make this safe, we should construct this part so that we have m of these edge crossings here because then we know that for each clause we have an edge where we can attach that clause to. Now, if we have m of these crossings here this means that we have m+1 of these groups of three vertices here so we have 3(m+1) vertices in this part here and then we have one more vertex here, one more vertex here so +2 if we extended like this, and this holds true for all of the other parts here as well. Now, for each clause but of course also going to add a vertex like so and again this vertex here is going to represent clause 1 this vertex here is going to represent clause 2 and so until we get to clause m. My first question for you is how many vertices are we using to represent the variables so to represent x₁, x₂ and so on until we get to xn and I would like you to enter this as four numbers and so it's going to be some number times n plus some number times m plus some number times mn plus possibly some constant. Please give me these four numbers here to correctly count the number of vertices that we have here to represent variables. The correct answer here is that the total number of vertices to represent the variables is 3<i>(n+1+2), so the number of vertices to represent one variable times n.</i> We have 3(n+1)+2 and the whole thing times n, which is equal to 3mn+5n. We have 5n, 0m, 3mn, and a constant of 0 here again. Then what is the total number of vertices for the clauses? The answer here is very simple, we have one vertex for each clause. We have 1 m vertices for the clauses. All other coefficients of this answer here are 0. The only vertices that we haven't counted yet are A and B, so there's two additional vertices, and now we know the total number of vertices that we are using here in our graph that is 5n + m + 3 mn + 2 vertices in total Now, let's assume that we had the clause vertices connected to these variable gadgets here. Of course, in the same way that I showed you before, so that the clause vertex can be visited like this--paying one extra edge instead of going here if the clause can be satisfied and we're traveling along this gadget in the right way, then otherwise it will cost us more than one edge. Now my question for you would be--so if the Boolean formula has a satisfying assignment, what is the length of the shortest path from A to B, and by shortest path, I again mean one that visits all vertices. I want to give you the answer as before something times n plus some number times n plus some number times mn plus some constant. Now, the important thing to understand to be able to figure this out here is that if the Boolean formula has a satisfying assignment then a shortest path from A to B that visits all vertices can visit each of these vertices by basically paying just one extra edge. Instead of going this way, we have to go this way exactly once for each clause. The length of the shortest path from A to B that visits all vertices is the same as the shortest path from A to B that does not visit the clause vertices plus m because we have to pay one extra edge for each clause vertex that we visit here. It's something plus m and we know that there is a path between A and B that visits each vertex exactly once, and so, the path length from A to B is almost the same as the number of vertices, it's just one less, so you can see this here in the example. If I have two vertices then the shortest path would mean those vertices is one so one less If I go 1, 2, 3, 4, 5 vertices then the path has length four and so on. What we have here is 5n + 3 mn +1 and then we have to add m. Our total here is 5m + 3mn +1. And now, we are almost done. We have shown that if the Boolean formula has a satisfying assignment then the length of the shortest path from A to B that visits all vertices has length 5n + m + 3mn +1 Where n is the number of variables and m is the number of clauses. Now, we also have to show the other direction of course. If there is a shortest path between A and B of length 5n + m + 3mn +1 then each clause in the Boolean Formula can be satisfied. We have a satisfying assignment. Right now, we have shown that if the Boolean formula is satisfied then we have a path of this length and now, we need to show the other direction as well of course. If we have a path of this length then the Boolean formula has a satisfying assignment. Why do we need to show those two directions? That is because the requirement for reduction is that our new instance that we constructed here is a yes instance if and only if this Boolean formula up here has a satisfying assignment Right now, we have shown the if and now, we have to show the only if, but this is actually quite easy because if we know that there is a path between A and B of this length here then we already know that each vertex is visited exactly once because this is the bear minimum of a tour between A and B given this many vertices. Secondly, we know that the tour will correspond to a variable assignment It will correspond to an assignment of true and false to these vertices here because otherwise we would visit a city more than once. We've already shown that and finally, we have also shown that each clause can be satisfied because we can only visit a vertex down here like that with paying just one extra edge if the assignment up here corresponds to a satisfying assignment. And now, we are almost done in showing that shortest tour is NP complete. I don't know if you noticed, but there is one small detail missing Right now, we are only going from A to B and we are asking for the shortest path from A to B. We are not asking for shortest tour yet and that is actually quite easy to fix. We'll just remove this vertex B here and make this edge very, very, very, very long over here and then it's not the length of the shortest path from A to B anymore, but it's the length of the shortest tour. And of course, that length is only true if and only if the Boolean formula is satisfiable And we're done. We have reduced SAT to a shortest tour. We have shown that shortest tour is in NP. So, now, our final conclusion this problem here is NP-complete Of course, it's a bit ironic that showing that a problem such as shortest tour is NP complete can sometimes feel like solving an NP complete problem in itself. That's why I would now like to show you how to even further simplify that problem is NP complete. So, is showing the NP completeness of a problem always so involved with playing around with strange constructions such as weird networks? Well, the answer is in a way yes. Showing NP completeness can often involve playing around a lot and some gory details in the proofs. So, even today, there are still scientific papers being published that basically just show the NP completeness of a certain problem or set of problems. So, it is not an easy task, but luckily, there is a whole arsenal of known NP complete problems out there which I'm now going to show you. If you go on Wikipedia, for example, there is a whole list of NP complete problems from graph theory, network design, sets and partitions, and so on and so on. So, for most practical problems that you will encounter either they have already been shown to be NP complete or although likely be very similar to one or more of these problems for which we already know that they are NP complete. In this case, similarity is a good thing because similarity means that a reduction will, in most cases, be either much easier than what we have just seen with shortest tour or, at least, if you then look at the NP completeness proofs for those problems, then I give you techniques and ideas for performing the reduction that you are looking for. The foundation for this library was laid by a computer scientist called Richard Karp who, in 1972, showed 21 different problems to be NP complete, and that was basically the starting point for this huge list of thousands of NP complete problems. Now, let's see if you already have an intuition which NP complete problems would be most useful to show the NP completeness of other problems. So, let's say you encounter a number of problems. One problem will deal with clustering or finding large groups of related objects or you would encounter a problem that deals with covering a set of object as efficiently as possible. So, you have to select a few objects that is some way observed or-- no, covering is a good term other objects in the set or you could encounter problem that in some way deals with optimizing pathways. So, getting from one point to another point but there are few constraints up here that you have to meet. Here, you are trying to find clustered groups of related objects. Finally, you could deal with a problem that is about diversification. So, large groups of independent objects don't have anything to do with each other. And finally, something else. Now, you already know the five NP complete problems. You know the shortest tour, you know vertex cover, you know SAT, independent set, and clique. Now, what I would like to know from you is if you encounter a problem that basically arises in one of these five situations here which of these problems here for which we know that they are NP complete would be your best bet for proving a problem that falls into one of these categories here is NP complete. So, basically using this as a basis for a reduction. So, these are numbered and you can enter your numbers for the ones that you think match best in these circles here. Now, of course, this overview is super subjective and far from complete and also maybe not always correct but nevertheless. I think clustering or finding groups of related objects, usually it's a good idea to try to do a reduction from clique. Covering a set of objects--that is basically the problem that Alice was looking at for her Telecommunications Company. Vertex cover is usually a good idea and there are certain generalizations of vertex cover called hitting set that can also be a useful tool in proving that problems like these are NP complete. Optimizing pathways--well, yeah that is shortest tour and also here you should know that shortest tour has a very closely-related problem and that is the famous traveling salesman problem. They are not the same but they are very, very close. Traveling salesman is basically shortest tour, but you cannot visit a vertex more than once, so it's enforced here, and traveling salesman or the shortest tour problem here, it is always a good idea to try to use these problems for a reduction when you want to show that a problem that deals with optimizing pathways under constraints is NP complete. Now, diversification/independent objects--yeah. If you're a bit test savvy, you would already have guessed. This is, of course, independent set, and then, finally, something else. Well, you use our general tool and that is SAT. We already have a pretty good tool set for NP completeness. We have SAT. We have vertex cover. We have independent set. We have clique. And we have shortest tour, and I guess also traveling salesman. In some way, it's amazing, isn't it? that all of those problems here are NP complete, which means in a way they are equally hard to solve, although they are all quite different. Now, I promise you a library of NP completeness. What I'm going to give you now is four additional NP complete problems that are often very very useful for showing NP completeness or also for recognizing NP completeness, because even before you do a formal proof, it's usually a good idea to say, "Oh, this problem just looks very close to SAT. We better be careful. This could NP complete." You don't always have to do the formal proof. It can also be a good indication of how hard a problem could be. Before additional problems, I would like to show you a problem called 3-SAT, a problem called k-coloring, a problem called packing, and a problem called common substring. So 3-SAT is basically SAT, but there's one restriction and that is that each clause has exactly three variables and that of course is a nice assumption to make in many proofs of NP completeness, because if you have exactly three variables in each clause, these proofs often become easier to read and much cleaner. As a side info, 2-SAT so where each clause has just two variables, a solvable in polynomial time. So one number here can make a difference, and the resulting 3-SAT formulas look like this. So you have three variables here in this clause then three variables here and of course with another index and so on. K-coloring asks if you can color a graph with k-colors so k is given as part of the input. And what is meant by coloring is that you give each vertex a color such as here. So we color this one red, this one red, this one green, and this one also green. The constraint is you cannot color two vertices with the same color if they are connected by an edge. So this here would not be allowed, and actually, the graph I've drawn here cannot be colored with just two colors so you need three colors to color this graph. This here for example would be one solution. It cannot be number two. And of course that's stated as a question. So is it possible to color the graph using k colors? For packing, you have given a number of containers and objects. And the containers have a capacity, and the objects have a value and a capacity requirement. So you have containers like these that come in different size and then you have objects. You have little objects. You big objects. You have very big objects. And they all have different values. So this might be not so valuable. This might be a little bit valuable, and this might be very valuable. So usually you cannot put all of these objects here into the containers. So the question is what is the maximum value that you can put into the containers? And of course, you could have the case that, for example, the bigger object is actually worth less than the smaller object so there are lots of different combinations here and will actually investigate this problem a little bit more in one of the next units. Now, common substring is actually a misleading name because some people use this in a wrong way I've seen this happened before. It actually should be called common subsequence. If somebody says common substring, better ask them if they don't mean common subsequence because common substring is actually not an NP complete problem, and common subsequence is the following problem. You're given two strings so string one and string two. Let's say lemonade and blender. And what's the difference between a substring and a subsequence? A substring is always lots of characters that are one after the other. For a subsequence, you can basically skip certain characters. So e, n, a, e is a subsequence of lemonade but not a substring. And actually, we will do this as a little brief quiz. What is the longest common subsequence of lemonade and blender? And the answer here is 5 because you can take the L, e, n, d, e, which you also find here-- L, e, n, d, e--so here's the sequence. Here's actually a substring so that contains common subsequence of length 5 between those two strings. Now just to familiarize yourself with these problems a little bit more, I would like to do the same thing that we have done here for these five problems. I will now give you a number of practical scenarios. What I would like you to tell me is which of these problems would probably be most useful for attempting an NP completeness proof? So again we will give these problems here numbers, one, two, three, and four, and I will give you six practical scenarios where you can then choose which problem to match to the scenarios, so you could have a scenario in Bioinformatics, but you would like to compare DNA sequences to each other. And what you are trying to find out is how much information they have in common. You could have a scenario where you want to schedule computer programs. What I mean by this is you have a bunch of computer programs. You know approximately how much time you took those programs is going to take. And you have a number of machines and of course you want to get as much work done as possible within let's say the next hour so you have to decide which program to run on which machine or you could have a question about let's say classrooms where you say, "How many classrooms do we actually need for the next semester to teach our courses?" So there will be certain courses that take place at a certain time or that cannot be scheduled together. A new question is how many different rooms would we actually need? Or you could have the scenario where two programmers have been working on the same programming code. And one of the programmers has made some changes and the other one has made some changes. And now you need to get these two codes back together again, and you do that by figuring out what they actually still have in common. Another problem could be that you have a number of vans or delivery trucks that you would like to fill and you want to find out how many vans you need to transport all of these packages here. They have different sizes. They have different priorities and so on. And finally, a scenario that is none of the above so something else. Please match the practical scenarios to the NP complete problem that is most likely to occur in that scenario, and I want you to do this by entering numbers here that correspond to these four problems. You'll have to use some of these problems here more than once. And now, of course, the answer is a little bit subjective because, since all of these problems here are NP complete, you could basically try an NP completeness reduction from anyone of those, but we were looking for similarity; so, bioinformatics comparing DNA sequences? Yes, that is a lot like common subsequence especially if those sequences have certain insertions and deletions in them. Scheduling computer programs? That is most often a problem related to packing. You have a number of programs and the number of machines and you need to match programs to machines as best as you can that is almost the same as putting packages into containers so that they are optimally filled. Actually, scheduling is almost an individual class of NP complete problems. If you look at the Wikipedia page that we just looked at, you should find a couple of problems in the section scheduling. Are K classrooms enough? That can be stated as a coloring problem. If you have a number of courses, and for some reasons, these courses cannot be held in the same room, then determining a minimum number of rooms can be the same as determining a coloring in that network. For this course here, we are using the red classroom, and for this room here, we're using the blue classroom, and for example, if you wanted to use the blue classroom for this course as well, that doesn't work because we have a connection here. You have to use another one here and of course another one here. That doesn't work as well, so four classrooms. Merging the source code of two programs have been working on, that is a common subsequence problem because the program as will have modified certain parts, will have deleted certain parts, possibly inserted other parts, so we need to find out what the true programming code still have in common. Filling vans? Yeah, that was an easy one probably. That is a classical packing problem because you're actually using packets. Something else always calls for the universal weapon and that universal weapon in the case of NP completeness is 3-SAT. Now, you have a library of one, two, three, four, five, six, seven, eight, nine, ten NP complete problems which are a good basis for showing NP completeness. Whenever you come across a problem where you think that it might be NP complete. You can use these problems to go through the three steps of proving NP completeness. Stating your problem as a decision problem and then show that it is in NP, and finally, use one of these problems here or some other problem that you know to be NP complete for a reduction. To find additional NP complete problems, you can either go to the list in Wikipedia that I showed you or you can see if your local university has a book on NP completeness. One of the most famous ones is this one here called by most simply the Garey & Johnson, but there are also other books that will give you a number of NP complete problems that you can use as a basis for a reduction. Now, before the end of this unit, two words of caution. The first one is that the border between NP completeness and polynomial time can sometimes be very thin. I already mentioned to you that for example 3-SAT, so where you just have three variables in each clause is NP complete but 2-SAT where you just have two variables is solvable in polynomial time and there are many other cases like that but of course this is good news because if your problem turns out to be just as hard to solve as 2-SAT you actually have a polynomial time algorithm for it although it might initially have seemed a bit harder or sometimes even if your original problem possibly is as hard as 3-SAT maybe you can look at a slightly different problem that becomes polynomial time solvable. Because oftentimes there are many different ways to frame the practical problem that you're trying to solve so sometimes you're lucky there. The second thing is an actual word of caution. Because this border here can sometimes be so fragile. It's very important to be precised in your NP-completeness proof. Because sometimes making just a little mistake in an NP-completeness proof can invalidate this whole proof and of course we don't want that. Now, it's time once more to congratulate you. You now know what NP completeness means and how you control NP completeness. And actually not many people can do that. Very few people know precisely what NP completeness means and also they're not capable of showing NP completeness. In the next unit, we're going to take you even one step further. We're going to show you countermeasures against NP completeness. Because even most people that understand what NP completeness means and that can also show NP completeness actually tend to give up once they've shown their problem to be NP complete. But that's actually not necessary because there are many many techniques that she can use to attack even NP complete problems. What should you do when you want to solve the problem and show that is NP complete? Should you carefully check your proof? Should you have somebody else carefully check your proof? Should you give up? Should you maybe try to think about ways of modifying your problem so that it could not be NP-complete or should you try to use the techniques that you're about to learn in the next units of this course. And of course, the only thing you shouldn't do is give up. Everything else--yes. Carefully check your proof. Have somebody else check your proof. Maybe the NP completeness isn't there, and if your proof is correct, think about modifying your problem--maybe it becomes easier on that case. And finally, look forward to the next units where we will discuss countermeasures against NP completeness. How can you deal with an NP complete problem if you can't avoid it and a simple algorithm doesn't work. Well, unless P=NP, you know there's not going to be a polynomial time algorithm for your problem. Now, that statement actually allows for some loopholes, which we'll investigate in this unit and the following units. The first loophole is to try and find intelligent algorithms that allow you to search through an exponential number of solutions still on exponential time, but so efficiently that sometimes you actually get a perfect solution. The second case we'll be looking at is if you accept that your solution is not going to be the best possible one but maybe within a certain range of the best possible one if you can then find faster algorithms to solve your problem. For each of these approaches, we'll be discussing the main ideas. I'll give you some examples and of course, we'll also be discussing a bit of the theory behind them. So far, our units have focused on showing that problems are hard or NP complete to be more precise. Actually, what I have very often observed in practice, and even in scientific papers where the office did not have a solid background in theoretical computer sciences is this. Once a problem is shown to be NP complete, many people would just tend to give up or come up with some, well honestly terrible algorithm that they've justified with. Well, the problem was NP complete, and that is why we're now going to turn our attention to count the measures against NP completeness. So, this unit and the following units are your first aid kit to help you overcome NP completeness or at least take a bit of the sting out of it because imagine you find yourself in the situation like the four computer scientist that we have gotten to know throughout this course like Alice, Bob, Carol, and Dave. Solving tough problems was part of their job. Alice was solving vertex cover for telecommunications; Bob was working in biotech developing new medicines, analyzing genes; Carol was working in finance designing secure investments; and Dave was working in logistics where he had to solve the shortest tool problem and actually there are logistics companies who developed algorithms with which they save millions everyday and also fuel. So, those problems are practically relevant although they are NP complete. So, when your company or your boss asked you to solve an NP complete problem, what should you do--should you say, "I want another problem," should you make her or him take this course so that they finally understand NP completeness, should you say "It's impossible to do that," should you say "It's proven impossible," or should you say "It's proven difficult but we can try." Of course, this was a bit of a simple inter quiz here. Yeah, probably that's not a good idea. Making anybody take this course is a very good idea, but of course, actually you're the computer scientist so you're supposed to be the one knowing about NP completeness especially after taken this course. You'll probably shouldn't say it's impossible. A better answer would be to say, "It's been proven to be impossible," but I think that after this unit, you will agree that the best possible answer is actually to say, "Well, it's been proven difficult or extremely difficult," but we can actually try to solve this problem even though it is NP complete and I will show you how to approach that. The thing is this--there's so many NP complete problems that are practically relevant that over the past years extremely clever algorithms have been developed for these problems. They have been developed for vertex cover, for clique, for independent set, for the shortest tour problem, for SAT, and so on. Knowing about these problems can really make you standout as a problem solver because many people, as I said, will give up once they know their problem to be NP complete. You should respect NP completeness, so maybe not be all smiling when you encounter NP complete problems, although it's nice to know that they are happy but I don't know. When they're solving their problem, be respectful but there's no need to be unhappy or scared of NP completeness. How can you deal with an NP complete problem other than avoiding it. Well, I think you should think of yourself as kind of a lawyer who has to work with the laws of NP completeness and the main law of NP completeness is this, unless P=NP, there will be no polynomial time algorithm for your NP complete problems. Now, what do good lawyers do with the law. They find loopholes and that is exactly what we are going to do for this law of NP completeness, and we're actually be looking at two loopholes. The loophole that we will be exploring in this unit is using intelligent exponential time algorithms. We're going to work in exponential time but we're going to do it in a smart way. We're going to avoid things like 2^n or 3^n, but rather we're going to have algorithm set for example I have something like 1.3^n, which is already much better and works for many practical cases. What we are then going to look at in the next units is what I like to call sloppy solutions. For all proofs of NP completeness, we always require the computer to provide the exact answer to our problem. One chance to circumvent NP completeness might be to say, "Well, we do not want the best possible solution, but we're happy with say one that is close to optimal" or for a decision problem for example, we might be saying, "Well, it's okay if we get the right answer in about 80% of the time." For each of these approaches, we will discuss the main ideas and also of course, give you some examples to make them more clear and talk a bit about the theory behind these approaches because these are techniques where you really have to understand the theory if you want to be successful in practice. So let's start out with smart exponential time algorithms. And we are going to kick this off with a little quiz. So let's assume that we have an algorithm with a running time of 2^n n², not O(2^n)n², but really 2^n n². You can add any constant you wan if that makes you happy but not so the point of this quiz here. And now we're going to look at an algorithm that is 10 times faster, so it has a running time of 2^n<i>n²/10.</i> And if you think about it, finding an algorithm that is 10 times faster is actually huge in practice. So imagine for example that whenever you start your computer, it would start 10 times faster than it does now--a huge improvement, but what I now want to show you is that such a huge improvement is virtually useless when you're dealing with exponential time. So assume for example that for this algorithm here, we have a computer where the maximum input size that it can handle is 30, what I would like to know from you now is if we run this algorithm which is 10 times faster, huge improvement on the same machine what is the maximum input size we can handle then. And I would like you to give me your answer here in this box. And the answer here is in some way surprising. Although we have a 10 times improvement, we actually cannot handle an input that is much larger. We can only handle an input where n is 33 or smaller, and the way you can figure this out is as follows-- If the maximum input size we can handle is 30, then the number of time steps this algorithm over here takes is 2³⁰ 30², which is 966,367,641,600 time steps. So already a rather powerful computer at work here I would presume. What if we have an algorithm that is 10 times faster. Now, 2³¹<i>31²/10 is about 206 billion, 2³²<i>32²/10=440 billions--that is still smaller than this</i></i> and 2³³<i>33² is about 93 billion, so slightly smaller still than this one here.</i> If you increase it to 34, then this number here will become larger than this one over here. We've put lots of effort into our algorithm to make it 10 times faster and we have gained only very little in terms of input size that we can handle. Now, what if we were even bolder and had an algorithm that was a 100 times faster. Imagine a 100 times--imagine your computer booting up a 100 times faster that it does today or your computer game not running at 30 frames per second but at 3000 frames per second, so 100 times faster--shoot speedup. What input size can we handle now? The answer here is almost depressing. Now we can handle a maximum input size of 36 even though we have a 100 times speedup, and the argument is basically the same as before. Again, you compare this number her for n=30 to this number here and then see when this one gets larger than this one over here. And that is why it's so important to understand algorithms and improve algorithms because if you do any optimizations that are a constant factor even if it's a huge constant factor, it doesn't really increase the performance of your algorithm if you're dealing with exponential time algorithms. So you really have to dive down and understand your algorithm and then improve it. Now, before dug deeper into the more sophisticated algorithms, I would like to briefly tell you a little about a technique known as brute force. So what does brute force mean? Does it mean that we take a hammer and beat the answer out of our computer? Of course not. Brute force is the algorithm that Alice, Bob, and Carol were using initially. So, you remember, for example, that for Bob, we were using an algorithm like this or not using but proposing an algorithm like this at least that simply went through all possible assignments of zero and one to the vertices, or at that time, we steal common genes and weakness of this algorithm was that it had a pretty unacceptable running time as soon as you got to more than 20 or 30 vertices in the network. But this algorithm actually also has two strength. One strength from it is that it's very simple, and the other thing is that, because it's so simple, you can actually also implement it rather fast. Under certain conditions, using an algorithm like this, actually might not be that bad an idea in this method of using all possible assignments. First of all, we're not confused the hammer here. This method if going through all possible assignments without any more sophisticated techniques or sophisticated algorithmic techniques is known as brute force. And so, as I've explained to you, there are certain conditions for brute force is actually desirable. So, let's have you figure out what those conditions could be, and by brute force, of course, we try all possibilities. Could it be that when you don't have much time to design and program a more sophisticated algorithm. Could it be when the instances where the inputs for which you're trying to solve your problem are small. Say n is the size of the problem smaller than 20 or could it be when you need to solve the problem only once and the input might be a little bit bigger there. For each one, I'm going to give you two choices whether under these conditions using brute force could be okay and the first one is a maybe and second one is a definitive no. I'm not going to give you a clear yes choice because, obviously, since we're dealing with NP complete problems here, brute force is never generally advisable of course. And, well, it's a bit of an opinion here but I would say that--actually for each three of these, you could say maybe, so if you don't have much time to design and program an algorithm, then brute force might be okay under certain conditions. For example when your instances are small and you have proper time to run the algorithm, then brute force might actually be a good idea because it's your time that you invest into programming a more sophisticated algorithm. If it's your time that counts and not computer time, doing brute force is sometimes actually a good solution. Whenever the instances are small, there's two reasons to us brute force. One is because you can implement it very fast, but the other good reason to us brute force in these cases here is that because brute force algorithms are so simple they can be programmed with very little overhead, so what I mean by that is that the constants that are involved in the O notation are rather small and for small instances, such speedups actually play a role. For small instances, it could be a good idea to use brute force, but again even for the small instances, it might not be fast enough. What you need to solve a problem only once--that might also be a condition where a brute force could be okay--that might mean that you have a lot of computational time available. Say you need to have this problem solved within the next 3 months or 6 months, maybe then brute force is kind of fast enough. Of course, in this case down here, I think that's the most debatable. You might want to try some of the more sophisticated techniques that I'm about to show you. But first of all, let's play a little bit more with the numbers. Let's say I make the following table here. This is the number of instances you need to solve--say 1, 100, 10,000 and this is the size of the instances, and this is the size of the instances, so smaller than 10, smaller than 20, smaller than 30 or larger than 100. And now let's say you have algorithm that has running time 2^n. We'll simplify this here, so as the running time is 2^n, no O off, no polynomial involved. All I want you to get here is a filling full of numbers. Now, what I would like you to think about is in which case you see a brute force would be something to try out. If you think that you should try brute force either you're sure about it or it's at least something to think about, then I would like you to make a check mark in these boxes here and otherwise, leave the box blank, and of course, this is very subjective. If we don't agree, just click next and let's discuss where we don't agree. So 2^n, if instances are smaller than 10 that means that the running time will be around 1000 time units or 1024 time units to be precise. If it's 20, you will have about 1 million time units. If it's 30, you will have about 1 billion time units. So 1 thousand times 1 thousand times 1 thousand. If it's larger than 100, then of course you have a huge running time here. You will have a running time that is about 10³⁰. It's clear that when your instances get larger than 100, you would not be able to use brute force. And on the other hand, if you just need 1000 time units, I think you don't even care if you have 1 instance or 100 or 10,000 because if you think about it a current desktop computer is running on gigahertz so it can perform several billion operations per second. Even solving 10,000 instances where each one is small is usually not an issue unless you're working in a very special environment. What about a million time units? I would clearly say well solving that once is okay. Again, your computer can perform several billion operations per second. Solving 100 instances is usually okay and even solving 10,000 instances. So 10,000 times 1 million that's 10 billion, which sounds like a lot but actually again desktop computers can handle this in most cases. Now what about this case here? Well, 1 billion is okay. We just said that over here. And we said even 10 billion was okay. So what about 100 billion? Well, this I think here is kind of debatable but I would still say it's worth a try probably. Then you have to probably wait for two or three or four days until all instances are solved or maybe even one month but in most cases that should be okay. You wouldn't even attempt to solve NP-commplete problem in real time for example. This one here I think is the most debatable. So 10,000 billion I would say in a general case you wouldn't want to do that. I mean, there might be special cases if you work for the secret service and you have a huge cluster of computers available but here you're kind of reaching the limits of brute force and here of course as we just said you've already reached that. So again, brute force can work if the instances are small or maybe even moderate but this approach is bound to fail at some point and that's when to apply intelligence instead of brute force using intelligent force. So let's have a look back at the laws of NP completeness, and the laws of NP completeness, of course, is a book that only holds unless P=NP. If anybody ever proves P=NP, then we can recycle this book here or delete the e-book. So what do the laws of NP completeness say--they say, "No polynomial algorithm." So now it's time to think like lawyers and try to put loopholes into the statement here and there's two loopholes that you can poke into this. One is that we only say, "No polynomial time." We do not say, "Exponential time." What do I mean by that? Well, what about a running time like 2^√n. It's not exponential time--it's called sub-exponential because you don't have the n as it is appear in the exponent, but it's also not polynomial time because you have some function of n up here in the exponent. A running time like this actually conforms with the law and it has an excellent speedup. So let's think about this for a minute. Let's say n=50. If n=50, what is the speedup of 2^√n versus 2^n. Of course, we're going to do this as a quiz. Is it over a million, is it over a billion, or is it over a trillion. Of course, I only want you to select one answer here, the best possible one. The speedup here is traumatic, just because we write the square root here. It's over a trillion and the reason is that 2⁵⁰ is about 10¹⁵ whereas 2^√⁵⁰, so the ^√⁵⁰ is about 7, 2^√ is about 134. You have 100 and 34 versus 10¹⁵, which is a speedup of over a trillion, and we're still within the laws of NP completeness using this function here. We can call this loophole 1 in the laws of NP completeness. Now, I'll show you another function that is actually exponential time but also isn't that bad. What about 1.1^n? Absolutely not a polynomial time algorithm but still a huge speedup compared to 2^n. Let's do another quiz here--speedup of 1.1^n versus 2^n, and again, we're going to say that n=50 then you don't have to recalculate this here. You already know that it's about 10¹⁵ and I'll give you the same choices here. Is the speedup bigger than a million, bigger than a billion, or bigger than a trillion. So 1.1⁵⁰ is about 117 which again is a speedup of over a trillion, so what we now have found is a second loophole, where the first loophole was sub-exponential time and the second loophole is small bases for the exponent. Not having a 2 here but a 1.1 or maybe a 1.2, so now of course the question is-- can we actually exposed those loopholes, so can we find algorithms that have these running times here. The answer is--yes, we can, and that is exactly the point of using intelligent force versus brute force, and I'm actually going to show you how this loophole here works. And the problem for which we're going to show this is vertex cover. It's been awhile since we last met Alice. It was working on vertex cover. And actually, the last time we left off, Alice wasn't happy like that. Actually, Alice was quite unhappy because we proved vertex cover to be NP complete. The last time we left off, there was little hope for her to ever solve her vertex cover problem that she was working on. Now, I promised to show you an intelligent algorithm for vertex cover. At least one that's more intelligent than brute force. But in order to do that, let's first start out with a brute force algorithm. Let's say Alice is running her algorithm on a very simple graph like this. Just four vertices and five edges. What her simple algorithm or brute force algorithm was doing was it was considering all possible assignments of 0 and 1 to the vertices. For four vertices, we had a total of 16 possibilities that her algorithm needed to look at. Her algorithm starts out, for example, by saying, "Oh, let's put no vertices into the vertex cover." And of course this leaves all edges uncovered so it's not even a valid solution. Then, it would maybe start out by saying, "Oh, let's put one vertex into the vertex cover." There's actually four different ways of doing this and at least this time we have some edges covered. None of these solutions is the valid solution because we still have uncovered edges and I've drawn a red here so you can better see them. No valid solution for any of those. The algorithm continues and says, "Oh then, let's put two vertices into the vertex cover." Finally, the algorithm has found a valid vertex cover for our small network but of course it has also found many, many vertex covers that are actually invalid because not all edges are covered so again redundant, redundant, redundant. And all the algorithm proceeds and although it has already found a solution where two vertices are enough for the vertex cover, it now puts three vertices into the vertex cover which has the advantage that it will always find a valid vertex cover but the disadvantage that it's totally redundant and unnecessary work. Same thing if you put all four into the vertex cover. Valid solutions but not the best possible ones. This is what your brute force algorithm is doing and you can see why brute force is so stupid because first of all it considers many solutions where you could have immediately said, "Look, this is not valid." You've taken an edge and none of the two end points is in the vertex cover. Why even consider all the other possibilities? As soon as you have an edge that is not covered, you can basically scrap that solution and go looking for another one and the other thing that her algorithm did that wasn't very smart was once it had found a solution with two vertices it still tried all the solutions with three vertices and four vertices. It could've stopped right here because it knew that it would not be able to find any vertex cover that is smaller. And that is the difference between brute force and intelligent force. In brute force, we go through all of the possible assignments of the vertices into the vertex cover out of the vertex cover whereas what we're now going to do is we're going to avoid stupid choices. And that is the basis for intelligent force. The way to avoid stupid choices in the algorithm and actually we can make Alice a little bit more happy because we're soon going to show her that we're not going to make her totally happy but at least neutral because we're now going to show her a better technique than brute force. And that better technique is known as a search tree and you would soon see why it's called a tree. If you were solving vertex cover by yourself, you would probably take the following approach. You would not see for all vertices together if they are in the vertex cover or not but rather you would look at a single vertex, say this one here, and then split it into two possibilities. One, you're going to say, "Yes, let's make this vertex part of the vertex cover." And the other one, you would say, "No, I do not want this vertex to be part of the vertex cover." And then, you're going to split down further so on this side here and on this side here. Let's look at this vertex here next. We're just going to draw it a little bit smaller so that we don't run out of space. We already know that this vertex here is in the vertex cover and we're now deciding for this vertex here on the left. So we'll have one case where we do put it into the vertex cover and another one where we don't put it into the vertex cover. And then for each of these cases again we can split into two possibilities. And this time we're going to look at the vertex down here. Same here. One case where we put it into the vertex cover and another case where we don't. Now here for this case already, we can stop. We have found a solution of size 3. All edges are covered. We do not even need to consider the possibilities for this vertex here. Over here, we still have to consider two possibilities so we still need to make a decision here on the right side so we can either put it into the vertex cover or not put it into the vertex cover. And so this solution here or it's not solution because it's not valid. And here again we have found a solution of size 3 or a vertex cover of size 3. So I'm just going to leave this check mark here and have this account for both. So now we still have to continue here for these four points where we left off earlier and again we're going to do the same thing so we're going to consider one possibility where this vertex down here is not in the vertex cover and again we see. Oops! This is invalid so we do not need to continue any further. The next time we're going to put this vertex into the vertex cover. And yes, we have a valid solution of size 2. Continuing over here. We're going to consider this vertex here again. So one possibility would be to not put it into the vertex cover but that is already invalid. And another one would be to put it into the vertex cover, which again leads us to further possibilities to check and we're going to check them for this one down here. So same game. Invalid solution over here. Still valid over here. And we need to consider two more cases. And you already know that this case here is going to be invalid. And over here we're finding a solution of size 3. So that's all that. Originally, we had with brute force 16 assignments of 0 and 1 to the vertices that we needed to check and now this algorithm here only considered 9 assignments. So I told you at the beginning of this course that constant factor speedups probably don't matter that much when we're dealing with exponential time algorithms. So we will have to do some further analysis on this one. And you also noticed that there could be certain other techniques that we can use for speedups. So for example here, we had already found a solution of size 2. So we probably could've even stopped our algorithm a little bit earlier over here but we're going to get into this. The main thing that I would like you to understand is the technique of the search tree and we're now going to analyze this search tree further and try to improve it. And of course, I should also tell you why it is called a search tree. And to show you this, draw lines along where the algorithm was searching and then we're going to rotate this picture by 180 degrees and now here you can see a beautiful tree with the solution as the leaves or the fruit or whatever you will. But this is why it's called a search tree. It's basically a tree that hangs upside down. I don't know what the terminology tells you about computer scientists but that's not my concern here. Using the search tree for practical purposes, we may have already gained some efficiency. But now the question is, does it really affect the running time of the algorithm when we use O notation and worst-case running time? Or is it just something that gives us some constant factor saving some practice? It's hard to tell right now because this tree as we've considered it is highly dependent on the structure of the graph that we're analyzing and we need to think a little bit more about this. One interesting thing to consider is the following: There were only two cases when we stopped further exploration in this tree here. One case was that we had found a valid vertex cover. The other one was when we considered an edge that could not be covered any more. Actually doing it this way is not the smartest possible way because for vertex cover we already know one thing. If you look at an edge such as this one here, then this edge here has two endpoints and now we want to assign these endpoints to be in the vertex cover or to not be in the vertex cover. So far we have looked at the vertices individually, but we could also look at both vertices at the same time so not go into two different possibilities but actually go in three different possibilities. There's three cases that makes sense here of assigning the vertices to be on the vertex cover or not. So we know this edge needs to be covered somehow and there's actually just three different possibilities of doing that. One is you take this endpoint here into the vertex cover. The other one is you take this vertex here into the vertex cover. Or of course you can also take both. But you can ignore the case where you would put none of the two endpoints into the vertex cover because then you already know that your solution doesn't make sense. This of course also covers other edges as well and now our algorithm can actually very quickly come to a solution because when we look at this edge here, there's only one possible choice that remains and that is taking this vertex here into the vertex cover. All edges are covered. We have a solution of size 2. So now let's do a worst-case analysis and say that this is the edge that the algorithm considers next. In all of the three cases, the edge is uncovered so it again goes into three possibilities here, three possibilities here, and three possibilities here. Of course if we had been lucky and had chosen this edge here, the algorithm would have had a much easier choice and actually we're later going to look at such optimizations for the algorithm and again we're going to branch into the three cases that makes sense for that edge so this one here would make sense for that edge but of course it leads to an invalid solution. This one here is actually the best possible solution. And this one here is also a solution but it's a larger one, and we're going to do the same thing over here. Now, what you might be thinking is, "Oh no! Now we're trying nine assignments." But the good thing is that, we can now do a worst-case analysis of this. I would like you to think about a few properties of constructing the search tree this way, so taking an edge that is not yet covered-- so where both endpoints are not part of the vertex cover-- and then branching into 3 different possibilities, putting 1 endpoint into the vertex cover, putting the other point into the vertex cover, or both. So will the search tree always find the smallest vertex cover? Of course it can also find larger ones, but will it always find the smallest possible one for any given graph? Or could there be special cases where the search tree is wrong and we still need to fix that? Is it that the search tree at each level--and by level I basically mean if this is the tree here, then this would be a level and this would be the next level-- is it that at each level the algorithm determines the assignment? So is a vertex in the vertex cover or not for at least 1 vertex? And this will require some thought, so this is a challenging one down here. Can we construct the search tree so that at each level of the search tree we determine the assignment of at least 2 vertices? And of course you could just guess here, but I would really like you to spend some time and think about the answers because this will be very important for you to really understand how you can build better search trees. The algorithm is correct, or the search tree is correct, because it still tries all possibilities; it's just smarter about avoiding stupid possibilities. And what I mean by this is basically that it deliberately avoids this case here where you have 2 endpoints of an edge not being in the vertex cover, so it tries to avoid those. Are there special cases where the algorithm could be wrong? No. It still searches through all possibilities. Again, it just does so in an intelligent way to avoid making any stupid choices. Does the search tree at each level determine the assignment of at least 1 vertex? Yes. That one is definitely true because if all edges would be covered, then the algorithm would be done; the search tree would not go much further. The usual case would be that we actually do an assignment for 2 vertices, and this will also tell you something about the answer down here. So usually when we have an edge that is not covered, we will have the case that we actually determine the assignment for 2 vertices. There is 1 special case, and if you have found that special case yourself, then you have truly understood search trees. But if you haven't, then just listen closely and don't worry too much about it. There might be the following case, where you have an edge that is not yet covered but you've already made the decision for 1 of the endpoints. The question is now what to do with this one here. But this is actually a case that is rather easy because here we don't really have to make a choice anymore because we know this edge must be covered. So whenever we decide for 1 vertex that it is not going to be part of the vertex cover, then we can put all of its neighbors into the vertex cover automatically. We do not need to make a choice here anymore, and this is why we can construct the search tree so that at each level we determine the assignment of at least 2 vertices. Just to make this very clear, let me show you this again here in this example. Let's go back 1 level. When we made the choice here to not put this vertex into the vertex cover, we could immediately also have said that this vertex here must be part of the vertex cover because otherwise this edge here cannot be covered and we would already have been done. And the same thing up here. So if we decide that this vertex is not part of the vertex cover, then we immediately know that this vertex must come into the vertex cover because otherwise this edge here would not be covered, and we also know because of this edge here that we have to put this vertex here into the vertex cover, so we are also done, having found a slightly larger solution. The only thing where we still need to make a decision is this part down here. There we can still go into 3 cases, either putting that one into the vertex cover, that one, or both. And this is of course something that an algorithm can do as well. So actually, we get down to 5 assignments here, which already makes this search tree better than the one we started out with. But now comes the really cool part because once we know that we can construct the search tree so that at each level we determine the assignment of at least 2 vertices, we can do a pretty, pretty cool worst case analysis of that search tree. So let me show you. We started out with a brute force algorithm, and the brute force algorithm basically considered 2 to the power of N assignments. Now let's look at our smart search tree or intelligent search tree and see how that is structured. We're going to do a worst case analysis here. We start out with a graph where we don't have any assignments, and then we branch into 3 different possibilities. Up here we don't know anything, so we have 0 vertices assigned. Now, since we know that we can construct it so that in the next level we will have at least 2 more vertices assigned, here we know that we have at least 2 vertices assigned. We can go 1 level deeper and again we will branch into 3 possibilities all of the time. Because we're doing a worst case analysis, of course we could already be done. Or let's say we just continue. In the next level we have again at least 2 more, so we have at least 4 vertices assigned and so on. So let's say we continue the search tree in this manner, so we will always get wider and wider and wider. Then we know 2 things. One is that the number of levels that we have can be, at most, N/2 because every time we assign at least 2 vertices. So N and a half levels is the maximum number of levels that we can have because after that, all vertices have been assigned. And another thing that we know is that while we start out with 1 possibility and each time we go 1 level deeper, again doing a worse case analysis here, the number of possibilities that we consider triples. The tree basically gets wider by a factor of 3. The width is times 3 at each level. My question for you is if you look at the lowest level of the search tree, each of these ones down here is an assignment of 0 and 1 to the vertices. What I would like you to think about is how many different assignments do we have at this level down here, level N/2? You can assume for simplicity that N is an even number, so N/2 will be some integer. I'll give you a number of choices. Is it 2 to the power of N assignments that we have down here? Is it 3 to the power of N/2 assignments that we have down here? Is it 3 to the power of N? Is it 2 to the power of 3 times N? Or is it 2 to the power of N/2 times 3? You might have to think about this for a little bit, but just keep in mind the facts. The number of assignments that we are considering triples at each level, and we have N and a half levels. The correct answer here is 3 to the power of N/2 because if you look at this tree, it starts out here at this level, at the first level, and it has 0 assignments that it's considering. At level 1 it's considering 3 possible assignments, so it triples at each time. At level 2 it's considering 9. At level 3 it will be considering 27 and so on and so on and so on. For level X it's considering 3 to the power of X different possibilities. The maximum level is N/2, so it's 3 to the power of N/2. So the correct solution here is 3 to the power of N/2. So, wait. Brute force, 2 to the power of N, and now we have a 3 in the base of the exponent? Well, we probably need to do a little calculation here. So what I would like you to tell me is what 3 to the power of N/2 can actually also be expressed as. So 3 to the power of N/2 is a certain number to the power of N, and I would like you to enter this number with 3 digits after the decimal and please round it up. The answer here is 3 to the power of N/2 is the same as 3 to the power of ½ to the power of N, which is the same as the root of 3 to the power of N, which, if you use a calculator, is 1.733 to the power of N. Instead of 2 to the power of N assignments, we now only have to check 1.733 to the power of N. We have just squashed the exponent of our algorithm using a smart search tree instead of brute force. You might not be too impressed here. So 2 to the power of N, 1.733 to the power of N, hmm, doesn't sound too good. But there's 2 things to keep in mind here. First of all, this is a worst case analysis, so in practice we might be doing actually better. And the second thing is even in a worst case analysis, because we are dealing with exponential time, this improvement here is actually huge. So let's say that we're looking at an input of size 50. Then 2 to the power of N assignments would be 10 to the power of 15, about 1.13 times 10 to the power of 15. So this is almost infeasible. Maybe with a very, very, very, very, very powerful computer, but you probably wouldn't want to do this and probably also wouldn't want to do this for more than a single graph. If, however, you have the smarter search tree, then you have 1.733 to the power of N, which is 1.733 to the power of 50, and that is about 8.71 times 10 to 11. And the difference here is a speed-up of over 1000. That speed-up will become larger as N grows larger. And the other thing is again that this down here is only a worst case analysis. In many practical cases, the search tree will be much smaller because first of all, as we saw, it's often the case that you assign more than just 2 vertices, and in that case the tree doesn't become as high. And also you can apply various other optimizations, some of which we're soon going to talk about, to make the search tree even smaller, both in practical cases and in the worst case. Now, should Alice be happy about this? Probably not yet because already for N equal to 50, the running time of the algorithm here gets rather large. So if she is solving the problem for a telecommunications network with, say, 500 vertices, it will still be out of the question to find an optimal solution using the search tree. But of course there's a little hope already because we haven't really fully explored search trees yet. Maybe it's going to get even better for her. But before we continue helping Alice, let's have a look at Bob and Carol and see if can apply smart search trees also for their problems: independent set and clique. So let's see now if we can design a better search tree for Bob and Carol as well so that they also can look happy. As you'll remember, Bob was working on the clique problem, finding a set of vertices in a graph that all were connected as much as possible, so a set something like this. All vertices are connected to all other vertices. And Carol was looking for the opposite thing, so a number of vertices that were not connected to each other at all in a network. So I'm going to draw this dashed line here to show that there's no connection. We're actually going just to look at independent set because as you'll remember, clique and independent set are so closely connected that it's actually once you have an algorithm for independent set, it's not that difficult to design a very similar algorithm for clique. You can basically use the same techniques. So in order to design a good search tree for Carol, how do we design this? Actually, it's quite similar to vertex cover. Remember how we defined an independent set. In an independent set, no 2 vertices can be connected to each other. We can actually play the same game that we played for vertex cover in a search tree. So let's say you have 2 vertices, and we're going to call this one here v and this one u, and the 2 vertices are connected by an edge, and we're now trying to assign values of 0 and 1 to those vertices. So 1 and 0 here, 1 and 0 here, same as for vertex cover, only this time we are looking at assignments that would be valid for independent set as opposed to vertex cover. Let's do a little quiz here. What is true for any valid--and by valid I mean with respect to independent set-- any valid 0, 1 assignment to the vertices v and u if they are connected by an edge? Is it that at most, 1 of the 2 vertices can be in the independent set-- and I'm going to write independent set as IS here just to not move out of the screen here. Is it that both v and u can be in the independent set? Is it that at least 1 of the 2 vertices must be in the independent set because we're looking for the largest possible independent set? Could it be that although we're looking for the largest possible independent set, they are both not contained in that independent set? And finally here, because both vertices are connected by an edge, is it the case that we would have to exclude both of these vertices from the independent set? Please check each one of those here that are correct. The first answer I hope wasn't that difficult to find. This one is true. The rules of an independent set are that 2 vertices cannot be connected by an edge if they are part of the independent set, and that means if we were to put this one into the independent set as well as this one here, then we would have an error here, which automatically also answers the second question. It's not the case that both vertices can be in the independent set because they are connected to each other. This one here might have been a little bit more tricky. So at least 1 of the 2 vertices must be in the independent set. You might be inclined to think that because we are looking for a maximum size independent set. But actually, that is not the case, and I will give you a little example for that. Say we have a very small network like this one here, and here you have v, here you have u. Then this network here has an independent set of size 2. Actually, it has a number of independent sets of size 2, but there is also 1 independent set of size 2 where v and u are both excluded. This is a bit different from vertex cover because you can actually have the case that both vertices are not part of the set even though they are connected by an edge. So this is false. Both v and u could be 0. Yes, this is exactly what is also shown by this example. You can have the case that both are not part of the independent set, so this is definitely a yes here. Do we have to set both vertices to 0? No. This is also not the case because, for example, you could also have an independent set here that you construct in this way. You put u in and this one out. So now we have also found a maximum size independent set, but we have included 1 of the 2 vertices. So this one here is clearly also not true. If you take all of those observations together, it's pretty cool because this now gives us a new search tree strategy that is actually quite similar to vertex cover. So we have our 2 vertices, v and u, here. Just as we did with vertex cover, we can spread into 3 different possibilities. The first one is we take v into the independent set but not u. The second one is exactly the other way around. We do not take v but we take u. And finally, it is possible that both are excluded. As long as we find an edge between 2 vertices, v and u, for which v has no assignment yet and u has no assignment yet, then we can branch into exactly 3 possibilities. Now, what happens if either v or u already has an assignment? For vertex cover I told you what would happen then. This time I will let you figure this out. So how can we deal with the case where either v or u already has an assignment? Do we have to modify the search tree for that? Do we have to initiate a brute force search in that case? Or is it the case that we do not need to worry at all because it's actually quite obvious what to do with those vertices? Please select whichever you think is correct. The correct answer here is, similar to vertex cover, those cases are actually the easy ones. And I'll show you why. Either v or u already has an assignment, and we can just consider 1 of those cases. So let's say v already has an assignment, here is u, and there's 2 cases. Either we said yes, v is in the independent set or we say no, v is not in the independent set. This case up here, that's very easy to see because if v is in the independent set and there's an edge here between those vertices, then you cannot be in the independent set. So that one is very clear. What about the case down here? That's a case that requires a little more thought. By itself right now, it could either be that u is in the independent set or it's not. And we don't know, so you might have been inclined to think that we need to modify the search tree or initiate some other form of brute force search, but actually, that's not necessary and I will show you why. This vertex u here, there are 2 possibilities. If u is not connected to any other vertices-- so let's say all other vertices in the network are independent of u-- then we can put u into the independent set without having to think because we're looking for a maximum size independent set. This is the only connection that u has to other vertices. Why not just take it? It doesn't really cause any other conflicts. Now, what if u is connected to other vertices? Here there's 3 different possibilities. The first possibility is that u has some neighboring vertex-- so one that is connected by an edge-- where we already have assigned it to be in the independent set. And in that case we can immediately say no, you cannot be in the independent set. We must assume that none of these vertices here is already in the independent set. So now there is 2 different cases. One is that 1 of these vertices here has not yet received an assignment. And in that case we don't have to worry about modifying the search tree because now we're looking at a case like this here again. So we can use our standard search tree to search through assignments for these 2 vertices here. If every vertex here, on the other hand, already has an assignment, then we just discussed, because we've just dealt with the other case, that all of these assignments here must be a 0. So all of these vertices here--and there can be more, of course-- are not part of the independent set, and that means that we can take u into the independent set again. It might not have been obvious in terms of thinking it through what to do in this case, but for an algorithm we can design it in a way so that the algorithm always knows what it is to do. First of all, it looks for edges where both vertices do not have an assignment. And once it cannot find those edges anymore, then it will know how to deal with the remaining vertices. And this of course means that for independent set we can use a search tree that, just like vertex cover, always finds an assignment for at least 2 vertices. So its height, so to say, of the search tree is N/2. The size of the layers multiplies by factor 3. So the size of the overall tree is 3 to the power of N/2. For independent set we have a search tree of size 1.733 to the power of N. Just like vertex cover, the calculation here is the same. And because independent set and clique are so similar, we just have to transform the network to the inverse network, as you remember, hopefully, from the first unit. We also have a search tree of size 1.733 to the power of N for clique. Just like Alice, no reason to be super happy, but Bob and Carol can be a little happier now. And of course we're going to go on investigating. We have only so far been able to touch on the very basic concepts of designing intelligent search trees. And research to date is much more advanced. So you might be wondering, considering the state of the art, how low can you go? What are the best search tree algorithms to date that we know of? Actually, I'm not going to tell you anything about vertex cover for now because that problem will deserve a little more attention later in this unit. I will show you the state of the art for some other problems. So for independent set there are currently 2 algorithms that could kind of be considered to be the smallest search trees. One has size 1.189 to the power of N, and the other one has size 1.211 to the power of N. It's 2 different algorithms. This here has a bit larger search tree, but the algorithm itself is probably a little bit faster in the worst case than this one here because of the polynomial factors that are involved. But this here is just the search tree size. For clique it's the same as independent set, as always, because of the close connectedness of those 2 problems. In one of the previous units you also got to know 3 SAT, which is a satisfiability problem where every clause has exactly 3 variables, and that can be solved with a search tree of 1.496 to the power of N last time I checked. This is a very advanced search tree. It's basically half a book of proofs required to show this here. Now, what about shortest tour or, more generally, the traveling salesman problem, which is shortest tour, only that you can only visit a city exactly once. This is a very interesting one because the best-- well, it's not even really a search tree--but the best algorithm has an exponential factor of 2 to the power of N. So here it's still an open research problem to find out if you can design better search algorithms for this problem. By the way, in case you're wondering, do the laws of NP completeness, as far as we know them, say anything about how low the exponent can go, so really put a limit on the space here? Say, for example, unless P equals NP, there is no algorithm for independent set with a search tree that is smaller than 1.1 to the power of N or something like that. And the answer here is we don't know. So it might be that you can solve independent set, for example, in an algorithm with 1.01 to the power of N as your search tree size. Nothing in the laws of NP completeness that would speak against that. So what does this mean for the problem sizes that we can expect to handle? I'm going to give you a little quiz here so that you can develop a feeling for that. Assume that we want to consider, at most, 1 billion possible solutions for an NP complete problem, 1 billion different assignments of 0 and 1 to the vertices. So what I would like you to do is to figure out the maximum problem size that we can handle using these best known search trees under this condition here. We want to consider, at most, 1 billion different solutions. So please enter your answer here in these boxes. What I would like you to do for this box here is use this algorithm. For this box here I would like you to use this one here. And for comparison I would like you to figure out 2 more. One is 1.1 to the power of N, and one is 2 to the power of N. So there's actually 5 different answers here. The general way to calculate this is using logarithm. So you say 2 to the power of N, for example, is smaller than 1 billion, which means that N must be smaller than the logarithm base 2 of 1 billion, so N must be smaller than or equal to 29, which is exactly what we're going to put here. And of course you can do the same calculation for the other ones as well. So you get here the maximum problem size we can handle would be N equals 217. Here it's 119, 108, and 51. The interesting thing to see here I think is that you see how even small changes in the base of the exponent can make a difference. So here the change is really small, from 1.21 down to 1.18, and already we could handle a problem size of 10 more. And of course this also shows you that the problem size that you can handle, at least in a worst case scenario, is about 4 times as much as you could handle if you used a normal search tree. And of course, if you could find a really, really good search tree-- and there are some problems for which you can come close to 1.1, actually-- then you can handle problem sizes that are almost twice as much as this one over here. So it's really a significant improvement. It's not dramatic in the way that now we could solve instance sizes of thousands of vertices or thousands of variables, but it's a significant improvement. But it's a significant improvement through using sophisticated algorithms. What I already mentioned to you is that this is of course just a worse case view. So this is what you just calculated here if we were to consider a billion different possible solutions. And the numbers would of course get much higher if we said we are ready to consider 10 billion or 100 billion possible solutions, but still they would not be in the thousands. And that's actually the surprising thing because if we look how well those algorithms perform in practice, they perform dramatically better. So for independent set and clique you can usually solve instances far over 1000 vertices, and for 3 SAT there are even annual competitions in which participants solve instances with, I would say, almost in the tens of thousands of variables. This varies by competition, so there are some competitions where it's in the hundreds, in the thousands, but you can solve instances up to 10000. And the reason for that is that it seems like most of the instances or inputs to NP complete problems that we encounter in practice are, in a way, well behaved. They rarely tend to be worst cases instances that force our algorithms to run in their maximum time. And there is also, besides search trees, other very interesting techniques that you can use to further improve your running time of your algorithms. I would now like to introduce to you preprocessing as another technique to deal with NP completeness. So now that you've learned about search trees and pre-processing, you already know quite a lot about the loopholes that we can find in the laws of NP-completeness in order to actually tackle an NP-complete problem, because now you can get from algorithms that would normally take 2 to the power of N time down to other algorithms that say take 1.3 to the power of N time, which already makes many more instances solvable. But to conclude this unit, I want to show you another loophole in the laws of NP-completeness that is sometimes very, very useful and that actually not very many people know about. So I'm going to state another law from the book of NP-completeness, and that law in which we will soon poke loopholes is larger instances are harder to solve. And that is actually quite obvious because we said that we were going to look at worse case time and always measure the running time of an algorithm as a function of the input size. Say we have an algorithm that runs in O of 2 to the power of N times N squared time. What this law here means is bigger and more time in worst-case scenario. So if you have a running time like this, a bigger input size means more running time required for the algorithm in a worst-case scenario. Let's talk a little bit about this N here, the size of the input, because this is often a very coarse estimate of how hard an input is actually to solve, and I'm going to give you one example of this or actually I'm going to quiz you about this. Given the search trees and the pre-processing, which of the following instances of vertex cover is easier to solve? And I know this is an easy one. In case you're wondering, the number of vertices in each of the graphs here is the same. Vertex cover is so much easier to solve for this graph over here. It would actually be solved by pre-processing alone, although both graphs have the same number of vertices. It seems like the size of the input is actually not the best way to measure how hard it is to solve an NP complete problem for that input. It seems kind of unfair to just say to this graph here--well, you're just as large as this one over here, so we're going to assume that you're just as hard to solve. And that is why you could think of hardness, meaning how hard is a specific input to solve as a combination of 2 things. One is, I think, the size of the input, and we always measure this as a number N. But the other thing is the structure of the input. In a way, it's not larger instances are harder to solve, but in a way you could say, harder instances are harder to solve. This of course might seem like a bit nitpicking around, so the question is, is this actually useful, and the answer is yes. For some problems, you can actually express the structure of the input, and I'm soon going to show you how to do that, as a number K. And while in classical NP-completeness, so to say, you would measure hardness as some function of N. You can then measure hardness as a function of 2 parameters. One parameter is still the size of the input, and the other parameter is going to specify something about the structure of the input. Now this might sound a bit abstract, so what could this parameter be? And I'm going to show you 2 possibilities for this parameter, and we're going to discuss them in detail. One is size of the solution, and the other one is something I would call distance from triviality. So for example, for the network from the last quiz, you could actually see that both parameters could tell us that finding a solution here is easy, because first of all, the solution here and optimum vertex cover is very small, you only require 1 vertex. And also, you could argue that this graph here is very trivial because all you need is a pre-processing rule to actually find the best possible solution. But again, we'll get into more detail. Let's start out with the size of the solution. And now we already know that we can solve vertex cover using a search tree. So we started with the original graph, and I'm now going to use again the search tree where we branch into only 3 different possibilities. We know it's not the best possible one, but it will be easier to understand the rest this way, but it also works for the more complicated search trees. So then on the next level, we again branched into 3 different possibilities on each level and so on. And we said that the search tree had a size of N half and the total number of solutions that we looked at in the search tree was 3 to the power of N half, which as you remember was about 1.734 to the power of N. Now I would like you to quickly think about the following: So as you'll remember, at each level of the search tree, we're looking at an edge where the 2 end points have not yet had an assignment, and we're branching into 3 cases, this one, this one, and this one. So now it's a very easy quiz actually. So how many vertices are added each time we go one level deeper into the tree? At least 1, at least 2, exactly 1, exactly 2, or is this something that actually depends on the structure of the input graph? And the answer here of course is that at least one vertex is added to the potential vertex cover each time we go down here in this tree or we branched because there's only three possibilities and in this possibility here, we add one vertex, and this possibility here, we also add one vertex, and here we will add too. And of course, there then comes data reduction and all that jazz, but we're always adding at least one. So what happens as we go down here, at least one vertex added and so on. So what does this have to do with measuring the hardness of vertex cover? Well, we'll get there in a minute. What I would like you to think about now is the following: Let's say we were looking at the decision variant of vertex cover where as input we were given a graph and an integer K, and our output was an answer to the question, does the graph have a vertex cover of size at most K? So now here comes my next question to you, what is the maximum height of the search tree if we are not using it to solve the optimization version of vertex cover but the decision version of vertex cover? Would that height be in half, would that height be K, would that height be N, or something we can't say? And please choose the best possible one here. And now this is the interesting insight here. The maximum height of the search tree is K Why is that? Well, we just noticed that each time we go 1 level deeper in the search tree, we add at least 1 vertex to the vertex cover. If the graph is supposed to have a vertex cover of size at most K, then the maximum number of levels that we can go down here is actually K levels, so for the decision variant, what we have here is that the height of the search tree is no longer in half, but it's actually bounded by K, and K is the size of the vertex cover that we're looking for. Now my next question to you is what does this mean for the number of assignments that we're looking for in this new search tree? Is that still 3^n/2, is it k^n/2, is it 3^k/2, or is it 3^k? What you can easily see is that the size of this search tree here is actually 3^k because we branched into three possibilities each time we go a little deeper, and this can happen at most k times. The size of the search tree is 3^k. Of course, this is only a very coarse analysis actually so you can have much better search trees and even for this tree here, you can do a better analysis because actually, this tree doesn't always have height K for the 3 cases that you branch in. In one of the cases, as you'll remember, you put 2 vertices into the vertex cover, so this one here, this one here, and here you put 2. Actually, that already decreases the size of the tree, so doing this type of analysis is out of the scope of this course actually. If you were to do this, then you find out that the size of the tree is approximately 2.4 to the power of K. And again, there are even better search trees for this. The main point however is this, look at what we have just done. We have just discovered a search tree for a vertex cover for which the size does not depend on the size of the input at all. The size of this search tree only depends on the integer K. It doesn't matter if we do it for a graph with 10 vertices, 100 vertices, or 1,000 vertices, the size of the search tree only depends on K, and it gets better if we implement this as an algorithm to solve vertex cover, so the decision version of vertex cover. Now look at this running time here and what that means. The running time here will be 2.4 to the power of K times N to the power of some constant, depending on how you implement it, but into the power of 3 will do here. The decision variant of vertex cover can be solved in 2.4^k<i>n³ time and this is by far</i> not the best algorithm for vertex cover there is and I'm soon going to tell you a little bit about that. Even with this, think about what that means and I'm actually going to quiz you on this one. Does it mean that for any fixed k, vertex cover can be solved in polynomial time? Does it mean that the running time is independent of the size of the input graph? Or have I been tricking you all along and it's actually the case that P=NP? Please check all of those that are correct. Of course, this one here is correct. So if we say we want to find out if a graph has a vertex cover of size 10, then all we need is polynomial time because then this decision problem can be solved in O of 2.4 to the power of 10 times N cubes time, and the exponential factor here is no longer dependent on the input size. So for a fixed value of K, vertex cover can indeed be solved in polynomial time. Of course, the running time is not independent of the size of the input graph because you still have this polynomial factor here. Does this statement here mean that actually P=NP? Unfortunately, it doesn't because K can take any value, so K can also depend on N in the general case, but what it does mean is that if we consider any fixed value of K, then vertex cover becomes easy. In other words, small vertex covers are easy to find. Now, so far, we've only worked with the decision variant of vertex cover. So, what about the optimization problem? Actually, that's not that difficult. We just run through all values of K. So we will first start off assuming K=1. Then our algorithm requires O(2.4¹<i>n³), then we'll increase K=2, algorithm requires o(2.4²<i>n³).</i></i> So each time we're solving the decision problem here, and we increase K even further to K=3 and so on and so on and so on. Until we hit some value k’ which is the size of the smallest vertex cover of the input graph. Of course, we don't know what that size will be in advanced? But once we have increased K enough, solving the decision variant will give us the answer, yes. Now, how much running time is this in total? Well, you need to know a bit of discrete mathematics for this, but running time O(2.4¹+2.4²+)...(2.4^k')<i>n²).</i> Now if you have a discrete math course and remember what you learned there, you will recognize this part here as a geometric series and this evaluates to (2.4^k'⁻¹-1/2.4-1) which is the same as 0(2.4^k'), and k' is the size of the smallest vertex cover <i>n³. We forgot the n³ here which is right here.</i> And this is amazing because now it means that not only the decision variant of vertex cover can be solved in (2.4^k' n³) time, but it means that the optimization variant of vertex cover can also be solved in O(2.4^k'n³ )time, where k is the minimum size of a vertex cover for the input graph. And this again emphasizes the fact, small vertex covers are easy to find even if we don't know that a graph has a small vertex cover as long as it is small, it will be easy to find and for any fixed k, so either in the decision variant, we fixed k or we say we look at all graphs that say have a vertex cover of size 10 or 20 or 30, we can solve this NP complete problem in polynomial time. And this is a concept known as Fixed Parameter Tractability. Well, that means is that as long as the parameter that measures the hardness and in this case, it's the size of a vertex cover for your graph, as long as that parameter is small or fixed, then you can solve that problem in polynomial time and that is what this here says, so as long as the parameter is fixed, the problem is tractable, if the parameter is not fixed, so for example, there's a function of n, then the problem is not tractable. And this of course is a super neat technique for solving vertex cover and actually 2.4^k is actually a very bad exponent here. We only did that because of what's easier to explain the problem that way. The currently best algorithms have an exponential factor of about 1.3^k. Actually, a current state of the art is that you can solve vertex cover in 1.3^k times some polynomial time. Now, the polynomial here that depends on certain analysis factors and so on but the important thing here is to see, first of all, vertex cover is fixed parameter tractable and second of all, the base of the exponent is actually really good. It's only 1.3^k. So now coming back to this picture here, you see what I meant when I said that hardness of a problem can be measured as both a function of the size of the imput and the structure of the imput, so in the case of the vertex covered, it turns out that what makes solving vertex cover hard is actually the size of the vertex cover itself. So if there's a small vertex cover, then the problem is easy and if it's large, then the problem becomes hard. Now of course, this immediately raises a question for the book of the laws of NP-completeness and that question is, is every problem fixed-parameter tractable? That depends, it depends on what you consider as a parameter, and one parameter I will soon introduce to you as well is a parameter called distance from triviality, but unfortunately in general, not every NP-complete problem seems to be fixed-parameter tractable. So for vertex cover, we have just shown that if you use the size of the solution as a parameter, then yes, this problem is fix-parameter tractable using K, and by K I mean the size of the solution of course. Now what about clique and independent set? And again, we can consider these 2 problems together because they're so similar. And here unfortunately, I have a bit of bad news for you because using K, by which I mean the size of the solution, that's highly unlikely to be fixed-parameter tractable. So by highly unlikely, what I mean is it would not be something as similar as P=NP or something like that, but still there is evidence in a way that is similar to P versus NP that clique and independent set are not fixed-parameter tractable at least if you consider the parameter to be the size of an optimal solution. Now what about shortest tour? Well, one possible parameter here would be using D, the size of a shortest tour, and here again, it seems somewhat unlikely that the problem is fixed-parameter tractable, but for shortest tour, another parameter has been investigated that actually seems rather promising, and that parameter is called using distance from triviality, and there it turns out shortest tour actually could be fixed-parameter tractable. Now what is distance from triviality? Of course, we'll do a little quiz to have you figure that out. What I would like you think about is the following: I'm going to give you 3 graphs, and I'm going to ask you for which of these graphs is shortest toward the hardest and the easiest to solve. So here you have 3 graphs, and each of these graphs has the same number of vertices in case you're wondering, or at least I hope it does, I counted twice, but you never know. And what I want I would like you to tell me now is for which of these graphs you think shortest tour is the hardest to solve and for which of these graphs you think is the easiest to solve and I've not written any distances on the edges, but you can basically assume that I would be able to write any distances that I want on these edges. It's more of a question about the structure of these graphs, and for the one that you think is hardest, I want you to enter the number 3 in one of these boxes, and for the one that you think is easiest, I want you to enter the number 1, and guess what number I want you to enter for the one that is in between. So please, go ahead. Now again, of course, this is a bit debatable, but I think you will all agree that this one here is actually super easy to solve shortest path on, because let's say you start here, this is your mail station where you start. You go all the way here and then you have no other choice but to go here, because you have to visit all those vertices, and then you go back. so there's not really difficult choices that you have to make when you solve shortest path for this one here. Now this one here is a little bit harder. Let's say it doesn't really matter where you start out because for a tour you can start out at any point because you have to come back to it anyway. And let's say you start out here and then you go up here and then you already have your first choice to make, so do you go this way or do you go that way? Well, probably you want to go that way, but actually there are certain distances where you might want to go this way, so you have to make a choice here. Let's say we go this way, and here we have to make a choice again, so do we go this way and back here or do we go this way and here? So a little bit harder to solve because we have to make certain choices, but still not quite as hard as this one over here, which I would think is the hardest because say we start out here, oh, first choice to make, this way or that way, well, that way. Oh, again, new choice, this way or that way, let's go that way. So all the time we have to make choices, which city to visit next, and this is really tough, so what does this have to do with what I just call distance from triviality? So what does with what I just call distance from triviality? If I mark the vertices in each of the networks, if I mark the vertices in each of the graphs that has more than 2 neighbors, then here we have just 1, here we already have a couple of them, and this one also although this one is fairly easy, but let's be consistent here, and here I have a lot of them, and I'll give you one additional graph, which looks something like this. Now this has a bit fewer vertices, but that's not the point here. The point is that this graph down here doesn't have any vertices that I would color because all vertices have exactly 2 neighbors, and this here is what I would call a trivial instance for shortest path, because you don't really have to make any choices where you want to go. Here you also don't have to make any choices, but what you see here is that the number of vertices that have more than 2 neighbors actually is an indicator of how hard it is to solve shortest tour on that respective graph. If you have a few of these blue vertices here that have more than 2 neighbors, then it's easier to solve shortest tour. Now I cannot give you the precise algorithm for this here because actually that is a bit more complicated to figure out and doesn't only have to do with these vertices here, but I think you get the intuition that we could try to use the number of these blue vertices or some additional structural information as a parameter, and it turns out that if you do this the right way, then shortest tour is somewhat fixed-parameter tractable. Now let's do a final quiz here using again distance from triviality so that you have a chance to understand this concept a bit better. Let's consider 3-SAT this time. You already know that 3-SAT is NP-complete, and you 2-SAT is contained in P, so 2-SAT is polynomial time solvable. So let's consider 2 Boolean formulas here. This is the first one here, x1 or not x2 or not x3 and x1 or not x5 or x6 and x2 or x5 or x7 and x3 or not x6 or not x7. Now it's not really difficult to see if either of these 2 formulas has a satisfying assignment or not, and that's not really the point. What I would like you to think about is the following: Considering x1, x2, and x3, which of these Boolean formulas is closer to triviality, and by triviality I mean which one of these is closer to a 2-SAT formula. So look at x1, x2, and x3 and consider what would happen if you were to assign them true or false values. And then you just check the appropriate box. And I think the correct answer here is this one above. Again, it's a bit subjective using these small examples, but otherwise it's just too complicated for you to see and explain. So my point here is basically this, if you have decided what you're going to do with x1, x2, and x3, then the following thing happens. You've already decided what you're going to do with x1, you've already decided what you're going to do with x2, and you've already decided what you're going to do with x3, and in that case, what remains is an instance of 2-SAT, and that is solvable in polynomial time. Of course this is a very simple example, so you could have already figured out how to solve it. So there's many different ways to solve it, but I just wanted to show you what I mean by distance of a 3-SAT instance to a 2-SAT instance, because over here you decide what to do with these values. Well, you have it figured out for this clause here, you have it figured out for this one here, but you have not figured it out for that one here. So in a way, the above formula is closer to a polynomial-time solvable instance of SAT than the one down here. But of course you would need a really, really large and tedious Boolean formula to actually take advantage of this. But in fact, many professional SAT solvers or SAT solving packages actually make use of this fact. There are a number of variants of SAT that are known to be solvable in polynomial time, and what these solvers do is they will try to figure out if the Boolean formula that they are given is actually close to one of those polynomial-time solvable instances. Actually, I don't even know if somebody has considered this as a parameter for fixed-parameter tractability, so there might actually be an open research problem for you here if you're ready to get into it. Congratulations! You have now learned a lot about solving NP complete problems in practice. You have learned about search tree optimizations, you have learned about pre-processing, and you have learned about other techniques such as fixed parameter tractability, and this is huge. Now, of course, in this unit, I could only teach you the very basic techniques that I use. So you might be wondering, what is the state of the art for solving NP-complete problems in practice? I would like to give you a few examples and numbers. For vertex cover on practically relevant inputs, you can sometimes find the vertex cover progress with over 10,000 vertices for independent set and clique. Independent sets and cliques have been calculated for many graphs with over 1000 vertices and traveling salesman which is very close to shortest tour and actually sometimes people also solve shortest tour, so a traveling salesman, you really have to be specific what kind of problem your are talking about. But there's one example where somebody solved an instance with ≥85,000 vertices. Think about what this means for the four computer scientists that we met throughout this course so far as started out with not being able to solve vertex cover for a graph with 10 or 20 vertices and then she learned about NP completeness. Her situation was actually quite dire, but then we showed her that there's search tree optimization and pre-processing and if those techniques are applied in the right way, then, Alice can't certainly expect to be able to solve her problem if she is working with 500 or 1000 vertices, because the thing is this, the instances for vertex cover that come up in practice are actually much easier to solve than worse case instances. One example is this, you're practical instances went up to 10,000 vertices. I think Alice can be pretty happy. What about Bob and Carol? Bob and Carol, of course, they started out being as unhappy as Alice because they also had impractical algorithms and then they found out about NP completeness. Of course, they can also use search trees and pre-processing, but their problems turn out to be harder to solve than vertex cover in general. Even so, I think they should be a little bit happy because for the problems that they try to solve in Genetics and in Finance, I think being able to work with about 1000 vertices should be okay. And again, we have to assume that, of course, they are working with inputs that are more easily solvable than worse case inputs but usually in practice, again, that's the case. What about Dave, who we met very late in this course? Well, when we met Dave, we showed a very complex proof that his problem was NP-complete, so he started out very unhappy as well, I would assume. And actually I think he stayed unhappy throughout this unit because whenever we came across shortest tour or traveling salesman, we always had to say, well, we're not really quite sure on how to do this. This is an open research problem. But then again, since this problem is so highly relevant in practice, there have been lots of developments regarding sophisticated algorithms that work very well in practice, so we can basically put it like this. From a theoretical perspective, Dave has to be very very unhappy, but if he uses sophisticated algorithms, then actually Dave can be the happiest of all because the algorithms that have been developed for traveling salesman work extremely well in practice. And finally, of course, we should also say a little bit about SAT. For the satisfiability problem, there are annual competitions and these competitions, of course, are based on mostly on instances that occur in practice than on instances that are deliberately hard. And yet so, each year, usually instances are solved with over 1000 variables. Now SAT is a problem that behaves very differently. So there are some instances of SAT even with 10,000 or 100,000 variables that are very very easy to solve because pre-processing is very effective for these instances. And then there are other instances for SAT that just have a few 100 variables that are super super hard to solve, so there, you usually need to try a lot of different packages and techniques, but nevertheless, when you come across an instance of SAT and there are certain practical situations but this is the case, then you shouldn't despair. SAT, again, if you're working with real world instances, for SAT, it's usually worth a try to solve it. So congratulations, you have now mastered a basic survival course for NP-completeness. You have learned about advanced algorithmic techniques such as intelligent search trees, pre-processing, and other advanced techniques such as fixed-parameter tractability that will help you solve and P-complete problems in practice. Now this material is very deep. Not many people, at least in my experience, even understand with NP-completeness means, but even fewer people know about these tools and techniques that you can use to poke holes or find loopholes in the laws of NP-completeness. So knowing these techniques and possibly learning more about them can really make you stand out whenever NP-complete problems need to be solved. Of course, even though these techniques are very powerful, sometimes it's just not possible in practice to solve an NP-complete problem. As I hope you're expecting by now, we still won't give up. Rather, in the next unit, we will see if it helps us when we relax a little bit, and instead of looking for the best possible solution, are content with solutions that are not quite optimal. In other words, next time we'll get sloppy. In the last unit, we have talked about what you can do when a problem is NP-complete, despite it being NP-complete. And we have found out that there are techniques such as optimized search trees, preprocessing, and fixed parameter tractability that you can often use to solve NP-complete problems and practice despite their hardness in general. So what can we do when these techiniques don't work, and we don't want to prove that P=NP? Well, in that case, we can try something else. We can try to give our algorithm a little leeway. So instead of demanding that the algorithm finds the best possible solution, we'll allow the algorithm to find a solution that is within a certain range of the best possible solution. In return, of course, we'll demand from our algorithm that it runs in polynomial time. In the last unit, we have talked about how if we encounter a problem that is NP-complete, we can often, using very advanced algorithms, still hope to find a solution for those problems, at least in practice. Because you learned about techniques such as intelligent search trees and preprocessing. Now, in this unit we're going to investigate something different. So consider a challenging problem such as measuring the length of an elephant. Now, doing that exactly is actually not that easy because the elephant might be moving and it might not like the ruler down here. So finding an exact solution such as the elephant has a length of 5.107 meters might actually be quite a difficult thing to do. On the other hand, if you allow for a bit of sloppiness, and say, "Well, let's just estimate it at about 5 meters," then you can get a solution much faster. What we're going to look at in this unit is if sloppiness, or at least allowing for a bit of leeway, can actually help us solve NP-complete problems more efficiently. And what I mean by sloppiness is the following: Let's say we wanted to solve shortest tour. What we always asked was, very demandingly, what is the shortest tour? No excuses, no leeway, no sloppiness. What is the shortest tour? And what would happen now if we didn't ask what is the shortest tour, but rather asked the following: What is a pretty short tour? So for example, 20% within the optimum. Then we become less demanding on what the algorithm is supposed to produce. And now, of course, the question is, will this allow us to construct faster algorithms? Now, before we dive into this, I would like you to quickly think about this approach for a bit. In which scenarios might a sloppy, or not-exact solution be acceptable? So what I would like you to think about for a little bit is, in what scenarios approximation to the best possible solutions would be acceptable? So approximations is the more formal term for sloppiness, and, of course, just to be precise, in this unit we're going to be dealing with optimization problems. You can also talk about approximations to decision problems, but that's a bit of a different scenario, and, actually, we'll get into that when we talk about randomization. But this is not part of this unit here. So would we be content with approximations if the stakes are low, so we're solving an approximation problem where nothing is really critical? I mean, you might spend a little bit more money, but it's not going to mess up research or anything like that. Would it be acceptable if the algorithm kind of sounds good? We do not have a provable guarantee, but it still appears to yield good solutions and make sense in general. And would using an approximation be acceptable if we find that exact solutions are simply out of the question? We're using the best search tree; we're using preprocessing, but still our instances are so large, and they behave so badly that we just cannot find an exact solution. And, of course, this is 1 of those easy intro quizzes just to get you thinking a bit about approximation. So it's clear, when the stakes are low, yes, approximate solutions are acceptable. If we gain running time, why not? If the approximation is very good then usually those solutions are also acceptable. The important thing that I wanted to emphasize is that, in this case here, I said that we have a provable guarantee on how good the algorithm is. So we'll not get into ±1%, unfortunately, in this unit, but what we will be doing is, we will be analysing approximation algorithms to see how good they really are. Because the thing is this: Approximation algorithms, where you have not done the analysis and they just sound good, can actually lead to very, very bad solutions, and I'll show you 1 example for vertex cover in this unit. So using approximation is okay, but you have to do the analysis nevertheless to see how good that approximation will be. Otherwise, you can walk into some rather nasty traps, I would say. And finally, whenever an exact solution cannot be obtained, yeah, of course, then we have to try an approximation if the problem is important to us. The important thing here, that I would like you to keep in mind, is what we found out in the last unit: that often it is possible to find exact solutions for NP-complete problems and practice. So many people tend to start out with approximation algorithms once they hear that a problem is NP-complete, and actually, I would like you to think about this the other way around. So first of all, NP-completeness can definitely mean that there still is a possibility for finding exact solutions, and only when that approach fails, or you're under time pressure, or there's no really good known search tree for your problem, and you have to solve it nevertheless. Only then would I like you to think about approximation. So I guess my message is this: Whenever you encounter an NP-complete problem, be demanding an exact solution unless you really know it's not possible. So let's talk about approximation quality. Because, obviously, even though you've decided that you're content with a solution that is not optimal, you still want to ensure a certain quality of your solution. And we'll be looking at 2 different types of approximation algorithms in this unit. The first 1 is called a constant factor approximation. And what a constant factor approximation is, well, as the name says, there is some constant C, so when you have an optimization problem where you want to minimize some quantity, this algorithm will guarantee you a solution that is no worse than C x the best possible solution. For a minimization problem, your solution will be ≤ C x the optimum, or the best possible solution. And that is a guarantee that this constant factor approximation gives you. So this is for minimization, and for maximization--so minimization problem you're trying to find this point here; for maximization problem, you're trying to find this point here, basically. Your solution is at least as good as 1 over C x the optimum. So let's do a quick quiz to practice this. So say you have a factor-2 approximation algorithm, which means that C = 2. So you have a factor-2 approximation algorithm for vertex cover. You run the algorithm on an input, and it returns to you a vertex cover of size 100. And, of course, this is a correct answer, so it is, indeed, a vertex cover, we just don't know if it's the smallest possible vertex cover because we're using an approximation algorithm. What I would like you to tell me now is 2 things: First of all, what is the maximum number of vertices in an optimum solution, and please enter your answer here, and what is the minimum number of vertices in an optimum solution? And please enter this number here in this box. Now, the first 1 is actually quite trivial; so first of all, vertex cover is a minimization problem, so we're looking for a vertex cover that is as small as possible. Now, if the algorithm already finds one with 100 vertices, then that means, in an optimum solution, there cannot be more than 100 vertices. Because we already know that there's a vertex cover of that size, the optimum solution might be smaller, but it will certainly not be bigger. Now here comes the interesting part. So we just said vertex cover is a minimization problem, which means if you have a factor-2 approximation algorithm, then the solution that we found, and we found a solution with 100 vertices, is ≤ 2 x the size of an optimum solution. Which means if you solve this equation, that the optimum is at least as big as 100/2, or 50. So the minimum number of vertices in an optimum solution is 50. Now, let's do the same thing again for clique. So, again, we're going to assume that we have a factor-2 approximation algorithm, and the algorithm gives you a clique for a given input. Again we're going to assume that the clique that you're getting contains 100 vertices. So now what is the maximum number of vertices in an optimum solution to clique? And what would be the minimum number of vertices that are in an optimum solution? So please, again, enter your answers here in these boxes. Now, the important thing to notice here is that clique is a maximization problem. That is, we're trying to find a clique that is as large as possible. So we have already found a clique with 100 vertices. So an optimum solution has to contain at least 100 vertices, because we already know that a clique of this size is contained in the input network. So this time, this 1 over here is easy. Now, what about the maximum number of vertices in an optimum solution? There could be a clique that is bigger than 100 vertices, but we just haven't found it. Well, since clique is a maximization problem, we have to plug it into this equation here. So our solution was 100 vertices which is ≥ 1/C. C is the approximation factor, 1/C x the optimum, and if we solve that equation, we find out that the optimum solution contains ≤ 200 vertices. So this gives you a good intuition: For a minimization problem, a factor-2 approximation algorithm means that we could have found a smaller solution, but it is limited by this factor-2, and for a maximization problem, we could have found a larger solution, but this is also limited by this factor-2, or, more precisely, by 1 over this factor of 2. So the factor here kind of gives us a range that tells us, in a worst case scenario, how far away we are from the optimum solution. In addition to constant-factor approximation algorithms, which we will look at in more detail soon, we are also going to be talking about advanced algorithms that are known as polynomial-time approximation schemes. Scary term. What the idea of a polynomial-time approximation scheme is, it's a sort of more advanced constant-factor approximation, so you can think of it as a sort of scale. The idea behind a polynomial-time approximation scheme is that the running time actually depends on the quality that you want to get. With a constant-factor approximation you always get the same guarantee, say a factor to approximation, and in a polynomial-time approximation scheme, you can more or less decide what the quality is that you want, but the better a guarantee you're demanding, with respect to quality, the more running time you'll have to put into that algorithm. That's the trade-off here. But first of all let's look at constant-factor approximation. We are now going to meet Alice again. Alice, as you know, is working on vertex cover. So far she has been the most lucky in this course, because she seems to actually be working on a very well-behaved NP-complete problem. We also learned that there's good search trees, there's good preprocessing, and vertex cover was even fixed parameter tractable. Alice can be quite optomistic about approximating vertex cover, and actually she has come up with 2 different ideas of how you could approximate vertex covers. Here are the 2 possible ideas that she has come up with. The first algorithm takes this input graph and then looks if some edges are still not covered in that graph, and if that is the case it takes the uncovered edge and puts both of the endpoints of that edge into the vertex cover. Then the algorithm looks again if there is still some uncovered edges, if there are any of those, then it takes again one and puts both endpoints into the vertex cover and so on until all edges are covered. And she calls that algorithm "Take 2," because it always takes 2 endpoints into the vertex cover each time you go through that loop until you're done. Here is her second idea, and she calls that idea "Greedy," because what that algorithm does-- It's still the same in the first line here. It looks if some edges are uncovered. Then what it does is it goes through all of the vertices to determine which vertex could cover the most edges that are still uncovered. So which vertex is next to the most edges that have not yet an endpoint in the vertex cover, and then it puts that vertex in the vertex cover. It kind of tries to maximize the coverage that it can achieve in each round that this loop here is run. So looking at this strategy, so these 2 algorithms, what I would like you to think about for a moment here is, which of these 2 algorithms should we expect to perform better in terms of approximation quality? The one that always takes 2 endpoints, or the one that tries to maximize coverage? The answer here, of course it's a bit subjective, but I think from just looking at the strategies that these 2 algorithms use here, it seems as if the "Greedy" alogirthm should perfom much better, because it always tries to cover as much as possible in each round, while this one up here seems almost a bit stupid, because it just takes any edge and always blindly puts both endpoints into vertex cover. Although actually just 1 endpoint would be needed to cover that edge. You may already be guessing that I asked you this question because I am now going to show you the exact opposite. Because it's the case that although this algorithm here seems better, and the strategy appears to make more sense, actually from a point of approximation quality, at least if you consider the worst case, this algorithm up here, "Take 2," is actually the better algorithm. Let's look at the approximation quality of these algorithms, and we're going to start with the "Take 2" algorithm. Here is the little graph for which we are going to try and example. As a first practice quiz, how large is a minimum vertex cover for this small graph here? Please enter your answer here into this box. As almost always with vertex cover, there is a number of possible solutions here, but the minimum vertex cover will always be of size 4. I'm going to give you the solution that I found. I could for example put this vertex here into the vertex cover. This one, this one, and this one. Then I have these edges covered by this vertex here. I have these edges covered by that vertex, and this vertex here covers these 2. This vertex here covers the rest. Let's see what the "Take 2" algorithm would do if it's given this graph here. The algorithm of course doesn't know the minimum vertex cover, but I'd keep those vertices marked here to help you answer the next quiz. What I would like you to think about is, how many vertices from the minimum vertex cover, does the "Take 2" algorithm put into its solution in each loop? By loop I mean this part here. So each time that this part here is run, how many vertices that the "Take 2" algorithm puts into the vertex cover actually belong to the minimum vertex cover? I'm going to give you 5 choices for this. Is it something that we can't make a general statement about? Is it at least 1? Is it at most 1? Is it exactly 1? Or is it exactly 2? Please select the correct answer here. If you play around a bit with this algorithm what you will see is this. Each time that this loop here runs, it puts at least 1 of the vertices from the minimum vertex cover into its solution. So the correct answer is this. Let me illustrate this. If you take any edge here, so the algorithm starts out fresh, and you take any edge from this graph, it's impossible to take an edge where not at least 1 of the points is in the minimum vertex cover. Say we take this edge here, then "Take 2" would put these 2 vertices here into its solution, and 1 of those vertices is actually part of the minimum vertex cover. Or if the "Take 2" algorithm say uses this edge here, then we even have a better case, because both of the vertices that it now chooses to be part of its solution, are actually also part of a optimum solution. And this works for all edges. No matter what edge you choose here, you will always have at least 1 endpoint that is part of a minimum vertex cover. Now that we know that each time this loop here runs, it puts at least 1 vertex from the minimum vertex cover into its solution, what can we say about the running time of this algorithm here? As in the previous unit, we can express the running time actually in 2 ways. We can either use n, the size of the input, or we can use k, which is the size of a minimum vertex cover for the input graph. So when you run "Take 2" on a given input of size n, and where the size of a minimum vertex cover is k, how often is that loop here executed? Does the loop run up to n times? So up to the number of vertices times. Does the loop run at most k times? Or does the loop run at least k times? Please select the correct answer here. And this might have required a little thought, but since we have figured out that each time this loop here runs, it puts at least 1 vertex from the best possible vertex cover into its solution. It means that this loop can run at most K times because once it has run K times, it must have put all of the vertices from the minimum vertex cover into its solution. And in that case all of the edges are covered. So the condition for this while loop here saying that some edges must still be uncovered cannot be true any more after this loop here has run K times. So we're very close to saying something about the approximation quality of the Take 2 algorithm, because we now know 2 things about this loop here. First of all each time this loop here is run, it puts at least 1 vertex from an optimum solution into its solution set. And the second thing that we know is that this loop here runs at most K times, where K is the size of a minimum vertex cover. Now my question to you is, after this algorithm here is done, how many vertices has it put into its solution set? Has it chosen at most K vertices, at most 2K vertices, at least K vertices, at least 2K vertices, or on average 2K vertices? Please select all that are correct. There's 2 correct answers here. The first one is very obvious. It's this one here. Because the algorithm, of course, returns the vertex cover and the vertex cover can never get smaller than K. But the really useful answer is this one here. The algorithm has chosen at most 2 K vertices where K would have been the optimum number. Because each time this loop is run, it chooses at least 1 vertex from the optimum solution. What that also means is that it chooses at most 1 useless vertex that didn't have to be part of that solution. So the error that it makes is at most 1 extra vertex, but it can make that error at most K times. And for that reason, the algorithm chooses at most 2K vertices which means that although the Take 2 algorithm doesn't look very smart, it's actually a factor 2 approximation algorithm. It guarantees that the solution that it gives you is at most twice as big as an optimum solution. So let's now have a look at the algorithm that seems so sophisticated. So let's start out again with an example here. And by example, of course, I mean a quiz. Actually I mean a triple quiz, because I have 3 questions for you. The first one is the size of a minimum vertex cover for this graph here. The second one is the size of the greedy solution. And then finally the size of the solution that would have been produced if we had used the Take 2 algorithm. So please give me your 3 answers here. So the first one is easy to see. The size of a minimum vertex cover is 2 because you can just take this one here and this one here, and all edges are covered. Of course I constructed it that way. And that is also the size of the greedy solution. Because what the greedy algorithm will do is it will look at the whole graph and then say, oh which vertex could I use to cover the most edges? And actually this vertex here is next to 7 uncovered edges, and this one here as well so it will just choose 1 of them. Put that one into the vertex cover, say, and then in the next round all of these edges here are already covered, so it will just say, oh, here's another vertex I can use to cover 7 edges. So let's take that one because all of the other vertices, they can just cover 2 or 1 edge. So after executing this loop just twice, the algorithm is already done and it has even found an optimum solution. Now the Take 2 algorithm, on the other hand, well that looks a bit stupid compared to the greedy algorithm for this graph here, because what would it do? Well, it takes any uncovered edge--it doesn't really matter which one. So let's say it takes this one here, and then it will put this vertex here into the solution set and this vertex here. So all of those edges here are covered, and that one here as well. And, well it's not done yet, so it will have to choose another uncovered edge, let's say it's that one here, and again put 2 vertices into the solution set and then all edges are covered. So here the Take 2 algorithm, which you know by now is a factor-2 approximation algorithm, actually performs as bad as it can. So it really maxes out this factor-2 leeway that it is given. But now the important thing is this. Just because I have given you 1 example where greedy works extremely well doesn't mean that this algorithm will perform well on any network. We haven't yet proven that it has a good approximation quality. And a good way to test approximation quality is to always try and construct an input for which the algorithm will perform really, really bad. So basically we are now going to try and trick this algorithm here--the greedy algorithm--into picking suboptimal vertices, basically using this greedy strategy against it. And if we do this basically using this greedy strategy against it, that will give us some indication on where this algorithm could fail and how badly it could fail. So if it's a factor 2 approximation algorithm, if it's a factor 1.5 approximation algorithm maybe, or if it's actually not a good approximation algorithm at all although it sounds good. And of course this is similar to some of the problems we have already had in this course. Finding out how to trick this algorithm, that takes a bit of playing around. So next to the screen here I have lying about 4 or 5 sheets of paper on which I experimented around to find out how I could trick this algorithm, and whenever you want to trick an approximation algorithm, it just takes a bit of time to sink your teeth into that. But here is something that I have come up with, and it's very similar of course to the ideas that other people have also had to try and trick the greedy algorithm. So I'll start out with the amazing number of 24 vertices. Now as if this weren't enough, I will now add 12 additional vertices. You can now see why I used up so much paper playing around with this. And then I'm going to connect them like this. Now my question to you is, how many vertices would greedy choose if we gave it this graph here as an input? And please enter your answer here. And the answer is, of course, that greedy would choose 12 vertices because it always chooses the ones with which it could cover the most edges. So this one here, this one here, this one here, this one here, and so on. And that is, of course, a total of 12 vertices. What am I going to do next? Well, guess what? I'm going to add more vertices. And this this time I'm going to add 8 vertices, and I'm now going to connect them this way, always groups of 3. And guess what I'm going to ask you now? How many vertices does greedy choose? And the answer here is that greedy chooses 20 vertices. Why is that? Well first of all, greedy will choose the 8 vertices that I added down here because they have the largest number of edges attached to them, which is this one, this one, this one, you get the picture. So we'll choose 8 vertices down here. And then after that the whole bottom part here of the network will be covered so it will then proceed as it did before. It will choose these 12 here. So that makes a total of 20 vertices. So maybe you already see a pattern emerging here, but I am now going to deviate just a little bit from this. I am now going to add 3 vertices here, 3 vertices here, 3 vertices here, 3 vertices here, so this is a total of 12 vertices. And just so that we keep that in mind here, up here we have 8, here we have 12, and here we have 24 in these layers here. Now how am I going to connect those? And this is where the picture gets actually quite messy. I'm going to connect them to all those here. So each of these 3 vertices here that I've added is connected to 6 other vertices, so there's 6 edges going out here--1, 2, 3, 4, 5, 6--and what you see also is that each of the vertices here in this layer--the first layer that I added-- is connected to exactly 5 vertices. So 1, 2, 3, 4, 5. And of course I deliberately constructed this in this way, and I'm going to draw these out here in a minute. I just want you to understand the principle. I've added these 12 vertices here in a way such that the greedy algorithm will first take these 12 here, then it will take these 8 here, and then it will take these 12 here. So I'm constructing my graph so that the greedy algorithm will choose the vertices in exactly the reverse order that I am adding them to the network. And in that way I can make that algorithm behave very, very, very badly. You would think that theoretical computer science is a clean and not messy science, but I think I can just show you the opposite here. But you get the principle now. So these 24 vertices here are the first ones that I have added, and I have now added these layers here. So I first added these 12 here, then these 8, then these 12 here in such a way that the greedy algorithm will choose these vertices here to be in a vertex cover and these here in a vertex cover. So the question, of course, now is, can I add even more vertices to this so that I am still making the greedy algorithm take my new vertices that I add? And in fact I can, but it will become really messy to draw. So I'm more going to explain to you how I'm going to do this rather than actually draw out every single vertex. So you see for each of the vertices that I've added here, I've connected them to larger and larger groups of these vertices here in the middle of those original 24, and I can continue this for a little bit by now adding 2 vertices which would then be connected to groups of 8 down here. So this would be connected to all over here, and then I will do the same part here. So again I can add 2 vertices here, and I will connect them to this group of 8, then 2 more vertices here, and I will connect them to this group of 8. And if you want, you can of course check. It will still be such that the 6 vertices I've now added will be the first ones that are picked by the greedy algorithm. And then those 12, and then those 8, and then those 12. What I can then do is I can add another 4 vertices, and this time I will look at groups of 12. So I will add 4 vertices connected to these 12 here in the middle, and I will add 4 vertices connected to these 12 here in the middle. And we'll be done soon, so in case you think this gets very tedious, bear with me for just another moment here, and we'll be done. So we've added another 8 vertices, and again these will be the first ones picked by the greedy algorithm. And final addition of vertices actually. I will add another 11 vertices. And these vertices will be connected to all 24. Now my question for you is, how large is a minimum vertex cover for this network that I've constructed here? And remember every vertex is connected to those 24 vertices here in the middle. So please enter the size of the minimum vertex cover here into this box. And the answer--and of course I've given you that hint--is 24. Because every vertex that I've added is connected to these 24 here in the middle. So by just choosing those, I can cover every edge in the graph. Now my next question to you is--how many vertices will the greedy algorithm choose? So please give me your answer here in this box. Well, the way we constructed this graph or the way that I first construct it--well of course as follows that we made the greedy algorithm take all vertices into the vertex cover except for those 24 here. So every vertex except for those that are actually in a minimum vertex cover. So how many are there. Well, up here we have 11, then we have an additional 14 here, then we have 12 here, 8 here, and 12 here, and that is a total of 57 vertices as opposed to a minimum vertex cover, which is 24. So given that the greedy algorithm takes 57 instead of 24, what's the approximation factor for this concrete example here where the approximation constant? And I would like to enter your answer here and please give me 2 digits after the decimal. And the answer here is that the approximation factor is 2.38, so it's performing worse than that take two algorithm, which have an approximation factor of 2. So what that means is that the greedy algorithm, although the strategy might sound good, doesn't perform as well as the take 2 algorithm, which is guaranteed to have an approximation factor of 2 and that's why it's so important to prove properties of algorithms and not just saying--well, this is a sound strategy, this one sounds good, because while it may sound good, it can actually in some cases perform really bad. So does this mean that the greedy algorithm is useless and we should always use and we should always use the take 2 algorithm. Well, not really because actually for most instances that you would encounter in a real world setting, so for example a telecommunications networks as Alice is trying to do-- this algorithm here will perform very well, but it is not guaranteed to perform very well. So now my question for you is, of course, which would Alice do if she want to approximate vertex cover? Should she run the take 2 algorithm, should she run the greedy algorithm, or should she actually run both algorithms? And the answer here is that I would recommend that Alice run both algorithms because both algorithms, if you look at them, are very simple so they can be implemented to run very fast even if the input graph is very large. So if she can first, for example, run the take 2 algorithm and then she already has a solution for which she has a guaranteed, so running the take 2 algorithm will defer some information about an optimum solution and that is the optimum solution cannot be smaller than some quantity x. And if she then runs the greedy algorithm, she can just see if the greedy algorithm gives her a solution that is better than the take 2 algorithm. In this case, she should take the greedy solution or if it produces adverse solution, so if by some accident she's running it on a graph that has the same properties than the one that we just constructed to trick the algorithm, then she can take the solution, and in this way, she gets the best of both algorithms. She gets the good performance or the generally good performance of this algorithm, but she ensures that she is within certain guarantees. The important thing here to keep in mind is just because an approximation algorithm sounds like it make sens or sounds like it is a good idea, doesn't really mean that it is a good idea. It could be a good idea, but unless you analyze the algorithms and try to prove that properties--you'll never know. So Alice is now super, super happy, but what about the others? So I suggest that we take a look at Dave here, and Dave, as you remember, was working on a logistics problem, so what he was trying to solve was shortest tour. And actually, last time we left off, Dave wasn't too happy, because we found out it is not very easy to find a good search tree or a pre processing strategy for his problem. On the other hand, of course, we mentioned that in practice shortest tour is usually very easy to solve, but from a theoretical perspective, maybe we were a bit lucky for Dave; if we're not looking for the best possible solution, but except an approximation, and then if we should find an approximation, Dave can get a little happier here and of course he doesn't have to be as jealous that Alice has such an NP complete problem and he seems to have a harder one. Now lucky for Dave, there is a constant factor approximation algorithm for shortest tour, but since Dave is not that proficient in theoretical computer science, I think he doesn't really stand a chance of coming up with this algorithm himself, so you will have to pay close attention now to be able to explain it to Dave. The concept that we will use is that of a spanning tree, and if you've had an algorithm course before, you will know what a spanning tree is, but I'm quickly going to explain it to you just to make sure. A spanning tree is a part of a graph or actually it's a selection of edges in a graph so that the result looks like a tree. Well, what that means is that you select edges so that you still keep the whole graph connected, but you don't have any cycles, so a cycle would be something like this where you can leave a vertex and then come back to it another way, so you select edges so that the whole graph is still connected, but there can be no cycles, so to have you figure it out, let's do a quick quiz here. This is the thing that worked 3 times. I'm going to give you 3 choices of what a spanning tree could be, and the red edges are always those that I'm selecting here. I would like you to tell me in which of these cases the red edges from a spanning tree for the graph. And actually, just this one here is correct. The other 2 are not correct, and as I told you, the conditions for a spanning tree are first, it can contain no cycles. and actually here, we have a cycle, so this can not be a spanning tree. And over here, we said that a spanning tree must still keep the whole graph connected, so all vertices connected to each other, and this is not the case here, so here, we have basically split the graph into 2 parts. Here is 1 part and here is the other part. So this is also not a spanning tree. So now that you know what a spanning tree is, I would like to introduce to you the concept of a minimum spanning tree. So a minimum spanning tree is still a spanning tree on a graph, and in order to find a minimum spanning tree, you actually need to have a special kind of graph, and that is one that looks just like the input for shortest tour. And what I mean by that is that all of the edges have a certain number assigned to them. So in the case of shortest tour, those were distances, but it can be other values as well; that doesn't really matter. The important thing is that each edge must have a certain value attached to it such as in this one here. Now what is a minimum spanning tree? Now, first of all, let's take any spanning tree for this graph here. So let's say we take this spanning tree. And what you can do if you have a graph like this where you have numbers attached to the edges is, for each spanning tree, you can sum up those numbers. So here we have 2+4+3+2+3+6, and the sum of that is 20. And so what you say is that this spanning tree here has a weight of 20. Now if you choose another spanning tree--for example, this one here-- that spanning tree will have a weight of 3+4+3+2+3+6, which is a total weight of 21. And now you can almost guess what a minimum spanning tree will be. A minimum spanning tree is the spanning tree for the graph for which this total weight--the sum of all of the edge numbers-- is the smallest possible one. A graph can have more than one minimum spanning tree, but every minimum spanning tree has to have the property that the sum of the edges is as low as possible. And, of course, I am going to quiz you on that. So what I would like you to do now is to think about what would be a minimum spanning tree for this graph here, and I would like you to make a check mark in each of the boxes that correspond to edges you would put into that minimum spanning tree. Now how do you go about finding a solution if you don't have an algorithm for it? Well, first of all, this edge here costs just 1, so we probably want to take that. Then we have a lot of edges that just have a weight of 2, and, of course, they have been arranged in a way that is very beneficial for us here because we can actually put them all into the tree, and we almost have a spanning tree here. There's just one vertex missing, which we still need to connect to that tree here. And the cheapest way to do that is to use this one edge down here, of course, using 4 instead of this one here which would use 6. So this is a minimum spanning tree for this graph, and this has a total weight of 2+2+1+2+2+4, which is a total of 13. How can we use a minimum spanning tree for shortest tour? Well there's actually one more thing we need to talk about in terms of terminology so that I can give you an algorithm for shortest tour. Then you will hopefully be able to explain to Dave as well, should he ask you. The edges are still there, but we will just look at the minimum spanning tree for now. The terminology that I would like to introduce to you is that of a walk along a tree. Of course you can define this formally, but it's actually quite easy to see. What I mean by this is if you want to do a shortest tour on a tree, then a shortest tour on a tree goes something like this. You start out at a certain vertex, and then you can travel along that tree by using every edge exactly twice. Just the way that I'm doing right now. Actually it's not possible to do it any other way. I mean of course you can walk along the tree in a different order, but actually if you want to do a walk along a tree, then you have to use every edge twice. Then of course you return back to your origin. This would be a walk along the minimum spanning tree. Enough with introducing new words to you. What is the algorithm that I propose that Dave should use? It's a very simple one actually. The algorithm is now quite simple to describe. Of course it takes a bit more effort to actually implement it. Given any graph, the first step that we do is we calculate a minimum spanning tree for that graph. That is something if you have had an algorithms class you know to be doable in polynomial time. That can be done in O(n²) time for an in vertext graph. Then you take a walk along the tree, and you can guess that that can be done in polynomial time as well. The running time of this alogirthm here in total---so it's a polynomial time algorithm. Now where I probably need to convince you is that this is actually a good approximation algorithm, because it sounds so simple again doesn't it? My claim now is, as I've written here, that this is an approximation algorithm for shortest tour. Actually it's a constant factor approximation algorithm for that problem. So how come? Well, since you already saw one constant factor approximation algorithm, I am actually going to let you figure this out. Let's start out by taking 2 numbers and comparing them. The first number is the weight of the minimum spanning tree, and by weight I simply mean if you take the sum over all edges that are in the spanning tree, that's what I will call the weight of the spanning tree. The second one is going to be the length of the shortest tour for the network. Now first of all I would like you to tell me what you can say about these 2 numbers. How do they compare? Is the weight of the tree smaller than the length of the shortest tour? Is it smaller than or equal to the length of the shortest tour? Are both the same value? Or is the weight of the tree larger than or equal to the length of the shortest tour? Or is it always larger than the length of the shortest tour? Please select which one is correct here. And the answer here is that the weight of the tree is always smaller than the length of the shortest tour. And the reason for that is the following: When you have a shortest tour for a given graph, then you can always transform the shortest tour into a spanning tree because the shortest tour visits each vertex at least once, so the connectedness is given. But, of course, a shortest tour always contains at least 1 cycle because you have to get back to the vertex where you started from. So you have to remove at least 1 edge from the shortest tour in order to make it a spanning tree. And then you have a spanning tree with a weight that is definitely less than the length of the shortest tour, because you have removed at least 1 edge. And now here, you even have a minimum spanning tree, so the weight of the minimum spanning tree must be even smaller. And that is why the weight of the minimum spanning tree is smaller than the length of the shortest tour. Now I would like you to look at a third number, and that is this 1 here, the tour. So what is the length of the tour that this algorithm constructs here? And I'm going to give you 3 options here: Is it equal to the weight of the tree? And by tree I mean, of course, here, the minimum spanning tree. Is it equal to 2 times the weight of the tree? Or is the length of the tour, at most, 2 times the weight of the tree? And by tree I mean the minimum spanning tree here. And the answer here is that the length of the tour is exactly 2 the weight of the spanning tree. That is because of the way that the walk was constructed, so you'll remember that when I just showed you how to walk along a spanning tree, or any tree for that matter, you use every edge exactly twice. So, if the weight of the tree is the sum of all the edges, then the length of the tour will be twice that number. So now one final piece of information. Let's compare the length of the shortest tour for the input graph with the length of the tour that the algorithm computes. So, again we're going to have the length of this tour, and by this I mean the one output by the algorithm, and compare that to the length of the shortest tour. Again, I would like you to tell me what I should put here. Is the length of the tour computed by the algorithm smaller than the length of the shortest tour, is it at most as large, is it equal, is it bigger, or is it at least as large? And of course, the part that is easy to see is that this is the shortest possible tour, so these two here cannot be true. And also this one here cannot be true because, after all, this is an approximation, and it is not guaranteed to give us the optimum solution. The question now is which one of these two here to choose. So is it always strictly smaller or can it be the same? And the correct answer here is that the length of the shortest tour can actually also be equal to the length of the tour output by the algorithm. It's not guaranteed to be, but it can be. And this could be the case, for example, if the input that we are given is already a tree, then the spanning tree will just be the input network itself. Then a shortest tour is indeed a walk along that tree. So in this case, you would have equality here. So length of the tour that we compute is at least as large as the length of the shortest tour but not always strictly bigger. So now that we have 3 pieces of information, let's put these pieces together. So the first two that we will put together is the statement here on the second line and this one here on the third line. So we know that the length of the tour computed by the algorithm is exactly two times the weight of the minimum spanning tree. Now we will use the piece of information that we will have up here, so let's make a little bit more space down here. We know that the length of the shortest tour is larger than the weight of the minimum spanning tree, so we can put this part down here. Now isn't that beautiful. At least I think so. So the length of the shortest tour must lie somewhere in between the weight of the minimum spanning tree and the solution that you have just computed, which is twice the weight of the spanning tree. And this means that the algorithm I specified here is actually a constant factor approximation algorithm for shortest tour. Oh, I forgot to write the factor here. Well, of course I did that deliberately because this is going to be your final quiz for this algorithm. Please tell me what is the approximation factor, using this information we've just figured out, that this algorithm has for shortest tour? And the approximation factor here is a 2, because the length of the shortest tour is larger than the weight of the tree. And the solution that we output is twice the weight of the tree, so it must lie somewhere in between here, which tells you that this solution here is at most twice as large as an optimum solution. So Dave can now be very happy because he has a factor 2 approximation algorithm for his problem. Which, of course, should he ask you, you can easily explain to him, because you figured out most of this by yourself. So now we have factor two approximation algorithms for Alice, who is, of course, very happy about this. And we've also found a factor two approximation algorithm for the problem that Dave was working on. So Dave is, of course, equally happy. Now, the question: Since Alice and Dave apparently are working on problems that can be approximated very well, what about Bob and Carol? And as you remember, the problems that Bob and Carol are working on are closely related to the one that Alice was working on. So, Alice was working on Vertex Cover, Bob was working, as you'll remember, on Clique, and Carol was working on Independent Set. So we already know that we have a factor two approximation algorithm for Vertex Cover. And from the previous units, you also know how closely Vertex Cover is related to, well, first of all, Independent Set, but also Clique. Given the close relation, we take this algorithm here and simply carry over our insight for Vertex Cover to Clique and Independent Set. So the question now is, given this factor two approximation for Vertex Cover, and given the close relation of Vertex Cover to Clique and Independent Set, do we now also know that there's a factor two approximation for Clique and Independent Set? And I'm just writing Independent Set as IS here, to save some space. And the answer here is, although it might be a bit surprising, it's actually that we can't be sure yet. You might be inclined to think that the answer is yes because the reduction from vertex cover to independent set was very simple. The thing is this reduction, simple as it may be, could still be destroying the approximation factor, and this is what we'll have a close look at now. So let's investigate this a bit further. And for now, we'll be focusing on vertex cover and on independent set. So let's say we're given a graph with N vertices, and we're looking at the smallest possible vertex cover, so a minimum vertex cover for that graph. And for the largest possible independent set. So a maximum independent set. So let's say the size of the minimum vertex cover for this graph here is K, so some integer smaller than N. And then--and you know this from the reduction between vertex cover and independent set-- the largest possible independent set that we can find in this graph has size N minus K. So now, instead of finding the smallest possible vertex cover, let's run the factor two approximation algorithm. And that algorithm will give us some number, and that number is guaranteed to be less than or equal to 2k. And what that means for the independent set, of course, is if we take those N vertices here and take away those 2k vertices, then of course we still arrive at an independent set, and that independent set has a size of at least N minus 2k. Because the size of the vertex cover and of the independent set always add up to N. So this here would be the optimum solution, and this here would be what the vertex cover factor two approximation finds. So what about the approximation factor? So you already know that for vertex cover we have a factor two approximation. And the way you arrive at the two is, of course, since this is a minimization problem, you take what the approximation finds and divide it by the size of the optimum solution. So it's basically 2k over k, and that's equal to two. Now, what about independent set? So, independent set is a maximization problem. So, for vertex cover, we took what the algorithm finds and divided it by the size of the optimum solution. But that was because it was a minimization problem. For a maximization problem, given how we define approximation factors, we'll have to do it just the other way around. So the approximation factor here is the size of the optimum solution divided by what the approximation actually finds. So it's divided by N minus 2k, which is equal to one plus K over N minus 2k. So the factor two approximation algorithm for vertex cover is actually a factor one plus K over N minus 2k approximation algorithm for independent set. And my question to you is, so this 1 + K over n-2k may look a bit strange, but is this here actually a useful approximation factor? And I'm going to give you four choices here. So it might be that, because this is a very general question about general graphs, and this also looks a bit complicated, that it's not possible to say at this moment if this is a useful approximation factor. It might also be that this is a useful approximation factor, but only if the independent set of the graph that we're given is very large. So it's a majority of the vertices. Or could it be that it is a useful approximation algorithm if N is very large, because N is in the denominator down here. Or is it just simply not a useful approximation factor? So please select the one here that you think is correct, and then let's discuss. So it turns out that, unfortunately, this is no useful approximation factor at all. And the reason for that is that the approximation factor depends on the size of the minimum vertex cover for the input graph. So the first thing to notice is, of course, that it's not a constant factor approximation algorithm, because we can be given any graph, and that graph can, of course, have different size vertex covers. Let's say we wanted this to be at least a factor two approximation algorithm. What that would mean is that one plus K over N minus 2k is smaller than or equal to two. So when you solve this, what you get is that K must be smaller than or equal to N thirds. Now, seeing this, you might be inclined to think, "Why isn't this answer here correct?" Because if K, which is the size of the smallest vertex cover, is less than or equal to n thirds, then most of the vertices are in an independent set, so the answer could be, if the independent set is very large, then we also have a good approximation algorithm. But the problem of that is, of course, that in order to really assess the quality of the approximation, you need to have an exact solution. And if you already have an exact solution, then approximation, of course, makes no sense anymore. So it's an approximation factor that can only be determined in hindsight once you have calculated an optimum solution, in which case you don't need the approximation anymore. So this here is also not a correct answer, and the unfortunate thing is it's actually not a useful approximation at all. So unfortunately the factor-2 approximation that we have found for vertex cover does not carry over to clique or independent set. Well we've only shown that it doesn't carry over to independent set, but since independent set and clique are, again, so closely connected you can already see or at least guess why it doesn't carry over here as well. And I've actually mentioned a similar thing to you in the last unit when we talked about fixed parameter tractability. Where it was also the case that if you took the size of the optimum solution as a parameter, there is a parameterized algorithm for vertex cover, but clique and independent set are both not fixed parameter tractable. So the thing here is this. A reduction that you use to show NP-completeness is, in a way, a very coarse way of reducing problems to each other. So coarse that it can destroy approximation factors, that it can destroy fixed parameter tractability, and so on. So there are special types of reductions that will keep approximation factors or fixed parameter tractability. Unfortunately we can't go deeper into them in this course, but you should just know that just because two problems are closely related, that does not mean that algorithmic techniques, such as approximation algorithms, easily carry over from one problem to the other as well, unfortunately. Now here, just because the fact 3 approximation algorithm for vertex cover doesn't carry over here doesn't mean doesn't mean there can not be an approximation algorithm for Clique and Independent Set; it's just that we can not use this one. So Bob and Carol still don't have to be unhappy, but unfortunately, I'm now going to make them very unhappy. For Clique and Independent set, there is no constant factor approximation algorithm unless P equals NP. That, of course, is a very unpleasant surprise and it's very surprising, so where did I get that from? Well, the proof for this result here relies on some very, very deep results of theoretical computer science which you will only get to know in very advanced theoretical computer science courses, if ever. But what I would like to do is just give you an intuitive idea for why there is no constant factor approximation algorithm for Clique and Independent Set unless P equals NP. Suppose we're playing a game--and that game is "guess the word"-- where I want you to guess a word, and all I'm giving you is how many letters this word has. So one, two, three, four, five, six, seven. So assuming you haven't already skipped ahead to the next part of this unit, can you guess my word? Of course, you can not guess the word simply by knowing the number of letters, because there are lots and lots and lots of 7-letter words. Now, what if I gave you two letters.? Can you then guess my word? Of course, if you can't guess it, just skip ahead, but I think there are good chances that you'll figure this one out. Of course, I was thinking of the word "Udacity." Chances are, I think, you've gotten this one. So what does this have to do with approximation algorithms? Well, it shows that even though a problem can be very hard initially, once you know just small parts of the solution it can become rather easy to obtain a complete solution. So the deep resolve that underlies the statement here basically works the same way. It says that if you know a small part of the solution of Clique and Independent Set, then you can use this to construct an optimal solution. The real proof of this is much more complex, but that is the basic idea. Having a constant factor approximation algorithm for Clique or Independent Set would reveal so much information about a perfect solution that you could construct a polynomial time algorithm from this. And actually there's a similar result for Vertex Cover, surprisingly, but Alice doesn't need to worry that much, so for Vertex Cover there is not constant factor approximation that is better than 1.36, unless P=NP. And actually, many people believe that this number here should be higher, but this is the highest number that has been proven so far. Now, finally, what about Bob, who is solving Shortest Tour? Well, Shortest Tour is a problem that hasn't been investigated that much. In the general case, for it's closely related problem, Travelling Salesman, we don't know. But there are many special cases of this problem where good approximations are actually possible. But the bounds of approximation for Shortest Tour and Travelling Salesman have actually not been investigated that much. So if you're really into it, that will be a possible area for research. Although, it seems to be quite hard to actually transfer the results from here over to Shortest Tour. So maybe we can make Alice a little bit less happy; although, she has been quite lucky in this course. She has a constant factor approximation algorithm, and the limit of 1.36 probably doesn't affect her that much. And Bob, well, it's not really clear if he should be happy or not, but as we mentioned, in practice it's likely that his problem is actually very well solvable. For some problems, there's no constant factor approximation algorithm unless P=NP or there are constant factor approximation algorithms but we know certain limits for how good that constant factor can get. There are other problems that allow for what is called a Polynomial-Time Approximation Scheme and the idea behind the polynomial-time approximation scheme is basically that if you put in more running time in to your algorithm, and that algorithm is called a polynomial-time approximation scheme, then you will get a better solution or a better guarantee for your solution, and depending on how good you want that guarantee to be, then again certain implications for the running time you have to put in. So, for an almost perfect solution, you will likely have to put in time that is pretty close to exponential time or even exponential time and for a solution that is--well, maybe only within a rather course bound of an optimal solution, you will need less time. Now, the NP complete problems that we have encountered so far obviously fall either into the category of having a constant factor approximation algorithm or admitting no such algorithm and that is why I'm going to introduce a new NP complete problem to you now called knapsack. A knapsack is a very simple to describe. Knapsack gives you as input a set of objects such as these here and each object has a size and a value and those are both integer number, so you have an integer size and an integer value and we're soon going to do an example for this, and then, additionally, you have given a container and that container has a limited capacity, and that capacity again is an integer, and the question you're trying to answer with knapsack is actually very simple, you're trying to ask the question, "What is the maximum value that I can put into this bag here while observing the limited capacity?" So the total sum of the size of the objects that I select to be in the knapsack, so say I select this object to be in the knapsack and this one here but I don't want this one here, then that means that the total size of these two objects cannot exceed the capacity of the container and among all other possibilities of putting objects into the container without exceeding maximum capacity, this gives me the best possible value, and of course, here for the values, we again do the sum to calculate the total value. Knapsack is known to be NP complete and now let's do a little example for this problem just to familiarize yourself with this and I'm going to give you a number of objects here, and of course, each of these objects has a size and a value. Now, my question to you is if I give you a container and that container has size 10, which objects out of these seven here should you put in to the container to maximize the value without exceeding the size here. Please check all the items that you should put in to the container to maximize the value. And the correct here is that you should put this one here B, C, F and G. Now, I've chosen the sizes and values so that this is not that difficult for you to figure out even though it is an NP complete problem in the general case. I suppose you have seen that there's lots of objects here, which have a comparably small size and a very large value. So probably putting in F and G is rather obvious and also I would presume putting in B and then once you're there, you can see what else you got and you've already used up 5 of your size units so you cannot put an E anymore. And then the best value of the remaining objects--A, C and D is given to you by C, which has a value of 5 as oppose to 4 and 2, and also you cannot put in more than one. So that makes C the only candidate to also put into that container, and for that, you get a total value of 3+5+5+2, so you get a value of 15 in your container. Actually, not using up all the space in the container because you only have size 2, 4, 2, and 1, which is the total size of 9. So when a container of size 10, you can carry a value of 15 given these objects over here. Knapsack is a very interesting problem because in a way and this is very informal, of course, it is among the easiest NP complete problems. So, where as clique and independent set for example seem to be very difficult, Knapsack allows for some pretty interesting algorithms and both of those algorithms which will be important for our P-test is called pseudopolynomial algorithm and you'll soon see why it is named that way. I'm first going to explain the algorithm to you; so you're given an instance of knapsack, which means you're given n objects. Each one has size s so we'll just label those sizes here S₁, S₂ until you get to Sn. Each object also has a value so the values will be labeled in the same way. So you have V₁, V₂ and so on until you get to V-sub-n. And now, here's the algorithm to solve knapsack. The algorithm basically works for the table that looks like this. The table has n rows one, two, three down to n and the table has a lot of columns one, two, three, four, five, and so on and so on and so on until we get to a number that I'll call V. And by V, I mean the sum of these values here. So the total V₁ plus V₂ and so on plus V-sub-n will be called B. And this is the table that we'll now use. Of course, I still have to tell you what values go into that table. Each cell here in this table is going to have the following meaning. I'll call the row that we're at I and I'll call the column that we're at J. Then, this cell here in row I and column J has the following meaning The cell here in this table will be the minimum size required to achieve a total value of exactly J Using the objects one, two, three, four, and so on until you get to I, so you cannot use all objects So, for example, in the first you row, you can only use object one In the second row, you can only use objects one and two and in the third row, objects one, two, and three and so on and that means that sometimes, of course, it's not possible to achieve a value of exactly J using these objects and so, we'll just write a dash into the table if that's not possible. So, let's use the example from before so you have the objects A, B, C, D, E, F, G and here we have the sizes and the values. So, the sizes were three, two, two, three, and so on. And to construct this table here, we'll, of course, have to label those items here So, this is item one, this is item two, three, four, five, six, seven. So, my first question to you now, a brief quiz here. What do we put in here? So, how many columns does this table have and how many rows does this table have? So the number of rows is the number of objects and that is 7, and the number of columns is the total sum of all the values, so 2+3+5+4+3+5+2 which is 24. So, we have 7 rows and 24 columns in this table. We're going to fill this out row by row, so we start in row 1 then row 2, and so on. So for row I and column J, what we want in this table is the minimum size required to achieve a value of exactly J using the objects 1 to I. Now in the first row, we only have the first object available, so the only thing that we can achieve is a value of 2 using size 3. So, value of 2 using size 3 and all of the other ones are just not possible. Second row, we have two objects available, we have objects A and B available, so what we can achieve is a value of 2, a value of 3, and a value of 5. Now for value of 2, we need size 3 again. For value of 3, we can do that for size 2. And for value of 5, we need size 5 and I'll put out one more row here for you. I'm not going to show you the part that goes beyond 8th row because that will not be important for what I'm about to explain. The interesting part here is this one here because object number 3 has size 4 and value 5 which means that we can achieve value 5 actually by putting in this object instead of using A and B as we did in the row before. Let's go to row 4, because in row 4, I can show you something very interesting. First value is not that interesting. So remember that in this row here, row number 4, we now have available to us, object A, object B, object C, and object D. If we are to go through the whole table, how efficiently can we fill out this table? And now that we have D available here in row number 4, I can show you something very interesting because you can fill out this table quite efficiently. Now, here we are in the column labeled 7 which means we want to achieve a value of 7. How can we achieve a value of 7? So you already know that we can achieve a value of 7 using these three objects, A, B, C because we have this row here. Now, what are the different possibilities of achieving a value of 7? We could either do this through the row above because we know that we can achieve it using objects A, B, and C, so it could be row above. We could also try to take D directly. That D has a value of 4 so here, that's impossible, so take the new object and finally there's only a third possibility here. Well, since D has a value of 4, we could try to achieve a value of 3 using the objects we had in there before and then add D to it. So add D to another set and that is the set of size 3 and we know just from looking at this table here that at size 2, we can already achieve a value of 3. D has a value of 4 and has a size of 5, so 2+5 is 7, which is actually now the same as this one here but of course you would be taking the minimum of the required sizes. So here, we would enter a 7. The interesting part is this. In order to fill the cell here, we do not need to go through all possible combinations of the objects that we have, we just need to consider three cases. Each of which can be calculated in constant time if we have the row previous to the row that we're trying to fill out. And of course, here it's time for another quiz. So my first quiz to you--you can already see there are going to be two--is what is the size of this table? Is is O(n²), is it O(n<i>v) and you remember v is the sum of all values, or is it even precisely n<i>v?</i></i> And of course, I want you to give me the best possible answer here. And, of course, the size of the table is exactly n<i>v because we have n rows</i> and v columns, where v is the sum of all the values. So the size of table is n<i>v.</i> And of course, once you have the complete table, then you also have found the solution to knapsack because once you have the complete table, you just start out in the right-most column and then go to the left, to the left, to the left, to the left, and each time, you look through each column and find what is the minimum size that I would need to achieve exactly this value and once you find a size that is at most as large as your container you would be done. So constructing this table here solves knapsack. Now, my question, the second quiz is of course the time required to build this table. Is that time 2^n given that we have n objects here, is that time O(2^n<i>n) or is that time O(n<i>v)?</i></i> And the surprising thing here is--well, it's not surprising anymore, but surprising once you see it-- is that the time to construct this table is O(n<i>v).</i> There's no exponential part in the running time for bringing this table, apparently at least. Now, wait a minute, we have an NP complete problem here knapsack and have just shown that the running time for solving this problem is of the order of n<i>v given n objects</i> and the total value of those objects, if you sum it all up, of v. Now, I just have to quiz you here of course. Does this mean that P=NP, although I've told you we don't know, and of course, I don't? I just want you to select something here but also to think about why. Now, the answer is rather obvious because I've already told you that we don't know if P=NP and actually, we believe that it isn't the case. The interesting part about this one here is why is the answer no, and the answer is that v might actually be exponential in n. So when we build this table here and you remember it has n rows and it has v columns, v could be some exponential function of n, so v could for example be 2^n because we haven't specified the maximum value of those objects here. And that is why this algorithm is a pseudopolynomial algorithm because it looks very polynomial, but actually there are cases where it is not polynomial. But you can already see why I said at the beginning that knapsack seems to be one of the rather simple NP complete problems--simply because the existence of the pseudopolynomial algorithm here. Now, if you really want to bug me here, you could of course now argue the following-- why not just divide all of the values--each value of each object by v. Then the total sum of objects would be 1 and the running time here would presumably be O(n). So is that a possibility? And the answer to that question of course is a little more subtle. So there's two reasons why that doesn't work. The first reason is a very formalistic one. The RAM can only handle integers. Or at least the RAM cannot handle numbers with an arbitrary precision because having an arbitrary precision is exactly the same thing as having an infinite amount of values available for each variable. And we said that the RAM doesn't support that. And actually your computer also doesn't fully support that. So you might be working with numbers such as 1.2345 or so, but these numbers are always rounded numbers. So also your computer does not have arbitrary precision. It' s pretty well thought out normally how your computer handle such numbers which is why we normally don't notice but in general there's no arbitrary precision for your computer also. Secondly, the table size wouldn't change. So we're not allowed to do this. But let's say we're allowed to do this and then represent all of the values in the table exactly. Then, the table size itself wouldn't change because you start out with a table that has 1, 2, 3, 4 and so on until you get to the columns. And now in your new table, you would just have the same amount of columns only the columns would be labeled 1/v, 2/v, 3/v, 4/v until you get to 1. The third and the fourth are not valid reasons. Just because then P would be NP is no counterargument against this. And of course, as I've just shown you, that is also not true. But asking this question here leads us to something else. What if we were to divide all values by some number, which I'm going to specify to you, and then round it down. By rounding, we do two things. So by rounding, we would make numbers that the RAM can handle. And also in the case of rounding, the table size would change. So let's say you had a table that looked like 0.5, 1, 1.5, 2, 2.5, 3, and so on. Then, you could always put two columns together. So these two. Except for the first one. That would become 0. But all the others you can put together. So those two would become column 1. Those two would become column 2. If you have 3.5 here, they would become column 3 and so on. So you would be able to scale down the table but of course the whole thing comes at a price. Because scaling down the table means that you put two columns together only taking the minimum of it and therefore possibly arrive at a suboptimal solution. Because certain objects where one object has a slightly higher value than another one become indistinguishable using this technique. Well, we're not going to divide by V. We're going to divide by some factor. Dividing all values by a certain factor is a good idea but we have to round and this gives us an error. Now, if you take a close look at this, you can almost see the approximation algorithm emerging here because what happens when this factor here becomes very large? Well, then we scale down the table that we build a lot. So here we have n and here we have v. If we divide all values by some large factor and of course we have to round, then this table here becomes very small but of course our error also increases. And if this factor here is very small, which means we almost keep all of the original table, well then our running time is still very large but the error that we make is potentially smaller. So this is exactly where the time and quality tradeoff will come from. Let's now have a look at that in more detail. Now, let's have a closer look at approximation and again, we're assuming that we're given an instance of knapsack, which means we have any objects and the sizes and the values of those objects are given to us and you know that the total sum of those values here we'll call V. So what we said now is that we wanted to scale down all of these values. So we'll scale this down to V₁/x and then round down and I'm going to write the rounding down like this, which is called a floor symbol--in case you haven't come across that. So I'm going to write down the same thing here, so this is going to become V₂/x, this here is going to become V₃/x, and so on. We're going to have Vn/x. So what rally do we use here for the x. Well, of course, that takes a bit of either playing around or pre-knowledge. In this case, we'll set this x here and we're going to set this to V/n<i>1-c.</i> Now, you already know most of the constants here, so you know n--n is the number of objects and V is the sum of all values. Now, c is some value I'm not yet going to specify to you. We'll just say for now that c lies between 0 and 1. Now, using these values here, if you use the knapsack algorithm using the table, my question to you is what is the running time now of the knapsack algorithm using these values here. So the original running time here was O(n<i>V) since the V was this value here and now</i> since we scaled it down using this factor here what we now have to do is we have to replace V by V/V/n(1-c), which is the same as O(n²<i>1/1-c), which is the same as this one here.</i> Now, of course, in order to be very correct here, we have to constraint c so that it cannot be 1; otherwise, this running time here would be undefined--well, that's okay. As you will soon see that actually makes quite a lot of sense. So you've seen that we now have made the running time independent of V and that is of course a very cool thing because V originally was what could make this algorithm run in exponential time and now we can use this factor 1-c here to control the running time. So the running time will, of course, again become exponential if c becomes very close to 1, but it will be polynomial if for example we set c to 0 and something in between when we set c to other values. Now, I still haven't told you what the c here is going to be about, but we'll soon figure that out. Now, of course, using the scaling process here, we kind of allow the algorithm to make errors and what I would now like you to think about is what kind of error are we introducing by using this scaling method. So dividing by that quantity here and then rounding down. And there's two answers that are correct here--namely, the first two ones. So the error actually comes from the rounding because as we discussed before-- if we did not round, then the table size will be changed and also the solution that we get. So the objects that we picked wouldn't change, but through these rounding down here, what can happen is that two objects that actually have a different value now appear to the algorithm to have the same value. So the algorithm say of objects V₁ and V₂ and we're going to do an example here to say-- V₁ has a value of 8 and V₂ has a value of 9, and we're now choosing this x here to be 2, then V₁ gets the scale down value of 4 and V₂ gets the scale value of 4.5. Now, assuming that both objects have the same size, it would be better to take V₂ instead of V₁, but now if we round down, both objects get a scales down value of 4, so the algorithm might pick V₁ over V₂, although that is sub-optimal, but the algorithm can't tell anymore because both objects in terms of value look the same to the algorithm. The cool thing is that we can actually specify and quantify how large that error is going to be. So this is not right. We can't specify it and this is exactly what we are now going to do. So let's get the facts. The optimum solution contains, at most, N objects, simply because there's no more than N objects in the input itself. So it's almost a very coarse estimate, but it'll do for us. So due to the rounding, we may introduce some error. So the algorithm, when working with the rounded objects, might tell you that it's best thing to take this object here, this object here, this object here, and this object here, for example. But instead, it could have been better to actually take this one here instead of that one here. Or this object here instead of this object, and so on. Well, some, some might also be the same, but sometimes we might make mistakes by just taking the wrong objects. So we know that these kind of mistakes can only be made if the value of A divided by X, rounded down, is the same as the value of B divided by X, rounded down. So mistakes of this kind, taking the wrong object, can only be made if, to the algorithm, object A, value-wise, looks the same to the algorithm as object B, value-wise. Which means that the value of A-- so the original value, divided by X, rounded down, is the same as the value of B divided by X, rounded down. But that actually allows us to quantify a mistake. So mistakes can only be made if this condition here is fulfilled. Now, the amount of value lost in each mistake that we make is, of course, the value of the object, B, which is the more valuable object we should have taken, minus the value of object A. And now my question to you, and this is of course a bit challenging, is what is the maximum difference in value that actually objects B and A can have? And the way to figure this out is to look at this condition, because the mistake is only made if this here is fulfilled. So what I would like you to figure out is what is the maximum difference in value between the objects B and A? And please enter your answer here. And the answer is that difference in values can, at most, be X. So if the difference in value between B and A is larger than X, value of A divided by X and the value of B divided by X, would round down to different numbers. So that's why we know the amount of value lost in each mistake that we make is actually smaller than X. And that is a very cool thing to know, because with these three things, knowing how many objects can be, at most, in an optimum solution, how many mistakes we can have made. And having quantified how much value we have lost in each mistake allows us to quantify the overall mistake that we can have made, at most. And I call this the maximum value lost, as opposed to an optimum solution. And that maximum value is, of course, well, there's, at most, N objects in an optimum solution. That means we can make, at most, N mistakes, and each of those mistakes costs us less than X. So the maximum value that we can lose overall by rounding down is smaller than N times X. And that, of course, is the absolute error that the algorithm can make by this rounding down technique. So now let's figure out the relative error here. And the relative error, since KNAPSACK is a maximization problem, is of course the value of an optimum solution divided by the value of an approximate solution. So let's just call the value of the optimum solution V opt, and opt stands for optimal here. And in that case we can write the approximate solution as V opt minus N times X. Now, this is not the precise value of the approximate solution, but it's a bound for the approximate solution. So we know it cannot get any worse than that. So, but to be precise here, of course then we'll have to write it like this here. Because we know that the approximate solution will have at least this value. Actually, it will always be bigger, because we have a strict smaller than here, so we should more precisely even write it like this. So it's smaller than V opt divided by V opt minus N times X. Now, we can simply write this as one plus N times X over V opt minus N times X. We know something about V opt because the value of an optimum solution can, at most, be the value of all of all objects combined, and we call that number V. So we can rewrite this as one plus N times X over V minus N times X. Now, let's have a closer look at X. How did we define X? Well, we said that X was equal to V over N times one minus C, where C was some number between zero and one. So if we plug the value of X into this equation here, what we get is one plus V times one minus C over V minus V times one minus C. Which means that Vs here simply cancel out, and you get one plus one minus C over one minus one plus C. Which is the same as one over C. So I didn't tell you about C earlier, but what we just found out is that the approximation factor of our algorithm is actually one over C. And you'll remember that the running time was also dependent on C. So we already figured this one out, right? It was O of N squared over one minus C. So a good approximation would be to set C close to one. Because then the relative error becomes almost one, but in return--and you see that in the running time here--the running time actually becomes very large, because if C is close to one, then you get a very small denominator here, which means that the overall running time, since it's a fraction depending on this, gets very large. But if you're happy with a--and I'm going to just call it bad approximation, then C can actually be smaller than one. C will always be larger than zero, so it'll always be a positive number, but it could be 0.5, 0.2 or even smaller, what will then happen is, if C is smaller than one--so it's this very tiny fraction, well, then actually this part here in the denominator will be very close to one. So the running time is very good, but this fraction here will actually increase. So in return, forgetting about the running time, you get a relative error that is much worse. And this is exactly the principle behind the PTAS. So we're trading on the quality of the approximation factor, which is this fraction here--one over C--against running time. More running time means we can get a better approximation factor. A worse approximation factor, in return, will mean that the algorithm runs faster. So this is already pretty amazing. Now, one last detail here: As you'll notice, the running time of the approximation algorithm is actually polynomially dependent on C, which is why this PTAS is sometimes also referred to as a fully polynomial time approximation scheme, or F PTAS. For the majority of polynomial time approximation schemes, the running time actually depends exponentially on the approximation factor that you want to achieve. But this is something for a more advanced course. I still sometimes find it mind-boggling that KNAPSACK is NP-complete, meaning that, in terms of intractability, KNAPSACK is likely to be just as hard to solve as nastier problems such as SAT or CLIQUE. So approximation, I think, shows very well that even within NP-completeness, there's a broad spectrum of difficulty, if you will. So, some of the most difficult problems to approximate appear to be CLIQUE and INDEPENDENT set. And then in the middle of the spectrum, we have problems like VERTEX COVER. And then we have problems which have a PTAS or even a fully polynomial time approximation scheme, such as KNAPSACK. All of these problems here are NP-complete. But some of them can be approximated with no constant factor at all. Others have algorithms that, if you don't look closely, could almost be mistaken for being polynomial. Of course, all of this is still under the assumption that P does not equal NP. If P equals NP, then all of these problems here would be polynomial time solvable, anyway. Now that we have looked at approximation, what else is there that you could try to tackle NP-complete problems? Next time we'll be basically poking around, meaning that we'll be looking at how randomization and random algorithms could maybe help us tackle these problems here as well. So, see you next time. As we've seen relaxing the requirement to find the best possible solutions can allow us to find polynomial time algorithms for NP complete problems. At least some times, so approximability is something that varies very much from problem to problem. For some problems, we know that we cannot approximate them at all, unless P=NP. Other problems such as vertex cover at least have a constant factor approximation algorithm. And then there are those very, very well-behaved problems such as knapsack for which we know polynomial time approximation schemes. But what if still all of this doesn't help? Well, in that case, we will literally have to start poking around. We'll be talking about randomization. So we have talked about using search trees, pre-processing, and approximation to solve NP complete problems. But there's one technique that we haven't yet talked about and that is using randomness to solve challenging problems. Now you know that so far in this course, I have always insisted on finding guarantees for the performance of algorithms. I wanted to have guarantees for the running time of the search trees. I even wanted to have guarantees for approximation. So am I ready to give that up now? Actually, I'm not, because even when we use randomness, we can demand certain guarantees from our algorithms. So, one way we could demand a guarantee from a random algorithm is, that we say it produces the correct or best possible solution with a certain probability. So best would be in the case of optimization problems and correct, of course, in the case of decision problems. And so, we'll also write this down for decision problems and finally we could also say that the algorithm has a running time that is random, and we want the running time to be polynomial with a certain probability and of course in this case here, we would be demanding that the solution is always the best possible solution or the correct solution. Well, actually we could also have combinations of these, but then the algorithm becomes rather weak in my mind and actually I'm not aware of any example where I have seen this before. Now, some of these approaches have special names and this one here is known as a Monte Carlo algorithm, and this one here is known as a Las Vegas approach. Don't ask me what that says about casinos in Europe versus casinos in America because I have no clue. Now the two approaches, Monte Carlo and Las Vegas are actually related to each other, and if you think about it for a little while, I think you can figure that out yourself. So my question for you is how are Monte Carlo algorithms and Las Vegas algorithms related to each other, and I'll give you three choices here. Is it that any Las Vegas algorithm can be turned into a Monte Carlo algorithm? So any algorithm over here can be turned into an algorithm like this. Is it the other way around, that any Monte Carlo algorithm can be turned into a Las Vegas algorithm? Or is it even that the two approaches are, roughly speaking, of course, more or less the same. And the correct answer is the first one--any Las Vegas algorithm can be turned into a Monte Carlo algorithm and the reason for that is the following-- In a Las Vegas algorithm, we said that the running time was polynomial with a certain probability and that means that we can let the algorithm run a few times, so sometimes it will take polynomial running time, sometime it would take exponential running time like this. So this is suppose to be the running time and let's say in the first time it's also exponential and we basically jut watch over the algorithm and as soon as it takes longer than polynomial time we stop it, we cut it off, and that would then give us exactly a Monte Carlo algorithm because here we said for this approach we demand that when we get the solution that solution is suppose to be the best possible one. So here the algorithm would also produce the best possible solution but we stopped it. We are stuck with some suboptimal solution or even no solution. Here the same thing as well, but then we started the next time and it just uses polynomial time and then we use that solution and this is exactly how a Monte Carlo algorithm would behave as well. It produces the best solution with a certain probability and in this case here this probability is dependent on the running time of the Las Vegas algorithm, which sometimes will be polynomial and sometimes will be exponential. In this unit, we will be working with Monte Carlo approaches because we're looking at NP complete problems and actually as you will see there is not that many algorithms using randomness for NP complete problems anyway and one I'm going to show you in more detail is a Monte Carlo algorithm. Now the important thing about a Monte Carlo algorithm is this here, the probability. Now of course it would be great if the probability with which we get the best possible solution would be some constant because then we would have a very good algorithm as the next quiz will show you. So say we have a Monte Carlo algorithm with probability 1/2, how often do we need to run it until we are 99.9% certain that we have the best possible answer and please enter your answer here in this box. Now if you don't feel comfortable with probabilities, of course, you can also skip ahead, but even if you just have a basic knowledge of probabilities, you can probably get this one. If we have a Monte Carlo algorithm that produces the best possible solution with probability 1/2 and we run it a couple of times, then what happens. If we run it the first time, we can be 50% sure that we already have the best possible answer. Then we run it again so the probability in the second run is again 1/2 that we do not get the best possible answer and in the third run, it's again 1/2 and so on. Now this is the probability of getting a suboptimal solution and of course, if we want to be 99.9% sure that we get the best possible solution, the probability of getting a suboptimal solution should be smaller than 0.1% and then the problem becomes (1/2)^n and n is the number of times that we run this algorithm here should be smaller than 0.001, which is the same as 0.1% and then you can just solve for n and get the answer and we have to run this algorithm just 10 times which is pretty neat. Now of course for an NP complete problem, it's very unlikely that we get a probability like this because as you can see we could very, very, very quickly in polynomial time get a solution that is almost guarantee to be optimal. So what you will find for most Monte Carlo algorithms for challenging problems is that the probability here first of all becomes sometimes even exponentially small and second that it also depends on the input size but we'll soon see how that works out concretely. Now before we dive deeper into the algorithms, I want to make one important point. When you use randomness in computation, there is sometimes a danger of taking the poking around that I mentioned in my topic before this unit a bit too literally. So some people when they see an NP complete problem or an NP hard problem and NP complete of course being for the decision problem and NP hard for the optimization problem, just terminology means both problems are hard. And then some people would just say--oh this is NP complete and this is NP hard, well let's just try very, very many random solutions and pick the best one, which of course works better if you have an optimization problem than a decision problem, trying many random solutions sounds easy, actually it is easy, and you trust that the solution that it produces will be good enough. Well, sometimes you have no better choice than that, but in my mind I think you're playing a dangerous game and I want to illustrate this for you. So let's say that we play a game and the rules of the game are as follows-- you bet an amount x whatever you want and then you throw a die and of course, the value can be 1, 2, 3, 4, 5, or 6, and if you throw a number between 1 and 5, I will give you back x+30% of x, and if you throw a 6, I'll give you back 0. Now my first quiz for you and again this involves a bit probabilities should you play this game, and let's say you can play as often as you want-- And the answer here is that--yes, I think you should play the game well, at least, if you're okay with playing games with money. So with the probability of 5/6, you're making 30% profit, and with the probability of 1/6, you're making 100% loss. So, your expected profit for each time you play is going to be 25% of this part over here minus about 16.7% for this part over here, which means each time you play, you make about 8.3% of profit on average as an expected value of course. So, this game looks good, and you play it a couple of times, and now, the following scenario happens. Now, let's say you watch other people play the game first and you notice the following thing: In the last 40 throws, no six was thrown. My question to you is, of course, why could that be. Could that be due to pure chance? Could that be due to something being wrong with the die or maybe even someone is cheating? Please check all of those that are correct. And the thing is all three are correct. So, 40 throws, no six, the chances of that are actually smaller than 0.1%, but that does not mean that it can't happen. So, it can happen by pure chance. Of course, you could also have the case that something is wrong with the die or somebody is cheating. So you've been watching the game for awhile and then suddenly the person who is playing that game announces, "Last round!" So this is the last chance for you to play the game. And the odds already looked pretty good and also the last 40 times that you checked actually nobody lost. What would be the factors you would have to take into account to determine if and how much to bet in this last round? Now of course this is a rather subjective quiz, but I think we should agree more or less. So I will give you four opinions that you could have, and I also think that more than one of them are valid. So the first opinion could be certainly because the odds are fantastic. You get 30% back if you throw a 1, 2, 3, 4, or 5. So that will give you 30% profit. And in the last 40 throws, no 6 was thrown and the probability for that is smaller than 0.1%. Or maybe your opinion is, well, you can play a little. You know your chances of winning 30%. That's fine. But you should be ready to lose what you're betting here. The third option could be that it kind of depends on your risk affinity. So if you're ready to play a riskier game, you might want to bet a little bit more or stay out of the game altogether. And finally, one opinion could be well better not because it does seem a little bit suspicious. And I think that the last three options could be valid responses. I think the first one is actually not. And the reason for that are two things: One is that I think it kind of does seem a bit suspicious but even if you don't think it's suspicious you don't really understand what's going on here. So on the last throws, it has all turned out very, very, very well. So no 6 was thrown. Always 30% payout. Now the reason could be pure chance and maybe the person offering the game at that point just had bad luck but the thing is you don't really know. So if you decide to play, I think you should only play a little and it certainly depends on your risk affinity if you even want to get into the game because I do think the whole thing seems a bit suspicious. Now what does this have to do with randomized algorithms? And of course any analogy can be criticized at one point or the other but I think it fits rather well. If you use a randomized algorithm without having any guarantees, well first of all, at a certain point in time, you have to determine that it's the last round. You're not running the algorithm any further. You've run it 200 times or 2000 times but then at a certain point you just have to say "Okay. This is it. This is going to be the result that I use." And it might be that the last 400 or 500 times or in this case 40 times the algorithm has not found a better solution. It has found one that seems very good and the solution has not improved so at a certain point in time you're just going to decide. Well, it's likely that this is a very good solution. Now, here's the thing where the analogy actually does not hold because if you think about it when we're dealing with an NP complete problem the chances of winning are not 5-6 over here. Indeed, we're playing a game with exponentially small probability of winning. It's like this, when you run a randomized algorithm without guarantees, you're playing a game with bad odds. You don't really understand what's going on and in the end even though you run the algorithm multiple times you only have one shot of getting it right at the point that you decide to stop your algorithm. Should you run a randomized algorithm without any guarantees, I think the rules are almost the same as the one for this game here. So if the stakes aren't very high so the probability of trying to solve this may be not that important and you're willing to take that risk then you can do it and sometimes it's the only possible way. But I think that an algorithm with guarantees is almost always preferable. First of all, you know what's going on and secondly and I think that's also very important to emphasize in order to get these guarantees here you have to construct an intelligent algorithm. So rather than just poking all the way around, you're poking intelligently. It's almost the same as with the search tree. So just using randomness in the way as brute force only that in this time it's random force. And I think the name already says how powerful that is but when you have guarantees, you're directing that random force in a certain direction and that of course tends to improve your results dramatically. Now in general and you might have come across one or more of these examples, using randomness is of course quite important in Computer Science. You might've come across randomness, for example, in crytography where randomness is in a way the only way to fully securely encode a message. You might've encountered randomness in something called symmetry breaking. Let's say you walk down a hallway and somebody comes in your direction, and you're trying to get out of the way of that person but the moment that you get out of the way, that person also tries to get out of the way in the same direction, and so if you did not have random decisions, then you would almost certainly crash into each other. And finally randomness is often used in simulations, so when you do physics simulation or financial scenarios, then of course, also randomness is something very, very useful. Now, the difficulty with using randomness to solve NP complete problems is this, in all of these examples here, being as random as possible is something rather desirable. So in cryptography, you want perfect randomness because that gives you the most security. Symmetry breaking works best if you have as much randomness as possible, so that these two entities, say, will make completely independent decisions of each other. And in simulation of course too, because the point of using randomness in simulation is to simulate random processes, so you want to model that as good as possible. Now for NP complete problems, this doesn't work because for NP complete problems, we don't want perfect randomness. What we are looking for is a needle in a haystack and finding a needle in a haystack simply by poking it from a few random directions won't really help. And that is why we need to direct our randomness. Let's say, you use randomness in a very naive way to solve clique and just assign all of the vertices, random values of 0 and 1. Now let's say you're doing this for a graph with n vertices. Well, actually I think you can answer this question if I give you four choices from which to choose. So is it 1/n²? Is it (1/2)^n? Is it 1/2 n? or is it 2^n/n²? And of course, the answer here is 1/2^n because for each vertex you have to make the right choice. If the vertex does not belong to the largest possible clique, then you have to assign it a 0 and if the vertex does belong to the largest clique, then you have to hope that the random algorithm you're using is assigning it a 1. And the probability of each correct assignment is one-half and you have to do this n times. So the probability of finding the largest possible clique using simple pure randomness, which of course is the same as 1/2^n which is exponentially small. We can't just hope to get the best solution by pure chance alone. We need a more intelligent or strategic approach for this. And there are several ways to employ randomness in a more intelligent way but there is one that is actually quite common. Let's assume that this here is a huge list of all possible solutions. So, for NP complete problems or NP hard problems, this will be an exponentially large list, and the strategy of more intelligent random algorithms, and we're soon going to see a concrete example for that, is basically to randomly pick out certain solutions here in this list, and let's say that the list is ordered in some way, which I'm going to explain in more detail when we get to the concrete example, and then, the strategy is to explore solutions that lie around the ones that we randomly picked so like this. So, you would look at all of these solutions here, something like this. Now, of course, each time the algorithm runs here, it can only investigate a number of solutions that is polynomial in size, but of course the list of all potential solutions, so this whole thing here, has exponential size, and through the way in which you design this algorithm, well, first of all, you want to ensure that you land in good places so to say, and this is often, of course, not very trivial to prove how to do that, and the other thing is that you want to have a good and intelligent exploration of the area around your solution again something which is of not very easy to prove or show. Actually, we can't expect it to be any other way after all we're solving a very challenging namely NP hard or NP complete problem here. So, just to prepare you a little bit for the realities that you are about to face. Let's do another quiz. Let's say we have a randomized algorithm for an NP complete problem and that algorithm has a fixed error probability. Let's say the algorithm makes an error with a 90% chance and only gives us the correct answer with 10% chance. So, should we expect that a randomized algorithm for an NP complete problem that has a fixed error probability so to say with 90% chance gives us the wrong solution and with 10% gives us the correct one? Should we expect such an algorithm to run in polynomial time? And I'll give you three choices, and as always, more than one can be true. The first choice I'm offering you is no because if we would run that algorithm just a few times we would almost be guaranteed a correct solution even though this algorithm here that I am asking you about makes an error with a 90% chance for each time that we run it or if the answer no we should not expect that because the number of potential solutions is exponential, and the algorithm, since it runs in polynomial time, and this of course anthropomorphises a bit can only afford to check a small part of that exponential solution space if you will. And finally, one choice I'm offering you is yes, we should expect that because the laws of NP completeness that we have gotten to know in the past units do not account for randomness. So, just as these laws don't account for small basis or if we are content with an approximate solution, it could be that randomness makes such algorithms possible. So, please check all of these here that you think are correct. And the correct answers here in my opinion are the first two. The first one is even if the algorithm makes an error with 90% probability, running it only a few times, it does guarantee a correct solution and that of course as you've seen before these probabilities here have to be multiplied with each other if we run the algorithm a couple of times. So, if you run it the first time, of course we have a 90% error chance, but if you run it the second time, we only have (90%)² error chance. If we run it three times, we have (90%)³. And once we have run this algorithm 50 times, we have an error probability of 90%^⁵⁰, which is about 0.5%, and running it a couple of times more of course, we can even get this figure out much much lower. So, since we only have to run it a constant number of times to get the error very very low, it would mean that we're staying still in polynomial time, but we're almost guaranteed a perfect solution. Now, I'm not saying that this is impossible because the laws of NP completeness indeed do not account for randomness but of course it's very very unlikely It's almost the same as with the approximation algorithm where you wouldn't expect an approximation algorithm with an approximation factor of 1.01 even though for some problems it has not been proven that that is impossible but you still wouldn't expect it. Now, the second choice here I think is also correct. And that is basically my reasoning why I say you shouldn't expect this. The number of potential solutions for an NP-complete problem is exponential. Since the algorithm only runs in polynomial time, it can only afford to check a small part of that solution. That is basically the image that we just had where you only able to explore small areas of the whole solution space. And of course you have to employ the strategy. I just think that with this strategy it is highly unlikely to get an algorithm with this performance up here. It just doesn't make sense because you're still poking around a lot. So why would you get a fixed error probability in an exponentially large space if you can only afford to check a polynomial size part of it. And finally as I said the laws of NP completeness indeed do not account for randomness, but the thing is this just because that is so it doesn't mean we should expect anything to happen. Again, I think this is the same thing as with the approximation algorithm. Of course for some problems it would theoretically be possible to have a 1.01 approximation algorithm, but it just seems too unlikely to be true. So in the last quiz you have seen that it's not very likely that we can find a randomized algorithm for an np complete problem that in polynomial time will deliver us the right answer with a fixed probability to be honest, we currently don't know if such an algorithm is possible or impossible but many believe that it is highly unlikely and so far no such algorithm has been discovered it seems that sometimes, however, if we either cross this one here off our list or this one here off our list and you'll soon see that it doesn't really matter what we cross off our list but if we kind of reduce the number of wishes that we have it seems that sometimes we can use randomness to at least improve the running time of exponential time algorithms so just as you've seen, when we optimize search trees it's sometimes also possible to improve the running time of exponential time algorithms or the base of the exponent using randomness now the question is could we use randomness to help Alice solve vertex cover or help Bob solve his clique problem, or Carol her independent set problem, or Dave his shortest tour problem at least when we say that we do not have this requirement here and the answer unfortunately is - we don't know we don't know if there are good randomized algorithms to solve vertex cover, or clique, or independent set, or shortest tour at least not if we're demanding guarantees so there are randomized algorithms that will look through a random number of solutions and these are also used in practice, but again they do not offer any guarantees there's one problem, however, that is MP complete where I can give you a randomized algorithm that's at least better than the best known deterministic algorithm. And that problem is 3-SAT As I hope you will remember, the 3-SAT problem had as an input a boolean formula with n variables and the boolean formula has a special property because it's 3-SAT, namely that each clause has exactly 3 variables And the output I'm looking for is, an answer to the question If this boolean formula, with n variables, where each clause has exactly 3 variables, has a satisfying assignment So how can you use randomness to solve this problem? Well there's a very simple, and in my mind very elegant, algorithm that in 1999 was proposed by Uva Sherning to solve a 3-SAT instance with n variables So this is the algorithm and as you can see it's really quite simple So you start out by picking a random 0 - 1 assignment for the variables and then you go into a loop that iterates 3n times, where n is the number of variables and what you do each time in the loop you take one of the clauses that is not satisfied and then you randomly flip one of the variables of that clause So what does this randomly flipping mean? You start out with a clause and we already know that this clause will have only 3 variables because we're dealing with 3-SAT Now you randomly pick one of those variables, say we randomly pick the 2nd one, and then you just flip its value meaning, if it was assigned to true you now assign it to false, or vice versa if it was assigned to false, now you set it to true and since it's a random process we don't know which variable we're going to pick So instead of this one here, we might have also picked this one here, and of course this one here And what happens is by this flipping, you satisfy this clause, but of course other clauses might become unsatisfied Now if we run this algorithm here once, what are the chances that it will succeed and find a satisfying assignment provided that the initial boolean formula does indeed have a satisfying assignment if it doesn't have a satisfying assignment, the algorithm can't find it but let's assume that it has one then the success of this algorithm will depend on two things the first one is: how far the initial assignment is off the satisfying assignment or, in other words, picking this random 0 - 1 assignment to the variables, how many variables did we get right? and by right I mean we set them to the same value that they would have in a satisfying assignment and the second one is, are these random choices that we make here, by flipping the variables, successful So if we are somewhere near a satisfying assignment, and by chance the algorithm makes the right choices then we would find a satisfying assignment provided –but we made that assumption– that the boolean formula here actually has a satisfying assignment But let's look at those two success factors a little more closely And of course, again, we'll do this as a quiz so, my first question for you regarding the first success-factor is this. In this line here, when we pick a random (0, 1) assignment for the variables how many variables can we expect to get right on average? By right, I mean, if in a satisfying assignment the variable is set to false, then this random assignment here also sets it to false and if it needs to be set to true this random assignment here also sets it to true. So, my three choices for you here are the following: Can we expect to nearly get all the variables correct in this random assignment here? Can we expect to get about half the variables correct in this random assignment here? Or is it not possible to make a statement about this here? And the answer here may be surprisingly is that using this random assignment here we will on average already get half of the variables right and that is of course because we have a 50% chance for each single variable of actually getting it right when we do it by coin flip because if in a satisfying assignment this variable needs to be set to false, there's a 50% chance that a random assignment will also set it to false and if it needs to be set to true, there is also 50% chance that we actually set it to true using this randomized assignment. Now, of course, sometimes we might get more variables correct and sometimes less but especially if N is large we can expect to get about half of the variables right in an average run. Now, the success-factor II, once we are half way there so to say what are the chances that using this process here will get us through the satisfying assignment again, if the original Boolean formula actually has one of those. So let's assume that we have an unsatisfied clause then we would pick one of those clauses and randomly flip one of the variables So, what I would like to know from you is what can we say about the condition that we find ourselves in, in this case over here? Is it true that at least one of the variables of that clause must be flipped? Is it true that all of the variables of that clause must be flipped? Is it true that the chances of flipping the correct variable are at least one-third? Or is it correct that the chances of flipping the correct variable are at most one-third? If you're a bit quiz savvy, probably this one was very easy to get, but I'll explain the answer to you of course as well. So, at least one variable must be flipped and the chances of flipping the right variable are at least one-third and I''ll explain it to you. Now, let's say we have one clause and that clause has 3 variables and it's not satisfied. So, if the overall Boolean formula has a satisfying assignment this means that in the satisfying assignment either this variable here, this one here, or this one here must evaluate to true and currently, they all evaluate to false. So, at least one of those variables must be flipped in order to satisfy the clause. What are the chances that we're flipping the correct variable? Meaning that we indeed choose the variable to flip that would also have a different value in the satisfying assignment. Well, since we select one out of three variables those chances are at least one-third. So, they are exactly one-third. If in a satisfying assignment, you have exactly one variable that evaluates to true or a variable set to false with a knot and the chances are even better if in the satisfying assignment you would have two of three variables that would need to evaluate to true, but there are always at least one-third. We initially can expect to get about half of the variables right and a random change will be successful or a random change and clause that is not satisfied will be successful with the probability of at least one-third and that of course also means that the probability of making a mistake meaning that we flip a variable that we should actually not have flipped is at most two-thirds. So another way that we can understand this is that we start out with a random assignment that has a distance of n/2 to the satisfying assignment Again, assuming that assignment exists. So, by distance, I mean the number of variables we need to flip. We can expect this to be about n/2 as we just found out. Each time this algorithm here goes through the loop, there's two things that can happen The first thing is that we move closer to the satisfying assignment and by closer, I mean that we gained one more variable that is set to the same as it would be in the satisfying assignment. So basically, making a step forward happens with probability one-third but of course as we also just found out, we can also make a step backward and kind of flip the wrong variable and the probability for doing that is at most two-thirds. Let's show worse case analysis here so we will erase this one here and say in a worse case, we make a step forward with probability exactly one-third and we make a step backward with probability exactly two-thirds. And how often do we make this step? Well, the loop here is executed 3n<i>.</i> So what happens is the following, we start off here with our random assignment and then 3n We either move forward with probability one-third or we move backward with probability two-thirds. And then the next time assume that we are lucky, we have move forward, we again move forward with probability one-third and backwards with probability two-thirds and this goes on and on and on and on until we either reach the satisfying assignment or which is much more likely, we don't reach the satisfying assignment. We might even get farther away from it. Actually, chances are pretty good that we are. Now, the nasty thing here of course is that we move forward with the lower probability than moving backward. So, the probability of coming from a random assignment to the satisfying assignment by running the algorithm once actually doesn't seem too good and the exact probability analysis here is somewhat complicated especially if you haven't had an intermediate course in statistics yet, but what we can try to do even if the statistic analysis is may be a bit complicated is at least do a simulation. So, run a program to do simulation for me. Assuming you start at a distance one half from a satisfying assignment What's the probability of making n/2 steps in the right direction if the probability of making a step in the right direction is one-third and the probability of making a step in the wrong direction is two-thirds and you try 3n and then run this for different values of n and here's what I got. Now, of course, when you run such a simulation yourself, you might get a little bit different results, but you will be more or less in the same range, I hope. Here are the results that I got. For n equals 10, you end up at 2.8% probability of making n/2 steps in the right direction. For n equals 20, it's 0.084% and you can see that it rather quickly decreases. Now, my question to you here, does the probability decrease as a function of n again logarithmically with n, linearly with n, or exponentially with n. And as you can see, each time we add 10 to n, so 10+10=20+10=30+10=40, the probability of reaching a success decreases by well more or less with a factor of 10 if not more. So this is clearly an exponential decrease. As we add a constant to n, the probability decreases by a certain factor and that factor is one-tenth or ever worse. So we definitely can see an exponential decrease of the success probability as a function of n. Now, the exact analysis of this algorithm is not within the scope of this course, although I would say it's understandable if have had a mid-level college course on probabilities and statistics. And the exact analysis of this algorithm here reveals that if the Boolean formula has a satisfying assignment, then this assignment is found where the probability of about 3/4^n times some polynomial of n and I'll just write that as p(n) here. So how many times do you have to run this algorithm given the success probability here to find the satisfying assignment on average, assuming there exist one. Now, if you have had a basic statistics course, you should already know that the expected running time, so how often we have to run this algorithm until we find a satisfying assignment assuming the Boolean formula has one is the time for a single run divided by the success probability of one run. And of course, I'm going to let you figure our the final answer for this as our next quiz. So is the expected running time O(3/4^n times the polynomial of n) which is this polynomial here times some other polynomial, which will represent the time for one run of this algorithm here or is it O(4/3^n times the polynomial of n) times the time required for this algorithm here, or is it O(3/4^n times the polynomial for this algorithm here) divided by this polynomial here, or finally, is it O(4/3^n times the time required to run this algorithm here) divided by this polynomial. And of course the correct answer here is this one because you're taking the time for one run, which is into the power of c and then you're dividing by the success probability, which is this here which means you need to divide by the polynomial and you need to divide by 3/4^n which is the same as multiplying by 4/3^n. So the expected running time is O(4/3)^n<i>n raised to the power of some constant</i> divided by a polynomial of n, and actually, we can combine these two terms here because this is a polynomial of n and this is a polynomial of n, which we can simply write as n to the power of some constant. Now, finally, let's see if you remember the use of O notation correctly. What does that equal. And of course, this is a bit of a nitpicker question but it equals O(1.3c₄^n<i>n to some constant)</i> and the reason being is that 4/3 is equal to 1.3333, of course, this goes on infinitely, and for O notation to be correct, of course, you have to round up, no matter what the digit is that you're rounding. So the expected running time for this algorithm here is actually exponential in n. Now, you might be asking--well, okay, so we know that three SAT is solvable in exponential time, now we introduce randomness, which means we're not even sure that we're finding the satisfying assignment, at least not totally sure, and we're still ending up with exponential running time, so what's the deal here. This table here is taken from a survey by Tobias Riege and Jorg Rothe. I had chose the development of better and better algorithms for 3-SAT So up here, you can see the deterministic algorithms for 3-SAT and down here you can see randomized algorithms for 3-SAT and you can see how over the years the algorithms get better and better and better and the same thing over here. Now, this is of course going to be a rather easy question, but which of these two algorithm categories generally seems to be better Is it the deterministic algorithms up here or the randomized algorithms down here. As you can see the randomized algorithms generally have much better time bounds or well they might not seem much, but you already know that for exponential time algorithms little differences here so 1.47 versus 1.32 actually makes quite a difference so they have generally a lot better time bounds than the deterministic algorithms It seems that randomized algorithms allows us to achieve a better worst-case running time than deterministic algorithms. Of course, up here it has the advantage that it's actually done after this amount of time whereas down here, it's always an expected running time and as I said you're gambling a little bit. You cannot be 100% sure that the algorithm has found a satisfying assignment even though there might be one. The question, of course, is if this table here actually suggests that randomized algorithms for 3-SAT will always be faster than deterministic algorithms. And I would argue no here, simply for the reason that such a statement would in some way have to be proven or at least argued for with more than just empirical data, but I believe we can also think of some other reasons why randomized algorithms currently have better upper bounds than deterministic ones. So my question for you to think about is, what could be the reasons that the randomized 3-SAT algorithms that we've just seen in the table have generally better bounds than the deterministic ones? Could it be because randomization is more powerful somehow than determinism? Could the reason be that no one has yet had the right idea simply how to design a better deterministic algorithm? Or could it be that analyzing deterministic algorithms is in a way more complex than analyzing randomized algorithms? And I would ague that all three arguments here are in a way correct. So you could argue that randomization is more powerful than determinism. Of course, we don't know why and we don't know if that is so, but it could be a valid reason that somehow randomization is a bit more effective but I think you could argue that randomization is in a way or that randomization could in a way be a bit more effective than determinism. After all, you're not really saying how much more effective, but maybe you gain a little edge through trying randomization. Of course it could also be that simply no one has had the right idea yet how to design a really really good deterministic algorithm for 3-SAT. Of course, the links of the table that I've just shown you suggest that people have put a lot of thought into this but maybe tomorrow, somebody comes up with a really good idea for a comparably fast exponential time algorithm for 3-SAT, and finally, I think this is also an important point, it could be that analyzing deterministic algorithms is just way more complex than analyzing the randomized ones. The 3-SAT algorithm, the randomized one that I've shown you with a running time of 1.334^n some polynomial is very very simple and it's analysis is also not that complicated. For the deterministic algorithms, however, you have to go through a lot and lot and lot of analysis to prove those bounds. So, it could be that you could modify some deterministic algorithm to be better than the randomized one but simply the analysis required to do so, is much more complex and by analysis, I really mean that you don't really have to modify the algorithm that much but just look at its performance a little more closely. So, there are couple of reasons why the randomized 3-SAT algorithms could be better than the deterministic ones, but of course, we don't know for sure. Why have we spending so much time on 3-SAT in this unit instead of our usual problems, vertex cover, clique, independent set, and shortest tour? The thing is, there are very little know results for randomized algorithms for these problems here. Of course, there are still many randomized algorithms for these problems here especially for shortest tour, some also for clique and independent set, but these are all algorithms where you don't know any guarantees. You don't know if the algorithm will perform well or if it will produce a very suboptimal solution, which of course leads to a question where you could ask, well, in what cases might it be okay to use an algorithm that is randomized and does not offer any guarantees? And of course, I'll let you think about that. Would it make sense to solve a problem with a randomized algorithm where you don't have any guarantees if the stakes are low? If no better algorithms are available, so the deterministic algorithms have failed and there's no randomized algorithm known with a guarantee, is it when you can think of any better algorithm, or is it when nobody you know including yourself knows any better algorithm than a randomized algorithm without guarantees? It's okay to use such an algorithm if the stakes are low. It's also okay if no better algorithm is available, I mean if you need to solve your problem, better have a suboptimal solution than no solution at all. Only if you don't know better, that was probably the only answer where I would argue with you because even if you don't know better algorithm for a problem, you should ask around. So, for example, when you're working on a problem like shortest tour, there are lots of specialized solutions, specialized algorithms, special cases, so better talk to an expert before settling for a suboptimal algorithm, but of course I realized that this quiz is a bit subjective and you might object to some of my answers. For example, saying that the stakes are low is something that is rather dangerous because sometimes even a small improvement can be worth a lot of money or save lives, so you have to be careful with this one, and also here if it's a high-stake problem, well, maybe it's worth putting some thought into it and designing your own better algorithm especially if it's not one of those famous problems here, chances are that maybe nobody has looked at it closely enough. In any case, and I think you remember my point from the beginning of this unit, using a randomized algorithm without any guarantees or detour in sight is always a gamble. So you need to think about if you want to take that gamble. It might be okay, it might not be. It's actually a wide open discussion whether randomization is actually helpful because with considerable analysis many randomized algorithms can actually be turned into deterministic algorithms by using a process called derandomization, and derandomization usually keeps fundamental properties such as polynomial running time, all the base of the exponent. Randomized algorithms therefore might be a bit faster but it's unclear whether this is due to luck if you will or lack of thinking. So, if you were to pit these two against each other, randomization versus determinism, it's not really clear who would win or if it's a draw. So to conclude our exploration of randomization, what might be some reasons that randomization is actually at least a bit more powerful than determinism? Is it that randomized algorithms are in some way harder to trick into a worst case behavior as compared to determinism and after all we're analyzing all of the algorithms using worst case analysis. Is it that randomized algorithm can usually be easier to analyze than deterministic algorithms or is it that randomized algorithms actually explore solutions that their deterministic counterparts could miss. And I think there are two correct answers here. The first one is indeed that randomized algorithms are in some way more difficult to trick into a worst-case behavior than deterministic algorithms. Now, to illustrate this for example think about the greedy algorithm that we use to approximate vertex cover. We could trick that approximation algorithm into a worst-case behavior simply because we expose the way that it works and we knew how it would work because it works deterministically. For randomized algorithm, of course, we never quite know what it is going to do. So, constructing a worst-case instance or finding an instance that really exposes worst-case behavior here might in some way be more difficult than for deterministic algorithm. Randomized algorithms can definitely be easier to analyze than deterministic algorithms although of course this one is a little bit debatable since statistics and probability can also get very nasty but when you get down to search tree analysis versus the analysis of random algorithms and with what probability they produce correct results usually these over here are easier, and we also had that in the last quiz where I mentioned it. Now, finally a random algorithm does not explore solutions that a deterministic algorithm would miss. Rather, it's the other way around. The deterministic algorithm at least if it's not in the approximation algorithm will always guarantee that you find a correct solution. On the other hand, with the randomized algorithm, you know about your probabilities because you're demanding guarantees, but nevertheless, you can never be 100% sure. You might be 99.9999% sure that it produces the correct answer but never 100. You now know the basics of dealing with NP-complete problems or NP-hard problems if we're talking about an optimization problem. Designing intelligent algorithms to find an exact solution, or, failing that, accepting approximate solutions, or even incorporating randomness into the algorithms. Are those all of the possible ways that you can deal with an NP-complete problem? Of course not; there are, for example, combinations between approximation algorithms and randomization algorithms. And, of course, there are also algorithms that you can use if you don't demand performance guarantees because the algorithms that we have analyzed, have always provided a certain guarantee as to how they would perform. If you don't require such performance guarantees, there's an arsenal of other techniques out there, known as heuristics. Some concrete examples for that would be evolutionary algorithms, genetic algorithms, simulated annealing, local search, meta-heuristics, and many more. Be warned, though; just because some other algorithms don't have any provable performance guarantees doesn't necessarily mean that they are simpler or easy. Rather, successful implementations of any technique for an NP-complete problem require a lot of thought. And I think the general rule here is finding good solutions to hard problems requires a lot of thought no matter what technique you're using. Now let's take a step back and see what you have learned so far. And the way we're going to organize this is that we're going to draw pictures of so-called complexity classes. And a complexity class is basically a collection of problems that can be solved under given constraints or resources. So you take a bunch of problems, you introduce a constraint such as the one we have seen with NP where we said must be solvable in non-deterministic polynomial time, and then you sort problems. Some problems will fall into the complexity class, other problems will basically just fall outside of the complexity class. And of course you already know some complexity classes very well. So let's do a little warm-up quiz here. So you already know the class P from the previous units. And I just want you to quickly fill in if the complexity class P is the class of all problems that can be solved in polynomial or exponential time on a deterministic or non-deterministic RAM. Of course, you know that answer. P is the class of all problems that can be solved in polynomial time on the deterministic RAM. Of course, I'll ask you the same thing for NP. And again, that is probably very familiar to you by now. NP is is the complexity class of all problems that can that can be solved in polynomial time or in non-deterministic RAM. That's what the N here stands for; now you might have found this quiz rather easy, but actually that you're so familiar with P and NP I think it's something special, because I find that not many people actually understand what P and NP stand for, and what the difference is between the two. Now if you really want to impress a theoretical computer scientist, of course you have to be a little bit nit picky. First of all, P and NP formally are defined for decision problems, so here we said all problems, but actually, if you're very formal, it's only for decision problems, and the other thing is that originally, those classes were not defined on the RAM but rather on a computer model known as a Turing machine, named after the computer pioneer, Alan Turing. Now having a precise definition doesn't really change anything about P and NP the way that we were talking about it, but when you get down into the details of these classes, it might actually matter that you have a Turing machine here instead of a RAM and that you're talking about decision problems instead of optimization problems. But for here, I think it's just fine to think of it as the complexity class of all problems that can be solved in polynomial time on a deterministic or non deterministic RAM. You might remember from the second unit that we can draw a matrix like this. Where here in the columns we have what a deterministic RAM can do, and here we have what a non-deterministic RAM can do. In the rows we have polynomial time and exponential time. You already know 2 complexity classes that go into here. One is P, and the other one is NP. There is actually also names for these classes up here. This one is commonly referred to as EXP or exptime. You can guess what that stands for. This one over here, guess what, is called nexptime. Since we are this far in the unit, here is a little challenging quiz for you. Because you can actually arrange all of these complexity classes here in a sort of hierarchy. Meaning that, for example, all problems that fall into this complexity class here automatically also fall into this complexity class here and this complexity class here. It's basically a hierarchy or containment of the complexity classes. I am going to give all of the complexity classes over here a number. 1, 2, 3, and 4. What I would like you to do is to enter the number of the respective complexity class so that you have built this hierarchy over here. So each complexity class here follows a number of conditions or has a number of conditions that define it, so P is defined as being the class of all problems that can be solved in polynomial time on a deterministic RAM, and NEXPTIME, for example, is defined as the class of all problems that can be solved in exponential time on a non-deterministic RAM. Now when you want to arrange those classes into a sort of hierarchy, then you always have to think about which conditions are more restrictive than others. And I hope it's clear by now that determinism is more restrictive than non-determinisms. So basically, we can say non-determinism is stronger than determinism. Of course, this is very hand weary, so don't show this to a theoretical computer scientist, but for here it is okay to think about it that way. Now what about exponential time and polynomial time, I think that is a very clear one. So exponential time clearly should give you at least as much power as polynomial time, and this basically gives us the hierarchy, because polynomial time is clearly the most restrictive one, and non-deterministic exponential time is clearly the most powerful one. So we can already say here that P goes into the very inner circle whereas NEXPTIME goes out here. Now what about NP and exponential time on a deterministic machine? When we talked about non-determinism, we already found out that polynomial time non-determinism can always be simulated in exponential time determinism, which means that exponential time on a deterministic machine is at least as powerful as non-deterministic time on a polynomial time machine. So NP goes into the second circle here and EXTIME into the third. Now let's do a little bonus question here. And this is, again, a rather challenging one, but I think you can figure it out. So exponential time, as you know, is time of O(2) to the power of some polynomial of n, so we'll just write this as p(n). And, of course, p is some polynomial of n, and this here is also a polynomial of n, and this is O(2^p(n)). My question for you is, given that we can simulate nondeterministic polynomial time and deterministic exponential time, does that imply that these two classes here-- EXPTIME and NEXPTIME--are actually the same? And the answer here is no, we cannot. And the reason is as follows; so when we simulate nondeterminism on a deterministic RAM, what we have is here--a polynomial-- and here we have 2 to the power of that polynomial, which essentially was needed for trying all possibilities for using the "if better" function or nondeterminism, if you will. Now if we tried the same thing over here, what we would have--we would have a nondeterministic machine that runs in 2^p(n) time. Now if you wanted to simulate this on a deterministic RAM, what you could have in the worst case is a running time of 2 ^2^p(n), which does not fall into this category here anymore because we said that exponential time was 2^p(n) and not 2 to the power of some exponential function of n. So you must not make the mistake that simply because we can simulate NP in exponential time, we can also simulate nondeterministic exponential time in exponential time. But given how bad these running times here are, you will, of course, not come across them very often in practice. Which actually brings me to my next question. Now, we have always said that NP-complete problems are very hard or challenging problems. Are there problems that are even more difficult to solve than NP-complete problems? And the answer here might surprise you. Actually, finding an optimum strategy in most games, such as chess or checkers, turns out to be harder than NP-complete. Of course, when I say chess or checkers, I do not mean the normal 8 x 8 board that you're playing on, but rather its generalized versions of those games where you can have an arbitrarily large board. The reason, of course, being that if you fix this as 8 x 8, then the problem size or input size is always fixed. So a concept like NP-completeness does not apply; you always need an input size. But if you take the dimensions of the board as an input size, then certain questions about these games become provably harder than NP-complete. So the problem of determining for a given game position on an n x n chessboard: if white can force a win, which means that no matter how good black plays, white can always find a strategy to win. Asking that question is believed to be much harder than solving an NP-complete problem. Now, I say "believed to be," because this hardness requires that P does not equal NP. If P equals NP, then, actually, many variants of this question here and their different ones will also be solvable in polynomial time. But in the case that P does not equal NP, this problem here is much harder than NP-complete problems. There are even some problems that are provably harder than NP-complete problems. So even if P were equal to NP, these problems would be harder. And I'll give you 1 example for that. And the game that I'm going to show you is called "Roadblock." Roadblock is a game for 2 players. It's played on a graph with end vertices where the edges are colored. And coloring--well, in a way, it's similar to Shortest Tour. So in Shortest Tour or Traveling Salesman, each edge had a number or distance assigned to it. And here each edge has a color, so you can have red edges, blue edges, yellow edges, any number of colors that you desire. And each edge has exactly 1 of those colors. Now, some of the vertices also have a label. Some of the vertices have a label that says, "player 1 wins," and others have a label that says, "player 2 wins." So the situation might look something like this. So here's the graph with end vertices, in this case, 11 vertices. The edges are colored either red, purple, or blue, and some of the vertices are labeled. Here we have the 2 vertices that say "player 1 wins," and here we have 2 vertices that say, "player 2 wins." So what are the rules of the game? Both player 1 and player 2 start out with a number of playing pieces that are also specified in the beginning. So each player has a number of pieces at specified vertices. So in this example I'm drawing here, it might look something like this. So player 2 might have a piece here; player 1 might have a piece here. Player 2 gets another piece down here, and player 1 gets another piece up here. So player 1 starts playing, then player 2 moves, then again player 1. So they play in turns, and here are the rules of the game: In any turn, you can take 1 of your pieces and move it along the edges of the graph. But you can only move your piece along edges that have the same colors. So you can choose the color, but you must stay on that color. So, for example, player 1 could move this piece here, either to this vertex down here or this 1 down here or this 1 over here; that would all be fine. Player 2 here, for example, could even travel 2 edges in 1 turn, or 3 edges, 1, 2, 3, because they're all red. But what player 2 could not do is travel 1, 2, 3. Because then the color of the edges would change, along which player 2 travels. Each time you have a move you can change your color, but not during a move. And there is a second rule, and that is you cannot jump over other pieces. So player 1 here, for example, cannot travel along these red edges here because player 2 has a piece here. And that is why it's basically called "Roadblock," because player 2 is blocking this road here for player 1. But, of course, player 1 could go here or here. How do you win this game? That is very simple. Player 1 wins the game if player 1 manages to place 1 of his or her pieces on a vertex that says, "player 1 wins." And player 2, likewise, wins when player 2 places his or her pieces on 1 of the vertices that say, "player 2 wins." It can be any graph, any combination of labels of the vertices, any edges, any color combinations of the edges. So you're given this configuration here as an input. The question is, can player 1 always win? Or, in other words, can player 1 'force' a win? And what I mean by that "is player 1 being able to force a win," means that no matter how smart player 2 plays, what moves he or she makes, how intelligent and whatnot, player 1 will always be able to make moves that will allow player 1 to win. So given this graph up here, can player 1 always win? And the answer here is yes; player 1 can always win this game here that I gave you. And 1 strategy for player 1 to do this, for example, is to move this piece over here to here. Now it's player 2's turn, and player 1 is now threatening to win in the next move by moving this piece here to this piece here. Now, player 2 could try and block this vertex here, but player 2 can only do this with this piece here. If player 2 were to move his or her piece over here, then player 1, in the next move could, however, move this piece here to that vertex. So no matter what player 2 does, player 1 will win in the next move by either moving this piece here to that vertex, or being able to move this piece here to that vertex. Player 2 could also use this piece here to block this vertex down here, but that would still keep this 1 here free, and player 2 also cannot reach any of the vertices that would let player 2 win. So for this initial configuration here, player 1 can always force a win. Now, if you figured out that quiz yourself, you should be very, very proud of yourself. Asking this question: "Can player 1 force a win?" for a given instance of Roadblock on a graph with end vertices is provably harder than any problem in NP. Which means that this problem requires exponential time to solve, even if P were equal to NP. So even if you showed this, or had a nondeterministic gram available to solve this problem, you would still require exponential time. And that is why Roadblock is 1 example for a game, or asking a question about a game, that is harder to solve than anything in NP. So the Roadblock problem is know to be exponential-time complete, which means it's provably harder than any problem in NP even on a nondeterministic machine. And the proof does not depend on whether P=NP or not. The proof is certain; Roadblock is harder than any problem in NP. So it's harder than, say, vertex cover. Now why is that? Why can't nondeterminism help us to solve Roadblock? Well, it can help us, but it apparently can't help us enough to make this problem solvable in NP. So there's several ways to explain this, and 1 of the differences between NP and problems that are harder than NP is that in NP, or, more concretely, in a problem like vertex cover, you're dealing with a static input. You're given 1 graph, and for that graph you're trying to solve 1 question. And that question is: Do you have a vertex cover of a certain size? Asking for an optimal strategy in a game like Roadblock is a bit different because this game is played against a player. So the question kind of is: After player 1 has made a move, what can player 2 do? And player 2, of course, has a number of possible reactions to what player 1 has done. You need to take all of these possibilities into consideration. How player 1 makes the second move or the third move always depends on what player 2 is doing in between. And that is why this problem here is intuitively exponential-time complete, because after every move that player 1 makes, you have to consider all of the possibilities that player 2 makes. And there's no way around that, instead of here, where we can just guess a small vertex cover. There's a description for this that is a little bit more formal. You can say that NP is kind of the set of problems that have a short proof. And by short, I mean a polynomial-time verifiable proof. So, for example, for vertex cover, when I tell you I have a vertex cover that only uses 5 vertices, and you ask me, please show me that vertex cover, well, I can just specify those 5 vertices to you, and you can check yourself that they will make up a vertex cover for the input graph. Now, for a game like Roadblock, that is not that easy, because if you said, "Player 1 can always win this game," and I asked you--I wanted proof of that, then we again get into this situation that the proof of the optimal strategy is exponential in size. Because that proof will basically start out by saying, okay, this is the first move that player 1 should make, but then there are a couple of reactions that player 2 could have to that move. So, let's say it branches out; so this is what player 1 is doing, and this is what player 2 is doing. Now, for each of these reactions of player 2, I will again in this proof have to specify what player 1 is supposed to do. But then, as you see, it branches out. Player 2 again has a number of possible reactions that it can have to this move. For Roadblock, if you think of this as a large search tree, it doesn't suffice to show that there's just 1 single path that leads to a solution, but basically you have to show that any path here in this tree always leads to player 1 winning. So for vertex cover or any other problem in NP and, of course, this is again talking very informally, it suffices to show 1 path in the search tree. Whereas for a problem like Roadblock, the proof that, for example, player 1 can always win, would require you to show the whole search tree and not just a single path, and that is why problems such as Roadblock are provably harder than problems in NP. Now let's get back to the general complexity classes. So we have already drawn this picture here--the hierarchy of P versus NP, versus EXPTIME, versus NEXPTIME. And, of course, there are other complexity classes that we have gotten to know in this course. So there's the class of fixed-parameter tractable problems. Then we looked at problems for which there are or are not approximation algorithms. So we had problems for which there was a PTAS, we had some problems for which there was a constant factor approximation, and we also mentioned that there are problems such as clique and independent set for which there's no constant factor approximation unless P=NP. And then, finally, we looked at randomized algorithms where we said there were Monte Carlo algorithms--those were the problems that were guaranteed to run in polynomial time but only with a certain probability give us a correct solution. And then we also mentioned Las Vegas algorithms which are algorithms that guarantee us a correct solution, but the running time is only polynomial with a certain given probability. Of course, we can also start building hierarchies here, so we can do a hierarchy for approximation, and we can do a hierarchy for randomized algorithms. And guess what--this is going to be our next quiz. So as in the quiz before, when we talked about P, NP, EXPTIME, and NEXPTIME, I'm, again, giving numbers to these complexity classes here, and, again, I would like you to enter the numbers here so that we form a nice hierarchy. I suppose that wasn't too difficult for you. PTAS clearly is the most powerful approximate ability, because with PTAS you can get any constant factor approximation that you want. It is the smallest bubble in here. Then we have the constant factor algorithms. So these here. Then finally we have all of those problems for which there's neither a constant-factor algorithm nor a PTAS up here. We already briefly mentioned that any Las Vegas algorithm can be turned into a Monte Carlo algorithm, and for that reason the complexity class of all problems for which there are Monte Carlo randomized algorithms, contains the complexity class of all problems for which there are Las Vegas algorithms. Now, if we put all of this knowledge together and just look at the problems that are in NP then there's a lot of different possibilities for the properties of that problem. So either the problem if it's an NP could be in P or this NP complete or it might even be something else. Now, we haven't really talked about this something else here, but they are some problems, which are believed to be somewhere in between P and NP at least if P does not equal NP, of course. One example here, for example, would be factoring two large numbers. Now, if your problem is NP complete, there are still very very many possibilities. Your problem could be fixed-parameter tractable. Your problem could have an approximation algorithm and that approximation algorithm might either be a PTAS, a constant-factor approximation algorithm, or also something else, and again, we haven't really talked about this something else, but for example, there are some approximation algorithms where you can have a logarithmic approximation factor and then there are randomized algorithms, Monte Carlo algorithms and Las Vegas algorithms, and there are many many other things that we haven't touched upon so really a lot of different complexities. Now, one final thing I should mention, they are two notions here especially if you talked to somebody who has studied theoretical computer science. They will nitpick you about the NP completeness, because NP completeness is technically only defined for decision problems. So if you're talking about optimization problems and you want to be very correct then you should call that problem an NP hard problem. But many people use this term interchangeably, and actually, when you are working in practice on hard problems, it doesn't really make much of a difference at least in my opinion, but it is not the most precise way to say it so decision problems, NP complete, optimization problems, NP hard. What would happen if we were able to show that P equals NP? Would then each single class we have shown here become P? Or would the classes separate? And what I mean by this is could be then showed that not every NP complete problem is fixed-parameter tractable or not every NP complete problem has an approximation algorithm. And more than one of these here can be correct. And there are two correct answers here. So the first one is if we were able to show that P=NP, well then, each single class here would lie in P because these are all problems that lie in NP as we said. So, all of these classes here would become P, which means that if we were indeed able to show that P=NP, then this whole picture here could just be written like this. Now, if the image of complexity classes that are just true look a bit complicated to you, I would have to say you haven't seen anything yet, because, of course, they are many many more complexity classes out there. Basically, any type of machine and restriction that you can think of forms a complexity class. And a nice collection of this, if you're interested in that, is the complexity zoo initiated by Scott Aaronson, a theoretical computer scientist at the MIT, and here we have a nice formatting of this document as a PDF, but it is also a website. So Google the complexity zoo. It's really interesting to see. And as you can see here in the glossary, there are many many many more complexity classes than ones that we talked about. So let's just see if we can find those that we already know. Here's FPT. This is the class of fixed-parameter tractable problems. Here is P. Down here somewhere is NP, but you see it's already difficult to find even those classes that we know, because they are so many different other ones. And they have lots of different origins, so there are some classes that are related to approximation, some classes that are related to randomization, and many classes here are also related to special models of computation that we haven't had the time to cover in this course. So there are some models of computation that work with circuits for example or even more exotic models such as quantum computing. The bad news about all of these classes here or all of the classes here in this document is that we don't really know much about the relationships between them. We know some, but as you have seen with P versus NP, there are lots of open questions here, which I think is also a good news for you. There are still lots and lots and lots of things to explore in computational complexity. Now, I don't want you to feel intimidated by all of these complexity classes rather you should be proud of yourself and I would say congratulations to you for having learned so much in this course about computational complexity where you met Alice, Bob, and Carol and later, we also met Dave We didn't know anything about their problems. We didn't know if there was a good algorithm for vertex cover or if we just couldn't find one. Similar for clique and independent set and shortest tour. Later, we also learned about SAT and then we started out with the concept of NP completeness, which suggested that many of these problems here are hard. Then we went on to search trees to show how some of these problems nevertheless can be solve efficiently, and we introduced the concept of pre-processing. We showed that some problems are fixed using parameter tractable using either the size of the solution or some parameter such as distance from triviality as a parameter. We talked about constant factor approximation algorithms, the concept of a PTAS, problems for which there's likely no constant factor approximation algorithm unless P=NP. We talked about Monte Carlo randomized algorithms. We talked about Las Vegas randomized algorithms. And we talked about which of these problems, although worst-case analysis might suggest otherwise are usually very well solvable in practice. This is my final quiz for you in this unit. What I would like you to do is think about all the things you now know about these problems what you know about vertex cover, what you know about clique and independent set, about shortest tour, and 3-SAT and then just make check marks here on what you know. And I think you'll agree that you now know a lot. So you know all of these problems here to be NP complete, which you probably didn't know before taking this course. We've also investigated intelligent search trees for vertex cover and for clique and independent set. We, unfortunately, were not able to find one for shortest tour, but we know one for 3-SAT. We talked about pre-processing for vertex cover, and we talked about pre-processing for 3-SAT. And we showed that vertex cover is fixed parameter tractable using the size of the solution, and we showed that shortest tour could be fixed parameter tractable as well as 3-SAT using a measure known as distance from triviality. We also talked about the constant-factor approximation algorithm for vertex cover. We showed that there is no such algorithm for clique and independent set. We had a constant-factor approximation algorithm for shortest tour. We did not touch upon 3-SAT unfortunately here. Regarding a PTAS, we know there's non-available for vertex cover. We also know there is non-available for clique and independent set unless P equals NP. We mentioned briefly that there might be some available for special cases of shortest tour but not in the general case also not for 3-SAT. Then we have the Monte Carlo algorithm for 3-SAT. We did not go much into Las Vegas algorithms here, but what we then also did we mentioned that all of these problems here are usually much better solvable in practice than the worst-case analysis and their NP completeness suggests. Now compare this table of knowledge with what the four computer scientists and you knew before taking this course. And I think you now know a lot about challenging problems but also about the techniques that you can use to solve them. So it's of course not all good news, because in general, these problems are hard, but using this arsenal of techniques here, you'll usually be able to do something about them in practice as others halve before you, and I think that can really really really make you stand out among other computer scientists because not many computer scientists understand the concept of NP completeness alone, but even those that do once they encounter an NP complete problem, they will tend to just give up or use some random algorithm, not a randomized one, a random one where as you now know about these techniques here and can use them to try and tackle those problems. So, I think our four computer scientist can be rather optimistic and that is also why they are all smiling a little bit here. So, now, it's time to say goodbye to Alice, Bob, Carol, and Dave and wish them all the best for their jobs because in the next unit we are going to take a look at problems that are far worse that anything you have encountered so far. In the final unit of this course, we are going to look at problems that are worse than NP complete problems, worse than games such as road block, and worse than exponential time complete. We are going to explore the very limits of computation and look at problems that no computer can solve ever, so see you next time. You have learned quite a lot in the last six units. You have learned about how to recognize that a problem is difficult to solve. You have learned about the theory of NP completeness surrounding those problems, and you have also learned some powerful techniques to deal with NP complete problems so that they might even be solvable in practice despite their general hardness. Now, there's one question we haven't yet looked at and that is kind of the ultimate question. Are there any problems that no computer, no matter how powerful, no matter with how much time is able to solve, and the answer surprisingly turns out to be yes. In this unit, I will show you that there are some deceptively simple problems for which we can prove that no computer, no matter how powerful will ever be able to solve them. You've already learned quite a lot in the last 6 units: How to recognize challenging problems, the theory of NP-completeness, and how you can, nevertheless, solve these challenging problems using exact techniques such as search trees, pre-processing, or fixed parameter tractability, or approximate method. So approximation algorithms, or randomization. So far, all of the problems that we have looked at have had 1 thing in common: If you gave the computer enough time, and it has enough memory, then eventually you'll get an answer. So, of course, if you have an intractable problem, say an NP-complete one or an NP-hard one, then, of course, you will have to wait a long, long time to get your answer. The computer is, at least in principle, able to give you an answer. In this unit, we will be looking at the ultimate limits of computation. What that means is, I will show you some problems that are not hard to solve, but are impossible to solve. So the computer has no idea how to do this. And there's 2 surprising things waiting for you. First of all, these problems here are very simple, surprisingly simple. And the second thing is, although these problems are totally impossible to solve, actually, your computer is probably solving them every day. So some baffling things await you in this final unit of our course. Of course, there are certain problems that a computer can't solve. It can't appreciate the beauty of a painting for example. A computer cannot predict the outcome of a soccer match at least not accurately and of course, a computer also cannot see into the future and tell you the lottery numbers of next Saturday. So, at this point, we have to start off a little bit more formal and specify exactly what kind of problems we are talking about and what we mean when we say we want a computer to solve a problem for us And we will do this through three requirements. These requirements might seem very obvious to you but later on this unit you will see that these requirements actually has some very, very important consequences So, the laws of computer problems. Rule number one for a computer problem, the input must be given to us as a finite string using a constant number of symbols at each position in the string. The input for a computer problem could for example be a number of zeros and ones It's not infinite so it has a defined end and by constant number of symbols, I mean, constant number of symbols at each place So, in this case, at each place in the string, we either have a zero or one. Here, we could have a zero or one. Here we could have a zero or one and so on. You could also have a string like this. Again, its finite in length. And this time, we're using the real alphabet. So, it doesn't really matter what kind of symbols you use as long as the number is constant and that is basically the same requirement that we already have when we discussed the RAM. Because for the RAM, we also said that at each memory cell, we could only have a finite number of symbols so no variable can be arbitrarily large and the same thing as here, we cannot use an arbitrarily large alphabet at each point of the string, Rule number two is exactly the same as rule number one with one exception instead of input, we write output. So, we also want the output to be given as a finite string using a constant number of symbols. Actually, we could ever restrict ourselves to decision problems here, but we're going to keep it general. So, you get the computer a string and you expect it to out put a string and then finally rule number three. Is that going to be as surprising as rule number one and rule number two? Yes, it is. Because rule number three is going to be that if we get an output then we want that output to be a correct answer to our problem and that is one important point and answer where we can objectively say that it is correct The moment that is given to us and it is suppose to be definitive So, we do not want the computer to say Oh let me work on this for a little bit longer. When it produces the output that is suppose to be the answer. So, these three rules here, you might be thinking, okay, come on we're in the last unit. Why are we even discussing this? The thing is this. When we talk about problems that no computer can solve, I do not want to be talking about these problems here, beauty of a painting, or predicting soccer matches or forecasting the lottery. I want to talk about problems that meet these three requirements here and while we can still prove that no computer will be able to solve them although these requirements here might sound very simple at first, its easy to miss some of the details here, which is of course why we're now going to have our first quiz. I'm going to give you a number of problems and I want you to tell me if this is a computer problem according to these three rules here or if we would not consider this as a computer problem. And you have to be very careful here. So, some of them are a little bit tricky, but then again you're already in the final unit. So, you've learned how to deal with tricky questions by now, I hope. So, here are eight problems for which I would like you to determine if they are computer problems according to these rules here. And again, some of them are bit tricky so you have to be really, really careful in checking it. The first three problems, given an essay written by his student. First problems, does that essay have at least 10,000 characters Second question, which grade does this essay deserve And third question, does the essay contain any misspelled words. A second set of potential computer problem would be the following here. Given two integers larger than zero, what is the sum of these two numbers? Second potential problem, does the smaller integer divide the larger one So is it a factor of the larger one so to say. Third question, given those two integers, please output a random integer between these two. So, between the smaller one and the larger one. And finally, I have two more problems for you to check. One problem is given the string of zeros and ones, check if that string is randomly generated and finally, calculate the square root of 5. So, please for each of these problems, if you think that this is a computer problem according to these three rules here then make a check mark,otherwise, leave the box blank. Again, some of them are a little tricky so you need to check carefully and if you get stuck then of course you can also skip to the answer, give this some thought first. So which of these problems here are computer problems? So, let's just check the three rules. Given an essay by a student, that is definitely a finite string using a constant number of symbols. So rule 1 here is okay. Does that essay have at least 10,000 characters? Where the output is same, either yes or no? So that is easily fulfill-able and of course the answer here is also objectively correct. You can easily count the number of characters and say, yes it's at least 10,000 or no, it's not. So this is definitely a computer problem. The second, one of course, well, the output would still be a finite string, because you could say depending on the grading system, A, B, C, D, or 1, 2, 3, 4, of course, the output is not objectively correct because different instructors tend to sometimes at least disagree on the grade that an essay deserves. So this is not a computer problem although there have been attempts for automated grading which is just weird to say at least. Does the essay contain any misspelled words? Now this is a tricky one. So the input again is finite. The output basically just says yes or no or it can even specify the word. The problem is that it's sometimes very hard to say if something is a spelling mistake. I'll give you one example. Consider for example this sentence here. He was attacked by a rat. At first sight, this sentence--at least if I'd written it in the correct way-- does not contain any misspelled words, but actually it could contain a misspelled word, because what if the author actually had meant to type he was attacked by a bat. That sentence by itself might make perfect sense but you could still have simply mistyped this word here although of course your computer has a spell checker, you might've noticed that the spell checker sometimes is wrong because it sometimes just cannot figure out in which context your saying your sentence. And even if it were a very very strong computer and this example here, you cannot objectively determine if this is the right answer. It can be dependent more or less totally on the author. This problem here is actually not a computer problem in the way that it's stated here. But this was a bit of a tricky one, so I hope you're not frustrated if you didn't get that. But it tells you that sometimes you have to watch out very careful with these rules. They sound very simple but actually there are some tricky details seen in here. So let's go to the next set of problems. Given two integers, what is their sum? That, of course, is a very classic computer problem. The integers are given as numbers 1, 2, 3, 4, 5. The output is a number that's also fine. It's finite. And adding something where you can definitely have a definitive and objective answer. Does the smaller integer divide the larger one? Yes absolutely a computer problem. The answer is yes or no and you can objectively say if the answer is correct or no. This one down here is not a computer problem and actually it's not a computer problem for two reasons. One reason which is a bit technical is the RAM computer or a normal computer doesn't really have true randomness. A normal computer generates numbers that seem like random using an algorithm but that is not random, but as I said this is a bit technical. I think the main reason why this is not a computer problem is that it's not possible once you have the answer to actually know if this answer is correct. So if the number was indeed generated at random. So let me give you one example. So for example, I have the numbers 7 and 10, and now I say that I have randomly generated a 9 which lies between the two. You have no way of checking this I really generated this number using coin flips, or throwing a dice, or if I just made that up, or maybe if I use an algorithm that always outputs a 9. So there's no way to determine from an output if that output has really been generated using a random process. And that is basically also the same reason why this one here is not correct. Of course you can kind of determine the likelihood if this is a very long string of 0s and 1s, you can say well this looks more or less like a random string or not random string, but actually if the string is generated choosing uniformly between 0s and 1s, any string is as likely as any other string, so it's not possible to objectively check the answer yes. So for example, if I say I generated a string using a number of coin flips and I have heads, heads, heads, heads, heads, heads, heads, heads, it might not look random but maybe I was just lucky at that moment. Now the final answer here and if you got that right without checking this answer video, then you're almost a master of theoretical computer science because this again is a quite tricky one in my mind. I will tell you that this is not a computer problem. Why is that not a computer problem? You can enter a √5 into your computer, which you need to do like this, into Google for example, and then we'll tell you that the √5 is 2.23606798 but that is actually not the correct answer. For example, if I enter it into another calculator or webpage that has more digits, then that will tell me that it's actually not 6798, but actually 2.23606606797749978969640917366973 and so on. The √5 is an infinite string. If I ask a computer to calculate √5 to within a certain position, say, I want the first 10 digits or so, then it is a computer problem but just asking a computer to calculate the √5, then this way is not correct. Why am I nitpicking you here like this? Well the thing is this, infinities will play a very important role here in this unit when it comes to problem set no computer can ever solve. This is why it's very important to make sure that the input is finite and the output is finite. So if you do not phrase the question here very precisely, then some of the results will change or not be correct. So, it's very important to ensure finiteness and later in this unit you will see why it's so important. So can a computer solve any problem that meets these 3 requirements? It seems, in a way, like a computer should be able to do that, doesn't it? I mean, the input is fit for a computer; the output is fit for a computer. We have even been very, very nitpicky with finite strings, constant number of symbols, and we want an objectively correct and definitive answer. No grading student's essays, no predicting the future, no looking at pictures and telling us if they're beautiful. I'm now going to show you a problem that meets these 3 criteria. I will also be able to show you that no computer can ever solve it. And this is actually a problem where it would be very useful to have a computer being able to solve it. So I guess you've all been in this situation here where on your computer, you're working, and you've just started a certain type of calculation or task on the computer. The computer tells you yes, I'm 10% done, and after a while this moves to 20%, after a while it moves to 30%, and, of course, pending on what system you're working on, your mouse turns into this hourglass here, and now the progress bar gets stuck. And it stays there. You go have lunch, you come back, and it stays there. So the question is, at some point in time--I mean, you want this task to get done-- but maybe in the next minute the computer will go on. Maybe it's just thinking, it's just working, but it could also be that your program has crashed. If your computer stays that way for quite a time, well, you probably would assume that it has crashed, but you never know for sure. So what if we had an algorithm for that? What if we had an algorithm that took as input a computer program, P. It could be written in any language, basically. So Python, C++, Java, or whatnot. And, of course, we also wanted input for that program. And the input, of course, in accordance with rule number 1, will be a finite string using a constant number of symbols. And actually, the program, of course, will be as well. So it may be, for example, the source code of a program. We want this algorithm to tell us if we run the program on the input, does the computer ever finish, or does it go into an infinite loop? Very simple question. And, of course, this problem totally conforms with all 3 requirements here. So as I just said, the input is a finite string, constant number of symbols, perfect. Output, it's a decision problem so the output will either be yes or no. And, of course, the output is also objectively correct, because we're talking about deterministic machines here, so you can easily check if the program, indeed, will go into an infinite loop, if the computer tells you where the problem is. And this problem is known as the famous, and it's really famous, halting problem. So, as always, when I introduce a new concept to you, we'll have a little quiz about this here. Now, it's always a bit difficult to ask, does P go into an infinite loop when given I, so we'll slightly change that to the opposite question here, and ask, does the program stop when given I? So it's basically the other way around, and also it's the more conventional definition of the halting problem, because it's called the halting problem and not the infinite loop problem, to just ask 'does the program stop?' Basically it's really just the opposite of an infinite loop. So if a program stops, it does not go into an infinite loop, and if it does not stop, it must be in some infinite loop. But let's do the quiz now. So I have here 3 programs. This is program 1, this is program 2, and program 3. And, of course, I have inputs for those programs, and what I would like you to tell me for each combination of a program and an input, does the program stop when given this input? It stops, then you can check here, if it does not stop, so if it goes into an infinite loop, then I would like you to check here. And, of course, this is not difficult to check. So the first program, definitely that will stop. It will print out the 3 words and the length of that word, and then it's done. Second 1? Yes. That goes into an infinite loop, because x starts out as -2, and while x < -2, it will decrease x. Now, you might have been a bit nitpicky here by saying, "Well, there was a certain limit on how large or small variables can get." Let's assume here that we're working with an integer structure that can get as small as we need it to be, and just uses up more memory in that case, and, in that case, this program here will indeed go into an infinite loop. And now for this 1 here it's very easy to see that it terminates. It just adds 1 to the -100 here, and then it's done. So definitely yes. This program will stop. For these simple examples here, it's very easy to check if the program stops on a given input or does not stop. What if we had an algorithm that could solve the halting problem for any computer program and any input? That would actually be immensely useful. For example, in software testing or in debugging, you would just write your code and then ask the algorithm, "Does this code go into an infinite loop at some time?" And the algorithm would tell you if everything is okay. So, of course, there might be other errors, but at least you've eliminated 1 very annoying way for a program to crash. So let's assume we had such an algorithm. So we had an algorithm, and that algorithm, or function, is called "halt," and halt is called with 2 arguments: 1 is a program, the other is the input. And, of course, this here is a string, and this 1 over here is a string as well. And our specification will be "halt solves the halting problem." Notice that we do not say how long halt has time for this. So halt can be an amazingly, amazingly complicated algorithm. It basically has unlimited resources. This algorithm can solve NP-complete problems, it can solve verse problems, we don't really care. The only thing that we care about is that halt solves the halting problem in some finite amount of time. So even in 1,000 years, 2,000 years, we don't care. As long as halt is guaranteed to solve this problem for any program and for any input, then we're satisfied. No further requirements other then that, after a certain amount of time the algorithm either says "Yes. This problem stops on the input," or "No." And now comes the amazing part. I can prove to you that this algorithm cannot exist. There is no algorithm, no matter how clever, how sophisticated, that can solve the halting problem. The halting problem, in other words, is known as a problem that is undecidable, by which we mean that no computer program or algorithm can reliably decide the halting problem for all possible combinations of programs and inputs. So how do we show that? You might remember from our proof of NP-completeness that considering all possible algorithms for a problem can sometimes lead to very, very messy mathematical proofs. In this case, however, the proof is actually not that difficult. So we're going to go through it together. And the way that we're going to prove that the halting problem is undecideable is by using a technique known as a proof by contradiction, which means that I will first assume that the halting problem is, in fact, decideable, and then show you that this assumption leads to an unresolvable contradiction. So let's start out by assuming that the halting problem is, in fact, decideable. So it follows directly from the assumption that the halting problem is decide-able that there must be some algorithm for the halting problem. Now, this algorithm can be very sophisticated, very complicated, whatsoever. But since the halting problem is decideable, or since we assume that the halting problem is decideable, we can directly conclude from this assumption that there must be some algorithm solving it, no matter what the program, no matter what the input. So now that we assume that we have this halt algorithm, what we're now going to do is something sneaky, and this will lead us to the proof by contradiction. We're going to write a program that uses this algorithm here, and this program I call inverse halt, and it's defined as following: So inverse halt takes as input a program, so not a program and input, but just a program, and then it calls the halt algorithm with two inputs. So the first input is, again, the program, just as in halt, but it also gives the program source code itself, if you will, as an input to halt. So it's basically the question of what happens if I give a program its own program code as an input? And the way this then reacts is the following: If halt says the program when it's fed its own code, it will stop. Then inverse halt, that's why I call it inverse halt, will go into an infinite loop. So if program stops on being fed itself, then inverse halt of that program will not stop. It will not halt. If, on the other hand, halt determines that program, given itself as an input, would not stop, so go into an infinite loop, then this whole program here, inverse halt, would in fact terminate. And we're guaranteed in this case that the overall program, inverse halt, will terminate, because we know that halt is guaranteed to terminate. After all, it's a valid algorithm that solves the halting program for any program and any input. Now we're almost there; there's just one more step missing to arrive at our proof by contradiction. And that is that we now run the following program: So we're almost ready to have proof by contradiction, and to actually conclude the proof, we'll now consider the following program: We run inverse halt with inverse halt as an input. So it's kinda similar to up here. We consider inverse halt in two ways: This one up here is the program inverse halt that we actually run, and this here is inverse halt, if you will, it's the source code of inverse halt that we want to analyze. So it's similar to up here again. We're considering a program both as an actual algorithm, but also the description of that algorithm. And what we're now going to show is that inverse halt, when given inverse halt as an input, is going to basically choke on itself. And of course, we're going to do this as a quiz. So there's only two cases that can happen here, right? If inverse halt is run on inverse halt, either this program will terminate, or it will go into an infinite loop. So what I would like you to think about now, what if inverse halt, when given inverse halt as an input, actually stops? Does this mean that halt, when run on inverse halt as the program and inverse halt as the input, returns yes? Or does this mean that halt, when run on inverse halt as a program and as an input, returns no? Now, if you're thinking a bit ahead, you'll notice that there's a third answer here, but we'll discuss that in a minute. For now, I just want you to tell me the direct implication of inverse halt halting when given inverse halt as an input. And the answer here is clearly that halt of inverse halt and inverse halt returns no, because that is the way that we constructed inverse halt. So if inverse halt receives an input, it only terminates if halt of the program as a program and the program as the input returns no. Otherwise, it would have gone into an infinite loop. And now let's think for a second about what that means. So halt of inverse halt and inverse halt says no. The first time inverse halt is a program, and the second time here, it's the input. So what halt's saying no basically means is the following: If I take inverse halt and give it inverse halt as an input, then this does not terminate, because halt says no, and we assume that halt is a correct algorithm. But that's a bit strange, isn't it? But now wait a minute: We just said that running the program inverse halt of inverse halt actually halts. But when we look at the implication of this, then it tells us that inverse halt, when run on inverse halt, does not halt. So, something doesn't seem quite right here. Which one is it? Does it stop or does it not stop? Before we go deeper into that, let's ask the question exactly the other way around. So this time I would like you to consider the direct implications, again, of the other case. So what if inverse halt, when run on inverse halt, does not halt? Does that mean that halt of inverse halt and inverse halt is yes? Or does it mean that halt of inverse halt and inverse halt is no? And again, please just think about the direct implication for the moment here. And the direct implication, of course, is exactly opposite to the last quiz. So if inverse halt, given inverse halt, does not stop, then this means that halt, run on inverse halt and inverse halt, did in fact say yes, because that is the only way that inverse halt can go into an infinite loop, because we know that halt is going to terminate. This is a direct consequence of assumption number two here, and there's no other way to go into an infinite loop. But again, something doesn't really seem quite right here when we dig a little deeper. So, halt running on inverse halt as the program, and inverse halt as the input, says yes. That means the following: Inverse halt as a program, when given inverse halt as an input, since halt says yes, will in fact halt. So again, we have the same contradiction here. We said that inverse halt running on inverse halt did not stop, or did not halt, and what we find is that the implication of this, though, is that inverse halt, when run on inverse halt, does indeed halt. Running the program inverse halt on inverse halt either must stop or it must not stop, but no matter which one of the two we assume, we always arrive at this contradiction here. Inverse halt on inverse halt stopping and not stopping at the same time, which just cannot be right. And having this contradiction here means that something either in the proof has gone wrong, or that we made some assumption along the way that cannot be true. So let's check them one by one. So we already know that we arrived at the contradiction. We checked that in the two quizzes, and we didn't make any mistake here. One thing that could be wrong is that we just cannot run the program inverse halt on itself. But again, this is perfectly fine because inverse halt is a program, and because it's a program, we also have its source codes. So we can easily feed this program to itself. So let's go back one more step, step number three. The program inverse halt, how we wrote that-- Did we make any mistake here? Well, no, we didn't. We just used the algorithm halt, we gave it a valid input. So we gave it a program to check, and we gave it also an input for that program. Sometimes it might be confusing that the program is both an input and an actual program, but it's perfectly fine again, because the program here is the source code, so we can take it as both. The rest of the code is fully valid, so it's deterministic, there doesn't really go anything wrong here. So this contradiction here cannot be due to step four, it can also not be due to step three. What about step two? Well, that there is an algorithm "halt" for the halting problem was a direct conclusion of assumption number one. So there also cannot be something wrong with number two, unless of course number one in itself was wrong. And since we checked two, three, and four, and there must be some sort of error in the proof, the only place where this error can be is here in step number one. So what does step number one say? Step number one assumed that the halting problem is in fact decideable. And since this logically leads us to contradiction, this assumption here must be false. So the halting problem cannot be decideable. It is in fact undecideable. And that of course means that there's no algorithm that will tell you, for any given program, and any given input, if that program will ever stop. Now, the technique that we used here, at least if you're not used to it, can sometimes be a little bit confusing. I would therefore like to give you a second illustration of exactly this proof here, just to make sure that you understand it. So let's construct a table like this. In the first column, we'll consider different programs. And I'm just going to label them p1 for the first program, p2 for the second program, and so on and so on. In the second column we'll then consider different cases of what halt can say with respect to that program, when considering what happens if the program is run on itself. So for example, we might say that for P1, halt might say yes, and for P2 it might say no when given the program, and the program has an input. Now, what does that mean? So if halt says yes in the first line here, it would mean that program one stops when given program one as an input. And of course, similarly, if halt says no, it would mean that P2 goes into an infinite loop when given P2 or itself as an input. Now we're going to do a very quick quiz here, because what I would like you to think about here for P1 and P2, what inverse halt, when run on that program, actually does. So what does inverse halt do when it's run on P1? And what does inverse halt do when it's run on P2? So does inverse halt, when run on P1, halt or go into an infinite loop? And does inverse halt, when run on P2, halt or go into an infinite loop? So please check the one that is correct for each one. And as we said before, and that's where the name inverse halt comes from, inverse halt more or less does the opposite of what halt says the original program will do. So if halt says that P1, when run on P1, says yes, then inverse halt will go into an infinite loop, and vice versa for P2, where halt says that it will not terminate when run on itself. Inverse halt will actually terminate. So far, all is good. But now I'm going to do the sneaky thing that I did in the last proof: I'm going to put inverse halt into this list of programs. So if inverse halt is run on itself, there can only be two cases, right? So, halt can either say yes or no. We know it has to be one of the two cases, because there's no other possibility. Now, just as above here, what would that mean? So if halt, on inverse halt and inverse halt, would say yes, that would mean that inverse halt--and I'm just going to write it like this, so inverse halt stops, given inverse halt as an input. And the other case, of course, would mean that inverse halt does not stop, given itself as an input. So this is what happens if we read the table in this way. Now, let's read it another way because what we noticed here is that, if the program stops when it's given itself as an input, inverse halt on this program should go into an infinite loop. In other words, if we transfer what we did here to down here, we would have to write the following. So now let's compare those two statements in this line here. And here we said inverse halt will go into an infinite loop when given inverse halt, which is just itself, as an input. So you have the same contradiction here as we had in the other proof. And of course, the same thing is true down here. So here we said inverse halt does not stop, given itself as an input. And here we said inverse halt does stop when given itself. So this table here is a nice way to introduce the kind of logic crash that we use in the proof by contradiction. Because there's two ways of constructing this table. So the first way is to construct it this way, basically. Meaning that we look at what halt says--either yes or no-- so we arrive at the conclusion of what the program does, based on what halt has to say about that program. Now, the other way of constructing this table is more or less going this way. So, based on what halt will say that the program does, we can predict the behavior of inverse halt. And this construction works perfectly fine. So constructing it this way or this way, those are both compatible views. With one exception: Once we feed inverse halt into this table, these two logics crash, because the conclusions that we draw in this way are exactly the opposite of the conclusions that we draw in this way. And that is why the contradiction is happening. And actually, constructing the table this way or this way is perfectly fine. The only problem is making the assumption that this halt algorithm here actually exists, which you already know it doesn't. Now, before we continue, I would like you to think a little bit about the implications of what we have just shown. We have just shown that the halting problem is undecidable. What I would like to think about for a moment here is what that means or implies, and I would like you to select the ones that are correct. The halting problem being undecidable, does that mean that an algorithm that solves the halting problem would take far more than exponential time to run, does it mean that an algorithm for this problem here for the halting problem cannot exist or does it mean that if we gave them any specific program and are asked to solve the halting problem that will never be possible, at least not using an algorithm. So the first statement here is obviously not true. We have not even talked about time. We have just pondered the existence of an algorithm for the halting problem or more specifically, the non-existence of such an algorithm, and that is exactly what we have shown. We have shown that there's no algorithm that solves the halting problem if we allow that algorithm to be given any program and any input, but of course, there are specific programs for which we can use algorithms to decide if they will go into loops or not and this is for example one technique that is used in automated software testing. It's not that there can be an algorithm that solves the halting problem for specific cases or specific programs, the halting problem cannot be solved for the general case. So if say you have an algorithm that can solve the halting problem for any program, any input that you throw at it, that cannot be the case, but for specific, special cases, we haven't shown anything so far. Now, I don't know about you, but every time I come across the halting problem, I cannot buy the mathematical arguments, but I still feel some would cheat it. It's important I think to realize what is being implied by undecidability and what is not being implied. Informally, all that the undecidability of the halting problem says is that you cannot analyze every aspect of computation using computation. Let's say this program here is supposed to solve the halting problem. This would be the program halt here. The difficulty lies in the fact that all this required not only to be able to say what one given program program two does, and of course, we'll assume there's also an input, but basically, it's supposed to be able to say this for an infinite number of programs. Now, the following is by no means a scientific explanation, but I think it's a good way to think about it. If we have the requirement that halt must be able to look at every other problem here then halt will also be part of this list. So somewhere in that stack of programs, you will have halt. Now, if you say halt must be more complex, and again, this is not a scientific explanation must be more complex that any program it's looking at, well, then halt must be more complex than halt itself, which of course is to an infinite cycle of complexity. So here, we cannot have this spiral of infinity, which of course cannot be so there's the error right there, and again, this is just an intuition a way which I like to think about it. You may find other ways more convenient. What I find is with undecidability and especially the halting problem there is a lot of misunderstandings and pitfalls. And actually, I would now like to go with you through one of the most common pitfalls regarding the halting problem and its undecidability. Wome of you might be saying for any real computer, the halting problem is decidable using the following argument. So you're given a program and you're given an input and you put it into the following algorithm. You start out by stimulating step one of the program. So again use the stimulation here just as in previous units. So you simulate step one. If the program terminates at that step then we output "Yes." And else, we record a snapshot of the machine-of the simulated machine, of course. And what I mean by snapshot is something you might remember from the NP completeness proof of SAT. A snapshot is a complete picture of the memory of the machine as well as the line where the program is currently at. And the reason why this algorithm is doing it is it's using one property of an infinite loop and that is if a machine goes into an infinite loop then snapshots at some point in time must repeat. So the third step of the algorithm is it takes that snapshot that had just recorded and compares it against all previous snapshots of the machine. And if it finds just one duplicate, it knows the machine has been exactly at that place before, which means it would also return to that place an infinite number of times. In that case, the halting algorithm or at least this algorithm here, which is supposed to solve the halting problem with output "No." And then the algorithm would simulate the next step of the program and go to step number two. This algorithm would be guaranteed to terminate at a certain point in time either if the program itself terminates or the simulation of the program indicates that it terminates or if the program goes into an infinite loop. Here is important that we have a real computer because if we have a real computer, we do not have infinite memory. So if we do not have infinite memory and the program goes into an infinite loop then at a certain point in time we must have a repeating snapshot. Now, if we had infinite memory that would not be the case. Now I would like to ask you two questions. My first question for you would be--is this argument correct? Does this algorithm here solve the halting problem on a real computer, so a computer with a finite memory? Please give me your answer here. And the answer here is that--yes, this algorithm is actually correct. It might not be very practical in terms of running time but the arguments are perfectly fine. If you have finite memory and a program is in an infinite loop, then at a certain point in time snapshots are states of the machine must repeat themselves--there's no other way. My question for you is--if we should think that this argument is actually practically relevant meaning okay. On an infinite machine, you might not be able to solve the halting problem, but on any real computer, it's actually possible to solve the halting problem. And the answer here, I think, is clearly no because a real computer, of course, has finite memory, but think about your machines. So let's say you have an older computer like me--so you have 1 gigabyte of memory. One gigabyte of memory is approximately 1 billion bytes or 8 billion bits. Now, how many different snapshots can you have with 8 billion bits--that is 2⁸⁰⁰⁰⁰⁰⁰⁰⁰⁰ snapshots. You wouldn't find a fraction of that as atoms in the universe. The argument is correct in theory, but it does not have any practical relevance--almost like the halting problem, which I will soon show you also has actually very little practical relevance, but for this counter argument, it's basically the same. For real computer, I think you can consider the memory to be practically infinite. So this algorithm here just isn't going to cut it unless by real computer, you mean a very, very, very simple one. Okay, so now you might be thinking--well, okay, so programs can become so complicated that no algorithm can decide whether they run infinitely or not. So is there a short program for which I could show you undecidability. Oh yes, there is such as a program--it's not very practical but it is an example for undecidability for very simple program. Here's a simple example of a problem that is actually not decidable, although it's very simple to write. So the input to that problem is an integer and we will just call that integer i and the output is the number of iterations that it takes to get to i=1 using the following two rules-- If i is even, then set i to i/2 so they divide by 2. If i is odd, set i to 3i+1, just two simple rules. And so for example when you start out with i being 10, then we first apply the first rule. We get down to 5, 5 is odd so the new value is 16 and then we divide by 2, we divide by 2, we divide by 2, we divide by 2, so we have 1, 2, 3, 4, 5, 6 iterations. So i=10, then the answer is 6. So now we're going to let you play a little bit with this algorithm and then discuss the undecidability for it. These two rules here form what is known more formally as the Collatz series named after the German mathematician Lothar Collatz and appeared somewhat erratic as I think you've seen with the program. Sometimes it will terminate very quickly for certain values of i and sometimes actually it will behave super eratic and it will go up and down and up and down until it finally terminates. Now here's the thing, it has been conjectured that this algorithm here will terminate for any value of i but so far nobody has been able to prove that. So if we were given an integer for this function here for which the Collatz hypothesis that this algorithm here always terminates has not been verified then that would indeed be undecidable. Now truth be told, it would have to be a very large integer because the Collatz hypothesis has been verified for large numbers indeed. Nevertheless, once the integer is out of this range, we have no way of deciding whether this algorithm would terminate or not. The only thing we can do is run it so the Collatz problem or the Collatz hypothesis is an open mathematical problem and of course as you know it's not the only open mathematical problem so we could have other mathematical problems as well. But I want to show you something. So if we have an algorithm that solves the halting problem, so if we indeed had this algorithm halt what we could then do for example is write the following program for i = 1 to 10¹⁰⁰ then run the Collatz rules for i so we start with i = 1 then we go to i = 2 and so on and then we feed this problem into the halting algorithm. And now if the halting algorithm says yes, then this means that the Collatz hypothesis is true for any number from 1 to 10¹⁰⁰ and if it says no then it means that there is some number for which the Collatz hypothesis is not true, which means that this part here would go into an infinite loop and then we can easily check this for larger and larger and larger numbers. An algorithm that would be able to solve the halting problem would actually be able to solve almost any open mathematical problem there is out there. Any mathematical problem that can be formulated as an algorithm could be decided by an algorithm that solves the halting problem. So this would almost be a kind of omission algorithm which also provides an intuition why this halting algorithm here cannot possibly exist. It would just simply be too powerful. It could answer almost any mathematical question that we can think of. Now the halting problem isn't the undecidable problem. There's actually a very large number of undecidable problems as we'll soon see. And the technique here is almost the same that we use for showing np-completeness. So if you remember that once we had shown SAT to be np-complete. We could take a whole bunch of other problems such as vertex cover, clique, and independent set and of course many more and show these to be np-complete using a reduction because we were able to show that if you could solve vertex cover in polynomial time then you could also solve SAT in polynomial time and we'll now use a very similar technique. Now we know the halting problem is undecidable, we can look at other problems and show through a kind of reduction that if we could solve these problems here then we would be able to solve the halting problem, which of course is not possible. Now, the first problem we might be looking at is a generalized version of the halting problem. As you remember, the halting problem takes as input a program and an input on which to run that program and what we could now ask is of course a more general question and that is, does the program have any input on which it stops or does it always go into an infinite loop? And we'll call that the generalized halting problem. So we're given P and now the question is, is there any input I for which P halts? And I'll show you now that this problem here is also undecidable and then we'll look at other problems and you can show that they are undecidable. So the proof always work in a very similar fashion. You again start out with an assumption. And then lead that assumption into a contradiction. The initial assumption is that we had an algorithm or a program that can decide the generalized halting problem. So assume there's a program P' that solves this problem here. Now, how could we use this program here to solve the halting problem? Well, that's actually quite easy. So we have the program and the input. And now we construct a new program from that. That problem is actually quite easy. We just make the input here part of the program code so in kind of a pseudocode writing here the first line of that program P'' would be set the input variables to I and that is now part of the program code of this program here. Here it was a separate input and now it's part of the program code. So we set the input variables to the input and then run P as always. And now it's clear that if we have a problem that solves the generalized halting problem then we can just feed it to this program here because this program here actually ignores any input that we give to it. Finding out if that program over here will ever terminate is the same as asking if the original program P will terminate on the input I. This program here cannot exist because if the generalized halting problem were decidable this would also mean that the special halting problem here where we are given an explicit input would also be decidable. So we know that this problem is now undecidable as well. Now I will give you another type of problem and this time you can prove that this problem is undecidable, and the problem is as follows and that problem is also one that sounds very simple. It's the equivalence problem. So this time, we're given two programs, P and P prime, and the question that we want to answer is do this two programs do exactly the same thing? For example, do they implement exactly the same algorithm only using a different type of implementation, and now, what I would like you to do is prove that equivalence is undecidable by showing that if you have an algorithm that would solve equivalence then you could also solve the halting problem. Now, the way we're going to do this quiz is as follows: I have here six building blocks or potential building blocks of this group, and I would like you to do the following: There are four building blocks that you actually need for the proof and there are two building blocks, which are not necessary for the proof. And what I want you to do is to find out which building blocks you need and which you don't need, and for the building blocks that you need bring them in the right order. So, right one next to the building blocks that would come first in a proof of undecidability of equivalence then you write a 2 next to the next building block and so on. It might be easier to first think of how you would prove this and then fill out the boxes rather than playing around with them. How you prove that equivalence is undecidable? To show that equivalence is undecidable, we should first start out with a program for which we want to decide the halting problem, and that should be P. We start out with the step here, and then we add a second program and that program is called P‘ and it goes into an infinite loop. No matter what input, this program is just programmed to always go into an infinite loop. Once we have those two programs P and P‘, we run them through the algorithm that decides equivalence and what that will do is it will basically ask-- does the program P for which we want to decide the halting problem do the same thing as the program that always goes into an infinite loop. And then, of course, that means if the two programs are indeed equivalent, then P will also go into an infinite loop because all that P‘ is doing is it always goes into an infinite loop and we don't even need the other two building blocks because we have now shown that you can use equivalence to solve the halting problem. You just compare any program for which you want to decide the halting problem to a program that always goes into an infinite loop and if they do the same thing, then they are equivalent. So you know that P will not halt, and if they are equivalent, well then P halts. Now, this was certainly one of the tougher quizzes in this course so congratulations for figuring it out, but of course I also trust that by now you have learned the ropes of theoretical computer science. You revert here is that I will give you a third proof of undecidability for free. And the third problem which is undecidable is a problem called specification, and that problem basically asks--does a program do what it is suppose to do. And that problem in the general case is also undecidable because determining the equivalence of two programs is basically the same as using one of the programs as a specification for what the other one does. Unfortunately even determining if a program is correct cannot be done automatically, at least not in a general case and we'll get to the special cases at the end of this unit of course. Now the proofs for showing undecidability are somewhat easier than showing NP completeness, because basically, what we are doing is the following. We start out with saying that for any computer program, we can decide a certain property and then derive from that but then you could solve the halting problem. And you have seen that this works with a lot of properties. So deciding if the program will stop doesn't work, deciding if the program is equivalent to another program doesn't work, deciding if the program even does what it's supposed to do doesn't work. Even though you might still feel somewhat cheated by the original halting problem proof, you might be inclined to think that once you accept that then there's actually not much you can decide about the properties of a program at least in general, and it turns out that that is exactly true. In 1953, Henry Rice after whom Rice's Theorem is named proofed that basically you cannot use an algorithm to decide anything about the properties of a given program. So we must be a little bit more formal about this property x thing here. And Henry Rice used the notion of a functional property here. Now, what is a functional property? Sounds very complicated. Actually, it's a very simple definition. Any functional property has these two properties. First, it describes how the output relates to the input. So this is what we mean by behavior and that is important to how they relate to each other not for example how much time we need or something like that. And the second property is that there must be some programs that have this property, and other programs that don't have this property. So that when you look at all possible computer programs, some of them will have this property others won't so that it can basically distinguish between the two. So to practice the definition of functional properties, here's our next quiz. I have here five potential functional properties and actually, I would like you to tell me which of these are functional properties and which of these are not. The possibilities are a program is a computer program, a program always returns 1, a program solves vertex cover, a program is a computer virus, and a program requires O(n) time. So which of these are functional properties. The first one of course is not a functional property because condition two is not fulfilled. All computer programs are computer programs. There is no computer program that is not a computer program. Of course, this sounds a bit silly but it's actually the only example I could think of where this condition here is violated. A program always returns one already is a functional property. First of all, it describes how output relates to the input namely output doesn't care about the input and is always one and property two is also always satisfied. For example, there are computer programs that I could write that always return two and property two is fulfilled for all the other three as well, so I won't even mention it anymore. A program solves vertex cover? Yes, definitely that describes an input-output behavior, how output relates to the input. Is a computer a virus? I would say yes, this is a functional property. Now, it is a bit debatable if saying it is a computer virus already described sufficiently how the output relates to the input but I would say that probably any definition of a computer virus that you would give me would in some way describe what the computer virus is doing. So, it might ignore anything that receives and overwrite your hard disc, so put something in the memory, or it might lock your screen. So, I would say here, the input-output behavior is variable depending on how you define computer virus but it is always defined. Now, the final one that is a bit of a tricky one saying that a program only requires linear time is not a functional property because that does not describe how the output relates to the input. It is the property of the program but it is not a functional property because it doesn't ask what does the program do and what does the program do is actually this relationship here. It only asked how fast that the program are doing that. This is something that is a little more tricky to figure out, but basically, any time that you ask can a program do X that will be a functional property that you are asking for at least in almost any of the cases. Now, what is Rice's theorem? Rice's theorem is actually quite simple. Rice's theorem simply says that if you asked for an algorithm to decide the program has a functional property and it can be any functional property, then, you're looking at an undecidable problem. I don't even know, that come out of surprise to you after we have shown that basically anything is undecidable. It's almost a surprise now that any problem on a computer should even be solvable but we'll get into that in a minute. The main question, of course, how can you show Rice's theorem, and the proof that is actually easy and it follows the same scheme as above here. So the proof of this general statement follows the same scheme that all of our other proofs of undecidability have basically used. So, again, we assumed that there is a program that can decide for another program if that possesses a certain functional property. So we're given a program P again, any program P, and we assumed that no matter what P is, we can always say "does P have a functional property?" Now, on the other side, assume that there is another program P', and what we want to do is solve the halting problem for this program here and then we'll use the algorithm here that can decide for any program P if it has a functional property to solve the halting problem and the way we do this is as follows: We construct a new program we will call program X and this program has only 3 steps. First, it runs P' then it clears all of the memory, so basically a fresh start of a machine, and this is the only reason why we need this condition too here for a functional property because if we have an algorithm that can decide a functional property, this means that there are some programs that has this property and others that don't. So, we will now add to our program X a program that has this functional property. So, run program with functional property, and what then do is we take this program X and fitted into this algorithm here. what you can see now is the following: If P' here, the problem for which we want to solve the halting problem, runs smoothly and terminates, then this program X will have the functional property that we can decide because it runs this algorithm here and it clears the memory and then it runs the program with that functional property. This is also the reason why time is not a functional property. That would kind of destroy the proof of Rice's theorem. But if time is not an issue, then as long as P' finishes, the program X will have the functional property that we can decide here. If, on the other hand, P' goes into an infinite loop, then the program does not have the functional property because it will never be able to reach these two lines here. So, deciding the functional property for this new program X here is the same as solving the halting problem for the original program that we started out. So now to computer with Rice's Theorem before we go back into practice, I'll give you a quiz very similar to the one we just had. All I want you to do is to figure out which of the following properties are decidable for a given program? A program always returns 1, a program solves Vertex Cover, a program adds 2 numbers, doesn't do anything, converts and MP3 file, reads a file, terminates after 3 timesteps, is a virus, writes to a file, modifies itself, returns an integer, downloads data. So please make a check mark next to those properties that are decidable, and leave the others blank. And there's actually only a single decidable property here. All of the other properties are undecidable. Now let's go quickly through them, one by one, to discuss why that is. So always returns 1; you know that is undecidable by Rice's Theorem. It's a similar case here; we already have that. Adding 2 numbers, Rice's Theorem. Doesn't do anything, Rice's Theorem. No matter how you define doesn't do anything; it will always come back to Rice's Theorem. Converts an MP3 file, Rice's Theorem. Reads a file; that is an interesting one, because you could argue that this does not fall under Rice's Theorem, but even if you have that argument, it's still not decidable, because what I could do, for example so I can modify any program so it will only read a file once it's done and that again will allow me to solve the halting problem. Is the program a virus; Rice's Theorem. Writes to a file. similar logic as reads to a file. Modifies itself; that is an interesting one, because of course here you could say Well, of course I could just go through the code and whenever the program accesses itself, I know it has that property, but the thing is this: the program could have certain lines that suggest this program modifies itself, but deciding whether those lines will actually be reached once the program executes, that again would allow you to solve the halting problem, so also this isn't decidable. The same one here; of course you can look at a certain program and say, Doesn't the program return integers? but you had a program that can decide if a program only returns integers, that again would allow you to solve the halting problem, And the same thing for downloading data. If I had a program that designs generally for any other program if it downloads data, I could use the same technique as for reading a file. I could basically modify any program so that it could run completely on its own data that it already has included and downloads data basically to signify that it's done. If I could decide this in the general case, then I would have also solved the halting problem. Now the question of course is, If this here has any practical relevance; for example, reading a file, because for most programs, of course, you will be able to decide if they ever read a file or not. Then again, on the other hand, if you look at general software testing, this is an interesting question from a perspective of code coverage, for example. If you could decide if a program reads a file, and of course you want the program to read a file, then that would tell you something about the correctness of that program. Is this a super depressing ending to this course, and can't we decide anything? Well, of course, Rice's Theorem and undecidability in general is prone to a certain criticism. I mean a crucial thing to notice is that Rice Theorem means that there is no algorithm that can decide a functional property for any program that we through at it, but this is a very general case. Rice's theorem an also the halting problem, of course, can only concern this very general case. If you're trying to prove something about a program you know very well, you might be in a very different situation, so if you're trying to find out, for example if a program you wrote even halts, and you can't prove that or can't even show that, then maybe you should consider writing some better understandable code. But what it does mean is that there's no fully automated software testing without trade off. So it means that fully automated testing basically the dream of a program and you throw any other program at it, and it will tell you if it's correct, if it stops, if it crashes, and that's the dream that we probably can't fulfill, but if accept certain trade offs, so for example, if we accept that the automated testing program will be right most of the time or that it only works on special cases, then we might be in a better situation, so I would interpret Rice's theorem not as a general negative message, but rather as a piece of caution as to what computers can do and can not do. So I would to consider with you one example of what Rice's Theorem might mean in practice and might not mean in practice, and the example I find very illustrative for this is malware detection, so determining if a program does something bad on your computer or if it is a harmless program that you want to run. So first of all, we have to think of it about what actually classifies a piece of software as malware? So a good classification of malware be that it's a piece of software that does something the user doesn't want it to do? Would it be a good classification if it deletes files? If it gathers information from your computer? If it disrupts or interrupts other programs? If it installs itself or something else without asking you as a user? Or some combination of the above. I think the only correct answer here can be the last one; it's some combination of the above criteria, because there's always counter examples if you just take a single one of them. So for example, if software does something that the user doesn't want, if the software enforces copyright protection, some people might call that malware, actually, but there are of course cases where software does something that the user doesn't want and it's still for a good purpose. Software that deletes files, no way, because you can delete files on your computer using the normal delete command, and that is not malware. Gathering information from your computer, not as a stand-alone criterion, because there might be software that you actually want to gather information from your computer. Disrupting other programs; well, sounds like malware, but on the other hand, if for example you have an anti-malware program that disrupts malware, that will definitely disrupt, or hopefully disrupt the computer virus that is trying to infect your system. It doesn't have to be malware just because it interrupts other programsl. Installs without asking; well, with most software having automated updates, I don't think that classifies as malware alone. So you see, even finding formal criteria to tell you if software is doing something malicious that you don't want it to do, that's very difficult, but let's assume you had found those formal criteria. Now my question for you would be What would be the problem with automated classification of a program as malware from a theoretical computer science perspective? So even if you had formal criteria that defined exactly what malware is, so are the issues here that automated malware detection is an NP complete problem? Is it automated malware detection undecidable? Or is it that automated malware detection can never be perfect? That means you will always have programs that are not malware that will be classified as being bad or other programs that are malware but will basically slip through the net or slip by this program here. And I think 2 of these answers here are true. First of all, if you had perfect formal criteria for malware, the whole thing would fall under Rice's Theorem. Malware would be a functional property and we know that functional properties are not decidable, which in turn means that since the problem is undecidable that malware detection can never be perfect. It's not really clear what kind of error you will be making, so if you will be classifying good software as bad or bad software as good, but it can not be perfect, because if it were perfect, then that would violate Rice's Theorem. Now NP completeness of course; that is not true for several reasons, so first of all, running time is something something that we just can see here, and secondly, as you've learned, there are problems that are much worse than problems that lie in NP so it can also be that malware detection is actually worse than NP complete. We just don't know, so this is not a correct answer here. You may or may not have heard of Godel's Incomplete Theorem, but since they are also mentioned in conjunction with the Halting Problem and undecidability, it worth saying a few words about them. Godel's Incompleteness Theorem is named Austrian-born mathematician, Kurt Godel, are concerned with mathematics, but are actually closely related to undecidability and as you might know, any mathematical system starts out with a set of axioms. What are axioms? Axioms are statements which you assume to be true without having any formal proof of them, such as if A equals B and B equals C, then A must also equal C or you can always draw a line from one point to another point, no matter where they are. Those would be axioms. Now axioms often sound very trivial, like this one here or the fact that you can always draw a line between 2 points but for many of them there are actually scenarios where they are not true. So axioms are the basis of any mathematical theorem or proof. Now what Kurt Godel showed, and it was a shocker at his time and to many it is still today, is the following: So what Kurt Godel showed was that if you had a set of axioms and they don't contradict each other and they are listable, which means you could have an algorithm that lists you all of these axioms, so either they are finite or they can even be infinite as long as you have an algorithm that can produce them all; if this is the case, then there are some statements that are true but which you cannot prove based on these axioms and this is what he meant by incompleteness how he basically showed that no matter what foundation you base a mathematical system on, as long as that is a consistent foundation, then you can not prove everything without adding additional axioms at least. He also showed, and this is the second Incompleteness Theorem, which is basically an extension of the first one that a system of axioms cannot not demonstrate its own consistency and what that means is that very informally, a mathematical system can not be used to show that it itself is consistent. These 2 statements are in a way very similar to the Halting Problem and Undecidability. The axioms; you can think of those as programming statements. So any program or algorithm is composed of a number of simple instructions that are then arranged, and of course there is an infinite number of possible computer programs that you can write, but they are made up of a fine set of building blocks and the second Incompleteness Theorem is of course very similar to undecidability in the sense that it shows that you cannot use a system to prove everything about that system, very loosely speaking, and the undecidability of the Halting Problem and all of the other undecidable problems, of course says that we cannot use algorithms to calculate everything about algorithms. I know that from a practical perspective there's lots of criticism of this, but truth be told, I just find that super fascinating. It's a bit ironic that although theoretical computer science is very precise, there are sometimes very confusing naming conventions, and since many students, at least those I have had have been confused by this, I just quickly wanted to clear one thing up. You will sometimes read that the Halting Problem is semi-decidable and we have to say that it's un-decidable, so which one of these 2 is it? Is it undecidable or is it half-way decidable? And paradoxically, it's both, and let me explain why. So assume that we have a program, P, and we want to determine if it halts, so we want to know, does the program stop at a certain point in time, and the answer to that, as you know, can either be yes or no. Now let's think about the 2 cases that are possible. So the first one of those 2 cases is that P stops, and my question for you is, if P does stop, can we a yes after a finite amount of time? And there answer here of course is yes, so as long as the program stops and after a certain finite amount of time, we will get the answer yes, simply due to the fact that the program has terminated, so you know for sure that this a program that halts. Now what about the other case? What if the program does not stop? Can we get this answer here after a finite amount of time? And the answer here, of course, is no, because it doesn't stop, it will run on and on and on We will never get this answer here. We will just have to wait and wait and wait. So the answer no is something we cannot obtain in finite time and that is why the Halting Problem is called semi-decidable, because we can kind of decide half of the answers and it's also called undecidable because we cannot output a clear yes or no after a finite amount of time. Why this nit-picking; what's the difference, you might ask. The interest of this, of course, is rather theoretic, but semi-decidable problems have a very interesting property called recursive enumerability. Now that sounds a bit strange; what does that mean? Recursive enumerability means that you can write a program that outputs all combinations of inputs and programs, and I seriously mean all combinations of inputs and programs that halt. So this program here cannot say for any input and program that this combination will not halt but it can output a complete list of inputs and programs that will halt, so let's have a look at this program, and of course, this program runs on infinitely, so it start off by defining a length called max length to be 0 and then it goes into an infinite loop, which is this one here, and what it does then is it increases max length by one each time it goes into this loop here, enumerates all programs of length at most max length. Now if you fix this max length here, there is a huge number of programs that have a length at most max length but it's finite; it's huge but finite, and the same goes for the inputs. So for all combinations of programs and inputs that are shorter than this value max length here, we run a simulation for exactly max length steps and if the program halts on the input after exactly max length steps, then we print the program, and we print the input. If it hasn't halted yet, don't care, throw it away, wait until the next loop. So please take a while and familiarize yourself with this algorithm and then tell me some of its properties. Does this algorithm eventually find any combination of program and input that halts, or are the some that this algorithm might be missing? Is this algorithm feasible or infeasible in practice? And finally, could we modify this algorithm here so that it doesn't only find program and input combinations that do halt, but also those that don't halt. And the answer here, surprisingly, at least I think it's very surprising this algorithm is capable of finding any combination of program and input that halts, and the reason is simple; if a program halts, then the program has a finite length, the input has a finite length, and the number of steps in which the program can run on the input, if it halts, is finite, and at a certain point in time, since this loop here is infinite, max length will be larger than any of those 3 constraints, and once max length has become large enough, we will find that P terminates on the input after a certain number of steps, and so we will print it. The only reason why the algorithm could not find the certain combination of program and input is that the program does not halt on that input. The first one, amazingly, means that the algorithm is indeed correct. Of course it is totally infeasible in practice, as well, because if you think about it, a program is a text string; now even for very, very, very small values of max length the number of these text strings for the program and of course also the number of text strings for this input here becomes exponentially huge, so it's a purely theoretical construct, but it explains at least in some theoretical computer science courses, you will hear that the Halting Problem is referred to as recursively enumerable. So the algorithm is totally impractical, but it is nevertheless correct, and that is the reason why the combination of programs and inputs for which the program halts on the input is called recursively enumerable, at least in some theoretical computer science courses. Now this one is interesting; can this algorithm be modified to output any programs that don't halt? And the answer here of course is no, because this technique here clearly only works when the program stops. As long as the program goes on, we can not make any statement about it. We cannot say it's a program, will it still continues running, if it will stop at a certain point in time, and that is the reason why we can't modify this algorithm, so that it finds combinations of programs that input that don't halt. This of course also tells you again why the problem is semi decidable because we can find those combinations here, but we can not find those over here. So are there any worse problems than undecidable ones? Well, that kind of depends on your subjective view, but from a perspective of computer science undecidability is the biggest and meanest monster of complexity; for a computer, there's no worse thing than "I can't do it." Which is undecidability, so the answer here is no, but that also means that you have completed your journey, which means that all that remains to be said is Congratulations for completing our Introduction to Theoretical Computer Science! I consider this to be a rather challenging course, so you should really be proud of yourself for having learning so many advanced concepts. You have learned about NP complete problems, some of the toughest problems that are out there, and you have also learned how to recognize these problems, so detecting NP completeness. You have also learned how to navigate around NP completeness using techniques such as search trees, pre-processing, fixed parameter tractability, approximation algorithms, and other techniques such as randomized algorithms, and finally, and this is all but trivial, you now even understand the cliffs of undecidability. I hope I've conveyed to you for many problems that are very, very challenging to solve, digging deeper into underlying algorithms and techniques can really be rewarding, because not only is it fascinating, but actually, problems that to many people will seem unsolvable can be solved using the tools that you've now learned. Theoretical Computer Science or the science of challenging problems is a very rich and deep field and you're no ready to dig deeper. Whether you want to dig deeper into the theory or you want to dig deeper into writing your own algorithms to solve nearly impossible problems, that is up to you, but in any case, I wish you all the best for that journey, and once more, congratulations for completing this course. So cleaning the input, which is more technically also known as pre-processing--what's the idea behind that? Here's what you would normally do for an NP-complete problem as we have talked about so far: So if you're given the input for an NP-complete problem. What you would do using the techniques from the previous units is you would fire up your search tree to try and find an optimal solution. And of course, that search tree has exponential size. So the algorithm goes through that tree here until, at a certain point in time, it says, "Bingo, I found a solution," or, "I found the best possible solution." The idea of pre-processing now is similar to something that we already saw for vertex cover or independent set, where, for certain vertices, while we were traversing the search tree, or even in advance, what we could already say for certain vertices, we know what assignment that vertex is going to have in an optimum solution. And we could make that statement without actually going through any branching, but in polynomial time. And that is the idea of pre-processing. The idea of pre-processing is, if you can actually find certain parts of the input, where in polynomial time, of course, you can already say how they would be handled in an optimum solution. So we're kind of nibbling away at the input here. And what that, of course, means is if your pre-processing is successful, or especially if it's very successful, then the search tree that results from that input is not going to be as big. So there's certain parts of the search tree that you don't have to do, because you already have found out in the pre-processing what that part of the solution is going to look like. So the search tree size will decrease. So we can, for example, cut off this branch here, because we've already pre-processed this, and we can cut off this one here because we also pre-processed that one. So now let's make this more concrete, and let me give you a concrete example. And we're going to do this for SAT, because SAT is a problem where pre-processing is usually very successful. So if you were, for example, to use a commercial SAT solver, then pre-processing will play a very very important role in that. I once talked to somebody who develops those solvers, and they basically said that his package works 90-95% through pre-processing. So even for SAT instances with thousands of variables, his package can basically solve it, but it can only solve it because the pre-processing algorithms are very good. So you'll remember that SAT was the problem of finding if a given Boolean formula has a satisfying assignment or not. And I'm now going to write down a Boolean formula for you, and then we're going to do a little quiz to make pre-processing more concrete. So the SAT formula is x1 or x3 or x5, and not x1 or x2 or x4, and so on, and so on. Now, of course this formula here doesn't have very many variables. It's just six variables-- x1, x2, x3, x4, x5 and x6. So with a little playing around, you would probably be able to figure out if this Boolean formula here has a satisfying assignment or not. But of course, what we want to do now is pre-processing, And that means that we want to see if, for certain variables, in this Boolean formula, we can figure out if they should be set to true or false, without actually trying all possible combinations. And as I said, we're going to do this as a quiz. So what I would like you to do is to look at this Boolean formula here, and then consider the variables x1, x2, x3 and x4, and for each of those variables, determine if it's easy to see, if they should be set to true or false. And by easy, I mean without actually trying around different true assignments for the other variables, but you can basically immediately say, for these variables, if they should be set to true or false. I'm going to give you one hint for the solution, and that is that, in my opinion--and this is a bit of a subjective question-- I think that for two of these variables here, it's rather easy to see. And I would like you to select those two. And as I said, this is a bit subjective. I think for x1, it's kind of very clear that this variable actually has to be set to true. And the reason is the following: If you look at all of the clauses here, they are connected by "and"s. So, if one of these clauses here becomes false, the whole Boolean formula here is also set to false. Now, here, x1 is in a very lonely position, so to say, because x1 makes up a whole clause. So if we set x1 to false, then this formula here, the whole formula here will also become false. So it's clear that x1 has to be set to true, and it's also easy to see that, because the variable just appears once. And this can be done in polynomial time; it's rather easy, because you just go through this whole Boolean formula here, or an algorithm could do it, then it finds a clause with just one variable. And it knows if you have a clause with just one variable, then it's immediately clear how you have to set this. So for example, if we had not x1 here, we would also know that we would have to set it to false. So what's the other variable where I think that it's rather easy to see if it should be set to true or false? Well, x2, if you look around it--so here's x2, here's not x2, not x2, not x2. So it appears a couple of times. It appears as x2 and as not x2. So without trying any other assignments, I think it's not that easy to see. X3 is the same. So here we have x3, here we have not x3, here again we have x3, not x3. That's also not easy to see. So what about x4? Well, the thing with x4 is this variable appears only once; namely, here. There's no x4 anywhere else. And that is why, in my opinion, it's very easy to see what to do with x4. The thing that makes SAT hard is when variables appear in different forms, right? So it appears here as x1, and here it appears as not x1. So if we set x1 to true, this clause here becomes satisfied. But we get one less variable to satisfy the clause over here. And vice versa: If we set x1 to false, then this clause here becomes satisfied, but we get one less variable over here because x1 is now set to false, so we have to either set x3 to true or x5 to true. So if a variable appears just once, we have nothing to lose; we can just set x4 to true, satisfying this clause here, and it has no secondary effects on any of the other clauses. And of course, an algorithm could also do this very easily. The algorithm just looks at each variable and counts how often does that variable appear? And if a variable appears just once, it knows how to set it. So here we have x4, we would set it to true. If we had not x4, we would set it to false. So let's try a bit more challenging example, actually. We have found two very easy pre-processing rules for SAT. If there's a clause with just a single variable, and of course if the Boolean formula is written in conjunctive normal form, then we know how to set that variable. And second pre-processing rule that we found out for x4: If a variable just appears once in a whole formula, then we also know how to set that variable. So now let me give you one more example, which is going to be a bit more challenging. So for the next quiz, I've changed the Boolean formula here a bit. And you'll notice that none of the pre-processing rules that we had in the previous quiz apply now. So there's no clause here with just a single variable, so that rule doesn't apply. And also, each variable appears at least once. So, x1 appears 1-2-3-4 times. X2, 1-2-3 times. And so on. So each variable appears at least twice. And also, the other pre-processing rule doesn't apply because each variable here appears more than once. So x1 for example appears four times. It appears here, here, here and here. And the same thing for all the other variables. So they all appear at least twice. So we can't use the rule that we just devised if a variable appears just once. Nevertheless, so if you look at x1, x2, x3 and x4, we're again going to ignore x5 here. Then I think it's still possible to kind of easily see for one of those variables here, if that should be set to true or false. Of course, this is a bit harder than the previous question, but I think you can nevertheless figure it out if you look closely at those four variables here. So let's have a look. What about x1? So here we have x1, not x1, not x1 and x1. I have no idea what to do with that, so it's probably not easy. What about x2? So here we have x2, x2, not x2, still kind of difficult to see if we should set it to false, making this clause here satisfied or if we should set it to true, satisfying those two clauses up here. It's not easy, or at least it's not doable without playing around with other true or false assignment. What about x3, same case? So here we have x3, not x3, x3, again, x3, not x3, no idea what to do with that. So all that remains is x4. Now, where does x4 appear? X4 appears here and x4 appears here. And what you'll notice is that both time we have not x4. So x4 could appear in two forms, right? So x4 could appear as x4, or as not x4. But we have just this one form appearing. And this goes back to the answer of the previous quiz, where I gave you an intuition for what makes SAT hard. What makes SAT hard is that, if you choose a truth assignment of true or false, then some clauses obviously become satisfied, but in other clauses you get less variables to satisfy that clause. However, if you have a variable that just appears in one form, then you don't have that dilemma. It's always clear that we should set x4, which is the correct answer here, to false, because then we satisfy this clause here, we satisfy this clause here, but there are no secondary effects again. So all of the other clauses are unaffected by how we set x4. So we just choose it to our advantage. And of course, also, this is something that is easy to do algorithmically. So for each of the variables that appear in a Boolean formula, an algorithm could just go through and see if that variable appears in both forms--so as the variable itself and in the "not" form. And if it appears just in one form, then we already know how to set it. So we have now found a third pre-processing rule for SAT. Now, let's step back a little bit and look at the general requirements of pre-processing. So now let's step back a little bit and look at pre-processing in general. So you've already figured out three pre-processing rules for SAT. And what I would like you to think about now is, in general, if we think about pre-processing, what are the requirements that we would have for a pre-processing algorithm? And of course, since we're defining pre-processing, I write requirements here in brackets because it has a somewhat subjective component. But here's the three choices: So what would be kind of good requirements for pre-processing? The first one is that it must run in polynomial time; the second one is that pre-processing should always speed up the running time, which means it would speed up the worst-case running time. And the third one is that pre-processing should not affect the solution. By this, I mean that pre-processing does not change if we get a yes or a no as a result. If we have an optimization problem, it's the same. So if, for example, we're solving vertex cover and we're finding a solution of size ten, then after pre-processing, of course, we would also like that solution size to remain the same and not get a solution of 11 or 12. So please check which of these three here would be very sensible requirements for pre-processing. So I think there's two things that are true here. The first one is polynomial time, because we're trying to do pre-processing for problems that normally require exponential time. So if we don't have this requirement here, you could use pre-processing to already solve the problem, because then you would have exponential time. And that really wouldn't make any sense. Of course, in practice it could make sense to have certain exponential time pre-processing algorithms where, for example, the base of the exponent is much smaller than of the general algorithm. But actually I've never seen that done. And right now, for us, polynomial time is a good requirement to have. Speeding up worse-case running time is, in my opinion, not a requirement for pre-processing. Of course, you would like to get a speed-up, but on the other hand, as you've seen, the pre-processing rules are very simple. So, we might always encounter instances where pre-processing does not apply. But that doesn't mean we shouldn't do it. Pre-processing runs in polynomial time, so it's easy to do. So we should just hope that pre-processing helps us, but not make it a requirement. And finally, that is of course very important. Pre-processing must not affect the solution that we get in the end. If we have a decision problem where the answer is yes or no, after pre-processing, we want the answer to be the same, of course. And the same is for optimization problems. If the answer is 10, 11 or 12, then after pre-processing, the answer should remain 10, 11 or 12. Because otherwise, pre-processing would actually alter the problem, and it would alter the solution to that problem, which of course is something we do not want. Alice is medium happy right now and our goal is, of course, to make her more happy here. Let's find out if we can find some good rules for pre-processing a graph for which we want to solve vertex cover, and the way we're going to do this is-- I am going to give you a couple of options of potential ideas for pre-processing. So if there is a vertex with just one neighbor--what I mean by this is there's a vertex like this it's connected to another vertex and that vertex is possibly connected to more vertices, but this one here is only connected to this one. Should we then, as a pre-processing rule, automatically take this vertex here into the vertex cover or should we automatically take this vertex here into the vertex cover, and as a third case, if we have a vertex that has just two neighbors--so something like this-- should we then have the pre-processing put these two vertices here into the vertex cover, which of course would also mean that you do not need to have this one in here. Please check all of the rules here that are correct--meaning that as required, they do not affect the solution that we're going to find in the end. Having applied this rule, we can still find the smallest possible vertex cover for the whole graph. And this was probably a bit challenging but I think it's also quite fun actually to play around with these ideas here. This pre-processing rule here is actually correct and the reason is the following-- so you have this vertex here and it has just one neighbor, so you have this edge here. We already know either this vertex has to be in the vertex cover or this one because, otherwise, this edge here would not be covered. Now, taking both is clearly is a waste. You wouldn't want to do that because once we have put this one here into the vertex cover, you do not need to put that one into the vertex cover, but if you know that you only need to put one of the two vertices into the vertex cover--well, in that case it's always better to put this one here into the vertex cover because it will not only cover this edge but also some additional edges. And in this case here, you've basically paid one vertex but you only get to cover one edge, so it's always better to use this one in that case, which also means that this rule here is not correct. Now, what about this case over here. You might be inclined to think that this is the same case so that instead of using this vertex here it's always better to put these two into the vertex cover, but unfortunately that is not the case and I will give you a very simple example of this. If you have a graph that looks like this for example--you look at it this way that this part here is the same as this part here, then you can see that if you put these two vertices into a vertex cover, then you need an additional two vertices and it can be either one of those or either one of those but you need two more to cover the whole graph. This would give you a solution of size 4, and actually, this graph has a vertex cover of size 3 if you use this one here and this one and this one and you have a size 3 solution. This is not a correct rule because it can lead us to find a suboptimal solution. So you have to be careful with pre-processing rules as useful as they are, but actually just having this one rule over here is already pretty cool because what does it tell us-- Well, once we have a vertex with one neighbor such as this one here, we'll put that one into the vertex cover and we also know that we do not need to put this one here into the vertex cover, and this will now help us to improve our search tree. We start off with an input for vertex cover then apply pre-processing using the rule that we just discovered, which means we then already know that this vertex here must be put into the vertex cover as well as this one here and this one here and these all do not have to be in the vertex cover and this of course is dramatically effective in this case here. It's unfortunately not always the case in practice but as you can see it only leaves a very small part of the network actually where we have to find an assignment but the main point is that we now put this into a search tree to find the best possible vertex cover for those vertices where we have not yet found an assignment. And now my point is this, the search tree that we had so far was as follows. We started out by looking at an uncovered edge and then we branch into three possibilities. We either put exactly one of the vertices into the vertex cover or both. And now comes the cool part, if we have applied pre-processing then we can redesign our search tree because what this pre-processing step means basically is that we have eliminated or we have already assigned all vertices now to have just a single neighbor. Now that we have applied pre-processing, we know a little bit more about these vertices here because we know that this vertex here will have at least one more neighbor because otherwise we would have already found it in the pre-processing and this one here will also have another neighbor. There can be more. The same thing here. What we can now do is we can do a more sophisticated search tree and that sophisticated search tree is going to be based on this part here, these three vertices. You can do more sophisticated search trees but I just want to show you the basic principle here. How do we use pre-processing. We know that we can find structures like these in our graph. And here can be other connections possibly--it don't have to be, but we'll ignore those for now. Now, if we look at this structure from a brute force perspective, there are eight different possibilities for assigning or not assigning these vertices here into a vertex cover. The eight possibilities are as follows: either we can take no vertex at all into the vertex cover and you already know that this going to cause a problem and we could take all of them into the vertex cover, and then then the six more combinations. A brute force search tree would look at eight possible assignments. Out of these eight assignments, if you were to design a search tree that directly branches into these cases here, there's only five cases that would even make sense. Please check which of these cases would make sense for a search tree. And the answer here is that this one makes sense, at least in principle, this one here, this one here, this one here, and this one here. The reason why the other three don't make sense is that you have uncovered edges. So here you have an uncovered edge which is not good, here you have an uncovered edge which is not good, and here you have even two uncovered edges. So there are only five cases that, in principle, seem to make sense. So this would suggest that, in a search tree, we would have five possible assignments, but, actually, we can even do a little bit better. We now know that the search tree, if we design it this way, doesn't have to branch into eight possible assignments but only five possible assignments--those here. So now my question is, if we design a search tree using this branching here, how large is that going to become? I'm going to give you two hints; the first one is the height of the search tree--that will be n thirds. Again, we have to take a little bit of care about the details if we can find such a structure here, but I think I've shown you often enough in this unit that this is possible, so hopefully you'll just believe me this time that it's also possible to always find the structure or, at least, if you don't find one, decide for certain vertices if they are going to be in the vertex cover or not. Now how much wider does this search tree get? It gets very wide, actually; each time you go down into a new level, you branch into five additional cases times five, times five, times five, and so on. Now what I would like to know from you--how big is that search tree? And I would like you to enter your answer here. It will be some number to the power of n, and I would like you to provide two digits after the decimal and round up. And the answer here is 5 to the power of n thirds, which is 1.71 to the power of n. Now if you compare that to the algorithm that we had before, that was about 1.73, so the improvement here is rather marginal. But there's two things to be said here--the first one is that the pre-processing rule that we used was actually a rather trivial one. It just concerned those vertices that have a single neighbor. There are much more complex pre-processing rules that will then allow you to design much better search trees. And the other thing is that we're using a very simple analysis of the search tree here. We're basically just saying there are eight possible assignments, and we're just using five of them; and in a more sophisticated search tree analysis, what you would do--you would not always have the same number of assignments in each of the cases that you go into. So you could have a search tree that, for example, in one possibility, only assigns two vertices a value; in another possibility, it assigns five vertices a value; and so on. And through this refined analysis, you can get much better, as we'll soon see for our vertex cover. And, of course, there are much more sophisticated pre-processing rules than the one that we have discussed here, which, unfortunately, lie outside the scope of this course. But there's one final question about pre-processing that I would like to discuss with you, and that is when to apply pre-processing. And this is one you'll have to think through a bit. Is it before starting the search tree--of course, you start the algorithm and not the tree, but you know what I mean. Is it at each level of the search tree? Is it regularly during the search tree algorithm? Or is it after the search tree is completed? So, again, you might have to think these through a little bit and then please check each one that is correct. So the first one is, of course, rather obvious, before you even start a search tree algorithm, you should always apply pre-processing. And the last one, of course, also doesn't make sense, because once the search tree is completed, then you already have your best possible solution so why would you want to start pre-processing again. The interesting part is this here, because it could be the case that the assignments that you create during your search tree algorithm actually allow you to do new pre-processing rules, and you have already seen this. For example, for independent set and vertex cover where we had said that during the search tree you come across cases where for other vertices you can already decide if they are going to be in an optimal solution or not, so it does make sense, and there are the names of it misleading to apply this pre-processing also during the search tree. Now the question is, how often and when you should you should apply it. You should definitely apply it regularly, because you can regularly gain new information during your search tree algorithm. Doing it at each level, on the other hand, I think should not be recommended, and the reason for that is although pre-processing requires only polynomial time, it still requires time, so if you do the pre-processing too often then on the one hand you waste a lot of time, and on the other hand, these rules will not be very effective because you need to have made a few more decisions each time in the search tree until new pre-processing rules might become applicable. How often to apply it is almost more of an art than a science, but you should definitely not think about pre-processing as something that you do only before you start a search tree algorithm but also something that can help you during a search tree. Welcome to problem set 1, we are going to be going over the running time today and what it means for an algorithm to be efficient or slow or difficult. So we're going to be going over few problems along those lines so I will go ahead and just typewrite it. So let's say we consider ourselves more practical engineers than theoretical scientist. So we're somewhere over here maybe. So we don't really want to look at algorithm code and try to figure out the running times instead what we rather do is implement the algorithms and then measure them, measure the running times of the algorithm for just some random instances let's say of various sizes and see where things go. So let's take a look at the three algorithms called alpha, beta, and gamma in this table. And we're running them on different input sizes. An input size of 100, 200, 300, and 400, and we're showing the running times. Now, this is just for one run of each of these algorithms. Let's say we're running each of these algorithms a million times on a random input of the given size so running alpha a million times on an input size of 100 and different randomly generated inputs of size 100, and it is taking an average of 25, and all these are in minutes. And similarly for an input size of 200, we're running alpha a million times on random inputs of size 200, and it's taking an average 317,000 minutes so you can see a growth somewhat quickly. We can ask a number of questions about these three algorithms. The first question I would like to ask is what is the running time for each algorithm, alpha, beta, and gamma, based on the information in this table. And you might be a little bit confused here because if alpha has linear running time then it also has polynomial and exponential running time since those are worse than linear running time. And similarly, if beta has polynomial running time then it's also exponential running time, but it's not linear running time then. Don't worry too much about that just give the lowest running time you can for each algorithm and check which one applies for each of the algorithms. Let's take a look at beta first just because it has smaller numbers, so maybe that's a bit easier to reason about. Now, as we grow the input size, notice that we're going the input size the linear way. And as we grow linearly, the time it takes beta also grows relatively linearly. So we double from 100 to 200, we roughly double as we triple from 100 to 300, and we get roughly triple of the initial input size. 16 is pretty close to 18, so I'm going to go ahead and say that beta is linear. Now, alpha just explodes--at 100, it doesn't take a whole lot of timing, that takes quite a bit less time in gamma but at N=200, alpha is already in the hundreds of thousands and then it gets even bigger and bigger very very quickly. So I think it's reasonable to say that alpha has an exponential running time. Now, gamma might be a little trickier to see, by I think, if you look at the input sizes relative to the running times in gamma, we can see that it looks to be polynomial. To see this, let's take a look at N² for this input sizes. N² for 100 is 10⁴ which is quite a bit bigger than gamma's running time. N² for 200 is similarly much bigger than gamma's running time and on and on. N² is really the lowest polynomial running time you are probably going to get that it is linear? And it definitely dominates gamma at least for the instances that we are looking at. So, I will definitely say that gamma is polynomial in running time. For more visual representation of this, let's draw a few graphs. Let's take a look at alpha first. Now alpha is still very tiny at N=100 and relative to this graph it is still very tiny here. Here it's quite a bit bigger but still compared to the 10¹³, 10⁹ is actually pretty small and then it's way up here for any of this, 400. Let's just kind of draw an approximation to that. This is not a scale but it'll give you an idea for the shape of the graph which is really what we're going for. But in gamma, we really just can't see them on this graph. They are so close to the x axis here that they might as well just be right on top of it. So that doesn't really help us. So clearly alpha is growing just unbelievably faster than both beta and gamma. So let's zoom in a bit and look at this again. All right, so now I'm only going up to 10⁴, so that makes gamma fairly easier to draw and if this on 100 still, pretty small. At 200, it's closer. At 300, it is about half way there and then it gets about here. So let's go ahead and draw it up. If we try to draw beta, it's still right about here, so it still grows much much slower than gamma does. As we can see that they're really in different classes because they're both just growing so much slower than alpha is, but beta similarly is growing just so much slower than gamma is. So they're definitely in different classes and this is kind of a visual intuitive representation of why alpha is exponential, gamma is polynomial, and beta is linear. Let's answer a few other questions about these algorithms--alpha, beta and gamma. First, I want you to tell me whether the best-case running time for given input size is always no longer than the best measured time for each algorithm--true or false. Also, I'd like you to tell me whether the worst-case running time for given input size is at least the worst measured time for each algorithm. I also like to know whether algorithm beta is the fastest for all inputs, not just 100, 200, 300 and 400 but any input I get that is algorithm beta faster always than alpha and gamma. And finally, I'd like to know whether the small inputs the algorithm with exponential behavior is sometimes faster than the algorithm with polynomial behavior. So tell me which of these statements are true and which are false. The first question, the best-case running time for a given input size is no longer than the best measured time for each algorithm. This is true and to think about this, all you really need to do is realize that our definition-- the best-case running time is better than all other possible running time. If there's one smaller than it, well, it's not really the best is it, and you can think of the same thing for the worst-case running time to the second one, which is also true. The worst-case running time for given input size is at least the worst measured time for each algorithm because if there is a worst or longer measured time, then the worst-case running time-- well then it's not worst is it. Now, for the third question, algorithm beta is the fastest for all inputs. This is actually false, and even though it's actually true for all of the inputs that we tested, it might not be true for much smaller inputs--for example, n=1 or 2. We can't say that it's the fastest for all inputs because well we haven't tested it on all inputs. It might very well be the case but in order to say that we'll actually need to test it and that's not really feasible. And for the final question, what else can for smaller inputs the algorithm with exponential behavior is faster than the algorithm with polynomial behavior, and this is actually true. If you got alpha and gamma, alpha being the exponential algorithm and gamma being the polynomial one, actually is faster--25 minutes is quite a bit faster than 500. So this is actually true and it's interesting to see that sometimes for small inputs and exponential algorithm isn't really that big of a deal. For this next problem, we're going to be looking at some tricky behavior of O notation when we're dealing with numbers. To illustrate this, let's take a look at the number 4000. Now 4000 has a magnitude of size of well 4000 but you can write it down with a lot less than 4000 digits. In fact, you can write it down with 1, 2, 3, 4 digits. So it's actually a logarithmic number of digits in relation to the size of the number. Similarly, if we wanted to write down 40,000, which is 10 times as big as 4000, we only need to write down well 5 digits. So the number of digits is growing logarithmically with the size of the number that we want to represent. Now, let's say we call the actual number we want to represent n. And let's say the number of digits necessary to represent n, we'll call d. And now, let's take a look at a fairly simple algorithm to test whether n is prime. So we have this basic isprime function to test whether n is prime. And it does this by first checking if n is less than 2 since 0 and 1 are not prime and returning false in that case. If n equals 2, then we return 2 because 2 is prime and then we get rid of all the even numbers because none of the even numbers other than 2 are prime. And then we check if there are any odd numbers between 3 and the √n that divide n. Because if there are any numbers that divide n, then it's not prime. And it turns out to check for primality, you actually only need to check up to the √n and we're not going to get into why that is the case right now because well that's another course. But if it finds any numbers that divide n then we return false and otherwise we go all the way through this and return true. So my first question is, which of these answers best characterize the asymptotic running time of this primality algorithm as a function of n, the value of the input size? Is it a constant order? Logarithmic? Is it in the order of √n? Is it linear? Quadratic? Or does it turn out that this is exponential? And my second question is, what about if we express the running time as a function of d, the number of digits that it takes to represent the number rather than as a function of n, the actual value of the number? If we express the running time in this way, then is it linear in the number of digits? Quadratic? Does it grow to the 10th power? Does it grow 10 to the log of d? 10 to the d/2? 10 to the √d? Or 10 to the d? Check whichever one is best. This is a bit of a tricky question, so let's go over the first one first and let's go back and take a look at the code. So, most of these are arithmetic operations and if you remember from the RAM model that we've been discussing in the lecture that according to the RAM model that we've been using, all arithmetic operations take constant time, so it means this, this, this, and this all take constant time. The only thing that doesn't is this for loop right here. So how many times does the for loop execute? Well, that executes based on n, the value of the input about square root of n times and if everything else is constant time and this executes square root of n times, well from around the order the square root of n. You can go ahead and check this. So this next part is very pretty tricky and it hinges on getting this part right. So if you have trouble with this, that is totally understandable. So first, let's remember that we can represent n with a logarithm and number of digits which is what d is. What this means is that n=c where c is just some constant that we're not going by * 10⁻¹ and as an example of this, let's say, that n is 4000 like we had before. So 4000=c where c is something * 10d⁻¹, d is 4-1 is ³, and well then that means that this has to be 4, 4*10³ is 4000. So this is how it represent an n by d and c is just some constant to make everything more count and since this is big O equation, we're not really that concerned with constants. Now, if we know this and we also know that the algorithm has a running time from the order of square root of n, and we're talking about it in terms of n, and then we can put these together, so square root of n is the square root of all this and we're going to have to do a bit of math here. Well, we can separate this two out to the √c and √10d⁻¹, well we can describe this by saying this, 10d⁻¹/2 since that's exactly that the square root is. And now we can pull this out and so now we have this nice three separate terms, and again since we don't really care about constants, we can just kind of get rid of these. We can say that √c * 10⁻¹/² is just some other constant we don't really care about code k. Because the only thing we really care about is D. So this is k * 10d/² and this is exactly what we need to say but this algorithm is in big O notation until we can say that in terms of d the running time in this algorithm is 0(10d/2). Now, if you didn't get that or if you had problems with it, don't worry about that it's really kind of a challenging problem and if you still don't understand it,then I recommend checking on the forms and discussing it. This is really the kind of basic math calculations that you're going to have to do and part of the problem here that a lot of people run into is these constants that we just drop or don't care about really and that's the kind of thing that makes big O notation really very powerful that we can just drop those and say we don't really care about those in the grand scheme of things. Since we'll be working on problems with graphs in this course, we need to find a way to efficiently represent them in a program. There are a lot of different ways doing this and they're really based on certain tradeoffs such as memory requirements, speed of certain operations, modifying the graph, determining the neighbors of a vertex, etc. And what you want to do and how you want to represent them really depends on the specific problem you're talking about. But let's take a look at a fairly simple way of representing a graph and that's called an adjacency matrix. An adjacency matrix specifies which vertices are connected to which other vertices. So let's go ahead and explain by building this adjacency matrix for this graph. So let's look at A. Well, A isn't connected to A and we're going to represent that by writing down 0. A, however, is connected to B and we're going to specify that by putting a 1 in this location. Similarly, A is connected to C and A is not connected to D, at least not directly. And that's really what an adjacency matrix cares about. All right. So an adjacency matrix is really pretty simple. You just put a 0 everywhere where one of the vertices, the row vertex, is not connected to the column vertex and vice versa since there's no direction here. And you put a 1 everywhere where the row vertex is connected to the column vertex. And so you see that the matrix is symmetric. That is, it's mirrored right about the diagonal here. So A is connected to B, which means that well B is also connected to A. It's not necessarily the case if you have a direction on each of these arrows but we're not going to worry about that right now. Now what I'd like you to do is give me the best possibly O notation running time for each operation below. We're going to assume a graph with n vertices represented as an adjacency matrix. We're also going to assume that the time it takes to access any particular element is constant and that the memory needed to represent the list of elements is order n. So give me the big O notation of the time it takes to represent all of these. So the times you see are two given vertices are connected. Well, if we can access every element of the adjacency matrix in constant time, well then we can just check that given element in the matrix in constant time. Similarly, the time required to add and edge between two vertices-- well, we can access that element in constant time and then just change it from 0 to 1 that's constant time, and similarly, we can change from 1 to 0 to remove an edge between two vertices. Now, the time to find the degree of a vertex. It's a little bit harder to find the degree of a vertex where the degree is the number of vertices that are connected to it. In order to find all the vertices that are connected to a given vertex, well, we have to go down that row or that column one by one. Since we have to do this n times, well this is what it end at least. Now, these questions are somewhat tricky and memory required to represent a graph with O(n) edges as an adjacency matrix and O(n²) edges as an adjacency matrix. This is a bit of a trick question. If we have n vertices, then we have an n x n, which is n² total elements. So we're going to need n² memory slots to put each of those elements in. You can pare that down a little bit if you're really clever, but if any of adjacency matrix approach, then the memory required isn't really a function of the number of edges so much as it is the number of vertices. So we want to go ahead and put n² for both of those. Now, let's get a little bit more work done with some adjacency matrices, just so you can get a bit more comfortable. So let's talk about inverse graphs. In the unit, we discussed how to create the inverse graph as a graph that helps us solve the clique problem. So, for example, the inverse graph of the graph that I drew before would be the graph with the red edges here, so quite a different graph here. Now, how do you represent this as an adjacency matrix. Well, to diagnose is the because we're not allowing loops anywhere in here, so the diagnose to 0's, and you know when once we have in the adjacency matrix are from the D to A or from A to D so the matrices is symmetric and from B to D and everything else is 0-- means that all of these edges disappear in the inverse graph. Now, how do you represent this in Python. Well, an easy way to represent a matrix in Python is as a list of list, so to look at some output of some code, we define a completely empty graph here. Now, we print the graph we see. But this is just a list of list with five 0's in our list, and if we invert this graph, when we see that we get the graph of all 1's except for the diagonal here of course since we don't have any loops. So what I want you to do is write an inverse graph function such that it takes a graph or a list of list and outputs a list of list, which is the inverse of the input graph. Okay. Let's take a look at my solution. So we defined invert graph. It takes a graph and then it creates a new graph that we called an inverted graph that we start as an empty list. Then for each element in the range of the length of the graph, we append another empty list to the inverted graph, and we're doing this so we don't change the input graph in case we still want to use it and since that also wasn't in the problem statement. Now, for each of those empty list since this is a square matrix, we again use the length of the input graph. Now, we check if i is not equal to j that is we're not on the diagonal of the matrix, and if so, we append 1- the current value. So basically, we flip that from 1-0, from 0-1. If we are on the diagonal, then we just put 0 there since we have already specified that we're not allowing loops and once we get done with this, we simply return the inverted graph. Okay, so tell me when we saw that Alice's algorithm for finding a valid vertex cover is very inefficient but fairly easy to program too, so I'd like to go ahead and try and implement this and we'll do this in two separate parts. First, I want you to find a procedure validity check that returns true if and only if the given cover is a valid vertex cover for the graph that is input, and the graph is going to be a list of lists, an adjacency matrix like we have seen before, and the cover is simply going to be a list of the same length as the number of vertices in the graph. So for example for the given graph, if we attempted to cover of say A and C, then the cover that we would input to validity check would be 1, 0, 1, 0, and the graph that we would have be 0, 1, 1, 0 inside the list 1, 0, 1, 0; 1, 1, 0, 1; 1, 0, 0, 1, 0, again in a list. So these would be our inputs to validity check here. So I want you to do is fill in the rest of this function here. The next thing that I want you to do is fill in vertex cover naive where it simply takes the input graph as a list of list as an adjacent to matrix and finds the minimum vertex cover of that input graph, and you can use the validity check to do this. So your code should check if the assignment is valid for a given assignment, should calculate the size of the assignment, and then it should update the minimum vertex cover variable if appropriate. So okay. Great. I hope you have fun with this problem. Let's take a look at my solution. So the first thing I do is assert that the length of the graph is equal to the length of the cover since we need the same number of nodes and vertices in both the cover and the graph. We set n equal to length of the graph then. So we go through every element in the adjacency matrix one by one and if the element is at 1, that is there's an edge between those two vertices, and either the first vertex which I think is not equal to 1, that is it is not part of the vertex cover or the second vertex it isn't, then we return false. And we check every single one of those and if we fall through all of those, then we go ahead and return true and then it is a valid vertex cover. Now for the naive vertex cover algorithm, what we do is first for every assignment and a product of 0's or 1's that is of length n, that's what this product statement does. And if the validity check is true for that assignment and that input graph, then we set the size to be the sum of the number of 1's in the assignments. So we add up all the elements in that list, all the 0's and 1's. Now if the minimum vertex cover is greater than the size, then we set that to be the size. We update it, otherwise, we leave it alone. Once we've look through every possible assignment and remember there are a lot of possible assignments, then we return the minimum vertex cover. All right, so let's say we want to try Alice's vertex cover a little bit smarter. So let's look at Alice's vertex cover. The main thing that happens, the key idea is that we're just going to try every single possible assignment of a cover to the underlying graph. So, let's say that graph, we might try this, this, and this or we might try this, this, and this, or just this, or maybe all of the vertices. The point is that we're not specifying an order to check the vertices in. We're just saying check every single one. What if we did though, what if we decided to check the vertices in order of size? That is we're checking the covers with increase in size. So first, we check a cover with zero vertices in it, that is no cover at all then we check every cover with one vertex in it. So let's say this one, then we check this one, then this one, and so on. And after we're done with that, then we do every vertex cover with two vertices in it. So this and this and this and so on, and we keep going checking all of the covers in increasing order. That way, once we found a possible cover, we know that that is the minimum possible cover and we can simply stop it. Now, my question then is does this change how the underlying algorithm performs? So let's go down the questions. First, does the new algorithm on average checks fewer assignments than the original? Second, does the original algorithm sometimes look through fewer assignments? And by that, I mean, does it look through fewer assignments than the original algorithm at least once? Next, is the worst case behavior of the new algorithm in O-notation better than the original? And similarly for the best case and the average case of the new algorithm in O-notation, are they better than the original? Please check all either true or false. Okay, let's look at these questions. So, the new algorithm on average, check fewer assignments than the original? This is actually true and to see this the area all you have to look at is the original has to check every possible assignment. If it doesn't, then it can't know that it's actually the lowest assignment whereas the new algorithm, as soon as it finds a vertex cover that works, since it starts from the bottom, it knows that that is the minimum vertex cover, so it knows that it can be done, so on the average, the new algorithm will actually check fewer assignments than the original. Now does the original algorithm sometimes look through fewer assignments? This is actually false and again, the same reasoning applies. The original algorithm has to look through every possible assignment, whereas the new algorithm sometimes doesn't. Now is the worst-case behavior of the new algorithm, in O-notation better than the original? This is actually false and to see this, you just have to realize that sometimes the new algorithm is still going to have to check through every possible assignment. Sometimes that's the best minimum vertex cover you can hope to find and since that's the worst case and it's the same as new algorithm, the worst case behavior in O-notation is also just as bad as the original. However, the best case behavior is actually better than the original algorithm. The new algorithm does better in the best case. The best case is that there happens to be a minimum vertex cover of only one vertex and it checks that first. And if it does, well then it's done whereas the best case of the original algorithm is still exponential because it has to check every possible assignment, so the best case behavior is far better. Now what about the average-case, how can we expect the new algorithm to behave on average? Well actually, the new algorithm isn't on average as synthetically better than the original algorithm. Again because it may have to check through just as many assignments as the original algorithm. Now, this last question is tricky. How about the average-case behavior in the algorithm? Compared to the original, is it better as synthetically? This is actually false and this might be a little hard to see but a good way of looking at it is to realize that on average, the new algorithm is still going to have to check through at least half of the possible vertex cover of all the possible assignments. And there are exponentially many different assignments to the graph. Well, half of the exponential number of assignments is still exponential, so on average, the behavior of the new algorithm is still exponential which is just as bad as the original. So, if you got that, great. If you didn't, don't worry. That's kind of a tricky question but hopefully I got you thinking. So if you have trouble with any of these, don't worry about it. Some of them were a little bit tricky but hopefully they got you thinking. Okay, that's it for this problem set. Hope to see you in the next unit. Welcome to the second problem set. Let's start this off with some questions just to check your understanding of NP and NP-complete problems. So first, are there some NP-complete problems that can't be transformed into SAT in polynomial time? Second, nondeterministic RAMs may give different results for the same decision problem. Third, a problem with exponential possible solutions can only be NP if P equals NP. And finally, every program that takes exponential time on a deterministic machine can be made to run in polynomial time on a nondeterministic machine. Check true or false for each problem. Alright, so the first problem is false, and this comes from the definition of NP-completeness. By definition since SAT is in NP-complete, every problem in NP can be reduced to it in polynomial time, so there can't exist NP problems that can't be transformed into SAT in polynomial time. The second problem is also false. Nondeterministic RAMs don't give different results for the same decision problem. This is something that a lot of people have problems with, but the key is that nondeterminism isn't the same thing as randomness. At each step, remember whenever the if better procedure is called, it makes the best possible decision, so it's not going to make a random one, and it's going to make the same best possible decision every time, so it won't give different results for the same decision problem. The third problem is also false. A problem with exponential possible solutions can only be in P if P equals NP. A good problem to see this on is sorting. Whenever you sort a list of N elements, let's say, there are exponentially many different possible sorts, but actually, there are quite a few sorting algorithms that can find the correct sort of an element list in much shorter than exponential time, so this is actually not true. The fourth problem, just like the other 3, is also false. It is not true that every program that takes exponential time on a deterministic machine can be made to run in polynomial time on a nondeterministic machine, and good examples of this are any program where the output size is exponential in the input size. For example, if you have a list of N elements and then you want to print out all possible sub lists, then the fact that you have to print out every single possible sub list, of which there are exponentially many in the input size of the list, means that if better doesn't actually buy you anything. You still have to explore the entire exponential space, so even a nondeterministic machine will have to take exponential time in that case. Let's say we are simulating a nondeterministic RAM machine inside of a deterministic RAM, so the main cost of that is simulating the if<u>better function since</u> it's really the primary difference between a deterministic RAM and a nondeterministic one. But what exactly is the cost of simulating if<u>better?</u> Let's say we have a polynomial time algorithm, and that algorithm uses if<u>better a constant number of times.</u> Then does that mean that the simulation on the deterministic RAM takes a constant number of time, a linear number of time, a polynomial amount of time, or an exponential amount of time? And similarly, if we use the if<u>better function</u> a logarithmic number of times in the input or a linear number of times in an input, and just for kicks, let's do something a little bit more challenging. How about if we use the if<u>better command</u> every 3rd instruction in the execution, then how much time does this simulation cost us? Please check once for each row. Alright, so we know that the running time for simulating if<u>better on a deterministic RAM is 2 to the number of times used.</u> Once we realize that, we really just have to plug in these times to figure it out. So for a constant number of times, this increases it to polynomial and similarly with order log N times. Now for order N times, we have essentially 2 to the N here, which is exponential. Now this last one is a little tricky, but really you just need to realize that this is a polynomial time algorithm, so it's at least slower than an order N algorithm, so it's also exponential. Let's say we have a friend Bob. Bob is blue, he's had a nasty run in with a can of paint. Now let's assume that Bob has a Boolean formula, not necessarily this one but just some Boolean formula. And suppose Bob comes to us and tells us I've already found out that this Boolean formula is satisfiable. Now let's say we don't necessarily trust Bob. Bob is given to exaggeration. We'd like to be able to figure out in polynomial time whether or not Bob is telling us the truth. So how would be go about doing that? Let's say Bob came to us with a complete series of snapshots from a nondeterministic RAM solving SAT on his formula. Would that be enough for us to believe that he had a satisfiable formula? How about if he had a list of satisfiable clauses? For example, he had a list that had x as the satisfiable clause and not Y as a satisfiable clause. Then for the entire Boolean formula, could we then determine whether it was satisfiable or not? What about if you had a satisfying assignment for all of the variables in the formula? What if we had all the calls to if<u>better on the Boolean formula?</u> So not necessarily a complete series of snapshots from a nondeterministic RAM solving SAT on his formula, but just all the calls to if<u>better.</u> Would that be enough for us to believe Bob? And finally, what if we had a satisfying assignment for not all the variables but 90% of the variables in Bob's formula. Could we believe him then? Please check all that apply. Alright, first if we had a complete series of snapshots from a nondeterministic RAM solving SAT on his formula. Well, a nondeterministic RAM can solve SAT in polynomial time, so we can check those in polynomial time as well since we just have a list of these. So once we have those, we can definitely verify that his formula is satisfiable. Now if we had a list of satisfiable clauses, this actually isn't enough to verify that Bob's formula is also satisfiable. To see this, let's take a look at the formula in somewhat pythonic form, X and not X. Now clearly X is a satisfiable clause and so is not X, but the entire Boolean formula is definitely not satisfiable. So a list of satisfiable clauses actually isn't enough for us to believe Bob. Now if we had a satisfying assignment for all of the variables in the formula, then sure, we can just plug them into the formula and check on a deterministic RAM, and that occurs in polynomial time. Similarly, if add all calls to if<u>better on the Boolean formula,</u> well, if<u>better is the only difference</u> between a nondeterministic and a deterministic RAM, so if we had all the calls to if<u>better,</u> we wouldn't actually have to simulate if<u>better,</u> we would know what the algorithm did at each step of the process. So we could also check Bob's formula using just this. Not even a complete series of snapshots is necessary just the calls to if<u>better.</u> Now let's say we had a satisfying assignment for 90% of the variables. Well, 90% of the variables still leaves 10%, and 10% of exponential is, well, exponential. So we would still have exponentially many variables to check. So this actually doesn't work. So now we're going to see a representation of Boolean formulas in Python that we're going to be using to then write a function is satisfied that checks whether a given Boolean formula and a given assignment of true false values to that Boolean formula or rather to the variables in that Boolean formula satisfies it. So first, we have a variable num<u>variables,</u> which is simply the number of variables that are in the Boolean formula, the number of distinct variables that is. The Boolean formula itself is represented as a list of lists where each inner list is a clause. For example, this inner list is the clause X1 or X2 or not X3, and you can see that the variables that are negated are negative. This clause would be X2 or not X4. And this clause is not X1 or X3 or X4. And then of course each individual clause would be anded together. Assignment is a list of true false assignments to the individual variables. Note that assignment has one more element in it than the number of variables. The first one is actually just a place holder. It doesn't do anything. We're only concerned with the second element through the end of the list. Now if we have these individual assignments to the variables and then we print is satisfied of these, we can see that it returns true. This is a satisfied Boolean formula or rather this Boolean formula is satisfied by this assignment where X1 is true, X2 is true, X3 is true, and X4 true. And if you run C through this and check, you'll see that that is in fact the case. Now if we change assignment to true, false, true, true, then we can see that this assignment does not satisfy the Boolean formula and returns false. So your job is to write the is satisfied function to fill in the body of the function so that it correctly interprets whether a Boolean formula is satisfied by a given assignment. So this is my solution to the problem, so let's just go ahead and run through it. Since clauses is a list of lists, we're just going to run through each inner list of for clause and clauses. We're going to set a variable called clause satisfied to false to begin with, then for each variable in the clause, if it is positive, that is if it is not negated than if the assignment to the variable is true, then we switch clause satisfied to true and break and go to the next variable in the clause. Else, we go ahead and recognize that the variable is negated and we check that the assignment is false, and if that is the case, then we set the clause satisfied to true and break. Finally, once we are done looping through all the variables in the clause we check if clause satisfied is false, and it is still false, then we immediately return false because there is a clause that is not satisfied. This is simply a shortcut to make the algorithm run a little bit faster. And once we're done with that, we simply loop back to the next clause and start all over. And if we fall through all of those, then we return true and say, yes, the entire Boolean formula is in fact satisfied by the given assignment. For the final problem in this homework, we're going to be talking about some distinctions between P and NP and also what it would mean if P were equal to NP or if instead P were not equal to NP. Let's look at a few examples. So first it might be the case that if P were equal to NP then that would mean that every single computational problem could be solved in polynomial time. It could also be the case that if P were not equal to NP, and we could prove that, then that would mean that there are no NP-complete problems that could be solved in polynomial time. We might also say that regardless of whether P equals NP or P does not equal NP that there are still NP-complete problems that are easier in some sense to solve in practice than others. We might also say that, well, if we have the ability to solve some instances of an NP-complete problem, then that necessarily implies that P equals NP. We could also say that showing a problem is NP-complete automatically means that we know it can't be solved in polynomial time. So, which of these statements do you think are actually true? Please check all that you think are true statements. So let's look at these from the top down. First, if P equals NP would that mean that every computational problem could be solved in polynomial time? Well, no, actually it wouldn't. First of all, there are problems that simply can't be solved it turns out, which we'll get to later in the course. But even if we restrict ourselves to problems that can actually be solved by a computer, there are still problems that would not be solvable in polynomial time. In fact, we mentioned an example of this in an earlier assignment where if you wanted to print out all the sub lists of list, then necessarily that means that it will execute in exponential time not polynomial time because you have to print out every single possible sub list, and that's a case where the if better construction doesn't actually help you out, so this is not the case. However, the next one is true. If P were not equal to NP and we proved this, then that would mean that no NP-complete problems could be solved in polynomial time. That's in fact part of the definition of P not equal to NP. And for the next one, this is also actually true. This is a little tricky and somewhat subjective depending on what you mean by easier here, but it's certainly the case that despite NP-complete problems all being in some sense as hard as each other, we might care about a certain subset of instances of a problem that for whatever reason are easier to solve in practice than another problem might be, and that really depends on what in practice you are concerned about and which instances of a problem that tend to come up in practice. And for the fourth one, this is not true. The ability to solve some instances of an NP-complete problem does not imply that P equals NP. For example, you can find the clique or a clique or a minimum vertex cover too of an empty graph relatively easily. It's, well, nothing because the empty graph has no vertices and no edges. That's an example of an instance that you can quite possibly always solve or you should always be able to solve very quickly, but that doesn't mean that you can solve all instances. And for P equals NP, we really have to concern ourselves with every single possible instance of a problem, and that's really where NP becomes quite complicated. And finally, showing a problem is NP-complete means it can't be solved in polynomial time. Well, no. In order to do this, we would actually have to show that NP is not NP or rather P does not equal NP. That's really the problem we're talking about here in not so many word. So just being NP-complete isn't enough. We also have to prove that P does not equal NP. Welcome to problem set three, let's dive right in. In the unit, we talked about a problem called k-coloring, and just in case you don't remember it, let's go over real quick. Let's say we had a graph and let's say we want to give all the vertices different colors. Well, not different colors, but we want to give them colors so that neighboring vertices never have the same color like keyword on a map for instance. Let's go ahead and start, I would green color this one. That means if we want to move to another color, we can color the adjacent ones a different color but we can't color any of these green because this is connected to all the vertices. So, let's start off this one and color that red but that means we can't color that red. We can color one of these red, so let's go ahead and do that too. Let's color this one red. That means this one can no longer be colored red either. Neither of this can be colored red or green, so let's color them purple. And now, we completely colored this graph with three colors, and at least for k>2, whether a graph can be colored and k many colors, is an NP complete problem. Now, in order to show the k-coloring is complete, really what we can do is simply reduce clique to k-coloring, and there are two basic facts that help us to do this. The first question we need to answer is that if a graph contains a clique of size k, then how many colors are needed to color the graph at minimum? And the second question is, conversely if a graph can be colored with at most k colors, how big can the largest clique in the graph be? Go ahead and enter your responses in the text box as provided. Now, it turns out that the answer to both questions is k. Let's see why that is. Now remember a clique is a sub-graph in which all of the vertices in the sub-graph are connected to all the other vertices in the sub-graph--like for example this sub-graph, now might be part of a larger graph--we don't really need to know that, but this is a clique right in here. So if we color just one of these vertices like this, well then we can't color any of the other vertices with that color. So we need as many colors as are in the largest clique and that would be k. Now, for the second question, let's say we know that the graph can be colored with at most k colors and that's all we need--we don't need more than k colors. Well, then we know because the reason we just use--the largest clique can only have k vertices in it. So as otherwise we wouldn't be able to use k colors in order to color the graph. Let's look at shortest tour but -how about we look at a bit more practical version of the shortest tour problem. So let's say first the shortest tour problem, instead of using 1 van which seems a little silly-- you'll realize, "Hey, let's just use a lot of vans," let's say we'll use n vans in order to deliver the mail. Now, if all vans start at the same time, well then how does this end up changing the behavior of the problem and the complexity of the problem. Well, let's take a look at two different questions. First, let's ask how much time until all the mails delivered and all vans return to the base in the n vans scenario and the 1 van scenario. Will the n vans take less time, less than or equal to the same amount of time, greater than equal to the same amount of time, or always greater than the time that 1 van will take. And similarly, for the sum of all individual times taken by the vans. Now, what I mean by that is--if let's say each van takes 8 hours to deliver the mail and then return back to base, then the total amount of time would be 8 hours times n where n is the number of vans. And is this total amount of time always going to be less than, less than or equal to, greater than or equal to, or always greater than the amount of time taken by a single van to do the same thing? Please check whichever is most appropriate for both questions. So if we look at this, it's actually the case that n vans splitting up the work. We'll take quite a bit less time from when they need to deliver the mail to when they get back to base. Now, there might be some cases where it doesn't actually help out too much. For example, if you have a graph where it's just a straight line well then all the n vans are going to go here and here and here and here, and then dot, dot, dot, dot,--well, you haven't really save any time. However, if you have instead a graph like this, well then, you can have four vans each go out on one of the arms and come back to base instead of having a single van that would have to go here and come back and here and back, and here and back, and here and back. That's quite a bit more time. You don't want to have to do that and that's why you used more vans and it turns out that the time delivered the mail and return is always going to be less than or equal to depending on the actual case. Now, how bout the sum of time taken by the vans. This is going to be at least as much as and maybe more. To see this, let's actually take a look at those same two problems. In this case, it takes an hour to leave base and go along the road to where you're delivering the mail and then an hour to come back. This is a very long delivery route. Then if you have four vans then the time taken is two hours for each van which would be eight hours which in this case is actually the same. Now, the other case where you have to go along here. Now let's say if you have four vans then, well, neither van come up here and then go back. Neither van to come up here and go back and then come up here and go back and then come up here and go back, that's actually the quickest you can do it while still utilizing all four vans. In that case, you're taking two hours there, four hours there, six hours there, and eight hours there. Instead if one man, he will just take one, two, three, four, five, six, seven, eight total. So the actual total time taken is quite a bit larger in this case. So, it really depends on what you all want to optimize. Generally, the time that it takes to deliver all the mail is probably more important to most people than the sum of the individual driver's time and it's really a trade off which is one is better here. So we showed in the last problem that it really depends on what time you want to minimize whether you want to use n vans or 1 van, and so let's take a look at those two problems. First, we could minimize the time until all mails are delivered or we could minimize the sum of the individual times taken by the vans. Now, what I'd like to know is whether minimizing either of these times is polynomial time solvable or NP complete, and let's go ahead and say this is the case for n vans and an n vertex graph. And go ahead and check whichever is appropriate. Now it turns out that minimizing the time until all mail is delivered is polynomial-time solvable because you have n vans and n vertices. You can simply assign each van to a vertex, have it go there, come back, and you're essentially done. The second one is actually still NP-complete, and the reason is, if you want to minimize the sum of the individual times taken by the vans, then you still have to essentially do the one-van shortest tour for each of those vans. And that ends up being NP-complete. Let's look at a famous NP-complete problem that we didn't cover in the unit, called Hamiltonian paths. Now a Hamiltonian path involves visiting every vertex of a graph exactly once, and here's an example. Let's say we have the very simple graph shown right here. Well, in that case, a Hamiltonian path, if we start it here--let's say we'll go to this vertex, then this vertex, then that vertex. And that is a Hamiltonian path. We visited each vertex exactly once. Now there is another NP-complete problem called a Hamiltonian cycle which is the same thing, but you have to start and end on the same vertex. And that's actually impossible on this graph. We can kind of start off here, but then, once we get here, there's no way to get back to our starting vertex. So now let's take a look at a slightly more complicated example. And what I'd like to know is whether this graph has a Hamiltonian path and, similarly, whether it has a Hamiltonian cycle. Please check the corresponding box if it has either a Hamiltonian path, a Hamiltonian cycle, or both. Now it turns out that this graph does actually have a Hamiltonian path. And to see this, let's go ahead and start here, and let's come around here and here. We're going to come over here, here, here, here, here, here, here, and here. And we have covered every single vertex, as you can see. Now it turns out that this graph does not have a Hamiltonian cycle. And, in order to show this, you would actually have to know a bit more math or exhaustively check every single possibility, which I am not going to do in this video because it would take far too long. So I invite you to try and find a Hamiltonian cycle if you doubt that, but it may take some time. Following along from the last problem, we can show that Hamiltonian cycle is actually NP-complete, and we can show this from a reduction from shortest tour to Hamiltonian cycle. To show this, let's say every edge for shortest tour has a cost, or an edge length, of 1. Then, we can say that a shortest tour for a given graph with n vertices has a given length if and only if the graph has a Hamiltonian cycle. And what I'd like you to do is give me this length that completes this. So the answer here is n, and to see this, let's start from the second part of the statement. Let's say that a graph has a Hamiltonian cycle; then that means it can start at one vertex and end at another, passing through every vertex on the way. Now if each edge has a length 1, then the shortest tour from one end to the other is going to pass through each of those edges. And then the shortest tour for the given graph has a length of n. Now let's say instead that we have a shortest tour for a given graph with n vertices, and it has length n, with the stipulation that each edge has length 1. Then we can simply use that shortest tour as the Hamiltonian cycle and be done. Okay, for this last question, I'd like you to prove that the 4coloring problem is NP-complete, assuming that it's already known that 3coloring is NP-complete. And we're going to do that by writing a program that models the reduction proof. So let's say we're given a magical graph is 4colorable function. Now, in order to perform this reduction program, we're going to give you a function graph is 4colorable. And this function takes as input a graph in the form of an adjacency matrix, like we've previously discussed, and it returns a boolean--either true or false-- indicating if the input graph is 4colorable in polynomial time. Now, what I'd like you to do is define a function graph is 3colorable that, again, takes an adjacency matrix as input and returns a boolean indicating if the input graph is 3colorable in polynomial time. Now, as I said, the point of this is to show that the 4coloring problem is NP-complete. So we'll want you to do a reduction program reducing the graph that is taken as input to 3colorable and change it into a graph that is an input to 4colorable to show this reduction. Okay, so what we're going to do intuitively is we're going to add a new vertex to the graph, and then we're going to add an edge from all of the current vertices in the graph to the new vertex. And then we're simply going to return the result of graph is 4colorable of this new graph. So we construct a new graph, which is just an empty list in this case, and then for every node in the original graph, we add in an additional 1. Since this is an adjacency matrix, that means that there is an additional vertex that every single node in this graph is connected to, like I just said. We're going to append this new node to each row in the adjacency matrix. Then, we're going to append a column of 1's at the end of this graph of the adjacency matrix, and this represents the vertex that is connected to every other vertex, which is what we've just constructed. And then we take this new graph, and we simply run it through graph is 4colorable. So we've reduced the 3colorable problem to the 4colorable problem. And, by the definition of NP completeness, that means that the 4colorable problem is also NP-complete. Alright, welcome to problem set 4; this first problem we're going to be talking a little bit about different kinds of search trees. And let's go ahead and dive right in. Now let's say we have a search tree, like so, but instead of branching twice at each level, we want to say that it's going to branch four times. So we have a search tree more like this, where at each level, we split four times. So that means that, since this is a search tree, there are four different possible paths we could go down at each different branch. Now let's also say that this tree has a height of n/3, where we're going to say that n is divisible by 3 just to keep things simpler. So we have a whole lot of n nodes or leaves down here at the very end, and let's just assume that there are a total of n/3 levels. Now since this is a search tree, all of these end leaves here represent a different possible solution that this search tree could come to. So my question is how many solutions does such a search tree, that splits at four times at each branch and has a height of n/3, actually go over? How many solutions are there? And please enter your answer in this box, and let's go ahead and say that this is to the nth power-- we'll go ahead and give you that--and type this in to 3 decimal places, please. Okay, let's think through this a bit. So, first of all, at each single branch, we have four possible choices. So we can take this branch, this branch, this branch, or this branch. So we have four choices, a total of n/3 times. So that's 4 4, times on and on, times 4, a total of n/3 times. Now I had you pull out to the nth power here, so let's go ahead and do that. So this is really 4^1/3 to the nth power, and that is approximately 1.587 to the nth power. Most of this problem is that it's going to involve building an improved search tree for the vertex cover problem. So in order to start off with that, let's go ahead and try building the naive approach which is very similar to what you did in problem set 1, if you'd like to take a look back at that very quickly. Let's take a look at this. I'd like you to fill in a function, recursive vertex cover, that takes an input graph, which is a list of lists, and an assignment, which is a list of vertices that we cover and then builds the search tree from that. So what your code should do--first, it should check if it's still possible to construct a valid vertex cover. If not, you should return float inf, the Python expression for infinity. If the assignment is a valid vertex cover, then you return the size of that cover. Otherwise, I want you to find a vertex v that does not have an assignment. And, once again, I'd recommend checking out the naive algorithm you implemented in problem set 1 for a different NP problem that is very similar to this one. Alright, let's go ahead and take a look at this code. We start out by grabbing the length of the n by n matrix that we're interested in, and we store that in n. Then we said v equaled -1; this is the vertex that we're currently looking at. Now, for every element in the graph, every vertex in the graph, we check if the assignment is none. And if so, we set that to be the vertex that we are looking at right now. Then we check, for each of those vertices, whether there is an edge between that and any other vertices. If there is, then either the assignment for i or j, the vertex we're starting at and the vertex we're ending at, should be 1. If both are zero, then this isn't going to work, so we return float infinity. Now if we fall through checking every single element, and we don't get float infinity as a return value, then if v is still equal to -1, then we set the size equal to zero, and for every element in the assignment that is equal to 1, we increase the size of the vertex cover until we return the total size. All right, so let's see if we can refine that a little bit. We've already implemented from the last question a very naive vertex cover algorithm that will basically check every single possible cover. Now, let's improve that by instead of checking just one vertex v, let's check two vertices--u and v that are still not assigned. Now, if no two such vertices can be found, we simply output the size of the vertex cover implied by the current assignment. Now, there may still be vertices that are unassigned, but as we've discussed in the unit, there's a very straightforward way to tell if this should count as 1 or 0. If you're confused about this thing, I'd recommend going back and looking over the unit. What I'd like you to do then is simply add un right here and it starts off as just setting u=-1 and then add un to the logic here wherever you would then normally be just manipulating v. So you don't have to do a little bit of changing things around to check for other vertices that are still unassigned and that's going to be a little complicated but most of these should be relatively straightforward. So okay. Good luck and I hope you have fun with us. All right, so let's take a look at how I decide to do this. Like I said, you set up a second vertex called u and set it to equal to -1. In other words, it's not set to any actual vertex in the graph at first. So for every single element in the upper triangular portion of the adjacency matrix since we're presenting this as an adjacency matrix, we check if there is an edge between those two vertices between vertices I and J. And if there is, then we check if the assignment for I and J is zero that is they're not none anymore, we have specifically set them to not be in the assignment. Well, if both of them are explicitly out of the assignment and there's an edge between them well then that's not going to be a valid vertex cover, so we return float infinity. Now, otherwise, if we find that the assignment for both I and J is equal to none, then that means we haven't actually look at this yet, so it's a good candidate for setting v and u-- so that we set u equal i and v equal to j and we continue on. Now, once we go through the entire double for loop, we check if v is still on set. If v is still on set, that means first of all we didn't fall out of this by not having a valid vertex cover and second of all, it means that all the vertices have been assigned to something rather because that's the only way that v could still be set to -1 and if v is set to -1, then note that u also is. Now, if that's the case, then we set a variable size equal to zero and we start simply counting up all of the different vertices in the assignment. If the vertex is set in the assignment, then we increment size. It it's still unset, well then we have to do a little bit of manipulation here. We'll just set the vertex i to 1 if a neighbor is zero because we want to make sure that this is still a valid vertex cover. So, for every j in range i--well, I just realized I put an i in here. Well, then there are unnecessary just a slight inefficiency, you can boost this to i+1 since we don't allow any loops in the graph. If we did, then we would have to simply use i but this doesn't really particularly matter for this. Moving on, so for every other vertex in the graph, we check if there is an edge between i and j again and if there is and if the assignment of j is zero, well then, we have to set i and we say that the size is an additional element because we now have to set i, and once we go through all this, we return the size and that's done. Now, for each of these for the recursive part that you don't have to worry about, we try all the different possible combinations that aren't zero-zeros since that would not be a valid vertex cover. We try 1, 0; 0, 1; and 1, 1. We compute the size for each of these and then we return the minimum of those and compute this whole thing recursively. So that was a little tricky. If you had trouble with that, totally understandable. This does give you a little bit of improvement in the total size of the search tree we end up searching through. Before, it was 2 to the end--Now, we got about 1.733 to the end. It might not seem like much but in practice, it can be helpful. So, okay. Let's go ahead and look a different problem now. For this problem, we're going to be implementing some pre-processing rules for SAT and we're going to be using the same format to represent SAT as in the problem set for Unit 2. So if you have any questions about that, go ahead and read through this part or go back and look at the problem set for Unit 2. Now, what you're going to be doing is writing a function that when given Boolean formula in the above format, we perform a few data reduction rules and I put the result in set of clauses. The goal for this is that we're going to give the actual SATs over a much, much smaller-- well, hopefully much smaller Boolean formula than it would ordinarily get and hopefully, we can improve the performance of SAT in that way. Now, the data reduction rules we're going to be performing are these four here. First, if any clause consist of a single variable, we're going to set that variable so that the clause is satisfied. So if the clause just consist of x2 for instance, then we'll set it to true, or is that the clause just consist of not-x2, we're going to set x2 to false, and that way, we know that x2 has to be that in order for the Boolean formula to be satisfied. The second one is that if a variable appears just once and it hasn't been set, then we set it so that the respective clause is satisfied. The third rule is that we remove all clauses that have become satisfied. In that way, we just don't have to worry about them anymore in the upcoming SAT solver. The fourth final rule is that we remove all variables that evaluate to false-- so all variables x that are set to false and all variables not x where x is set to true for instance that we know are set in that manner. Now, if this results in an empty clause, then well that means that the input formula doesn't have any satisfying assignment for that variable, which means that the Boolean formula itself isn't satisfiable. So then the function should return the Boolean formula 1, -1, and that is so that when we give it to a SAT solver, it will always result as unsatisfiable. Now, the difficult part is implementing rule 2 and rule 4--that's because your function must perform these data reduction rules excessively until they can't be applied any further. So after you applied these rules, there might be other clauses for which these rules now apply that they didn't apply to it before. Now, you have to be careful if a variable that now appears once has already been set earlier. If not, then rule 2 may apply, otherwise, it doesn't. Now, remember that during the course of this pre-processing, we can't change the satisfiability of the overall formula or else the pre-processing rules aren't really helpful at all. If a SAT problem is satisfiable, the output of pre-processing also needs to be satisfiable. So go ahead and implement this function in the space given. Let's take a look at the code. Now the first thing we do is we set a variable called rules affable to be true. And this is so that we know when we can continue applying to the given rules and that way we know when we can simply be done with the function. We also get a temporary assignment to all of the variables of none since we haven't assigned that neither true or false values yet. Now in this loop, well, we can still apply rules. We first set rules affable to false and let's say that unless we come into a situation where we might be able to apply the rules again, we just assume that this is the last time we'll be able to do this. We first deal with single occurrence variables, so we set a counter to be zero for each of the variables here and we'll also set the variable setting to none for each of the variables. And then, for each of the clauses and each variable in each clause, we set the absolute value of the variable and then we increment variable counter of that variable by 1 since we've seen that variable now and we set this variable to 1 if it does greater than 0 or 0, otherwise. Or we set it to 1 is 0 to represent true or false if it is positive or negative. Now, we enumerate all of the variable counters with i and var, and if var is not equal to 1 then we go ahead and just continue. And if our temporary assignment is not none, that is it's already going to assign to something, we also continue, otherwise, we fall through and we set the contemporary assignment to the current setting available. In here, we try to deal with single variable clauses. Now, for each clause in the list of clauses, we first check that the length of the clause is not zero. If the length of the clause is greater than 1, we go ahead and just continue to do it. We don't need to check any further; otherwise, we set the variable equal to the only element in the list in the clause and we set a var to the absolute value of that variable. Now if the temporary assignment of avar is not none, if it's already assigned something, then if the temporary assignment of avar is not equal to 1, if the variable is greater than 0 else 0, then we return 1, -1 and this is because that means that the variable cannot be satisfied. This clause and that cannot be satisfied, and if not, then we go ahead and fall through and we set the temporary assignment of this variable to 1 if the variable is greater than 0 and else 0. Now, we need to go ahead and clean up all of these clauses. In order to do this, we are going to accumulate all of the current clauses into a new list of clauses, so that we can remove the ones that we don't need to worry about anymore. And we enumerate all the current clauses and we also enumerate all the variables in each clause and we set the assignment equal to the temporary assignment for each of these variables. If the assignment is none, then we go ahead and append that variable to the new clause because it's still haven't determined what it should be, otherwise, we said that, well, we might be able to continue applying rules here because we're about to remove some clauses. Now, if the current variable is assigned true, 1 and the variable is greater than 0 or the assignment is false, 0 and the variable is less than 0, that is it's negated then we can go ahead and remove the entire clause. So we set this new clause equal to none and we continue on. Otherwise, well, then we just have to remove the variable and we pass through. Now, if clause could not be satisfied then if the new clause is the empty set then we go ahead and return 1, -1 to indicate they cannot be satisfied. Now if the clause instead is greater than 0 then we go ahead and append this clause to the new list of clauses and at the end of this double for loop, we set the current list of clauses to the new list of clauses and if we have set rules applicable to true, then we go ahead and loop that through until that is not true. At the end of all this, we go ahead and return the list of clauses and that's it. In the unit, we've been discussing fixed parameter tractable problems and there are a lot of new things about these. First, the exponential part of the running time is restricted to the parameter k rather than the parameter n, and at least in many cases k is much less than n. Another new thing is that they provably allow for some very effective pre-processing rules and the details of some of these are a little bit out of scope for this course, but we can get a bit of a taste for them by working at vertex cover and noticing a few key insights. Now, let's say we have a graph G and suppose it has n vertices along with parameter k, now what I'd like to know is does she have a vertex cover of size at most k. So in other words, we were discussing the decision variant of the vertex cover problem. Another way of saying this is that at most a certain number of vertices are needed to cover all the edges and this could be either k-1, k, 2k, k+n, or n. Another fact that this question or the answer to this question will imply is that if any vertex is an endpoint to a certain number of edges or more, then it must be in the cover, and this could be either k-1, k, k+1, 2k, or k² edges. So for both of these questions, please check whichever on is most appropriate. The original question was--does she have a vertex cover of size at most k and this first part is a different way of saying exactly that. So at most, k vertices are needed to cover all the edges. However, what this implies is that if there's any vertex does an endpoint to k+1 edges or more, then it must be in the cover because otherwise we would require more than k vertices to cover all the edges, which is not the same as the original question that we are asking. Let's build off this a little bit. Let's do that by taking all of these vertices that have k+1 edges or more and actually putting them in the cover and that's because we already said it has to be in the cover. Now, what we can do is actually remove these vertices from the graph and any edges connected to them because those edges are automatically covered so we don't have to worry about them anymore. We automatically are dealing with a much smaller graph or potentially much smaller graph. What this tells us is that after removing these vertices, each remaining vertex can cover at most a certain number of edges if it's put in a cover, and this could either be-- k-1, k, k+1, 2k, or k² edges. What this would then mean is that the remaining graph can't have no more than a certain number of edges if G is a "Yes" instance of the vertex cover decision problem, which is the original assumption that we made, and this can either be k-1, k, k+1, 2k, or k². So please check whichever is appropriate for both of these questions. So the answer to this first question is k and that's because--well, we've already gotten rid of any vertices that have k+1 edges or more, so all the remaining vertices can have at most k edges connected to them. Now, to answer this final problem, we have to remember that we said earlier that at most k vertices are needed to cover the entire graph. Well, if there are k vertices necessary to cover the graph and each vertex has at most k edges attached to it, then the remaining graph can have no more than k² edges since we have to cover all of them. Now, this might have seem that we were involved, but there's actually something powerful here. What this means is that after doing all of these little pre-processing steps, then we either know that the graph G is not a "Yes" instance of the vertex cover decision problem-- in other words, it's a "No" instance or we know that the size of the resulting graph is bounded not as a function of n, which it was originally, but rather as a function of k, and remember what we said earlier that very often k is far less than n. So this is potentially a very big win for us. Welcome to problem set five. Let's talk a bit about approximating vertex cover. Suppose someone comes up to you and tells you that they devised a really really clever algorithm for approximating vertex cover. Let's call it clever<u>vc.</u> Now, this is so clever that they don't actually want to show you the source code. They want to keep it secret so you can't see that, and they don't even return the list of vertices that are in the cover. They just tell you the size of the cover. So, how would you go about figuring out the performance of this and how it works? In order to test the performance of clever<u>vc,</u> how about we test it against four fairly large graphs of 10,000; 20,000; 30,000; and 40,000 vertices, and let's compare that against factor-2 approximation algorithm that we have. See what the sizes that both come up with are. So, you can see that the sizes of minimum vertex cover for clever<u>vc</u> is always smaller than factor-2 approximation, sometimes, not very much. For example in this run, 233 versus 234, not much of a difference. In other cases, it's a rather large difference like 295 versus 600 in the 30,000 verticy graph. Now, based on this table, there are number of things that we can say about clever-vc. And these are the questions that I would like you to answer for me, the statements that we can definitely say about clever<u>vc,</u> and if you need to refer back to the table, then we'll have that below in the instruction comments. Can we say that given any graph, clever<u>vc will outperform the 2-approximation algorithm</u> since in the graph that we gave it, it most certainly did outperform the 2-approximation algorithm? Now, can we also say that clever<u>vc is a factor-1.75 approximation algorithm</u> or finally could we actually say that clever-vc is not a correct algorithm? And check true or false for all three of these. Let's go through these one at a time; now, given any graph, can we say that clever<u>vc will outperform our factor-2 approximation algorithm, and this is actually false.</u> Well, it seems like it outperformed our factor-2 approximation algorithm in each case we tested it. In order to actually verify that it will outperform our other algorithm, will he either have to test it against every possible graph, which is somewhat impossible or we would have to give a mathematical proof that clever<u>vc will outperform</u> our factor-2 approximation algorithm in every circumstance, and since we haven't done that, we can't actually say that this is true. We also can't say with certainty that clever<u>vc is a factor 1.75 approximation algorithm,</u> and that's because well we can't see the source code at all. If we can't see the code, then we can run test and be more and more certain whether or not it's a factor 1.75 approximation algorithm, but we cannot be certain so we can't say that this is true. However, we can say with certainty that clever<u>vc is not a correct algorithm and why is that.</u> Let's look back at our table here; now, the key thing to notice here is that the algorithm were comparing clever<u>vc against is a factor-2 approximation algorithm.</u> That means that each of these numbers, each of these minimum vertex cover sizes, is at most twice the actual minimum vertex cover. So, let's think about what that means. That means that the minimum vertex cover for 10,000 vertices graph is actually at least 284, let's go ahead and round up here. Similarly, the minimum vertex cover for the 20,000 vertices graph must be at least 117. For the 30,000 vertices graph, the minimum vertex cover has to be at least 300, and this is the key right here. So, the absolute minimum vertex cover of this graph has to be at least 300 but clever<u>vc is saying it found one that is only 295.</u> So, that means that this is wrong. This cannot possibly be if this is a factor-2 approximation algorithm. So, either this isn't actually a factor-2 approximation algorithm, and let's say that we verify that it is, or this is not a correct algorithm for finding the minimum vertex cover. In the unit, we talked about a greedy approximation algorithm for vertex cover. Let's review that very quickly. So if we were to implement this algorithm in a function called greedy<u>vc,</u> the first thing we would do is go to loop that checks that not all edges are already covered. Within that loop, we're going to first choose a vertex that has the most uncovered edges and then we're going to put that vertex into the cover. Now, another step, you might choose a different vertex for this-- depending on how you traverse the graph. If you have multiple vertices that all have an equal number but the maximum of uncovered edges in the graph. So your order with this might vary. So I'd like you to implement this entire algorithm in the function greedy<u>vc,</u> where you get an adjacent c matrix as the input. Now, as output, I'd like you to return first the size of the vertex cover and then a list containing all of the vertices that are in the cover. And again, we're not going to worry about order here because you might get a different order than what we get and we'll check for that. Let's walk through this code--so, first we set n is equal to the length of the n by an adjacency matrix that we took as input and we set assignment to be n(none), so a list of n(none) and we initialize the cover to be the empty list since we haven't actually set a cover yet, and we set valid off as false so that we can start this wild loop going While valid is false, we first check to find the vertex with the most uncovered edges So, we start with the first vertex and set candidate index to zero and the number of uncovered neighbors that it has to zero. Now, for every vertex in the graph, we check if it has already been assigned. And if so, then already covers all adjacent edges. If not, then we first set the sum of uncovered edges to be zero and then again for every vertex in the graph, we check if there is an edge between the two vertices represented by I and J and if J has been assigned. If it hasn't been assigned, then we increment the sum of the uncovered edges since there is now an edge that is not covered by either I or J, and we loop through all of the other vertices to check if there is an edge between I and J. Now, if the sum of the uncovered edges that we just counted up is greater than the maximum uncovered neighbors then we have a new candidate index for which vertex we should next add to the cover and then we set the max uncovered neighbors to be sum uncovered, which we just calculated and then we keep looping through this for every vertex until we find the max uncovered So, we figured out which vertex we should next add to the cover. Now, if we didn't find any uncovered neighbors, if max uncovered neighbors is zero then we see that this is valid vertex cover. We set valid to true and that means we'll fall out of this wild loop and continue on, otherwise, we append this index to the current cover and we set the assignment of this vertex to be one and then we continue on finding the vertex with the next smallest number of uncovered adjacent edges. Once, we eventually fall through that is once we eventually hit valid equal true here and fall out of this wild loop, we go down here and calculate the size of the cover and return So, size equal zero and then for every vertex in the graph, we check if it is currently in the assignment. And if so, we increment size and then we return size uncover. So how about we try modifying the greedy vertex cover algorithm. Remember, the greedy approximation algorithm is that while not edges are covered, we choose a vertex has the most uncovered edges and we put that vertex into the vertex cover. So we're going to modify this by also picking up random edge each time we go through this loop and picking one of that edges endpoints at random and adding that endpoint to the vertex cover. Now, what I'd like to know is does this algorithm perform as well as a factor 2 approximation algorithm or maybe does it perform even better. Now, I'd like you to do is go to the forums and provide a proof that does, or if it doesn't, then provide a counter example--provide a graph that it doesn't perform as well as the factor 2 approximation algorithm on. So it could be either one, and I'd really like all of you to discuss this and see what it proves or counter examples you come up with. So when you've done that, go ahead and post to the forums and then check this box. Let's consider the following graph and suppose we want to find a shortest tour for this graph, and in order to help with that, we first find the minimum spanning tree for the graph. So let's mark the edges that are part of the minimum spanning tree in purple here like so. So, if you are to take a tour along this minimum spanning tree, let's say starting at A, we might do something like this starting at A then through D and G and back to D through E through H back to E, B, C, F, and then all the way back along the route, back up to A. So, maybe you can see that there are some redundancies in this tour, for example, we go to D back down to G and then back up to D. So, instead of going along this tree route, let's optimize a bit, but instead of always following the minimum spanning tree, let's compute this tree route first, but then, instead of following it, we look at the next vertex in the tree route that we haven't gone to yet and we take the shortest path there. So, for example, we would start out at A and then the next vertex along the path is D, so we go there, and then G, so we go there, but then the next vertex that we haven't visited yet along the tree path is E not D and we can go there just by short circuiting here. So we cut D out and go straight to E and then we'd go to H, and again, the next unvisited vertex along the tree path is B not E, but there's no shorter path in this from H to B, so we would still follow it in this case. Then C and F would still be unvisited, so we would follow them exactly, but then the next unvisited vertex, well, is all the way back at A since we'd just say that the first vertex is unvisited. Well then, what we really want is the shortest path from F to A not necessarily along the tree route and you can see that shortest path is actually along up here. So, instead of following this tree path, we have a slightly shorter tour that sticks close to the tree path but it doesn't necessarily follow it exactly. Now, my questions then are what percentage improvement do we get in this tour versus the original tree path? And second, what approximation factor do we achieve in this specific instance? Now remember, in order to figure out the approximation factor, you'll need to calculate the optimal tour length for this graph. Please input your answers in the two boxes. All right, let's take a look at these--now, in order to figure out the percentage of improvement for this first question, we need to figure out the actual cost for each of these tours. So if we look at the improved shorter tour, the cost is 20 when we add all these up, and similarly for the true path, the cost is 24. Now, in order to find the percentage of improvement what we need to do is take 1 and subtract this fraction here. What we get then is right about 16.67%. Now, for the second question--to find the approximation factor, we need to find the optimal tour and it turns out that the optimal tour starting from A just goes way along the outside here and if you add these up, you get 15. And the cost of the improved tour that we were using is 20. If we want to find the approximation factor, simply see that this is four thirds, which is approximately 1.33. Welcome to problem set 6. Let's take a look at the shortest tour problem. Now let's say we wanted to use a randomized algorithm to solve the shortest tour problem, and how about we run it on an N-vertex graph. Say we decided to run our randomized algorithm a thousand times and we got the following results. We got a tour length between a 1056 and 1537. Along with that, we got the number of times each of those results were found. Now we also have a known factor to approximation algorithm, and we found an approximation of 1236 with this. Now what I'd like to know is given the above information, and we will copy that information in the instructor comments below so that you can look at it during the quiz, which of these statements are true? Does the shortest tour for the input graph have to have a length of 1056? Is the random algorithm likely a factor 3 approximation algorithm? Have we found a tour that is at most 1.71 times as long as the optimal one? Or similarly, have we found one that is at most 1.43 times as long as the optimal one? Check whichever of these you think are true. So this first one is actually false. We don't know that the shortest tour for the input graph has length 1056. That's the smallest one that we happen to have found, but if we ran the algorithm numerous more times, then we might find a smaller one, and the only thing we know for certain is that the minimal vertex cover is at least 618 because of our factor 2 approximation. We also don't know that the random algorithm is likely a factor 3 approximation, again because we would need to run it many, many more times to really be certain of that. Now we have found a tour that is at most 1.71 times as long as the optimal one because we found a tour of length 1056, and we know that the optimal one is at least 618, which is 1.71. Now we have not found a tour that is at most 1.43 times as long as the optimal one, and if we plug that into our previous equation and we solve it for X, then we would get X equals 1.43 times 618, which is about 883, which we didn't find a tour of 883. So that is not true. Say we wanted to develop a randomized algorithm for the vertex cover problem, and let's go ahead and start off by looking at our 2-approximation to the vertex cover problem. And if you remember from before, the basic algorithm for this was while we still have edges that are uncovered, we take an uncovered edge and then we add both endpoints to the cover. Now we're going to change this around by choosing randomly here, that is we choose a random uncovered edge, and we're also going to choose the endpoint that we add to the cover at random. So instead of adding both, we add one or the other at random, and that's how we develop a randomized algorithm based on this 2-approximation vertex cover. Now if we run this on an N-vertex graph, which we know has a unique minimum vertex cover of size K. My question then is how long does the randomized algorithm run in the worst case? Is the algorithm guaranteed to finish after K iterations, 2K iterations, or N-1 iterations? And check whichever the 3 you think is most correct. The answer to this is actually N-1. So in the worst case, it still has to look through N-1 iterations, which is not really any better than any of our other algorithms. And let's take a look at an example of why that is. So let's say we have this star-shaped graph, and we can see that there is a single vertex cover that is better than any of the others. That is you pick this vertex in the middle, and that automatically covers every single edge, and no other possible vertex cover is going to be as good. So with our randomized algorithm, let's say that we pick an edge at random. Let's say we pick this one, and then we have to pick one of the two endpoints randomly. Now let's say we pick this one and add it to the cover. Well then we've only covered this edge, and then we start over and reiterate. And let's say we pick edges at random, and each time we pick the outer vertex. It's unlikely, but it can happen. Now if we do that, then we've had to go through N-1 iterations to get a cover, and we are going to get a not great cover either. Now if we do this, you can see that we've had to go through N-1 iterations to find this cover, and it has a remotely close to the K equal 1 cover that is actually optimal in this case. Let's take a look at a few questions about complexity classes. Now I'd like you to look at these 3 statements and check which ones you think are true and leave unchecked the ones you think are false. The first one is from a computational perspective, NP-complete problems are the hardest ones out there. Second one is P=NP would imply that all NP-complete problems are solvable in practice. And finally, all NP-complete problems are solvable in polynomial time on a nondeterministic RAM. Check whichever ones you think are true. So the first one, from a computational perspective, NP-complete problems are the hardest ones out there. This is actually false. There are much harder problems. For example, problems that are in the complexity class P space, or exponential space, or any number of other complexity classes. The second one is also false. P=NP would not imply that all NP-complete problems are solvable in practice. We might still have huge polynomials. For instance, we might have a polynomial that is n to some very, very large number, and in practice this is still not going to be solvable. P=NP isn't necessarily going to imply that we can solve these problems in practice. The third statement is true. All NP-complete problems are solvable in polynomial time on a nondeterministic RAM. That's more or less the definition of what it means for a problem to be an NP. Let's look through a few more of these problems on complexity classes. Again I would like you to check whichever ones you think are true and leave unchecked the ones you think are false. The first one, all problems solvable in exponential time by a deterministic RAM take polynomial time on a nondeterministic RAM. Number 2, it is likely that randomization algorithms can solve some NP-complete problems in expected polynomial time. And finally, if P≠NP, some NP-complete problems do not have constant-factor approximation algorithms that run in polynomial time. The first statement is false. All problems solvable in exponential time by a deterministic RAM take polynomial time on a nondeterministic RAM. This is not true. There are problems that would still take exponential time on both a deterministric RAM and a nondeterministric RAM. For example, if you wanted to find every sublist of a list. This is going to exponential time even on a nondeterministic RAM. The second statement is also false, because if randomized algorithms could solve some NP-complete problems, let's say vertex cover, in expected polynomial time, well by the definition of NP-completeness then we could reduce any other NP-complete problem to vertex cover and then solve that in expected polynomial time. There's no evidence that this is actually the case. The final statement is true. If P≠NP, then there are some NP-complete problems that don't have constant-factor approximation algorithms that can run in polynomial time. The reason for this is actually the converse. We know that if we can find a constant-factor approximation algorithm that runs in polynomial time for any NP-complete problem, then that implies that P=NP. Alright welcome to the last problem set. Let's go ahead and dive in with a question about decidability. Given a program on a RAM and an input to that program, which of the below are decidable? The RAM runs at least 1,000,000 steps before terminating. The RAM runs at least 1,000,000 steps and will eventually terminate. Or the RAM runs at most 1,000,000 steps before terminating. Check all that are decidable. Alright the first one is definitely decidable. The RAM runs at least 1,000,000 steps before terminating. To do that you just run the program and count how many steps it takes. If it takes at least 1,000,000 steps then we know that it will take at least 1,000,000 steps before terminating. We don't actually need to know whether or not it terminates to answer this question, we just need to know that it runs at least 1,000,000 steps before that might happen. The RAM runs at least a million steps and will eventually terminate. That is not decidable. The reason for that is in order to answer this question we do need to know whether the program eventually terminates, unlike this first question. In order to answer that we need to answer the general question of whether a program will terminate, which we've discussed in the unit is actually undecidable in general. So this is not decidable. This final statement is decidable. It's decidable in much the same way that the first statement is. The RAM runs at most 1,000,000 steps before terminating. Well simply count the number of steps it takes and then answer the question. One argument you might make against undecidability and the importance of saying whether a problem is undecidable, is that every computer is actually finite. It has a finite amount of state. It can run for a finite length of time. Therefore we can determine whether a program halts or not simply by letting it run either until it terminates or it arrives at a state where it has already been. By state I mean the memory in the computer is exactly the same, and we are executing the same line of code as we were the previous time around. Because if both of those things are true we are going to loop back around again and have the same memory and line of code executing, and again, and again. Then we'll know if it will terminate or not. One of the problems with this is that today's computers have a whole lot of memory. So why don't we try it with something a little bit smaller? Let's try it with a smaller computer. A computer that only has a single kilobyte of total memory. This is a ridiculously small amount of memory for this day and age. It's really kind of a joke. You can't even fit the Udacity logo in this amount of memory. Now remember, a kilobyte is a 1,000 bytes, and a byte has 8 bits in it, which can each be set to either 0 or 1. Let's say that this computer can take 10 billion steps in a single second. What I'd like to know is if we did this, and we wanted to know if a program that we were running on this computer would terminate, how many years could it potentially take us to decide if our given program terminates? I'd like your answer in the exponent for 10 to the---however many numbers of years. If you'd like a little bit of a hint, the age of the universe is estimated at about 14 billion or 10 to the 10th years. Your answer should be substantially larger than that. Go ahead and enter the exponent in here. Let's look at a way we might try to calculate this. We need to know the number of possible states that this computer could go through in order to know whether or not we could get to a state we've already been to in a reasonable amount of time. How many states are there? Each bit can be in 1 of 2 states, either 1 or 0. There are 8 bits per byte, that's 2^8 states, per byte. We have a 1,024 bytes in our memory. We have a kilobyte of memory. That gives us 2^8^1,024 power, which is 10^2466. This is a huge number already. This is just the possible states in our memory. How many can we go through in a year? We take 10 billion steps per second. So 10 billion steps per second is 10^9 steps per second. Now how many seconds in a year? This is just multiplying by 60 seconds in a minute, times 60 minutes in an hour, times 24 hours in a day, times 365.25 days in a year. This equals 10^17.5 states that we can calculate in a year. That means that really what we want to do is take 10^2466 states and divide by this 1 year/10^17.5 states. This gives us 10^2448.5 years. This is an insanely huge number. This is for a computer that only has a kilobyte of total memory. The sheer number of states that we can be in, even in such a small memory and especially in a larger memory like you would see in a computer today, is just so massive that calculating decidability in this fashion isn't actually feasible. This is why we still really care whether our problem is undecidable theoretically or not. How about we take a look at a seemingly simple little puzzle. Let's say we have a list of string pairs. So a pair b, aabb, and a pair bba, abb, and so on, and we have some number of these pairs. My question is, can we select from these pairs so that the 1st strings form the same strings as the 2nd strings? Let me show you an example to let you know what I mean. Let's pick these pairs in the following order: The 3rd one, the 2nd one, the 4th one, the 2nd one again, the 3rd one again, and finally the 1st one. If we do that, and we can catenate the 1st string in the pair and can catenate the 2nd strings in the pair, then we get this string. If you look at these, then they are equal. Beit they're cut in different places. We take the 3rd one first, and we start with aabb and aa. Then we take the 2nd one, bba here, abb here, and so on. This problem, whether or not we can do this with a given set of strings, is called the post correspondance problem or PCP, after the logician Emil Post who first posed it. Here is the really mindblowing part. It turns out that any computer program can be stated as a PCP using just 7 pairs of strings. Now I'd like you to tell me what this means from the given list of statements. Does it mean that PCP is generally undecidable for 7 pairs of strings or more? Or does it mean PCP is generally decidable for 6 pairs of strings or less? Any SAT problem can be transformed into a PCP using 7 strings. And finally, no PCP instance with 7 pairs of strings or more is decidable. Check whichever statements you feel are true. This first statement is true. PCP is generally undecidable for 7 pairs of strings or more. To see that you only need 7 pairs of strings to specify any computer program, and that includes undecidable computer programs. If PCP was decidable for 7 pairs of strings or more, then you would be able to answer undecidable questions. The second statement is not true. PCP is not generally decidable for 6 pairs of strings or less. That's because we don't know if we can represent an undecidable computer program with less than 7 pairs of strings. We might well be able to. We can't say this for certain. This third statement is true. Any SAT problem can be transformed into a PCP using 7 strings. We might be able to transform it into a PCP using less than 7 strings, but if we can do that we can certainly use 7 strings and just not actually use them in our list of decisions. By that same reasoning, this last statement is not true. No PCP instance with 7 pairs of strings or more is decidable. That's actually not the case, because you can think of a decidable program with less than 7 strings or 7 pairs of strings, and then simply add in more strings that you don't end up using. This is perfectly acceptable. So this is not a true statement. Congratulations. This is really impressive. You've gotten all the way through the course. The only thing left is the final, and good luck on that. Now I'd like to ask you to challenge us to improve this course. We'd like your help with that. We'd like you to tell us how you think that we can improve this course, and what other topics in theoretical computer science you would like to learn about. We have a link to a survey that we'd really appreciate it if you took, down below the video in the instructor comments. Once you've taken this survey go ahead and check this box, and then good luck on the final. Once again I'd like to thank you for being a part of this course.