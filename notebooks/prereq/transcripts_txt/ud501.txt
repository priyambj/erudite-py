Hi there, I'm Tucker Balch. I'm a professor at Georgia Tech and I'm the instructor for this course. Hi, I'm Devpriya Dave, a graduate student at Georgia Tech. You can call me Dev. My original research was about machine learning for robotics, but in 2007 I became interested in using these same algorithms for investing. Since that time I've shifted my research and teaching towards finance. I also cofounded a financial technology company called Lucena Research. I'm a graduate student who's been working with Professor to built up predictive system for stock market. I'm also working on the software to support this course. You're going to see a lot of Dev in this course. She makes a lot of things happen behind the scenes. Now Dev, I'm thinking about buying Apple stock. Do you think I should do it? Mm, well, it depends on a lot of factors. What are the other stocks in your portfolio? What do you think will predict stock prices? Also, how much risk do you think you can take it on? So those are all good questions, and Dev is exactly right. We need to consider all of those things before we make an investment. Now in this course we're going to cover a lot of these issues. We're going to show you how information influences the movement of a stock price, how to build software to analyze and visualize these relationships, and details about how the stock exchanges work. Finally, in the last section of this course we're going to show you how to build machine learning algorithms that you can use to build real trading strategies. Now let's get started. Let's do it. The overall course is broken into three mini courses. The first one is Manipulating Financial Data in Python. In this first mini course, we show you how to read historical financial data into Python and manipulate it using powerful statistical algorithms. The second one is Computational Investing. In the second mini course, we show you the algorithms, methods and models used by hedge funds and investment banks to manipulate and work with financial data. And the last one is Learning Algorithms for Trading. In this last mini course, we pull everything together. We take what you learned in the first two mini courses, show you how to take that data and use it with machine learning algorithms like Q learning and random forests to build trading algorithms. Now, our goal is that after you complete this course you'll be equipped to join a trading system development team. Say a hedge fund or an investment bank. But I want to emphasize that you shouldn't immediately begin automatic trading. This course is just a starting point to teach you some of the things that you need to do that well. But, again, it's just a starting point. We will be using three different text books in this course. For the first mini course, we will be using Python for Finance by Hilpish. In the second mini course, we will be using a book I wrote with Philip Romero titled What Hedge Funds Really Do. It's a thin book, but it covers a lot of important material that I think you will enjoy. Finally, in the last mini course, we will be using Mitchell's Machine Learning. The good news is if you're taking the Machine Learning course, you'll already have that book. So you don't have to buy it again. I also wanted to mention that we're not going to cover all the material in these books, so you don't need to worry about being overwhelmed. [MUSIC] Hi, Dave. Hi, Professor. Now, you took this course recently, didn't you? Yes. Do you think you have to be a stock market whiz to pass this course? No, not really. I got interested in the finance only after I took your course. [LAUGH] The main prerequisite for this course, is that you should be a strong programmer. We have a lot of assignments and projects, and we move at a quick pace. We also use Python which may be new to some of you, so you should prepare for that challenge. [MUSIC] Oh, Professor, can I ask you what you are doing? This is my Monty Python impression. You know, the Ministry of Silly Walks. No. Hi I'm Tucker. And I'm Dev. Welcome to this mini course, Manipulating Financial Data in Python. Our goal is to give you a quick introduction to the skills you'll need to work with financial data in Python. Now, some people complain about our choice of Python for financial applications. I don't agree with those people. Python allows you to quickly prototype algorithms while also providing computational speed. It has a number of features. Firstly, it has strong scientific libraries. Second, it is strongly maintained. It is also fast if you can stick to metrics notation because lower levels are returned in C. Some other potential languages that might have made sense for this course include R and MATLAB. Which are themselves also great languages for financial data. But we've chosen Python and we'll be using this book Python for Finance in the course. Look for readings assigned in the course outline. Our objective in this class is to get you up and running quickly, to show you some real data, and some code you can use to view it and manipulate it. And just give you a feeling that you know what's going on. So we're going to take you from examples of raw data all the way to visualization. Now let's get started with the data. In this class we're going to work almost entirely with data that comes from CSV files. CSV files are plain text. The C stands for comma, S stands for separated, V is values. So comma-separated values. Let me show you an example of what might be in a CSV file. Most CVS files start with a header line. In this example, this is a CSV file that's telling us about weather conditions. So we've got temperature, pressure and humidity and that tells us what information is in the columns that are to follow. Following our header line we have lines or rows of data. So these numbers here make up our data. Again, header row and rows of data, where each data element is separated by a comma. Now the files that we're going to be working with, the stock data files, have thousands of lines and many more columns as well. Our objective for this lesson is to show you how to read in data like this, focus, say, on one column or another, and create a plot from that data. Okay, so now you've seen an example with weather. Let's start thinking about stocks. Which fields or items in a header row, would you expect to see in a comma separated value file of stock data? So here are the options. Number of employees for the company, date/time, company name, price of the stock, company's hometown. Good luck. The correct answers are date/time and price of the stock. Let me mention a couple of reasons why some of these others aren't correct answers. Sure, the company name is important to know, but it doesn't change over time, so there's no need to allocate space for this information every day over time. Company's home town, same thing. Number of employees can be important data and actually it's Information that is sometimes provided via proprietary data feeds, but it's not something you typically find in a historical data file of stock prices. Okay. So, let's take a look at some real stock data. We provide for you in this class hundreds of CSV files that represent the prices of stocks over time. Here's an example from one of those files that you provided. This is data from the file HCP.csv. So, here is our header row and here is the information that you'll find in one of these files. So, Date, which date is the information for? Open, this is the price that the stock opened at. In other words, in the morning, when trading on the exchange began, that was the first price of the day for that stock. High, throughout the day, what was the very high price, what was the very low price, and at which price did the stock close? So when we reached 4 o'clock, what was the final price? Volume, that's how many shares of the stock traded altogether on that day. And finally, this value, adjusted close, which is a little bit different from close. And this is something we cover in the next course where we talk about finance. I'll talk about it a little bit here, as well. But let me delay talking about it for a moment. Okay. I fleshed out this data a little bit. First thing I want you to notice is that the dates start with most recent dates, and then as you go forward into the file, you find older dates. So, what that means, more or less, is that we sort of go backwards through time in these files. Now, this is a feature, if you will, of data from Yahoo, and that's where we got our data for this class. Thanks very much, Yahoo. And this is just what a real one of those files look like. Now later when we read the data in, we managed to get it in the right order, and Dave will tell you a little bit more about that. Now, I had talked a little bit earlier about Adjusted Close and Close. Let me tell you a bit more about what that means. Now Close in this data is the actual price that was reported at the exchange when the stock closed for that day. Adjusted Close is a number that the data provider generates for us. And it's adjusted, as the name implies, for certain things like stocks, splits, and dividend payments. Now, on the current day, let's pretend for the moment that we're in 2012, adjusted close and close are always the same. However, as we go back in time, we eventually see that adjusted close and close differ. So if we go all the way back to the year 2000, we'll note that the actual price the stock closed at was $25, but this adjusted price was only $5.36. Now, what you can observe from that is as we go forward in time, if we had purchased this stock back in 2000 and held it to 2012, what are we looking at there? About eight or nine time return over those 12 years, so 800 to 900% return. If you looked only at just the actual price on the market, it's only a factor of about two, but this adjusted close reflects things like I said, like dividend payments, and splits, and so on. So that's what is in an actual stock CSV file. And this is the data that we're going to be working with throughout this course and the next two parts of the course. We're going to make heavy use of a library called Pandas. This library was created by Wes McKinney at a hedge fund call AQR. It's used at many hedge funds and by many people in the finance industry. One of the key components of Pandas is something called the dataframe. And I'm going to show you a little bit about what that looks like. So this is the basic layout of a dataframe. We have our symbols along the top, so our columns represent symbols in the stock market. Like, SPY which is an ETF representing the S&P 500, AAPL the symbol for Apple, GOOG for Google, GLD for Gold. And the rows are the dates over time, so we go back as far as 2000, then come all the way up to 2015. So again, symbols from left to right, one column for each symbol, and time coming down like this. So here's our dataframe fleshed out with a little bit of data. I made up some of these numbers, so it's not intended to be gospel truth, but notice how we have, let's say this is closing prices. So we see these numbers for SPY, Apple, Google, and GLD. Now, there are some special or unusual values here. NaN, that stands for not a number, and that's Python's way of saying hey, I don't know, I don't have information for this. The reason you see those values here is, back in 2000, Google did not exist as a publicly traded company, and neither did the ETF GLD. Now these NaN values can cause problems, and we'll be talking about those in a later session. Now as I said, this might represent closing prices, but Pandas can also handle additional data in a sort of three dimensional sense. So you can have a dataframe that represents, again in columns, our particular symbols, and in rows, dates. This one can be close, we can have another one that has, for the same stocks and the same dates, volume on those dates, and adjusted close, and so on. So Pandas is a very flexible way to read in, manipulate, and plot data. Now I've shown you, kind of at a high level, what this data looks like and what Pandas looks like. I'm going to hand it over to Dave now, and she's going to show you some real live examples with Pandas. She's going to show you how to read this data in, and plot it and so on. So here's over to you, Dave. Thank you, Professor. Hey, everyone, this is Davia. So here's an example of what the data looks like that Professor was talking about. This is basically a comma separated file, as you can see. And as you observe that the CSV is in the reverse order, but soon we will teach you how to fix that. Pandas provide a number of functions that makes it easy to read in data like the .csv file we just had a look at. Here's a code that reads in AAPL.csv into a data frame. So, first of all we will have to import the pandas library. To avoid writing pandas every time we use a functionality of it, we rename it as PD. So, this is the main function, which will call the test run function. Let's have a look what's there in it. Pd.read_csv, as the name suggests, will read AAPL.csv into a data frame, which we name it as df. As of now, imagine dataframe as a structure similar to the 2D arracy. That is, with rows and columns. Let's go ahead and print this. So here's the entire csv file on your console. As you can see, the entire data is loaded in your console, but just to have an idea of the .csv file, you can just print the top five rows of the data frame. This is how you do it. Data frame dot head. Dot head is the functionality provided by the pandas for the data frame that would help you to view just the top five lines of the .csv. That will give you a rough idea of what the .csv actually contains. Let's go ahead and print this. So here it is. Just the top five lines of your data frame. You can observe that all the columns of the .csv can be viewed here. You will also observe there is a column that is not named and has values 0, 1, 2, 3. And this is not from the .csv. These are called index for the data frame, which help you to access rows. Similarly, you can view last five values using the df.tail. So now let's do some interesting stuff. What if I want to view rows from the DataFrame in between some random values and not the head and the tail? We can do something of this kind. If you want data from index, 10 to 20, just add this line. Let's see the output. Here it is. All the data between the index 10 and 20 are displayed. But you might also observe that if you want data between 10 and 20, you have to mention 10:21. Because 21 is not inclusive in the range. This operation is called slicing and it is a very important operation in Python pandas, which you will encounter in the future lesson. Now let's do some more processing on the data frame. We can start with finding the maximum closing value for each of the stock AAPL and IBM. So here's the code. The test_run function simply loops over two symbols, AAPL and IBM, and will print the maximum closing value of each of the stock. Let's call the function get_max_close along with the symbol. Here's the function that will compute the maximum closing value. Let's see what get_max_close function does. The first step would be to read in the csv into the data frame. The next step would be to get only the closing values from the entire data frame, which means we have to extract the column close. This is how you do it. df[, pass the parameter of the column name, that is, 'Close'. Make sure you include the inverted commas. The last step is to calculate the maximum value, and it is as simple as calling the .max() function over the extracted data. Let's go ahead and print this. Here is your output. The max close for the AAPL is 680.44 and the max close for the IBM is 209.5. Your task is to calculate the mean volume for each of the given symbols. You can start with extracting the volume column form the data frame and then finding the mean. I'll come back with the solution. Good luck. So here's the solution to find the mean volume for the given stroke. As I explained, the first step would be to extract the volume column from the data frame. The next step is to find the mean. It can be done by calling the mean function. Let's run this code. Here you go. The mean value for Apple, and the mean value for IBM. I hope you enjoyed the quiz. Now let's do some plotting. It's easy to plot data in the data frame. Here's how you plot Apple's adjusted close. First let's call a library that would help us to do this. We import a library name, matplotlib. Do not worry about the details. You will learn them eventually in the further lessons. But to plot the adjusting close, we first need the adjusting close data from the data frame. And, as you learned in the previous video, we can slice over the column using the square brackets. Plotting the adjusting close is as simple as calling a plot function. To show the plot on your screen, we need to add one more line and this plot.show. Now let's run this code. Here's your first graph. You can observe there is no x-axis label, no y-axis label, no header also the data is printed in reverse order since the CSV is in the reverse order. So the Apple prices are not moving down, they are just printed inversely. In the coming lessons, you will learn how to fix it. As of now, enjoy the power of the Python Pandas that can plot information using just one line of code. Get ready to plot some data by yourself. I'll be back with a quiz. So here's the question for you. Plot the high prices for the IBM. You can approach this problem by first getting the CSV data of the IBM followed by getting the high prices from the data frame and then plotting it. You can refer to the previous example. Good luck. Here's the solution. You can get the csv of the IBM by using IBM.csv. The next step was the get the high prices from the data frame. df[high] will do that for you. And finally, you go ahead and plot it. Let's see how the graph looks like. I hope you got a graph similar to this. An advice I would like to give you at this point is, you will get hold of Python easily if you experiment. Try different options and see what works and what does not. During the course you will realize why some things worked and why just some things failed. I'll sign off by showing you some pair of pandas. We are about to plot two columns simultaneously on one graph. That is close and adjusted close for the Apple stock. Don't worry about how to extract multiple columns from the data frame. But intuitively you use a double square brackets and pass the two column names, that is Close and Adj Close. We go ahead and plot this. Here's the graph. You can observe two lines. One is blue, which corresponds to Close; and one is green, which corresponds to Adj Close. Observe that we did not write code to print the legend, or give color to each of the graph lines. This is the pair of the Python pandas. The blue line corresponds to the close value, and the green line corresponds to the adjusted close values. You will learn in the further lesson why there is a difference. That's all for now, I'll see you in the next lesson. Happy coding. So far in this course we've been working with one stock at a time. Yes, professor. Dave, are you a juggler? No. Can you juggle lots of things at once? What? [Laughter] I can juggle two. Sorry, I can't do this. Allright. We're not jugglers. Okay, in this lesson, we're going to dive into how do we fill a dataframe with the data that we want. And we're also going to touch upon a couple issue that we had that were pointed out in the previous lesson. For instance, remember when we had that issue that the dates were actually in the reverse order when we loaded them in, we're going to fix that. We're going to fix a couple other things too. Okay, just to refresh your memory, here's the kind of stuff that goes in a dataframe, our columns are the particular symbols of stocks that we're interested in, and our rows are dates. So time, goes from the top of the dataframe down to the bottom, and symbols, from left to right. So in order to get to a dataframe like this, we've got a couple of problems to solve. And we're going to solve them in this lesson. So one of the first issues is we want to be able to read in particular date ranges. So if you remember from the last lesson, we just read all of it in. But what if we just want to read in a certain part of it, instead of from 1995 to 2012. What if we want, say, just 2010 to 2012? Well, we gotta figure out how to solve that. Something that's very special about Pandas, and one of the things that makes it very powerful, is that we can index the rows by dates. We don't have to just use a single number like zero for instance. We need to be able to read in multiple stocks, instead of just, say having one. We want to have SPY, IBM, Google, and Gold all at once. We need to be able to align dates. For instance, If GLD traded on particular days and SPY traded on particular days we want to make sure that those line up, so that for each row we have the correct information for each equity on that particular date. Finally, we need to undo that problem that we discovered in the last lesson. Namely that these dates and the files we read them from are in reverse order. So, we want to be sure that we have them in the right order when we're processing them. So, these are the tasks we're going to dig into in this lesson. Here's a quiz, and something important to think about. How many days were US stocks traded at the New York Stock Exchange in 2014? Here are three possible answers. The correct answer is 252. The reason is, you need to factor in weekends and holidays. And interestingly, the New York Stock Exchange has a set of holidays that occasionally differ from the US Government holidays. In almost all cases, almost every year, we've got 252 trading days and this number is going to come up a lot, as we continue to look at days and calculating statistics about stocks. Now here's how we're going to build that data frame. Alright we start by constructing an empty data frame that has all the dates we're potentially interested in. And Dave will show you the syntax for doing that later on in the lesson. We'll call this df1 for data frame 1 of course. Now, we want to load this data frame up with a column of data for SPY, for IBM, for Google and Gold, and I'm going to show you step by step how we do that. Okay, so we separately read in SPY. And again, Dave will show you how to do that. Now when we read SPY, we get all the potential dates and all the prices that go with that. And in this case, we're loading adjusted closed data. Note that there's many more dates here than there are here. And this is our target data frame that we loaded with the particular dates that we're interested in. One other thing to mention, that I didn't mention before, is these two days are weekend days. So you can go ahead and check your calendar, go back to 2010, and see if I'm right. Interesting thing, or just obvious thing about weekends, is the markets are not open on weekends. So if you compare this with this, look in our SPY history, we don't have the 23rd and the 24th because SPY did not trade that day. So, we've got a little bit of mismatch there that we need to deal with. And this actually is one of the important reasons that we use SPY as a reference, because if SPY traded, it meant the market was open. And if the market was open, SPY traded. So, SPY, the S&P 500 ETF, is our reference for many, many things. So pandis has many very powerful features, among those features are the ability to do many operations that you may be familiar with from databases. In particular, one that we're going to leverage here is adjoin. So we're going to join this data from SPY and our empty data frame. And we're going to do a special join that says, look, we're only interested in dates that are present both in SPY and df1. And what happens is, we end up with this data. According to its date and this position in our target dataframe, and, of course, the other two rows as well. But note, because of the join, these two days were missing from SPY and the result of the join is they are eliminated from our dataframe. They're eliminated because it's the weekend. There was no trading, because we know that because SPY is our reference. All right, so here's our original data frame now after we've loaded an SPY. And those weekend days that were here are gone because of that join. Now we can add more columns from other stocks, here's one for instance, IBM, by performing additional joins. So after this join with data frame IBM, bump, we've got this new data over here in our empty data frame. We can repeat this process for each additional symbol that we want to add. So we'll add Google and GLD. And again, Dave will show you the syntax for doing that and pandis in just a few moments. Let's try to build the data frame professor outline. Starting with the things we need to populate the data frame with, r, firstly dates. We used pandas date range method which takes two parameters, that is start and end date. For this code, we will take a small date range that is from 22nd Jan 2010 to 26th Jan 2010. We then call the date range function as I mentioned before, passing two parameters, start date and the end date. Let's run this code to see what variable dates has in it. The output you see is not the list of strings, but the list of date time index objects. Now, what do you mean by date time index object? Let's extract the foremost element of this list. You can get the forced element of the list by writing dates[0] Let's go ahead and run this code. This is the first element of the list which a date/time index object. The trailing zero zeros for each object is the default time stamp. The index for a stock data only consists of dates. We can ignore the time stamps for now. Next we define an empty dataframe df1 with these dates as index. We use the parameter index to supply the dates. Note that without this parameter the dataframe will have an index of integers 0,1,2 as seen before. Let's print this now. So here's your DataFrame, DF1. It's an empty DataFrame with no columns. However, as we pass the index parameter, we have an index as dates. And you can see that it's a date time index object. Two major steps have now been completed. Continuing on, let's read the csv file for SPY. In dfSPY, a temporary DataFrame. The next step is the heart of building the final DataFrame. We combine the empty DataFrame, df1, with the temporary DataFrame, dfSPY. We use the join function of the DataFrame for this purpose. Let's do it. DataFrame.join does a left join by default. So if we write a.join b, it will read in all the rules from a, but only those rules from b whose index values are present in a's index. For the remaining rows, that is the index values, not present in b, pandas introduce nans. So in this case, all the rules from the df1 will be retained and we will get all the values for the prizes from dfSPY for the given range we defined above. So in our case, all the rules from the df1 will be retained and only those rules of dfSPY, which is present in df1, will be retained. This will give us all the prices for the stock SPY in the defined date range. Let's use join df1 one after the join step to make it clear. You should expect to see all the values of SPY for the given dates. Observe the output. We did not get any values from the dfSpy. What do you think? What could be the reason? Let's print dfSPY to investigate. Commenting out the join lines. So let's see what dfSPY has. We told pandas to join df1, and dfSPY. But dfSPY has an index of integers, which is not the same as the dates index that df1 uses. We fix this by informing the read_csv function, that the date column in the csv file should be used as index. We do this by using the index_col parameter. Make sure you give the correct column name. We also want the dates present in the DataFrame to be converted into date time index objects. This can be done by setting the value for the parse_dates parameter to True. Let's see if this works. Notice that the Date column is now being used as the index. There is no separate integer index on the left. Now let's see what the resulting join DataFrame looks like by uncommenting these lines. But before that, let's add some more parameters to the read_csv function. Note that we are interested in just two columns, which is the Date and the Adj Close. We can get rid of the other column, by using the usecols parameter of the read_csv. We pass a list of column name we are interested in, which are Date and Adj Close. Now let's see what's there in df1. You see now we have just the Adj Close for the SPY for a given date range. Also observe that weekend dates have NaN value. Before we go ahead, let's understand that csv NaN as string, so we need to tell the read_csv that NaN should be interpreted as not a number. This is how you indicate it. One last step. We just want the date, on which SPY traded, so we can add more stocks based on these dates. Let's drop the rows where SPY is NaN. For this, we use the dropna function. df1.dropna will drop all the rows which has NaN values for the SPY. Let's go ahead and print this. Now we have built a clean DataFrame filled with SPY data using a selected date range and keeping only the dates that SPY traded on. Note that we use two steps for combining the data frames. That is left joining the empty data frame with dfSPY, and then dropping the rows that SPY did not trade on. This can be done in a single step using the how argument when calling join. Can you figure out what the appropriate value of how should be? Type it in the box. We are essentially trying to do an inner join, that is, we only want to retain rules common to both dataframes. Note that this is not the default, hence, we have to mention it explicitly. So what is the default value? What effect does it have on the result? Find out using the documentation link provided in the instructor notes. So we want to read in more stocks into a combined dataframe. Start with the code we used to build our dataframe with the SPY data. Then define a list with the required stock symbols. Now we can write a for loop to read and join each stock into the dataframe just like SPY. So here's the for loop which takes each symbol in the symbols list and joins it to our main dataframe. Let's go ahead and print this. Oops. There is an error. Reading the error message carefully, we observe that index column Adj Close has an overlap. What is happening here is that, irrespective of the stock the column we are extracting each time is named Adj Close. So the join method is confused as to what to name it in the result. Column names must be unique. As professor described earlier, we would like each stock symbol as the corresponding column name or header. So we add these two lines. This renames the column Adj Close to the respective stock symbol. Now let's see the output. Here you go, everything is finally in place. You must have noticed how we are carrying out essentially the same operation in different places. Why not write some utility function that we can use going forward? I have implemented one function for you, symbol_to_path. It accepts a symbol name as a string and returns the path to the corresponding CSV file, assuming it is stored under data by default. For example, symbol_to_path IBM will return data/IBM.csv. Can you finish the implementation for get_data? It take a list of symbols and dates as index and is supposed to return a data frame with stock data for each symbol within the given date range. SPY is inserted into the list, if not already present, in order to solve as a reference. Note that you must ensure the column for SPY does not have any nulls. That is, the data frame should only contain dates when SPY actually traded in the given date range. Type in your code here. You can use test run to execute your code and submit to evaluate it against our test cases. Don't worry, there is no limit to how many times you can try. Good luck. As show in the previous demo, there are three main steps to implement inside the for loop. The first one is to read in the data from the symbol. Make sure you specify all the parameters. Also notice how I have used symbol_to_path function to get the path to the CSV file. The next step is to rename the adjacent close column to the symbol name. And the last step is to join this new data with the new data frame. Now, we have to take care of one important thing. That is, dropping off the lines from the SPY. Subset is equal to SPY will ensure that only those rows will be dropped where SPY is none. Also the statement ensures that SPY is used as a reference. And that we do not have any non-values in the SPY column. Let's run it. So here's the output, same as before. Okay, let's suppose we have a nice big beautiful pandas dataframe and this time read in a lot of data. We didn't just focus on a few days, we've got the data all the way from the beginning of 2010 to 2012 and we got data for SPY, IBM, Google and GLD. Now suppose we want to focus on just a subset of that data. In fact, we might call that a slice. For instance, what if we wanted to look at just the values for Google and GLD between these dates, February 13, 2010 through February 15, 2010, and we want to again just look at Google and GLD. Well there's very beautiful syntax in Pandas that allows you to do that. So we're going to be learning a lot more about this syntax in a later lesson. But this is sort of a preview of the very nice things you can do. To select these rows we do a simple statement that they will show you later to create a date time object. And we just put the start date colon end date. And if we just write df1[sd:ed] where this is start date and that's end date, then we end up With these three rows, but we want to be more selective. We want to focus on these three rows and these columns and we need to add one more piece of syntax that indicates these columns. So this statement will extract these rows and these columns, and leave you just with this sub-portion or slice of df1. So, if we were to execute the statement df2 equals df1, and then this additional syntax, we will end up with this little morsel of data right here in our new dataframe. Now there's lots of different ways you can slice the data, you don't have to take a group of pieces of data that are right next to each other. You can grab any different columns you want and any different rows you want. So you might build a new dataframe by taking GLD and IBM. And it'll just take those two columns and splat them into df2. So that's slicing. This is just a brief introduction. We're going to go into some deeper examples when we get to the lesson on numbpie. To do any kind of analysis on the data, we need significant amount of data. So let's read data for each stock for a period of one year, that is, the year 2010. You can do this by changing the stock and the end date as shown here. Let's see the data frame contains now. So this is your data frame which has stock prices for the symbol SPY, Google, IBM and gold for a year 2010. We briefly explained slicing in the last lesson. In this lesson we will learn how to do slicing using the data frame we just created. There are basically three ways we can slice the data frame. First, row slicing. As the name suggest, it will give us the required rows along with all the columns. This is useful when you want to compare moment of all the stocks over subset of time. This is how you do it in the code. We use the function .ix of the data frame and just mention the start and the end date in the square brackets. Here we extract the moment of all the stocks in the month of Jan. Note that the start and the end date should be in the chronological order. If you write the 31st Jan date before 1st Jan, the date frame will give you an empty data frame. Even if you remove the .ix function and just to print DF passing the dates in the chronological order, you will get the same result. However, .ix is considered to be more Pythonic and robust, so we follow that. Now let's run the code to see the stock prices for the month of January. You can observe that we get the data only for the January month but for all the symbols, this is known as row slicing. Second way of slicing is useful when you want to view prices of only one stock over the date range, in this case you can use column slicing. We want to project the prices of Google for the entire year of 2010. Here is how we do it. A square bracket along with the name of the column and do not forget the colon. To retrieve a single column we just pass a single label. To select multiple columns we pass a list of labels. Let's print this. And this is the output for multiple columns. The last way of slicing is to slice through both dimensions, that is rows and columns. The most robust way to do this is using the IX selector of the data frame. Let's go ahead and use it. If you need more than one column, you define them in a list like this, and date range are separated with a colon. Here you go, the stock prices for the symbol SPY and IBM over the date range 10th March to 15th March. One application of this way of slicing is to compare multiple stocks over a period of time. Panda support many ways of slicing a data frame to suit different needs. Find out more using the link in the instructor notes. Suppose you've got a data frame. It's pretty easy from the data frame to make a plot. In fact the syntax is as simple as this. Pandas will take this data and create a nice chart that looks about like this. It will give an individual color to each time series and give you a nice legend telling you which is which. Now one problem with viewing. Data like this is for instance, at this time, by the way, these numbers are made up. But it's often the case that stocks are priced at significantly different levels, so in this example, say, Google had a very high price and the other stocks had low prices, and it's hard to look at them sort of In a good way comparatively when they have these widely variant prices. So what we'd like to do instead is be able say to have them all start at one single point here, say that's 1.0. And then go out from there so we can compare them on an apples to apples comparison. So we'd like to end up with a chart that looks like this, where everything starts at 1.0, and we can compare them on an equal basis going forward. Okay, let's try a quick quiz. What is the best way to normalize price data so that all prices start at 1.0? So, here are two choices: a nested for loop or a one line expression. Good luck. Well, it was a little bit of a trick question because both of these will accomplish the same goal, namely normalizing everything according to the first row. This method uses two nested four loops to go through each date for each symbol and then make the division. This is the preferred method however, and that's because it's elegant, just a single line. We divide the entire data frame by its first row. The other reason that this is the way to do it is because it's much much faster. This ends up being executed in C at lower levels. Whereas this will be executed at the higher level, the higher interpreter levels of Pandas and Python Carly Fiorina rightly states that the goal is to turn data into information and information into insight. So let's better understand the data by improving our plots. We will need the matplotlib library for this purpose. Specifically we import the matplotlib.pyplot and rename it as plt for ease of use. First, let's define a trivial plot function. We define a plot data function which will essentially plot the contents of the data frame. We pass the data frame to it and use its plot function to plot all the data in it. Let's see the output. Remember, to see the graph, we have to call the show function from the matplotlib library. Observe that x axis has dates and y axis has prices for all the four stocks. The graph still looks incomplete. We need to add details like give a name or title to the graph, add x and y axis labels. We will give name to the graph by passing in parameter title. This should be customizable. And here we pass the value of the title to the parameter title of the dataframe. For x and y axis labels, we need a handler to the plot which the dataframe generates. The output of df.plot is such a handler. You can imagine it as an object. We name it ax for axis. Now we call set x label and set y label on this object to give the x and y axis some meaningful labels. The desired labels are passed as a parameter to the function set_xlabel and set_ylabel. Remember that set_xlabel and set_ylabel are the function of the object that we got from df.plot. You can also use the fontsize parameter in df.plot to make the graph more readable. Now let's see the modified plot. So here is your detailed plot with x label, y label, and a title. You now know how to read stock data, slice it, and plot it. The challenge for you now is to write the code to plot the values of SPY and IBM over the date range. Go ahead and write your code in this function. The clue to this is use slicing. To complete this, four slides using the notation you learned earlier. Once you get the desired data set, the next step is to plot by calling the plot and the score data function we defined earlier. Recollect that, plot_data takes the parameter, data frame and title. Let's see what we get now. Here's the plot showing the changes in the stock prices for SPY and IBM for the period of March. Let's analyze the graph that we had plotted for the four stocks. You see the four stocks are all multiple ranges. But we need to observe the movement of the stock. By movement I mean how much the stock went up or down as compared to the others. To do this, we need to normalize the prices of all the stock. We do this by dividing the values of each column. By day one. This will ensure that all the stocks will start with $1. Power of pandas and Python is that we can do this in one line. Let's add it. We define the function: normalize data and pass the data frame through it. First, we want all the values of the data frame. Hence, we just type the name of the data frame, which is df. Now we want to divide all the values of this data frame by the first row of eight. So we extract the first row using row slicing. This will give us the first row. Now we will just divide it. Let's see how the graph changes. Observe, all the stocks start with price one. And now you can see the changes that is the stock movement. That's it for now, I will be back soon with more coding. Until then, enjoy the power of the Python and happy coding. In this lesson, we're going to learn about the NumPy numerical library. NumPy is a Python library that acts as a wrapper around underlying C and Fortran code. Because of that, it's very, very fast. NumPy focuses on matrices which are called in the arrays. The syntax is very similar to MATLAB, so if you've used MATLAB before It'll look familiar to you. NumPy is one of the important reasons people use Python for financial research. Now, how does NumPy relate to Pandas? Well, I said just a moment ago that NumPy is a wrapper for numerical libraries, well it turns out that Pandas is a kind of wrapper for NumPy. So remember our traditional data frame here, with our columns being symbols and our rows being dates. This data frame is just a wrapper around this ndarray, access the columns with symbols and the rows by dates. But you can, in fact, just treat this inside part as an ndarray directly. If you use this syntax in Python, that pulls these values out and lets you access it directly and then ndarray. You don't really need to do that though, you can, if you like, treat a data frame just like a NumPy ndarray. And so we're going to assume in the rest of this lesson that we're just working with an ndarray. And like I said, you can use all of these mechanisms that we're going to show you with ndarrays and with data frames directly. What you get if you create something as a data frame, as we'll see in a lesson a little bit later, you get many, many, many more routines. And you can treat it, like I said, just like an ndarray but you get a vast new number of statistical functions and so on. Consider an nd array, nd1. I'm going to show you now how to access cells within that. Now, the notation, at first, might seem sort of familiar, but there's some new and different things that you probably haven't seen before. So the usual syntax is the name of your nd array, bracket, the row and the column. So again, these are our rows. So row indicates which row we're using. Column, which column. It's important to know that in NumPy, our columns and rows begin at 0. So this element is nd1[0,0]. It then continues of course, 1, 2, 3, 4 in the rows, and in the columns, 0, 1, 2, 3. Before I tell you, see if you can guess how to address this cell. The answer is that this cell is nd1 [3,2], 0, 1, 2, 3, 0, 1, 2. Now, this is probably the kind of stuff you've seen before. It turns out, though, that the NumPy is much more powerful and can do interesting and different kinds of slicing. What if, for instance, you wanted to address this sub portion of the nd array? How could you indicate that? NumPy uses a special symbol, the colon, to let you indicate ranges. So we can indicate this range in rows with 0:3, which indicates the zeroth to the, just before the third row. And in the columns, we've got 01:3. So this syntax indicates starting at the zeroth row to just before the third and the first column to just before the third. And in fact, captures this region. The key thing to remember here that's a little bit tricky is that this last value is one past the one that you actually want to include. So, for instance, this is column 3, but it's not included. Now, if we just use the colon by itself that indicates, for instance, if we place it in the rows position, that we want all of the rows. So you don't have to use the colon just to indicate a range. You can use it by itself for all of them. Now, look at this statement, see if you can figure out which part of this nd array it refers to before I show you. It is this region right here. So it's all the rows and column 3, 0, 1, 2, 3. So it's this section right here. NumPy includes some special syntax that lets you refer to the last row or column. So, for instance, the last row here, you can indicate with negative 1, second to last row would be negative 2. So if we wanted to refer to these 2 cells here, we would take advantage of this negative 1 syntax. So a negative 1 indicates that last row. And then to get these 2 columns, we would use 1:3. 0, 1, 2, and then we don't include the last 1 there. There is a bunch of new syntax. I hope that you find it exciting. This is really one of the most powerful aspects of Python and NumPy. And it really enables you to do some interesting things. Now, we've got a quiz to see if you can figure out how to use this new syntax yourself. Now we've shown you how to address slices of ND arrays. We're going to give you a little quiz to see if you can figure something out. Suppose we have these two ND arrays, nd1 and nd2. And we want to replace some of the values in nd1, with these values from nd2. Here are four alternatives, see which one you think makes the most sense. Of these four, this one is the right answer. Here's why. This is the only left-hand side that singles out these correct rows, starting at zero, and ending at one. And these correct columns, again starting at zero and ending at one. If you look at the right hand side, here is a little bit of new syntax that you hadn't seen before. We indicate the rows second from last by a -2. So that's what that -2 means. And a colon with nothing after it means go all the way to the end. So we've singled out these rows and this indicates these two columns. So that's why this one is the correct answer. Now, I'm going to hand it over to Dev, and she is going to show you how to do all these things directly in Python syntax. Here's to you Dev. You can access the underlining NumPy array within a Pandas data frame using the values property. But you can also create NumPy arrays from scratch. There are many ways to create an array. Let's start with creating a one dimensional array from known values. NumPy has an array function which can convert most array-like objects into an n d array. What do we mean by nd array is n-dimensional array. Let's see how this works for Python lists. To start with, we need to import the library numpy. And we rename it as np for the ease of use. Next, we simply call a function np.array and pass a list which has value [2,3,4]. Note that this function can take as input a list, a template, or other sequence. Check out the documentation for the array function and nd array type for more information. Now let's see the output. The output you see here is not a list but it is an array. Let's go ahead and create a 2D array. Now if you want to create a 2D array, we simply pass in a sequence of sequences to this function. Each tuple enclosed in round parenthesis serves as one row in the resulting array. We could also have passed a list of lists. This is called sequence of sequences. Let's go ahead and print it. Here is the output and as expected there are two rows and three columns. This function is mainly useful when you have a list of sequence of values, and you want to convert them into NumPy arrays. NumPy also offers several function to create empty arrays with initial values. For certain computations these help avoid growing arrays incrementally which can be an expensive operation. Let's start with creating an empty array. The empty function takes the shape of the array as input. The shape can be defined as a single integer, as we did over here, for creating a one dimensional array, or a sequence of integers denoting the size in each dimension. For a two dimensional array, a sequence of two integers is needed. That is the number of rows and the number of columns. For this example, we will create an empty array with five rows and four columns. Passing in a tuple with values 5 and 4. So here I pass a tuple with values 5 and 4. In case you need a three dimensional array, or any greater number of dimensions, you can just add another number to the sequence. This will give you a 3 dimensional array with a depth of 3, and each depth having 5 rows and 4 columns. For this lesson we will only work with two dimensional arrays. Now let's check the output. Hm, strange. The empty array is not actually empty. What happens is that when we call numpy.empty to create an array, the elements of the array read in whatever values were present in the corresponding memory location. These are effectively random values that depend on the state of the computer's memory. Also observe that by default the elements are the floating points. Next we create an array full of ones. Like the empty function, we pass in the number of rows and columns as a sequence. To create an array full of ones, you call the one function and pass the sequence, which has number of rows and number of columns. You can expect this time to have an array of 5 rows and 4 columns with all the values equal to 1. Let's go ahead and check this. Here it is. An array with 5 rows, 4 columns, and all the values of the array equal to 1. We notice that the default data type of all the values in the array is. Fortunately, you can change this when creating the array. What parameter do you need to add to this function to create an array of integers instead? Type the name of the parameter and the correct value in the corresponding boxes. Documentation for the array.ones function might be helpful. dtype is the parameter we passed to the function to specify the type of the value we want in each array location. Here we defined the values to be integers using NumPy data type np.int. Just as a matter of fact, NumPy supports a much greater variety of numerical types than Python. Let's run this. Here it is. The array now has integer values. And since we defined the array as ones, it has all the values as 1. Just like function np and ones, you can create an array full of zeroes using the zeroes function. All these functions accept the dtype parameter. Before moving forward, I would like to mention that we can also create n-dimensional array using the low-level NumPy function ndarray. But ones, zeroes and empty provide a more friendly interface for creating arrays. And are hence generally preferred. Refer to the documentation links and instructor notes for more information. Numpy also comes with bunch of handy functions to generate arrays filled with random values. These functions are defined in numpy's random module. The random function generates uniformly sampled floating point values between 0 and 1, with 0 inclusive and 1 exclusive. More formally, we can say that it generates values in the half open interval 0.0 and 1.0. Let's go ahead and print this. Here is the generated array with five rows and four columns. Note that we pass the array shape as a tupple. A slightly radiant of this function is rand which randomly accepts a sequence of numbers as arguments and straight of the tuple. It is otherwise equal valid. Observe that, we directly pass the values of the rows and columns through the function and did not define a tuple. Here it is the area with same shape as before five rows and four columns. Numpy provides this to achieve a greater compatibility with the more established math lab syntax. We highly recommend using a more consistent num pi function that explicitly accepts a shape tuple. Now both the function, rand and random, sample, uniformly, from the rain 0 and 1. What if you wanted a sample from a different distribution? To sample, or normal distribution, we can use the normal function. Recall the normal function from numpy dot random and pass the shape of the array required. Let's run this. The core produced a 2 into 3 array of random numbers with a standard normal distribution. That is 0 mean, and unit standard deviation. You can change the mean and the standard deviation as well. Let's see how to do that. We change the mean to 50 and standard deviation to 10. Now, let's see the output. Notice that the values are centered around 50. To generate integers, we can use the randint function in one of the several ways. Passing to values 0 and 10 will not divide randint to generate a single integer between the range 0 and 10. We can also specify randint how many integers we want between between 0 and 10 by specifying the size attribute and giving it a value. So, this statement will give us a 1d array of 5 integers between the range 0 and 10. Going forward with that, we can pass a tuple value to the attribute size, which will create a 2d array with all the values between the range 0 and 10. Now, let's see the output. These are the single random integers between the range 0 and 10. Next, we created a 1d array with five values. Note that, we mentioned the number of values needed in the one dimensional array with the parameter size. Passing a tuple to the size parameter gave us the 2d values. And also note that all the values of the array are between 0 and 10. Check out the random sampling routines on the numpy website for more distribution and usage radiations. Find the link in the instructor's notes. Any numpy array has a number of attributes that describes it. In addition to the elements it contains. One of the most useful one is shape. Essentially a tuple containing the number of rows and columns are height and width of the array. We have already seen how to specify this when creating arrays. The shape of the array A would be five rows and four columns. So this is your array. Now let's see how to access the shape of the given array by using the shape attribute. a.shape will give you the shape of the array. Let's run it. Array.shape will return you a tuple with the first value specifying the number of rows. And the second value specifying the number of columns. Next we will learn how to individually access number of rows or number of columns. a.shape[0] would return the number of rows and a.shape[1] would return the number of columns. Let's check the output. Here you will see that the number of rows are correctly extracted as five. And number of columns as 4. If you have more dimensions, you will have additional elements in the shape tuple. The number of dimensions in an array can be found by simply asking for the length of this tuple. a.shape will return a tuple and the length of that tuple would inform us what is the dimension of the array. It rightly tells us that the dimension of the defined array A is 2. Okay, how about total number of elements in an array? Yes for a 2D array, it will be the product of number of rows and columns. But if you had more dimension, this calculation could be a little complicated. Fortunately we can retrieve the number of elements directly using size attributes. a.size will give us the number of elements present in the array A. We can expect the output to be the product of the rows and the columns which is 5 into 4, which is 20. Let's check it. As we expected, the output is 20 which means there are 20 values in the array. Attributes like size and shape are very useful when you have to over array elements to perform some computation. You can also access the data type of each element using the D type attribute of the array. Let's check the data type of the values present in array A. In this case, our array elements are of the type float64. That is 64-bit floating point numbers. Next you will see how to perform various mathematical operations on np arrays. Let's use a random heading of integers. Let's create an array with shape five rows and four columns. Let's see the output. So here's an array with five rows, four columns, and all the values between the range 0 and 10. Note how we used seed, the random number generator with the constant, to get the same sequence of numbers every time. Let's run again and see if the output remains the same. You can see that we have the same values for the array. Summing all the elements in an array is as simple as calling the function sum on the array. Here is our array a, and we call the sum function on it. Let's check the output. This is our array and this is sum of all the elements present in the array, which comes out to be 79. We can also sum in a specific direction of the array. What I mean by direction is along rows or columns. NumPy gives this direction a special name. It is called access. Access is equal to zero, signifies rows, and access is equal to one indicates columns. Remember this terminology as you will use it frequently. Let's code to make things clear. Passing the parameter, axis, along with a specific value will give you the sum along that axis. To understand this, let's first see the output. To get the sum of each column, we pass the value to the axis attribute as zero. And to get the sum of the rows, we pass the value as one. To understand this imagine if you wanted to sum the values of each column, what would you iterate on? You would say something like, For each column, sum all the values of each row of that column. So you would essentially iterate over the rows. Hence we pass axis=0 to compute column sums and similarly axis=1 for row sums. Observe the output when we pass axis=0, we get four values. These are basically the sum of each columns. And when we passed axis=1. We get five values which are the sum of each row. Let's go ahead and try some basic operation like finding minimum, maximum, and mean of an array. So, if I want minimum along columns, I have to go through each row of each column, so axis equal to zero to get the minimum of each column. To get the maximum of each row, similarly we call a max function and pass access equal to one. Just calling a.mean, that is array dot mean, will give us the mean of the entire array. Of course we can get mean along each axis as we did for max and min. Observe the output. Minimum of the first column is one, which is shown over here. This value is essentially, minimum of the first column. This is of second, this is of third, and this is of fourth. Similarly, for maximum of the each row, you can observe that for the first row, the maximum is five, and it is shown here. The mean of all the elements is 3.95 which is calculated using the mean function. There are many more functions which you can experiment with. Check the documentation link in the instructor's notes. So far we have seen how to compute certain measures. How about finding the position of some element in an array? Can you implement this simple function to find the index of the maximum value in the one-dimensional array. Remember NumPy is your friend. To get the maximum value in a given 1D array, you could loop through the array, finding the maximum and keeping track of an index. But numpy can help you do this in a single call. You must have seen argmax and argmin used to described optimization equations. This is the same idea. Let's check the output. So the function returned us the maximum value, along with the index. Now for multidimensional arrays, finding and representing indices is a little tricky. But numpy provides some utility functions like underscore index to help you out. We claim that run.py is fast, very fast. So let's confirm this. But before that, we need to learn how to time a particular operation. We need to import a library for that. We import the time library to help us know how fast our operation is. We use the time function from the imported library. The idea is to capture the time snapshot before the operation, and then again capture the time snapshot after the operation is performed. We then subtract the two times. Simple, right? Let's check the code. Here we will check how much time a Python print statement takes. So we capture the time before the print statement and then record the time after the print operation is performed. Then, finally, subtract t2- t1. Let's run the code, now. Here, we get the time taken by a print statement. Oh, the number is really very small. Now when we know how to time an operation an operation in Python let's check how fast Num-Py is. Let's define a really large array so that the time taken for the operation will be significant to compare. So here is our large array of 1,000 rows and 10,000 columns. Before I go ahead, I would like to mention that this is just a demo code to show the speed of Num-Py. So, I will be giving a high level explanation of this code. Moving ahead, we will be comparing how to compute mean of the array using Num-Py and using standard iteration. Here is the manual mean function which computes the mean of the values in the defined area. We trade over each row, and for each row it trade over each column. We then sum present all the values throughout the array. Finally, we divide by the size of the array and hence we get the mean. In case of using Num-Py for calculating the mean, we just write array.mean to get the mean of the entire array. How long function will just compute the time each matter takes. Now, let's check what's the time difference. Do you see the difference? This is the time taken by the numpy.mean function to calculate the mean of the entire array. And remember the size of the array are in thousands. On the other hand, the time taken by the manual method is about 5 seconds. Hence proved, Num-Py is super fast. We also compute the rate of how fast the Num-Py is and the numbers are crazy. It's about 290 times faster than the manual for loops. Observe that Num-Py not only makes the code more cleaner as compared to the manual method, but there's about 290 times faster than other method. Don't you think it's just awesome? Accessing array elements is straightforward. You can access a particular element by referring to its row and column number inside the square brackets. The first integer over here denotes to the row number and the second integer denotes to the column number. Let's see which element do we get at position 3,2. Observe that the element we get actually belongs to the fourth row and the tall column, but note that the row and the column indexing start from zero. Hence if you want an element of the fourth row and tall column, you pass the parameter as we did, that is 3,2. Now let's do some interesting stuff, accessing elements and ranges. If I would want to access elements from first through third column in the zeroed row, here is how I would do it. This operation is called slicing, as explained before using data frame. Let's read out this slicing operation. For the 0 through, get values from first through third column excluding the third column. Now let's run this. So here's the output. For the 0 through, first through the third column excluding the third column. This was just column slicing. We can combine row and column slicing and get a subset of the array. If I would like to access the top left corner of the array, I would do this as follows. We can combine row and column slicing and get the subset of the array. Here is the top left corner, which has elements at position 0, 0, 0, 1, 1, 0, and 1, 1. One last interesting thing in slicing, which I would like to bring in front of you. You see a lot of numbers over here, so let's break it down and read it. The three number separated by the colon, this is not accessing the tall access. But a slicing of the form, n is to m is to t, will give you values in the range n before m, but in steps of size t, hence this statement will give you values of the column 0. Skip the values of the column one, and then give the values of the column 2. Let's run this. As explained, you get the 0, and the second column with all the rows. Seems like magic, right? Moving forward. It is good that we can access elements in a, but another important operation is assigning values to specific location in a. This will give us access to the element at the position 0, 0 in the a. Using the assignment operator, we can assign a value one to it. Let's see the output. Here you go. This is the original array where we replaced the element at 00 with 1, but that's not all, with the minor change you can assign a value to the entire row or column. Let's do it. This will give us access to the 0 true and we assign the entire row a value of 2. Let's run this. Using similar operation and column slicing, we can also assign an entire column a single values. Now what if we need each column or row to have different value and not the same as we did over here? Let's see how we can achieve this. Yes, this is a list of values. You can assign a list of values to a row or a column. Here we assign this list of values to column number three, but make sure you keep an eye on the dimension. That is, for this example, if you have five rows in an area the list should have five elements. As you can see, all the list values have been assigned to the third column. So now it's your turn. Go ahead and try more row and column slicing. There are various options of indexing. And that gives NumPy indexing great power. NumPy array can be indexed with other arrays. It is just one other tool which can be used to make process of accessing values in array easy. To start with, we create a one dimensional array of five random values. Next we create a variable indices which is also a one dimensional array. But the elements of this array, which is 1, 1, 2, 3, are actually the index we need to access. That is, we want the value at index 1, again at 1, 2, followed by 3. Next step we learn how to use this indices along with the edit to access the desired values. Yes, you saw that right. Just passing the area of indices to another area will give us the values. Let's check the output. So here is the output. Observe that the length of the indices array and the returned array is the same. Also it return value from array a at index 1,1,2,3. It is a bit difficult to understand the application of this now, but this is a tool you would like to use once you get hold of it. We can do such indexing using multidimensional array as well. But things get complicated with creating multi-dimensional index array. These are just a few interesting ways of indexing. There are a lot more out there for you to experiment with. Check the link in the instructor notes. Next we will be working with boolean arrays. In simple terms arrays with values true and false. This can also be used for indexing. Indexing using boolean arrays is very different as compared to index arrays, we learned previously. Imagine a situation where we want to get all the values from the array, which is less than mean of the entire array. The first step to solve this problem would be to calculate the mean. Consider a two dimensional array. As we learned before, we will calculate the mean using the mean attribute of the array a. Let's check what the mean is. According to our problem, we want all the values from the area which is less than mean. Mean is 14.2. You can imagine that the solution would contain values 10, 10 again, 5, 0, 0 again, 2, and so on and so forth. If you need all these values, one way is to run the for loop over the array, and get them. But using masking, we do this in one single line. To read this operation, it would be for each value in array A, compare it with the mean. If it is less, we retain the value. Let's check the output. Here is the values which we expected in the form of list. Now to go ahead with this concept, we can also replace these values with the mean value. We just assign the mean value to masking operation we performed before. Let's see the output. Observe that all the values previously less than mean have been replaced by the mean. This is one of the important operation that shows the power of the and justifies its extensive use throughout. Arithmetic operations on arrays are always applied element wise. Let's start with simple multiplication operation. Here we define a simple array so that we can easily track the changes. This will multiply each element by 2. Let's check the output. When using arithmetic operation, a new array is created and the values are stored in that array. So our original array a still holds the same values. And this is our new array which we get after multiplying array a by two. Observe that, it is element wise multiplication. Let's try division. Here we use the division operation to divide each element of array a by two. Let's check the output. Observe that, when you divide 1 by 2, you get a value 0 over here instead of 0.5. This is because both the array and the divisor are integers. If we were to do 2.0 instead of 2, you will get float values. Keep this point in mind before performing division in general. That is int divided by int will give you an integer output. To get float values, you need at least, the numerator or the denominator to be a float value. Let's check the output. Observe that, we could successfully get a floating point value instead of 0. How about arithmetic operation using two arrays? We will start with addition. We create another array b with these values. Now, let's just add a and b using the plus operator. As mentioned, this is element wise. This is our new arraya plus b. One important thing to note here is that the shape of a and b should be similar before the operation a plus b, else it will throw error. Similar to the addition, you can perform subtraction. Now, let's move ahead with multiplying two arrays. This is interesting, because unlike other many metrics languages multiplication operator when used with two array will not give you metric product, but will do element wise multiplication. That is, element at position 0,0 in array a is multiplied only with the element at position 0,0 in b. Let's print the multiplication of matrix a and b. Can you also element wise multiplication? But the next question would be, what about matrix multiplication? How do you achieve that? Like, for everything, Num Pi has a function. It has function called dot, which performs matrix multiplication. Similar to multiplication, division of two arrays can be performed. Just include division of operators between the two arrays. Let's check the output. As seen before, since array a and b are indigenous, we get the final array in the form of indigenous as well. If you want to see floating values, convert one of the arrays to float. Well, that's all for now. Keep practicing. All the operations and functions explained in this lesson are those which will help you perform computation. But there is a lot more to learn. Check out the link in the instructor notes. I will meet you in the next lesson with some more coding. Happy coding with Python and bye until then. Are you ready, Dave? Ready for what, Professor? We're going to start some serious number crunching now. What do you mean? In this lesson, we're going to unleash the power of Python. We're going to show folks some tools that enable them to calculate all kinds of important statistics on time series data. What are we waiting for? Let's go. In this lesson, we're going to take a look at the various kinds of statistics that we can take on time series data. Let's start first with global statistics. Consider our trusty data frame DF1 with columns for SPY, XOM, Google, and Gold. We can take the mean of each of these columns very simply with a statement like this. This statement will take the mean of each column and put it in the appropriate location of a new one-dimensional or row-wise of the array. Now because this is a data frame, and remember, a data frame augments NumPy and provides a lot more functionality. It's sort of in the array on steroids. Now we get lots and lots of functions we can access in this way. We already mentioned mean in addition to mean we've got median, standard deviation, sum, prod, mode. All together there's at least 33 global statistics you can compute in this way. And they're always adding more. Let me hand it over to Dave and she's going to show you how to do this in code. Let's do some coding to get an idea of what professor just explained. Starting with defining our symbols list, having symbols like SPY, XOM, GOOG, and GLD. We then move ahead to build our dataframe df just like we did in couple of lessons before. So df is our final dataframe. Now let's start computing statistics. First we compute mean. We need mean of stock prices for each symbol. And dataframe.mean will do this for us. As professor explained, it computes mean for each column. And our columns denote one stock each. So we get mean for all stocks in just one line of code. So to compute the mean, we just called the name of the data frame df.mean. Let's check the output. Note how Pandas prints the mean for each symbol properly labeled. Also, here's the graph with all the symbols and their data. Similarly, we can compute median and standard deviation. Let's do it. We compute the median of the data frame by calling the median function. Remember the difference between the mean and the median. Mean is the average of a set of values that is the total sum divided by number of values. Whereas median refers to the value in the middle when they are all sorted. Now let's try standard deviation. We compute the standard deviation by calling the function std over the data frame. Let's check the output. Mathematically, standard deviation is the square root of variance. But more intuitively, it is a measure of deviation from central value. Here, the central value is the mean. A higher standard of deviation like here for Google indicates that the stock prices has varied a lot over time. We're going to introduce a new kind of statistic now called rolling statistics, and as opposed to just taking the mean across the whole period of time we take sort of a snapshot over windows. I'll show you what that means in just a moment. Now on that last slide, we computed a global mean, which would be something about like this on this data. A rolling mean is a little bit different and here's how it works. Let's suppose we're going to take a 20 day rolling mean. We go, starting from here, 20 days, it's right about here. And then we take the mean of all that data behind us. We can draw a little box around that. This is called the window. In our case, it's 20 days. So we average all these values, and we get one mean, which is this point. We then move the window forward one day and we take another mean. Here's our next mean, which is a little bit higher. Now if we do that everyday over this entire year, so this is S and P 500 over the year 2012, we get something that looks about like this. You can see essentially, that it's a line that follows the day-to-day values of whatever it is we're tracking, but it lags a little bit. It's sort of a smoothed and lagged line. And this is called the rolling mean. We can compute statistics like this, just like the rolling mean. We could do standard deviation. We could do mode, median and so on. All of those statistics I showed you just a moment ago can also be used as rolling statistics. In the next mini course we are going to spend a lot of time talking about technical indicators, and this is actually one of them this rolling mean, it's called by technical analysts a simple moving average. And one thing they look at is places where the price crosses through the rolling average. So, in this case, the price is moving down through the 20 day mean. Now a hypothesis that I'm not saying I support, but a hypothesis that many who conduct technical analysis, is that this rolling mean may be a good representation of sort of the true underlying price of a stock, and that significant deviations from that, like this one here eventually result in a return to the mean. So if you can look for, say significant deviations like this one, you might find say a buying opportunity here. A challenge though, is to know when is that deviation significant enough that you should pay attention to it. Assume we're using a rolling mean, and we're tracking the price here in blue. And we're looking for an opportunity to find when the prices diverged significantly far from the rolling mean that it might be an opportunity for, say, a buy signal or a sell signal. How can we decide that we’re far enough away from the mean that we should consider something like that? So the question is, which statistic might we use to discover this? Here are a few options. Give it some thought, and check the box you think makes the most sense. The answer is rolling standard deviation, and we'll show you why in the next note. Returning to that question of how can we know if a deviation from the rolling mean is significant enough to warrant a trading signal, we need some way of measuring that. And John Bollinger, in the 1980s, came up with something he calls Bollinger bands. And whenever you mention that you have to put a little R there, because he has registered Bollinger bands as a trademark. If you don't do that, they'll come after you. [LAUGH] Anyhow, how might we measure that? What Bollinger observed was that we ought to take a look at the recent volatility of the stock. And if it's very volatile, we might discard movements above and below the mean. Whereas if it's not very volatile, a similarly sized movement maybe we should pay attention to. His idea then was to add a band 2 standard deviations above and 2 standard deviations below. Now I'm not going to make any comment as to how effective this method is. That's something for us to assess in the next mini course. But the theory anyways is that when you see excursions up to 2 sigma or 2 standard deviations away from the mean, you should pay attention. And in particular, if we drop below that and then up back through it, that is potentially right there a buy signal, because the hypothesis there is that we've gone quite far from the simple moving average. And we're now moving back towards it. So if you buy there, you should anticipate positive returns as it climbs back through the average. Similarly, here where you see it punch through the top and then go back down through, that's potentially a sell signal. And as you can see, in this particular case, if we had bought here and sold there, we would've done great. But if you look at many, many examples of this, it's not always so great. So don't run off and start trading, but just be aware that this is an example of a technical indicator, and how you might involve it in a trading strategy. Dave is now going to show you how to read in data like this, compute a rolling mean, and chart it. And once again, I want to repeat that I'm not necessarily endorsing technical analysis here, although I think it can be very powerful. Just introducing some of these concepts to you. And again, in our later mini course, we're going to talk a lot about these approaches. Okay, here's to you, Dave. For working with time series data, pandas provide a number of functions to compute moving statistics. We use rolling mean function to compute the rolling mean of the SPY. Note that rolling mean is not a DataFrame method but it is a function with the pandas library. So we wouldn't be able to call def.rollingmean. Instead we pass in a set of values for which rolling mean has to be calculated as the first parameter. Now let's go for this. Firstly, let's get SPY data in our data frame for the year 2012. We also go ahead and plot the SPY data. Notice that we retain the matplotlib axis object so that we can add to it later on. Next we call the rolling mean function from pandas library, and pass in two parameters. As explained before the first parameter would be the values for which the rolling mean has to be calculated. Hence we pass our data frame containing SPY values. The next parameter is the window size, for which the mean will be calculated. We use a period of 20 days. This will return a series consisting of the rolling mean. It is always good to visualize the rolling mean. So we plot the series using the plot function. This time, while plotting the rolling mean, we pass in the matplotlib access object so that it gets added to the existing plot. Notice that we specified a label is equal to rolling mean. This will be used to create a plot legend. Let's add the legend and some access labels to our plot. So here we add our legend to the upper left corner of the plot at the X label and the Y label. Finally we are all set to view the plot. Observe that the rolling mean has missing initial values. The reason is that we defined a window period of 20 days, so the first 20 days there are no values. Also notice how it follows the movement of the draw prices, and is also less spiky. It's quiz time. Professor explained to you how to get Bollinger Bands and now you get to try it yourself. Here's the data frame containing the stock prices for SPY for year 2012. Now computing Bollinger Bands consists of three main steps. First, compute rolling mean followed by computing rolling standard deviation. And then, finally, computing the values for the upper and the lower bands. We want you to implement one function for each step. You can call each function in this manner. Note that in this case, we use a window size of 20 for calculating rolling statistics. But we should be able to vary this. Finally, we plot the original prices, rolling mean, and the Bollinger Bands. Let me start you out with one of the functions. Here is how I would implement get_rolling_mean. Now go ahead and write code to compute the rolling standard deviation and calculate the upper and the lower Bollinger Bands. Wondering how to compute rolling standard deviation? Check out the trusty panels documentation for that. Now refer back to the previous video if you forgot how to calculate Bollinger Bands. Note how we calculated the rolling mean. The rolling standard deviation can be computed in a very similar way. Pandas provide a function called rolling_std to do this job. We simply pass in the values and the window size. Now, onto Bollinger bands. Recall that upper bound is two standard deviation above the rolling mean. Let's type this in our code. Here, we add 2 times the value of the rolling standard deviation to the rolling mean. Though the mean and the standard deviation values are in the form of CD's, the mathematics still works. It is similar to the arithmetic operation on numpy arrays, which is done element-wise. Next, let's calculate lower_band in a similar way. Here, I subtracted 2 times the rolling standard deviation values from the rolling mean. Note that will return the values for the two bands together. These are received back when the function is called. Let's see if a function computes Bollinger bands correctly. Looks good to me. Observe the selling and the buying points. You can play with the window size and see how the bands change. You could also try computing bands at different deviation away from the rolling mean. Now we're going to look at something called Daily Returns. Daily returns are one of the most important statistics used in financial analysis. So let's consider first here this time series, S&P 500 in 2012. What daily returns are is simply how much did the price go up or down on a particular day? So, for instance, on this day it went down a little. On the next day it went up a lot. Daily returns are calculated easily using a simple equation here. So the daily return for day t, let's say today, is simply today's stock price divided by yesterdays' stock price, minus one. Let me show you an example. Let's suppose on this particular day the price went from $100 yesterday to $110 today. The daily return then, for that day, is (110/100)- 1, or 1.1- 1 = .1, which is 10%. So that's how we calculate daily returns. Now one thing to remember is this is a kind of statement you might put in a for loop where you iterate over individual days. Don't do that. Use the NumPy syntax we showed you, where you can do this in a single statement with no for loops. Here's what a chart for daily returns might look like. Everything is scaled now from minus 10% to plus 10%. And what we see here is the daily return for each day. If it was a positive return, of course it's positive, and negative if it were negative. Remember the day when we calculated we had a positive return of 10% that corresponds to that point right here. And for instance, here on the next day we had negative daily return. That corresponds to that point right here. Key thing to remember here is this is a line that sort of zigs and zags, usually close to zero. And if you were to, say, take the mean of all these values because we've had a generally upward moving trend here, our mean would probably be a little bit positive, above zero. Where looking at daily returns can be really important and revealing is to compare daily returns between different stocks or different assets. So, for example we might compare how Exxon moves in comparison to S&P 500. As one example, if you take a look at this section here you can see that when S&P 500 went up, Exxon went down and that's revealed here in this section of the daily returns. We're going to spend a lot of time in some future lessons, looking at how these statistics, specifically how daily returns between different assets, can be revealing. Dave is going to show you now in Python, how to calculate these daily return values. Here's to you, Dave. Ta da! It's quiz time again. Can you write a function to compute daily return values? It should take a data frame as input. Apply the formula to calculate daily returns. Use proper slicing and indexing to avoid having to loop over each value. Note that the return data frame must contain the same column labels and the same number of rows as the given data frame. Which means if there are any missing or unknown values, replace them with zero. First we make a copy of the data frame, where we can save computed values. Dataframe.copy will help us with that. For the next part, let's consider this. Suppose we want daily returns for date at index T, then we need to divide the value at index T by the value at index T minus 1. And subtract 1. We want to do that for all the dates, starting with index 1. Now let's code this. Here, df[1:] picks all the rows from 1 till the end. And df[:-1] picks all the rows from 0 till 1 less than the end. This operation cannot be done at index zero since we do not have the price of the stock prior to this day. So we set the values at the zero throw to all zeros. Finally, we return this data frame. You must be wondering why did we use dot values attribute of one of the intermediate data frames. The reason is to access the underlying num pi array. This is necessary because when given two data frames, Pandas will try to match each row based on index when performing element wise arithmetic operations. So all our effort in shifting the values by one will be lost if we do not use .values attribute. Okay, now let's run this. Here is what the daily returns look like compared to the original stock prices. As you can see, the original prices of SPY and XOM are quite different. However since the daily returns are implicitly normalized, they show up at a comparable scale. Each daily return value is either positive or negative fraction related to the previous day's value. This reveals that Exxon or Exxon Mobil actually matches ups and downs of the SPY quite closely. There is another way to compute daily returns. This time, directly using Pandas data frame. Here is how we can do it using Pandas data frame function, shift. Note that we still have to replace the values at the zero true with zeroes. The reason for doing this is, Pandas leaves these unknown values as 9 by default. Now let's check the output. As you can see the result is same as before. One last important statistic on a stock that's important is called cumulative returns. So let's consider S&P 500, again, back in 2012. Now in 2012, the S&P 500 started the year at $125, and it ended the year at $142. When you listen to the news you hear things like, for the year 2012 S&P 500 gained 13.6%. That is cumulative return. You don't hear them say over 2012 S&P 500 went from $125 to $142. So how do you calculate these cumulative returns? It's really easy. Here's the equation. The cumulative return for a particular day, t, is just today's price divided by the price at the beginning. So price of zero is over here, and the price of any particular day, say would be here. And we can calculate the value like this. Now the cumulative return for the whole period is where t is this last day. So let's consider the example we've got here. To calculate the cumulative return for this whole year. It's the price at the end, divided by the price at the beginning, minus one. Turns out 142/125 is 1.136- 1 gives us .136 Which is equal to 13.6%. So our cumulative return for the ETF SPY was 13.6%. We can calculate and chart cumulative returns just like we did earlier for daily returns, except now the plot is showing us the cumulative return of course instead of the data return. Note that the shape of the chart is the same as the price chart. It's just now it's normalized, and in fact this equation is exactly our normalization equation. So that is how to calculate and plot cumulative returns. We're not going to have Dave show you how to do that, you're on your own there, now that you know how to do daily returns, it shouldn't be that tough. Okay, that's it for this lesson, we'll see you again soon. Historical financial data is of course essential for effective financial research. One reason people are attracted to finance as an area of research, is because they believe the data is very well documented. In other words, all the data is monitored and recorded by computer and saved for us to pore over later. It turns out though that there are many ways the data can be faulty. In this lesson, we're going to look at how missing data can occur and what we can do about it. Now, as you might have guessed, the data isn't really pristine. So, here's what people think financial data is like. They imagine that it's perfectly recorded minute by minute. The prices that are recorded are exactly right. The volume data is exactly right. But that's not the case. But that's not the only mistake [LAUGH] people make about what they think the data's like. People assume there's no gaps in the data, that we have every single minute recorded. That data for stocks started since the beginning of time, and they continue to the very last minute. The reality is that our data is an amalgamation created from many, many sources. For instance, for any particular stock, it may be traded on the New York Stock Exchange, at NASDAQ, at Bats, and over any particular minute during the day, it may trade at one price at New York Stock Exchange, another price at NASDAQ. The reality is that there's no single price for any stock at any particular time. In fact, it's hard to say who's right. So, the reality of the data that we get is that it's a combination from all these different sources. And different data providers will provide, actually, different numbers. And finally, one part of reality that's especially troublesome is not all stocks trade everyday. Sometimes stocks come into existence and suddenly, there's values for them and before that there was no data. Sometimes stocks go out of existence and suddenly, they quit existing and there's no data for them going forward. There's another kind of failure mode or missing data mode where a particular stock will be trading, data will be missing, suddenly, it starts trading again. And these are the sorts of problems we're going to take a look at and find a way to solve in this lesson. Okay, let's take a look at some examples so we can see how prices are recorded over time. We'll start with SPY. This is showing a time series of that ETF over time. This is the downturn in 2008, 2009. SPY represents the S&P 500. It's one of the most liquid and actively traded ETFs out there, and we typically use it as a reference, a time and date reference for other stocks. Because we know if SPY was trading, the stock market was open and we can use its time history as a reference in that regard. It goes all the way back to 1993. There are of course some stocks that go back further, all the way to 1901 and so on. But most of what we're going to do, it's fine that we know it's been active since 1993. Now Let's look at a couple more examples. We'll add JAVA, J-A-V-A, and as you can see, it was trading from the beginning here but for some reason or another, abruptly stopped. Now what happened there? Well, you may remember that Sun Microsystems, which was trading under the ticker JAVA, was acquired by Oracle in 2010. And on that date, that ticker went away. So if you look at historical data for JAVA, you'll see that it ends at sometime in 2010. Something else that's interesting about this ticker JAVA, is that before it was Sun Microsystems it was actually Mr. Coffee. So if you look historically for data for JAVA you'll find two different time series. One for when it traded as Mr. Coffee and another when it traded as Sun Microsystems, but it doesn't exist any longer. So imagine if you're processing this time series data, and you arrive at this abrupt end for JAVA, what's going to happen? Well in the data you'll see NAN, meaning not a number, meaning there's no data there. And the focus of this lesson is what to do about that. Let's take a look at another example. Okay, we've added now an additional set of data, and as you can see we named it FAKE meaning this example we invented for the purpose of this discussion. Now, each of these symbols is available to you in the data that we provide you for the class. So you also will have this FAKE1. Now, the data represented by FAKE1 is fairly common, and we only invented it just so it would work out well in this chart that we're looking at. Anyways, what's going on with FAKE1 is, as you can see, it didn't exist before this time. So instead of having, for instance, NAN values after a certain date, this FAKE1 data is going to have NAN values before a certain date. So we'll have a different kind of problem trying to process that data. Now we'll look at one more example, and as you might have guessed, we named that FAKE2. Now what's special about this one, is it's got all of the different kinds of problems at once. So it didn't exist before this date, data was absent in between these two dates, and so on. This is not typical data for a very liquid, very large stock, for instance like Google or Apple, but indeed data like this exists for thinly traded stocks. In other words, companies that don't have a high market capitalization, and they trade very little if at all occasionally. So we still have to be able to deal with data like this in our studies, and so let's focus on this FAKE2 example. The question is, what do we do in situations like this where we don't have data between two separate dates? Now, you might think, Gee, let's interpolate. And so we would estimate what a line is between those two dates and then fill in at each point an interpolated value. Why not do that? Well, the truth of the matter is, between these two dates, there was no trading. There really was no price for that data. But if we're going to do something like, for instance, compute a rolling average. Or a mean over that data, and there's nans there, that'll wipe out our entire calculation. So we can't leave it empty, but we shouldn't interpolate it either. So here's what we might do. One thing that we can do, is we fill forward, going from, we go over all the data, and when there's some missing data, we fill forward from the last, previous known value. So for instance, if we were to do that here, we would get these values up until that date, where it takes over there. We would fill forward here, and fill forward here. Now notice there's a big gap between there, and there's a big gap here, but that realistically reflects what was going on with the data. Now the reason we do this instead of the interpolation is the following. Let's suppose we were looking for patterns in the data and we had rolled back time and we were simulating history. And let's suppose for a moment we had this interpolation. And let's suppose we're right here in time and we're trying to figure out what's going to happen next. We're looking for patterns and so on. We're actually giving ourselves information about the future. We're observing that the price is going up. So if we were to make a calculation here, we would actually be peeking into the future. And that is not allowed. We do not want to do that. So we need to stick with only filling forward a last known price. If we do that then we're not peeking into the future. So let's get rid of that ugly, nasty peeking into the future. Okay, so now we've actually filled in all our gaps and we have continuous data from this start point all the way to the end. However, there still is missing data here at the beginning. And because we need some value here in order to calculate rolling averages or whatever sort of statistics we want to do, it's better to have some value here. Instead of not a number. And in this case, we fill backwards. So remember, if you are going to fill your data to resolve problems with gaps, fill forward first and fill backward second. That way you will avoid, to the max extent possible, peeking into the future. Now we'll hand it over to Dave. And she's going to show you how to do this in code. Here's to you, Dave! Thanks, Professor, I'll take it from here. So hello, everyone, and we will be using Pandas fillna function to fill the missing data. So let's find the documentation of this function, and let's go to this site. So here it is. The link is included in the instructor notes. I encourage you to bookmark this site. So it gives the usage for any function at a glance and it will help you a lot. So let's scroll down and let's search for a function using this small search box. Let's search for fillna. Here it is, DataFrame.fillna function, and we'll be using this. Read and try to understand different options and how to call this fillna function, and I'll be right back with a pop quiz. So here's a question for you. How would you call fillna() to fill forward missing values? Go ahead and type your answer in this box. So here's the answer. In order to fill forward missing values we need to specify the method ffill. Note that the method value is a string, so it has to be enclosed in quotes. So, let's do some coding. To start with, let's use an example stock with missing values. We will be using fakedo.csv and this file is included in your data folder. So as usual, we will be reading the csv into the data frame and we will do some plotting. So now let's go and plot this data and see what turns up. So, here is the graph. For the given range of dates, you can notice that there is a gap in the beginning and also a gap at multiple places in the middle. So now, let's try to fix this. We only need to add a single statement to fill those gaps. As you must have read in the documentation, method ffill corresponds to forward filling and inplace is equal to TRUE will save all the changes in the same data frame. Try removing this and see what happens. Now, let's plot and see how the graph looks now. So here's the graph. If you look closely, you will observe the forward filling effect. The stock prices retained their previous values throughout. However, note that the missing values at the beginning of the range have not been filled. Think about what you need to do to take care of that. Time for some coding quiz. Okay. Here's some code to read in our data for multiple symbols during a specified period of time. If you go ahead and plot this, you see where we have data missing for JAVA, FAKE1, and FAKE2. Your task is to fill these gaps using the filimon method and yes, it can work for multiple stocks or in that case, multiple columns of the data frame simultaneously. You can refer to the documentation and the previous example if you need a que. Good luck. So, here's the solution. To solve this, you need to use both forward and backward fill. The key is to use forward fill first, and then the backward fill, to avoid peeping into the future as much as possible. Now let's see how the graph looks now. Here is the resulting graph. Know the effects of the forward filling and the backward filling in different segments of the missing data. That's all for now. Happy quoting till I get back to you. Daily returns are one of the most important factors for us to consider when looking at market statistics. But daily returns for a single stock just by themselves are not very informative. One of the most informative ways to consider daily returns is when we compare the returns of one stock with another. We're going to use daily returns as a basis for the analysis in this lesson and we build daily returns, like we've seen before, by starting with a price time series. And each point in this daily return chart is related to how much price has changed on that corresponding day. So, for instance, this represents how much the price changed from this day to that day, about 1%. And, of course, we have that for each of the days in our history. Now looking at this data, this daily return data, it's not too revealing. It's hard to draw any sorts of interesting conclusions just by visually looking at this data from day to day. And so, there's a number of interesting ways that we can look at that data, and that's what this lesson is all about. Those two ways are histograms and scatter plots. Let's start by taking a look at histograms. A histogram is a kind of bar chart where we plot the number of occurrences of each item versus the value. So the way we accomplish that is, we split up the range of data into lots of little bins. And we count up how many times the data matches the range across that bin. So, as an example, if you notice here we've got several occurrences of this value, which is about the same, and those three occurrences are probably in say, this bin. So when we go to plot the histogram overall, we would see a bar of the appropriate height here that represents how many times the data matched that value. And of course, we have values in other bins, and so the bars in those bins would have various heights. And as you gather that data across all of time, a shape emerges of this histogram, and that provides a lot of information. So let's consider what that shape might look like. Suppose now that we've looked at, say the S&P 500 over many years and we've measured each day what the daily return is for the S&P 500. And we conduct a histogram and plot that histogram. So, for each little bin we have a bar there. What is the shape of this histogram going to look like? Do you think the bars, when we put them all together, will have a sort of flat shape, maybe a triangular shape, or something that's more like a bell curve? Check the box next to the histogram that you think is the best answer. The correct answer is bell curve. [COUGH] That's what many, many distributions in nature. And if you consider, [LAUGH] the stock market nature, is not unusual that a histogram of daily returns ends up looking like a bell curve. Once we've got our histogram, there are a lot of statistics we can run on it to characterize it. For instance, of course we might be interested in the mean. We might also be interested in the standard deviation. Which is essentially on average how far do individual measurements deviate from the mean. Another very important measure is something called Kurtosis. Kurtosis comes from a Greek word that means curved or arching. So what does Kurtosis mean? Well let me show you. Kurtosis tells us about the tails of the distribution. So the tails are the parts out here towards the ends. And if we assume that our distribution is similar to a Gaussian distribution, or normal distribution. The measure of kurtosis tells us how much different our histogram isfrom that traditional Gaussian distribution. So in this case we have what are called fat tails. We got them over here and over here. What that means is that there are occasional, and more frequent than would happen if we had a regular Gaussian distribution. There are frequently large excursions more frequently than if this was a normal distribution. If you were to measure the kurtosis of this histogram, you would get a positive number. Meaning that there are more occurrences out in these tails. Than would be expected if it were a normal distribution. If you measured a negative kurtosis. It would mean that there are many fewer occurrences out here on the tails. Than would be expected if it were a normal distribution. So we can plot our data in this sort of bar chart called a histogram. We can measure statistics on it like standard deviation, mean and kurtosis. And remember the following about kurtosis. If we’ve got a positive kurtosis, that means we’ve got fat tails, like in this example. There’s more occurrences outside in the tails than would normally happen with a Gaussian distribution. And if we’ve got a negative kurtosis, we’ve got skinny tails, meaning there’s less out there. Now, I’m going to hand it over to Dave, and she’s going to show you how to make this plot and calculate these numbers in Python. I recently read a post on Humans of New York page, and this woman mentioned in her interview that programming is magic. It allows us to make things with words. Isn't that true? So let's create our own magic. Let's make histogram. Firstly, let's check out the ingredients needed to make histogram of daily returns. To calculate daily returns, we need to get stock prices first. To start with, we get stock prices for the SPY for a period of three years. Next step is to calculate daily return. This is similar to what we saw in lesson four. Now we call this function and pass a DataFrame to it. We also plot the daily return value by passing the daily return DataFrame to our plot data_function. This graph show the prices of the SPY stock over three years. And this is the daily return graph for SPY. Now we have our base ready, so let's make our histogram. And after five lessons, you must have guessed that even this can be done in just one line. Here is our histogram. Professor explained the concept about bins. We did not mention the number of bins while plotting the histogram. The default number of bins is 10. If you look closely, you will observe 10 sets of ranges. Can you see this? 1, 2, 3, 4 and so on. If you count, there would be ten. But as usual, Python is flexible and allows us to change the number of bins, using the bin keyword. We inform the histogram function that we need to empty bins by passing a parameter bins and assigning it a value 20. Now let's check our changed histogram. Notice that the width of each bar has reduced. And the number of bars has increased. If you read this graph, it would say that there are approximately 300 values which lie near 0. Next we compute some statistics on the daily return. Starting with mean and standard deviation. We call the function mean and std on our dataframe to get the values. Let's go ahead and check the mean and the standard deviation for the daily returns of SPY stock. So we get the mean and the standard deviation. Happy with just knowing the mean and standard deviation value? But I am not. I want to see it on the plot, just like Professor did. So let's learn how to add mean and standard deviation line on plot. Matplotlib library has a function axvline. Looking at the substring vline, we can guess it will give vertical line. Let's check out its parameters. First we pass the mean value, then just for beautification and so that we can differentiate the mean line from the rest histogram, we add a color, which is white, make it a dashed style line and increase the linewidth to two. Now let's check our output. So this our mean and this is how it is plotted on the histogram. Now let's go ahead and plot standard deviation. To plot the standard deviation line, it is similar to the mean. But as we want the standard deviation line on both side of the mean, we plot it twice. One with the positive value and one with the negative value, to show standard deviation line on either side of the mean. Ta dah, we have our standard deviation lines on our graph. To give the standard deviation a red color, I have just replaced the parameter color of white, with red. Now I'm happy with the graph and I hope you do are. Let's move ahead to kurtosis. We can expect that dataframe would have a function for calculating kurtosis as well. So that's it. This line will give you kurtosis of the daily returns. We get a positive value for the SPY stock, which means we have fat tails. Just for your information, you can also get bincounts using numpy.histogram function. Check instructors notes for more information. Over to you professor. A common practice in finance is to plot histograms of daily returns of different stocks together and look at them together and assess how they relate to one another. So here, we've got a plot of an XYZ stock and SPY or S&P 500. Now take a look and see what difference you can see between them. Now to help out, I'll draw what the underlying shape is looking like. Check which answer you think is most correct in terms of volatility and return for XYZ versus SPY. This is the correct answer. XYZ has a lower return and higher volatility than SPY. You can tell that if you look here at the mean of XYZ, you can see it's lower than the mean of SPY. You can see the shoulders are broad on XYZ, meaning it's got a larger standard deviation, and therefore, higher volatility. Dave will show you now how to plot histograms like this, right next to one another in Python. I'm back again. This time with a really small segment. We need to plug two histograms. So first we need the values for two stocks. We get data for two stocks, which is SPY and XOM. We also go ahead and compute daily returns for each of the stock. Note that our daily return data frame will have daily return values for each of the stock prices. Now like before, we just call histogram function on the daily return data frame, and let's see what happens. We keep the bins count to be 20. Now let's run this. Okay, so we got two subplots. But we go ahead one step and plot them on the same x and y axis so that we can compare the histogram of SPY and XOM. To get two histograms on the same x and y axis, we call the histogram functions separately on each of the stocks daily return values. We also add the label parameter so that we can differentiate between the histogram of the SPY and XOM. Now, let's run this. Here we go. We get two histogram of SPY and XOM on the same X and Y axis. Now you can compare the histogram and see that the teams of XOM is thin as compared to the SPY. That's it for this coding segment. I'll be back soon. Over to you professor. We're now going to take a look at another way to visualize the differences between daily returns of individual stocks. Let's get back again to our daily return chart. We've got S&P 500 here plotted already. And let's compare that to another stock xyz. Now note here that frequently xyz moves in the same direction as spy, but it also sometimes moves a little bit further like in these sections here. We'll be able to visualize those differences in a scatterplot. So on a scatterplot, there are a number of individual points or dots. And each one represents something that happened on a particular day. So let's look at this particular day. On this day, spy was positive, close to +1. So we'll look at +1 on spy. And xyz was about +1 as well but a little bit larger. So that day would correspond to a point about there. Now we look at each day one by one individually. And populate all of our dots based on what happened each day. Another interesting day is this one where spy and xyz were moving in different directions. So again we had spy in positive territory, but xyz was in negative territory, so that would represent a dot about like that. Now if we were to continue this process for very many days over a long period of time, for most stocks a trend appears which is something like this where you can sort of see there's a relationship here, maybe a linear relationship. And, however the dots are somewhat scattered. They don't form a perfect line. It is fairly common practice to take this set of data and fit a line to it using linear regression. Let's say we got a line something like that. And to look at the statistics of that linear fit. One property is the slope. When we fit a line, what's the slope of that line? Let's assume it turns out to be 1 for this particular stock and its relationship to the S&P 500. This slope, in financial terminology, is usually referred to as beta with this symbol, or just the word beta. And what beta means is how reactive is the stock to the market. So if beta is 1, and we have a slope here of 1, it means, on average, when the market goes up 1%, that particular stock also goes up 1%. If we have, say, a higher number, say, 2, that would mean that if the market were to go up 1%, we'd expect on average for that stock to go up 2%. There's another factor you can see here when you look at where that line intercepts the vertical axis. That is called alpha. And you've probably heard about alpha in investing circles, and what that means is that this stock is actually on average performing a little bit better than the S&P 500 every day if that number, alpha, is positive. If it's negative, it means on average it's returning a little bit less than the market overall. That's how you can plot the data, fit a line to it, and measure a couple aspects of this performance with regard to the market or with regard to some other stock. Now add a scatter plot for another stock, ABC, and again each one of these dots represents the daily return of SPY versus ABC, and we fit a line to it, and it turns out it's got a slope of two, so now we're going to ask you a couple of questions about it. Now add a scatter plot for another stock, ABC, and again each one of these dots represents the daily return of SPY versus ABC, and we fit a line to it, and it turns out it's got a slope of two, so now we're going to ask you a couple of questions about it. The slope is just the slope. Correlation is a measure of how tightly do these individual points fit that line? So you could have a shallow slope but the data tightly fitting that line, and thus a higher correlation. Or you could have a steeper line and the data fitting that line at a higher correlation. Correlation is just a measure of how tightly do those dots fit the line. And you can have a correlation from 0 to 1. Now add a scatter plot for another stock, ABC, and again each one of these dots represents the daily return of SPY versus ABC, and we fit a line to it, and it turns out it's got a slope of two, so now we're going to ask you a couple of questions about it. Now add a scatter plot for another stock, ABC, and again each one of these dots represents the daily return of SPY versus ABC, and we fit a line to it, and it turns out it's got a slope of two, so now we're going to ask you a couple of questions about it. Which of these statements is the most true about the relationship between ABC and XYZ in terms of beta and correlation? This is the correct answer. It's got higher beta because the slope is higher and higher correlation because the dots are closer to the line that fits it. Now, Dave is going to show you how to create scatter plots and make these measurements in Python. Here's to you, Dave. Thank you, Professor. So I am back with more Python and more graphs. This time, let's scatter some data. I mean, let's learn how to build a scatter plot. We will compare scatter plot of SPY versus XOM and SPY versus GLD. So let's read this data and compute daily returns as well. As usual, We call get_data function with this symbols and also compute daily returns. Next we first plot scatter plot for SPY versus XOM. Kind parameter of the plot function of the data frame will help us achieve this. So we mention we need a scatter plot, but since the data frame daily return has values for three stocks. We have to mention which should be our X axis and which should be our Y axis. As we are plotting SPY versus XOM, we assign X attribute aas SPY and Y attribute as XOM. Ready to see the output? This is our SPY versus XOM. Now let's similarly plot SPY versus GLD. Since we want GLD on our y-axis, we just replace the y label from XOM to GLD. So here are two scatter plots. SPY versus XOM and SPY versus GLD. But we want to recreate the graph that Professor drew. So we fit a line to the scatter plots. For that, we need the help of another good friend of ours. Which is numpy. So let's import it. After importing the numpy library we areall set to fit a line to our scatter plot. So we have a set of points, and we want a line which has an equation of degree one. So we go ahead and fit a polynomial of degree one. This is what polyfit function of the numpy does. So let's use it. We will first do it for SPY and XOM. The polyfit function needs x-coordinates and y-coordinates to fit a line. For us the x-coordinates are the daily return values for SPY and the y-coordinates are daily return values for the XOM. The one denotes the degree of our function. Calling this function will return two things. The first is the polynomial coefficient and the second is the intercept. Since we have a polynomial of degree 1, it would be of the form y = mx + b. So m is the coefficient and b is the intercept. We name them as beta and alpha. Just as Professor explained. Now we finally plot these values. The idea for plotting the line is, for every value of x that is SPY, we find a value of y using the line equation, which is mx + b. This parameter denotes that we want a line plot with the color red. Now, let's check our graph. Here is the fitted line. Let's do it for GLD so that we can compare them both. We also print the beta and alpha values for each. Now, let's compare the beta values which shows how the stock moved with respect to SPY. You can see that the beta values for the XOM is greater as compared to that of GLD. Which means that XOM is more reactive to market as compared to GLD. On the other hand, the alpha values denote how well it performs with respect to SPY. Numbers over here say that GLD performed better. Let's cross check. You can see the upward movement of the GLD as compared to the SPY. One last thing is to find the correlation yet again. The data frame has a function corr which means correlation, and we can define which method to use. We use the method pearson. It is the most commonly used method to calculate the correlation. There are other methods as well, check the instructor's note for more detail. We get the output in the matrix format, with correlation of each column with each other column. You can see that the SPY and XOM are highly correlated. The value of the correlation for GLD and SPY is very small. Let's check the graph. You can observe that the dots do not fit the line closely. And that's why the correlation value for the SPY versus GLD is less as compared to SPY versus XOM. For more information on data frame scatter plot and polyfit, check the link in the instructor's notes. As you have seen in this lesson, the distribution of daily returns for stocks and the market look very similar to a Gaussian. This property persists when we look at weekly, monthly, and annual returns as well. If they were really Gaussian we'd say the returns were normally distributed. In many cases in financial research we assume the returns are normally distributed. But this can be dangerous because it ignores kurtosis or the probability in the tails. In the early 2000s investment banks built bonds based on mortgages. They assumed that the distribution of returns for these mortgages was normally distributed. On that basis they were able to show that these bonds had a very low probability of default. But they made two mistakes. First, they assumed that the return of each of these mortgages was independent, and two that this return would be normally distributed. Both of these assumptions proved to be wrong, as massive numbers of homeowners defaulted on their mortgages. It was these defaults that precipitated the great recession of 2008. Up until this point we've been computing statistics about individual stocks. We're going to shift now to computing statistics on portfolios. We're going to focus on some of the most important statistics that are used to evaluate the performance of portfolios and accordingly portfolio managers. We'll define a portfolio as an allocation of funds to a set of stocks. For the moment, we're going to follow a buy-and-hold strategy where we invest in a set of stocks with a certain allocation and then observe how things go moving forward. We'll assume the allocations sum to 1.0. We want to be able to calculate the total value of a portfolio day by day by day. Once we have that information, then we can compute statistics on the overall portfolio. So let's start with an example. Assume we start with a portfolio value of one million dollars, and we're going to take a look at that portfolio from the beginning of 2009 to the end of 2011. And our portfolio consists of these three symbols, S & P 500, Exxon, Google, and Gold. And at the beginning of 2009, we're going to allocate .4 or 40% of our portfolio to SPY, 40% to Exxon, 10% to Google, and 10% to Gold, and we'll enter those positions in the beginning, and we'll hold them, and step forward, and see what the overall value of the portfolio is day by day. How do we calculate the total value of the portfolio day by day? Here's how to do it step by step. We start with our prices data frame. Remember the four columns with prices every day, indexed by date. The first step is to normalize these prices. As we've done before, it is just the price values divided by the first row. So after we normalize, we have a new data frame, normed, which is, as we said, all the prices divided by the first row. That's going to give us now this new data frame where the first row all 1.0 and then it proceeds after that. And these are essentially cumulative returns starting from the start date. The next step is to multiply these normed values by the allocations to each of the equities. So we'll just multiply normed times our allocations, allocs, and that gives us a new data frame alloced. Now as you remember, our allocations were 0.4, 0.4, 0.1, 0.1. So when we do that multiplication, the first row is going to represent those numbers. And the data after the first row will be sized accordingly. Our next step is to multiply our alloc data frame times start_val. And what that'll give us is, in this first row the amount of cash allocated to each asset and then going forward, it'll show us the value of that asset over time. So we've got now a new data frame, pos_vals, what that means is position values, that at each day, that's how much that position is worth. So we started out, for instance, with 400,000 for the first one, 400,000 for the second one, 100,000, 100,000. But now as we go forward each day, it's as if we invested say 100,000 in this one, and it reflects how much it was worth each day after that. Now that we have the value each day for the individual assets, we can calculate the total value for the portfolio each day by summing across each day. So on the first day for instance the value of the portfolio was four hundred thousand plus four hundred thousand plus one hundred plus one hundred thousand or one million. Now those values change of course as the stock prices change going forward. So each day is a little bit different. We can calculate the value for each of these days by taking the sum of pos_vals, position vals using axis=1, so that's telling python to sum across each row like that. So that sums each day across into Port_val, which now reflects the value each day for our total portfolio. Let's recap now. We start with our prices. We normalize that to the first day, so the first row here is all ones. We multiply it times our allocations, and that gives us now in each column, the relative value of each of those aspects over time. We multiply by our initial investment, and that causes now each row to be the real value of that investment each day over time, starting with our initial allocations. If we then sum each row we get the value of the portfolio on each corresponding day, and that's it. That's how you calculate daily portfolio value. We showed a moment ago how to go from prices to port-val, which is the daily total value of the portfolio. Now that we have port-val, we can compute a number of important statistics on the portfolio, and thus assess the portfolio and the investment style of whoever is managing that portfolio. An important first calculation is to compute daily returns. We've talked about how to do that before, so I won't go over it here. But an important observation is whenever you compute daily returns, the first value is always going to be zero. And that's because on the first day, of course, there's no change. So we want to exclude that value from any calculations we do across all daily returns. It's easy to accomplish this with a simple python statement, which is just to replace daily returns with daily returns where we just include the second row forward. And boom, we're rid of that first zero. Now that we have this information, we can compute four key statistics that everybody wants to know about regarding the performance of a portfolio. They are cumulative return, average daily return, standard deviation of daily return and sharp ratio. Cumulative return is just a measure of how much the value of the portfolio has gone up from the beginning to the end. So to calculate that, we take the last val, which is port-val of -1. Which is this one divided by the beginning and subtract 1. Average daily return is just the average of these numbers, so we just take the mean. Very simple. And standard deviation of daily return, again simple. Just use the standard deviation function right there. Now sharpe ratio is a little bit more complex than these other ones. So we're going to spend a little bit more time diving into sharpe ratio. The idea for Sharp ratio is to consider our return, or our rewards in the context of risk. As we mentioned before, most finance folks consider risk to be standard deviation or volatility. We're looking for a measure that essentially adjusts a return for that risk. So, here are a couple of examples that I want you to think about, and we'll have a little quiz associated with it. But we have three example charts here, where we're comparing two stocks against one another. So in this first one we've got ABC and XYZ and both of them have about the same volatility, except one returns a little bit more than the other. In this next question, question two, they both return exactly the same amount. But one of them is more volatile than the other. And finally, we have again these two stocks. One, ABC, returns 11%, XYZ returns 9%, but ABC is much more volatile than XYZ. So I want you to think about this and mark which portfolio or stock you think is better in each one of these examples. For number one here, ABC is the correct answer because its volatility is the same but its total return is higher, so all else being equal, higher return is better. In this next one, the correct answer is XYZ. And the reason is, XYZ had the same return as ABC, but it was less volatile. So, all else being equal, less volatility is better. Now, number three was a trick question. [LAUGH] ABC has higher return, but it's offset by a higher volatility. XYZ has lower return, but that's offset by lower volatility. So, you don't really have enough information to make the choice here. You can sort of stand back and squint and look at it, and tell you what your gut says, but we need a qualitative way to measure this. That's what the Sharpe ratio is all about. Sharpe ratio is a metric that adjusts return for risk. And it enables us in a quantitative way to asses each of these example compared portfolios. So Sharpe ratio will show us for instance, that in this case ABC is better because It has about the same volatility as XYZ, but higher return. If it were to assess these two, even though they both have the same return, it'll say XYZ is better because it's got lower risk. And finally, in this case where these two are very close and it's hard for us as humans to determine which one is better, Sharpe ratio here will give us a number that will help us determine between the two. So with regard to the numbers that Sharpe ratio ends up providing us, all else being equal, lower risk is better, higher return is better. Sharpe ratio also considers something called the risk free rate of return. That's the interest rate you would get on your money if you put it in a risk free asset like a bank account or a short term treasury. The reason that it includes this number, is we always need to consider, gee, maybe this asset we've got isn't performing as well as the return I would get it I just put it in the bank. Now, lately, as of mid-2015, the risk free rate of return is about zero. In other words, if you were to put your money in the bank or to buy very short term treasury bonds, that's the interest rate they would pay you. And this is why lately folks have put so much money into the stock market, because you can't make money putting your money in the bank these days. The Sharpe ratio is named for William Sharpe. And he developed something called the Sharpe ratio that accounts for all of these. Now think about what the form of that equation would look like. Consider that you have these three factors. Portfolio return, risk-free rate of return, and standard deviation of portfolio return, or volatility, or risk. How would you combine these three factors into a simple equation to create a metric that provides a measure of risk adjusted return? In other words, like those examples we showed you before, all else being equal, higher return is better, all else being equal, lower volatility is better. Which of these three do you think is the best metric? This is the best answer, here's why. First of all, observe that we're dividing by volatility here on the bottom. So as things become more volatile, the ratio goes down. We've got return on portfolio here on the top. So as return goes up, the metric goes up. And finally, we subtract the risk free return here. So as risk free return increases, the value of our metric decreases. Meaning, essentially we need to have a higher return on our portfolio. Than the risk free metric in order to have a positive number here. This is indeed the form of the sharp ratio. There are a few more details. But this is essentially the ratio devised by William Sharpe Here's the equation for computing the Sharpe ratio as proposed by William Sharpe himself. It's the expected value of the return on a portfolio, minus the risk free rate of return, divided by the standard deviation of that same difference. This is the ex ante formulation, meaning, because we're using expected, it's a forward looking measure of what the Sharpe ratio should be. Now to calculate this in reality, we need to look back at those values. So, for instance, the expected value of this difference is just simply the mean of what that difference was over time. So to calculate this in Python using historical data, we just take the mean of daily returns minus the daily risk-free rate, and divide that by the standard deviation of the daily returns minus the daily risk-free rate. Now you may be wondering, what is this risk free rate? Where can we get it? Traditionally there are a few numbers that people use for this. One is LIBOR or the London Interbank Offer Rate. Another is the interest rate on the 3-month Treasury bill. And finally, a value that people have been using a lot over the last [LAUGH] few years is 0. 0 is a good approximation to the risk free rate. Now I've been presenting this as if this risk free rate changes each day. And indeed, LIBOR changes each day and 3-month T-bill changes a little bit each day. But there's a shortcut people use a lot that simplifies this equation significantly. And this shortcut makes sense because usually the risk free rate is not given on a daily basis for, for instance, putting your money in a bank account or a certificate of deposit. Usually that's a percentage on an annual basis or a six month basis. So you can convert that annual amount into a daily amount using this simple trick. Let's suppose our risk free rate is 10% per year or 0.1. That means if we start at the beginning of the year with a value of 1.0, at the end of the year we have 1.1, so we add 1 here. So this is the total value of our asset at the end of the year. Now, what is the interest rate per day that would enable us to get to this value? It's a number that if we multiple it by itself each day for each day in the trading year, or 252 times, would arrive at this number. So here's how we do it. We take the 252nd root of that sum, believe it or not, that's pretty easy to do in Python actually, and subtract 1, and that is our daily risk free rate. We are, in most cases in this class, just going to approximate the daily risk free rate with 0, because that's what it's been for such a long time. Of course, it may be changing in the future, so keep this shortcut in mind. Now, suppose we want to use this value, which is fine. We would plug that in here, and also plug it in here. So observe that if we plug a constant in here, in this standard deviation calculation, we can just remove it. Because a set of values minus a constant, when you calculate the standard deviation, is just as if this were 0. Summing it all up, this is the equation we typically use for calculating Sharpe ratio using daily returns. We drop the daily risk free rate from the standard deviation because we treat that as a constant. If our daily risk free rate is greater than 0, then you need to plug it in here, but we can usually use a constant there as well. But wait, there's more! The Sharpe ratio for the same asset can vary widely, depending on how frequently you sample it. So in other words, if you sample the prices every year, and compute your Sharpe ratio based on yearly statistics you'll get one number, if you sample monthly you'll get a different number, if you sample daily you'll get still another number. The original vision for the Sharpe ratio is that it's an annual measure. So if we're sampling at frequencies other than annually, we need to add an adjustment factor to make it all work out. So if we have our original sharp ratio over here we multiply it by an adjustment factor called K to get the annualized version. Now what is K? K is simply the square root of the number of samples per year. Since if we're using daily data. There are 252 trading days per year, so K is the square root of 252. If we're, say, taking weekly samples, it'd be square root of 52. Important thing to keep is mind is the number in here is the rate at which we're sampling. So as an example, let's suppose we were trading for 85 days. Because we're sampling at a daily rate, we use this number for our K. Square root of 252. Even though we only traded for 89 days, we use 252 here because we're sampling daily. It's the frequency at which we sample that effects this value for K. So, recapping, if we sample the value of our portfolio monthly, K is the square root of 12, if we do it weekly, it's the square root of 52 because there's 52 weeks in a year, and if we sampled daily, it's square root of 252. Bringing it all together, if we're using daily data, our Sharpe ratio is square root of 252, that's our K, times mean of our daily returns minus the daily risk free rate, divided by standard deviation of daily returns. Assume we've been trading a strategy for 60 days now, and on average, our strategy returns one-tenth of a percent per day. Another word for this is 10 basis points. One basis point is one-hundredth of a percent. So ten bps or basis points is one-tenth of a percent. Our daily return is, on average, 10 basis points. Our risk free rate, which we'll assume is just a fixed number, is 2 basis points per day. And the standard deviation of our daily return is 10 bips, or 10 basis points. What is the Sharpe ratio of this strategy? The correct answer is 12.7. That's a really, eye-watering Sharpe ratio. Anyway, these numbers are just made up for example, so it's not surprising we might get an absurd number here. But, here's how we calculate that. Remember our Sharpe ratio is the square root of 252 because that's how frequently we are sampling the data, daily. 252 days in a year, square root of 252. A lot of people probably saw this 60 days of data and thought that it should be square root of 60. It's not correct. It's the frequency that you're sampling. Anyways, getting back to it, it's square root of 252 times the mean of portfolio return minus risk free return divided by standard deviation of our daily return. So that becomes square root of 252 times 10 bips minus 2 bips divided by 10 bips. This just becomes 0.8, and multiply it all out, and you get 12.7. Now you know how to compute daily portfolio values and, from there, important portfolio statistics. The main ones we're going to focus on are cumulative return, average daily return, standard deviation of daily return, or risk, and Sharpe ratio. These are the key factors most people focus on when evaluating the performance of a portfolio. The assignment associated with this lesson is for you to build a function that can calculate these values automatically. You've got what you need to build this, so have at it. In this lesson we're going to look at optimizers. Optimizers sound scary, but they're really cool and really fun. I'm going to show you all kinds of neat things you can do with optimizers. What is an optimizer? An optimizer is an algorithm that can do the following things. Optimizers can be used to find minimum values for functions. So say you have a function like f(x)=x2+x3+5 or something like that, an optimizer can find. For what value of x is this overall function minimized? Another thing that optimizers can do is find the parameters for parameterized models from data. So we might have some data from some experiment, and we can use optimizers to find a polynomial fit to that data. And that is actually one thing we are going to learn in this lesson. Finally, we can use an optimizer to refine allocations to stocks in portfolios. What does that mean? Well, that means for instance, you can decide what percentage of funds should be allocated to each stock using an optimizer. How do we use an optimizer? It's really just as simple as three key steps. First thing you need to do is define a function that you want to minimize. As an example you might use something like f of x is equal to x square plus point five. You define that in Python and then the minimizer will call this function many, many times as it tries to find the minimum values for x that causes this function overall to be smallest. You also need to start with an initial guess for x that you think might be close to the solution to the problem. If you don't really know, then you can choose a random value or just some standard value. But then the optimizer starts with that guess and it repeatedly calls a function, tests different values, and narrows in on the solution. Finally, you call the optimizer with these parameters and stand back while it searches for the minimum. Let's take a look at this function, f(x) is equal to x minus 1.5 squared plus 0.5. That function is a parabola that looks something like this. It's centered horizontally at 1.5, and its minima is here at 0.5. Now, the minimizer doesn't know that. We can tell it by looking at the equation, but the minimizer has to figure it out on its own. So let's suppose we tell it, hey minimizer, why don't you start with a guess of 2.0 and see if you can figure out from there what it is? So the minimizer says, okay, I'll give it a go. [LAUGH] And here's what it does. First thing it does is it checks the value at 2.0, it turns out that that's about 0.75. It then tests the value nearby, say here and here. And it finds out that this equation has a slope about like that, at this point. Now, it's trying to minimize, and so what it does is it marches downhill, it's called gradient descent. And it tries another value down along that slope. Gets a particular value here, tries another one, and so on. And eventually, it narrows and it discovers that 1.5 is the value for x at the minima. And the value of y there is 0.5. Now, the example I gave you for sort of marching down this gradient descent is one method. There are many variations on that method, that different kinds of minimizers use. And Scifi, the library that we're using, has many of those options. And you can choose different ones according to your taste. We're going to stick with one particular approach through our examples here. But you ought to experiment and try some of the other ones as well. Let's try that same example function now in Python code. So up here we have our normal imports, here is where we define the function and again we're simply using X-1.5 squared +0.5. Now within this function we're going to go ahead and print what the value is when we get called. It just is a little bit handier so that we can see what exactly is going on. But you don't have to have that of course. And then we return y. Now this is going to be the function that we're going to Ask SciPy, or in particular the optimizer, to minimize for us. And by the way, we've included this optimize package as spo. So scipy.optimize as spo. This is our call now to the optimizer or the minimizer. Before we call it we first set our guess value to be 2.0. And we're using the function minimize so we call spo.minimize. F, that's our function here, so we're saying minimizer, please minimize find the minimum for this function. X guess is our guess. Method is, we're directing minimize to use a particular minimizing algorithm. We'll talk a little bit about that a little bit later. But this is one of those particular algorithms that happens to work pretty nicely. We send it one more option here, disp, which is True. Which means we just want it to be verbose about things that it discovers. Anyways, that's it. That calls the minimizer. The minimizer repeatedly calls our function and finds the minimum value, then it prints out those results. Let's try a test run and see what happens. Remember, in our function that we wanted to minimize, we explicitly printed X and Y. So here you can see each time it gets called it prints these values out. And so the minimizer is repeatedly calling that function f and it's printing these things out. So it gets called initially with an X of 2 and it discovers that the value is 0.75. Then a value slightly greater than 2, a value slightly less than 2. And the minimizer very quickly converges on 1.5 as the answer, and here it prints out those values and finds the minima at 1.5 with a value of 0.5 there. So pretty efficient and effective discovery of the minimization. I added a few more lines of code here which I'll highlight, merely to plot the answer, so all the rest of the code is the same. But let's take a look now if we plot it as well. So, same result as before but nice plot with our minima identified right here. So, that is how to code up a minimizer, it's really very easy and very powerful. Let's look at it a little bit further. Now that you know how minimizers or optimizers work, think a little bit about what might be hard for them to solve. So I'm going to show you four example function shapes. And I want you to consider whether these would be hard or easy for the minimizer to solve. Here are four function shapes to look at. If you think that one would be hard for the minimizer we just talked about, check the box next to it, and tell us why. Type out a reason in the text box. All right, have at it. Most of these are hard. This one's hard. This one's hard, and this one, and let me explain why. This one is hard because of this flat area here and here. Suppose the minimizer tested this point here and then tried on either side. It wouldn't be able to find any gradient to follow, so, it wouldn't know which direction to go. This one is difficult for at least two reasons. One is it has several local minima that aren't necessarily the global minima. So, it might iterate and find, say, this as a minima. But notice that actually there's this other two that are actually smaller. And then if these two have exactly the same value, turns out we have two global minima. So, those sorts of conditions are tough for these minimizers to solve. This one is challenging A, because of this flat area, but also because of this discontinuity. So, four examples, three of them would be hard for our minimizer to solve. Now, I'm not saying that these are not solvable by optimizers. In fact, there are optimizers that can solve these problems with varying degrees of success. And they're likely to find a minima, just not guaranteed to find the minima. While we're on the topic of problems that are easy or hard for optimizers to solve, let's talk for a moment about a particular class of problems that are indeed the most easy for these types of algorithms to solve. And those are called convex problems. Here's the formal definition of a convex function. I'm going to read it to you from Wikipedia. And then I'll show you what it means on these graphs here. A real valued function f of x defined on an interval is called convex if the line segment between any two points on the graph of the function lies above the graph. A lot of words there. Let me show you what that means more easily. First step, choose two points and draw a line between them. Now, for each of these lines, if the line is above the graph, everywhere between those two points, then the function is convex between those points. So for this function, yes, it's convex because the line is above the graph everywhere. In fact, any two points you chose on this graph, we'll have that property. So this function is convex everywhere, at least where we're looking at. Here, notice that this part of the graph lies above the line. So this is non convex. Similarly, this one, we've got this region here that lies above the line, so this one is also non convex. And this one is of course convex. So a couple things to observe here, some properties that emerged. One is in order for the function to be convex, it has to have only one local minima. And in other words, that local minima is the global minima. This one fails for that reason. We also can't have any flat regions that essentially don't have any slope downward. Now, if the function you're trying to find a minima for is convex, then these algorithms will find the minima quickly and easily. But again, there are algorithms that can still find the minima for more complicated examples like these. But they require a little bit of randomness and they aren't necessarily guaranteed to find the global minima. So far, we've been looking at functions that just have one dimension in x. So for instance, the parabola that we looked at. It’s just as easy for these optimizers to work in multiple dimensions. Here’s an example of a function that has two dimensions in x. It still has its y result. But the minimizers can solve these problems with gradient descent just as easily. So instead of just one dimension, we can have one, two, three, four, as many as we’d like. Now we're going to do something really cool. I'm going to show you how to build a parameterized model from data. What do I mean by parameterized model? This is an example of a parameterized model that you're probably familiar with from algebra. It's a function of x and it has these two parameters, m and b. In fact, as you're probably aware, this is the equation of a line. So m and b are the parameters of that line. Now for convenience in our code instead of using m and b, I'm going to use C0 and C1, just to be consistent. Let me motivate this with an example. Let's suppose we have some data from an experiment. Now this can work for many sorts of experiments, but for now, let's assume we've taken some measurements of humidity, and we've observed on those particular days we measured the humidity how much it rains. So each dot here represents one day and one sample of data. So on this date, it was this humid, and it rained that much. Now we probably have lots more data, one for each day. When we look at this data, we see there's a kind of relationship here. And our intuition is maybe that it could be fitted by a line. Just sort of by eyeballing it, looks like the line might look about like that, and so our parameters here coefficient 0 is equivalent to the slope here, and coefficient 1 is the y intercept. So our task is to find C sub 0 and C sub 1 that provide the equation for this line that best fits the data. The question here is, how do we reframe this problem so that it makes sense for our minimizer? What is it we're trying to minimize? So restating the problem, suppose we have our original data points here, and we're trying to discover the equation of a line that best fits those points. Suppose this blue line is a candidate line and we want to evaluate it. Is this good or bad? So the equation for that line is, our first coefficient times x plus the second coefficient. And what the minimizer is going to do is it's going to vary this C0 and C1 to try and minimize something. And so we have to come up with an equation that gets lower in value as this line better fits the data. What should we use for that equation? So here's one step towards solving this problem. We can take a look at each one of our original data points and observe how far away it is from this line that we're evaluating. Let's call each of these distances e. So e sub 0 is that one, e sub 1 is that one. Can we come up with an equation in terms of e or error that gets us to this solution? Here's a quiz to get you thinking about that. So again, e is the error at each point. In other words, this is our original data point. This is the line that we're hypothesizing might be a good solution. And we can test how far off our model or our line is at each one of these points and measure that as e. So which of these formulae might be a good overall error measure? There could be more than one. So these two are reasonable answers. The reason that this one is not a good answer is because some of these e's may be negative. In other words, this one is negative, these two are positive, but you could end up with a negative error if you just added them up. You can fix that by adding absolute value or by squaring it. This measure here is one of the more famous one. Of course it's squared error. Let's step through this now with an example of how a minimizer would try to find the coefficients of a line that best fits this data. So keep in mind that we have to give the minimizer an equation that it has to minimize. And what we're going to give it is that error metric. In fact we used squared error. So we might guess an initial C0 and C1 and that would be a line like this, and we would give that to the minimizer and let it go. So it would measure the error with this particular line, it would fiddle with these values a little bit and see how much the error changed, try a new set of values see how that works. And eventually it's going to iterate, and eventually it's going to settle on what it thinks is the best solution. So key points here are that we express the problem for the minimizer as a minimization problem and we give it the equation to minimize as the error. And then, what it finds now instead of x is it finds the values for these coefficients. So, let me show you how to do that now in code. Now we'll look at some example code that can fit a line to data that's given. Remember, we're using a optimizer to do this. And first thing we have to do is describe for the optimizer what is the function it's trying to minimize. So we'll call this function error, and it takes two parameters, line and data. Line is just two coefficients, C0 and C1. And data is just a list of data, of course. Well, we've got some nice comments here that explain it, but really, our error is expressed simply in this single equation. We have the value of the actual data at each point here, minus the estimate that the line we're currently looking at would give at that same point. So we use the 0 coefficient, and the 1 coefficient, times the x value of the data at that point. So we take those differences and square it, and that's our error function. And that's what we're trying to minimize. We've added some code to illustrate how to use the minimizer to find the equation of a line. We start with our original line that the minimizer doesn't know. So, it's our secret, [LAUGH] but we're testing it to see if the minimizer can discover the equation of this line. Here's the equation for our line. It's just a two element array. It'll have a slope of four so coefficient zero is four. And Y intercept of two. So coefficient one of two. Here we generate X and Y values. Again keep in mind our minimizer doesn't know these but we are just generating them so we can look at them and we are plotting them for looking at it later. We take that original line and we use from numpie the random function to add some noise to it. So at each point along the X-axis, where we have data, we add some noise. So, now we've got our original line, plus some noise, and we're going to challenge our minimizer to find the equation for that original line, even though there's noise. We wrote a separate function fit_line that takes the data and the error function we defined and finds the equation for that line. Here's fit_line it does that for us. Two parameters the data, remember this is noisy data that is approximately a line and in other words we took our original line and added noise to it. And the error function, or the function we're trying to minimize. We have some nice comments here that tell us what those are, but now we just follow the steps like we've talked about before. We start with an initial guess. Here our initial guess is a slope of zero, and a mean of the rest of the data as our y intercept. It could be anything really, but that is a reasonable guess. We plot the initial guess so we have something to look at, and I'll show you that later. But here really is the meat of the function. You've seen it before. So we call our minimize function with the error_func. In other words, this is the function we're trying to minimize. Our initial guess, and this is a parameter you haven't seen before, but this is a way by which we can pass the data to our error function. This is the method that we're going to use. And finally although it goes off the end here. We'll set display to true, which will mean we'll get to see any information as it goes along. So that's it. I mean really the key here for this is, this minimize call right here and then it returns the result. So let's run it and see what we get. There was some additional code that I skipped over that generated this plot. You can look at that on your own, of course. Okay, let's take a look. Our original line is this blue line. Of course the minimizer doesn't know anything about that. These green dots are our noisy data where we just added noise values to the blue line. Now we're asking our optimizer, okay find the equation of a line that best fits this data. The metric you're trying to minimize is error. So we passed it in an initial guess here of this purple line and this data. So that's all it knows right now is this initial guess of a purple line and this data. And then it iterates and tries different slopes and different y intercepts. Until finally, it converges to this red line and that's the solution. And I think it looks pretty decent. We can check it here, so if you look in the code, you'll see that our real line had a slope of four and a y intercept of 0.5. So we've got 4.17 and 0.64, not exactly. But if you look at the data you can see that it's pretty hard to know exactly what the underlying line would look like. So, I think our equation solver did a pretty good job. We can fit even more complicated functions to data like this. I'm going to show you the code of how to do that in just a moment. But I wanted to start with sort of the result, and then go back into the code and show you how we did it. So our original polynomial is a blue line. It's under here. You can't quite see it. And the noisy data, or the green dots there. This purple line is our initial guess. And the fitted polynomial, the red line here, fits the original pretty closely. So let me show you a little more detail. Here is output from our program. This is our original polynomial. It printed in kind of a weird way. Our original polynomial is 1.5 x to the fourth, minus 10 X to the third minus 5 X squared and so on. Down here are the results of our optimization. So here's what we got instead of 1.5 for the fourth power, we got 1.6 Instead of -10 for the third power we've got -10.5 and so on. But overall, pretty close and as you can see by that chart I just showed you, you know, very nice fitting. Let's look now at how we do that in code. The code here for, a higher-degree polynomial is very similar to what we had for the line. Again, there's an error function we're trying to minimize. And we take in the coefficients for the polynomial and the actual data. And our error function is computed here. Again it's a sum of the difference between the actual data and the polynomial value squared. We take the sum of all those values and that's our error. So again very similar to what we did for the line. Here's our function that finds the coefficients of the polynomial has just a few parameters. The data the we're trying to fit our error function. In other words, how do we measure error and what are we trying to minimize? And the degree of the polynomial. We created an initial guess. In other words, what do we think the values of the coefficients are? And what we're doing here is we're just setting them all to be ones. We plot that, and then we call our minimizer, just like before. We have to tell it, what's the error function we're trying to minimize? What's our initial guess? We have to pass along the data, which then gets passed to the error function, and again, this method, SLS Q P and finally, you can't see it it is off to the side there, but same options essentially they are verbose options. And that's it that's how we use Python to create a model based on data. Let's review what we learned. I showed you how to use a minimizer to find x such that f of x is minimized. I showed you how to minimize in multiple dimensions. And how to use a minimizer to build a parametrized model. Where can you go from here? There are a number of ways you can carry this forward. You can use functions besides polynomials, you can model stock prices, or you can optimize a portfolio. Your final project in this mini course is to create a portfolio optimizer. That might sound like a tough problem, but you've already got the tools to do it. In this short lesson, we're going to lay the groundwork to help you know what portfolio optimization is and how to build one. First, what is portfolio optimization? Given a set of assets and a time period, find an allocation of funds to assets that maximizes performance. What is performance? We could choose from a number of metrics, including cumulative return, volatility or risk, and risk adjusted return, which is Sharpe ratio [LAUGH]. You can use any criteria you like, but for this assignment, we're going to focus on Sharpe ratio. Now, let me show you how to use a minimizer to optimize a portfolio. As an example consider this portfolio where we have Google, Apple, Gold, and Exxon from the beginning of 2010 to the end of 2010. This is what the performance of that portfolio would look like in the blue line, if we had an equal allocation to each asset. So, we gave 25% to each of those stocks at the beginning, and then we observed at the end, the total performance. And we include a chart here for S&P 500 for comparison. Now, this is an un-optimized portfolio. Here's what it would look like if we optimized for sharp ratio. Look at that. Look how much higher performance we get compared to our benchmark S&P 500. And observe over here the allocations to the assets. 60% goes to Gold, 40% to Apple and none to Google or Exxon. Now, one thing to emphasize here is, this is looking back in time, so we're looking back historically. What happened in 2010 and observing at the beginning of 2010, if we knew what we knew now, how should we best allocate? So, there's a question as to how much this can help our portfolio going forward. And I'll give you that answer ahead of time. Indeed, when we optimize for sharp ratio, hold that portfolio, rebalance, in other words re-optimize that sharp ratio and continue that month by month, we very often, most frequently see that that improves the performance of the portfolio versus just an equal allocation. But I do want to observe that this is computing back in time, so, yes, of course we can find a better portfolio, but indeed it helps going forward as well. Suppose I were to give you the following problem. Take these four stocks and over a particular time period, I want you to find the optimal allocation to those four stocks. I might ask you to find the optimal allocation that maximizes cumulative return, minimizes volatility, or maximizes Sharpe ratio. Which of these optimizers would be the easiest to write and why? The answer is, it would be easiest to write an optimizer that optimizes for cumulative return. Because all you have to do is find the single stock that maximized return over that time period. If you're going to optimize for minimum volatility or Sharpe ratio, you actually have to evaluate various combinations of those stocks. In this case the allocation would just be 100% to the highest returning stock. We're going to focus here on optimizing for Sharpe ratio. So solving that problem is not trivial, but it's not too hard either. What we need to do is frame the portfolio optimization problem as a minimization problem, and then we can solve it using the tools you have already. As you recall, in order to use a optimizer that minimizes, we have to do three things. First, we have to provide a function to minimize f(x) that takes in x, two, an initial guess for that x, and three, call the optimizer and let it run. Now, in this case, x are the allocations that we're looking for. And we want the optimizer to try different allocations in order to discover the best set of allocations that optimizes this function. Well, what is that function exactly? We said just a moment ago that we want to optimize for Sharpe ratio. So, is this just a Sharpe ratio? Well not exactly, because what the minimizer will do, in this case, is try to find the smallest Sharpe ratio. So it'll find allocations that minimize that. And we want, of course, the largest Sharpe ratio, because larger Sharpe ratios are better. That's easy to fix. All we do is multiply this by negative 1. So, all that we want our optimizer to do is optimize for a negative Sharpe ratio. And that'll find the best allocation or the best value for x to solve this problem. And remember, x can have multiple dimensions, so each dimension of x here is an allocation to each of the stocks. So, if we're trying to solve for a portfolio of four stocks, x will have four dimensions, and the value for each of those dimensions is the percentage of funds to allocate to each of those stocks. There's two more things you need to know about before you start optimizing portfolios. One of them will help your optimization run faster. And the other is essential for you to get the right answer. We'll start with the faster thing first. The first thing you can do is you can tell the optimizer that it should only look at certain ranges for X. In other words, for this problem, for each of the various allocations, it's only worth looking at values between 0 and 1. In other words, the value of 2 would indicate 200% of your fund is in a particular asset and that's not possible. It's only feasible to have 0% to 100% or 0 to 1 in each of these assets. So, you can tell the optimizer only focus on values between 0 and 1 for each of the dimensions of X. And if you do that, the optimizer can run much more quickly because it knows not to look at other values of X outside those bounds. It limits the search area significantly. Another thing you can do with the optimizers in numbpie are provide constraints. Constraints are properties of the values of X that must be true. As an example we want the sum of our allocations to add up to one. So let's say for example we're for portfolio of four holdings. So we have X0, X1, X2, X3. We want the sum of the absolute values of those to be equal to 1.0. In other words, our total allocation should add up to 100%. The optimizers we use in this class have the ability for you to express that and that guarantees that at the end when it finds out the values for X, you end up with a total of 100% allocated to the various assets. Now we're going to show you how to do these two things in the assignment text itself, because the syntax is a little bit tricky and we want to convey to you exactly how to do that. So we look forward to seeing you solve this problem and good luck on your final project. Welcome to the first lesson of computational investing. My assumption in terms of learning goals is that you want to be a portfolio manager. What is it you need to know, and what motivates you? It depends on what type of fund you manage and what your incentives are. Your motivation is probably compensation. And your compensation depends on the type of fund you manage and how well your fund performs. As I mentioned, we're assuming that you want to be a portfolio manager of some sort and there are several different sorts of portfolios you might manage. So let's take a look at a few of those. There are many different types of funds, of course, but three broad classes that we'll take a look at are ETFs or exchange-traded funds, mutual funds, and hedge funds. Let's look at the differences between these. ETFs, or exchange-traded funds, are very much like stocks in the sense that you can buy and sell them. You can observe their prices intraday. You can trade them just like stocks on the stock exchange. They represent baskets of stocks. Sometimes they represent other instruments like bonds and so on. But it's very well-known and they publish what it is they're holding. Accordingly, ETFs are very transparent and they're very liquid. Mutual funds are somewhat similar to ETFs in the sense that they have a declared goal or mechanism. In other words, they're, for instance, trying to track the S&P 500 or some other such goal, but they're a little bit different. First of all, you can only buy or sell mutual funds at the end of the day. So at the end of the day they add up all the things they hold and compute a net asset value, and that's the value at which you can buy or sell shares of a mutual fund. They don't disclose exactly what they're holding except once every quarter, so they're accordingly less transparent. They're less transparent because since their last disclosure, you don't know exactly what they might have bought or sold. Still, they're somewhat transparent because they have stated goals and you know what they're trying to achieve, similar to, say, an ETF that might represent the S&P 500. There are also mutual funds that represent large cap stocks like the S&P 500. Hedge funds are even less transparent than mutual funds. In fact, even to buy shares in a hedge fund, you have to enter into an agreement that is usually secret in the sense that you're not supposed to reveal the contents of that agreement. It's hard to exit a hedge fund. They usually require you to put your money in and leave it there for some number of months, sometimes years, and when you take it out, you can't necessarily take it out all at once. Hedge funds don't ever have to disclose what they're holding, not even to the investors in the hedge funds. Now, that might dissuade you from wanting, say, to invest in it if you don't know what they're holding. On the other hand, you know, if they show you a good performance, you might want to invest. They will usually describe to clients what their strategy is and so on to encourage clients to invest. Accordingly, hedge funds are not transparent at all. I mentioned a couple words while I was describing these different kinds of funds that I wanted to touch on real quickly. I said liquid a couple times. What that means is the ease with which one can buy or sell shares in a particular holding. Stocks are extremely liquid. ETFs are liquid in the same way, in other words you can go to a stock exchange, you can buy an ETF and sell an ETF. It's priced just like a stock, but when you buy it, you're buying shares of multiple stocks instead of just a single stock. But ETFs are liquid because they're easy to trade. They're also liquid in many cases because there's so much dollar value trading in them each day. If you look up an ETF on say Google Finance or Yahoo Finance, you can see how much volume is traded each day. And ETFs with higher volumes are even more liquid. I mentioned large cap. What cap means here is capitalization or in other words, how much is the company worth according to number of shares that are outstanding, times the price of the stock. So, some really huge cap stocks, say like Apple are worth many, many billions of dollars. So when I say large cap stocks, that's what I'm referring to. There's also small cap stocks that are similarly, have lower value. And one thing to mention as long as we're on this topic, is the price of a stock really only relates to what one share is selling at. It doesn't relate to the overall value of the company. We'll get into all of these topics a little bit later. Now to recap, there are at least these three types of funds. There are electronically traded funds, which you can trade like stocks on a stock market. There's mutual funds, that are a little bit harder to get in and out of, but you can trade them on a daily basis. You usually have to go through a specific broker. You can't just trade them on your own, and finally hedge funds require a specific agreement to trade into or out of. Okay, those are the three major types of funds. I want you to fire up your web browser, and do a little bit of research. Take a look at either Yahoo Finance or Google Finance, and you'll find the answer to this question. I want you to look at each of these five funds and determine is it a ETF, a mutual fund, or a hedge fund, and fill in the text in each of these little boxes with an E if it's an ETF, an M if it's a mutual fund, and an H if it's a hedge fund. Again E, M or H. Now as you might have discovered, these four- or five-letter symbols represent particular funds. So VTINX is a mutual fund. DSUM is an ETF. FAGIX is another mutual fund. You probably discovered the Bridgewater Pure Alpha doesn't have one of these symbols, and that's because it's a hedge fund. These guys have symbols, these short several-letter abbreviations, so that they can trade more easily on exchanges that have hundreds and thousands of different assets that are being traded. Whereas when you go to engage with a hedge fund, it's just a one-on-one relationship. Hedge funds typically have no more than 100 investors, whereas all these other types of symbols have thousands and maybe even millions of investors. Finally, SPLV is an ETF. A couple of other things to mention. It's fairly common practice that mutual funds have five letters and ETFs have four or three. Again, you can see this mutual fund has five letters. And this is another ETF with four letters. Okay, on to more fun. We talked already about some of the differences between Exchange Traded Funds, Mutual Funds, and Hedge Funds. And those differences that we talked about are primarily having to do with how they're traded and how visible, what their holding is to those who invest. Another very, very important sort of difference is how are the managers of these funds compensated? In other words, there's some sort of rule for each one that shows how the fund managers make money. And that's very, very important because the manner in which they're paid incentivizes them to trade or act in certain ways. So let's talk about each one of these individually. Before I get started, though, I have to introduce one concept here. It's called assets under management or AUM. And this is the buzz word that simply means how much money is being managed by the fund? It's important because for all of these part of the compensation is a percentage of the AUM. The managers of ETFs are compensated according to an expense ratio which is simply some percentage of AUM. Expenditure issues for ETFs are usually pretty low. They vary from as low .01% or, one bit as that might be called, to as high as 1%. But one that's up to 1% is fairly high and pretty unusual. Mutual fund managers are also compensated using an expense ratio. These are somewhat higher than ETFs. They range from a low of, typically, about 0.5%, to some that are very high, up to 3%. Now, what's the reason for this difference? Well, mutual fund managers will tell you that the way they manage funds requires much more skill. They have much more discretion than those who are managing ETFs. ETFs usually are tied to an index. As an example, a popular ETF, SPY, is supposed to track the S&P 500. And, all that an ETF manager has to do in that case is just make sure that they are holding all the stocks and the S&P 500. Mutual funds, on the other hand, supposedly use more skill and therefore, they can charge a higher expense ratio both were the cost of research and also for their skill. Finally Hedge funds are completely different breed in terms of how their manager's are compensated. You follow the old model called two and twenty which means 2 or 2% of AUM, plus 20% of the profits. So as you can see, it's higher than both of these other methods. And most importantly, it includes this component relating to profits, that 20%. Now, one or two other things to clarify here. What I've been talking about is the way that the folks who manage these funds are compensated. Separately, if you are an investor in one of these funds, in other words you give your money to one of these types of funds to be managed, your return is based on how much the value of that fund increased and in most cases that increase is subject to what happens to the economy or what happens in the markets. Let's look at a more detailed example of this two and twenty structure. Consider this example for the 2 and 20 situation. Assume you're a hedge fund manager and that you've been managing a fund of $100 million, and that over the course of a year your skill has resulted in an increase in value of that fund by 15%. So over that year, the fund grew in value from 100 million to 115 million. What would you're compensation be? So it's 2% of AUM plus 20% of profit. The two component works out to be $2 million. The 20 component is 20% of the $15 million profit we made which is 3 million. So total compensation for this year for the hedge fund manager would be about five million dollars. Now one question that some people might have is, hey is this two component 2% of 100 million or 2% of 115, and it depends on the hedge fund of course. And it depends on when they take snap shots to do accounting. The full answer is probably it's going to be a blend somewhere between 100 million and 115 million. This structure Two and Twenty has been assailed lately and it's very rare now to find a hedge fund that offers rates that high. They're much lower now. One and Ten. Things like that. So the Two and Twenty was in the heyday of hedge funds in the 90s and early 2000s. Nowadays they are typically a little bit lower. There are some Star hedge funds that charge more. For instance, ASC Capital, which is no longer operating to the public anyways, that charge as much as 40%, so it was 4 and 40. However, most hedge funds you find today will be somewhere between Two and Twenty or lower. I want you now to think a little bit about these incentives that we talked about. I want you to think about if you were a fund manager and you had one of these incentives, what would it incentivize you to do? So for instance, think about making profits. If you believe that an expense ratio compensation structure more strongly motivates profits, then click there. If you think two and twenty is a stronger motivation, click there. Now it's okay, if you think it's about equal or there's no difference, for you to click both. Give it a go. With regard to accumulating assets under management, the expense ratio approach really most strongly motivates that. Although I wouldn't count too much off if you also clicked two and twenty because of course the two part of two and twenty is assets under management. But, if you were strictly driven by expense ratio, you're going to be applying most of your energy towards accumulating assets so that you'll have a higher return. In other words, as a portfolio manager, you'll get more money. Profits are different, ETF's and mutual fund managers are not compensated for making profit. Especially when you consider, say, ETFs, exchange traded funds. They're just supposed to track a particular asset or index, and they should be good at that. It's not up to them whether that index goes up or down. So two and twenty is the structure that most compensates for profit because it has this twenty component that is indeed part of that profit. With regard to risk taking, an expense ratio based fund really is not incentivized to take risks at all. If they take risks, there's no compensation for it. Under the two and twenty model though, they are incentivized to take risks because that's how they can get to profits. Also, because they're always going to get this two percent, even if they take huge risks and don't make a profit, they're always going to get that two percent. So they're incentivized to take a risk because A, there's not too much of a penalty and B, if they take a risk and make profits, then they'll be compensated more. >From here on out I'm going to assume that you want to be a hedge fund manager. And one of your first tasks as a hedge fund manager is to get investors. So who might your investors be? There are three major types of investors in hedge funds. Of course, there's others besides these, but these are the three main types. Individuals, in other words, a single person that wants to invest in a fund. Of course, these are typically very wealthy folks. Keep in mind that hedge funds typically can only have up to 100 investors. So they want each of those investments to be fairly large so that they can manage, of course, a significant amount of funds. So the individuals who invest in hedge funds are typically, as I said, very wealthy. Institutions. What do I mean by Institutions? These are things like very large retirement funds, like CalPERS out in California. These are university foundations like the Harvard University Foundation or the Georgia Tech Foundation. In other words, institutions, very often non-profit institutions that have a large sum of money that they need to keep somewhere. And of course, they'd like to see an accrual in value, so that's one reason they look to hedge funds. And finally, funds of funds. What funds of funds do is they group together the funds of many individuals or institutions. So for instance, you might be an individual that could, say, invest in one hedge fund, but you'd really like to get the advantage of investing in several funds. So you might allow your money to be collected by a manager of funds of funds. And then that manager would gather together all these assets and pick carefully several hedge funds to invest that money in. So besides knowing who your investors might be, it's critically important to know why they might invest in your fund. How can you present the case to them that will convince them that they should let you manage their money? Here are at least some of the criteria that folks like this would consider before investing in a hedge fund. Track record. So if your fund has a great track record, that's, of course, some of the best evidence that it's going to continue to work well. Many institutional investors will want to see a good track record for at least five years before they'll invest in a particular fund. Now if you're a young whippersnapper hedge fund manager and you don't have five years yet, what are you going to do? Well, what you can do is simulate or back test your strategy, and investors will consider these simulations. But that simulation has to be backed by a very compelling story describing that strategy. In other words, you've gotta have a reason for why this method works and it needs to make sense. And finally, they consider how your strategy fits within their portfolio. In other words, if your strategy is for large cap S&P 500 stocks, and they've already got that covered with another fund, they might not consider you. However, if you, for instance, are looking at small cap growth stocks, and they don't yet have that part of their portfolio filled, they'll give you some more thought. So, when an investor is considering a particular hedge fund, they want to know, what are the goals for the hedge fund? And they'll also want to know the results of certain metrics. Let's take a look at goals first. Now, you might say, of course, my goal is to make money. Well, it's a little bit finer than that, or a little bit more subtle than that. There are, of course, other potential goals, but these two are the primary types of goals that hedge funds go after. One type is to beat a benchmark. What does that mean? Let's suppose, for instance, that you've got a strategy that looks at the stocks that are in the S&P 500, there's 500 of them of course and you're especially smart at picking out the good ones. So you might build a hedge fund who's goal is to beat the S&P 500 index as a benchmark because you're wise at selecting among all those, which stocks are going to outperform? And, of course, the over all index has the good stocks and the bad stocks, so you're going to do better because you picked the specific good ones. An important component of the benchmark model is that many benchmarks, like the stock market as a whole, for which S&P 500 is a good representative, go down. And it is of course natural that a portfolio consisted of stocks from this index might go down as well. So, even though both the index and the fund go down, you can outperform the index by going down less. So, this kind of fund that is tagged against a benchmark can still meet performance goals if it goes down. So long as that index is going down more. That brings us to absolute return funds. Their goal is to provide positive return no matter what. These funds are usually long/short, which means they make positive bets in stocks they think are going to go up. And they make negative bets in stocks are going to go down. We'll talk about shorting a little bit later. In any case there objective is to make slow gradual positive return no matter what. Often, these types of funds don't make the same percentage gains as the beat a benchmark fund, but they have very low draw downs. In other words, when the market takes a bit hit, they often don't. The next question is well, how do we measure how well that fund is meeting those goals? We talked about these metrics in the mini course manipulating financial data in Python, but we'll repeat it just a little bit here to remind you, and also to bring those folks up to speed who didn't necessarily have the previous course. Cumulative return is a measure of, given the funds I started with, how much more did I end up with after a certain amount of time? So suppose we have and in the array of values of our portfolio, where zero is the first value, and minus one is the very last one. We can easily compute cumulative return by dividing that last value by the first value and subtracting one. So for instance if we made 20% over a year this would end up being 0.2. Volatility is a measure of how rapidly and aggressively the portfolio goes up and down in value and of course lower volatility is better. Volatility is simply measured as the standard deviation of daily returns. Our last factor here which is a measure of the ratio of risk to reward is typically measure using sharp ratio, and the sharp ratio is calculated like this. Sharp ratio is also sometimes called risk adjusted reward. So, you can consider that to be reward divided by risk. A reward is our average, daily return minus the risk-free rate. And our risk is simply a measure of that standard deviation of daily returns or volatility. We multiply that ratio by the square root of 252. That is how many trading days there are in a year and remember we're always working with daily returns. So that's why we use this 252 number. So recapping, hedge funds have goals, typically either to meet a particular bench mark or to gain absolute return. And then metrics by which we judge how well they accomplish those goals. So, cumulative return, how much do they make over a period of time? Volatility, how volatile were they over that time? And then risk adjusted reward or sharp ratio. One thing I want to mention before I leave this topic with regard to benchmarks is the benchmark you choose should depend on the expertise you have. So let's suppose you're an expert in Eastern Europe. And you're great at picking stocks in emerging markets in Eastern Europe. You should select some benchmark that represents that similar kind of investing. And there are indexes that represent emerging markets in eastern Europe. There are also other funds who's values you might use as a benchmark or let's say your expertise is in banks. You might choose an index for the banking industry and show that you can beat that. Hedge funds are among the most computationally demanding environments I know of. They have infrastructure requirements like huge databases, significant network connectivity, low latency and high bandwidth connectivity, real-time processing, and so on. I want to show you as an example, the typical kinds of computing that goes on inside a hedge fund to motivate you for this class. In other words, this isn't exactly the way all hedge funds work, but this is just to give you a taste for how many hedge funds work. And you'll see, I think, that computing and computational capabilities are core here. So we're going to work backwards from the market back towards the sort of back office of the hedge fund. The way things work are we have certain portfolio that is which stocks we have and whether we're in positive or negative positions with regard to them. The trading algorithm here is central. It's interacting with the market, observing the live portfolio. And what it's trying to do is to get this live portfolio to match some target portfolio. So somewhere further back inside the hedge fund we've decided what this target portfolio ought to look like. In other words, how many shares of Apple, how many shares of Delta Airlines we should have, and so on, and this trading algorithm is trying to get us there. So it's comparing target with live. And then to move this portfolio towards that target, it's issuing orders. So it sends order like buy 200 shares of Apple to the market. Those orders get executed or not, and that updates the live portfolio. Now one reason this kind of trading algorithm is important is you don't want to execute everything at once. In other words, suppose we wanted to take a very, very large position in Apple. If we were just to send an order, hey, buy me 10 million shares of Apple, that would affect us detrimentally in the sense that the price for Apple would probably rise. And we would not get a good execution. So this training algorithm takes those sorts of things into consideration as it moves our live portfolio to be more close to the target portfolio. In fact, sometimes it takes days to enter a particular position. So this doesn't necessarily happen all at once. And there's many, many different types of trading algorithms that have been invented to solve these problems. Now let's step one step back into the computing of the hedgefund, and look at how we arrive at this target portfolio. Here's that target portfolio, and here is some of the data and computing that could go into computing that target portfolio. So from somewhere, machine learning perhaps, we have a forecast of what stock prices are going to be at some time into the future. And that can of course drive what our target portfolio ought to be for today. In other words, if we're forecasting that BAC is going to go up, this might represent that we think it's going to go up 5%. We might want to increase our holdings in that. If we think that Apple, for instance, is going to go down, we might want to decrease our holdings. So this forecast informs this algorithm called a Portfolio Optimizer. That works to balance the risks and rewards for a balanced portfolio that considers volatility and correlation between different stocks and so on. We're going to talk a lot about portfolio optimization later in this course. Some other considerations that go into Portfolio Optimizer are historical data, open, high, low, close, and volume. We can look at that historical data to inform how stocks are correlated or uncorrelated to one another, and also of critical importance is our current portfolio. It may be the case that if we're holding something, we don't want to exit it immediately because we'd be penalized by rapidly selling it. So this optimizer takes all this information into account to get to the target portfolio that our trading algorithm is working to drive us towards. Now one more stop along our road here at the computing infrastructure of a hedge fund is to look at how do we come up with this N-day forecast. By N, N might be five days or ten days or whatever. So here's this N-day forecast, and we've got some kind of forecasting algorithm. This is very often in the form of a model, in fact, a machine learning based model. And creating these sorts of forecasting algorithms using machine learning is the focus of the last mini-course in this group of mini-courses. Anyhow, how do we get to this forecast? Well, we've usually got some sort of proprietary information, again, historical data, and our forecaster crunches all that data to build a model and create a forecast. So, bringing it all together, that's the computing in a hedge fund. And we've also spent some time talking about what might motivate you as a hedge fund manager. That's it for this lesson. I'll talk to you again soon. You may have experienced trading stocks over the Internet, using a platform like E-Trade, Interactive Brokers, or another online broker. What happens when you click buy? It's probably a lot more complicated than you think. The way that you build a portfolio, or buy stocks that you hold in your portfolio, is by issuing orders. Usually you send those orders to a stock broker, and they take care of executing them for you. We're going to dive now into the details of what happens when you create an order, and how it gets to the market and back. And how things can go wrong, and how they can potentially go right. The first stop there is to think about what is actually in an order. What are the components of an order that can go to a stock exchange? Here is all the information that must go into a well-formed order. First of all, I need to know are you looking to buy or sell shares of a stock? Next is the symbol. This is an identifier for the stock or perhaps ETF that you want to buy or sell, for instance IBM or SPLV. Next you need to tell your broker how many shares you want to buy or sell. Stocks and ETFs and other assets are sold in units of shares, not by amount of money. So you don't tell your broker I want $100,000 worth of Apple, you tell your broker I want a thousand shares of Apple. Next, you need to tell your broker whether this is a limit order or a market order. Let's start with market first, market means you're willing to accept a good price but essentially whatever price the market is currently bearing. And I'll show you in a moment how that's determined. A limit price means you don't want to do any worse than a certain price. For instance, suppose you're selling some stock. You might specify I don't want it to be sold below a particular price. Or if you're buying stock, you might say, I don't want to pay more than a certain amount to get it. If you're issuing a limit order, then you have to say what the corresponding price is. If it's a market order, you're not able to specify that price because essentially when you issue the market order you're saying I'll take whatever price comes back. Let's take a look at a couple example orders. Here's one. Buy IBM, 100 shares, limit, 99.95. So this means I want to buy 100 shares of IBM at no more than $99.95. Another example, sell Google, 150 shares, market. Notice there's no price with this because we're going to take whatever the market price is. So let's look at what happens when these orders reach the exchange. A key construct at most exchanges is something called the order book. Each exchange keeps an order book for every stock that they buy or sell. And here's how it works. Let's suppose you've just issued an order to buy 100 shares of IBM with a limit price of 99.95. And let's suppose for the moment that this arrives at the New York Stock Exchange and so far today nobody's put in any orders. So your order is the first one and they'll use it as the basis to start building their order book. So yours is the first entry in the order book. And it simply shows somebody has bid 99.95 for 100 shares of stock. And this is public knowledge. People can view this and see, okay, there's interest in buying shares of this stock. Now, they don't know who has made this bid. The exchange knows that it's you that's made that bid. But they see that there's interest in 100 shares. Now others may send in orders like yours. And this number just keeps getting larger depending on how many orders come in. When this is displayed publicly, people just see that okay, there's interest maybe from various people. And 1,000 shares of IBM at 99.95. So far nothing's been bought or sold yet though because we don't have anybody willing to sell. Well, let's suppose a sell order comes in. Sell IBM 1,000 shares, limit of $100. Well, there's nobody willing to buy 1000 shares at $100. So, the exchange again, is going to have to add this order to it's order book. And this will be our first ask. We've got now our first ask as part of our order book. Now let's say more and more orders come in. And it fleshes out our order book a bit. Here's our order book as it's fleshed out a bit, as orders have come in. We've got a number of asks, which are requests to sell stocks, and a number of bids, which are requests to buy. Suppose now we get a market order to buy 100 shares of stock. Here's our new order, and here's what happens. The Exchange looks at it's order book and it sees, yes, we have lots of shares for sale here. We have to give the client the lowest price so we'll give that client 100 shares of these that are priced at $100. So, that means now we've only got 900 left here, we take that 100, give that to the client who put in the order and this is the state now of our order book after that transaction. Consider this order book now for a moment. Look at how many shares we have for sale and how many shares people want to buy. Do you think the price of this stock, in the next few minutes, assuming this order book, is the price going to go up or down? Check the box that you think is correct. The correct answer is that the stock is probably going to go down in price, because there's much more selling pressure. Imagine for a moment if we put in two market orders. Suppose there was a market order to sell 500 shares. What would happen? Boom, you would sell 100 at 99.95, 50 at 99.90 and so on, the price would immediately go down. Consider on the other hand if someone put in a market order to buy 500 shares, well the price wouldn't budge. You'd just get 500 of these 1000 for sale but the price would still remain between $100 and 99.95. I'll explain that a little bit more as we provide some specific examples on what happens to the order book as different orders come in. Okay, so to understand better how the order book works and how exchanges work, let's look at a couple more example orders. For brevity I'm leaving out the symbol IBM. This is all about IBM, so just keep that in mind. Okay, so a market order comes in to buy 100 shares at market. So again, we see that there's 1,000 shares that people are willing to sell. And the exchange has to give the best price to the client, and so we give the client 100 shares at this price. So what happens, the order comes in. 100 shares go away. And now the order book has changed just so that there's 900 shares available here now instead of 1,000. And the execution price is $100. Let's consider now a limit order. Someone wants to buy again 100 shares at a limit of 100.02. So, again looking at the order book, again, we can satisfy that order and, again, at $100. So we're saying that we want to pay no more then $100.02. So again, we can execute at 100, and now this goes down to 800 shares instead of 900 being available. And the execution price for this transaction again, is $100. And note also that that's less than that limit price of $100.02. Let's look now at one last order, a market order, where someone wants to sell 175 shares. So that comes in. And we have 100 shares available at 99.95, so those get sold. And there's none left there at that price. So a 100 shares get executed at 99.95. So to get this 75 more shares, we need to go deeper into the book. So we'll take these 50, 0 left there. We still need 25 more shares to meet this order for 175. So we go even deeper into the book and take some of these. So after all these transactions, the order book has been changed quite substantially. And this client gets a 100 shares at 99.95, 50 at 99.90, and 25 at 99.05. So all together, there's some average price at which this was executed for that client. Note now that as time has gone on, the executed prices have been decreasing. Clearly we're seeing that's a consequence of there's much more sell pressure than buy pressure. So that's how the order book works and how exchanges use order books to facilitate transactions between their clients. This is what an order book looks like in real life. Here in the middle, we have prices. And on either side here, we see the order sizes. We're seeing here, sell orders and how large they are, and on this other side, buy orders and how large they are. And the prices that they're being executed here are in the middle. And as you can see, it's changing dynamically and rapidly as trades are executed. Here we see a price chart showing how the prices is going up and down as these trades are being executed. So that's a live order book. This is using the trading platform called Think or Swim. We've talked about what orders are and we've talked about what happens to them when they get to the exchange. Let's talk now about how do the orders get to the exchange from you. Well, here you are with your laptop connected to the internet and you've just entered an order to buy some stock. Your buy order goes over the internet to your broker. Your broker in turn is connected to several exchanges and the broker determines where to route your order based on information it knows about the exchanges. Let's suppose the exchanges we're looking at are New York Stock Exchange, NASDAQ and BATS. For the stocks you want to buy, each one of these exchanges has its own order book. Your broker has a computer located at each exchange and it queries the computer to say, hey, look at the order book and tell me the prices there. Query has added all the exchanges and your broker gathers and examines that information and based on that, routes your order to the exchange that has the best price. Let's say that's New York Stock Exchange. Your order enters the exchange, gets executed and the price comes back to your broker and forwarded back to you and you get a confirmation. Now it turns out that because this is happening constantly all the time, there's multiple brokers, hundreds of thousands, millions of people making orders that the order books at each of these exchanges tends to be pretty similar. In other words, the prices don't differ much between one or another and it's this sort of pressure that keeps prices the same across these different exchanges. Let's consider another scenario. Suppose there's another client of this same brokerage, Joe and that Joe wants to sell some stock. Well, the brokerage can observe, hey, I've got some clients who want to sell, some clients who want to buy. I can just make that exchange internally and I don't even need to go to the exchanges. This can be advantageous for the broker, because a broker doesn't have to pay now fees to the exchanges for this transaction to occur. However, according to the law, both the seller and the buyer have to get prices that are at least as good as they would've gotten if they had gone to an exchange. And eventually, at the end of the day, this transaction has to be registered with one of the exchanges. Usually, it's recorded at the exchange where that particular stock is homed. Let's consider one more example. In this case, Lisa also wants to sell some stock, but she uses a different broker than you do. There's one more kind of entity out there called a Dark Pool that acts as an intermediary between brokerages and exchanges. So the Dark Pool is looking at the order books of the various exchanges and they're often making predictions about which direction stocks are going to go. They actually pay the brokers for the privilege to look at the orders before they go to the exchanges. And if they see an advantageous trade, they'll go ahead and take it. So in this case, this cell might be routed through the Dark Pool from broker two to broker one. And again, the transaction never makes it to the exchanges. In fact, these days, 80 to 90% of what they call retail traders orders never make it to the exchanges. They're either executed internally within a brokerage or filled using a Dark Pool. The brokerages in the Dark Pools argue that, that's just fine, because both partners in this transaction are getting prices at least as good as they would get at the exchanges on the order books. But they're saving money, because they don't have to pay the exchange fees. We've talked so far about how the exchanges work and how the order book facilitates transactions at the exchanges. Now we've talked about how orders get to exchanges or not. Now, lets take a look at how hedge funds can exploit inefficiencies in this system. Okay, let's suppose you live in Seattle and you want to make an order. You look at the prices on your computer. You see what you think looks like the prices are going to go up. So you enter a buy order. Now your order travels all the way across the country. And because you use ETrade it stops in Atlanta, and then it hops to New York City. Let's now zoom in and see what's happening at the Exchange in New York City. So, we've zoomed into the New York Stock Exchange, and the order book there is visible to you over in Seattle, but also to computers that are colocated. So, let's suppose our hedge fund has a colocated computer. And it's observing the order book as well. Now here's the advantage that this colocated hedge fund has. It's computer is located maybe a 100 meters away from the main exchange computer that holds the order book. So that 100 meters amounts to 0.3 microseconds in terms of how long it takes information about the order book to reach that hedge fund computer. You, on the other hand, are located at least 2500 miles away. And that means when this order book changes, it takes 12 milliseconds at least for that information to get to you and 12 milliseconds at least for your order to reach the exchange. So, here's how what I call the order book exploit works. The hedge fund is continually observing the order book. And remember, it takes only 0.3 microsceconds for it to do that. Based on what it sees at the order book, it thinks the price is going to go up. The hedge fund buys some of that stock based on what it sees. You're thinking the same thing, so you've entered buy. And your order starts making its way across the country. While your order is coming across the country, indeed, the price is going up, because other orders are coming in from other places. Eventually, your order makes it to the New York Stock Exchange and is executed there. And, in fact, the hedge fund sells it to you. And over this few fractions of a second, the hedge fund has bought some stock, watched it go up and sold it. It might have held this 100 shares of stock for only a few milliseconds and made a profit. And the hedge fund is exploiting essentially all these people remotely located around the country observing the order book, essentially late sending in orders that it can take advantage of because it can act much earlier before those orders from around the country arrive. There's certainly many sorts of ways to exploit market mechanics. Here's one more. I call this one the geographic arbitrage exploit. Suppose we have exchanges located some distance away and because they're located distantly prices may drift a little bit up or down. Now a hedge fund might place their own servers at each of these Exchanges and connect them with an ultra high speed dedicated connection. And they're observing the order book, the prices at both these locations all the time and comparing notes. Let's suppose a difference emerges that in New York the price is a little bit lower, in London price is a little bit higher. The fund will immediately buy in New York, and sell in London. They're not necessarily even transferring those same shares. They might buy some set of shares in New York City, and sell a different set in London. But they're getting that difference in price advantage immediately. Now, because hedge funds do this, because they're monitoring the prices that exchanges all over the world, these sorts of differences rarely arise and when they do it's just by fractions of a cent. But those differences do arise because there are inefficiencies in the markets and there are hedge funds there to pick those pennies up off the ground. Again, this is geographic arbitrage. Now you may have heard of other types of orders besides just buy and sell, market and limit. It turns out though that the exchanges only execute these types of orders. They don't execute those other types. Well, you might wonder, okay, how do those other types of orders come into being? These other types of orders are implemented by your broker. The way that works is you enter this order type and I'll give you a couple examples in just a second. The broker holds that order and watches the market until the conditions that you specified are met and then when those conditions are met, the broker sends your order to the market accordingly. So here's some examples. Stop loss is a kind of order where you say when the stock drops to a certain price, I want you to sell it. Stop gain. Similarly, when the stock reaches a certain higher price, I want you to sell it. Trailing stop is a combination of stop loss but also an automatically changing value for when that criteria is met. So for instance, you might have this trailing stop remain say, $0.10 behind the price. So as the price goes up, the value at which you would want to sell the stock goes up along with the price, but when it drops down below. Then that stop loss is triggered. But probably the most important and most impactful kind of order the brokers implement for you is something called selling short. What selling short allows you to do is take a negative position on a stock, in other words, you sell a stock short if you believe its price is going to go down. Keep in mind here we're selling stock we don't even own. So how is that possible? Well, again, it's possible because the broker facilitates it for you, and I'll explain how in just a minute. Okay, I'm going to step you now through the mechanics of short selling. Pay attention because it's complicated. [LAUGH] Okay, let's imagine the following scenario. You want to take a short position in IBM, and IBM is currently selling at $100. That's the current market price. Joe holds 100 shares of IBM. He likes IBM, he wants to hold onto it. But he's willing to lend you those shares of IBM. In fact, Joe's broker will take care of that for him. He may not even know that he's lending you the shares. Let's suppose Lisa thinks that IBM is going to go up and she wants to buy IBM. So you want to sell IBM short. You don't own any shares of it. Lisa wants to buy IBM. She thinks it's going to go up. So here's what happens. You borrow that 100 shares from Joe. Now that you have those shares, you can turn around and sell them to Lisa. And in exchange for those 100 shares that you gave Lisa, she gives you 100 times $100, or $10,000. So let me recap that. You want to sell IBM short. Joe has 100 shares of IBM. Lisa wants to buy IBM. So you borrow those 100 shares from Joe. You immediately turn around and sell them to Lisa, and you get $10,000. The result of this transaction, after everything settles, is you have $10,000 in your account but you owe Joe 100 shares of stock. And of course, Lisa has 100 shares of stock and so on. Now the problem sort of arises here that Joe may decide he wants his 100 shares back. What you'll have to do is go buy them from someone and then give them back to Joe. But let's deal with that a little bit later. Let's suppose you've been watching IBM. It's reached about $100, and you'd like to short it because you think it's going to go down. Suppose you shorted it right here when its price was $100. Now you're in that short position. You watch the stock for a few days. It goes down to $90, and you decide, okay, I want to exit. So you submit an order to your broker to close out your position by buying out those 100 shares and you do it at $90. The question is, what's your net return? Did you make money? Did you lose money? What's the total return in dollars of this transaction where you short 100 shares when it's at $100 and you buy to close when it's at $90? The answer is $1000. For each $1 the stock drops in price, you make $100 because you've got 100 shares. So altogether, the stock dropped in price $10, you had 100 shares so your net return is $1000. All right, let's recap what happened. You borrowed 100 shares from Joe, so that's indicated by this sort of empty box here. You sold those 100 shares to Lisa. So now you have $10,000 in your account, but you still owe Joe those 100 shares. Let's suppose that since that time, IBM has dropped in price and now it's selling at $90. You can make a profit from that, and you want to go ahead and exit. So you approach Lisa and say, hey, can I buy those 100 shares back? And she says, no, I want to keep IBM. Well, that's a little bit of a problem, but fortunately, there's lots of people who have shares of IBM and would be willing to sell them to you. So Lisa's now out of the picture and not part of this transaction anymore. But, there is somebody else out there, Nate, who's got a hundred shares and he's willing to sell them. So you buy a hundred shares from Nate and give them back to Joe. So your obligation to Joe, is now completed. IBM was selling at $90 so you had to give Joe $9000. But remember you had $10000, so the net result after everything is said and done is you've got a $1000. And you don't have any obligation any longer to Joe. So that's how short selling works. Now I personalized this story by talking about Joe and Lisa and Nate and so on. In reality you don't have to make these personal agreements with any of these people, your broker makes all that happen. Your broker is sitting here in between all those actors and making all this happen for you. Well this all sounds wonderful doesn't it, what can go wrong? Let's roll back time a little bit. Let's go back to where we had $10,000 in our account and we owed Joe 100 shares of stock. What can go wrong? What if, instead of going down, IBM went up to $150 per share, and now you want to exit your position? Well, again, you go to Lisa and say, hey, Lisa, do you want to sell me your shares? She says no. Well, Nate is still out there, he's willing to sell. So again, you buy those shares from Nate then you return them to Joe. But this time it costs you $15,000 because the price has gone up. And remember, you've got only $10,000 in your account. So the net result after all this is said and done is that you're out $5,000. So if you bet wrong when you short a stock and the price goes up, you lose money, and it can be significant. So to recap, we've gone through many of the different aspects of the mechanics of the market. We've shown you how hedge funds exploit the market. We've shown you different order types. And we've shown you especially the details of short selling. I'll see you at the next lesson. I'd like to show you this cool machine I have. In fact it's one of my most prized possessions that my great uncle gave to me before he passed away. Let's pretend that this machine represents a company, and that I'm the CEO of that company. This company can take raw materials like this paper, and process them, and turn them into dollars. Here's how it works. So, each year, this company can output a dollar bill reliably. What is this company worth? So think about that last segment. What is a company worth if it provides one dollar every year guaranteed every year in the future? What is that worth if you could own that company? So here are a couple of potential answers. One it's worth one dollar. Another at towards $70, because after that I'll be dead. Not me. I'm living beyond that. [LAUGH] Another is while I'm getting a dollar a year forever, so it must be worth an infinity number of dollars. And, finally, this company that produces $1 a year forever is somewhere between $10 and $25 depending on interest rates. So all of these answers are possibly correct depending on your point of view. I think this one is the most correct and will be covering that in this lesson. But some of these other answers could be reasonable as well, so don't feel bad if we scored you wrong. So in a moment, we'll address how you estimate the value of that company that generates $1 per year. In other words, that dollar bill machine. Before we dig into that, lets spend a moment considering why does it matter how much a company is worth? This course is about buying and selling stocks, so we're going to look at why company value matters with regard to buying and selling stocks. Of course, we want to buy a stock when the price is too low and we want to sell it when it's too high. In general, the value of a company goes up monotonically. In other words, it is always increasing over time. Let's assume for a moment, this is the true value of that company. We'll address in a little bit what true means, but let's assume for the moment that we have some understanding of the underlying real value of that company. Now that true value is distinct and different from the value estimated by the market. In other words, what price the stock market says, it's worth? So on one particular day, maybe the price is higher than the true value. On some other day, maybe it's lower and on some other day, it's the same. Very many trading strategies, which is what this course is about, focus on identifying situations where the current stock price is different from the true value. So in other words, if the stock price goes up a lot, but we know the actual company is only worth a certain amount. When it goes up high, that might be a selling opportunity. In other words, if we see the price up here and we know the true value of the company is down here, sell it. And similarly, if we see the price really low compared to what the company is worth, that could represent a buying opportunity. There are many, many ways that we can estimate the true value of a company. We're going to touch on a few of them in this lesson. One is intrinsic value, this is based on the value of the company as estimated by future dividends. In other words, companies pay many companies not all, pay each year or each quarter a dividend. So it's a cash payment, if you own a share of stock, you get a certain amount of dividend. For instance, for Apple this year, it's about $2 per year. So intrinsic value is based on, if we own one share of stock, we're going to get some amount of dividends accumulated over all of the future. What's the value of the company based on that? Another is book value, which is based on the assets that the company owns. So in other words, we add up the value of all the factories that they own and so on. Finally is market cap. This is based on the value of the stock on the market and how many shares are outstanding. So in other words, this relates to what is the market think the company is worth? This relates to what's the value of the sum of the assets? And this one relates to, well, if I own a share of stock, how much money am I going to get over the future? And what's that worth overall in the future going forward? We're going to consider now the intrinsic value of our one dollar machine. In other words, this machine generates one dollar every year. Now to understand that, we need to think about what is the future value of a dollar. What do I mean by that? Well, let's suppose I told you, hey look, awesome student, I promise I will give you $1 in a year. How much would you pay me today on the basis of that promise? In other words, maybe you would pay me 80 cents, and then in a year I give you $1, maybe you would pay me more. Think for a moment about how much you would pay me given my promise that I'll give you a dollar a year from now. Okay I want you to consider these three assets. One of them is a dollar right now, in other words I pull a dollar bill out of my pocket and I give it to you right now. Another is, I, Tucker Balch, promise to give you a dollar in a year. Now that's a promise you can abide by, you can trust me, I'm your professor, I'm going to give you that dollar in a year. But what you need to think about is, what's the value of that promise or that bond, considering that it won't happen for a year. And finally, consider this asset where the US government promises to give you a dollar in a year. Now I want you to rank each of these assets, a one dollar bill, a United States of America bond, or a Balch promise, a Balch bond, to pay you $1 in a year. How would you rate these one through three where one is the best, where three is the worst? How would you rank these three assets? In other words, which would you rather have if you had to choose one or the other where one is the best and three is the worst? So the answer is a little bit subjective, depending on how much you trust me versus the United States government, [LAUGH] but let's start with number one. The absolutely no question the most valuable asset among these three is number one, $1 right now, because you can take it, you can go with it, you can spend it. These other two are promises for a reward in the future. Now among these two, I personally would value myself as number two, but it's probably more correct to say that the US government promise to give you in a dollar as the second most valuable. And then of course I am number three. It should be obvious now that the value of a dollar delivered in the future, even if it comes from the US government is worth less than a real dollar right now. A real dollar right now is worth $1. If I promise to give you a dollar in the future it's not worth as much. So how should we estimate or think about the value of dollars delivered in the future? I think we've also agreed that the United States government, promising to give you a dollar in the future, is worth a bit more, than the promise of Tucker Balch giving you a dollar in the future. But having a real dollar in your hand right now, this one, is worth the most. Why is that? You know intuitively why that is. The deeper reason is there's a chance that I won't deliver on that guarantee whereas we can be pretty sure that the U.S. government will deliver on that guarantee. So it amounts to risk. And it all boils down to interest rate. We're trying to figure out the present value, or PV of a dollar that will be delivered in the future. So it's worth some fraction of this future value. Present value is worth some fraction of the future value. So here's the formula in it's entirety. Present value is equal to future value divided by 1 plus interest rate raised to the i. So the i is how far into the future this payment is going to be delivered. So for instance, if it's going to be delivered right now i is equal to 0 this whole component becomes 1 and present value is equal simply to future value. In other words, if we're going to pay a $1, present value is worth $1, if in the future that future is going to be 1 year from now. It's 1 plus the interest rate, raised to the 1th power. And that is what the future value of that dollar is. So, let's work out an example. Suppose with the United States government, because they're so trustworthy, you can negotiate a 1% interest rate. Actually, as of today, which is 2015, this 1 year interest rate is only one-quarter of a percent. In order words, interest rates are very, very low. If you work it out, the value of a $1 bill paid to you in the future, 1 year from now, at a 1% interest rate is $0.99. In other words, today, it's worthwhile for you to pay $0.99 to the US government for the promise that they'll give you a dollar in a year. Okay, consider now the Balch Bond. So it's hard for me to sell you this asset right now for the same price as the US government because if you had to choose between me and the US government for a 1% return, why wouldn't you choose the US government? You should go with the US government because they're more trustworthy than I am. So, how can I attract you? Well, I can offer you a higher interest rate. Let's say 5%. And that works out to a value of about $0.95. In other words, in order for me to attract you to buy my promise for $1 in the future, I could only charge you $0.95. So let's consider this in a chart form. So how much is $1 worth if I promise to give it to you today. Well, in that case, this i is equal to 0, so the present value is equal to the future value of all this divided by 1. So in all cases, if the number of years we're going to wait for the delivery of that dollar is 0, the value is $1. But what if we talk about promising you that dollar in the future. If we look at this for the US bond, in 1 year we see it's worth $0.99. If we carry that forward, it's sort of this exponentially decreasing value like that. If you look at the Balch Bond, which is, of course, not as worthwhile as the US government, you see one that decreases at an even faster rate. So in other words, at each year in the future, this $1 is worth less. In other words, if I promise to give you $1 in two years, it's worth less than, if I promise to give you $1 in a year, it's worth even less than if I promise to give you $1 right now, and these charts are different depending on what the interest rate is. In other words, for the higher interest rate assets, they decrease further into the future. In other words, a dollar delivered in the future is worth less now than the lower interest rate assets. Think back now to our original problem. What is the present value of a future dollar, FV, delivered some number of years in the future, where i is how many years it is? And we use IR, or the interest rate, as a factor that affects this value. The analogy for this to real companies is that real companies pay dividends. In other words, if you own a share of a company, you will get some cash payment each year or each quarter. As an example, if you own one share of Apple stock, it pays you about $1 a year. Consider that you'll get that payment every year into the future. What is the value of that payment over time? What this interest rate relates to is how risky the company is. In other words, you're as sure that it's going to pay you that dollar every year as you are sure that the US government would pay you a dollar on a bond. Then, this IR interest rate should be the same as the US government bond rate. However, if you're less certain that this company is going to pay you at that rate, this interest rate needs to be a little bit higher. In other words, you need to expect that the company is going to pay you more in the future or that it's going to be more likely to pay you that dollar in the future. This is called the discount rate. The discount rate is higher if you trust the company less or you think it's more risky. The discount rate is lower if it's more certain to pay you that dividend every year. Let's suppose that after considering all the factors, you feel that it's appropriate that a company should pay you a 5% interest rate considering its risks. Now based on that, if you want to calculate what the value of the company is based on the dividends it's paying, you can take that into account in the following way. Essentially, what you want to do is compute what is the value of all the future dividends that it's going to pay me? So that's the sum of the dividend it'll pay you in a year. The dividend it'll pay you a year after that, and the year after that, and the year after that. In fact, you want to sum those all the way out to infinity. So what we're looking for is the sum of this equation, but over all i going into the future. We can draw on this infinite sum, in other words for i = 1, 1 year to infinity years, of the sum 1 over n to the i. So this n here is this value, and we can replace 1 here with future value. So this is not a math class, I'm just going to give you the answer. The answer is that this infinite sum, in other words, some future dollar paid each year in the future over an infinite number of years, is that value divided by n minus one. Which is equal to future value divided by discount rate. So in the case of our dollar machine, we're paying one dollar each year in the future at 5% interest. So the value of our dollar machine is $20 overall. What we've just described, where future value is the dividend we're going to pay at regular intervals and DR is discount rate. In other words, what the risk of the stock equates to in terms of an interest rate we should pay. This equation tells us the intrinsic value of the company. In other words, if we're going to pay that future value or dividend every year or every quarter going into the future, what's the value of the company on that basis, this is intrinsic value. And in the example of the company we were talking about, that creates a $1 every year. It's the value of the $1 in one year from now, next year, next year, next year, next year, continuing ad infinitum into the future. And that's 20 bucks. Let's check your knowledge now. Consider a company that pays $2 per year in dividends, and a discount rate of 4%. What is the intrinsic value of this company? The answer if you recall is that the present value is equal to the future value divided by the discount rate. So we've got $2 divided by 4%, or $50. Answer is $50. Now if you recall from the beginning of the lesson, we talked about three major ways to estimate value. One is intrinsic value, which we just covered. Another is book value, which we're going to cover now. And the other is market capitalization. So let's take a look at book value. Here's a classic definition of book value. It's total assets of the company. In other words, things like property that is owned and so on, minus intangible assets and liabilities. Intangible assets are things that are difficult to put a price on. They're things like the value of a brand, or a pent, or so on. Liabilities are a little bit easier to calculate, those are just things like loans that are owed and so on. So, let's consider what's the book value for an example company. Let's say that a company owns four factories, and that each of these factories is worth about $10 million. These are assets, and altogether they are worth about $40 million. Suppose this company also holds three very important patents and each patent is valued at about $5 million. The value of these patents is about $15 million, but these are intangible assets that are hard to price exactly. Finally, suppose this company has one large loan. This would be under the liabilities column of $10 million. If we follow this rule that book value's total assets, so total assets are this $40 million plus the $15 million or $55 million, minus intangible assets so we just don't count these intangible assets. And liabilities. So all together we've got our total assets minus intangible assets, which is $40 million, and liabilities minus this $10 million, so in this case this company's book value is $30 million. The third way of estimating company value is simply to let the market decide. And that's called Market Capitalization. This is a simple calculation, Market Capitalization is just equal to the number of shares that are outstanding times the price. So, in other words, you can look at the stock market and see what the current price is and see how many shares are owned by people. And it's just one times the other and that's the value of the company in terms of market capitalization. If you follow the stock market, you may have noticed that when news comes out about a particular company its stock price can change considerably. Why is that? Well, the stock price is of course the main mechanism by which investors can essentially let their view of the stock be known. In other words, If they think that the company is buying less, they're going to sell and the prices are going to go down. If investors think the value of the company should go up, they're going to buy the stock and the prices are going to go up. Now, why is it that this information or news affects the stock price. It's based on these things that we've covered up to now in the lesson. In other words intrinsic value, book value, and well of course, market capitalization. But let's take a look at how it affects, say, intrinsic value. Consider a company run by this CEO and assume for the moment, that his business, his company, is to grow and sell coconuts. What if the following news comes out? The CEO is ill. Maybe he has cancer, maybe he has something else that prevents him from collecting those coconuts as effectively as he might otherwise do. Well, certainly that should affect the stock price downward because the probability that we are going to get dividends in the future is decreasing. Either that or the amount of the dividends is going to decrease. So, if you think back to the intrinsic valuation that we talked about. The potential for reduced future dividends reduces the value of the company significantly. Now consider another scenario where's there's an island with our original company and another company. And news comes out about the soil on the island being contaminated. That news is going to affect not only our original company, but also all the other companies on the island. So you can think of this sort of news as being sector news. In other words it relates to the sector of growing coconuts on this island and it affects all the companies in this sector. Lets consider one last scenario were we have many islands with many companies on those islands. And news that might effect all of them like sea level rising, that is going to negatively impact all of these companies. So we have examples here of companies specific news that affects the price of an individual company. Sector-specific news that effects, say, the companies on a particular island or in a particular industrial segment. And market-wide news that affects all the companies in the market. So that's how news can effect the prices of the stock. Primarily because they reduce the expectation of future dividends. We've seen how that can affect the intrinsic value and accordingly, why people would want to pay less for that stock. Now I want you to try to pull all this together that we taught you so far in this lesson. I'm going to give you some specific details about a particular stock and I want you to tell me if you would buy that stock. And give you information about the company, which has one value and the stock which is not necessarily the same. And I want you to tell me, would you buy that stock. We're going to break it into a few individual problems, three little problems and then we're going to ask the big question. We'll start with the three little problems. Consider this company. It's an airline. It owns ten airlines. Each of them is worth 10 million. It's got a brand name that's worth 10 million, and it's got a loan or liability of 20 million. All those go into the calculation of the book value. With regard to intrinsic value, it pays $1 million per year in dividends assuming a 5% discount rate. What's that intrinsic value? Finally, I want you to compute the market capitalization assuming there's one million shares outstanding and $75 stock price. Okay, for book value, brand name doesn't count because that's an intangible asset. So we've got 10 airplanes at $10 million each, that's $100 million. And we've got a $20 million loan liability. That means the book value for this company is $80 million. Intrinsic value, we calculated that before. It's just $1 million divided by 5%. The intrinsic value then is $20 million. Finally, market capitalization, remember that's just the number of shares outstanding times the stock price and in this case, that's $75 million. So let's go back to that original question. Assuming this company has a book value of $80 million, an intrinsic value of $20 million, and a market cap of $75 million. And by the way this means that you can buy the entire company for $75 million. Our question is, would you buy this stock? And more specifically, would you buy this whole company for $75 million. Yes or no, would you buy this stock? So maybe you felt like it was a tricky question, because the intrinsic value is so low. It's not tricky. Here's why. You should absolutely buy the company. You should buy the whole company for $75 million. And then you should break it apart and sell all of its individual assets for $80 million. And your net return is an immediate $5 million. This is why stocks very, very rarely go below their book value. Because if they ever go very much below their book value, a predatory buyer will buy the entire company. They'll buy all the stock. Break it up and sell it for pieces. I know that's kind of depressing, but that's the way it is. Let's wrap up this lesson. We've talked about three key ways to compute the value of a company. Intrinsic value, which is based on future dividends. In other words, companies pay a certain amount to their investors every year, based on how many shares they own. And this is the value of all future dividends going into the future. Book value, which is the value of the company if we split it up into pieces and sold those individual pieces. And finally market capitalization which is simply the value that the market is placing on the company. So, many stock trading strategies look for deviations between say, intrinsic value and market cap if intrinsic value drops significantly and the stock price say is high, it may be worthwhile to short that stock. Or if say dividends are going up and the market capitalization is low it might be an opportunity to buy the stock. And similarly book value provides a sort of lowest price, when stock price begins to approach book value, you can pretty much assume that the price is not going to go below book value. Or not much below it, because if it does, a predatory buyer would buy the whole company, and break it up for parts. Anyhow, that's company valuation. And I look forward to seeing you at the next lesson. Bye bye. In this lesson, we're going to cover one of the most significant ideas affecting finance in the last century. It explains how the market impacts individual stock prices. And it also provides a mathematical framework for hedge fund investing. It's called the capital asset pricing model or CAPM for short. It was developed by a number of researchers independently in the 1960s. William Sharpe, Harry Markowitz and Merton Miller jointly received the nobel prize for this contribution in 1990. The CAPM led to the development of index funds and the belief that you can't beat the market Before we launch into details of the capital assets pricing model, we have to lay down a little bit of groundwork. Let's start with the definition of a portfolio. A portfolio is a weighted set of assets. So as an example, let's suppose you've got a portfolio that's got three different assets in it, Apple, Google, and Oracle. And if you look at the entire value of your portfolio, let's suppose that 60% of it is in Apple, 20% is in Google, and 20% is in Oracle. If we consider this as a set of weights, that means we've got 0.6 in Apple, 0.2 in Google and 0.3 in oracle. So, the first part of our definition of a portfolio is that w sub i is the proportion of funds that are an asset i. We require that the sum of all these w sub i is equal to 1, in other words they add up to 100%. Now sometimes, for leveraged portfolios that we're not going to cover in this class, this number might be greater than one. But skip that for now. We do allow that you might short some stocks. So for instance, let's suppose you shorted Google. Your allocation there would be, minus point two. So, let's refine this equation a little bit and require that the sum of the absolute value of the weights is equal to one. So, some of them might be short, some of them might be long. But, if you add up the absolute value their weights will require that to be 1.0. So now that we've defined what a portfolio is, let's think for a moment about what will the returns on a portfolio look like. So, it's a simple equation, really. It's the sum for each asset of the weight of that asset in the portfolio, times the return for that day, of the asset. We just add all those up, one by one, and boom, that's the return on the portfolio for that day. Okay, let's suppose you've got two stocks in your portfolio. Stock A and Stock B and 75% of your portfolio is in Stock A and -25% is in Stock B. In other words, you've taken a short position in Stock B. Now let's suppose on a particular day Stock A goes up 1%, and stock B goes down 2%. What's the return on your portfolio if this occurs So remember from our equation on the previous page that the return on the portfolio is the sum of each return times the respective weight added together. So the weight for Stock A is .75 times 1% and the weight for Stock B is negative 25%. The return was negative 2% for that stock also. So because we shorted B and it went down, we got a positive component there, or .5. And our long on A adds up to .75 so our total is 1.25. So a concept that's important to the capital assets pricing model is this thing called The Market Portfolio. Now what is that exactly? When someone refers to the Market what they're usually referring to is an index that broadly covers a large set of stocks. In the US, best example of that is the S&P500. The S&P 500 represents the 500 largest companies that are traded on exchanges, and that index changes each day according to the prices of all of its components. There's similar indexes in the United Kingdom, Japan, any country or large market has indexes that represent this. Now, these indexes are composed of many, many individual stocks, and the market portfolio is a combination of those stocks in a certain weighting. Most of the important indexes are what we call Cap Weighted. And what that means is the individual weight of each stock in the portfolio is set according to that stock's market cap. So, market cap, if you recall, stands for Market Capitalization, and it's simply the number of shares available for the stock times its price. So to calculate the weight for any particular stock, you take its market cap and divide it by the sum of the market caps of all the stocks. Now, if you think back to my example of the CEO living on an island building his product, and there being many islands and an ocean and when market forces rise of fall that affect all of the islands, you can think of these large indexes essentially as being an ocean. Now within each of these oceans if you like, there are a number of sectors. For instance, in the US we typically break the market into ten different sectors, I list four of them here. Energy, technology, manufacturing, finance and so on. And these are essentially the islands. So, if some malaise occurs to, say, energy stocks, you can think of that as something bad happening to the energy island. These things might be Saudi Arabia is pumping more oil, so the cost of oil is going to go down. That usually would have a negative impact on energy, so the energy island would be negatively impacted. Same thing with these other sectors. The main point here being that positive and negative news can affect each of these sectors individually without necessarily affecting the others. So it's not unusual to break up these large markets into individual sectors. Now just recapping before we depart, when we talk about the market portfolio in this class, we are almost always talking about the S&P 500. And that market portfolio consists of 500 stocks, the largest stocks in the U.S. that are traded publicly, with a weighting set like this. One thing to keep in mind Is some stocks have surprisingly large weightings. For instance, Apple and Exxon each are about 5% of the S&P 500. So those two stocks have a strong effect on what happens to this index. There are smaller stocks that comprise say only a tenth of a percent of the overall effect on this market. We're finally able now to get to the core of the capital assets pricing model, and that's expressed in this single equation that's really important. You need to memorize it and understand it. And here's what that equation is. So the capital assets pricing model says that the return for an individual stock on a particular day t = beta times the return on the market. So, I told you just a moment ago, for instance, that the, when we say the market in the United States, we're usually referring to the S&P 500. And this particular stock, i, is one of the stocks in the S&P 500. So its return on a particular day, again, is beta times the return on the market of that day + alpha of that particular stock on that day. So what the capital assets pricing model is asserting, and this is important, is that a significant portion of the return for a particular stock is due to the market. In other words, the market moving up or down strongly affects the change in price on every individual stock. And the extent to which the market affects a particular stock is encapsulated in this beta which we'll talk about in just a second. But every stock has its individual beta that specifies how much it's affected. Many stocks have a beta near one which means when the market goes up or down 1%, that stock goes up or down 1%. But if you had say a larger beta, say two, that means if the market goes up 1% we would expect, all else being equal, that the stock goes up 2%. This other component, alpha, is called the residual. So of course, if you look at all the stocks over one day and look at how much the market goes up or down, and you calculate how much the stock should have gone up or down according to beta. Well there'll be something left over. It won't exactly match what beta predicted. And that's what this alpha or residual component is. An important part of the capital assets pricing model is that the expectation for alpha is 0. Essentially this is a random variable with an expected value of 0. It's important to remember that. Where do we get this beta and this alpha? Well, it comes from daily returns and essentially how the daily returns for a particular stock relate to the daily returns of the market. So look at returns here for S&P 500, and consider the S&P 500 in comparison to this other stock xyz. So xyz, its daily returns are shown here in green. And blue shows S&P 500. Now look at each day, seems that the xyz stock is more reactive. In other words, if S&P 500 goes up a little, this stock goes up more. And, on average, it tends to have a higher return each day. We can look at what happens with the returns on each day and plot them over here in a scatter plot. So on this particular day, the market went up a little bit, and xyz went up a little bit more. So that would correspond to a point right about there. Now, if we plotted the results for a lot of these days, we would get a scatter plot that looks a bit like this, where each green dot represents one day. And if we fit a line to it, we'd get something that looks about like this. So beta is simply the slope of this line, and alpha is simply this area here, in other words, the y-intercept of that line. Now this is an after the fact of calculation. In other words, just because historically a particular stock, looking back at time gave you a particular alpha, you shouldn't necessarily expect that in the future. And again, CAPM says that you should expect this to be 0. In reality though, it's not always 0. So, that's the key to the capital assets pricing model and where beta and alpha come from. Consider these two scatter plots. This one is for stock XYZ versus S and P 500. This one is for stock ABC versus S and P 500. And each one of these dots represents the return for S and P 500 versus ABC or XYZ for that particular day. Okay. So look at these two plots and tell me, which one has higher alpha and which one has higher beta? So recall that beta is the slope of the line and alpha is where it hits the y-intercept there. So, higher alpha. Well ABC is intersecting the y-axis there much further up than XYZ so ABC's got higher alpha. In terms of beta, look, the slope of ABC is much higher than XYZ so ABC also wins on the higher beta question. Now you may have heard about the debate of passive investing versus active investing. This question about passive versus active didn't really exist before the capital assets pricing model came out. And I'll explain why in just a moment. But let me just briefly tell you about passive versus active. So passive essentially says that you should just buy an index portfolio. Like buy something that represents the S&P 500, and hold. Just sit on it and let it grow. Active portfolio managers don't just buy the index portfolio, they pick individual stocks. Another way you can think of this is if you compare the active managers portfolio to the index. You'll find that he or she has higher weights for some stocks and lowers weights for other stocks. Of course those weights could be zero, or even negative. But the general idea here is that the active portfolio manager's portfolio differs from the market portfolio by selecting different weights on different stocks. Let's return now to the capital asset pricing model here, and consider passive versus active in that context. Both active managers and passive managers agree with this part of the equation. In other words, however the stock moves each day is most significantly influenced by the market, and that the amount that it moves is strongly related to beta. Where they differ is with regard to their treatment of alpha. The CAPM says two important things about alpha. First, it's random. You can't predict it, and the expected value is zero. Some days it'll be positive, some days it'll be negative. It may be large, it may be small, but it's random. And on average, it's value is going to be zero. Active managers, on the other hand, believe they can predict alpha. In other words, they can compare two stocks and they say I think this one is going to go up relative to the market. Remember, this alpha is market-relative. Or, I think this other stock is going to go down relative to the market. Now, they might not be exactly right on every single pick. But they believe on average they're better than just flipping a coin. So if you believe what active managers say, you can use information and perhaps machine learning to find stocks that have either positive or negative alpha. And you can use that information to select your stock picks. And we'll show some examples of that later on. Anyways, if you believe the capital assets pricing model, in other words this alpha is fully random, then you should be a passive investor. Just buy an index and hold it. If you believe active managers, that they can find alpha, then you should consider being an active investor. Suppose now that instead of just looking at one stock, you want to think about a portfolio. And remember that a portfolio is defined by the various weights that indicate how much of your funds you've allocated to each stock. So recall that for an individual stock, i, it's return on any particular day is Bi times return on the market for that day plus alpha for that particular day. So, to compute the return for the entire portfolio, we compute this return for each individual stock, multiply it by the weight for that stock and then we take the sum across all the stocks. And that's what we get for the entire portfolio. Now if you note we can calculate beta for the entire portfolio simply by doing this. Beta for the overall portfolio is simply a weighted sum of the individual betas for each of the stocks. So the capital assets pricing model tells us that we can simplify the expected overall return for a portfolio by computing a beta for that portfolio, multiplying it by the return on the market and then there's some alpha. So that alpha is composed of multiple example. So this alpha, remember capital assets pricing models says that all of these are on average going to be zero, so we don't need to bother necessarily adding them up, we can just approximate it by an overall portfolio alpha. So again, this is what the CAPM tells us we can expect on any particular day, and again, CAPM asserts that this alpha is random with mean 0. The active portfolio manager will say, okay, yes, I agree that the beta component is the same as CAPM at pricing model says. But I think I can find value in this alpha and it needs to be broken out individually. So the active portfolio manager is going to have this formulation of what they could expect in return each day compared to the CAPM, which is a little bit simpler. So I want you to consider a little bit the implications of the CAPM, and I want you to consider implications in upward markets and downward markets. So here's the question. If we're in upward markets, do you want a larger beta or a smaller beta? And if we're in downward markets, do you want a larger beta or a smaller beta? And remember, CAPM says that alpha doesn't matter. So for upward markets we want larger beta, because that means we'll go up even more than the market if beta is greater than 1. If we have a smaller, that means we're not getting the full advantage of the market going up. In downward markets we want smaller beta. So for instance if the market goes down 1% and our beta is much less than one, that means our portfolio will go down less than 1%. So on a downward market, the smaller the beta the better. Let's summarize now the implications of CAPM. Let's start first with the equation. So the CAPM tells us that the expected return on our portfolio is the veta of the portfolio times the return on the market plus alpha of the portfolio. The first point, an important point, is that alpha is random, and the expected value of alpha is zero. So that excludes alpha from our toolbox of ways to make money. What's left? So the only way we can beat the market now is by cleverly choosing beta, so that when the market is going up, we choose a positive beta, and when a markets going down we choose a lower or even negative beta. So CAPM says the only way we can beat the market is with high beta and up markets and low beta and down markets. The only problem with that is the efficient markets hypothesis. We haven't covered that yet, but it's coming soon. But anyways, the efficient markets hypothesis says you can't predict the market. So, these avenues are not available to you, either. So, all these things taken together say that you can't beat the market. If the capital assets pricing model is true, we can't beat the market. Now, I don't believe that, and this whole course is about ways that you can potentially beat the market. So, we're going to get to those eventually, but we had to present the capital assets pricing model as a framework in which to consider all these other things. Now before we close, there's one other thing I want to touch on. It's called Arbitrage Pricing Theory. Arbitrage Pricing Theory was developed by Stephen Ross and first published in 1976. So Dr. Ross observed the CAPM as it was. But he said look, we have this single beta that represents a particular stock's relationship to the market. Maybe really we ought to have multiple betas. The CAPM is really only allowing us to consider a stock in the entire ocean. And his idea, if you continue the sort of analogy we've been doing in this class, is that we ought to consider the different islands. In other words, a particular stock might have exposure to different aspects of the market. So, the stock might have some exposure to finance, so we could compute the component of return due to finance via the beta with regard to finance and the return for finance of that day. So we could compute for each stock, for each sector, and individual beta. And so his assertion was that by breaking out the betas into these different factors, we could get a more accurate forecast of what the return's going to look like. And of course we still have our alpha over here. We're not going to use APT in this class, but since we've been going forward with this analogy of oceans and islands and so on, I wanted to bring it to your attention because I thought you might find it interesting. Okay, that's it for the capital assets pricing model. I'll see you again soon. The typical hedge fund develops methods to find stocks they think will perform well. The informational edge that they're seeking is usually market relative, meaning they're looking for stocks that will go up more than the market. If the market goes up, your stocks will go down less than the market if the market goes down. If this information they have is reliable they can take advantage of the cap m to virtually guarantee positive return. In this lesson I'll show you how all of that works. As an illustration of how hedge funds use CAPM, let's consider a two stock scenario. So our hedge fund has done some research maybe they've used machine learning, maybe they've used some other method or maybe they've just thought very hard and for whatever reason they predict that stock A is going to go up 1% over the market in the next ten days. And they've looked backwards in history and observed that the beta for stock A, with regard to the market, is 1.0. So plus 1% beta of 1.0. They've looked at another stock, B, which they predict to go down 1% whichever way the market goes, it'll go 1% below it. And the beta for stock B is 2.0. So this introduces for the first time this idea of a long short portfolio. In other words, we think that stock A's going to go up, so we should long it. And we think stock B's going to go down, so we should short it. And there's some strong advantages to this long short approach that'll begin to emerge as we go through this lesson. So we're going to talk a look at a couple scenarios with these two stocks to see how we should best allocate between the two. So looking back, this is what the S&P 500 has been doing. Remember stock A has a beta of one, so it follows what the S&P 500 does pretty closely. Stock B, on the other hand, has this beta of greater than one, or two. And so it's reacting much more wildly than stock A. Here's our first scenario. Let's assume the market stays flat, in other words it returns 0% over these following ten days, and that we enter our positions as of this day and our positions are going to be a $50 long position in stock A and a $50 short position in stock B. Now assume going forward also that our predictions are perfect. That A goes up 1% over the market and B goes down 1% below the market. What will happen? Well, if our predictions were perfect, stock B should go down 1% below the market, and stock A should go up 1% above the market. What does that mean in terms of how much money we would see returned? So if we look at stock A, and remember we're using the CAPM, we should expect to see the return for A as beta of A times return on the market plus alpha. So, the market didn't move at all so this gets nullified so alpha for A is one percent and we invested $50 in that so our return is $0.50. Similarly for B, this element is removed because our return was zero and all we're left with is alpha. Now essentially our alpha here was negative and we made a negative bet, so our return is 0.5 or altogether $1.0 or 1% for our total investment. I'd like you to consider another scenario now. Instead of the market staying flat, what if the market goes up 10%? I want you, for stock A and stock B, to compute the expected return pecentage-wise and then also in terms of dollars. And then compute the total for both down here at the bottom or, in other words, what's the return on your portfolio. Let's start by taking a look at stock A. So, market one up 10%, we predicted that A would go up one percent over the market and its beta is one. So, we should see a return of about 11%. So, we get 11% here and $5.50 here. B is a little bit more tricky. Remember, B has a beta of two. The market went up 10%, so B's going to go up 20% minus the one percent we thought it would do relative to the market. So for B, the stock price went up 19% but, we had a negative bet there, so we get negative 19% here. So, we're going to lose $9.50 on that bet. Now, to compute the totals here, let's do the dollars first. So, we made $5.50 on stock A, but we lost $9.50 on stock B, so altogether, we lost $4. Now, when you calculate the total return here, you can't just add these two up and get negative eight, because remember, we only had .5 over allocation in each one of these. So, to get the total, you multiply this return by .5, that return by .5, And you get negative four. Yes, it's a little bit tricky. Let's run through one more example here just so we get it straight. Let's assume now that the market goes down 10%. How does this all work out? Stock A should only go down nine percent, because we think it's going to perform one percent over the market and it's beta is one. Stock B is going to go down 20% and minus that one percent that we think is going to go below the market. So let's talk B is going to go down 21%. So we're going to lose nine percent or $4.50 on stock A, but we're going to really kick butt on stock B. Stock B went down 21%, but remember we shorted it, so we're going to get all together $10.50. So all together we're going to win six dollars or six percent. What's the take away here? The take away is even if we have perfect alpha and perfect beta, if we're not careful about how we allocate our money, we can still lose. How can we fix this? The CAPM can help. Let's pull out the CAPM and take a look at this portfolio. Remember for each individual stock, the expected return is beta times return on the market plus alpha times the weight for that particular stock and when we're short, the weight is negative. And we do this across the stocks in our portfolio. And then, that's our expected return for the portfolio. So, I'm going to expand this sum. First, I'm going to start with the beta component. So we get, weight a times beta b, plus weight b times beta b, times return on the market. So recall the numbers from earlier. Our weights for A and B were each .5 and -.5. We got a beta of 1.0 for A and a beta of 2.0 for B. For our alphas we had plus 1% for stock A and -1% for stock B. We can plug all these into our equation and work it out. For our beta component, we end up with a beta for the portfolio of -.5. Our alpha component for stock A ends up just being .5 and for stock B, -.5 times -1 or .5. Bringing it all together under these assumptions, using the CAPM, our expected return for this allocation is -.5 times a market return + 1%. Let's double-check this by plugging in one of our earlier examples. Consider that example where the market went up 10%. So we've got -.5 times 10% + 1%. So in the case where the market goes up 10%, we expect a -4% return for our portfolio. So if you step back a little bit, remember that we arrived at this 1% using information. So we have some information about these stocks that lead us to believe one would go up 1% over the market, another would go down 1% over the market. On the other hand, we don't really have any knowledge about what's going to happen for the market over all. So we have no control over this component. Is there some way that we can remove this? Can we make this part equal to 0? If we can do that, then we essentially remove market risk from our portfolio. And we preserve this 1% over here. Well, the way to do that is to focus on this part. Remember, this is beta for the portfolio. Can we make beta for the portfolio = 0? Or in other words, can we find weights for A and B, such that their sum turns out to be 0? What are these two weights so that the overall portfolio beta is 0? Suppose we have two stocks, our stock A and our stock B. These are the same two stocks we've been working with. A has a beta of 1.0 and alpha, our prediction of +1%. B has a beta of 2.0 and a forecast alpha of negative 1%. So we want to go long on A and short on B. The question is what should the weights be so that we can minimize or eliminate market risk. Okay, so we want to find two weights, A and B. Such that when you multiply them by their betas, the sum turns out to be 0. Now keep in mind, that we're going to short B, so this one needs to be negative. And we're going to long A, so this one needs to be positive. Just keep that in mind as we go forward so, let's solve for A initially here. So we know that the weight of A should be equal to -2 times the weight of B. We also know that the sum of A and B, well the sum of the absolute values of A and B, should be equal to 1. If we plug thi minus 2 weight of B and for weight of A we get this, or long story short. The absolute value the weight of B = 1/3. So I know the weight of B has to be negative, so we get minus one third for the weight of B. And coming all the way back up here, we know that the weight of A is equal to Negative two times the weight of B. So we get this. So finally, the answers are: 2/3 for the weight of A. -1/3 for the weight of B. Okay we've calculated these weights. Let's see how they work on the examples we've been looking at. So again our weight for stock A is going to be .66 and for stock B is going to be negative .33. And we're going to look at this scenario where the market goes up 10%. We'll pull out our old trusty CAPM and expand it for these two stocks. So for stock A we have the weight of stock A, times its beta times the return on the market, plus the alpha component. So these are the two parts that relate to the return on the market, and we'll bring them together. So for stock A we have 0.66, and our beta is 1.0. And for stock B we've got -0.33 times 2 times the return on the market. So because of all that work we did to figure out these values, we know already that this is going to become 0. We'll carry down our two alpha components, so for stock A, our alpha expectation is 1%, and our weighting is 0.66. For stock B, our weighting is negative one third, times -1, our expectation is just going to go down 1.0%. So combining these two, 0.66 plus 0.33 gives us a 1.0% expected return. Whichever way the market goes. Remember, we eliminated the return on the market. So, whichever way the market goes, we can expect to get 1% return. Now, need to add a lot of caveats here. These betas aren't necessarily fully guaranteed to continue into the future, and these alphas aren't guaranteed, either. These are just estimates that we computed based on information we thought we had, so this is not a guaranteed thing by any means, but it is a way to use long/short investing to reduce exposure to the market overall and to focus on those alpha components where we do have information. Let's bring it all together now, how hedge funds can use CAPM effectively. Assuming we have some sort of actionable information that we can convert into a forecast alpha, in other words, a prediction for a particular stock i, about which way it's going to go. And also the beta of that stock with regard to the market. We can do the following. We can minimize market risk by finding a beta for our portfolio that's equal to zero. And we can do that by finding the appropriate weights on each individual stock. So, CAPM can be a really valuable tool in terms of portfolio construction because it can enable you to build these portfolios that are less exposed to market risk. And this is where the whole idea of long short trading came about. You know, CAPM really enables you to refine that. All right, that is it for now. We'll see you again soon. Thank you. There are two broad categories of approaches to use for choosing stocks to buy or sell. They're based on Fundamental analysis and Technical analysis. Fundamental analysis involves looking at aspects of a company in order to estimate its value. Fundamental investors typically look for situations where the price of a company is below its value. Another camp is based on Technical analysis. Technicians don't care about the value of a company. Instead, they look for patterns or trends in a stock's price. This lesson will focus on technical analysis. Let's start by looking at a few characteristics of technical analysis. First, what is it? One of the most important things to remember about technical analysis is that it looks only at price and volume. That's as opposed to fundamental analysis that looks at fundamental factors, like earnings, dividends, cash flow, book value, and so on. Technical analysis is price and volume only. We look back at historical price and volume to compute statistics on this time series, and these statistics are called indicators. Indicators are heuristics that may hint at a buy or sell opportunity. Now there is significant criticism of the technical approach. Folks consider that it's not an appropriate method for investing, because it's not considering the value of the companies. Instead, maybe you could think about it as a trading approach as opposed to an investing approach. Still there are reasons to believe that technical analysis might have value and that it might work. First of all, there is indeed information in price and information in price change. It reflects sentiments of buyers and sellers, and especially if we see that the price for a particular stock is moving in a different direction than the overall market, that might be a hint that there's something going on. Additionally, we know that in other domains of artificial intelligence, heuristics can work, and they work frequently. So even though it's controversial, there are reasons to believe technical analysis can work. Okay, now that you know some differences between fundamental and technical factors, I want you to look at each one of these four factors and fill in the box, T for technical or F for fundamental. So, for each one decide wether its technical or fundamental and fill in the box. Remember that technical factors use only price or volume, whereas fundamental factors use other components. So moving average of price is only using price, so that one's technical. Percent change in volume is only using volume and that's allowed for technical factors, so that one's technical. This one is using price, yes that's technical, but it's also using earnings which is a fundamental factor, so that makes this whole thing a fundamental factor. So over here intrinsic value is based on dividends, which is a fundamental, so this one is a fundamental indicator. So over the last few years I've been using technical analysis a lot. I've also been using fundamental analysis. And people often ask me well, you know, when is one valuable versus the other. Let's look first at technical analysis and where it's effective. Here's some rules of thumb that I've built for myself over the last few years. First is individual indicators, by themselves, are weakly predictive. Now back in the 80's and 90s when some of these were creative, I believe they had stronger value. But since that time, more and more people have been trading according to them, and essentially the more people who are following a particular approach, the less value is realized by any person by themselves. So individual indicators are weak. However, combining multiple indicators adds value. I see over and over again that combinations of three to five different indicators, in a machine learning context, provide a much stronger predictive system than just an individual indicator. Another useful approach is to look for contrasts. In other words, look for one stock that has a strongly different indicator than another stock, or a stock that is contrasting to the market. In other words, if all stocks are behaving in the same way as the market, there's no reason to pick any one stock over another, but if you see certain stocks are behaving differently than the market then they are worth a further look. Finally, technical analysis generally works better over shorter time periods than longer time periods. To understand the value of technical analysis versus fundamental, it's valuable to consider the trading horizon. In other words when you buy a stock and sell it, what's the time period between those two activities. So, it can be milliseconds, maybe even smaller time periods. It can be days or it can be years. So, for instance, Warren Buffett often buys and holds stocks for years, high frequency traders are trading on the order of milliseconds. So to illustrate what I mean, consider Fundamental factors. If we are trading over a time period of milliseconds How much do fundamental factors contribute to the change in price over those short periods of time? When we're trading machines on the stock exchange, what really matters is what's happening there on the stock exchange. For instance, the order book or momentum and so on. So at these short time periods, Fundamental factors really have low value. Now consider all the way out to years, we know from, for instance, Warren Buffet's success, that fundamental factors over long periods of time may have significant value. What about days? Well, maybe over a period of days Fundamental factors do have value. So, imagine that we sort of chart it like this. Over long periods of time, fundamental factors provide a lot of value. Consider the same sort of chart now, but for technical factors. Let's start out over here, over many years. Think about if we make a technical analysis of a stock, what it's 20 day momentum is which we'll talk about in a moment. How much is that really going to affect the price of a stock years later. Very little. So over long terms technical analysis is not so valuable. Think back now to very very short periods of time. This is where technical analysis can shine, and it potentially has high value over very short periods of time. So we have a chart that looks a lot like the fundamental chart, but it's swapped. Let's consider a couple other factors. I won't draw the charts like these, but just think about these. So consider for instance, decision complexity. How complex is the decision to buy or sell a stock if you're going to hold it for years. Becomes more complex this way. How about decision speed? How fast do the decisions have to be made? Well, certainly, we have to be able to make the decisions really, really fast if we're trading at the millisecond level. And of course we can take a long time to make a decision if we're going to buy and hold for years. So as you look across this spectrum, consider where is the best region for humans to operate and where is the best region for computers to operate? Well, because at this very high frequency the complexity of decisions is simple. Computers can make this decisions very, very fast and that also happens to be where technical analysis has value which is the domain of the computer. So computers excel in this region of the chart. Over here where we can take a long time ti make a decision and the decisions are complex. This is the best region for human investors. So, if you look at different types of hedge funds the high frequency trading computer driven hedge funds are operating over here. The insight driven, human based hedge funds are operating over here. And then there's this region in the middle where we often see humans and computers working together. There are hundreds of technical indicators out there. We're going to take a look at just three because, of course, our time is limited but I will point you to resources online where you can learn about other indicators. Theres three are some of the most common and most popular that people use. The three we will look at are momentum, simple moving average, and Bollinger Bands. Let's take a look first at momentum. Momentum is really one of the simplest indicators, and it's just over some number of days how much has the price changed. So for instance, if we look at this point to this point, we've got positive momentum. Or if we were to look from here to here, we've got negative momentum. The steepness of that line is the strength of the momentum, either positive or negative. Now, in terms of using this in a trading strategy, there are many folks who look at the momentum for a stock, the recent momentum, and if it's positive they buy, because they anticipate that the momentum is going to continue. Now, I'm not necessarily recommending that to you. I'm just telling you how some people use it. Now I'm going to show you in a later slide, how we can use momentum as part of a combined strategy. Now, you can see here how we can look at momentum visually. But for machine learning, which of course we're going to get to in the next mini course, we actually need to convert these to numbers that we can use quantitatively. And, of course, this course is about quantitative analysis. So there's always, for technical analysis, a graphical or visual presentation, but we need to also consider the quantitative presentation. So, when we talk about momentum, we talk about how many days of momentum that is. So, that might be n days, where we use n right there. So, n might be a number like 5 or 10 and so on. Here's the pseudo code for how we compute momentum on a particular day. So let's suppose this is day t right here. We just take the price as of that day and we divide it by the price in days earlier and subtract 1. So this will give us a number, say 0.1, if the price has gone up 10% or -0.1, if it's gone down 10%. So we usually see numbers in the range of, say, about -0.5 for a big, significant, 50% drop, to about +0.5. So on any particular day, this is how we would calculate the value of this technical indicator momentum. Our next indicator is simple moving average or SMA. And again, it's indexed by n, which is how many days are we looking back. So if we want to calculate the value of the simple moving average for this day, we look back over n days, and this is called an n-day window. So the SMA for today is simply the average of the values over this look back period. So it would be a value about right there. And if we carry it forward, it'll look like this. So, the SMA looks essentially like a smoothed value of the price chart as it moves around. And an important thing to note is it sort of lags the movement. So as we started down here, it slowly started coming down, and when we started up here, it lagged that movement upwards. There are at least two different ways that technicians use simple moving average as parts of trading strategies. The first is they look for places where the current price crosses through the simple moving average. Those tend to be important events, especially if the average is over many, many days. If you combine that with momentum, in other words, the price has strong momentum, and it's crossing through that simple moving average, that can be a signal. This particular crossing, where the price goes through the simple moving average, doesn't really illustrate strong momentum because it just started going up. However, when you do see strong momentum crossing those lines, then again, that can be a trading signal. Another way that technicians use simple moving average is as a proxy for underlying value. In other words, if you look back over a certain period of time and take that average price, that might represent the true value of the company. And if we see a large excursion from that price, we should, for instance, here and here, we should expect that the price is eventually going to come back down to that average. And so it's an arbitrage opportunity, sort of like we saw with fundamental analysis. And again, for example, there's a large excursion downward here, so this might represent a buy opportunity, and these two might represent sell opportunities. Because there was a strong diversion from that moving average. Now we talked about earlier how every technical indicator has a visual presentation like I'm showing you here, but we also need a way to quantify it, to turn it into a number. The way we do that is to compare the current price with the current simple moving average, and construct a ratio. So, in this case, we would look for a negative value. And in these cases, we'd want to see positive values. So, if we were to calculate, say, the value of the simple moving average on this day, we take the price for that day, and we compute the mean for the last n-days, which is here. And remember, this is over a look back window of n-days. Divide that into the price and subtract one. So, if, for instance, the price is 10% above the simple moving average, we'd end up getting a positive 0.1. If it were 10% below, we'd get a negative 0.1. So similar to the momentum, we typically see values here ranging from, at most, minus 50% to plus 50%. Let's suppose you liked what I told you about simple moving average, and you're looking at the historical price of this stock. And you're trying to decide, okay, how much of an excursion from the simple moving average should I use as a signal for a buy or sell? So let's add our simple moving average line here. Now you might say, okay, I think I see an excursion of say 1% like this, that that's a meaningful excursion and I should trade based on that. So let's carry forward and now you're getting this huge excursions all the time and you'd be chasing it trying to trade all the time. So clearly a fixed number is probably not the best way to go. If you look at this chart, you'll see that we've got a region of low volatility over here. And high volatility over here. So John Bollinger observed that for low volatility stocks or stocks that are currently experiencing low volatility, you probably want to use a smaller number for that trigger. And when we see high volatility, you probably want to use a larger number. Well, how can we accomplish that, well, we can use the standard deviation. So what Bollinger suggested was, okay, let's take this simple moving average, but let's add a band above and below two standard deviations. And that's our measure for how strong of a deviation we want to see before we respond to it. So for instance in this region, this smaller excursion goes outside that band, so we should take a look at it. But over here, it takes a much larger excursion to get our attention. How might we use Bollinger Bands now for trading signals? Here's a method that I've seen that is effective. So here's a rule of thumb for using Bollinger Bands that might be effective. You look for times where the price's outside, one of these Bollinger Bands and when it crosses to the inside. So for instance, here, we're outside and we cross to the inside. So this would be a cell signal. We've got a large excursion from the simple moving average. And we're expecting that it will retreat back to the average. And it's demonstrated that it's retreating because it's gone from outside the band back towards the moving average. Conversely, here we're moving from below the lower band. Back towards the simple moving average. And that would be a buy signal. So, recapping. The way that people use Bollinger Bands is they look for the price to go outside the bands. And then look for it to retreat back through the band. And that's verification that it is moving back toward the simple moving average. Here's how to calculate the Bollinger Band on a particular day t. So here's the price on that particular day t, we subtract the value of the simple moving average, so we are comparing these two values, and then divide by 2 times the standard deviation. So the value up here is going to be something greater than 1.0 because if it's exactly at this band, it's exactly 2 standard deviations away, so it would be a value of 1 right at the band. It's greater than 1 here. Similarly, down here, we would have a value less than negative 1. Because the price excursion is more than 2 standard deviations below. So we typically expect to see values for this Bollinger Band calculation to be between negative 1, and 1. In other words, most of the time the stock is going to be between those bands. But occasionally, we'll see excursions above and below those values. All right suppose you like that whole idea that I told you about Bollinger bands. Let's see now how well you might use it. So I've identified four different times here where the actual price crosses and upper or lower Bollinger band. I want you to look at each one of those, and identify here whether it's a buy signal, a sell signal or no signal at all. Let's take a look at this first one. So we went from outside the upper band and crossed down inside it. That is a sell signal because we've gone very far from the moving average, and we've validated now that we're moving back towards the moving average so that's a sell. Here, we've gone from inside to outside, and that is never a signal. It does indicate, of course, a significant excursion from the moving average, but we're looking for the validation that it comes back inside, so this is not a signal at all. Here however we've come back through that bottom band, and that is a buy signal. Finally for this last one, number four, we've gone outside the lower band and we've transitioned up inside it, that is a buy signal. So that's Bollinger bands and how you might use them. Before we leave technical analysis I want to bring up one more point called normalization. So, take a look at these different technical indicators we created here, simple moving average, momentum, and Bollinger bands. They have different ranges that they typically operate over, so, like I said we would expect to see values of -.5 to +.5 For simple moving average. For momentum, similar kind of range. Bollinger Band typically inhabits -1.0 to 1.0. If we were to plug these values into some sort of machine learner we would have a little bit of a problem. And what would happen, we'll have to go into the details later. But the Bollinger Band factor would tend to overwhelm these other factors and become the most important one. It might get even worse if we included fundamental factor like PE ratio that can range from 1 all the way up to 300. The solution is something called normalization. And what normalization does it takes each of these factors and essentially compresses them or stretches them so that they vary on average from -1 to +1. Normalization is simple, you take your original values for a particular factor subtract the mean from all of them, then divide by the standard deviation of all of them. This will give you a normed result that, on average, is going to vary between -1 and 1, and it'll have a mean of 0. So remember this trick for later when we get to machine learning, or if you're working with technical indicators yourself, you may want to apply this normalization approach to the numbers you're working with. Let's wrap up technical analysis now. So to review, technical indicators are really heuristics that represent someone's interpretation or hunch of how a statistical approach to previous prices and volume might suggest future price movement. The particular examples that I've provided here are my approach. So if you go look up, for instance, on John Bollinger's website how to use Bollinger Bands, you might discover his approach is slightly different. I showed you specifically how I have found them to be useful in the past. Finally, lots of times when people get exposed to technical analysis they get really excited and they want to run off and start trading. Well, hold your horses, there's a lot more to learn. So stick with it, and we'll see you in the next lesson. Data is, of course, very important for computational investing. The core data and the primary data we will work with in this course is historical price and volume data. That's what we'll focus on in this lesson. Our first step in considering data is to think about how it's aggregated. In other words, imagine that many, many trades are happening on different exchanges. How is all that data combined and how is is reported back to us so that we can analyze it and use it. The finest resolution of data is called a tick. A tick represents a successful by cell match or a successful transaction. So let's suppose that this time there's a successful transaction $100 was the price and 200 was the volume. So we record that here with a single point. A little bit later there was another transaction 9905, a 100 shares. Now, something to keep in mind is each of these transactions happens at no specific time. It happens only when the buy and sell are matched. So there's no guarantee that there's going to be a trade in any particular minute or any particular hour. It just happens when it happens. Each exchange provides its own data feed regarding these transactions. So you can subscribe to these feeds and see at each tick when a transaction happens on any particular exchange. So I've added some red dots here that represent transactions that might be happening on another exchange. Note that the prices are a little bit different, the volumes of course might be different. All of this happening simultaneously and the prices of different exchanges aren't guaranteed to be exactly the same. Now for highly liquid stocks, there may be hundreds or thousands or hundreds of thousands of transactions like these every second. Collecting and using all these ticks for all the exchanges over a long period of time would result in a lot of data, and it becomes very complex. Tick data is usually consolidated into minute by minute or hour by hour chunks. So I've drawn some boundaries here. Let's suppose those are minute boundaries, and we collect all the data together within each minute, and represent it as open, high, low, close and volume. So the open is the first transaction within the time period. So we came in here, we had a transaction at 100, so our open value is 100 within this time period. High, well you look at the entire time period and you see what was the highest price. The highest price here was also 100. Low was 99.05, close is the last transaction and that was 95.50. And volume is just the total volume during that time period. So it's 200 plus 100 plus 300, so 600 shares. So for this minute of time we've consolidated all that information into open, high, low, close, and volume. Similarly we go to the next minute and consolidate it in the same way. So in this next minute our open was 99, our close 99.95, low is 99, high was 99.95 and our volume was 300. And we will continue throughout the day to consolidate the data at each minute like this. And depending on your data feed, this might be the result say, for one exchange or it might be combined across multiple exchanges. In this course, these time boundaries are in days. So the data we'll be working with is daily data. And so we'll be looking at what is the data at the end of the day for each day. Now, all of the concepts that we teach here, you can just as easily apply at smaller time periods. It just requires more computing, faster computing, more and larger databases, and so on. So that's why we look at daily data in this course, is there's a little bit less data to work with. It's easier for you to download and work with and so on. If you look at this data over many years, you'll see that there are a couple sudden price drops. For instance, here it goes from $300 to $75 in one day. Here, it goes from 250 to 125 in one day. So those represent a 75% drop and a 50% drop respectively. Now surely the value of IBM did not drop that much in just one day. I want you to think about why this might've happened. In a moment, I'll give you some options that you can choose. But why might the price of IBM dropped by this significant amount over these days? Here are a few options for you to consider. Check the box that you think makes the most sense. So the correct answer is stock split. You might cry foul because I haven't told you yet what a stock split is. But don't worry, we're getting there. But just as advance warning, here's what it is. What happened on this day is that the stock was selling at 300, and if you had one share of the stock on this day, on the very next day, you had four shares. So your total value was preserved, you still had $300 worth of IBM, just now you had instead of one share, you had four shares. That's called a stock split. So indeed these big price drops were caused by stock splits, why do stocks split? The most common reason and as far as I know, the only reason, is that the price is too high. Why is a high price a problem? Well, consider for a moment that stock may be above say $500 per share. People like to buy stocks in groups of 100. So that means, for instance, it would be $50,000 to buy or sell a block of 100 shares of a $500 stock. Now, of course, you can buy it in smaller blocks. That's fine. But another aspect is that options when they're traded on stocks are usually traded with regard to 100 shares. So options covering 100 shares of $500 stocks, becomes suddenly very expensive and less liquid. So from the point of view of options, and also individual stock shares, very high prices are a problem. Even in the case where you want to buy just one share of the stock, let's suppose you're setting your kid up with an account, and you want to buy one share of Apple. Earlier this year that would have cost you $600. So even buying one share of a very expensive stock can be a problem. Finally, one other issue here is if you're building a portfolio and you want to have a finely tuned proportion of each stock in your portfolio. If some of the stock prices are very high, it becomes difficult to get that fine resolution that you want. So, when the prices get very, very high, what the companies do is they say, look, let's take that 1 share that's price at $300 and break it into 4 shares at 75. So that's called a 4 of a 1 split. In this case, we had a 2 for 1 split. So that's why splits happen. Now let's look at this data. Suppose you read this data into your computer and you were going to analyze it and look for trading opportunities. Well, your algorithm might discover, hey, look, here's a great shorting opportunity. Whenever this condition occurs, whatever that was, you want to short the stock, and then you'll see a 75% drop, and you'll reap a significant reward. And also here, you might identify this time as a good opportunity to short as well. Well, of course, that's wrong because what's happening underneath, is that the value of the company isn't really decreasing. You just have more shares. So if you want to trade using this actual closed data, you have to account for all these splits. And that becomes cumbersome. So someone came up with a great solution to this problem. Mainly, adjusted close. Or adjusted prices. And the idea is to create a timeline of prices that are adjusted to account for these changes. Such that you can look back over adjusted close. Simulate buying at a particular time. And seeing how the value increases over time accurately without having to account for these splits. Here's how it works. The first thing to point out is that at the very last day, in other words, today, adjusted close and actual close are always the same. Now we track back in time and adjusted close and actual close are exactly the same. But then, on this day, when we see this 2 to 1 split. What we do is we go back over all the historical data, and we divide it all by 2. So the first day before the split, we get about a $125 price instead of that 250. Then when we get to this 4 to 1 split we divide by 2, and then by 4, so that on this 1 day before that split our price is in the neighborhood of about $70, and that continues back in time. As we go back we adjust for each of the splits in history. So now we have a nice smooth price timeline without these big jumps. And for instance, if you consider that you bought the stock on this day and held it until this day, the accumulation in value that you see there is accurate. That reflects all those splits and you would have a lot more shares here, but this would also correctly represent the increase in value. Consider this situation. This green line represents the actual price for a stock over time. On this day, it had a two for one split and accordingly, it went from $100 to $50 on that day. So in light of this split on this particular day, I'd like you to consider these actual closing prices, and then calculate what the corresponding adjusted closing prices would be on these days. So, let's start over here, going back from today, our adjusted price is the same as the price today. So, as we go back and we get to this day where there is a $100 in the actual. There's no change, it's still a $100 also for the adjusted okay, we go back further on this day of the split, again, no change that would have been $50, but we're looking to calculate the price just before $100. In other words, when the actual price was 100 just before that split, what would the adjusted close be? Well, we divide everything by 2 remember, so we would have 50 here. So it would cruise along like this. And again, here we divide by two because that's what our recent split was and we would have 25 here. So this correctly represents that if you. If you bought the stock on this day it would double in value by the time you got to this day. And if you bought it on this day and held it all the way to here, you would actually get four times your value. Now remember earlier when we were talking about stock value, or I should say company value. And we looked at a way to compute company value based on dividends. So companies pay regularly, many companies, not all, dividends to their owners. And this can be worth a lot of money. So a stock that's priced at say around $100, can very often pay up to $1 or $2 per year in dividends, or 1 or 2%. Some stocks pay even more than that. Now dividends can have a significant affect on what happens to the actual price of the stock, and here's why. Suppose this stock is trading at about $100. And they announce, on this date in the future, we're going to pay a $1 dividend. So for every share of stock that you own, you'll get $1. What do you think is going to happen to the price of this stock between now and the date of that dividend? Let me give you a little bit more information that might make things simpler. Let's suppose that the consensus on the value of the company, by whatever means you've determined that consensus, is that the company is worth $100 per share. So on this date, in order to we get that $1 dividend, we're going to have one share of the company that people think is worth $100 per share and we will have $1. So on this date, we'll have one share of a company supposedly worth $100 and $1. So think about it. What prices will we see this stock converge to on the day before the dividend is paid and the day the dividend is paid? So answer this as a quiz. Here fill in what would the price of the stock be the day before the dividend, and what the price of the stock be the day the dividend is paid? When people get $1.00 and they also keep that share of stock. So, what's going to happen is that the stock price is going to rise to 101 because everybody knows that on the next day, you're going to have one share of a stock worth $100 and $1. So, the total value of that is $101. On the very next day, the price is going to drop by $1. And everybody who held a share that day will have one share of stock and $1. So their value continues at this $101 level. So the answers are, the day before the price, we should expect to see, is $101. And the day the dividend is paid, we should expect to see $100. And don't forget, you've got your $1 dividend also. So here I've redrawn that same scenario. We've got the price of a stock, trundling along. On this date, the dividend is announced that it will be paid on this date. And so we see, in general, the price rising up until that date and then a strong drop. And again, the consensus value for the company is about $100. Let's consider now how we might adjust historical prices for this situation. Again, adjusted price as of today or the latest day in our data, is always the same as the actual price. And as we go back in time, it remains about the same until we hit one of these events like a dividend or a split. So we treat, historically, the price in the same way that we do with this split. In other words, just before the dividend is paid, we adjust all of these prices down by the proportion of the dividend. So in this case we adjust everything down by about 1%, all the way back in history. So our adjusted price continues like this. Now to double check this for rationality, consider that you bought the stock around this date and you held it all the way though the dividend payment you would get an increase in value of your holding of about one dollar. So the adjustment is achieving its purpose, which is to allow us to not worry about dividends and splits. Just go back in time, buy, and hold the share, and see how much our value accumulates. So for the data we'll be working with in this class, which are daily close values, we have in our data both actual and adjusted. And in almost every instance I will assume that we're using adjusted closed prices in our calculations. Another couple things to reiterate about adjustments is the last day in our file, usually that's as of today, the adjusted and actual close value are the same. So any day that you look, say you've gotta go to Yahoo Finance or Google Finance and you get adjusted close and actual close, you'll see that today they're exactly the same price, but as you go back in time they will begin to diverge and the prices we use are adjusted for both dividends and splits, and it's very important that you always use adjusted close. One other thing to mention is suppose we had this data as of 2012. And so this last date here in our file is some date in 2012, and you go and you look at the adjusted close, let's suppose this is some date in 2010. That value, that adjusted close value, will be different if you gather data from, say, 2015. So if you go to Yahoo and get today's adjusted close, there will certainly, for most stocks, there will be dividends and splits that have occurred since 2012. And so this adjusted close price today in Yahoo's data, will be different, most likely lower than the adjusted close for that date, if you had gathered it in 2012. I know it's a little bit tricky, the key point is for projects in this class you need to use the data that's provided for the class. It was gathered as of 2012. If you go to yahoo and get new data, you're going to get different answers for the projects, so just keep that in mind. One of the things we do in this class is to simulate strategies that we might develop. We roll back time, and pretend that we traded on certain dates according to certain signals, and we see what the result of our strategy might have been. Now to do that, you have to start with some universal stocks. One of the most common universes is the S&P 500. When you simulate your trading, you roll back time and you look at that universe of stocks. You apply your algorithm to choose which stocks you might buy. A very common mistake that people make is that they look at the membership of that universe, as of today. Then they go back in time and they use that list of stocks for their strategy. So let's suppose we go back in time, we take the current list of the S&P 500, and we run our strategy and our strategy is just doing great. I'm going to call that the biased strategy. So why is it biased? Well, we're selecting from stocks way back here that we knew were existing over here, so there's a built in bias that these stocks are going to do well because they weathered the storm here. Now consider, what if we use the S&P 500 as it was back in 2007? So a lot of the stocks from back then did just fine, they survived, but a lot didn't. 68 stocks from the S&P 500 died. They completely went away, from 2007 to 2009. So if you applied the same strategy that appears to be so awesome, but you use the real members of the S&P 500 from back then, you're probably going to have a significantly lower performance. And the difference between these two is the bias. The lesson learned is to use survivor bias free data and that's available from a number of providers. It's not usually free, but it's not necessarily that expensive either. But if you do that, you'll avoid this sort of false optimism for a strategy that you develop. Okay, that's it for dealing with data. I hope you found the lesson useful and we'll see you again soon. Bye-bye. We haven't stated these explicitly, but we've been operating under some assumptions. For technical analysis we assume that there is information in historical price and volume data that we can discover and exploit in advance of the market. For fundamental analysis we assume there is information in fundamental data, like earnings, that can be exploited and traded upon in advance of the market. The efficient markets hypothesis says we're wrong about both. The first ideas that eventually became the Efficient Markets Hypothesis were postulated by Jules Regnault in 1863. Eugene Fama carried those ideas further in the 1960's, and it became his PhD thesis. Fama recently received a Nobel Prize, so we know those ideas were good. So what's the efficient market hypothesis about? We'll start by looking at some of the assumptions that it makes. Probably the most important assumption is it that there are a large numbers of investors interacting in the market for profit. So they have an incentive to find opportunities where the price of a stock is out of line with what its true value is. Because there are so many of these investors operating simultaneously, any time a little bit of information comes out there, the price is going to move. The next assumption is that new information arrives randomly. So it arrives at random times, it arrives at random rates for different stocks, but it's constantly arriving and investors are paying attention to that information and therefore the prices are adjusting quickly. Finally, the efficient market hypothesis assumes that the current price reflects all available information. In other words, all this information that's trickling in is acted upon by the investors, the price adjusts quickly to that information, and the current price reflects all of the information about that stock. There's a number of places information can come from. Let's step through a few of these sorted from most public to least public. But even this is certainly not an exhaustive list. There's many other places we can get information. But let's step through them. Price volume, this is public. It's rapid, it's quick, everybody can see it. This is the basis of technical analysis. Fundamental data. This is reported quarterly and everybody can see it as well. It's public, but it points more to the root of the value of the company than just the price volume. Exogenous data, that's a fancy name for a simple concept. It's just information about the world that effects the company. As an example, if we were looking at an airline stock, an exogenous piece of data that would effect the price of the airline stock is the price of oil. If price of oil goes down, usually the price of the airline stock goes up because energy is the number one cost for airlines. A very important and secretive type of information relates to company insiders. So, let's suppose you're a CEO, and you know that this drug that you've invented is about to be improved. You might go buy shares of your stock because you think the price of your stock is going to go up because that drug is going to be approved. Now, depending on the circumstance it may or may not be legal, but this reflects information that you have that people outside the company do not have. And so this insider information is probably the least accessible of all these types, of course, and of most other types of information as well. Now, each of these types of information has a relationship to the efficient markets hypothesis. In particular there's three forms of the efficient markets hypothesis. And these types of information relate to each of these three forms. We'll get in to that in just a second. There are three versions of the official markets hypothesis that go from weak to strong and we'll take a look at them each one at a time. The weak form of the EMH says that future prices cannot be predicted by analyzing previous prices. The idea here is that the current price. Reflects all information we might know. So just by looking at these historical prices you can't predict what is going to happen next. Notice, however,that this does leave room potentially for fundamental analysis. The semi-strong version of the EMH suggests that prices adjust immediately to new public information. So, for instance, when companies have their quarterly reports, that contain fundamental information, prices react immediately to that information. So, if semi-strong is correct, that would seem to prohibit even fundamental analysis. There's one possibility left though. One way that we might make money and that is based on insider information. Well, the strong version of the EMH says we can't even make money on insider information. Prices reflect all information, public and private. So even if there's some secret information within the company that points to a higher price later. The price will go up in the face of that knowledge. So, if the strong version of the EMH is true, it is essentially impossible to make money by holding a portfolio, other than the market portfolio. So let's recap each one of these real quick. The weak form says that you can't predict future prices by looking at historical prices. It is silent on things like fundamentals or insider information, it's just about price. You can't profit by looking at historical price. Semi-strong says that public information such as quarterly reports cause the price to adjust quickly. The price adjusts rapidly to this new public information. So semi-strong essentially says that even fundamental analysis won't work. Finally, the strong version says that even insider information can't be leveraged to profit in the market. Consider the three forms of the deficient markets hypothesis. Weak, semi-strong, and strong. Which one of these types of analyses or strategies would these corresponding versions of the EMH would prohibit? So for instance if you think that the weak version of the efficient market hypothesis prevents fundamental analysis from working. You would check the box there. Okay, have at it. The weak version prohibits us from profiting from technical analysis, because the weak version says that, you can't predict future prices from past prices. But the weak version didn't say anything about fundamental or insider information. Semi-strong prohibits technical analysis, also fundamental. But it's silent on insider. And finally the strong versions says that, you can't profit from any of those three types. Is the efficient markets hypothesis correct? Well, if it is, then a lot of what we're trying to do in this course is not possible. Namely, we can't beat the market using any of these strategies we might be looking at. Now, I think there is evidence that certain versions of the hypothesis are not correct. And there are a number of very successful hedge funds out there that would seem to indicate that you can make money in the market by investing in things other than just the market portfolio. I would say the strong version of the efficient markets hypothesis is the least solid. In other words, the strong version says that you can't even profit from insider information. The reason that I think that one is not true is because we have seen people make money from insider information. Some of them have gone to jail, but clearly, it's a method that can provide profit, even though it might be illegal. This is an interesting data set that seems to refute the semi-strong version of the efficient markets hypothesis as well. It's a little bit complex, so I'll step through it carefully. So, let's look at the blue dots. Each dot here represents the P/E ratio on a particular date, so, for instance, this stock had a P/E ratio of 20, that's price to earnings. That's the horizontal component of its location. The vertical location is how much money did it make in terms of price over 20 years. So for instance, this stock had a price/earnings ratio of 20. And it made about 4% annualized returns. As we go down this way, the P/E ratio is lower. So lower numbers for P/E ratio are better. If you think about it, price divided by earnings, if it's a lower price and has higher earnings, you'll get a lower number. So, presumably, lower values this way indicate higher value for a stock. And each group of colors represents different decade when the analysis was done. So, for instance, this dark blue was an analysis based on what the P/E ratios of stocks were in 1890 to 1910 and all the way up to the red, which was 1970 through 1985. Now for all of these decades, we saw that at the beginning of the corresponding time period, low P/E ratios corresponded with higher returns. So this shows that price/earnings ratios are very predictive across many, many decades of future returns, and that tends to refute the semi-strong version of the EMH. Okay, that's it for the efficient markets hypothesis. I will see you again soon, bye, bye. You're probably familiar with Warren Buffett. He's one of the most successful investors ever. He's made a number of insightful comments over the years, many of which relate to this class. One of my favorites is, only when the tide goes out do you discover who's been swimming naked. That's not the one for this lesson though. The one for this lesson is. Wide diversification is only necessary when investors do not know what they are doing. Mr. Buffett is talking about two things. Investor skill and breadth or the number of investments. This lesson is about how investment performance relates to those two factors. In the 1980s, Richard Grinold was seeking a method of relating performance, skill, and breadth in investing. So for instance, you might be a very skilled investor, meaning that you can pick stocks well, but you might not have many opportunities or breadth to exercise that skill. So Grinold felt that there must be some equation whereby we could combine skill and breadth to create an estimate of performance. He developed a relationship he called the Fundamental Law of Active Portfolio Management. I'm going to state it here at the beginning of the lesson, and then spend the rest of the lesson trying to justify it and show you why it makes sense. And here's his expression, performance is equal to skill times the square root of breadth. So we need some measure of skill and some measure of breadth. So if you want to improve your performance you can improve skill, or you can find more and more applications or methods or opportunities for applying that skill. So, as an example breadth might relate to how many stocks you invest in and skill relates to your skill in choosing them. So, again you can invest in either improving your skill or improving your breadth. So performance is summarized in something called information ratio, which is very much like the sharpe ratio that we've discussed before, but it refers to the sharpe ratio of excess returns, in other words the manner in which the portfolio manager is exceeding the market's performance. Skill is summarized in something called Information coefficient and and breadth is just how many trading opportunities we have. Okay. So, we'll expand more and more on this as we go through the lesson. Now we're going to explore these ideas in a thought experiment called the coin flipping casino. So, instead of buying and selling stocks, we're going to flip coins and we're going to be on the outcome of whether those coins come up heads or tails. So that's analogous to a single investment in a stock, or a single trade in a stock, where you buy it and hold it and either you make money or you lose money. Well, we're going to flip a coin and either make money or lose money. Now the coin is biased. In other words, we have information about this coin, and we know that it's more likely to come up heads than tails. In fact, that probability is about 0.51 that it will come up heads. So that's our edge, that's like our alpha when investing in stocks. And the uncertainty of the outcome is like beta in stock investing. Here's how betting works. So you can bet on any particular coin flip, you can bet n coins. If you win, in other words it comes up heads. You now have 2 n coins. If you lose they take your money. So this is called an even money bet. So on each outcome you either make n coins or you lose n coins. Here's how the casino works. There are 1,000 betting tables each with their own biased coin, and you have 1,000 tokens. So you can chose to bet however you like. In other words, you can put ten tokens on each of a hundred tables, you could put a thousand tokens on one table, you could put one token on all the tables. Once you've distributed all your tokens, which represent your bets, the coins are all flipped at once. In other words the game runs in parallel, and for each bet that you made you either Get your winnings or they take the chips that you bet. So now that we've set up this environment for us to experiment with, I want you to think a little bit about it and think about how would you allocate these tokens? Is it better to bet all your tokens on just one coin flip, or is it better to bet on multiple coin flips at once? So I want you to consider these two scenarios, two different ways to bet. In one case, you put all of your 1000 tokens on a single table and 0 of your tokens on the other 999. So that's one way you might bet. And the outcome is going to depend on only what happens on the coin that's flipped on that single table. Another approach is to put 1 token on each of the 1000 tables, and then all the coins are flipped in parallel and you get your reward or loss that way. Which one of these is better? Or is it the case that both of these are equivalent? Now, it would be fair for you to object and say, well, Professor Balch, what do you mean by better? I'll get onto that, but I think it's pretty clear, actually, that this is the best bet, and we'll spend some time explaining why. But the big picture is, this bet is very, very risky. There's a 49% chance you'll lose all your money with a single flip of the coin, whereas in this case, your coins are distributed over 1,000 individual small bets, and there's very little chance you'll lose all your money. And furthermore, the expected return for each of these bets is the same. It's just that this one has much lower risk. To figure out which of these scenarios is best, we need to consider reward and risk. Let's start here first with reward. So when we talk about reward in this situation, we're talking about our expected return. So in the single bet case, we bet 1000 chips at once. Our expected return is the chance that we'll win the bet times the return we get plus the chance that we would lose the bet times what we would lose. So, the chance that we're going to win is 0.51. Remember, it's a biased coin. And we have the opportunity to win 1000 tokens or $1000. The chance that we'll lose is 0.49 or 49%. And if we lose, we would lose a $1,000. So if you multiply this all out and add it up, you end up seeing that our expected return is $20. I'd like for you now to figure out what's our expected return or what's the reward in the multibet case where we bet 1000 individual chips on 1000 different tables. And all those coins are flipped at once. All biased coins with a 51% chance of winning for us. What's our expected return in that case? So, we make a bunch of individual bets, each one has the same chances as this one up here, except each one of those individual bets only provides a loss of $1 or a gain of $1. So, each of our individual bets has this 0.51 chance of winning $1, and 0.49 chance of losing $1. And we just have a thousand of those. So if you work out the numbers it turns out that this works out to be 0.02, and we multiply it by a thousand and we get $20. So what's remarkable, or at least interesting, is that for both of these ways of betting, our expected return is exactly the same. So the reward side of this determining which is better, is showing us that it's the same, so why should I say that this multibet approach is better? Well, it turns out that that's all about the risk, so let's look at the risk now. There's a number of ways that we might consider risk in this scenario. Let's look at first, this idea of what's the chance you might lose it all. So, you put out your bets on the thousands tables. The coins are flipped, in that event, what's the chance you'll lose all, all of your money? In the single bet case where you put all of your money on a single table, and the outcome is determined by the flip of a single coin, remember, even though it is biased in your favor, there still is a 49% change it'll come out against you. So if you put all of your money on a single table for one coin, there's a 49% chance that you'll lose all of it. That's pretty high. I mean consider that in the context of would you put your savings account on a single bet like that? Now, I want you to think a little bit, consider the multi-bet case where we put one token on each of the 1,000 tables. So there's 1,000 coin flips and our return is determined by the result of all those individual thousand coin flips. What is the chance that we would lose it all in that case? Well the answer to that is that it's the probability that we lose on the first table, times the probability that we lose on the second table, times the probability we lose on the third. And as you can see, we do this for all of the thousandth table and multiple those probabilities altogether, and that's the probability we would lose everything in the multiple bit scenario. That is a very, very small number. It's point four nine to the one thousandth power. How small is it? Let's try and calculate it on a calculator. So it's 0.49 raised to the 1,000th power. Let's see how small that is. It's so small it's not even a number. That's how small it is. Okay, let's look at another way to evaluate risk. Another way that we can look at risk in this thought experiment is to consider the standard deviation of all those individual bets. So again consider we have a thousand different betting tables out there, and we have the opportunity to allocate our bets however we like. We could put 200 tokens on one table, 5 on another, and so on. We're looking at the two extreme cases here of course, but in any case, what is the standard deviation of the results of all those individual bet?. So we're going to look at standard deviation after the fact, in other words, we're going to assume we bet already and we're looking at the outcome. So if we have one token per table we might have a loss of one token on one table, a gain on another, another loss, and a gain, and a gain and so on, all the way across our 1,000 tables. Now, we don't actually have to spend much time doing the math here. It turns out that the standard deviation for this case is pretty easy to calculate. Because for each table, the result is either -1 or 1. And it turns out that the standard deviation in this case is easily calculated as 1.0. So it doesn't matter what the particular outcome turns out to be. We know we're either going to lose 1 or gain 1 at every single table. And so our expected standard deviation there is 1. The outcome for the second scenario where we make one bet with a 1000 tokens and then essentially 0 bets on the other tables, turns out a little bit differently. So on this first table where we bet 1000 tokens, we either win 1000 or we lose 1000. And on all the other tables, the outcome is exactly 0. Same for this case where we lost on that first one. So again, we bet on one table 1,000 tokens, and we bet 0 tokens on the other 999. Reasoning it out this way enables us to calculate the standard deviation. Whichever way it goes whether we win or lose, the standard deviation on this event is the same. And the answer is 31.62. Key point here is, the standard deviation or risk is much, much larger. Well as you can see about 31 time larger, when we make that single bet on one table and no bets on the other tables. Now we're going to bring all these components together and consider risk adjusted reward and this is just like the sharp ratio that we've looked at in other contexts. In the single bet case we can calculate this ratio easily like this. So remember our reward or our expected return was $20 and our risk was $31.62. So if we divide this out, we get our sharp ratio. Or just the adjusted risk/reward ratio for this scenario. And it turns out to be 0.63. I'd like now for you to fill in the numbers for the multi bet case. In other words, a case where we point one token on each of the 1,000 tables and then get our return from that single event. So the reward or the return is the same. But remember the standard deviation of the risk was very much smaller. So we end up with a much larger ratio in the multi bet case. So the take home message here is. Even though we have the same expected return, we can have much lower risk and thus a much higher risk adjusted reward if we have many, many, bets. You know a thousand bets instead of just a single bet. So lets step back a moment and look at these results for these two extremes. So we have this one extreme where we bet all 1,000 chips on a single coin flip and another where we bet 1 chip on each of a 1,000 coin flips. Now the risk adjusted reward or the sharp ratio for the single that was 0.63, in other words if we bet all 1000 chips on a single flip of the coin our sharp ratio is 0.63. So let's call this SRsingle, now the sharp ratio if we bet 1000 times in other words 1 chip on each of 1000 tables turns out to be 20. So what's the relationship between the two? Of course, 20 is about 40 times bigger than 0.63, but there's something more interesting there. And it turns out that it's this. So if we take the single bet case and multiply it by the square root of 1,000, we get the sharp ratio of our multi-bet scenario where we bet 1000 at once. So isn't that curious? So it turns out that in general, if you carry that scenario out to more examples, that if you split your bets evenly across multiple tables, this relationship will hold. In other words, the sharp ratio for the single bet, 1000 chips on one table, is our base case. And as we spread it out over more and more tables, the sharp ratio improves by the square root of that number of bets. And this relation is exactly like the fundamental law of active portfolio management. Namely, our overall performance is related to the skill, in the case of making a single pick, times the square root of the number of picks that we're able to make. So our coin flip casino has helped to show us How we can derive an equation like this for betting, which is what buying [LAUGH] stocks really is, and to show that you can improve things either by having more skill, In case of coin flips, skill is how biased is the coin. In the case of investing, it's how good are you at predicting the future return of the stock. Or you can improve your performance by increasing your breadth, but you only get to improve it by the square root of your breadth. Consider now the results of this thought experiment. Our casino enabled us to allocate our 1,000 tokens to 1,000 tables. We looked at two extreme cases. One where we put a small bet on all 1,000 tables, and another where we put all our money on one table. We saw that the expected return was the same in both cases, about $20, but the risk was substantially higher for the single bet case. This was true for both type of risk that we looked at, risk to lose everything, and risk as standard deviation. When we consider risk and reward together, we come away with three lessons. One, higher alpha generates a higher sharpe ratio. Two, more execution opportunities provides a higher sharpe ratio. And three, sharpe ratio grows as the square root of breadth. Let's consider now the real world, and in particular hedge funds. So let's consider two real world funds. One is RenTec or Renaissance Technologies, it was founded by Jim Simons, a math and computer since professor, and he's had tremendous performance over the last several decades, and Warren Buffet, who runs Berkshire Hathaway. Both of these funds over the years have produced similar returns. But on the one hand, Warren Buffet holds maybe 120 stocks, and he doesn't trade much, he just holds them. Renaissance technology trades may be 100,000 times per day. Can a single theory relate these two? Can it account vastly widely differing numbers of trades per year, and can it relate the fact that they have similar performance and maybe different levels of skill? How does that all work together? Well, yes, there is a theory that can relate them, it's the fundamental law of active portfolio management, and I'm going to show it to you in just a moment. Before I introduce the fundamental law, I've got to define a few terms. Let's start with information ratio. So recall, the return on our portfolio for a particular day is equal to the market component of the return, which is beta for that portfolio, times the return on the market for that day, plus this residual return. Another way to look at that is to say that this component of the return is due to the market, and this component is due to the skill of the fund manager. Remember, alpha is about skill. Now, we want to focus on the skill component. In other words, what is the fund manager bringing to the table? And we can calculate the Sharpe ratio, essentially, of this component, just like we can calculate the Sharpe ratio of an entire portfolio. But we can focus on this skill component, and essentially the Sharpe ratio of this skill component is the information ratio. It works like this. So the information ratio is the mean of all of the alpha components divided by the standard deviation of the alpha components. So this is our reward component. That's our risk component. And by the way, this is calculated by looking back historically at the daily values of alpha. And we take the mean and the standard deviation of them over time. You can find these by finding beta for the portfolio, calculating what the market return component was for each day, and then the difference is this residual or skill. So that's how you can compute historically the value of this information ratio. Now by the way, this information ration applies in many different cases, not just in this fundamental law case. People use information ratio as a measure of manager performance all the time. It's fair to say that information ratio is essentially a Sharpe ratio of excess return, this part that's due to skill. IC, or the information coefficient, is just the correlation of the manager's forecast to actual returns. So for instance, if she made a forecast on IBM, that it would go up 1%, and it went up 0.5%, well, it's a positive correlation. This value can range from 0, where the correlation is not present, to 1, where it's very, very strong. Finally, BR, or breadth, represents the number of trading opportunities per year. So for example, if you're Warren Buffet, and you hold 120 stocks, and you just hold them all year, that's 120 trading opportunities. If, say, you're Jim Simons, and you trade 100,000 times per day, you multiply that times the number of trading days in a year, well, it turns out to be a very large number. Key thing is, even if it's just a portfolio where you buy and hold, you count the number of positions in that portfolio as the number of trading opportunities, because this is oriented around an annual measure. Now that we've introduced these factors and to find them, we're now able to describe the fundamental law as expressed by Richard Grinold. And it's simple, it's just this. He was able to show mathematically that information ratio is equal to information coefficient times the square root of breadth. I'm just going to present it without proof here and encourage you to go look at Grinold's book if you're interested, for more detail. So, performance of the manager, or the fund, is due to the skill at making predictions. Times the square root of breadth. So that means, for instance, that yes, you may be very skilled but you've got to have opportunities to invest in order to operationalize your skill. Now if you want to improve your performance you can either focus on improving your skill or focus on improving your breadth. Sometimes it turns out, that it's a lot easier to increase breadth by finding additional stocks you might look at or additional markets. You might have some commodity trading strategy that works great. You can increase your breadth by looking at additional commodities. However, the strength of this increase, in other words, as you increase breadth, the overall performance only increases as the square root of that breadth. So it tapers off after some amount of time. It turns out, though, that it's very, very hard to improve your skill, so that is why, for instance, folks often focus on the breadth component of this equation. Let's get back to that original question that motivated some of this, which is how can we relate the performance of Renaissance technologies? Or Jim Simons versus Warren Buffet? And the quiz here is for you to use the fundamental law to see if you can relate the two. Okay, so for this problem, assume that both Simons and Buffet have the same information ratio. I'm making that up, I don't know for sure that they do. But this is just a simplification for this problem. Assume that Simons' algorithms are only one 1000th as smart as Buffet. So that's another way of saying that their information coefficient is one 1000th the value of Buffet. Also assume that Buffet trades 120 times per year. Given that, how many trades must Simons execute in order to maintain the information ratio at the same level as Buffet? The answer is 120 million, so if Buffet trades only 120 times per year, Simons has to trade 120 million times. So here's how I arrived at that. We know that their information ratios are the same, so we just set the equation equal to each other. One for Simons and one for Buffet. So the information coefficient for Buffet, times square to 120. This is Buffet's information ratio. Now this is Simon's information ratio. It's his information coefficient times the square root of x, which is what we're trying to find. Now first thing we can do is replace ICS with what we know is that it's one-one thousandth of Buffet's. Now we can multiply both sides by 1,000. And divide both sides by Buffet's IC. And we get this. And now we just square both sides and we're left with x or 120 million. Okay, that's it for the fundamental law of active portfolio management. I'll see you again soon, thanks. Suppose you have a set of stocks that you've determined are good investments. How much of your portfolio should you invest in each? There are many potential answers to that question. In this lesson we take a look at the approach called mean variance optimization, or portfolio optimization. The specific question we're looking to answer is this. Given a set of equities and a target return, find an allocation to each equity that minimizes risk. If we're going to find a portfolio or an allocation of assets to different stocks that minimizes risk, we have to pause for a moment and consider what is risk. Let's consider two stocks, XYZ, here that's gone up about ten percent, but as you can see, it's been very volatile. Here's the historical price of another stock, ABC. It also went up ten percent over this same time period, but as you can see, it was less volatile. So it's this volatility that we use as a measure of risk and that is simply the standard deviation of historical daily returns. Again, in this case, risk is measured as volatility or standard deviation of historical daily returns. That's the standard view of risk in most finance texts. There are other ways to view risk that we touch upon here and there through this course but the key is standard deviation of daily returns. Now, as you've probably heard over and over and over again, there's no reward without risk. And we often want to consider multiple stocks together and evaluate their risk versus return. So, one way we can do that is plot them on a scatter plot where each dot here represents one stock. So risk goes along this axis. Return is along this axis. So for instance, this stock here has higher risk, but about the same return as this stock. And then for comparison, this stock here has shown, historically about the same risk as this stock, but it's got a much higher return. Now we can build the portfolio by combining multiple assets, like the various stocks I've got plotted here and waiting each asset by a particular wait that represents it's allocation within the portfolio. So each stock has a wait and when combined altogether we end up with a portfolio that has properties of each of the stocks. It's typically got a risk somewhere in the middle there and a return somewhere in the middle I'd like you to consider these three portfolios. Now, each of the green dots represents an asset that's in the portfolio. And it's on this risk versus reward scatter plot. We've indicated the weights of the assets by the size of the dots. So for instance, this portfolio has most of its assets in these two equities, whereas this one has most of its assets in these three. Now, over here in this right column, I indicate with a big orange circle the risk/return level for several different portfolios, and what I want you to do is match these resulting portfolios to these weights. So, give it a go and I'll come back and show you the answer. Okay. So in this portfolio, we're emphasizing risky assets and our portfolio ought to be somewhere around in here once we combine them. And of these three, this one seems to match the best so the answer here is B. If we look at this one, we're emphasizing less risky assets. So we should expect the portfolio to have a value at low risk. And of the three choices, A looks like the best match. This is the only one left, but note that it's essentially a combination, mostly of low return and low risk and high risk stocks. And so it's somewhere between and the answer there is C. So for quite a long time, people built portfolios this way. They would look at a bunch of assets, essentially equally weight them, and end up with a portfolio that behaved somewhat in between. Now, if you wanted a low-risk portfolio, you should focus on assets that are low risk out here. If you wanted, for instance, high return, you should focus on assets over here. In both those cases you would end up with a portfolio, say, here, or a portfolio, say, here. Now, can we do better? In other words, is it possible to get portfolios over here? So can we have a portfolio here that has a return similar to these assets over here, but risk similar to these assets over here? Indeed we can, and it's due to a man named Harry Markowitz, who won the Nobel Prize for his insight. What he discovered, and what people had been overlooking, was the relationship between stocks in terms of covariance. So the resulting performance of a portfolio, especially in terms of risk, is not just a factor, or a blend of the various risks, but it has to do with how they interact day to day. So indeed, if we pick the right stocks in the right proportions, we can get a portfolio that performs over here, that in fact, can have lower risk than any of the individual assets, and I'll show you how to do that in just a moment. Now before I do that, I want to mention though one other thing about Harry Markowitz. Up until the time of his discovery, most people viewed bonds as the lowest risk asset, in other words, if you wanted low risk, you should use bonds orly. Markowitz showed that a blend of stocks and bonds is actually lower risk than either one of those by themselves. And I'll show you how that makes sense in a moment. So to illustrate the importance of covariance, we're going to take a look at a couple different stocks here. These are pretend, of course. So here's one, ABC, it's gone up 10%. Here's another stock, GHI, it's also gone up 10%. But notice it tends to zig when ABC zags, so it's not going in lockstep with ABC. Finally, here's our last stock that we'll take a look at, DEF. Note how it goes almost in lockstep with ABC. So, three stocks, two that move together very similarly, and one that moves opposite them sometimes, yet they've all provided about 10% return. What is the best portfolio we can build by combining these three different stocks? So, let's consider their covariance, or how they move together, for a moment. So ABC and DEF move very similarly. And if we were to measure their covariance, and this is the covariance of daily returns, which if you're just looking at one stock versus another, that's the same as the correlation coefficient of their daily returns. So 0.9 means that they move very closely to one another. Now, if we were to look at the co-variance of daily returns of ABC and GHI, we would find that they actually have a negative correlation. In other words, when ABC goes up, GHI tends to go down. So they actually have a negative correlation, or a negative covariance, whereas ABC and DEF have a positive covariance. Again now, what's the best way to blend these together? So lets consider a couple different portfolios, which are just weightings on these different assets. Let's look first at one that is 50% ABC and 50% DEF. So what's that one going to look like? Well, they both move very similarly, so this portfolio is going to track the two of them together. So the performance of this portfolio is going to look something like this. So that's fine, it ends up returning 10%, just like the two major assets that it holds, but there's no real advantage in blending these two assets because it just has the same volatility as each one of them by themselves. So what if we try something a little bit different? What if we take 25% of ABC, 25% of DEF, so that's going to give us this same motion that we saw here when we combined those two, but, we put the rest of it in GHI? So now we're combining an anticorrelated asset with these other two. So what's this portfolio going to look like? Well, it's going to be a nice blend of them, with very low volatility, because when one zigs, the other zags. So this portfolio will also have a 10% return, but look how smooth it is. And that's because we're blending anticorrelated assets together. So we get the same return but lower volatility than any asset by itself. So all these assets by themselves had significant volatility, but when we put them together, we reduced volatility significantly. That's the magic of what Markowitz provided, and we'll look a little bit more at that in just a moment. When Markowitz added to the game was this consideration of variance and co-variance between individual stocks. And the recognition that you want to blend those together that have anti-correlation. So you can have a much lower risk portfolio if you combine assets that are anti-correlated. Or anti-varianced. [LAUGH] If that is a word. Because when one moves up, the other moves down. They cancel each other out. And you have much less volatility. Now of course you want, overall, all these assets to in general move up together. So often what we are looking for is anti-correlation in the short term and positive correlation in a longer term. But out of this work grew a number of algorithms, one of the key ones being mean variance optimization. Which is a way of taking a potential set of assets and figuring out how they should be blended together by looking at their co-variance among other things. So lets consider this group of assets here and how we might combine them or allocate funds to them to provide a good portfolio. One thing I didn't point out before that I want to mention now. Is it generally the higher return stocks or assets, whatever they might be tend to also be the highest risk. So as we roll down the risk we tend to also look at lower return. Now again, how do we combine these into a good portfolio? Here's what goes in to a mean variance optimizer. These are the factors that it considers. So for each stock you have to provide an expected return. In other words, what do we think in the future it's going to provide in terms of return. You also provide volatility and covariance. Volatility is simply historically how volatile has each one of these assets been. Covariance is a matrix which shows between each asset and every other asset, what is the correlation of daily returns. So it takes all of these into account when it is searching for the right waiting for each of these stocks in a portfolio. So the last and perhaps one of the most important inputs to this is the target return. We can target a return anywhere from the max return asset to the min return asset. And then anything else between those, of course, we can accomplish by blending. So let's suppose this is the level of our target return. So I'll just put a dotted line here so we can mark that for later. So the output of an optimizer is a set of weights, one weight for each asset, that provides the target return. But minimizes risk, so in the end we're looking for a portfolio that's out here. In other words it's got risk that's even lower than any of the individual assets. But it meets the target return. And this is possible because we consider covariance. We're only looking at individual risk we wouldn't be able to find the right blend that would bring us out here. Now that's it for optimization and the insights from Markowitz. But there's one more thing to look at with regards to optimizers that I'm going to show you next. There's one last topic I wanted to talk about with regard to portfolio optimizers and modern portfolio theory. Consider these assets, and also recognize that for any particular return level, there is an optimal portfolio. So let's suppose we picked this return level, and that this is the optimal portfolio. In other words, this portfolio reflects weightings of all these assets that provides the lowest risk for this particular return. Now, we can compute this for all the potential returns from the minimum return stock here up to the maximum. And if we did that for all of them, in fact there's an infinite number of them, so we couldn't really do it for all of them. You get a line. So our maximum return portfolio is up here and it would consist entirely of that one asset. But as we bring the return down we find a number of other portfolios all the way down to here. A couple of different things to observe that are interesting. One is as you reduce the return sometimes this curve comes back in this direction, indicating that actually the risk is increasing as we reduce the return. So for the most part, people don't want those sorts of portfolios. In other words, who wants a lower returning portfolio with more risk. So we typically look only at portfolios above this line. As you might have guessed, the name of this line is the efficient frontier. So what does that mean, the efficient frontier? It means that there are essentially no portfolios out here. And that any portfolio that's on this side of the frontier, it's suboptimal in some way. So for instance, if you had a portfolio here, you are assuming this much risk, for a lower return than you could have, than if you were up here on the frontier. Or if you were targeting this much return, you could be over here with regard to risk. So any portfolio inside here is not efficient because it's either higher risk or lower return than it could be if we were on the efficient frontier. One last thing to mention about the efficient frontier is if you draw a tangent line from the origin to the frontier where it hits is the max sharp ratio portfolio for all of these assets. In practice the efficient frontier isn't used for that much other than as a theoretical device, but people do often like to plot the efficient frontier so they can see where there portfolio is In relation to the assets that they're using and where they could be in terms of efficiency. Okay, that is all. I will see you online soon. Thank you very much. Welcome to the first lesson of machine learning algorithms for trading. In this lesson we're going to introduce how hedge funds and other financial institutions utilize machine learning. In general, the focus is on creating a model that can be used to predict future prices for stocks or other assets. Models like these have been around for a long time. What's different about machine learning is that it provides a suite of tools that support a data-centric way to build predictive models. Scientists like to talk about the algorithms they build in terms of the problems that they solve, so this mini course is about machine learning and let's think about the problem the machine learning solves. In most cases, machine learning algorithms are focused on building a model. What's a model? A model is something that takes in observations like this x here, run it through some sort of process, and provide a y. So this y is typically a prediction, and the x is some sort of observation of the world. Examples might be, for us, x are some features of stocks and y is a future price. There are many other uses of machine learning models. That's just one of them. X can be multidimensional. In other words, there might be multiple factors that we're considering, might be Bollinger Bands, PE ratio, and so on. Y is typically single dimension and just represents that single-dimension prediction that we're trying to make. Now, there are lots of models that people have built that don't use machine learning at all. One example is the Black-Scholes model that predicts option prices. There are many other types of models that predict things that people build not using machine learning, but they develop mathematical formulas. But, of course, with machine learning, we're trying to use data. So the machine learning process is to take historical data, run it through a machine learning algorithm of some sort to generate the model. Then at runtime or when we need to use the model, we push x's in it and y's come out. Now consider you were building a model and we were going to use it in trading in some way. Which factors might you consider as inputs or x's versus which of these might be appropriate outputs or y's for our model? So the two things that make sense here as ys are future price, because we're trying to predict it, or future return, which is very similar. All these others are factors that we might use to predict these two. So price momentum is a predictive factor, Bollinger band value's a predictive factor, and current price might be as well. The particular flavor of machine learning that we're going to focus on in the first part of this course is called supervised regression learning. Those are a few big words. Let's break it down word by word. We'll start in the middle here with regression. Regression is a weird word. I don't think whoever chose it to represent what it means did a good job, but we're stuck with it. All that regression means is we're trying to make a numerical approximation or a numerical prediction. That's as opposed to classification learning where we might be trying to classify an object into one of several types as opposed to making a numerical prediction. Supervised means that we show the machine the x and also, if you will, the correct answer y. In fact, we show the machine many, many examples of x and y, and that's how it learns, okay, when I see this x, this is the y that's associated with it. That's the supervised component. Finally, when we say learning, what we mean is we are training with data. In this class we're taking historical stock data and training the system to make a prediction about the future, usually about price. There are a lot of algorithms that solve this problem and are supervised regression learning techniques. You've probably heard of linear regression and used it. Linear regression is a method that finds parameters for a model. So we call it parametric learning. K nearest neighbor, or KNN, is an extremely popular approach. And in fact, you're going to build a KNN learner as part of this class. What's different between parametric learning and instance based, which KNN is an example of, is that in parametric learning we take the data, munge it around to come up with a few parameters, and then throw the data away. In k nearest neighbor we keep all of this historic data, the x and y pairs, and when it's time to make a prediction we consult that data. That's what makes it instance based. Anyways, we'll spend a lot of time talking about k nearest neighbor. Two other techniques that are really popular are decision trees and decision forests. As you might guess, the way decision trees work is they store a tree structure and when a query comes in, it essentially bounces down that tree according to factors of the data. Each node in the tree represents essentially a question, is this x value greater than or less than this other value? And eventually we reach a leaf and that is the regression value that's returned. Decision forests are simply lots and lots of decision trees taken together, and you query each one to get an overall result. So this is the definition of supervised regression learning, which we're going to use a lot, and these are various algorithms that solve that problem. I'd like to show you an example of supervised machine learning from my robotics past, this robot you see here is called Latgr or learning applied to ground robotics. It is using keeners neighbor to learn how to navigate. Let me talk a little bit about what comes in and what goes out. It has a sensor in front of it that sees the world in front of it. It can see along a number of directions where there are obstacles or where the road is clear. So, the input is, in which directions are their obstacles. And also, it has the direction towards the goal. So in this case, the robots trying to get to a goal that's off the left, but these bushes that line the path are sort of preventing it from getting there. So x, in our case, are these perceptions. What do I see around me? And what's the direction to the goal? And y, or the output, Is, which direction to steer. So let's let it go for a while and see how well it can navigate based on a little bit of training that it's been given. It's doing pretty good here so far. But, it hasn't been trained quite well enough and boom, it goes off the path. This is where learning comes in. We back it up over that area where it messed up, and we switch the learning switch on, and we're essentially tell it, okay, watch what we do, that's the correct thing to do in this case. So it takes all those examples of x's and y's, x's being the perception and y being the way it should respond, adds that to its memory, and now when it's running live, it consults this memory. It says oh, I see this, what should I do?. It finds the k nearest neighbors to that current observation and looks at what they say, and they essentially vote on what direction the robot should go. Now after we've trained it for about a half hour or so, it's able to navigate through difficult scenarios really quite easily. So keep in mind, this robot's driving autonomously, it's just consulting its memory for when I saw this, what was the right answer, why? Supervised learning, and it's able to get around quite well. Here's another more complicated scenario. The goal where it's trying to get is on the other side of that tree. So that's supervised learning for a robot and, again, the model maps these perceptions x to y, what it should do. And finance instead of Y being which way the robot should go, it's often a prediction about what a future price is. Okay, enough about robots, let's move on. Let's consider how we can use this same approach now for stock data. This is one of our pandas Data Frames that contains some factors or features of stocks, and it's arranged in the usual way where each column represents the value of the feature for a particular stock. And time goes downward essentially. Now we might have many features for each stock, for instance we might have Bollinger Bands, momentum, PE ratio, and so on. We represent that by stacking these one behind the other. These are our X's. What is our Y? In most cases we want to use our historical feature data to predict a future price. But to train our model, we're going to use historical price as well. So the value of these factors or features today we call X and we like to be able to run that through the model that we've built and get Y which is our predicted future price. Well, we don't have that model yet, we've got to learn it. And we've got to learn it from data. So here's how we do that. We roll back time so that we're back in history here at our first data point. We look at the values of our features there, and then we look, say, 5 days into the future to see what that future price is. So now we've got a pairing of these features with that future Y. We save that XY pair into our data. Now remember X can be multi-dimensional. And that's one instance of data. We move forward one day. So we've got a new set of X's and a new Y. And we record that in our database. Eventually, we reach a point where we can't go any further because there's no more Y data. In other words, if we went one day past this, Y would be out here in the future. So we don't have that data to use, and that means we've got some leftover data. In any case, we now, for each of these days in history, have a pair of X's and Y's that we can feed into our database to build our model. I'd like to show you now how we use this process to build a machine-learning based forecaster at a FinTech company, at my company, Lucena Research. The first step is to select which factors do you want to use? So those are our Xs. Remember, it can be multi-dimensional. So these are things like Bollinger Bands, PE ratio and so on. Measurable quantities about a company that can be predictive of its stock price. The next step is to select what is it you want to predict? Usually we want to predict change in price, market relative change in price, or for now we could just think about that as future price. These both become our data, our Xs and our Ys that we used to train the model. Now that we know what our predictive factors are and what Y is going to be, we need to consider the breadth and depth of the data that we're going to use to train the system with. So that includes, for instance, time period. How far back in time do you want to go to train the system? And what's your stock universe? What universe of data, which symbols are you going to use to train the system as well? Now we can train our model. We can take this data to produce that model. We unleash our machine learning algorithm. This might be kNN. It might be a linear regression. It could be decision tree. Whatever. That algorithm takes this data and converts it into a model. We're ready now to use that model to do some prediction. The way we do that is we measure the quantities about the stocks that we want to make a prediction for now. We measure what those Xs are today, plug those into the model and the model should provide us our Y, or our prediction. Now let me show you how we use these very same algorithms in a real application. This is a cloud-based application called QuantDesk. It was developed by a company I cofounded called Lucena Research. Now, the way it works is over on the left here, there are various lists of stocks that you can choose from. I've chosen Dow Jones, and when you click on that, you can see the list of stocks that make up that group of stocks. There are any number of ways that you can list particular stocks you're interested in looking at. Now, over here are our forecasting options, and this is how we tell the machine learning algorithm which factors we want to use, how far in the future do we want to predict, and so on. We're using right now the default model, and what that is is that's the list of factors that we think are important for making a future price prediction. So we can click here and see what those factors are. This is the list of factors that we're using now. So it turns out that these factors are determined using another machine learning algorithm. We use a genetic algorithm for discovering these. That's a subject for a different lecture. But anyhow, these are the list of factors considered at present. Now, let's do a one week forecast. Let's make it a one month forecast. And let's use three months of data. So we're going to be looking back three months at all these factors. When we roll back time, we're able to see the future price of these stocks. So we can see how those factors presumably affected the future price. So let's do a forecast and see what the result looks like. So, this area here is the forecast for Apple. This is the historical price, looking back the last three months, and this is the forecast future price. So that line is indicating that we think it's going to go up, and this arc line above and below Is our confidence interval. We also report that data in a tabular format up here. So this is the current price, this is the forecast change in price, and the forecast percentage change. So, our system thinks that from today Apple is going to go up about 2.5%. Now, we also report some other information over here. We report what we call confidence and back tests score. Confidence refers to when we find those k nearest neighbors, how diverse are the ys that comes back? So, k is the number of neighbors, and when we look at all those neighbors, are the closest to the values of the quantities that Apple has today, we find the 30 closest ones, and we look at the standard deviation among all those 30. If they're very close, we're confident in our prediction. If they're spread apart, we're less confident. So you can see here, American Express is a more confident prediction, and, we rate this by a number of stars, by the way, where five stars represent our most confident estimates and one star, of course, our least confident. So our system thinks that American Express is going to go down by 0.9% over the next month. It's got a high confidence, and it's also got a high back test score. So what's this back test score? What we do is we roll back time, and we look over all this last three months and look forward one month. And we see how accurate all those predictions were over the last three months. The more accurate those were, the higher ranking we get there. So this is just an example of how we can use these same tools to make predictions in a live real system. And this is using, behind the scenes, the same software that you're learning in this class. Of course, a natural question is, well, how accurate are these forecasts? Can you act on them? Do they really predict the future? Well at least a first step towards answering that question can be found by back testing. So that means you roll back time, and you test your system. So here's our historical data as usual it's organized with time coming down. Now in order to test the capability of our approach, we have to limit the data it sees to a certain amount of time and then make predictions into the simulated future. So we allow our system to only look at data up to a certain point. It can use data before that all it likes. It builds a model, and then makes a forecast. On the basis of that forecast, we can then now place orders, anticipating that that forecast will be achieved. So we might long some stocks or short them as appropriate. We can take those orders now, put them into our trading simulator and see how the portfolio works. So this time right here is the same as this time here, so we enter our positions on that date which was the same as that date and then we roll it forward and see what happens with the portfolio. Using software that we've built in this class, you can measure things like Sharpe ratio, return, and so on for that portfolio. Now we're training over new data, make a new forecast and then make a new set of orders. We enter these orders in our trading simulator and then go forward and see what happens. I'm optimistic and it's always going to go up and to the right. Anyways, this process can be repeated over and over again using historical data and we can simulate our learning algorithm and how it would trade in this way. And that's called backtesting. On the QuantDesk platform, we can backtest in exactly the same way. Go over here to the BackTest tab and click on Forecast. And again, we can configure which group of stocks are we going to work with, and what are the settings for our backtest. For instance, how much money do we start with? How frequently do we want to trade, over what period of time do we want to run the backtest and so on. Anyway, we make those selections. We also need to choose parameters for the forecaster. Again, which model do we want to use, which includes what are the factors that we're paying attention to. How far into the future do we want to make our forecast and how much data looking back do we want to use. Once we make all those selections, we can click on BackTest and it'll start running. It takes quite a bit of time, so we're going to go ahead and process in the background. And I'll show you what one of these backtests looks like. Here's an example report their system generates. This is again for a forecast backtest. The orange line here represents the historical value of our portfolio. The blue is the benchmark that we're using, which is S&P 500. You can see here a number of metrics tabulated over this period of time we saw 346% return. Our sharp ratio was 1.14 and so on. So this is just an example of the kinds of systems you can build using the sorts of things we teach you in this class. So that's the forecast backtest. As you saw by that Beck test, regression-based forecasting can be useful. It's also worth noting that that particular Beck test was not spectacular. It did indeed beat the S&P 500, which is important, but it didn't beat it spectacularly. [LAUGH] Usually we find that performance in the real world Is not as awesome as in back testing. So we would probably still see good return from that strategy but it wouldn't be quite the same as we saw in that back test. So I want a list a few problems we see sometimes with regression based forecasting. First of all, our forecasts always seem to be noisy and uncertain. So there is value in there, but it has to be accumulated over many trading opportunities. It's hard to know how confident you should be in a forecast. I mentioned in my software demo a moment ago that we could look at standard deviation of the nearest neighbors. That works okay. It's really not too strong of a measure, however. So it's difficult to know how confident you ought to be in any particular forecast. It would be nice if you could know because that would enable you to essentially bet less on forecasts that are less certain. Additionally, it's not clear how long you should hold a position that might have arisen from a forecast, and how you should allocate to that position. These are all challenges using regression based forecasting. Some of these issues can be addressed using reinforcement learning. Where instead of making a forecast of a future price, we had the system learn a policy and the policy tells the system whether to buy or sell a stock. We'll get to this towards the end of this class but it's an interesting alternative to the regression based approaches we're going to use here at the beginning of the class. I'm going to take a moment here now to talk about the problem we're going to focus on for the rest of this class. We're going to look at a certain period of data, train our models over that period, and then make forecasts and trade over some other period. So here's our historical data. We're going to use the period of 2009 as our data to train our model. You'll be implementing several machine learning algorithms to create different models and will be comparing them one against another. Then we'll test over the years 2010 and 2011. So those testing values will become our X which will push through the model to create a Y or a forecast. And using this forecast you'll generate an orders.txt file which you can push through your market simulator. We'll see how that strategy performs, measure it's sharp ratio and its total return and so on. And that way we'll be able to compare different machine learning algorithms that generate these orders. That's it for this lesson. Our introduction to machine learning and how it works at hedge funds and other financial institutions. I will see you online again soon. Bye-bye. This lesson is about supervised regression learning. I've never much liked the name "regression", because it doesn't describe the activity very well. I prefer a name like numerical model. In any case, we're stuck with regression as the name for using data to build a model that predicts a numerical output based on a set of numerical inputs. I'm going to start with parametric regression, which is a way of building a model where we represent the model with the number of parameters. Let's start with a simple example. Suppose we want to build a model that will predict how much it will rain today based on changes in barometric pressure. So as you may know, if barometric pressure declines, that usually means there's bad weather coming and it's going to rain. And when barometric pressure increases, it typically means that we've got good weather coming. So on this scatter plot each individual point represents one day. So let's consider a particular day, say here. And what this means is that on this day, the barometric pressure decreased by 10 millimeters and we had 50 millimeters of rain, about 2 inches. So let's consider that over time we collect data for many different days and that's what this looks like. So again, each one of these dots represents one day's worth of data and we have multiple day's worth of data here. And as you can see there's a general trend of as barometric pressure decreases, we typically have more rain and as it increases we have less rain. We'd like to create a model based on this data that when we query it at any particular point it'll give us a prediction of how much is going to rain, so we would measure barometric pressure or its change and then estimate how much is going to rain. The classic solution to this problem is to fit a line to the data. So let's give that a shot. As you probably know, this approach is called linear regression. And the model looks like this. So if you remember, from algebra in elementary school, or high school, wherever you got it. [LAUGH] The equation for line is simply y equals mx plus b. So x is our barometric pressure change variable here, and m and b are the parameters of our model. Our model now is fully described by these two parameters, and if we want to estimate or query how much it's going to rain at any particular point. We measure the barometric pressure. Let's say the barometric pressure today increased by 5. We would then plug that 5 into our model here and multiply it by m and add b. And that's our estimate for that day of how much it's going to rain. And the linear regression approach is how we arrive at m and b. This model is decent, but it doesn't track the actual behavior of the data, for instance, in this region and in this region, so we can make a more complex model. Instead of fitting a line we can fit a polynomial, we can add one more term x squared and now we've got to also find this additional parameter m2. So, when we find our model it's now represented by three parameters mm2 and b. This polynomial model will look something like this. It fits the data pretty well over here, but not so well over here. Now, we can add more terms. We can fit an x cubed term and have another parameter and so on. In general, these parametric approaches come away with a number of parameters, and the more complex the model, the more parameters. Still, three parameters is a pretty simple model. All of these models, whether it's linear, with just mx plus b, or polynomial, with a cubed or squared term, are parametric models. In the end, after we learn these models, we have our parameters, in this case, m2, m, and b. And we throw away the data, and the model's represented just by these three parameters. But there's another way to approach it, and I'll show you that next. There's another approach, it's a data-centric approach or instance based approach where we keep the data and we use it when we make a query. So here's an example, let's suppose our barometric pressure has gone down by 5 millimeters and we want to consult our model to see how much it's going to rain today. So our query here is at -5 millimeters. And let's suppose that K is equal to 3. So we will find the 3 nearest historical data points to this query. And those are 1, 2, 3. And we'll use them to estimate how much it's going to rain today We've identified that we want to use these three historical data points in order to answer our query about how much rain we would expect if barometric pressure drops five millimeters. But what should we do with these data points to find that prediction? Here are three alternatives for you to consider. Take your time and check which one you think makes the most sense. The correct answer is that we should take the mean of their y values. So that'll give us an answer somewhere around here. We don't want to take the average of their x values because that would be something like 5 millimeter, and in reality you know the correct answer is around 40 millimeters. We don't want to take the largest y, because we want to take advantage of all these votes that we have to get a closer, more correct answer. So again, the correct response for this query is to take the mean of the K, where K is equal to 3, nearest neighbors. Take the mean of their Y-value, and that gives us a value somewhere about like there. If we were to repeat this process at many, many points along the X-axis, we end up with a model that looks like this. What's nice about it is it fits the data over here where it's curving this way. It fits the data over here where it's curving that way. And in interpolates nicely and smoothly between all the data points. There are number of methods like this that keep the data around and when they make a query, they consult the data to find the answer. The most famous of these methods is K nearest neighbor. But there are others, such as kernel regression. The main way that KNN differs from kernel regression is that in kernel regression we weight the contributions of each of the nearest data points according to how distant they are. Where as with KNN, each data point that we consider gets essentially an equal weight. We've covered now parametric models, where our goal is to find parameters like M and B. And we toss the data away, and then just use M and B later to make our queries and here I've shown you non-parametric or instance based methods where we keep the data and we consult it when we make a query. So I'd like you to consider two data sets, and think about whether it would be best to use a parametric model or a non-parametric model. Our first problem is a cannon, and we orient the cannon up or down a certain number of degrees, and we want to estimate based on how many degrees up or down it is how far is the cannonball going to go. The cannon's oriented at a certain angle, boom, the cannonball comes out, and it follows some trajectory like this, and [SOUND] splats over here, so this angle theta is our x, and this distance, how far it went, is our y. And so we take the cannon, we orient it at many different thetas, and we measure how far the cannonball goes. And that's our data. Here's another problem from animal behavior. Let's suppose we have a beehive, and we want to estimate the behavior of the bees. In other words, how many of them will be attracted to this food source as richness of the food source increases? So in other words, our x is the richness of the food source, and our y is how many. So the reason this is a different sort of problem than, say, that cannonball problem, is it's not clear that as we increase the richness of the food, that necessarily more bees will come. Consider these two problems. The cannonball problem, we're trying to build a model for how far will the canon ball go depending on what is x, the angle at which the barrel is aimed. And the honeybee problem, how many honeybees will visit a food source as we change the richness of the food source from, say, poor to rich. Do you think this problem is best solved by a parametric model, or non-parametric model for each one? So go ahead and enter your guesses and I'll tell you what I think the answer is. So in my view, this type of problem is best solved by a parametric learner, and this sort of problem is best solved by a non-parametric learner. And here's why. For this problem, you can start with an equation, you can look it up on the net or whatever. That will express an estimate of how far a cannon ball will go given this angle. What's missing are some parameters of that equation that reflect the velocity of the cannon ball coming out and so on. But just by taking certain measurements of how far the ball goes at different angles, you can use a parametric learner to find those parameters. The key thing here is that you can start with an estimate of the underlying behavior of the system in terms of a mathematical equation that expresses how it behaves. Now, in the cases of the honey bees, we really don't know, we don't really have a guess of what that underlying mathematical equation might look like. And if you don't have a guess, it's better to use a non-parametric or instance-based model because it can fit any sort of shape. Another way to put that is that this model is biased, in the sense that we have an initial guess of what the form of the equation is. This solution is unbiased because we don't know. Now, we're raised to think biased is a bad thing, but if you go into the problem already knowing the form of the solution, it makes sense to take advantage of that bias, and aim your solution toward that bias. Let's reflect on the pros and cons of each approach. For a parametric approach, we don't have to store the original data, so it's very space efficient, but we can't easily update the model as more data is gathered. Usually we have to do a complete rerun of the learning algorithm to update the model, thus for parametric approaches, training is slow but querying is fast. For non-parametric approaches, or instance-based, we have to store all the data points. So it's hard to apply when we have a huge data set, but new evidence can be added easily since no perimeters need to be learned, adding data points doesn't consume additional time, thus training is fast, but querying is potentially slow. Most importantly, these nonparametric approaches avoid having to assume a certain type of model, whether it's linear or quadratic or so on. And therefore, they're suitable to fit complex patterns where we don't really know what the underlying model is like. Consider now the data that we're going to use. We're going to have features that we've computed, these are things like Bollinger bands and momentum and price change and things like that. We're going to use these features to try and predict prices or price changes. So this is our X data, and if we've got multiple features, we've got multiple dimensions in X. So this might be X1, X2, X3, and so on. And this is our Y data, which we're trying to predict. In order to evaluate our learning algorithms in a scientific manner we need to split this data into at least two sections. A training section and a testing section. If we trained over the same data that we tested over, the results would be suspicious because we should obviously be able to do very well if we test over the same data we trained on. This procedure of separating testing and training data from one another is called out of sample testing. This is a very important and essential technique. We'll call the X data that we use for training, Xtrain and the Y data that we use for training, Ytrain. Similarly, the data we'll test on will be split into X and Y sections, Xtest and Ytest. So the general idea here is that we'll take our Xtrain data and our Ytrain data, run that through our machine learning algorithm which might be linear regression or KNN to generate a model. We can then test the accuracy of that model using this data. So, the input to the model is Xtest, so we plug that X data into the model, and out comes something, some kind of Y. And the question is, is that Y equal to this Y which we know is ground truth. The more closely the model outputs a Y that reflects this Xtest data, the more accurate the model is. Something that I didn't mention, is that in this class, our data is time oriented. So, as you move downward, we're going forward in time. We typically split the data up according to time. We train our model on older data and test it on newer data. It's generally frowned upon to do the reverse. You might argue, well this data's different than that data. It's still out of sample. But there are certain look-ahead biases that can occur if you were to train on later data and test on earlier data. As part of this class you're going to have to write some software. In particular, you're going to have to write some machine learning algorithms. It's useful if we standardize on what the application programmer interface ought to look like for the code you're going to write. So here's what it looks like. For a linear regression learning algorithm, your API ought to implement something that works like this. A constructor that creates an instance of one of these learners, which is now learner. A method called train that can take our training data and train the model. And a query function that takes a list of X values that you want to test and returns a list of Y values according to what the model thinks they should be. These Y values, in turn, are the ones that we'll compare to Y test to see how well the algorithm works. Our KNNLearner ought to have the same methods. The only difference is the constructor here has this additional argument, K, which would allow you to set how large you want K to be. So if K is 3, that means you use the 3 nearest neighbors. But it also has a train and a query function, just like linear regression. Now, I'm going to show you some pseudo code for how you might implement this API for a linear regression learner. So we define our class as LimRegLearner. And this first method init with underscores on either side is the constructor. The constructor is really easy. For the linear regression learner, we actually don't have to do anything when we instantiated an instance of the learner. So we just use pass, which means do nothing. Our training method takes an x and a y, and remember, x can be multidimensional. And what it's doing, it should take this x data and this y data and fit a line to it. So it's trying to find an m and a b. So the job of the train method is to find that linear equation or the parameters for that linear equation, m and b. So here on the left-hand side, we have self.m which means the m goes to the local instance, and b to the local instance, and you're allowed to use any number of linear regression algorithms at your disposal as part of SciPy and NumPy. So go Google and find which one you want to use here and just stuff it's output into m and b. Finally, query is passed in x and it's supposed to predicted y given that x. And remember, this is potentially a list of x's and it can also be multidimensional. Anyways, it's very simple. You just multiply that x times m and add b and return y, boom, that's it. In short, this is literally how short your LinRegLearner can be. Now, the k and n API is going to look exactly the same. And the reason for that is if we have the same API, we can easily mix and match, and try training and querying with the different algorithms and see how they compare. Okay, that is it for regression. I'll see you at the next lesson. Have a great day. We've posed the general problem of supervised regression learning and introduced two algorithms that can solve it. Linear regression creates parametrize models and K and N is a non-parametric instance base method. There are in fact many algorithms that can solve this problem. Each algorithm has it's on pros and cons. In this lesson we'll look at various methods for assessing those algorithms. As we begin now looking at how to evaluate various machine learning algorithms, let's start back with KNN and look a little more closely at the sorts of solutions it provides. Let's start with our training data, and remember we've got pairs of X and Y, so each one of these dots represents one training tuple. And I'm just making this data up, of course. But suppose we were going to query this KNN model over in this region. Say right here at this point. Well, the nearest three. Let's use K=3 here. The nearest three are going to be these. And remember, we take the mean of their value to get the value at that query point. So if we query from here all the way to about here, our model is going to take the mean y value of those, so the output of our model is going to look something like this. And notice it gives the same value at all these points. Eventually, as we query from left to right, we get to a point where this one gets dropped out, and this one gets added in. And at that point we'll have a sudden drop about like that in the model. And we continue on like this. We'll have another drop like that. If we query our model now from left to right in very, very tiny increments we'll get the result that looks something like this. Note that indeed there are sort of jump points here. Some nice things about this are that it's not over fitting the data. In other words, it's not tagging each point. A negative aspect though is at the ends there we have these horizontal lines that are no longer changing or essentially this model is not able to extrapolate like we might if we had a parametric model. Let's consider now what happens to the model that comes out when we change the value of k. So we've got three k nearest neighbor models here. Each one is using a different value of k, and I want you to match the value of k to the output model here. Okay, so I want you to look at these different charts. Each one of these models shown in red is using a different value of k. So I want you to fill in these little boxes, which chart corresponds to the value of k. So one of these charts was created with k=1, one was created with k=3, and another was created with k=N, where N is the total number of elements in the dataset. And there's another question I want you to answer. True or false, as we increase k we are more likely to overfit. I haven't told you yet in too much detail what overfitting is. Let me just give you a quick gist of it so you can answer the question. An overfit model strives really hard to match the dataset exactly. And then when we go on later to use new data or test it with test data, it tends not to do so well. So go for these two questions and I'll come back in a minute and tell you the answer. Alright, let's start with this one. One of these models was created with k=N, and it's this one. If we use all of the neighbors and all the data points, and take their average, the value of our model will be the same at every single point. Namely the mean of all the Y's of all the data points. So this one is b, as in bravo. Let's do this one next, K=1. We know that this model is going to tag each point exactly, because, when we're at that data point, we'll have exactly that value. So this model steps up and down and tags each individual point exactly. So that's a C, and this is, this one is K=3, which we already looked at, A. Okay this next question, as we increase k we are more likely to overfit, that is false. In K and N, if K is equal to one, will have the most overfit model. And as we increase K, we're less and less likely to overfit as we go forward. Let's consider now a similar question, but now we're using parametric models, a polynomial model of degree d. Real quick, here's what we mean when we say polynomial of degree d. So here's what our polynomial model looks like, it's m1 times x, m2 times x squared, m3 times x cubed plus b. This is a third order polynomial, or a polynomial of degree d so I want you to consider d=1, d=2, d=3 and I want you to select which model over here goes with that degree. Then I want you to consider this question. True or false, as we increase d we are more likely to overfit. Okay, let's start with d=1. Well, that's a linear model. That includes just this component. So of course, it must be a line, so it's gotta be this one. That means the answer here is c. Now we have order two and order three to choose from. Two is a parabola, so it's including this component as well. This one's a parabola of course. And so the answer to that one is a. And finally that leaves only b, but let's look at why that is. When we have a cubed component, we can get this additional curl in there. Now as you notice, as we increase from order one to order two to order three, we're gradually getting closer and closer to tagging the actual data. So we get to this question, as we increase d we are more likely to overfit. That is true. And in fact, it can be shown with a polynomial like this that as the order of the polynomial or d reaches in, the total number of points, we actually can match the data at every point. Now a couple things to note here. One is as we go off the edge here for all these models, we're able to extrapolate in the direction the data seem to be going. And this is capability that parametric models or these polynomial models have that KNN does not. I've shown you some graphs that suggest the ways the models can fit the data, more or less closely. But let's have a more formal definition of this matching. It's called error. A standard way to measure error, is called RMS error. Let me show you how to calculate this. Let's suppose we use this data, which are these green points, to build a model. Let's say it's a linear model like this. We can assess the model at each real data point. For instance, at this data point. And measure the difference between the Y value of the data point, and the model. And this difference is error. Now, we've got an error at every single one of these data points. And what we do to measure root mean squared error, is to take the error at each one of these points, square it, add them together, take the average, and take the square root of that. So that sounds kind of complicated, but here's what it looks like. Ytest minus Ypredict. So Ytest are the actual values of the data. Ypredict are what our model predicted. We take that difference at each point. That's this difference. Square it, sum all those together, divide by the number of points and take the square root. And that's our root mean squared error. And what this is an approximation of really, is sort of the average error here. But we end up emphasizing larger errors a bit more. Now, we just measured the error of this linear model against our original training data. We know, though, from say, k and n, that we can build models that can fit this training data exactly. So we can have arbitrarily small error against our training set. The more important measure is, what is our error out of sample? So, what out of sample means is we train on our training set, but we test on a separate testing set of data. And, that's going to be different than our training set. So, to measure out of sample error, we look at the error from our testing set, not our training set. So we look at each one of these test points and measure the error for each one of those. So we look at these blue points instead of the green points, plug them into this equation just like before, and that's our out of sample root mean squared error. Suppose we're measuring the error of a model that you built. Which sort of error would you expect to be larger? In sample error, in which we measure the accuracy of our model against the set it was trained on? Or out of sample error, where we measure the error of the model against a new test set that it hasn't seen before? Which is worse? In general, in fact in almost every case I know of, out of sample error is always worse than in sample error. Usually when researchers are evaluating a learning algorithm, they split their data into two chucks. The training chunk, and a testing chunk. Training usually is about 60% of the data, and testing is about 40%. Now if you train and then test on that data, that's one trial and in many cases that's enough, you measured your root means square error and that's an assessment of your algorithm. You might compare it against another algorithm. But one problem researchers sometimes encounter is they don't have enough data to effectively analyze their algorithm. One thing they can do is effectively create more data by slicing it up and running more trials. Here's how that works. So what we can do is we can slice our data into say five different chunks, and then we can train here on 80% of the data, and test on 20%. That's one trial. Then we can switch things up and train on this 80% of the data. And test on that, that's another trial, and so on. I'm sure you see how this is going. We can effectively get five different trials out of this one set of data. Cross validation is a great tool, but the typical usage of it doesn't fit financial data applications well. The reason is that it can permit peeking into the future. So for instance, if our training data is after our test data that means we're seeing the future ahead of our test. Any sort of peeking like this can read to unrealistically optimistic results, so with this sort of data we need to avoid it. One way to avoid this problem is with role forward cross validation. That means our training data is always before our testing data. But we can still have multiple trials just by rolling our data forward, like this and this and this, till we run out of data. Another way to visualize and evaluate the accuracy of a regression algorithm is to look at the relationship between predicted and actual values of our dependant variable Y. Here's what I mean, query our model, the one that we trained on training data with Xtest, our testing data set. The output of that query is a new vector of Y values, Ypredict. So based on this Xtest data our model predicts this Ypredict data. We can now compare what we know to be the correct, or true, data and Ytest with what our prediction was. So this pair would appear somewhere on this chart, say here. So its a value along the horizontal access here is what the prediction was and along the vertical axis was what the ground truth is. So we can plot these pairs all the way through our data. Now, if this scatterplot is arranged in approximately a nice line like this, that means we've got a pretty good prediction algorithm. On the other hand, if they're not aligned so well and they look sort of like a shotgun blast, our learner is not so good. We can measure this property quantitatively using something called correlation. You can use the num pi function corrcoef to measure the correlation between Ytest and Ypredict. You'll get an answer somewhere between -1 and +1. Where +1 means they're strongly correlated, -1 means they're inversely correlated, and 0 means there's essentially no correlation at all between them. One thing to point out here is that correlation isn't the slope of this line. Lots of people think that's what it is. Correlation has to do with how well aligned the points are with the line that we fit. So if it's a nice oval that fits close to that line, we usually have a high correlation. If it's a big round thing we've got poor correlation. I want you to think now about the relationship between RMS error and correlation. And in particular, I'm talking about correlation between our predicted result and the actual result. Do you think that as RMS error increases, correlation would decrease, correlation would increase, or we can't really be sure? So in most cases, in fact almost all cases, as RMS error increases, correlation decreases. So this would be a reasonably correct answer. But it is possible to construct examples where as RMS error increases, correlation might increase. So that also lets you have it correct if you checked we can't be sure either way. I've mentioned overfitting before, but I haven't yet defined it. Before we could define it, and I could give you an example, we needed to have a definition of error. Let me now show you what I mean. Let's consider parameterized polynomial models where we can, one at a time, add additional factors, like x, x squared, x cubed, x to the fourth, and so on. Let's create a graph where we have along the horizontal access degrees of freedom, or d, the degree of our polynomial. And vertically here, we'll have the error of our model. So let's measure error as we increase d on our training set. So when d is smallest, our error is greatest. And as we increase d, our error drops and drops and drops. In other words, we're fitting the data in sample better and better. When finally we get to N, where we have as many parameters in our model as we do have items in our data set, our error gets all the way down to zero. This is in sample error. Now, let's add a similar line for out of sample error. Remember that we expect our out of sample error to always be greater than or equal to in sample error. The curve will look something like this. It'll start out at maximum error, about the same as our in sample line, and as we go down, we begin to diverge like this. Now in this region both our in sample and out of sample errors are still decreasing, but eventually we'll reach a point where our out of sample begins to increase. In fact it may increase strongly. In this area, as we increase degrees of freedom, our in sample error is decreasing, but our out of sample error is increasing. And that's how we define overfitting. This is the region where overfitting is occurring. So, let me state that again. In sample error is decreasing, out of sample error is increasing. And we have those two together, it's over fitting. I want you now to consider overfitting in KNN. So in this case our horizontal access will be K and it could range again from 1 out to N, the number of data points and then the vertical access will be error. I'm going to draw three charts here showing N sample error as a factor of K and out of sample error as a factor of K. And I want you to look at each one of them and consider which one of them you think is the proper representation of what that ought to look like for KNN. Which of these three charts correctly represents the shape that we would expect for out of sample error and in sample error for KNN, as K increases this way and error increases that way. So take a look and go ahead and fill in your answer over here. So the answer is b. This is a little bit tricky because the relationship for k and n and error is a little bit different than it is for polynomial degrees of freedom and error. Remember that as we reduce k down to 1 our in sample error approaches 0. In fact it becomes a 0 when k is equal to 1. And similarly as we decrease k, our other sample error decreases. But at some point it begins to increase. This one is wrong because as we increase k, our error increases. So this is not showing that relationship correctly. And this is just garbage that I threw in there to see if anybody would bite. [LAUGH] Now the region here in which overfitting is occurring is here, because remember, as out of sample error increases, and in sample error is decreasing, that's where overfitting occurs There are a few other factors worth considering when evaluating a learning algorithm, and I've tallied a few of them here. I want you to think about each one of these and select which you think has better performance in that regard, linear regression or KNN. So let's step through them. How much memory do you need in your computer to save the model? How much compute time do you need to train the model? How long does it take to query the model? And finally, how easy is it to add new data to your model? So, again, I want you to check the box according to which one has better performance with regard to these factors. So, in terms of space for saving the model, linear regression is a hands down winner. For instance, if we're learning a third order polynomial, we have to only store four numbers. KNN, on the other hand, requires you to keep all the data, so it could be megabytes or gigabytes of data. So, KNN is bad in this regard. Compute time to train. KNN is much better in this case. In fact, it takes zero time to train KNN. You just stuff the model into a data store and you're done. On the other hand, linear regression has to take all that data, compute over it, to find those parameters. Compute time to query. LinReg wins hands down. All you do is you plug your X in, multiply it out and that's the answer. KNN requires quite a bit of time to query because you have to, among other things, usually do a sort to cross all the data. Ease to add new data. KNN wins that because all you gotta do is just plop it in there, you don't have to do any re-calculation. With linear regression, you have to add the new data and then recompute the factors. Well, that's all for how to assess learning algorithms. I will see you again soon. Thank you. In 1988, Michael Kearns and Leslie Valiant posed the following question. Can a set of weak learners be combined to create a single, strong learner? One answer to that question came in 2009. Back in 2006, Netflix offered a $1 million prize for a machine learning algorithm that could do 10% better than their own algorithm at predicting which movies their customers would like to see. The prize was not awarded until three years later in 2009. The winning algorithm was not a single algorithm, but a combination of several, or an ensemble. This lesson is about ensemble learners. Creating an ensemble of learners is one way to make the learners you've got better. So we're not talking about creating a new algorithm, but instead assembling together several different algorithms or several different models to create an ensemble learner. One thing I want to emphasize here is that you can take what you learn here about ensemble learners and plug it right in to what you're already doing with your KNN and linear regression models. Now, what we've been doing so far, is that we've had one kind of learning method, say KNN, we plug our data into there and we learn a model. We can query our model with an X and it will give us a Y. So this is not an ensemble learner, this is just a single learner. And the idea with ensemble learners is that we have several additional learners. So, we might have a linear regression based model, we might have a decision tree based model, we might have a support vector machine based model. You could continue this on with any different number of algorithms. They're all trained using the same data, and so now we have, in this case, four different models. To query this ensemble of learners, we query each model by itself and combine the answers. So if we wanted to query this model with X, we plug X into each model, the same X and then our Ys come out. So we have a Y output from each of these models, how do we combine them? If we're doing classification where for instance we're trying to identify what the thing is, we might have each of these Ys vote on what it is. But we're doing regression, and so the typical thing to do here is to take the mean, and that is the result for this ensemble learner. We can then test this overall ensemble learner using this test data that we set aside. Why ensembles? Why do we use them, why might they be better? Well, there's a few reasons. First of all, ensembles often have lower error than any individual method by themselves. Ensemble learners offer less overfitting. The ensemble of learners typically does not overfit as much as any individual learner by itself. Now why is that? Here's at least an intuitive answer. As each kind of learner that you might use has a sort of bias, it's easiest to talk about that in terms of linear regression in terms of what do I mean by bias. So clearly, with linear regression our bias is that the data is linear. KNN has its own kind of bias, decision trees have their own kind of bias, but when you put them together you tend to reduce the biases because they're fighting against each other in some sort of way. Anyways that's what an ensemble learner is like if we use multiple types of learners. I want you to think about the tools that you have now. You have a cannon learner, and you have a linear aggression learner. And also, we've taught you a bit about how to use the linear aggression like tools to build parameterized models. With these tools, how could you go about building an ensemble? Consider each of these approaches, A B C D and E, and put a checkmark next to the one that you think is the best solution. So some of these are okay, but I want you to pick the best answer. Okay, let's step through these one by one. A, Train several parameterized polynomials of differing degree. Yes, we could use that to create an ensemble, but that's not the best answer. B, Train several KNN models using different subsets of data. Yes, that's good too, but it's not yet the best answer. C, Train several KNN models with randomized Y values. This is, of course, a terrible idea and would give you mush. D, Combine A and B into a super ensemble. Yes, that is the best answer. E, combine B and C. And of course, that is mush as well and we're not going to do it. Okay, we're actually going to look now at this method of creating an ensemble of learners, training several KNN models using different subsets of data. There's another way we can build an ensemble of learners. We can build them using the same learning algorithm but train each learner on a different set of the data. This is what's called bootstrap aggregating or bagging. It was invented by Bremen in the late '80s, early '90s. Here's how bagging works. So what we do is we create a number of subsets of the data. I've drawn little bags here to represent bags of data. And each one of these is a subset of the original data. Now how do we collect these? Well, we do it randomly. So for this subset it contains n prime values and our original data set contains n different instances. We grab n prime of them, at random, with replacement from this original data. So what, with replacement means is, let's say we had these values, we might grab this one and put it in our bag. We might randomly grab this one and put it in our bag, but each time we grab randomly, we randomly choose across the whole collection of data. So we might choose this one again and put it in the bag. So this one and this one are really the same one and they're repeated twice. And that's okay. That's what with replacement means. So we crate all together m of these groups or bags. And each one of them contains n prime different data instances chosen at random with replacement. Let's note these things. So, n is the number of training instances in our original data. N prime is the number of instances that we put in each bag and m is the number of bags. We almost always want n prime to be less than n. Usually about 60%. So each of these bags has about 60% as many training instances as our original data. That's just a rule of thumb. Now, we use each of these collections of data to train a different model. We have now m different models, each one trained on a little bit of different data. And just like when we have an ensemble of different learning algorithms, here we have an ensemble of different models we query in the same way. We query each model with the same x and we collect all of their outputs. We take the y output of each model, take their mean, and boom, that's our y for the ensemble. Now keep in mind we can wrap this in a single API. Just like that API you wrapped your [INAUDIBLE] in and your KNN learner in. Which of these two models do you think is more likely to overfit? A single 1 nearest neighbor model trained on all the data. And by 1 nearest neighbor, what I mean is it's a k nearest neighbor model, where k is equal to 1. So, a 1 nearest neighbor model, or an ensemble of 10 1 nearest neighbor learners, where each one is trained on 60% of the data. You knew it, of course, the ensemble's going to be less likely to over fit. I've been preaching ensembles here so, you knew that was coming. But let me show you why. So supposed this is some example data and we are going to create a bunch of one nearest neighbor models. We first have to select, randomly, some of our data, to go into the first bag. So I'm going to circle some of theses points, randomly, that represent our first model. So we randomly selected some of these points. Now let's show what that model looks like. So this zigzagging orange line here represents what that one nearest neighbor model would look like. And, yes, to me it looks like it's overfitting. But that's just our first model. Then we draw some more data, and we have another model. So our other model, Model 2, is somewhat overfitting as well. Well, let's consider now a ensemble model where we combine the results of these two. And at each point where we query, remember what we do is we take the mean of the two models. So, you can see already, as this blue curve is a bit more smooth. And the individual models, we're beginning to get something better. But let's add some more models. So I've drawn over here a couple more one nearest neighbor models. And you can see each one of them individually as sort of over fit. But if we now sample at each individual spot across here and take the average across all of them we get something that's much more smooth. So here's what our ensemble looks like. And as you can see, it's much more smooth. Of course, I hand drew it. So you could accuse me of smoothing it by hand. [LAUGH] Anyways, the point here is that you can build an ensemble that is much more smooth than any of the individual learners by themselves. Boosting is a fairly simple variation on bagging that strives to improve the learners by focusing on areas where the system is not performing well. One of the most well-known algorithms in this area is called ada boost. And I believe it's ada, not ata because ada stands for adaptive. Here's how ada boost works. We build our first bag of data in the usual way. We select randomly from our training data. We then train a model in a usual way. The next thing we do, and this is something different, we take all our training data and use it to test the model in order to discover that some of the points in here, our x's and our y's, are not well predicted. So there's going to be some points in here for which there is significant error. Now, when we go to build our next bag of data, again, we choose randomly from our original data. But each instance is weighted according to this error. So, these points that had significant error, are more likely to get picked and to go into this bag than any other individual instance. So as you see, we ended up with a few of those points in here and a smattering of all the other ones as well. We build a model from this data and then we test it. Now we test our system altogether. In other words, we've got a sort of miniature ensemble here, just two learners. And we test both of them. We test them by inputting again this in-sample data. We test on each instance and we combine their outputs. And again we measure error across all this data. Maybe this time these points got modeled better, but there were some other ones up here that weren't as good. And thus we build our next bag and our next model. And we just continue this over, and over and over again up until m or the total number of bags we'll be using. So to recap, bagging, when we build one of these instances, is simply choosing some subset of the data at random with replacement, and we create each bag in the same way. Boosting is an add-on to this idea where in subsequent bags we choose those data instances that had been modeled poorly in the overall system before. All right, so I want you to think back over what we've been talking about, bagging and add a boost. Which is more likely to overfit as m increases? Now keep in mind that m is the number of bags that we're using, or the number of models that we're building to create our ensemble. So as m increases, which one is more likely to overfit? The answer is Ada Boost and the reason is that Ada Boost is trying really really hard to match those parts of the data that are off or outliers or whatever, and accordingly it's striving to fit, and subsequently it may be susceptible to over fitting. Before we finish this lesson, I wanted to summarize things and tell you how this all fits in to machine learning for trading. The first thing to point out here is that bagging and boosting are just methods for taking existing learners and essentially wrapping them in this meta algorithm that converts your existing learner into an ensemble. And you should use the same API to call your ensemble that you would have earlier been using to call an individual learner. So externally, to whatever part of your program is calling the learner, it doesn't know that underneath there you're doing boosting or bagging. Your resulting learner is also likely to lower error and reduced overfitage. So to summarize, boosting and bagging are not new algorithms in and of themselves. They're meta algorithms that let you wrap your underlying learning algorithms into something that's better. Okay, that's it for this lesson. I will see you again soon. Bye bye. Up until this point, we've focused on learners that provide forecast price changes. We then buy or sell the stocks with the most significant predicted price change. This approach ignores some important issues, such as the certainty of the price change. It also doesn't help us know when to exit the position either. In this lesson, we'll look at reinforcement learning. Reinforcement learners create policies that provide specific direction on which action to take. It's important to point out that when we say reinforcement learning, we're really describing a problem, not a solution. In the same way that linear regression is one solution to the supervised regression problem, there are many algorithms that solve the RL problem. Because I started out as a roboticists, I'm going to first explain this in terms of a problem for a robot. So here's our robot here and our robot is going to interact with the environment. So we represent the environment as this sort of cloud up here. So the robots going to take actions that'll change the environment. It will sense the environment, reason over what it sees and take another action. In robotics, we call this the sense, think, act cycle and you don't have to implement it only using reinforcement learning. There's many ways that you could implement sense, think, act, but we're going to focus on how to do that with reinforcement learning. Okay, so our robot observes the environment and some form of description of the environment comes in. Let's call that the state s, so s is our letter that represents what we see in the environment. Now the robot has to process that state somehow to determine what to do. And we call this pi or policy, so the robot takes in the state s and then outputs an action. We'll call that action a and it affects the environment in some way and changes it. Now this is a sort of circular process, the action a is taken into the environment and the environment then transitions to a new state. So T is this transition function that takes in what its previous state was and the action and moves to a new state. And that new state comes out, boom, back into the robot. Robot looks at his policy, action comes out. Now there's a question, how do we arrive at this policy? How do we find pi? Well, that's what we're going to spend a couple lessons on, but this whole puzzle is missing a piece and that's the thing that helps us find pi. And part of that piece is well, there's this other part called r which is the reward. So everytime the robot is in a particular state and it takes an action. There's a particular reward associated with taking that action in that state and that reward comes into the robot. And you can think of the robot has having a little pocket where it keeps cash and that's what that reward is. And the robot's objective is, over time, to take actions that maximize this reward. And somewhere within the robot, there's an algorithm that takes all this information over time to figure out what that policy ought to be. So let me recap a little bit. S is the state of our environment and that's what the robot senses in order to decide what to do. It uses its policy pi to figure out what that action should be. And by the way, pi can be a simple look up table. Over time, each time the robot takes an action, it gets a reward and it's trying to find the pi that will maximize its reward over time. Now in terms of trading, our environment really is the market and our actions are actions we can take in the market, like buying and selling or holding. S are factors about our stocks that we might observe and know about. And r is the return we get for making the proper trades. Now as you know, we want to use reinforcement learning algorithms to trade with. So let's think now about how we can map the trading problem to reinforcement learning. Okay, so consider each of these factors. Buy, sell, holding long, Bollinger value, return from trade, daily return. And then consider, is that item a description of our state that we ought to consider before we make a trade? Is it an action that we give to the market to cause a trade to occur? Or is it a potential reward that we would use to inform our algorithm for learning how to trade. And it's potentially the case that some of these may serve more than one role. Okay, let's step through these one at a time. Buy and sell are actions. So, those are directives we give to the market or the environment to change it, and potentially change our state. Holding long is a part of the state, it tells us whether we are holding the stock or not. We might also be holding short if we had shorted of the stock. So holding long is a part of the state. Bollinger value, that's a feature, a factor that we can measure about a stock, and that's part of the state as well. That would inform us whether we wanted to act on it in some way with an action. Return from trade, when we finally exit a position. That is our reward. We might lose money, so it would be a negative reward if we lost money. We might make money and that'd be a positive reward, so that's R a reward. Daily return, that could be either a state, in other words a factor we consider for deciding what to do, but it could also be a reward, we'll get into that more later and you'll see how it could be one or the other. Let's consider now a little more carefully how we map trading to an RL problem. So first of all the environment here is really the market. Our state that we're going to consider includes things like market features, prices, whether we're holding the stock. I'll list a few of those items right here. Our actions are things like buy and sell, and potentially do nothing is also an allowable action. So let's think about this in the context of trying to learn how to trade a particular stock. So we've got this historical time series, and let's say this vertical line is today. Now we can look back over time to infer the state of the stock. So what are the Ballinger Band values and things like that. Now we process that and decide what's our action. Let's suppose that we decide to buy. So once we buy, we're now holding long. That's part of our state. We go forward, we're now on a new state where the price has gone up. We're holding long, lets suppose we decide to sell at that point. So we've had two actions, well we've been in two states in state one we were not holding. We executed the action by, went forward in time, we're holding along now, and then we execute the action sell. Note that we made money here and that's our reward, r. So just to recap for a moment. The policy that we learn tells us what to do at each time we evaluate state, and we're going to learn that we haven't talked yet about how we learned the policy. But we're going to learn the policy by looking at how we accrue money or don't based on the actions we take in the environment. Let's formalize this a little bit. What we've been working with is something called a Markov decision problem. And here's what makes up a Markov decision problem. There are a set of states S. Those are all the values that this S can take as it comes into the robot. There's a set of actions A, which is these potential actions we can take to act on the environment. There's a transition function. This is the T within the environment. And this is a little bit complicated, but let's just step through it. T is a three-dimensional object, and it records in each of its cells the probability that if we are in state S and we take action A, we will end up in state S prime. Something to note about this transition function is, suppose we're in state, a particular state S and we take a particular action A. The sum of all the next states we might end up in has to sum to one. In other words, with probability one, we're going to end up in some new state, but the distribution of probabilities across these different states is what makes this informative and revealing. Finally, an important component of Markov decision problems is the reward function. And that's what gives us the reward. If we're in a particular state and we take an action A, we get a particular reward. So if we have all of these things defined, we have what's called a Markov decision problem. Now, the problem for a reinforcement learning algorithm is to find this policy pi that will maximize reward over time. And, in fact, if it finds the optimal policy, we give it a little symbol pi starred to indicate that it's optimal. Now, if we have these, and, in particular, if we have T and R, there are algorithms we can unleash that will find this optimal policy. Two of them are policy iteration and value iteration. Now, in this class, we don't start off knowing T and R, and so we're not going to be able to use these algorithms directly to find this policy. Most of the time we don't have this transition function, and we don't have the reward function either. So the robot, or the trader, whatever environment we're in, has to interact with the world, observe what happens, and work with that data to try to build a policy. So let me give you an example here. Let's say we were in state S1. So, that's what we observed there. Our robot took action, A1. I'm making this little subscript to indicate which step in this series of steps it's at. We then find our self in S'. And we get reward R. Now this is an experience tubal. This is very similar to experience tubal in regression learning where we have an X and a Y paired together. That's an experience tubal of you know, when you observe this X you see this Y. Here we're saying when you observe the state, S1, you take action, A1, you end up in this new state, at least it's an example of you ending up in this new state S1', and reward, R1. Now we find ourselves in a new state S2, but that's really, this state is where we found our self. We take some new action, A2, we end up in some new state, S2', and we get a new reward, R2. When we do this over and over and over and over and over again, gathering experience tuples all along the way. Now, if we have this trail of experience tuples, there's two things we can do with them in order to find that policy pi. The first set of approaches is called model based reinforcement learning. What we do is we look at this data over time and we build a model of T just by looking statistically at these transitions. In other words we can look a every time we were in a particular state and took a particular action. And see which new states we ended up in. And just build a tabular representation of that. It's not hard. Similarly, we can build a model of R. We just look statistically when we're in a particular state, and we take an action, what's the reward? We can just average that over all these instances. Once we have these models, we can then use value iteration or policy iteration to solve the problem. There's another set of approaches called model-free. And that's the type we're going to focus on. In particular we're going to learn about Q-learning. And model-free methods develop a policy just directly by looking at the data. And of course we'll talk about those soon. We didn't go into enough detail about what it is we're trying to optimize here. I just said something vague like we want to maximize the sum of our reward. Well, it's not so simple, in fact, here's a great story to illustrate that. There's a great Russian comedian, Yakov Smirnoff, you may remember him or not, but he told this joke once that I really loved. He said, have you heard about the Soviet lottery, it's a million rubles if you win, one ruble a year for a million years. So the point is, and if you recall from one of our earlier lessons, that one dollar or one ruble delivered to us a million years in the future is really not as valuable as a dollar or ruble that we get now. And so, for instance, if we think about a robot living forever, it might do something just mundane to gather a dollar a year. That's an infinite amount of money, but in practice it doesn't really work that well. So to consider that, and to illustrate that, I'm going to show you a little maze problem here, and we'll think about what the robot ought to do that would be optimal in this maze. So here's our robot, and here's the challenge for our robot. We have a reward here of $1 and a reward over here of $1 million. So if the robot comes over here and gets this $1, it's special in that each time he touches it, he gets $1 and it goes away but then it comes back. So the robot could come here go back and forth and get a dollar each time it moves here. This one, once the robot tags it, it's gone. But clearly it's worthwhile to come over here and grab it. Now this red area is obstacle, it can't go there. And here I wrote some rewards that the robot, in fact negative one is a penalty. But the penalties the robot would get as it went this way, and zero penalty that way. Now, if we say that what we want to optimize is the sum of all future rewards, then it doesn't matter whether we go this way and just get that dollar over and over and over again. Or if we go this way, get the million dollars, come back and get that $1 over and over and over again. Now there's no difference because they both sum to infinity over time. Now what if we say, okay, I want to optimize my reward over three moves. So I've got a finite horizon. Let's consider the rewards we get with a finite horizon of three if we go this way versus this way. So if we go this way, we're going to get rewards of -1, -1, -1, and if we go this way we get zero, $1, and then we have to move down here, and get another zero. So clearly, starting here, with a finite horizon of three, the best thing to do is go up there. Now, if we extend the horizon a little bit further, say out to eight, we would find that this is the best thing to do. So if we go this way, we get -1, -1, -1, until we hit the jackpot here and get $1M. Clearly if you sum this up, it's a pretty good prize. If we go this way and touch that $1 over and over again, we get this. So clearly as we expand our finite horizon trivially up to say eight steps, going this way and tagging at one million is the best thing to do. If we carried it even further, we'd discover that then we should come back this way and go to that dollar and tag it over and over and over again. Let me formalize these a little bit. With the infinite horizon what we're trying to maximize is the sum of all rewards over all of the future. So it's the sum of each of these rewards for i equals one to infinity. The finite horizon is very similar, it's just we don't go to infinity. So for optimizing over horizon of four steps, n would be four. We're just trying to maximize the sum of the reward for the next four steps. Now, there is yet another formulation that if you think back to that lecture a while back about what's the value of a future dollar. We can dig that up and it makes a lot of sense in terms of reinforcement learning. So remember that if it takes us say, four years to get a dollar, that dollar is less valuable than say if it takes one year. And the same way, if it takes, say, eight steps to make a dollar, that dollar is less valuable than a dollar I can get just in one step. And the way we represent that is very simple. Just like we represented the sum of future dividends and it looks like this, it's called discounted reward. So instead of just summing up the r sub i is we multiply it by this factor gamma to the i minus 1, such that our immediate reward, the very next one we get, whatever gamma is when it gets raised to the zero power is just one. So that means for the very next step we get r. But for the step after it, it's gamma to the one. So it devalues that reward a little bit. Gamma is a value between zero and one, the closer it is to one, the more we value rewards in the future. The closer it is to zero, the less we value rewards in the future. In fact, if gamma is set equal to one, this is exactly the same as the infinite horizon. But gamma relates very strongly to interest rates if you recall. So, if say, gamma were 0.95 it means each step in the future is worth about 5% less than the immediate reward if we got it right away. This is the method that we use in q learning. One reason is that the math turns out to be very handy, and it provides nice conversion properties. I want you to consider each of these optimizations and answer which of those will get us to the $1 million. In other words, if the robot is trying to maximize the sum over these horizons, which ones will lead it to a policy that causes it to reach that $1 million? So there are actually several that satisfy that. Infinite horizon is a little bit iffy because the robot can go this way and get a dollar on every other move and that will add up to infinity. It can go here and get the $1 million and then come back and do that and it will add up to infinity. So it's possible that infinite horizon will cause it to do that but there's two equivalent solutions. Finite with n=4, no it won't get to that $1 million. Because if it tries to go that way, it'll only get negative reward here, but it'll get positive reward if it goes that way. However, if we let n go out to 10, boom, it'll reach that $1 million. And finally, discounted reward, where each dollar in the future is only worth 0.95, and that gets smaller as we get further and further into the future. Still, by the time we get to the eight steps that it takes to reach this reward It's still so huge that that's clearly the optimal thing to do. Okay, so those are the answers to which horizons will cause us to get to that $1 million. Let's summarize things and wrap up this lecture. I just want to repeat the points so you so reinforcement learning is something that we can use in trading. The problem for reinforcement learning algorithms is a Markov decision problem. And reinforcement learning algorithms solve them. A Markov decision problem is defined by S, A, T, and R, where S is the potential states, A are the potential actions, T is a transition probability, which is given I'm in state s, I take action a, what's the probability I'll end up in state S', and R is the reward function. The goal for reinforcement learning algorithm is to find a policy, pi, that maps a state to an action that we should take, and its goal is to find this pi such that it maximizes some future sum of the reward. We talked about that being either infinite horizon, fixed horizon, or discounted sum. We can map our task for trading to reinforcement learning and it works out like this. S, our states, are features about stocks and whether or not we're holding a stock. Actions are buy, sell, or do nothing. The transition function here is the market, and finally, the reward function is how much money we get at the end of a trade. So, we can apply reinforcement learning algorithms to find this policy. We've mentioned a few of those algorithms, for example policy iteration, and value iteration, and Q learning, but we haven't talked in detail what they are, and that's the subject of lessons coming up. Okay, that's it for reinforcement learning, I'll see you again soon. This lesson is about Q-learning. Recall that Q-learning is a model-free approach, meaning that it does not know about or use models of the transitions T or the rewards R. Instead, Q-learning builds a table of utility values as the agent interacts with the world. These Q-values can be used at each step to select the best action based on what it has learned so far. The fantastic thing about Q-learning is that it is guaranteed to provide an optimal policy. There is a hitch, however, that we'll cover later. Q learning is named after the Q function. What is that? Well, let's dig in and find out. Q can be written as a function, so we might have parentheses around s and a, or you can think of it as a table. So in this class we're going to view Q as a table. And it's got two dimensions, s and a. So s is the state that we're looking at, and a is the action we might take. Q represents the value of taking action a in state s, and there's two components to that. The two components are the immediate reward that you get for taking action a in state s, plus the discounted reward. And what that is about, what the discounted reward is about, is the reward you get for future actions. So an important thing to know is that Q is not greedy, in the sense that it just represents the reward you get for acting now. It also represents the reward you get for acting in the future. Let's suppose we have Q already created for us. We have this table. How can we use it to figure out what to do? So what we do in any particular state is the policy. And we represent the policy with pi. So pi of s means, what is the action we take when we are in state s, or what is the policy for state s? And we take advantage of our Q table to figure that out. Here's how it works. We're in state s and we want to find out which action is the best. Well, all we need to do is look across all the potential actions and find out which value of (Q [s,a]) is maximized. So we don't change s, we just step through each value of a, and the one that is the largest is the action we should take. And the mathematical way to represent this is to use the function argmax, so argmax of a of this function. So what that does is it finds the a that maximizes this, and then the answer is a. After we run Q learning for long enough, we will eventually converge to the optimal policy. And we represent that with a little star. So the optimal policy is pi star of s. [COUGH] And similarly the optimal Q table is Q star [s, a]. Now this is how to use a Q table if you have it. We need now to consider how do we build that Q table in the first place. Here's the big picture at a high level of how we train a q learner. We have our data here and we select which data we want to train on, of course this data in the case of the stock market is time series. And so it's arranged from oldest to newest vertically here. So we select the day we want to train on. And then we iterate over this data over time. So we evaluate the situation there and for a particular stock that gives us s our state. We consult our policy and that gives us an action. So we take that action, plug it into our system here, evaluate the next state, and we get our s prime and our reward. So after one iteration here we've got an s, an action, an s prime, and an r. Or an experience tuple, and we use that experience tuple to update our Q table. Once we get all the way through the training data, we test our policy and we see how well it performs in a back test. If it's converged or it's not getting any better then we say we're done. If not, we repeat this whole process all the way through the training data. So what do we mean by converge? Well, each time we cycle through the data training our Q table and then testing back across that same data, we get some performance. And we expect that each time we complete an iteration here, our performance is going to get better and better. But after a point it finally stops getting better and it converges. So overall the chart's going to look something like this. Eventually we reach this regime where more iterations doesn't make it better and we call it converged at that point. Let's consider now in more detail what happens here when we're iterating over the data. So here are the details as we iterate over our training data. We start by setting our start time, which is right here at the beginning and we initialize our Q table. The usual way to initialize a Q table is with small random numbers, but variations of that are fine. Now we're here in time and we observe the features of our stock or stocks and from those build up together our state s. We consult our policy or in other words we consult Q to find the best action in the current state. That gives us a. Then we step forward and we see what reward we get and what's our new state. We now have a complete experience tuple that we can use to update our Q table. So we take this information that we just learned and we improve Q based on that information. Then we step to the next point in time and the next point time and the next next one time and so on. So these are all the details of what happens in this step of the big picture. Consider our robot here that's interacting with the world. The first thing it sees is some state, and as we've talked about already, the thing to do now is to take that state, go look in the Q table and find the action that corresponds to the maximum Q value. And then take that action. Once that action is taken, that results in two new things. One is a new state, we call that S prime, and a reward. All that information comes into the robot, and it needs to use that information to update its Q table. So as a consequence of this interaction with the world, it's got an s, an a, an s prime, and an r. How does it take that information to improve this Q table? There are two main parts to the update rule. The first is, what is the old value that we used to have? And that's Q [s, a]. And what is our improved estimate? And we want to blend them together. And to combine them, we introduce this new variable, alpha. Alpha is the learning rate. Alpha can take on any value from 0 to 1. Usually, we use about 0.2. And what that means is, in our new improved version of Q, which I indicate over here as Q prime, it's a blend of alpha times the improved estimate, plus 1 minus alpha of the old value. So larger values of alpha cause us to learn more quickly, lower values of alpha cause the learning to be more slow. So a low value of alpha, for instance, means that in this update rule, the previous value for Q of sa is more strongly preserved. So stretching it out a little bit more detail. Again we have here, our current value for the Q at s,a, plus alpha times the immediate reward, plus gamma times later rewards. Now we're introducing gamma here, so I promise there's only two new parameters here that you have to worry about. What gamma is is the discount rate. And similar to alpha, gamma usually ranges from 0 to 1. A low value of gamma means that we value later rewards less. Remember the discount rate when we were talking about bonds? Same thing. A low value of gamma equates to essentially a high discount rate. The high value of gamma, in other words a gamma near 1, means that we value later rewards very significantly. If we were to use 1.0, that means a reward 20 steps in the future is worth just as much as a reward right now. Now, we have to expand this component here in a little bit more detail. This next part here is a little bit tricky, but don't worry, we're going to step through it step by step. This component represents our future discounted rewards. In other words, we end up in state s prime, and from then on out, we're going to act optimally, or at least, the best that we know how to. And the question is, what is the value of those future rewards if we reach state S prime and we act appropriately? Well, it is simply that Q value, but we have to find out what the action is that we would have taken, so that we can reference the Q table properly. So, If we're in state s prime, the action that we would take that would maximize our future reward is argmax a prime, so a prime is the next action that we're going to take. With regard to Q, s prime, a prime. So we're going to find that best a prime, that best action, that maximizes the value when we're in that state. So this collapses just to a prime, and then we look up the Q table value for Q s prime, a prime. So that allows us to bring it all together now. So our update rule is the following. Our new Q value in state s, action a is that old value multiplied by 1 minus alpha. So depending on how large alpha is, we valued that old value more or less, plus alpha times our new best estimate. And our new best estimate is, again, our immediate reward, plus the discounted reward for all of our future actions. And that's it. This is the equation you need to know to implement Q learning. There are two finer points that I wanted to mention about Q-learning. First is that the success of Q-learning depends to some extent, well, to a large extent on exploration. So we need to explore as much of the state and action space as possible. One way to accomplish this is with randomnes. And the way we can interject that fairly easily in the step of Q-learning, where we are selecting an action, we flip a coin and randomly decide if we're going to randomly choose an action. So that means really two flips of the coin. The first is are we going to choose a random action or are we just going to pick the action with the highest Q value? Then if we decide okay, we're going to choose an action randomly, now we need to flip the coin again to choose which of those actions we're going to select. Typical way to implement this is to set this probability at about 0.3 or something at the beginning of learning. And then over each iteration to slowly make it smaller and smaller and smaller until eventually we essentially don't choose random actions at all. What we gain here is when we're choosing these random actions fairly frequently is we're forcing the system to explore and try different actions in different states. And it also causes us to arrive at different states that we might not otherwise arrive at if we didn't try those random actions. Okay, now that you have a basic understanding of Q learning, let's consider how we can turn the stock trading problem into a problem that Q learning can solve. To do that we need to define our actions, we need to define our state, and we also need to define our rewards. Let's start here first with actions. It's actually pretty easy. We just have three actions, buy, sell or do nothing. So let's consider how that might play out with an actual stock, and let's suppose we've already trained our Q learner what to do. Let's see what's likely to happen. So usually what's going to happen most frequently is that we do nothing. There will occasionally be buys and sells, but usually nothing. Well, at least, that's my expectation, we'll have to see when we create these learners what actually happens. So we are evaluating the factors of the stock. In other words, we compute, say, several technical indicators. That is our state. We consider that state and we do nothing. So let's suppose we do nothing for quite a long period here, but somehow or another, after a little while, boom, something triggers and says we should buy. So we buy the stock here we're holding it. We do nothing, nothing, nothing, nothing, nothing, nothing, and boom, our very intelligent Q learner says, hey now is the time to sell. And we continue like that through the rest of our time series. Let's consider now what these buys and sells, how they affect our portfolio value. So we start out with whatever we've got in the bank and there's no trading for a while. Suddenly there's a buy, and then we see an increase in our portfolio value until we hit that sell. Then nothing. Again, another buy, and a sell. Then nothing. So you see this sort of stepped behavior. Now of course, because I was drawing this and I wanted us to look good, I was choosing opportunistic times to buy and sell. Your real strategy is probably not going to be so good, but ideally this is the kind of thing we'd like to see. Now consider rewards for our learner. Of course it makes sense that rewards should relate in some way to the returns of our strategy. There are at least two approaches that we can utilize. Short-term rewards in terms of daily returns or long-term rewards that reflect the cumulative return of a trade cycle from a buy to a sell, or for shorting from a sell to a buy. So consider these two, daily returns, where each day we get a reward which is equal to the return over the last day, or a reward where our the reward is equal to zero, until we exit the position. Then the cumulative return that we gained across that whole trade. Which one of these do you think will result in faster conversions? The correct answer is daily returns. The reason is, if you choose the other one where we get no reward at all until the end of a trade cycle, from a buy to a sell. The learner has to infer from that final reward all the way back, that each action in sequence there must have been accomplished in the right order to get that reward. If we reward a little bit each on each day, the learner is able to learn much more quickly because it gets much more frequent rewards. This by the way, is called delayed reward and this is more of an immediate reward. Now we come to the last thing we need to solve in order to convert our trading problem into a q learning problem, and that is to define our state. I want you to consider these factors and let me know which ones you think make sense to be in this state. Okay, so here are a few factors. Look at each one and consider whether you think they make sense to be in state. And check the ones that you think do make sense. Adjusted close is not a good factor for learning, because you're not able to generalize over different price regimes for when the stock was low to when it was high. Also, if you're trying to learn a model for several stocks at once and they each hold very different prices, adjusted close doesn't serve well to help you generalize. Same thing is true for simple moving average. However if you combine adjusted close and simple moving average together into a ratio that makes a good factor to use in state. Bollinger Band value is also good. P/E ratio is good. And a new kind of feature that we're considering here with reinforcement learning, is whether we're holding the stock or not. That's an important state to know, in other words, if you're holding the stock it may be advantageous to get rid of it. But if you're not holding it, you might not necessarily want to sell. So this additional feature about what your situation is is useful. Similarly, return since we entered the position might be useful. In other words, this might help us set exit points for instance, maybe we've made 10% on the stock since we bought it and we should take our winnings while we can. So both of these are important and good factors to have an acute learning system. So an important consideration in what we're doing here is that our state is a single number. It's an integer. That way we can address it in our cue table. It is certainly the case that some reinforcement learning methods are able to treat the state as a continuous value. But just to get started here, let's use state as an integer so we can work more easily with the data. Now we have to do a little bit of work to get our state to an integer and here is the general way to do it. Our first step is to discretize each factor. It's a weird word, I'll explain it in a moment. But it essentially means convert that real number into an integer. Next is combine all of those integers together into a single number. We're assuming that we're using a discrete state space and that means more or less that our overall state is going to be this one integer that represents at once all of our factors. So consider that we have four factors and each one is a real number. Now we have separately beforehand figured out how to discretize each one of these factors. So we run each of these factors through their individual discretizers and we get an integer. Now I've happened to select integers between 0 and 9 but you can have larger ranges, for instance 0 to 20 or 0 to 100 even. It's easy if we just go from 0 to 9 because then we can stack them together into a number. But it's not too hard to think of algorithms will enable you to combine larger ranges of integers together. In this case we're just able to stack them one after the other into our overall discretized state. Discretization or discretizing is an important step in this whole process. What we want to do is have a way to convert a real number into an integer across a limited scale. In other words, we might have hundreds of individual values here between 0 and 25 of a real number, and we want to convert that into an integer, say between 0 and 9. There's a fairly easy way to do that and I'll show you how right now. So here's what we do. First thing is we determine ahead of time how many steps we're going to have. In other words, how many groups do we want to be able to put the data into? Like I said before, to have an integer between zero and nine, we would use ten in this case. So we divide how many data elements we have all together by the number of steps. Then we sort the data, and then the thresholds just end up being the locations for each one of these values. So in other words, if we had, say, 100 data elements and we were going to have 10 steps, our step size is 10. So we just find the 10th data element and that's our first threshold, and then our 20th and 30th and so on. It ends up looking something like this. When the data is sort of sparse, our thresholds are set far apart. When the data is not sparse, these thresholds end up being closer together. So in this particular example, our thresholds might end up looking something like this. And when we go to query, when we have a new value and we want to see what is its discretized value, we'll say it was a value here. Boom, it's between those two thresholds, so it would be an 8. Okay, let's recap what we've learned about Q-Learning. First, let's consider what it takes to build a model. First step is define states, actions, and rewards. So states are combinations of our features. Actions are buy, sell, do nothing. And rewards are some type of return. Next you choose the training period and you iterate over that training period and update your Q-table on each iteration. When you reach the end of that training period you backtest to see how good the model is and you go back and repeat, until the model quits getting better. Once it's converged you stop, you've got your model. Testing the model is simple you just backtest it on later data. Remember we're always training on one set of data and then testing on later data. And that's it. I hope you enjoyed the lesson. One problem with Q learning is that it takes many experienced tuples to converge. This is expensive in terms of interacting with the world, because you have to take a real step, in other words execute a trade, in order to gather information. To address this problem, Rich Sutton invented Diana. Diana works by building models of T, the transition matrix and R the reward matrix. Then after each real interaction with the world, we hallucinate many additional interactions, usually a few hundred. That are used then to update the queue table. Dyna-Q is an algorithm developed by Rich Sutton intended to speed up learning or model convergence for Q learning. Remember that Q learning is model free. Meaning that it does not rely on T or R. T being, our transition matrix and R being our reward function, it doesn't know it. Q learning does not know T or R. Dyna ends up becoming a blend of model free and model based methods. Here's how it works. So let's first consider plain old Q learning. Dyna is really in addition to Q learning. So let's start with the regular Q learning and then look at how we add Dyna into it. So we initialize our Q table and then we begin iterating. We observe s, we execute action a and then we have observe our new state s prime and our reward R within updater our Q table with this experience tubal and repeat. And we do that over and over and over again, interacting with the world and our Q table becomes better and better. So when we augment Q learning with Dyna-Q. We had three new components, the first is that we add some logic that enables us to learn models of T and R then for lack of a better term we halucinate an experience. So rather than interacting with the real world like we do appear with the Q learning part and this is expensive by the way. We hallucinate these experiences, update our queue table and repeat this many times, maybe hundreds of times. This operation is very cheap compared to interacting with the real world. So we can leverage the experience we gain here from an interaction with the real world, but then update our model more completely before we step out and interact with the real world again. After we've iterated enough times down here maybe 100 maybe 200 times. Then we return back up here and resume our interaction with the real world. The key thing here is that for each experience with the real world, we have maybe 100 or 200 updates of our model here. Let's look at each of these components in a little more detail now. So in this part where we update our model. What we really want to do is find new values for T and R. The point where we update our model includes the following. We want to update T, so I'm calling it T prime for the moment, which represents our transition matrix and we want to update our reward function. Now, remember that T is the probability that if we are in state s and we take action a will end up in s prime. And r is our expected reward if we are in state s and we take action a. I'm going to show you in a moment how we'll update T and R Here's how we hallucinate an experience. First, we randomly select an s, second, we randomly select an a, so our state and action are chosen totally at random. Then we infer our new state s prime, by looking at T. And we infer a reward, our immediate reward R by looking at big R or R table. So, now we've got s, a, s prime and r. Or a complete experience tuple and we can update our Q table using that. So, the Q table update is our final step and this is really all there is to die in a queue. We've added these three sections and what's missing and I'll get to in just a moment is how do we update our model of t and our model of r? So what I'm about to show you are my methods for doing these things they may not correspond exactly to what Rich Sutton did. So keep that in mind but I've used these methods in practice and found them to work really well. Let's start with Learning T. Remember T of SA S prime represents the probability that if we are in state S, take action A we will end up in state S prime. To learn a model of T. we're just going to observe how these transitions occur. So in other words we'll have experience with the real world we'll get back on s, a, s prime and we'll just count how many times did it happen. So I'm going to introduce a new table. I call T count or TC. And it goes like this. So we initialize all of our T count values to be a very, very small number. The reason for that is later on you'll see that if we don't do that we could get in a situation where we have a divided by zero. Then we begin executing Q learning. And each time we interact with the real world we observe, s, a, and s prime. And then we just increment that location in our T-count matrix. So every time we see it transition from S to S prime with action a, boom, we add a one. And that's pretty, it's pretty simple. That's it. Okay, assume now we've been watching our interactions with the real world for a while and we would like to consult our model of T. I would like for you to write an expression for T in terms of Tc or T count. Okay, so fill in this text box with your opinion of how we can compute T of s, a, s prime in terms of T sub c. And remember T sub c is just the number of times each one of these has occurred. Okay, consider that state s and a are somewhat fixed. What we're trying to find is given s and a, what's the probability of a particular s prime? So, we'll begin this by just consulting how many times did this transition occur? In other words, how many times when we were in state s did action a, did we end up in s'? So that's how many times this particular transition occurred. Now we just need to divide it by the total number of times we were in state s and did action a. So essentially, it's the sum over i. Where we have i iterate over all the possible states of T[s, a, i]. So this is the number of times in total that we were in state s and executed action a. And so this ratio ends up being the probability that will end up in s' if we're in state s and take action a. The last step here is how do we learn a model for R? Now remember, when we execute an action a in state s, we get an immediate reward, little r. So again, big R, s, a as are expected reward if we're in state s and we execute action a. Little r is our immediate reward when we experience this in the real world. So big R is our model, little r is what we get in an experience tuple. So we want to update this model every time we have a real experience. And it's a simple equation, very much like the q table update equation. What we have is one minus alpha where alpha is our learning rate and again that can typically be something like zero point two. Anyways we multiply that times our current value for R and then we add in of course our new estimate of what that value ought to be. And we just use r for the new estimate. So it's alpha times little r, which is our immediate reward, or our new best estimate of what the value should be, plus what the value was before times 1 minus alpha. So we're waiting presumably. Our old value more than our new value, so we converge more slowly. But that's it. That's a simple way to build a model of R from observations of interactions with the real world. Before we close, let's recap really quick how Dyna-Q works. So, we start with straight, regular Q-Learning here and then we add three new components. The three components are, we update models of T and R, then we hallucinate an experience. And update our Q table. Now we may repeat this many times, in fact maybe hundreds of times, until we're happy. Usually, it's 1 or 200 here. Once we've completed those, we then return back up to the top and continue our interaction with the real world. The reason Dyna-Q is useful is that These experiences with the real world are potentially very expensive and these hallucinations can be very cheap. And when we iterate doing many of them, we update our Q table much more quickly. I'm Tucker Balch, we're here with Tammer Kamel, founder of Quandl. We're going to dive now into details about how the Quandl platform works. So let's start with sort of a big picture, imagine I'm a hedge fund and I'm interested in working with Quandl. How does Quandl fit in to my work flow? Right. So in any hedge fund where quantitative thinking is some or part of the investment strategy, then at the very start of that process, is good, high-quality data. And that's where Quandl starts and finishes, in a sense. We view it as our mission to get the data that professional investors need into their hands and into the format that they need it in. So Quandl offers a hedge fund literally dozens of mechanisms to pull that data. Whether it's a low level API and they can pull the data right into a database that they're maintaining themselves, or into Python or R, or MatLab or Stata or any analysis tool they might be using. But we consider our job, mission accomplished for Quandl, if we quickly and painlessly get the hedge fund the data they need into the system they want. Now presumably, this includes a combination of historical data and live data. Are all of your feeds historical as well as live? Or are there some that are special in some way? Right, so all of our data is historical for sure, and updated daily. Live data is a little bit in the future for us, it's not available on the platform as of this moment. So I could imagine a flow something like this. Lots of people are on a daily cycle. I think that's a majority of what people do. You might read historical data to inform your model or build some sort of model. But after market close, you wait some period until the market data is available and then whatever data one might pull from Quandl, do some number crunching overnight and put in orders for what you might do in the next day. Now what time does your data available and what mechanisms do people use to pull it? So what you described is really a canonical use case for Quandl, right. A fund or an analyst will take the historical data, build and calibrate a model, and when they're comfortable that it's ready for action, then they're going to start executing on it. So Quandl market data is updated pretty quickly after the close, within minutes or depending on the exact database, we're talking about ours so. But definitely in time to run today's numbers through your model to get the output and know what actions need to be taken on the next trading day. So I love to learn details about how people build complex financial systems. So where do your machines live? So Quandl is quite modern in that respect. Everything lives in the Cloud. We're customers of Amazon, like so many others are. At the heart of Quandl is a modern, no SQL database. And that's where the 15, 16 million times series, few billion data points live there. On top of that, we've built an API. And then the Quandl website itself, interestingly, is itself just another client of the Quandl API. If you look at our website, you will discover it's perfectly orthodox. It's a standard Ruby on Rails website, built very conventionally, it's just another client of the Quandl API. Why the choice of no SQL? So because of scalability, right? We really need to be able to deliver lots of numerical data to lots of people very, very quickly. The number of data points in the Quandl database is in the order of a few billion now, but we expect that to be 10 or 20 or 50 billion within a year or two, and at that point, conventional relational databases get kind of difficult to work with. So the glue between the various components is Ruby on Rails? It is, indeed, yeah. So it's no SQL and Ruby on Rails, and that's it? That is it. Quandl is, by software engineering standards, pretty plain, vanilla, simple implementation. Where Quandl, where we sweat day-to-day is usually in maintaining the accuracy of 12 million data sets. The technical infrastructure is, not to say it's trivial, but it's conventional best practices software engineering. Getting back to the data, tell me a little bit about timestamping. Let me tell you what I'm getting at. So let's just consider market close data. So the price for a particular stock essentially is stamped at 4 o'clock, so one potential timestamp for that data is New York time, [LAUGH] one potential timestamp for that data is 4PM, but maybe I can't observe it until 4:05. That's just one example. But I'm curious, does that sort of time stamping feed into what you all do? Yeah, that's actually a really good point. I suppose what you're getting at is the risk of creating a look-ahead bias in your analysis, right? Yeah. You know what, I can't claim that Quandl has any sort of panaceas for that sort of thing. We time stamped the data, of course. And the meticulous, diligent analyst should be aware of this kind of thing. And they'll see that this database is the 4PM closing prices, but- This more likely did occur with things like earnings reports. Yeah. With those sort of things, we reach to the vendors and the publishers for this, but they are acutely aware of that, so you'll see. Take for example our earnings data. They're both as reported to the point and time data and revised data. So those kind of blatant risks of the look-ahead bias, those are well mitigated. When you look at your various vendors who are providing you data, what sorts of flaws do you see in that data and what sorts of steps to you have to take to mitigate those flaws? It's interesting, there's no such thing as a perfect data set in this world, right, and we're of course strongly motivated to get as close to that ideal as possible. The way we've done it is kind of simple, but also a little bit original. And it falls from the mechanism we've set up, where consumers of data have a direct relationship with the publishers of those data. And indeed, the publisher of the data's livelihood depends on keeping that consumer satisfied or happy. And so unlike sort of many other data platforms, where there's a lot of opacity between the end user and a lot of layers too, between the end user and the actual publisher. In fact, you might in many cases, not even be able to reach the publisher. Quandl has this direct relation. So what you find is that if and when there's errors in the data, our publishers are very keen to correct it, and fast. Because they've got 5 or 10 or 50 customers who know it's them who are responsible for it, and they're keen to keep these people paying for the service. Right? So this is an amazing, this is a reality that happens in many marketplaces. When you start removing the distance between the end consumer and the actual producer of the product, you get this quality improvement. The other thing that, of course, affects that is good old healthy competition on a marketplace. We actually, right now, for some databases, we have two or more vendors offering competing products and nothing drives quality control like competition. Okay, great interview. Thanks very much. I'm sure the students out there will find this fascinating. Thanks for your time, I really appreciate that. That's the end of this discussion with Tammer Kamel, and we'll see you online. Hi there, I'm Tucker Balch. I'm here with Tammer Kamel, he's founder of Quandl. We're here at Quantcon, which is a conference organized by Quantopian. So I want to talk with you now about your experience advising hedge funds. I guess you have some experience actually managing money. And students in the class are really interested to hear about real live strategies that succeeded or failed or lessons learned. So what is jump diffusion? The jump diffusion was a model to try and capture the sixth sigma event. And the idea here was, it was a smart idea, and I can't take credit for it entirely. But the idea here was if you mix normal distributions and drew from them at different probabilities. So for example, you had a distribution with volatility of sigma. I think I know what you're talking about, but I just want to review it, in case folks there, so they can follow. So you might have a distribution of returns for one strategy or one stock. Right. And so you're talking about the distributions for maybe different strategies or different stocks and then potentially combining them in some way. Yeah, exactly. And everybody assumes those distributions are Gaussian, right? So the bell curve- Right. And so, Gaussian distributions are so delightful to work with, right? [LAUGH] So, the problem is that reality doesn't intersect with them that much, right? But one nice thing you can do is you can actually simulate reality a little bit better if you use not one, but two Gaussian distributions. And as your random variable moves, you draw usually from the first normal distribution. But then with some random probability, you draw from a distribution with a much higher standard deviation. Thus simulating these rare events and creates the fatter tails, and is great for risk management. It's predicted power is minimal, because it's random so you don't. But for risk management it really gives you a much better sense of the fact that- [CROSSTALK] So you might have a current portfolio and do some sort of Monte Carlo simulation to see how risky that portfolio is. That's exactly the use case. Gotcha, gotcha. Okay, okay. So in one of your earlier careers [LAUGH], you advised hedge funds. What sorts of strategies did your company generate and advise the hedge funds on? So I graduated from an engineering program at the university in the mid 90s. And I always call this sort of the golden age of quantitative financing. It was an era when Wall Street was plucking young vulnerable engineers like myself, [LAUGH] And having us mathematically model markets. And back then there was all kinds of really fat opportunity. The first thing we used to do was- Anybody with a computer could make money, right? [LAUGH] Well if you could do a bit of math you really could, right. There was this thing, we made a lot of money on was yield per arbitrage. If you did just a [CROSSTALK] model the swap curve, for example, with a two or three factor model. And you would discover, a, that at any given time, some deviation between a sensible looking yield curve and what was- So a particular asset would be currently priced in a such a way to be contrary to what the yield curve would predict? What it would come down to is it would be mis-priced relative to its peers on that yield curve, right? And backtesting would tell you, would confirm that time and again, that anomaly would revert back to something more normal, right? So you could make a lot of money by taking these reasonably sophisticated yield curve positions. Where you were long at two points of the curve, and short at two other points of the curve, and you get these funky butterfly kind of trades, right? But they'd be sort of neutral to the level of the curve, and even neutral to the slope of the curve, but there's these third and fourth factors that would be in revert all the time. So, to take a short position in a fixed income, you would have to be a credit swap of some sort? Or how would you do that? Many ways you can do that. Credit swap certainly does it. There was no such thing as a credit swap when we were doing this. You could short a government bond, borrow it and sell it in the repo market? I just think of with the way you can trade today electronically, you never really think about the borrowing and the reselling. Right we used to worry about that stuff. Yeah repo rates, and all of that. But yeah, that's been extracted away to some extent, right? But yeah, that's how we used to do it. But, so you talked about looking at yield curves. Did you all do anything in equities? Or was it just primarily the fixed income? We did, also in the 90s, stat arb and even simple pair trades were very effective trading strategies, right? There was a lot more inter-stock volatility. A lot less correlation between the stocks, at least until the late 90s and the crash. And you could even do more sophisticated stuff like the stat arp stuff or eigenvalue PCA analysis on stock markets and do sort of payer trading strategies on these. So a lot of that stuff doesn't work anymore. No it doesn't. [LAUGH] That's why I started a data company. I see, okay. Anyways, I wanted to ask to what do you attribute the evaporation of alpha and these kinds of approaches? I think there's a lot of interesting things going on, right? There's no question that the number of participants executing similar strategies is a factor. Volatility is low these days, right? And these strategies thrive in high volatility environments, right? Like the 90s was a much higher volatility environment, even in a bull market. Another big advantage we had in the 90s was the phenomenon of the day trader, which was for lack of a better term, incompetent trading. Right. Right, which would create all kinds of wacky, if the day traders woke up on a Tuesday morning and they were all in love with Ebay for example. Then everybody just went and bought that, and it would create a mispricing in Ebay, right? But what you don't have irrational actors in the marketplace, it makes these relative value pair trades are harder to adapt. And I guess at that time maybe the day traders were a higher percentage of the volume, right? It was definitely a large fraction of the volume, or a meaningful faction of the volume. Taking food from children's mouths. [LAUGH] So if someone were, some young whipper snapper wants to go out and start creating some kind of systematic strategy, is there any alpha left out there? Or where should somebody like that start? Oh, I'm sure there's all kinds of alpha to be had. It's just you have to, don't look in the same old places because everybody already has been there and there's only a bit. I think there is all kinds of opportunity if you find new information sources. You hear great stories about little creative ideas where you pay someone sitting in China to count trucks coming out of a factory. Right, right. Right, you've heard this one. And then you get a sense of how production is going for that company. Very simple little information advantage. Right. Mechanical Turk like sorts of things. Yeah, yeah, yeah. There's all kinds of things you can do with that. So I think that's fascinating. The one thing I would say to sort of reinforce the kind of thing that Quandl can offer is we often find that the combination of different data sources adds value. So as an example, maybe over simplified. Back in the 90s, a strategy, say based on Bollinger Bands, might have worked when you hit the top that could be a cell signal. Nowadays, that just by itself, it doesn't work. [LAUGH] But, a combination of multiple technical indicators plus some fundamental data, putting all those together instead of just a simple, single factor model can work. Yeah, I know, I think so. I still have, there's three rules of thumb for building quantitative strategies these days. I think one should look for theoretically sound ideas. So don't bet on black box, neural net, kind of things, because they always fall down, right? But if something makes theoretical sense in an economics or financial sense, it's a good chance you're onto something. So it's a good intuitive story to start with. Exactly, it actually should make sense on a whiteboard to start with, right? Grounded in some of the fundamental principals that we know govern financial markets in economics right? Number two is empirically tested, right? So build something that's theoretically sound and then show yourself empirically, with data, that this thing worked. And then the final thing is be scared of complexity. If it doesn't stay simple its a warning sign your probably over fitting and getting yourself into a trap. But if you devise a strategy that ticks these three boxes, that it's sort of theoretically sound, empirically testable, and still simple, you're probably on the right track. Yeah. [LAUGH] That's great. I'm in total agreement with you. So, one last question. So we've talked about things to do or how to attack it. What should people run from, [LAUGH] what should they be scared of? Look I think the single biggest trap, and I've fallen into this thing myself, right, is if you find yourself calibrating the same model on the same data usually, and you calibrate it. Oh, it doesn't quite work. And then you turn a few knobs and it doesn't quite work. And then the eighth time you finally turn the knobs just right and it's working? Odds are you've just curve fitted, right?. Don't fall into that trap of endlessly iterating on the same data. Because you're in for unpleasant surprises once you get into, out of sample data. Great. Yeah. [LAUGH] You're totally going to reinforce the things I say in the class, so that's awesome, but they don't believe it when they hear it just from me. Trust me. I've lost a lot of my [LAUGH] Cool. Well that's it. Fantastic, great interview. Thanks so much for your time Tammer. The pleasure was mine Tucker, thank you. And hope you all enjoyed it and I'll see you online. So long.