Welcome to this course on Android design. I'm Nick, a Design Advocate at Google. And I'm James, a course developer at Udacity. And I'm Roman, also a Design Advocate at Google. If you haven't figured it out already, this is a course on Android design. With over a million apps in the Google Play Store, design is an important element to making your apps stand out. Right. And unlike the early days of Android, it isn't enough just to have a good idea, and to implement it. Your users will expect, nay, demand something that's easy to use and beautiful. In this lesson, we will start with a quick overview of Android design principles. In the rest of the course we'll explore key Android design principles through the lens of material design, the new visual language in Android 5.0. Let's get started. In this lesson we're going to cover a lot of ground. We'll talk about choosing the right UI patterns, laying out your screens, working with graphics and texts, and a whole lot more. But before we get into all those really fun things, we'll first need to learn about one of the core aspects of Android design. That your designs must work on a lot of often very different devices. Android runs on all types of things from tiny watches to phones and tablets, even to cars and TV's. This variety can be daunting. The good news is that Android has been designed to handle this variety in device types from day one. The platform gives you a whole bunch of tools and techniques for handling different devices easily and gracefully. Your goal should be to create a single app that runs across a range of devices adapting the interface depending on what device it's currently running on. As we'll find out throughout the course, optimizing the user experience across a variety of device screens and form factors isn't that difficult, and can actually be pretty fun. Let's start by talking about the screens on all of these different devices. At the end of the day, what good is designing beautiful buttons, text, and graphics unless you understand the screens that it will be shown on, right? When thinking about the variety of screens your Apple run on, it can be tempting to look at the screen's resolution as the number of pixels on the screen. Screen resolution is a commonly used spec when buying a device, but it's actually not that useful when designing for Android. because thinking of screens in terms of pixels ignores the notion of physical size, which for touch device is really really important. When Android was first released, there was a single commercially available device. The T-Mobile G1. As a result, it was easy and often common practice to design with the resolution of this device in mind. Mobile designers accustomed to IOS, where there was only one form factor to design for, would apply that same practices to Android and design assets for one or two flagship devices with exact pixel sizes. These designs would look horrible when viewed in a device with different proportions. Android 1.6, Donut, introduced support for more varied device types and densities. Recognizing that generating pixel perfect assets for every existing device doesn't scale and that one would need a systematic way to deal with assets on different screens to better fit. Density-independent pixels allow the designer to create assets that appear in an expected way, no matter the resolution or density of the target device. A density-independent pixel is equal to one pixel at the baseline density, or 160 dpi. They're often abbreviated dip or just dp. Don't confuse that with dpi which stands for dots per inch. So, what about at 320 dpi? This is often called 2x. Now, at 320 dpi, 1 dp is equal to 2 px. So, working with density-independent pixels helps you deal with crazy situations like this where you may have two devices with the same pixel resolution but differing amounts of space. In this case, the tablet has a lot of space and the phone has a lot less, but they have the same pixel resolution. We'll see how density-independent pixels makes this much easier to work with. Now because the tablet is at the baseline density, its physical and density independent pixel sizes are the same, 1280 by 800. This phone, on the other hand, has a higher pixel density, so it has half as many density independent pixels as physical pixels. So 400 by 640 density independent pixels. Now using density independent pixels makes it easier to mentally picture, that you have much more space on this tablet than you do on this phone. Similarly, if you have two devices with similar screen sizes but different pixel densities. One is, let's say, 800 by 1280 pixels, and the other is 400 by 640 pixels, you might think that you have to design totally different layouts for the two of these devices. However, when you think of the screens in terms of density independent pixels, they are the same size. They are both 400 by 640 dps. This makes it a lot easier to make layout decisions. You don't have to design completely separate layouts. You basically just design once, and you'll kind of use the same layout across both of these types of screens. Let's try an exercise. Here's the 2012 version of the Nexus 7. The screen resolution in pixels is 1280 by 800. The density is 213 dpi, and the diagonal screen size is seven inches. Now, using the conversion formula we looked at before, what's the resolution of the 2012 Nexus 7 in dips? So, using this formula, we can see that the Nexus 7's resolution in dps is about 960 by 600 dps. It's larger than a phone, which is about 360 dps wide, and smaller than a 10-inch tablet, which is about 800 dps wide. So you could see that this 600 value, this is the width when it's held in portrait. Is neatly between this 360 dp wide phone and an 800 dp wide 10 inch tablet. You might be enticed to start your design work for larger screens. After all, everyone has these humongous phones and tablets these days, right? While the average size of phones and tablets is growing, we're going to consciously design for the smaller sizes first. If you design an interface for a phone screen, it's still usable on a tablet screen. It might have lots of white space and look odd, but the app will still work fine. Now you can't see the same for a tablet UI viewed on a phone. That'd be really hard to use, all those little touch targets. Starting with small screens also really helps you simplify and prioritize what should go into the UI. At each step we want to carefully consider which elements, if any, to add to larger screens. Instead of using the device's exact pixel density which can vary quite a bit like 311 dpi or 442 dpi, Android groups devices into a number of density buckets. Each device gets assigned a density bucket that most closely matches its actual pixel density. So a device with a 311 dpi screen might get assigned 320 dpi or XHDPI, and a device with a 442 dpi screen might get assigned XXHDPI or 480 dpi. Though there are density buckets for both incredibly low density screens, like 120 dpi, and really high density screens, like 640 dpi, you generally only have to work with the middle four shown here, 160, 240, 320, and 480 dpi. And these are sometimes referred to as 1X, 2X, and 3X. Now, these buckets give you control over the scaling of your graphic assets, things like icons. They also ensure that you don't have to create hundreds of different versions of these little icons for each screen's exact pixel density. They essentially make your UI elements almost exactly the same physical size, like really, really close while letting you only produce assets for a handful of densities, these four. So we've all seen it. When we load an older app on our nice new device, sometimes icons look really, really blurry. In these cases the app most likely used a low-resolution asset for a UI element that was given a larger size. An easy first step to improving an app is to make sure it has a high-resolution assets like this one. Much better, right? While you should generally provide assets for all these major density buckets, it's normally okay to include just XHDPI or XXHDPI assets, and let Android scale them down or down-sample them. It's not ideal, but if you had to pick one, provide the higher density assets and not just the lower ones. However down-sampling has risks. There's a minor performance hit when Android has to do scaling for you on the fly. Additionally, Android's down-sampling algorithm is really optimized for speed, not perfect scaling. It doesn't look great at all if you have to down-sample from a very large 16 by 16 hundred pixel graphic to a small 200 by 200 pixel space. The good news is, there are lots of great tools out there for automatically creating graphics for all the major density buckets when your creating you're app. One example that's useful for icons is the Android Asset Studio. Check the instructor notes for a link. Back in the days when there was just one screen density for devices, a designer might create a pixel perfect logo or other graphic in Photoshop. Now that was fine, until more screen densities started coming along, like HDPI and XHDPI. You'd need to redraw the pixels in the graphic at a larger size to ensure it was the same physical size but look perfectly crisp on the higher density screen. With four or five popular density buckets these days, this practice can get really tedious, really really quickly. Designers who don't want to repeat themselves should use a graphics app that can work with and export vector graphics. Apps like Photoshop and Gimp are geared primarily to working with rastrographics. That means they store the actual color information for each pixel in the resulting image. Those raser images can be scaled down with no problem but you start to see blurring and other bad artifacts when you enlarge them. Vector graphics apps like Ink Scape, Illustrator, and Sketch, instead store information about the individual shapes in the image. For example, the center and the radius of the circle. So you can scale the image up or down without any loss of quality. The shapes will just be drawn at a larger size. While Photoshop lets you work with vector graphics too, Illustrator and Sketch actually let you export your graphics to vector format like SVG or Scalable Vector Graphic. In newer versions of Android, you can directly use vector images in your app, using a format similar to basic SVG. Sure beats exporting a bunch of png files over and over again, right? So, here is the resources directory from a sample project created in an Android studio. There are some predefined drawable folders for different screen densities such as mdpi, hdpi, xhdpi, and xxhdpi. And if you remember that's 160, 240, 320, and 480. Additionally, there's a drawable folder with no qualifier. This is useful for things like XML shapes. There's also a folder called Drawable-nodpi which you can put in images that shouldn't scale based on density, things like background images. If you remember from Android fundamentals, there are also qualifiers for user locale, screen width, API level, and more. These can be applied to any type of resource, whether it'd be graphic assets, layouts, or text strings and style definitions that you would put in your values folder. So you could customize a layout for screens that are 600dp or wider. Or you could provide styles that only apply to Lollipop devices, that's devices with API level 21 or higher. And if you wanted to customize graphics assets for specific languages, you could do that, too. Just remember to also specify the density for those assets. Check the instructor's notes for a link to developers.android.com and a listing of the accepted resource identifiers. Graphic elements of your user interface can change appearance to reflect the different states they're in. For example, they may change appearance to show that they are checked, or pressed, or focused, or even some combination of that, such as both checked and pressed. If you were making a web app you would define these states in CSS, but in Android we use state lists. States lists are XML files that list the assets to use given a particular state of a UI element. You just give it a range of resources for the different states and everything is taken care of for you. So here's a state list for check boxes drawable. It uses different images for each of the defined states. When the check box is just checked, it uses this image. When it's just pressed and not checked it uses this one and if it's both checked and your finger is pressed down on the check box, it should use this image. And by default, and in this case where there are no special states, it just uses this default version. When using a stateless drawable for a UI element, Android traverses the selector and looks for the first item that meets the minimum criteria for the state. So if you want to use an image to represent multiple states, such as this one, pressed and checked, that should be above the more general ones. Now, the interesting thing about states is that you can even create your own. While there's things like pressed and checked, and focused and selected and activated, and really a lot of different types of states, you can even create your own states to map to whatever your application needs to represent in its UI elements. So now that we understand how to address the variety of screen sizes and densities out there, we can get into how we go about constructing your user interface. As you remember from Android Fundamentals, your UI is a nested tree that we call the view hierarchy. Now, this tree defines the entire structure of the UI from the root view group all the way down to the leaf views, such as text, buttons, or images. Now, every single thing you see on the screen in your app is a view somewhere in this hierarchy. You can define your UI either by creating these objects in code, or by declaring your layout in an XML file. Now we very much prefer the latter approach, as it allows you to separate the presentation from the app's behavior. Each element in your UI will have a number of parameters associated with it. Some are common and must be provided for all views, such as its width, height, or location on the screen. Other parameters are specific to a particular view, such as a button will have parameters for its background and the text to display. Let's dive in and see how the elements are sized and placed on the screen. If you've ever dabbled with web development, then you'll be familiar with the box model in CSS layouts. If you haven't, let's take a quick tour. Now all UI elements in Android take up a rectangular space equal to the minimum rectangle needed to enclose the object. We call this the content bounds. Take this avatar place holder image for example. Even though the image is a circle. It's content bounds are this enclosing rectangle. Well, that's not entirely accurate. The objects bounds also include any padding, that is, any space that is considered to be part of the object that push its bounds outwards. So, in our example, the bounds would be equal to the content's area and plus any padding applied to it. When positioning an element relative to other elements, you might also want to leave some space between them. This is where we can use margins to add extra space between objects that critically isn't considered to be part of the element. So we've seen how both padding and margins can be used to add extra space around an element. So you might be wondering when to use one or the other or perhaps even a combination of both. Now the key thing to remember is that if you want the space to be part of the object, then you should use padding. And if you don't want it to be part of the object, then you should use margin. So, when do you want it to be part of the object becomes the question. The answer is if you want the touchable area or the background of the object to be enlarged, then use padding, otherwise use margin. So in our example, if you want this avatar to be clickable with a nice, big touch target. But we don't want any touch highlight to extend too far towards the other items. We could use a combination of padding around the element to enlarge the touch area. And then margin between the elements to separate them out without that being part of the clickable zone. For those familiar with the web box model, notice that there's no concept of borders. While you can still apply borders, these are typically achieved using background images. So now, that you know how individual UI elements are sized. Let's talk about how to start arranging them together. Let's have a quick refresher on what you learned in Android Fundamentals 1 about the core layout managers. Like frame layout, linear layout, and relative layout. Now, remember a frame layout arranges the views inside it, one on top of each other and each view can have a gravity or stretch to fill the width or height of the parent frame layout. So frame layouts are a great way to display overlapping content. A linear layout arranges its children in a single direction. For example, a vertical linear layout arranges its children from top to bottom. Linear layout is one of the most useful layouts to have in your toolbox. You can create pretty much any layout with it. Be careful though not to over rely on this as another layout might be more efficient way to create the desired effect. A relative layout arranges its chart views relative to each other or to its bounds. So for example, a field can align to the top left or top right or to the bottom edge of the relative layout. While a relative layout can be powerful, it also has some performance implications. So be weary of using this layout especially near the root of your hierarchy. A GridLayout arranges children in a grid, shocker. When each child has a given row or column within that grid, they can be arranged automatically in any direction. And now, have a weight property in order to fill a column or row. GridLayout is a great way if you want to align content along multiple axes, such as vertically and horizontally at the same time in a grid which you would be hard to achieve with a different nested layout manager. A ScrollView is a very simple view which holds one single child. It allows you to scroll its contents, either up or down. In under fundamentals, we also touched on ListView and its newer cousins RecyclerView and ViewPager and how it dynamically uses a small number of child views to present a small window into a larger collection. ListView and RecyclerView let you scroll through a list of items, while ViewPager let's you horizontally page through individual items. To understand when to use a particular view group, let's take a look at some examples of real world screens and talk about how you would build them. After that, we'll show you a quiz and ask you, yes you, to apply layouts to build up a relatively complex UI. Okay, so here's our first simple example UI. You might recognize this as something similar to Gmail. How would you go about constructing this UI? In my situations where you have stacked content like this, one on top another, it's likely you'll want to use a linear layout. Now the red toolbar at the top, which we'll go into a in a bit later on in the course, is going to have a fixed height, and the second view in the linear layout, whatever that is, should take up the remaining space. Here you can see if I stretch it out, the red toolbar remains the same height, but the list expands to fill the space. So the way we do that is we set a weight of one and a height of zero dp. The zero dp height tells us that we aren't using a fixed value here and it will be worked out later. Now, below this toolbar is this list and this floating red button here, which we'll go into, again, later. Now because these elements overlap each other, we'll want to use a frame layout. For the list, we use a list view or a cycle view, so that will be the first child, and it will have a layout width and height of matched parent. The button will then be the second child, where if a gravity at bottom end, and a generous layout margin, something like 16 dp to move it away from the edges. And in case you're wondering, the frame layout should be the one that has the zero dip height, and layout weight of one. Here's another, similar example based on a contacts app, say for creating a new contact. Now in this situation you again have a toolbar at the top with a scrolling section below it. Since we have a fixed set of form fields, instead of a list view, we're going to use a scroll view that holds a grid layout. The grid layout contains a left column with icons which identify the form of sections and then a right column containing the form fields themselves. Now when using the scroll view, it can only contain one child view, and that child should have its height based on its contents. That's why we use wrap content for the height of the grid layout. One quick note here. If we want the toolbar to scroll off the form, we'd simply move the toolbar inside of the grid view as its first row, and set its layout column span to two so it fills both columns. Let's look at one final, more complicated, example. This resembles an apps detail page in the Play Store. We can see there's this banner image at the top with an overlayed toolbar on top of the image. Below that, there's this scrollable white pane with details of the app. Now the overall composition is a frame layout because we want the toolbar to overlay the image banner and the entire screen to be scrollable. The first child is an ImageView because we want it to be behind everything else. It has a fixed height, but its width can vary, so we use a scale type of center crop to ensure that the image itself always covers the entire banner area. Next is the scroll view which contains a vertical linear layout. Because we want this to appear in front of the image when scrolling, but behind the toolbar, the linear layout itself has a white background, but it's offset by 200 dp using top padding on the scroll view. This makes the image visible behind it, but as you scroll, the image becomes obscured by the scroll views background. The final child of the frame layout is this toolbar which sits on top of everything else with a transparent background. Now, when composing this kind of UI, you'll likely want to do some tricks to slowly move the image at a different rate to scrolling, or perhaps fade in a background on the toolbar and the title as we scroll. There's some common techniques that we're going to go through later in the course on how to go about doing this. Now finally for the things inside the linear layout, we can use nested layouts such as another horizontal linear layout for these buttons across here. Okay, last one. But this time, let's make it interesting. Here's an example layout. You've got a large app bar at the top of the screen with icons along the top and text along the bottom. There's content below it and whoa there's this button straddling the edge between the bar and the content and it's along the right side. Now you're pretty familiar with layout hierarchies at this point, right? To check that you understand, take a look at these possible hierarchies and select the ones which you think might be appropriate to create this kind of UI. So the answer is A and D. Let's first take a look at why B and C wouldn't work. For B, because the button overlaps the toolbar and the content view below, you can't really use a linear layout. Because in linear layouts, children can't overlap. You see, because the button needs to appear above the toolbar, it can't be the middle child. It would need to be last. Now A works well. All three children of the frame layout are anchored to the top of the screen with varying offsets. They're also in the right drawing order. First the content, then the toolbar, and then the button. And D works great at well. The toolbar and content are arranged in a vertical linear layout. We wrap the linear layout in the frame layout, so that we can place the button at any arbitrary location on the screen. In this case, along the right edge and offset from the top of the screen by a fixed number of DPs. So we just recapped different layout managers and looked at how you'd use various layouts together to create some example screens. As you probably noticed we started using these circles and buttons and toolbars. Let's start diving a little deeper into what some of those elements were and why they keep appearing all over the place. Now each application is an individual snowflake with different content and goals. Just because they're unique though, it doesn't mean that we should force users to learn new conventions to operate them. By following some established patterns of the platform, you can accelerate your users understanding of the app, making it feel intuitive. Imagine if every model of car had a different layout of the pedals, the steering wheel and the levers. While you might be able to learn one model you'd have a hard time moving to another. Your UI is exactly the same. By following some conventions users can quickly get in and drive your app. Here is some of the most prevalent patterns used on Android to organize your interface and navigate around it. A Toolbar is a horizontal bar, which provides a standard way to present titles and actions in your lab. It's made up of a navigation area on the left, a title area, and the menu of actions. It's a very flexible widget, and each of these function is optional. A nice feature is that the toolbar can show actions either directly within the tool bar, or they can be collapsed under a sub menu known as an overflow if there isn't enough room. And it will base it's decision on whether there's enough room to show everything. Tapping the overflow item itself yields this overflow menu of additional actions you can take. The toolbar itself is a view group, so you can add children to it. For example, I could add a Spinner Control as a child view to provide some kind of navigational control. Now, toolbars are used extensively in Android. So they're very recognizable to your users, and a common place to look for actions or present them. They generally use a standard height which varies by screen size, and can be queried using the actionBarSize Free match P. They're also a great place to embed your brand's color. Next, the App bar. The app bar is just a special case of a toolbar, where it's placed at the very top of the screen. As such, the title field often provides a screen title. And the navigation icon provides access to screen level navigation options. The app bar often uses an extended height to provide more space for branding or to contain a header image. In this case it's using multiples of the standard height. Next up Tabs. Tabs let you organize and navigate to different sections within your screen or app. On Android, tabs always appear at the top of the screen. And you can switch between them using a horizontal swipe gesture. Generally, they sit on the same surface as your app bar, if you're using one. Now, tabs can be a great way to provide the main way of navigating about your app. Or providing sub-navigation if you're using a different top-level navigation construct. Such as a Navigation Drawer. Now a Navigation Drawer is a panel that slides in from the left of the screen and it contains the top level navigation options to different parts of your application. The drawer itself can be divided into sections and frequently provides access to account information here in this top area. Now, the drawer is closely associated with the so-called hamburger icon. This three-line icon in your toolbar. Either pressing this or dragging from the left edge of your device will open the drawer. The drawer can work well if you have a number of different sections that you want to provide quick navigation to without taking up persistent space on every screen. However, if you don't need this, say if you only have a few sections to navigate between, then a different pattern, like tabs might be more relevant as they're going to be more obvious to your users. It's also important to use restraint and thoughtfully select items to put in the navigation drawer. It shouldn't become a dumping ground for all the things. Android also has pretty common patterns around Scrolling and Paging. Users are typically comfortable with scrolling vertically to see more information on the screen. Horizontal scrolling is less common, especially with text content, as it can be frustrating to read. More common is to use a horizontal gesture to page through content. So, each gesture takes you to one screen page, back or forward. So for example, if you're reading emails or news stories, then it's a very useful pattern. Horizontal Paging is especially common for a details view launched from a list, where you have a mental model of what the next page of items might be. Note, that as we just covered in the tab section, horizontal swipes should change pages between tabs. So the effort is kind of incompatible to use both tabs and horizontally paid content. Another extremely common pattern on Android is List to Details, where you would show a list of individual items and clicking on one would take you to a subsequent detail screen. You've probably used this 100 times. Such as viewing your contacts or reading news stories for example. A variation on this pattern is to show both the list and detail sections on the same screen on larger devices. So here these two screen would be separate on a small device and brought together on a larger device. Showing just a list on a large screen can look awkward and leave a lot of empty space. Additionally, showing both items at once can allow you to obtain more context about the activity you're performing and prevents what we call Pogosticking. Where the user is forced to go into details and back up, and into a details and back up. We'll go into much more detail on other patents for larger screens in lesson five. Now it's absolutely okay to deviate from these patents if and when it makes sense for your specific use case. These are patents after all, not strict rules. But make sure you're doing so for good reasons, as you'll be asking your users to learn a bespoke interaction. The phrase I like to use here is deviate with purpose. Picking an application's structure and navigation scheme depends on the content in your application. A good exercise is to sketch out an Entity Relationship Diagram. This shows the objects in your application and how they relate to each other. Once you understand this, you can pick an application structure to match. Let's start with a simple to do list. What do you think are the major entities that this application contains? Check all that apply. The correct answer is options a and b. A to do list is something that will contain to do items. To do items will have the particulars of the item to be done. Once we understand the entities, we can pick an appropriate application structure. The main content that your app deals in should be on the first screen and it should offer navigation to related actions. Let's take a look at Simple Note and reverse engineer what the entities are. It's clear that the hero of the app are the notes. And with a click or two, you can see the other entity tags. Now that you know a little about how your app will be visually organized, and some of the common design patterns you might use, let's talk about how you can customize its look and feel. Android uses themes and styles to create reusable sets of attributes that can be applied to your UI to customize it. It's similar to CSS on the web. A style the appearance of a single UI element. You might change the style of an element for branding reasons, such as the color or the font. Or for practical reasons such as legibility. A theme uses the same syntax as a style, but applied as a collection of styles to an element, an activity, or even your whole application. Now styles always operate on a single element. Whereas themes cascade to its children. For example, if you wanted to turn all of the buttons in your application pink to match your branding, then you can create a style to do that. And then apply it to the whole application theme. Next up James will show you how to apply this lesson. Thanks Nick. Here on this Android device we have an activity with an element that we want to change, namely this text field here. So let's switch over to Android Studio to see how we can do this in code. In the project window here, under this folder called values. We have a file called styles.xml, this holds the default theme for this application called AppTheme. As we can see, we have no customized properties in our AppTheme. As we can see from this parent property, AppTheme derived from Theme.AppCompat.Light.DarkActionBar. Now, let's look at some of the properties that make up this DarkActionBar theme. So there are a couple of ways to do this. So if we right-click and go down to Go To, and then Implementation or you can Ctrl+Click. So we see the style right here. The Theme.AppCompat.Light.DarkActionBar. That derived from Base.Theme.AppCompat.Light DarkActionBar. So if we go to that one, we can see there a couple of properties here. Some of the interesting ones here are the colorPrimaryDark and the colorPrimary. Now, you can go and see what those colors are by doing another Ctrl+Click. And we see right here that, that corresponds to a black color. So now, that we're back in our styles.xml file, let's create a new style. So in this code right here, we have a style called MyStyle that assigned a greenish type color to android:textColor. So now, that we have our style, let's assign it to an actual element. So if we go back into our project view, let's go to layout > activity_main. So here's the text view that we previously had that shows up as a grayish color. Let's go in here. So in these text views declaration, we just need to add this last line here where we say the style is equal to @style/MyStyle. And that's referring to the style that we created before called, MyStyle. One thing that you notice is the style property right here, isn't appended with an android:. So if we go over to the design view, we can see this green color here for Hello world! So your style should look something like this. We have a bluish color in red-green-blue notation, and a bold style. Now one thing that you might want to notice is over here in the column, it shows you a small preview of what the color is. So if we go over to our design view, we can see that the text has changed to a bolder blue color. Styles and themes bring the unique character of your company's product to your app. We will do a formal deep dive in lesson three when we discuss, Bold graphic design. In the meantime, you can take a look at some open-source apps like the 2014 Google IO Scheduler app or this list on Wikipedia of open-source Android apps to see what others have done. Now, be advised that not all of these apps use material design principles, you might see some old UIs in there. Material design is a system for cross platform visual, motion, and interaction design. It employs our experience of the physical world to make UIs more intuitive. It borrows ideas from print design world to help drive simplicity and beauty in UIs. At a glance, it might appear as another implementation of flat design. While material rejects the tropes of extreme skeuomorphism, it does bring in physical world concepts like light and shadow and rendering volumes. Now the four main concepts of material design, and coincidentally the titles of the next four lessons are. Tangible surfaces, surfaces that we can touch and react to our input. Bold graphic design. An homage to great typography and print layout. Meaningful motion. Motion that guides and encourages the user, and. Adaptive design. UIs that look great no matter how large or small the screen is. Now we mentioned cross platform before. While this is a course on Android, material design is intended for use on many different platforms, such as the web. A lot of the design principles you learn about here will be useful outside of just Android. As in the first lesson, I'll walk you through code samples that will help you tackle the final project. Welcome to lesson two. We're going to start by digging into one of the key materials in material design, paper surfaces. Material design seeks to describe what your UI is made out of. We use the metaphor of distil paper to build on top of people's real world experiences to make your UI easier to understand. Right. We'll explain how the idea of tangible surfaces can make your app easier to interact with, how it can focus attention, promote key actions, and delightfully respond to user input. Once we've covered the theory, we'll go over how to apply this practice to our Android apps. We have a certain intuition about what objects will feel like, and what we can do with them, just by looking at them. We call these affordances. Take for example, this piece of paper, and this apple. I know from my previous experience with paper that I can easily pick it up. I can twist it. I can tear it, and so on. I know that the apple has greater mass. It'll be harder to pick up, but that I can throw it up or even take a bite out of it. Now these learned expectations help us to quickly recognize how we can interact with objects. Now completely recreating real world objects in our UIs can be limiting and have some adverse affects. We can, however, take advantage of some of these basic principles of affordances and tangibility to make our UIs more intuitive. In material design, we imagine UI's to be composed of pieces of digital paper, which we call surfaces. Now these surfaces have tangible attributes to imply real world behaviors, but they aren't limited like their real world equivalents. Everything on the screen lives in one of these surfaces, including all texts, icons, photos, buttons, any UI element, really. Now, these surfaces have a tiny amount of physicality, just enough to show that one thing is distinct from another. And how they sit relative to one another. This taps into our instinctive ability to quickly recognize objects. There's no need to take the metaphor too far, and use real world textures, sheens, spectral highlights, and so on. Just the smallest set of real world cues are enough to express a lot of meaning. Surfaces also exist in 3D space, we have varying widths and heights, and at different elevations. These surfaces are arranged in front of and behind one another, and cast shadows on lower surfaces. So here we can see as the fab raises up in elevation, it casts a more diffused shadow. Let's take a small detour and really focus in about how and why shadows get cast by surfaces. In general, objects that are closer to us command more of our visual attention. And we can tell which objects are closer based on their size and how they cover and cast shadows. On the things that are behind them. So we can use depth as a queue in our UI to direct attention to important elements. So how do we use these concepts on a 2D screen? We use the shadows to convey a surface's elevation relative to other surfaces. Surfaces nearer to you will cast a larger shadow. There's a lot of complicated maths behind how to draw these shadows correctly. But luckily, on Android, we only have to edit a bit of code to have the shadows drawn dynamically for us. Let's take a quiz to test your little on how this hierarchy works. Given this interface, rank the component by their elevation. Let's take a look at the answer. That's right, this floating circular button here casts a large shadow on the other surfaces in our interface, so it must be the highest surface. Next is the blue surface just below it. And then lowest in the hierarchy is the background surface. You might not have caught it, but there is a slight shadow that the blue surface is casting on the background. Just by looking at the screen, even without any text or icons to guide us, we can immediately establish a sense of the hierarchy of these UI elements, the higher ones commanding the most visual attention. A surface is a container for your content and provides grouping and separation from other elements, but there are other lighter weight ways to visually group the content. So when should you create a surface? Let's look at an example. Here, we have a surface for the app bar and a surface for each list item. The issue here is that the surfaces act as a kind of cognitive speed bump. While it's useful to visually separate the app bar from the content, placing each item on an individual surface lowers your speed in scanning down the list. A much cleaner approach is to simply draw the content on a single service using a subtle separator. Conversely, in this example, placing each of these very different items onto their own separate surface let's you visually process each one individually. A good rule of thumb is if content is homogeneous, when scanning and comparison will be important, then it likely belongs on a single surface. If you need to present a collection of heterogeneous items, then individual surfaces are appropriate. Directing attention is a powerful technique, but needs to be used judiciously. Having too many separate surfaces on a screen at once can be distracting. As a very rough rule of thumb, try not to have more than around five surfaces on the screen at once. So let's talk about how to actually create a surface with the Android STK. So, as we said, a surface is essentially a container which casts a shadow. We can identify which views in our hierarchy are surfaces and set appropriate backgrounds and elevation values. So let's start with a simple example and create a screen that contains a single surface that casts a shadow. So here I am in Android Studio looking at a simple activity layout file. I have a frame layout which will be our surface. I can give it a height and width and some margins and set its background here to white. To create a surface, the key thing is I can set this elevation value here. Here I'm setting 4dp, and Android will render that as a shadow for us. The elevation is the distance of surfaces above the back plane. Higher values produce larger shadows. So here we are running this on a device. And as you can see, our frame layout is casting a shadow along the bottom edge onto the background behind. This clearly shows that it's a separate surface. Back in Android Studio, I can duplicate our surface a couple of times, so the same frame layout. But here, I'm setting different values for the elevation. So we have one set with 4 dp, a second set is at 8 dp, and a third at 16 dp in front of the back plane. Running this, we see that Android renders these three different surfaces of different shadows. So here's a subtle shadow, a little more noticeable, and more noticeable still. The higher the elevation values produce a larger more diffuse shadow giving the appearance of being higher up or further in front of the back plane. Let's get our feet wet and apply this concept to an app mock screen by making it more material with some surfaces. The goal of this app, Walk In, was to replace those buzzers you receive at restaurants. Instead of sticking within a short range, you could scan a QR code, get on the list, then go off and do whatever you wanted until you were notified that your table is ready. It was one of those apps I developed back in 2011. You can call it a bit vintage, back when Android specific design hadn't taken off yet. So how will we use surfaces to make this screen more material? The image and the restaurant information are related so they should be on their own surface. The items in the queue are also related, that's another surface. The last surface is the button bar down here. It'll be replaced for other reasons, but for the purpose of this exercise, it also should be a surface. What is the standard elevation for an app bar? The standard elevation for an app bar is four dips. In the elevations and shadow section of the material decision guidelines, we have a chart here that the resting elevation of different u types. Now if we scroll down this list, we can see here that the resting elevation is four dips A hallmark pattern of material design is using a floating action button or F-A-B, FAB. This is a vibrant-colored circular icon button that floats above the rest of your content in your app. And it's a way of promoting a prominent action and of communicating the character of a screen. As this button floats in front of other content, it's always easily accessible and communicates its importance. While it floats above content, and generally has the highest elevation of all views, it can still respond to changes in other parts of your UI. For example, scrolling with the content or repositioning. FABs have standard sizes and elevations, so that they are recognizable across applications. They come in either 40 or 56dp diameters and generally have a resting elevation of 6dp, rising to 12dp when pressed. While they can be positioned where ever makes sense for your interface, they tend to sit well on seams and steps where two surfaces meet or anchored to an appropriate corner. Just as the FAB is a great way to direct attention, you should be careful not to overuse it everywhere in your app, and only use a single FAB per screen. Not every screen needs a FAB, but if there is one clear action on the screen then it's a great way to promote it. If you're struggling to identify which action should be a FAB then it's a good sign that you probably don't need one on that screen. So let's continue to work with the Walkin app. We've identified the key component to the app of surfaces, but we still have that pesky ancient toolbar. Which of the following toolbar button should be a floating action button? Scan, The List, or Settings? The correct answer is Scan. It's the only option out of the three that's a clear action. The other two are nouns describing things that you want to view, set or change. You want to view the list and set or change settings, but scanning a bar code is a clear thing you're doing and you'll likely want to do when you open the app. Now that we've identified what should be our promoted action, let's create one. The designs port library implements all the features one would have to build into a fab, like touch elevation and interaction with other elements. Some features, like ripples, are not supported in all versions of Android, even with the use of the support library. Depending on when your project was created, or what version of Android Studio you use to create it, the project might already have some of the things I'm going to add. On the other hand, you'll likely come across a legacy app that you would need to update, so it's good to know what to look for. First you'll need to add these two lines to your build.gradle file. I'll explain why we need appcompat in just a second. The design library adds several widgets and layouts that make implementing material design much easier. 22.2.0 was the most recent version at the time of recording, but use whatever is the latest and greatest. So here's our definition of the floating action button that will be in our layout file. So as you can see some of these attributes are on the app namespace, and some are on Android namespace. Let's focus on the app ones. So as Nick mentioned before, the fab can be normal sized or mini. This corresponds to 56dp. Next we have an elevation, a resting elevation for our floating action button, we want that to be 6dp. One thing that might be new is layout gravity. Assuming a left to right layout system, end is a synonym for right. So it should lay out the fab to the right of whatever element or your layout. Next is the pressedTranslationZ property of 12dp, so when this button is pressed, we want it to raise to a total of 12dp. That's followed by a bunch of attributes here that you've probably already seen before. So we're not going to go over these point by point right now. Now, if we try to build this right now, it'll refuse to run properly. Android Studio will first complain that there was an error inflating the floating action button. That's because the fab needs AppCompat for style information. To resolve this last error, we need to replace instances of Material with AppCompat. And then you're all set. You're fab will elevate and show ripples when touched. And you can treat it like any other button in your UI. In Material Design, there are two primary forms of visual feedback in response to touch. The first is a subtle ripple effect that radiates outward from your finger, extending to the bounds of the surface that it's drawn on. For borderless elements, the ripple extends out just enough to give you a sense of the element's size. We sometimes call this an ink ripple. Because we liken to a wave of digital ink spreading on a surface. Almost like a droplet of ink falling and spreading on a piece of paper. This idea of radial motion emanating from your fingertip is a key theme in material design that we'll touch on more in lesson three. User initiated radial response not only puts the user in control of the UI, but it will make the UI really satisfying to use as well. Now, let's look at the second form of visual feedback. For smaller interactive surfaces like buttons, the surface itself can lift to meet your finger. Almost like your finger is magnetically attracting that surface. So you see here that the fab rises to meet my finger as I'm pressing it. The design support library has a built in fab widget. It already has ripples and elevation enabled. But it's a good exercise to wire up one yourself to see what's been done for you. We're going to create this app. It has two fab widgets. One we've created by hand, and one that uses the design support library. So I've gone ahead and created a new project and selected the Blank Activity option. In my build.gradle file, I've made sure to add the design support library as a dependency. At the core of a fab widget is an image view. We can make life a little bit simpler by using an ImageButton. I've set the background to use the accent color, and a plus button as the source image. Fabplus is a vector drawable I've created. You could use an image with transparent images, but it's more scalable to use a vector drawable because they can be resized without any quality loss. As you can see here, our button isn't very circular. We can do that by setting it's background to be a shape shaded in our accent color. Now is also a good time to set our elevation. Because we use the background drawable, Andriod can use that data to calculate a shadow. We don't need it in this case, but you could create a custom outline provide to control how shadows are cast. You can see more information about that in the instructors notes. So going back to our button, we have a button that we can click and that has elevation but it doesn't have any ripples and it doesn't raised to our touch. Let's go ahead and add a ripple. To enable ripples, we need to change the buttons background from a static shape to one that's enclosed in a ripple tag. The color control highlight is the color applied to things like ripples, list selectors, etc. The main difference between oval_shape and oval_ripple is that the ripple tag encloses our shape. The next thing we need to do, is add a material reaction to the fab widget to raise it up to meet our touch. To do this, we'll add a state list animator to run an animation when the user touches the button. In the layout, we reference a file fab_raise, that lives in the resources anim directory. We have two object animators, one for when the button is pressed and one for when it's released. Notice how we animated the translation Z property of the button, rather than the elevation. The final elevation is calculated by adding the current value of translation Z to the base elevation we set in code. So this translation Z property goes from a value of 0 to 8 dps. Now if we remember, our fab button has a resting state of six dp. So it's going to actually go from an elevation of 6dp to 14. You won't generally need to implement fabs from scratch and you definitely should use the design library. But it's likely that you'll need to create custom widgets that you'll need ripples for or elevation changes. While the metaphor of paper and ink are useful, we'll still designing for digital medium. So we shouldn't be limited by those pesky rules of physics like their real world equivalents. Material surfaces have some unique properties that bring them to life, and let your applications connect with users. Material surfaces can be created and destroyed, they can change shape, split apart or rejoin like this example. Similarly, a section of the surface that is ink components can lift out and form their own surface. You can see this happening in this parent to child example. Where a list item lifts out and expands to become the detail screen. These material properties can help you to create immersive applications that respond to interaction, rather than jumping into new states, making them easier to comprehend. We'll expand on using motion in lesson four. One easy transformation we can do is a circular review. We'll cover other elements of meaningful motion in more detail later in the course, so let's consider this a preview. In this app, clicking one of the recycler view items will kick off a circular review transition to new item texts. The circular reveal effect is used a lot in material design and ties in nicely with ripples. So let's talk a little bit about how we're going to make this circular reveal. This is the signature of the createCircularReveal function. The view we're going to operate on, a center X and Y to start the transition, a startRadius, and an endRadius. So let's say this is the view group holding the text we want to change. First we need to find the center point of our reveal. We can do that by taking the item's width and height and dividing in half. The reveal should start from nothing, so our starting radius is zero. You might remember from geometry class that the diameter is a line segment that passes through the center and whose end points lie on the circle. The radius is half of the diameter. So if we fit our item to a circle, and situate the center points here to line up, our ending radius would be from about here to here, or a little bit more than half the width of the item. One reason why it would be a little bit more, is just because if it's a square item, it's not going to perfectly align with a circle, so you would need to adjust that. So now we have all the pieces we need to create a circular reveal. As I mentioned before, you couldn't just use half of the width of the item. You actually need to use the hypotenuse of half the width and half the height. And here are all the components of the createCircularReveal function that create our animator. After that set, we chang the text, and the title, along with the background color. Lastly, we start the animation Just as materials can change width and height, they can also change elevation. We saw a glimpse of this with the magnetic reaction of buttons to the touch of your finger, but this can also occur with interactions such as scrolling. Consider two surfaces which start off in the same plane and move together and lock step. At a certain point, one surface may need to stick and raise up to allow the other to pass below it. We call this a seam to step transition. The two adjacent surfaces first form a seam. But when the lower surface slides below the other, they form a step. For example, this app employs an extended app bar that collapses to a standard height and pins to the top of the screen as the user scrolls. So you see the elevation increasing. Now, you can build this effect entirely in XML using the new at bar layout and collapsing toolbar layout. Let's look at some layout XML code. At the root, we start with coordinator layout which helps coordinate behaviors across several kinds of views. In this case it will coordinate the scrolling of a list with the scrolling of our app bar. Since CoordinatorLayout is in the android design support library. We'll need to references it by its full class name and also include the app name space for support library attributes. We'll use and AppBarLayout under the CoordinatorLayout and give it the expanded height we want of 168dp. Within that we'll include a CollapsingToolbarLayout and tell it to scroll off the screen until it reaches the collapsed size, that's this exitUntilCollapsed flag. Inside that we'll place our Toolbar widget. And give it the smaller height we want to collapse to the 56dps. Note that the collapsing toolbar layout will be responsible for drawing the title. The toolbar widget here is only responsible for drawing the icons. Finally, the other widget here will be a RecyclerView, which uses a special predefined layout behavior that triggers appbar_scrolling when the RecyclerView is scrolled. The Android design support library does all the rest. Check out the documentation for scroll flags in layout behaviors to find out about other great scrolling behaviors you can build with the library. Using these techniques we can divide our UIs into surfaces to communicate the relationship and provide interaction cues. Interfaces should be dynamic. Responding to user interaction and clearly communicating any changes in state. Remember these techniques when trying to express the relationship between your UI elements. They'll help make your screens immediately comprehensible and make your app much more intuitive. Let's go to James, who will show you how to put this to practise with code. So let's get started by looking at the example Roman discussed. The awesome thing about this is that most of the logic lies in the layout file and the Java code stays pretty tame. The only time you refer to the collapsing toolbar layout is here, where we assigned the title. Collapsing tool bar layout allows us to set the title style when the tool bar is expanded or collapsed. We'll explore in a moment why this is useful. So, let's take a look at another food inspired app. As we can see, we don't have to be limited to a solid background when dealing with a collapsing toolbar. When you scroll, the image disappears and the word eclairs appears in the app bar. The interesting bits about this image view are right here. We want the image to have a parallax effect as it collapses. That's to say that the foreground moves faster than the background, providing a sense of depth to the scene. In this layout we have a text view whose content takes up a lot of space. We would expect to need to use a scroll view. Without this line, the app doesn't know when to scroll the toolbar, so your toolbar remains stationary. This is because AppBarLayout expects to have a sibling in CoordinatorLayout that is capable of nested scrolling. You can do that with a nested scroll view from the support library, or by setting nestedScrollingEnabled to true. The nestedScrollingEnabled property is only present on scroll view for Lollipop and above. Nested scrolling works with CoordinatorLayout to notify and manage when the app bar should be scrolling, the nested view should be scrolling, both should be scrolling, or none. Check the instructor's notes for some resources on AppBarLayout. Okay, we've been talking a lot about surfaces, elevation and how surfaces behave when you interact with them. Let's take a quick quiz to see how we're doing? Here you see three different screens. In each screen, there's an app bar and some content. But the surface arrangements in these three screens is very different. Notice the shadows are a bit different here. And when you scroll the content, the natural behavior of the surfaces in each screen differs as well. For each screen assuming the app bar doesn't change its elevation check the box if the app bar should stay in place when you scroll the content. The answers at the app bar should stay in place at the first and the third screens. Let's take a look. In the first screen, since the app bar is above the content, forming a step, the content surface should slide beneath the app bar. In the second screen, since the app bar and content are adjacent surfaces, they form a seam. When you slide the content surface, the app bar has to move as well to make space for the content surface. In the last screen, the app bar is below the content surface, again, forming a step. But, this time, when scrolling the content, it should cover the app bar since the content surface is at a higher elevation. In this lesson, we learned about constructing your UI out of tangible material surfaces. We learned how surface arrangement and layering can make UIs easier to understand. We discussed how to determine which actions should be highlighted in a FAB and how to have surfaces react to touch and scrolling. In the sample app, we put these concepts into practice with code. In lesson three we'll start thinking about the content of those surfaces. The ink on our digital sheets of paper. Stay tuned. Instantly recognized by most of the connected world, the Google logo wasn't always so polished and also has a rich typographic history. The original logo was created by Sergey Brin in GIMP in a typoface called Baskerville Bold. That's right, in GIMP. There was even a time when the Google logo had a exclamation point like with Yahoo! Ruth Kedar designed the logo we see today, but before the final design was reached, She iterated on a whole bunch of ideas. The final wordmark is set in the Catull typeface, using the primary colors in green. It's continued to evolve over the past 16 years with minor refinements, and most recently, a flatter more simplified look. Now Google doodles have become a much anticipated part of the Google.com homepage. but did you know the idea for doodles came about when Sergai and Larry wanted to mark the occasion of attending Burning Man in 1998. The doodle is a temporary mask that denotes holidays, signficant events, or figures. The doodles stylistically mix organic and inorganic objects and figures to make the letter forms. And after viewing just a few of them, thanks to the gestalt laws of grouping, your brain immediately recognizes even very lyrical and stylized drawings as the individual letters in the word Google. Now material design utilizes these very same principles and concepts to make it easier for users to comprehend your UI. Knowing all that will you look at the Google logo the same ever again? Welcome to lesson three, where we'll cover bold graphic design. In lesson two we talked about surfaces, kind of like these sheets of digital paper. Now, let's go further with the physical metaphors of material design and talk about what appears on that paper, digital ink. Specifically, we'll be diving into design elements like space, color, type, and imagery to make your apps more beautiful and impactful. The world around us is complex. We're constantly being bombarded with visual information, pictures, words, symbols, and more. When it comes to quickly processing that information, we make sense of the chaos around us by using a few tricks. We recognize patterns, compare and contrast things, and refer to our past experiences all in an instant without even realizing it. We can make sense of how our brains do this by looking in the field of cognitive psychology. More specifically, a set of principles called the Gestalt Laws of Grouping. Let's take a quiz to get started. Here's a UI from which we removed all the images and text. What do you think this app does? There may be more than one correct answers, so don't think about it too hard. Now the only two options out of the four that the UI probably wouldn't be is a photos or maps application. Rather, it would be a really bad way to browse photos or maps. The one or ones you guessed were likely influenced by the apps you currently use or used to use. You see the boxes as individual events and the circles as the creator or owner of the meeting you might have set a calendar. Or maybe a person and their name. The point of the matter is that you derived a lot of information about the user interface based on how it was arranged. So let's go through some of these Gestalt Principles. The first is the Law of Past Experience. Early apps and mobile platforms took advantage of this by sowing you digital versions of things from the physical world, like notepads, stop watches, and weekly planners. The lines on the paper of a notepad app are sometimes referred to as skeuomorphic details. They're ornamental decorations that can make the UI feel a little more comfortable and familiar to the user. As mobile devices became more and more prevalent, it became less and less useful to incorporate these kinds of details. People became more and more comfortable using apps that didn't exactly look like their real world counterparts. And how about the Law of Proximity? Returning to the example from our quiz, these boxes representing text are close to these circles that are likely images. They're closeness tells us instinctively that they must be related. The text is probably the label for the image. Even without knowing what each item says, we won't mistake the relation between this and this with something like this and this. We can also recognize that these three items are close to each other while the others aren't. This helps us further visually deconstruct what's going on in this screen. Finally, we can take this a step further with the Law of Similarity, and recognize that each of the items in this list must represent similar things because they look basically the same. The cool thing is, all we did here to set up these relationships was use white space to our advantage. Adding more space between elements separated them both visually and conceptually. Tightening the space between elements help them feel more related to one another. Now that we have a better understanding for how things can be grouped together to communicate relationships, let's talk about the specifics of laying things out on the screen. Material design uses an 8dp grid to align components. Text aligns to a 4dp baseline grid. Let's take a closer look at the grid so you can see it a bit clearer. Notice that for finer grid control, the baselines of text sit on a 4dp grid. That's kind of a subset of this 8dp grid. So things like image and icon sizes, spacing, margins, and paddings are all multiples of 8dp. So things like 16, 72, 40, and 16, those are multiples of 8. And for text, line heights are multiples of 4, so 20dp. These 8dp and 4dp grids allow us to easily apply the laws of grouping and keep our UIs organized, balanced, and in harmony with the rest of the operating system. There are material designed templates and stencils that use this grid, available for Adobe Illustrator, Photoshop, and Sketch. Check the instructor's notes for links to them. Even though there's a grid, we need a couple other pieces to lay out our UIs. Keylines are used to vertically or horizontally align objects in a user interface. Aesthetically, they enforce a sense of order in a UI. They also make it much quicker to scan the screen and take in the information. The material design specs suggest some common keylines to use in mobile design. Using 16dp margins from the left and right for auxiliary content like icons, and avatars, and so on, and 72dp from the left edge for the primary content, the things like the page title and the page contents. Now, if you don't have auxiliary content, then your primary content should probably also align to the 16dp keyline. And the exact value of these keyline is less important than the concept aligning content to bring order to your UI, and making it quicker to visually parse. Before we move further, let me pass it over to James to have you apply these concepts in Android Studio. Let's take a look at Muzei. Muzei, is a live wallpaper application that displays a new work of art as your background every day. If you go and check out the source code, in addition to Roman, you'll see Ian Lake listed a number of times. You might remember him from our advanced Android App Development course with Joanna and Dan. Muzei, is a good example, because it makes extensive use of dimensions files to make its UI work on multiple form factors. So I went ahead and downloaded the source code from the link listed in the instructor's notes. Now in this dimensions file, this is for the tablet screen, with the smallest width of 600 dips. And we can see that we have a number of dimensions listed in here. We also have a general dimensions file that lists many of the same properties, just with different dimensions. Now, if we go to our activity, we can see how we use these dimensions, so instead of specifying the dips right here, we're using @dimen and then the name that was specified in the dimension file. Now Android Studio does a couple of things for you. So, sometimes you'll see the dimensions like this, where they're listed in green. If you ever see a property that's listing gray, that means that Android Studio is showing you the value that it's pointing to. So if you hover over one of these, you can see the dimension value that Android Studio is pulling from. We've evolved to recognize color and shapes at a very basic level. Just as we saw how shape and arrangement can tell us a lot. We also infer information from an item's color and appearance. Color can tell us if a particular food looks ripe or rotten, if we should stop or go or if our battery is running low. It can be used to direct attention or imply hierarchy and structure. Material design encourages you the app developer to embrace bold purposeful uses of color. Not just for aesthetics, but to make your app easier to use. The material design color pallet includes a set of primary and secondary colors that can be used across devices. One note on the material pallet is that it is in no way restrictive. These aren't the only allowed colors. If you have established brand colors, use them. It is however a great hand picked starting point that you can use to get going. It recommends picking a major or primary color that is representative of your app's branding or personality. You can use this color in large blocks such as this toolbar to make your app instantly recognizable. For example, YouTube's primary color would be red or inbox's color would be blue. Next, you pick an accent color. This is a brighter, more saturated color designed to draw attention to certain elements, such as a floating action button. Two colors alone may not be enough range to create your whole UI, so we then break these down into lightness ranges to build out your palette. Here's an example of Material's light blue color swatch. Material assigns numerical values to this range, where lighter shades have a lower number and darker shades have a higher number. These numbers themselves don't mean anything intrinsically, but they're useful terminology when discussing when to use a particular tint. We calibrate our lightness scale on your primary color calling it the 500 shade. Then darker shades have higher numbers, like 700 or 900. And lighter shades have lower numbers. We use an A prefix for those accent, those more saturated colors that we talked about. Such as, light blue A200. Now we recommend that you stick to three hues of your primary and one accent color to keep your palette simple, but versatile. For example, let's create the palette for an app which has an indigo personality. I'll pick indigo 500 shade as my primary color. And then grab the indigo 700 and 300 shades for complementary areas. Next, I'll pick pink A200 as a hot accent color for contrasting elements. Let's apply our shiny new palette to our app. We can use the primary color in blocks of your UI like extended toolbars, to embed our personality. Next, we could apply the 700 shade to the status bar to give it contrast against the toolbar. And then the 300 shade for a block of secondary information for example. Finally, we'll use the accent color on elements you want call out, such as the fab, on toggles or perhaps a focused text field. Material provides a hand-tuned pallet of colors that you can use in your apps, and are a great starting point if you don't have an existing brand. If you do, however, then you absolutely should use your own brand colors. But, applying the Material system of accents and shades helps to work this into your UI. If you have a primary color, but no accent, then you can use color fairy, such as complimentary colors to help you pick one. There's some great tools online. This is an example from color.adobe.com. If you really want a monochromatic palate, so just one color in there, it's fine to just use just shades of your primary color. But then you're going to lose the ability to highlight certain elements. A quick tip is that you'll likely use your accent color close to or on top of your primary color. So, for example, the fab on top of this toolbar here. So you want to make sure you pick colors that have enough contrast. So this one would get a little bit lost. So that's the essence of working with color in Material Design. This is the most powerful, immersive and completely adaptable to your application. So no matter if your app is whimsical or serious, it's easy to work with color to express that. Now that we have the color palette sorted, let's hand it over to James to implement in our sample app. Thanks, disembodied hand. So here's the palette that Nick created running in an actual Android app. The first thing I did was create a colors.xml file containing the colors that I wanted to specify. For the names, I used what was listed in the material design guidelines, so indigo_300, indigo_500, 700, and pink_a200. And the use the hexadecimal value for those colors. In the style for the app, I used those identifiers, prefixed by @color, and a slash for my color primary, primary dark, and the accent color. This makes it whole lot more readable and you only have to change colors in one place, your colors.xml file. In the xml for our view, we can specify those identifiers in a couple different ways. So we can see here, we set our app bar layout, that's the container that holds our app bar, to have a background with the primary color. Now the reason we have this question mark here is that colorPrimary refers to a theme local attribute. We could have also listed ?attr/colorPrimary. So if we look at the floating action button you might notice that there isn't any designation of color information here. That's because behind the scenes, it assigns the color accent value if you specified it. So check out this link, which is also specified in the instructors notes, to see what other attributes you can change and customize in material design. For this primary color, which of these colors down here would be the best accent color? So out of these four colors here, three of the colors can look very similar to this primary blue color. Now these two look visually similar already. And if you're certain types of color blind, this green will not be that distinguishable from any of these blues. So the answer would be to choose this red color. So switching over to Android Studio, I've created a little app to demonstrate extracting a pallet from an image. The first thing we need to do in our apps file is add the support library for a pallet as a dependency. So after we receive an image resource identifier for an image, we can load it into our view and convert it into a bitmap that the palette will use to generate the color swatches. Alternatively, If we've taken a photo, we'll receive a bitmap from the camera without the need for that conversion step. These color swatches fall into two different areas, either vibrant or a muted color. The type and number of swatches is dependent on the composition of your image. And how much of it is in a certain color and how that color contrast to other colors in the image. If you want to read more about that, you can check the instructors notes for a link to the java docs, for the palette library. So right here in this code, I take the palette and I'm looking through all of the different swatches to see if they exist before returning a hash mat. So let's check it out on a device. If we hit this floating action button and pick an image, let's pick something from our Android Nanodegree kick off. We can see that it's created a palette for us. Now, one of the interesting colors here is this vibrant color from these Android stickers. When I click the item it shows us how many pixels in the image were from that color. Next, Roman is going to talk to you about typography. So switching over to Android studio, we need to do a couple of steps before we can extract a palette from an image. The first thing we need to do in our apps build.grade file is to add the support library for palette as a dependency. So after we get our resource identifier for our image, we can convert that into a Bitmap, that the palette will use to generate the color swatches. These color swatches fall into two different areas. Either a vibrant color or a muted color. The type in number swatches is dependent on the composition of your image and how much of it is in a certain color and how that contrasts to other colors in the image. If you want more information for that, you can check the source code for the palette library. So right here in this code, I take a palette and I'm looking through all of the different swatches to see if they exist because they can be null and then I return that map. So if we want to see this on a device, make a little app here that can show an image and pull out the palette information. So let's hit this floating action button down here and pick an image, and let's pick one of the images from our Android kick off, and we can see that it's created a palette for us. Now, the interesting colors here, I'd say, is the vibrant color that it's picking up from these Android stickers After space and color, type is the next item you should consider when creating a great app. Roboto, the default sans serif font family for Android, is a great place to start, as it was specifically designed for user interfaces across a variety of screens. Using Roboto gives you the comfort of knowing your text will work with a variety of languages and remain crisp and legible on any screen. And, you can use Roboto across your entire app, whether it be for headlines, body text, smaller captions or whatever. It includes a bunch of weights, like light, regular, medium, bold, and black, and variants like condensed and slab. Having those variants available in addition to font size and color lets you clearly communicate, for example, what's a headline versus what's part of the body text. Or, as we sometimes say, it'll help you establish a clear hierarchy for the text in your app. Now, typography is a really large topic, and we'll try to fit as much as possible into this course, but we can only cover so much. If you're interested in typography outside the realm of mobile app design, I strongly encourage you to check out some of the books linked in the instructor notes. There's a whole world of information out there if you're a typography fanatic like me. Type presents us with an interesting problem. Not only do we need to consider different screen densities, but we also need to factor in the user's preferred text size. More on that in a second. Let's take a quick pop quiz. Given that we need to support different screen densities, and preferred text size, what are the right units for text in Android apps? The correct answer is sp or scale-independent pixels. If you use dips, that piece of text has a specific physical size. No matter if the user has set their preferred text size. Android won't prevent you from using other units of measure like pixels, millimeters or dips. But you should always remember to use sp or scale-independent pixels. So what is this user preferred text size anyway? Well, for accessibility purposes Android allows users to customize their font size. Users that have trouble reading text can increase their font size. You can normally find this option in the display settings on your phone or tablet under font size. It's often also available through the accessibility settings. With scale-independent pixels, 16 sp is exactly the same as 16 dp when the user's font size is normal or 100%. But when the user's font size is large, for example 125%, 16 sp will translate to 20 dp or 1.25 times 16. Using sp units will make for a better experience for people with impaired eyesight. You'll be saving someone the frustration of downloading your awesome app, only to find that they can't read the text. Let's now dive into some characteristics of fonts a bit. Think of this as a crash course on the anatomy of type, a super fast primer on basic typography. Now, as we mentioned earlier, Roboto is a standard font included in Android. It is a Sans-serif font. Sans-serif means without serifs. Serifs are the little wings attached to the strokes of a letter like these here that hang off the letter r. Serif fonts are common in printed works like books and are generally considered more comfortable for long form reading. On the other hand, Sans-serif fonts are more common on the web and can be well suited to short bursts of texts like in user interfaces. There's also generally a safer choice when you're dealing with a range of screen densities. A Serif font can be a great compliment with Roboto if used sparingly for things like title headings and large type. Now, due to issues like anti aliasing which would make small Serifs appear kind of blurry. It wouldn't be advisable to use a Serif font for really, really small text. Let's also briefly talk about font metrics. We're only going to talk about the English alphabet for now. When trying to describe the anatomy of text, you can easily go down a long, long, long rabbit hole. Anyway, let's first start with the baseline. The baseline is essentially the optical bottom point of all text that doesn't extend below, like the lowercase y here. Next is the x-height which refers to the height of the lowercase x in the font. Basically the height of most lowercase letters, like the letter e here. Fonts with the relatively large x-height tend to be more legible and better suited for body text. After that is the cap height which is the height of most uppercase letters like the capital T here. And next you have ascenders and their cousin descenders. These are part of the lowercase letters that extend way above the cap height or below the baseline. So the h has an ascender here and the y has a descender. And finally, you have the leading. That's the spacing between vertical lines of text. On Android, you can control the leading by providing a line spacing multiplier or line spacing extra for a text view. Now, there's a lot more to font anatomy than just this. Like I said, we just talked about the English alphabet. Check the instructor's notes for links where you can learn more about font anatomy and other cool font typography type stuff. What about all the different variations of fonts? A font family, or even a family of families can contain dozens of variations. First, Roboto actually has four distinct font families, including a condensed, monospace and even an older slab serif family. Within each font family you have a variety of weights. Font weight is the relative thickness of each letter. The most common weights are regular and bold, but really great fonts will come in light, thin, regular, medium, bold or black. And now these can go by different names, like semi-bold or ultra-thin. Weights often also get numbers assigned to them, from 0 to 1000, where the thinnest weights have something like 100 value, and the darkest or the thickest weights have a 900 or 1000 value. And finally, each of these weights normally has a normal and an italic style. Now when it comes to styling text in Android, the terminology is a little different. If you're using Roboto, text views have two attributes that let you customize the font, fontFamily and textStyle. FontFamily lets you choose which family to use and the specific weight, such as thin or light. And textStyle lets you choose italics, but it also lets you make the text bold. You should generally avoid using textStyle to make text bold and instead use the fontFamily attribute, since you'll have more control over the exact weight to use. Also note that not every weight is available in every family. For example as of this writing, Roboto condensed doesn't include a thin and a black weight. Here's some sample code for applying a font family in text style. Here we're saying to use the condensed family but italicized. And here are some other examples of values you can use for fontFamily to set the fontFamily or the weight, like thin, medium, light. Now, one quick note with the condensed fonts, the Roboto Condensed example here. You can squeeze a lot more text into the same horizontal space with these fonts, but condensed fonts can definitely be overused. They're not quite as legible and don't always look great with other wider fonts, like Roboto Regular, or even wider fonts than that. So definitely be careful when using condensed fonts as your font family. So you've decided that you need more than what can be provided by all the variance of Roboto. How do you pick an additional font? Well, it's pretty hard. Choosing the right font isn't only a technical challenge. It's not enough to just pick a font that's easy to read and contrasts well with the content around it. Your choice of font can impact how your users perceive your app. And how they emotionally respond to it. Hand written fonts or fonts with rounded terminals can make your app feel informal. On the other hand, very geometric fonts might give an impression of order and structure. And some fonts might even feel robotic. Weight matters too here. Light fonts are those with really thin serafs, can invoke impressions of elegance, but also impermanence. Meanwhile ultra bolds might evoke heaviness. But possibly stability, and fonts can even be associated with a time period. While some may have an almost historic significance, others may be considered a little too trendy. There really aren't great absolute rules for choosing the right custom font for your app, but here are a couple of tips that might prove handy. First, limit your font pallet. You can often get away with using just one custom font for branding areas like your app bar and Roboto for everything else. If you do pick another sans sarif font to replace Roboto for UI elements like the text here, make sure to switch over completely. So you don't have two similar looking fonts next to each other. Here Helvetica and Roboto are placed next to each other. But since they look kind of similar, it's kind of this weird uncanny valley. It's not clear if it's intentional or not. Second, try out the font you're thinking of on a couple of different devices with varying screen densities. What looks awesome at xxhdpi might look really muddy at mdpi. Notice the serifs on the H are barely even visible. And finally, watch out for unintended cognitive dissonance. And make sure the font fits the mood you're setting in the app. If your product is all about being fast, putting a font with a heavy weight on might give the feeling of a slow lumbering giant. On the other hand, if you have an app that's highly technical an overly decorative font might not only be distracting but might erode your user's trust in what you're trying to do. So does your proposed extra custom font meet all those requirements? Great. James is going to walk you through how to use the font you just picked in your app. So let's say you found a font that looks great on a bunch of different screen resolutions and different sizes, and even better, it doesn't detract from the overall theme of your app. How would you use it? So here's a small app that I did to show you the different typographical sizes that are available in Android and their names. Now, right now they're all using the Roboto font. Let's go and change that. So here's the app that we were just looking at. So if you want to add your own font, the first thing that you will need to do is add an assets directory under source main. And we've included our font, which is Courgette-Regular. It was just a font that I found on Google web fonts, because most of them are available with open source licenses. So if we switch over to the Android view, it will show up as assets and resurrectory. But those are the same location, so you might see one or the other depending on how you set up your Android Studio. If you're using your font inside a fragment, due to the fragment life cycle, you need to instantiate the type face in the onAttach method. The reason for this is there's a short period of time after a fragment is created, but before it's attached to a host activity. So, if you can see in this Typeface.createFromAsset function, we have getActivity and then getAssets. If this is called before it's attached to the activity, it will result in an error. So, if we go to our onCreate method, after instantiating our text views, we just call the setTypeface function with the object that we just created. So if we look at this on a device, we can see that our display4 and our headlineView have changed. So this is our display4 here, and then if we scroll up a bit, right here is our headline. Good imagery makes us form a connection to the subject, sympathizing with their joy, pain, or delight. Though only visual, a good image might even make us recall a familiar smell or sound. Migrant Mother by Dorothea Lange is the iconic representation of the Great Depression in the United States. In it, we see a mother with a steely gaze into the future unsure of the end of her current crisis. It put a face and a feeling to what migrant workers were experiencing during the Great Depression. Afghan Girl by Steve McCurry appeared on the cover of National Geographic in June 1985. It's one of these most recognizable magazine covers ever, and has become a symbol of the status of refugees worldwide. So, what do these two moving photographs have to do with Android design? A lot. Though they come from different eras, both tell an immersive and compelling story and can connect emotionally. Neither feels like stop imagery or clip-art. While every photo or illustration you use need not be Pulitzer Prize quality, you should seek to select imagery that is relevant to the user, provides contextual information, or delights them. Imagery should convey information, personalize the experience of using your app or provide delight. Your use of imagery will strongly reflect and reinforce your branding. So if you're brand is bold and dynamic, then use imagery in the same way. If your brand is playful and informal, then maybe a more illustrative style. If you're chic and refined, then tell that story visually. But what types of imagery can you use and when are they appropriate? The major classes of imagery you can use for somewhere on a spectrum from photography to illustration, to iconography. Let's take a look at each of these and when they might be appropriate. Now photography is great when it's specific to your content. If you're showing information about a particular person, place or thing, then photography can quickly and beautifully communicate that. Conversely, if your content if more abstract, we don't have imagery specific to the content, then photography might feel off the mark. Here in this example, we're showing details of the London Eye and then having a specific picture works very well. But if you're showing information about another place, here Waterloo station, which is near the London Eye, but not the same place and then the image doesn't connect in the same way and it feels off. As another example, if I'm showing content from other people like this messaging type app, then showing a photo of a the contact immediately communicates far better than a label or a generic graphic might. When presenting photography, make sure you have sufficient quality images to avoid pixelation. If you do have great quality imagery, then don't be shy about using it immersively. It's perfectly acceptable to use imagery as a backdrop to set the mood of the screen. Always considered the different ways that images might be cropped depending on different layouts of size of the device. Think about the aspect ratios, scale types and focal points that is important to maintain. We're going to go into much more detail about this later on in lesson five. Illustration is great for communicating abstract concepts or metaphors without getting hung up on the specificity that comes from photography. Take these three examples. The first two communicate the concepts of syncing photos or doing a brain training game without the specific images of people. The last image helps on board users without having to have imagery for every specific device. When creating illustration, aim for clarity instead of being overly decorative. Have a focal point and a message that you are trying to communicate. While the exact style of the illustration is up to you and your brand, do try to stay consistent within a series of illustrations to keep them connected. For example, using a consistent perspective, color pallet or using textures. Iconography provides clear way finding. Its goals are almost the exact opposite of illustration to succinctly explain their meaning and get out of the way. They should be easy to identify and interpret in your UI. For this reason, it's best to use the platform iconography for common tasks, such as search or share as your users will already be familiar with them. The material design provides a wide range of icons that you can use in your applications for creating new icons, then check out the extensive style guide, which is linked in the instructor notes. And there's a great community starting to pop-up and create more icons in the same style at materialdesignicons.com. So those were the main types of imagery you can use in your app. Picking the right one really depends upon the feel of your brand and the content you're showing. No matter what type of imagery you use, it'll help to create an immersive experience and can be a great way to introduce motion. For example, this music player eases the transition between states and has an incredibly immersive feel for its use of imagery. The images themselves can introduce motion using videos, scrolling effects like parallax or other other types of animation. We'll expand on using motion in lesson four. Once you've picked the imagery that works best for your brand, you can use it to make your application experiences more immersive, personal and delightful. Let's hand over to James now and get into how you'd implement this in your app. To help you visualize this a bit better, I've created a small app to show you how you can manipulate images. Here we have an image inside a card view with a label composed of a couple of text views. Below the card view are a series of radio buttons with different transformations and scale types you can apply to the above image. The default scale type for an image Is FIT_CENTER. It scales the images to fit inside the view will keeping the aspect ratio. If the axes don't match, the empty space is distributed on both sides of the image, either the top and bottom or the left and right. FIT_START and FIT_END also scale the image to fit inside the view but they align the image so that the unused space appears before or after the image. FIT_XY scales the image to use all the space in the view, even if the aspect ratio changes. In other words, unless your image has an aspect ratio that closely matches your view, using FIT_XY might be a bad idea. We have three center options, center, center crop, and center inside. Center displays the image centered in the view with no scaling at all. In this case, the image is larger than our view so we only see a small portion of it. Center inside attempts to center the image in the view and will scale it down to fit. If the image is smaller than the view, it won't scale it up and the extra space will be evenly distributed around the image. If the image is larger than the view, center inside will look similar to the results of fit center. Center crop scales the image so that both the width and the height exceed the dimensions of the view. It centers the image and then crops everything that was left around it but not in view. It can make an already great image more impactful. If none of those options fit your needs, you can select matrix and a matrix composed of translations, scaling, and rotation. For this matrix, I scaled the x and the y axes in half and translated a 100 pixels in each direction. Last but not least, there's this radial button here. There isn't a no scale type. This is my not so vague way of saying don't use ill sized images for your views or add large paddings. It makes your images look lower quality. Whatever you choose, play around with images of similar quality and size to what you'll use in your production app to see what works best. When showing avatars, that is an image representing a person, it's very common to show these as a circle. Now there's no strict rule about this but a circle is a friendlier, more organic way to present the image. Psychologically, we're also predisposed to notice faces. In fact, there's a special part of our brain dedicated to it. So using a circular treatment in a UI, otherwise mostly made up of rectangles helps them to stand out. A very simple way to achieve this is to use the RoundedBitmapDrawable clause. We use this by the RoundedBitmapDrawableFactory which has static methods to create a rounded image from an existing bitmap, an input stream, or a file path. Notice the class is a RoundedBitmap not a circular bitmap, so we need to call setCircular to make it a perfect circle. If you're using an image loading library like Glide or Picasso, as covered in Android fundamentals two, then take a look at the image transformation capabilities they provide. That's a great way to take care of the rounding when the image downloads and on the background. If you're displaying dynamic content where you don't know the exact size it will be or when handling different size devices, it can be useful to display the image at a fixed aspect ratio. So you know how your design will appear for your users. We've already covered using scale type such as center crop, to make the content fit within an image view. But how do we enforce the size of the view itself? To do this, we can easily subclass image view to enforce a given aspect ratio. Let's walk through an example of always wanting our images to show with a 3:2 aspect ratio. That is whatever width its given, will set its own height to be two-thirds of this. Let's create a new class and we're calling it 3:2 image view here. And will extend from ImageView itself. Now, we'll generate all of the required constructors to handle create this view from code or from XML. Now the key part, let's override the onMeasure method. We'll unpack the width we're given, and then calculate two-thirds of this. As the threeTwoHeight. We'll then say that our view's height wants to be exactly that two-thirds of the width height. We then pass these onto the superclass to handle the rest of the measurement class. To use our custom class, we use our fully qualified name in the tag and follow the convention setting 0dp as the height. As this declared value isn't used, but has to be provided. And the view itself will then calculate height later on when it measures itself. This is similar to how we used weights in lesson one to fill the space in a linear layout. We set 0dp as the unused size because the weight would fill it in later. We'll go into much more detail on altering your lay out for different size devices in lesson five. Frequently, you'll want to show content on top of imagery, particularly icons or text. When doing so, you'll need to ensure that it is clear and legible. This is especially important for dynamic content when you don't know exactly what the color or how complicated the image will be. For example, with this dark image, we can see the title text and the share icon but if the image given to us is light, the title and icon get somewhat lost. For the overlayed icon, we can use a subtle shadow on the image to separate it from the background. Here we've added a subtle dark shadow to the white icon so that it's visible, even if the content behind is similarly colored. Third, text, adding shadows are possible but it can make the text itself somewhat harder to read. A better approach is to use what we call a scrim. Now this is a semitransparent layer between the image and the text to help provide contrast and legibility. Here we're using a gradient scrim which goes from 30% opaque black at the bottom to complete transparency. The black gives enough contrast for the overlayed white text to be readable. Let's take a look at the scrim from an angle giving you a clearer representation of what is going on. Now, the gradient sits on top of the image but below the overlayed text. We could have used a solid block of color, rather than the gradient, which would reduce the overall impact on the image but the sudden change can be distracting. You should choose the size of your scrim and the opacity values to get the best legibility without distracting from the image. To implement this technique, we can use a gradient drawable placed on top of an image view. Here, we're creating a gradient and it's going to fade from this color here, which is 30% opaque black, at the bottom to completely transparent at the center and top. We can then use a FrameLayout to stack our views. First, we place the ImageView at the back to display the picture. Next, we place a View which has that scrim drawable we just created that's set as its background. Finally, we place a TextView on top of it, which is going to draw the text here at the bottom. Don't be afraid of layering content on top of imagery. It can be a great effect for creating a mess of apps. Do, however, be careful to make sure that it's always legible. You should have a better grasp on how to use the material design guidelines to make your app designs more immersive, more bold, and more graphic. We began the lesson with a brief discussion of the Gestalt principle of grouping. We used it to add space to our designs, and make them more easily scannable and more quickly comprehensible. Next was a discussion of color, and how to create a color palette for a brand and apply it to an app. Then we discussed typography, and how a clear hierarchy in type imbues meaning into your user interface. Last, we talked about imagery, and learned how to pick photos and illustrations that are relevant to our users, provided important information, and were a delight to see. Stay tuned for the next lesson, where we'll talk about choreographing the movement of digital paper and ink through this concept we call meaningful motion. #HOLOYOLO and #MaterialYOLO have both been used to praise and ridicule Android design. So, what's the deal with them? Much like the New York City skyline, design in Android didn't come out fully formed, but slowly built over time. In the beginning, there were years of desolation where Android users had to wait a long time for first party apps. And when they finally did come, in many cases, they were exact ports of the iOS versions. This all changed with the release of Android 3.0 Honeycomb and its HOLO theme. The HOLO theme and its refinements continued to flourish in Ice Cream Sandwich, Jelly Bean, and Kit Kat. HOLOYOLO became a rallying call from the users that expected the apps they use to look like Android. Sometimes, before the next version was out of beta. No longer could you say that Android users and developers don't care about design. With the release of Android 5.0 Lollipop, #HOLOYOLO gave way to #MaterialYOLO. We learned in this course we really shouldn't use the material theme if we want to make our apps backward compatible. If anything, we should say #AppCompatYOLO. You know? In the real world, things don't just appear or disappear out of thin air. They move into place. Instantaneous changes can be confusing or disorienting. Just as we learned how applying lessons from the physical world to create tangible surfaces in our UI helps to convey information about them. Applying real world principles of motion can make your interface more understandable. Think of your user interface as existing on a shared stage. Elements move in and out of this stage in a controlled manner. Right, in this lesson we'll look at how you can use motion to create a more continuous experience, how we can teach your users about using your UI and how we can also provide moments of delight. We're going to cover a lot in this lesson. Touching on both design and implementation aspects of animation. Let's start by jumping straight into some code. More specifically let's look at how building animations with the Android SDK has evolved. >From its humble beginnings to the powerful and flexible APIs we have today. >From the earliest releases the Android .view, .animation APIs let you move, scale, and fade items onscreen. This is available to every device out there, but it's pretty limited. Here's a really simple example. Pressing the button slides it up, fades it out, and then shows a new screen. And here's the code. First we create some objects, like AlphaAnimation and TranslateAnimation and combine them together using an AnimationSet. Then we add a listener, allowing us to run code when the animation ends. In this example, when the animation finishes we'll start another activity. We're also providing a custom transition telling the new activity how it should appear on the screen, and telling the current activity how it should disappear. Once we call startAnimation on the button it'll begin to slide and fade. And once those are done our animation listener will get called. It's worth noting that you could also define these animations in XML and inflate them into real animation objects using animation utils. And here's what the actual XML looks like, back in the early days this seam XML format was used to describe animations on views as well as transitions for activities It was really simple, but also really limited. All you could really do was scale, move, rotate, and fade different views or different activities. So around the time of Android 3.0 and 4.0, the animation API started receiving a slew of major upgrades. The API for basic view animations got a lot simpler and easier to use. Here's that same animation from before with the new API. Notice how the API uses a fluent interface. You could chain together multiple calls like .animate, .alpha, .translationY. This made for a much more compact code, more importantly, you could also now animate any property on any object. So while before you could animate the x position of a view, you could now also animate a buttons text color for example. So here's a quick example of this, and note that the Argbevevlatuator tells the object animator what text color to set, ranging between black and red, over the course of one second. The next major upgrade came with Android 4.4 KitKat. Which introduced the scenes and transitions API. To see what's going on behind the scenes, let's look at a small example. When I tap this button the OS executes a transition and needs to do a couple of things. First, it needs to capture the starting and end state for every view in the scene. And create an animator that will interpolate between the starting and end states. So in this case the end state is that the image is gone. The starting state is that the image is visible. So here's the code to slide a view off the top of the screen, beginDelayedTransition takes a view group and a transition type. In this case it's the root view and the slide transition. Immediately after the call to beginDelayedTransition, transition calls capture start states. Which indicated captures the start save for all views in the view group before we've modified them. After that's done we modify the elements we want to change or transition. When the frame is done, transition manager calls capture end states, which does, you guessed it, stores the end states of all of the views in the view group. The transition calles creat animator with the state and animator set and executes it. The STK comes with a bunch of fabricated transitions listed here. Be mindful that all of them aren't supported on all versions of Android, so if you require them you might be excluding some users. What's the default transition for Transition Manager? The correct answer is AutoTransition. AutoTransition automatically fades, moves, or resizes views during a scene change. In Android 4.4 KitKat or API level 19, Android started getting really serious about coordinated motion. The new scenes and transitions API made it much easier to define how UI elements should move together. Let's take a look. The scenes and transitions API introduced a new paradigm for animating objects in your UI. James gave you a glimpse into this API, but it actually lets you do a whole lot more. The API allows you to define different states for your UI, called scenes. There's actually two scenes in this example here. And also, let you define ways to transition between those scenes, coordinating several UI elements at once. So, when UI elements appear, disappear, move, or otherwise change, you could easily define the animations to use. In this example, you can see some of those elements moving, some elements appearing, and some disappearing. Pressing the info or close button, switches between those two scenes. The way this works, is you have two layouts which describe the two scenes. Here's what they look like. They're pretty simple, just some linear layouts, some relative layouts, image views, text views, and buttons. Now the magic happens here in the onClick handlers. When you press the info button, we use this new TransitionManager class, to change from the current scene to the other one, as defined by the second layout file. If we don't specify anything else, Android will automatically figure out some nice transitions for you. Moving elements shared between the scenes. Fading new elements in, and fading old elements out. But let's say we wanted to customize the transition. We could do things like stagger the transition so that not everything happens all at once. For that, you could your describe custom transitions in XML, and pass them into the TransitionManager, like so. And here's an example of the custom transition XML. There's some similarities with the animation XML we talked about before. But the primitives you're working with, like changeBounds and fade, are a bit different. As you can see, the animation capabilities in Android have been evolving, from basic animations in early Android to much richer capabilities in Ice Cream Sandwich, Jelly Bean and KitKat. Let's go to Nick, who will tell us about the new animation capabilities in Android 5.0, Lollipop. Android 5.0 Lollipop, or API 21, added new ways to better choreograph moving between activities. Firstly, a new API lets you to run a transition when you launch or leave an activity. This allows you to customize how individual views in the screen, enter or exit. We call these content transitions. Secondly, it added the ability to create a shared element transition. This is where an element, which is present on two screens, transitions smoothly between them. The result is visual continuity for shared elements across the two activities. Before we dive deeper into these powerful new APIs, let's take a second to talk a little bit about backwards compatibility. So far in the course, almost everything we've covered has been achievable on all relevant versions of Android. Especially with the help of Android support libraries like AppCompat. As we've seen in this lesson, the Android animation APIs have become more powerful with each release. This means that some of the more advanced effects might be impossible or unfeasible to achieve on older devices. A generally good approach for implementing animations, is to use the newest APIs but to then degrade gracefully on all the devices, swapping in simple animations for the more complex ones. Remember, that devices are constantly being refreshed and upgraded. So while working on the newest API's might have a lower uptake at first, the return on investment will only grow. Okay, let's take a closer look at the new activity transitions in 5.0. Okay, so back to activity content transitions. These transitions allow you to animate the views within an activity when they enter or leave it. Say you have two activities, A and B. >From activity A, we can launch activity B by going startActivity and return by hitting the back button. When A calls startActivity to launch activity B, we have the opportunity to run two sets of transition animations. Firstly we can run an exit transition on the views in activity A. And secondly, we can run an enter transition on the views in activity B. We can define these transitions either in code, or declare them in XML and then set them on the activities feed. Let's take a look at examples of both approaches. Let's, for example, add animations to this app, which shows a grid of images. Clicking on an individual image takes you to a detail screen. So here's what it looks like before we add any content transitions, we just see the standard window animations. Let's add an exit transition to the first grid screen. We'll use an explode transition, which moves all of the views outwards. Let's do this declaratively. First, we create a new file in res/transition, and we're going to call it grid_exit. You may have to create this transition folder if it doesn't already exist. Now, the transition itself uses the exact same syntax as we saw earlier. To use the built-in explode transition, all we need is this explode tag. Now, to assign the exit transition to the activity, we'll open the activities theme and add an entry for windowExitTransition which points to the transition we just defined. Lastly, there are a couple of things we need to do to enable activity content transitions. First we'll need to alter our call to start activity to use this variant which takes a bundle. We'll go into this bundle a bit shortly. Next we might need to set the windowContentTransitions flag to true on your applications theme. If you're already inheriting from a material theme or AppCompat then this will automatically be set for you. Okay, so now that we've done that, here's how it looks. Not too bad. We see that the views move outwards as we move on to the detail screen. Let's add another transition to the content on the detail screen as it comes in. Let's slide the text into place from the bottom. This time we'll create the transition from code. In the DetailActivity we instantiate a new slide transition object. And we here, in the constructor, tell it to enter from the bottom edge. We then set which views it's acting on using this, addTarget call passing in the id of the view. We'll also set the duration and interpolator to quickly ease the view into place. More on these concepts soon. Finally, we call setEnterTransition on the window. Here's the result. Well, the title and description slide in nicely, but the image just appears. This is because by opting in to use activity content transitions, we're implicitly turning off the window animation feature. As our transition doesn't target the image specifically, it just appears. We'll fix that shortly. Let's take a second to consider these two different approaches for creating transitions in code and XML. Now, the code approach might involve less steps, but there are some trade-offs to consider. Firstly, it's harder to reuse the transition in other places. Also, this example was relatively simple. But as you create more complicated transitions, then this can get a bit more complex. It can be nice to keep this contained in a single XML file for good separation of concerns and to keep your activities clean. Lastly, as we mentioned, this feature was introduced in API 21. So we should guard our code to not attempt to use APIs that don't exist on earlier versions. In the code approach you can use an API check like this or declaratively, you can use a resource qualifier such as transition-v21 and values-v21 to only use it on the newer platforms. As you might have guessed, I'm quite a fan of the declarative approach, but pick the one that makes the most sense for your use case. You can even mix and match by using a transition inflator to load the XML transition in code. Now you may have noticed that when we hit the back button to return from the details page to the grid, our explode transition reversed, or imploded, I guess. Now, this is a default behavior, to reverse any transitions that you set on the way back. But you can, of course, hook into this and set your own. So in addition to the enter and exit transitions we've looked at, you're also able to specify return and re-enter transitions. So going from activity A to B, and back again, the sequence would be first, an exit transition on activity A, followed by the enter transition on activity B we've already looked at. Then when you hit back, you have the opportunity to run a return transition on the views in activity B, followed by a re-enter transition on the views in activity A. Let's hook into the re-enter event to customize the behavior when returning from the details page to the grid. Let's make the items slide in from the top like this. This is as easy as simply specifying a new transition in the theme like so. So here the windowReenterTransition pointing to one of the default platform transitions. So that was quite a lot to take in. Let's have a quick quiz to consolidate, take a look at this transition between screens, which starts at a grid, and then launches to a detail screen. Where are we specifying a slide from right content transition? The answer is activity B enter. Now we can see that content of activity B is animated both on the way in and on the way out. While the content of activity A, the grid, remains static, so the transition must be on activity B, one of these two options. Now as the content slides from the right on the way in, then it must be the enter transition, this option Now that we've covered activity content transitions, let's move on to shared element transitions. Let's start off by taking a look at why they're useful. Now when changing the state of your UI, motion can help you to explain that change as well as focus your attention on the content that matters. So, in this example, the album cover remains throughout the transition between an artist's screen and album screen, smoothly moving into place. The transition is organized around the object that you selected, and it unfolds from your touch. It helps to keep you oriented. We call this a shared element transition as the album cover is shared across the two states. Even if your UI doesn't include rich imagery for you to transition between states, you can use these same principles to convey navigational relationships. In this example, clicking on an item in the list causes it to lift up, forming its own surface, and then expand into place. This reinforces the parent to child relationship. That you're drilling down into an item. The motion guides the user between the two states. We can also take advantage of this advanced paper material which can transform its size and shape and position. This helps us to move between states within a screen, not just across screen boundaries. So in this example, clicking on an event in your calendar. The material lifts up into its own separate surface and then transforms into the Event Details page. These examples all help to provide continuity between different states in your UI to create a more understandable experience. Just like activity content transitions, shared element transitions use the same plumbing to power them. That is the transitions framework. Let's go back to our photo grid example, and add a shared element transition, so that the selected photo transitions smoothly between the grid and the details page. Here's what it's going to look like. Hopefully you agree that this is a much smoother, more continuous experience. Now to build this, it helps to understand a little bit about how the system works under the hood. When we say we're doing a shared element transition between two activities, we aren't actually sharing any views in their hierarchy. Each activity has an independent view tree. What we're doing, is passing information about the shared view. Such as, its position and its size between the two. When the second activity launches, it sets a transparent background and hides all of its own view so that you can, so to speak, see through to the previous activity behind it. It then locates the shared view within its own hierarchy and alters its attributes to match those passed in from the launching activity and makes that single view visible. It then runs animations to transition the shared view from this state to its natural position in the layout. As the transition progresses, the window background and the rest of the non-shared amids slowly fade in until they're totally opaque. So, while the views aren't technically shared, it's clever trick of smoke and mirrors as it were, makes it appear that they are. So now that we understand how the process works, let's take a look at how we mark elements as being shared, and how we control the animations that are run. So to implement the shared element transition we need to designate which views are shared. We do this by setting the same transitionName attribute on the views in both activities. I tend to use a string resource to make sure they match exactly. Next, when we launch the activity, we need to use a variant of the ActivityOptions.makeSceneTransitionAnim- ation API, that lets us specify the shared elements. We pass this API the View and the TransitionName so that it can look for its counterpart in the launch activity. They're a variants of this API for specifying a single shared element like this or ways to specify many shared elements, if you want multiple things to transition. Note that, interestingly, the TransitionName field is a string, rather than, perhaps, identifying a view by ID. This is because shared element transitions don't just work between screens within your own app. You can publish the transition names you support and have shared element transitions between different applications. Pretty rad. So that's enough to create a shared element transition. Not too much effort for quite an impressive effect. You may be wondering how the system knew to animate the size and position in our example. Well, by default, shared element transitions use a built-in transition called Move. This is what it looks like. The changeBounds transition does a lot of the heavy lifting and moves and resizes elements between states. The remaining transitions help with images to change the transformatio and clip applied to them. If you want to customize the animations used, then we can create our own transitions, and set them in a similar way to the activity content transitions. Here's how you'd set a custom transition via XML and via code. These days, we understand a lot about human behavior. For example, our eyes are naturally drawn to motion. If something is moving while everything around it stays the same, we're naturally drawn to the thing that's moving. This is a powerful tool in UI design, really useful for directing your user's attention to an important or immediately relevant UI element. But that's just the beginning. We saw in lesson two, that shadows can tell you a lot about a surface. Well, how that surface moves can actually tell you a whole lot about it as well. More specifically, an object's motion can provide important cues about how you could interact with it. Let's take a look. Take a look at this example of tabs. Okay, now take a look at this one. Can you tell the difference? Here they are side by side. In both cases pressing on the tab at the top changes to that tab. But, in the second example, a little slide animation is used to switch tabs. This subtle animation helps communicate that you can actually swipe the tabs to switch between them. We call this instructive motion. Without this kind of instructive motion, it would be less likely that users would discover this behavior, as the spatial relationship between pages would be less clear. In this example, as the music player controls move into view, notice how the volume control slides into place. This animation provides a subtle cue that the user can move the slider, horizontally, along the track. And remember in Lesson 2 how we talked about the elevations of surfaces and how they can imply what happens upon scrolling? Well changes in elevation could help communicate changes in interaction. When two surfaces are adjacent like here at the same elevation they might move together, but at some point one surface might change its elevation to communicate that it now moves independently of the other one. The way that content enters the scene can also imply ways to interact with it. In this example, the bottom sheet enters from the bottom of the screen, implying that it can be dragged upward or dismissed by dragging it back downward. In all these examples of instructive motion, you can see that how something moves can give you plenty of hints about how you can interact with it. Let's see what implementing instructive motion might look like. In this example, we have a full bleed image and some content below it. There's a tension here, we want to show the image in full, but we also want to indicate that there's more text available. And perhaps, we want to show some of that text content right away too. What we can do is start off with the image fully visible, but then immediately slide up some of the text to indicate there's more content. Let's see how we can implement this pretty simple form of instructive motion. Let's start with the layout. Nothing fancy here, just a frame layout with a fixed height image, and a scroll view in front of it. The linear layout in the scroll view will contain our text content, and have a white background. We'll give the linear layout a little elevation to make it clear that it's a distinct surface. Now, at the default scroll position, you see the full image, but very little text content. All we need to do is animate the scroll position as the screen first opens to a position that shows more of the text content. Here we're using an ObjectAnimator to animate the scrollY property of the ScrollView. We could just use the ScrollView's smoothScrollTo method, but this gives you a bit more control over that animation. We start the animation inside of onEnterAnimationComplete to ensure that the window transition ends first before we start the animation. This is only available in Android 5.0 and later, but you could fake it on earlier versions using something like a start delay. The effect is that you get a quick preview of the image before you start reading about it. And you quickly realize you could quickly scroll up to see that image in full again or down to read more. As we've seen so far, motion can be a powerful tool to direct attention, and provide cues about how something works. But as all [LAUGH] Spiderman fans know, with great power comes great responsibility. Motion needs to be used purposefully and judiciously. Here are some practical tips for designing motion that enhances the experience, rather than detract from it. Let's start off with some basics. How long should your animations run for? Here's some examples. The first one here is too slow. The animation feels gratuitous. The second one is too fast. It feels almost accidental. The third is just right. Animations should be slow enough to convey their meaning, but as fast possible, so that they don't get in the way and become annoying. A good rule of thumb is to use animations that are around 300ms long. And tweak from there if they feel too slow or too fast. Remember that in general, designers and developers alike, tend to use animations that are longer than users would prefer. So if you think you need one full second for an animation, you probably actually need a lot less to get the point across. And another tip, where possible, use the size of the object and the distance it needs to move, to help you time the animation. This will make sure that animations that can have varying start and stop states, feel right in every situation. Now that we know how long animation should run for, let's talk about interpolation. In the real world, objects don't start or stop moving instantaneously, like in this red circle. They accelerate and decelerate to get from point a to point b. Now, material design takes this a step further. Motion curves in material are asymmetric. Meaning as objects move, their acceleration and deceleration aren't equal. For objects that move across the screen, you can use a fast-out, slow-in transition. Because most of the movement happens early on, items spend more of the transition near their final position. The effect is that animations feel fast and precise. This also reduces a lot of the negative effect that can come from too much motion. And when elements are entering or exiting the scene, do so at full velocity. For objects entering, the linear-out slow-in interpolator works well for this. For objects exiting, you can use the fast-out, linear-in interpolators. Finally, let's talk about the notion of user-initiated change. This is really, really important in material design. Almost all state changes start with something the user does. User input, such as touch and keyboard focus, is thus at the very center of motion story material design. Here's an example similar to what we saw in lesson two. Notice how the surfaces respond to touch by lifting up and showing temporary ink ripples. Coordinating motion around the user's touchpoint makes complex state changes easier to visually process and understand. In this example, when transitioning between two states, animations across the screen are staggered based on their distance from the touch point. The result is that the motion feels more intentional and connected to you. It makes you feel powerful and in control. To see some concrete examples of interpolation, I've put together this little app, and it has two spinners here. The first one has a list of a bunch of different interpolators like accelerate, decelerate, bounce, decelerate, linear, overshoot. And the second spinner has different timings, from 100 milliseconds all the way up to 3,000 milliseconds or three seconds, so that you can see how fast or how slow things work. So if we just select 3,000 milliseconds, it's going to be really slow. And just like Roman was saying in the previous video, it's kind of gratuitous to, and it's just too much motion to be bouncing up and down that much. So let's try, maybe a 900 milliseconds. That looks a little bit better. So let's switch to the code and see how this works. So here's the code that makes that work. We start off with creating a new instance of our interpolator. Because it's different based off of what the name is, we actually use the Java class forName to get the class and then instantiate a new instance. But if you were using this in your own app, you would call, say, new BounceInterpolator directly. So after we have that, we call animate on our text view, and set the interpolator and the duration from our spinner, and tell it to start in 500 milliseconds and to move the animation from the bottom of the screen, and then start. Check the instructor's notes for more information about interpolators or this sample app that you can play around with to see how they work a little bit better. You can create more interesting movement by animating multiple objects, or even the children of an item as the parent itself moves. In this example, the cards move onto screen at different speeds, helping to convey that they are separate items. When doing this, it's key that you do so in a coordinated matter, here we are achieving coordinated motion by using a consistent direction and timing. All cards move in from the bottom of the screen, from different distances, which causes the closing up effect. Because they use the same duration and interpolator, the acceleration and deceleration will link them perceptively, thanks to the gestalt laws of grouping that we looked at earlier. When moving multiple items at the same time, be mindful to choreograph their paths in a cohesive direction. In this exaggerated example, each card arrives from a different direction, appearing chaotic. Try sketching out the paths that items will travel upon to check that they are coordinated, avoiding overlapping paths in conflicting directions. In the real world, few items move in a linear fashion, so using linear motion can feel robotic and unnatural. In this example clicking on an item performs a shared element transition on the circle. Notice that the difference between this straight line transition and curved transition. The latter feels more natural. Be judicious with this technique as it can attract attention, so make sure it's used when that is your intention. As we've seen, material surfaces can transform their size, shape, and position. We've also seen how an items elevation shows hierarchy and importance. When animating a change in size of an item, you want to avoid having your users mistake this for a zoom effect, which might imply an elevation change, like this example. A good way to do this, is to animate the width, and the height at different rates, making it clear what is changing. Check the instructor's notes for the source of these examples to see how they are achieved. Which of these transitions would be appropriate for a parent-to-child transition? Is it A? B? Or C? So which of these would be appropriate for a parent-to-child transition? Transition A was far too slow. Transition C was all over the place and kind of hard to follow. So that leaves us with transition B. As Eames said, the details make the design. Motion can be an opportunity to provide delight and make a connection with your user. They can also bring personality to your app. After all, animating literally means bringing to life. Whenever an element changes state this is a great opportunity to animate this change. This helps both to explain what is changing and can direct attention. This technique isn't restricted to larger blocks of your UI. Animating small details eases the transition. Take a look at these examples. The clock up here runs an animation whenever we switch tab. This helps to communicate the tab's purpose. PocketCasts here animates the transition between the play and pause states. And here the Google I/O app, when we reach the bottom, it animates the logo. Now these last two might not provide extra functionality. These small details bring a smile to your face and make the experience of using the app more enjoyable. To craft delightful details like these, we'll take a look at the VectorDrawable and AnimatedVectorDrawable classes. We'll start by looking at what VectorDrawable allows us to do, to understand what we can animate. VectorDrawable was introduced in Lollipop and lets you create density independent images by defining a series of drawing commands. It's similar in concept to SVG on the web. Here's an example of a VectorDrawable. It defines a path which has a series of space separated drawing commands, which use a subset of the SVG path data spec to draw lines, curves and so on. For example, these commands draw a cross by moving to a point. Drawing a line to another point. Lifting and moving to another point. And drawing another line. Simple. Now vectors aren't appropriate for every kind of image. You wouldn't want to represent a person's face with a vector, for example. But iconography and simple illustrations are great candidates. The vector format provides density independence, meaning that the same image works on any screen density. When vector support reaches enough devices, you won't have to explore assets at multiple different sizes like we covered in Lesson One. It also generally produces a small file size. But the opportunity to animate all or parts of the image is what we're really interested in right now. The AnimatedVectorDrawable class lets you animate any property of a part of set of parts. Here's a list of what you can animate. Now, the first five have pretty standard animation properties. But having the ability to target individual elements within the drawable is quite powerful. Let's take a closer look at these last three more unique properties and the kind of animation they allow. We can animate the actual path data itself, allowing you to morph, so to speak, one shape into another. Here's a simple example of changing a tick into a cross. We can, of course, combine this with other effects, such as throwing in a rotate, to get a little bit fancier. The restriction when morphing is that the shapes need to have the same number of drawing commands in them in order to interpolate between the two states. When drawing a path, VectorDrawable allows you to only draw a portion of it by trimming the start or end of it. In this example, we had a path, which is the handwritten word, Android design. And animating the trim on it produces this fun writing effect. VectorDrawables also support the notion of clip pass. That is applying a clip region to your drawing. Animating this clip region allows you to reveal or hide portions of the image. So in this example we have an outline heart. And then on top of that a filled heart. By applying a clip region to the filled heart on top and animating it, we can produce this filling up and emptying effect. These were just a few examples of what you can do with animated vectors. They're a great opportunity to make your app feel alive. Now that we understand what's possible with animated vectors, let's walk through an example of implementing them. We'll return to this tick to cross animation and implement them. The first step is to create two vector drawables, one for the tick, and one for the cross. Here are my drawables, I'm generating the path using my favorite drawing graphics package, and then exporting the SVG and and grabbing the path data from it. Soon Android Studio will be able to import SVG directly as a vector drawable. A pro tip that I found helpful is to create a resources file to keep all of the attributes of an animation together. Here I'm calling it tickcross. For example, we'll need to reference the path data from a couple of different places. So saving it as a string resource and then referencing it makes it easy. Next we create animators for each of the steps that are changing. Here's an example that morphs the ticks across. See how it references the strings we specified in the resources as the from and to states. Finally, we create an animated-vector drawable which connects the image to the animator. For example, this animated-vector drawable acts on the ic_cross vector drawable. It targets one of the path sections by name here, the crosspath. And then specifies and animator to run on it, here running the cross_to_tick animation we just looked up. Once we have all of the moving parts together, we can show the drawable in an imageView. And start the animation when appropriate. Perhaps in response to an event like a click. You can find the full source code to this demo linked in the instructor's notes. Fun details like this are a great way to entertain your users and show some personality in your app. In this lesson, we learned how treating your screen as a shared stage that elements purposely move in and out of makes your UI more understandable. We studied how animation can explain complex state changes and make the user feel in control. We considered what makes a good transition and how to apply this to the elements in your UI. And finally, we looked at how motion can provide elements of delight and whimsy that express the personality of your app. Stay with us for the next lesson, where we'll study how to apply everything we've learned so far to the myriad of devices out there through something we call adaptive design. So far, we've mostly focused on portrait phones, but Android devices come in all shapes and sizes. From smartphones to phablets to large and small tablets, and beyond, to new formed factors like watches, cars, and TVs. Android was built from the ground up to not only embrace this variety and to make it easier to design UIs that adapt to it, we introduced this notion briefly in lesson one, but here in lesson five, we'll go much deeper into this notion of adaptive design. As we saw in lesson one, Android makes it really easy to create UIs that stretch based on screen size. We call these fluid layouts because they can stretch and compress depending on the amount of space they have. And you can build these using layouts like linear layout, grid layout, frame layout, or relative layout. But fluid layouts only get you so far. Most of the time, on larger screens you can end up with a lot more white space than you originally planned for. These massive seas of white space result in an unbalanced UI and can make your app look less useful and less beautiful. Now before we jump into ways to improve this, let's dive a little bit further into the problem at hand. Let's look at some examples of UIs for tablets that are less than optimal and see where they break down. We'll use the factors we discussed as a rubric for grading each UI. This first example shows a list of messages or updates, perhaps it's some kind of social app. It's essentially a list with full width text and images. Let's see how it does against our rubric for what we're optimizing for. Now firstly, I don't think this design offers a balanced use of space. The left alignment can leave lots of empty space and it feels a bit lopsided. Secondly, any time you have full width text, this isn't optimizing for reading comfort as you're likely to exceed the 45 to 75 character line lengths we want. Lastly, I'd say that this design risks blowing images up to fill this width, sacrificing quality. This next example is something like a detail screen, with a full width image with an awkward aspect ratio. Looks like it might have a fixed height, but a fill width off the screen. Then it has some text content top left aligned. Looking at our optimization goals, odds say that this design isn't very balanced. All of the content is concentrated here on the top left. This design also doesn't seem to respect image quality. Displaying a small sliver like this is likely to only convey a portion of the whole image. Lastly, I'd say that there might be a missed opportunity to maintain context. This looks like a sparse detail screen. It might have made more sense to show this info in a larger context, say, in its own panel or dialogue. Our last example tablet screen shows some kind of image feed. Here the images flow horizontally from left to right. Again, looking at our rubric, I'd say that this design doesn't make balanced use of space. We have dense content here on the left and sparse areas here on the right. This design also doesn't optimize for image quality. It's not that the layout is likely to blow up images, it's more of a missed opportunity to display them more richly or interestingly. This design appears to use a fixed size for each image, which is a shame. Why not make better use of the space available? Lastly, I've marked it down for overall aesthetic. I'd say that this kind of jagged look, like this, is somewhat awkward. While these examples might seem contrived, they're representative of how many apps out there today aren't thinking adaptively. With some simple tweaks, you can vastly improve how your app might appear on larger devices. Okay, time for a quiz. Take a look at this example tablet app UI. There are clearly a couple of things that could be improved here. Check off the factors on the right if you think the tablet UI is non-optimal in that area. This layout clearly doesn't have a very balanced use of space. The text is at danger of becoming uncomfortably wide for reading, and the image isn't being displayed optimally with this stretched width and awkward aspect ratio. We can start addressing these kind of issues by practicing adaptive design. Let's start by talking about the when of adaptive design. Or, at what points do you want to begin adapting your UI? The basic idea of adaptive design is that you change your UI, based on the screen size. That is, your UI adapts to the amount of horizontal or vertical space that you have. We do this by introducing what we call break points. Break points are the points at which your UI changes. For example, you could show another column of content once your screen width is 600 dp or larger. 600 dp is therefore a break point in your UI. Now you might be wondering, how should I choose these break points? Well, the material spec identifies some common breakpoints. While you can start with these, it's important to ensure your breakpoints make sense for your content. It's important to think content first. You can then think of the breakpoints as the point in which your UI literally breaks for the content it's trying to present. So what does it mean to be content versed? In this case, it means starting by figuring out what the constraints are for your content, and then figuring out the break points from there. Let's return to some of the layouts we looked at in lesson one and see how they might work on larger devices. Now, as the screen width increases with this layout The line length the text increases is making harder to read. So, you might want to have a break point somewhere where the line length exceeds 45 to 75 character guideline. In this form layout, on wider devices there's too much unused space, here on the right. Making it feel unbalanced. You might set a break point round about say here to re balance the layout. In this example, see how these two buttons take up half the width of the screen. On wider layouts, this starts to get quite awkward, around about say this point. So that might be a break point. Also notice how maintaining a constant height and center crop image starts to break down on larger sizes. It ends up showing this kind of small sliver of the whole image greatly blown up. Lastly, the left-align content can start to feel unbalanced leaving large empty areas on the right of the screen. Choosing break points based on content requirements is more future proof than basing them on a specific set of devices. You'll know those requirements will be satisfied no matter what devices get thrown your way. Okay. So now that we know that we want to do something different when a UI gets to these break point sizes, in the next section we'll talk about how you do this with code. If you're a member, we talked about resource qualifiers in lesson one. The idea's that you can vary things like drawables, strings, even layouts based on qualifiers like language and device orientation. There are a number of resource qualifiers you can use to start changing your UI based on screen size. The primary ones you should use are width, height, landscape orientation. And portrait orientation. Width and height simply mean the device's current width or height. Which of course changes when you rotate the device to portrait or landscape. There's is also the smallest width qualifier. Which is the smaller of the screen's width or height. It's the same in either portrait or landscape, so it's a useful qualifier for controlling attributes that you don't want to vary when you rotate the device, such as font sizes. There's also small, normal, large, and extra large size buckets. These are less useful and because they don't give you as much control. They're considered deprecated. So going back to break points, say we chose a break point point of 600 dps. Once the screen is wider than 600 dps, we want to tweak our UI. For this, we add the w600dp directory qualifier to hold whatever new resources we create. Another good resource to use is the design metrics tool on the Google design website. It lists the screen dimensions and densities for many popular devices in Android, iOS, ChromeOS and Android Wear, along with a UI designer in Android Studio. It's a good way to visualize how your design might need to change to fill up space on, say, a Nexus 9 in landscape mode. Now that we understand the when of adaptive design, namely the points at which our UI breaks, let's talk about the what of adaptive design, specifically the techniques for what to fix. Let's think back to what we wanted to optimize our UIs for and what we can do. Filling the width of the screen can become problematic on wider devices. This might not optimize for balance and line length. There a couple of approaches we can take to address this. Firstly, you can show additional content on the screen. Instead of just filling the extra space, we can instead show more content there. One way to do this is to reveal previously hidden UI elements. For example, you might use an off-screen navigation draw on small devices, but then pin it on-screen on larger devices. We might also divide the available space to show additional content. For example, showing a details page on the same screen as a list rather than on a completely new screen. We also might reflow content on different size screens to better arrange it. It this example, we're reflowing a few things on the larger screen. Firstly, we switch from a single column of content to multiple columns to make better use of the available space. Secondly, we're not just rearranging these content cards, we're also adjusting their layouts to better fit with this new arrangement. Lastly, we tweak the app bar height when the space is available for a more balanced, branded appearance. We can also use this reflow technique in different orientations on the same device. In this example, a portrait layout places an image with a set aspect ratio above some text. Now using the same layout in landscape would likely fill the entire screen with an image and push the text down below the fold. A better approach would be to reflow the content so that it's horizontally stacked instead of vertically, allowing you to see both the image and the text together. Notice that we're also reflowing the FAP to a more appropriate position for this layout. If you don't have more content to show on-screen, then you can expand the content up to a point, and then introduce margins to constrain it from growing too wide. This works extremely well with a paper metaphor, where you can use a paper surface which has a maximum width to constrain the content. This technique can also work great if you have rich imagery, such as a full bleed background, which you can put behind the content and layer a service on top of it. This can create an extremely immersive experience. We talked about the when of adaptive design, specifically, choosing breakpoints, and using resource qualifiers, like w600dp. And we also touched on what we want to fix at these breakpoints. Let's now get into the how of implementing adaptive design on Android. Now the simplest to adapt your UI, is to create a separate layout in res/layout-w600dp. You'll probably end up copying and pasting a bunch of layout XML code, because your layouts probably won't be completely different. For example, here you can see the basic layout is a top bar, with a collection below it, and it's the same in this tablet layout. This approach of simply copying and pasting will quickly lead to a maintenance problem with your code, where you'll need to make the same changes in lots of different layout XML files. Now, you could, instead, just vary your subsection of the layout, using layout includes. Layout includes are, basically, a way of saying, hey, right here, at this point in my layout, insert the contents of this other layout. In this example, the list view portion of the UI is in an include. The nice thing is that the container layout, and the included layout, can each vary individually, using resource qualifiers. So in this code, we're saying, when the width of the screen ins over 600dp, change the included layout to this one. That layout can be better optimized for tablets, such as using a grid, instead of a list. Layout includes help reduce code duplication quite a bit. But for more targeted land adaptations we can get even more fine-grained. Using all those resource qualifiers we learned about, we can vary everything from number of columns to heights and widths to margins and spacing and beyond. Let's take a look. You could use the w600dp qualifier to variant integer resource. Changing the number of columns in a grid of items. An integer resource is basically a number with no units like pixels or dp or anything like that. On a phone, you could have one column, which is basically the same as a vertical list. And on a tablet or with the w600dp qualifier, we could bump it up to three columns. This approach works for both grid view and the grid based layout managers bundled with recycler view. When switching from a list type presentation to a grid, you'll likely want to use a different layout for each item. To do this, you can access your column count integer resource from code in your adapter. And use that to decide which layout to inflate. It's worth noting that in addition to integer resources, there are also Boolean resources. So you could have a Boolean like multi column, which defaults to false, but in w600dp gets set to true. And then you could decide to use a tile versus a card type presentation. Another super powerful technique is to just vary specific metrics like paddings, margins, or even button widths and heights. Here's our same UI, but this time we're defining the tool bar and content view once. And specifying height and margins that change on a 600dp wide screen. This technique is really, really powerful and let's you minimize code duplication quite a bit. Here's another example. A full width button on a phone might get too wide past 400dp. So you can create a dimension resource called button_width, that's match_parent on phone, and exactly 400dp once the screen was this larger using the w400dp qualifier. Note that simply typing match_parent won't work in dimension resources because it's a special value, -1, that doesn't have any units. Here's a quick trick that works around that limitation. Just put this item tag in your dimensions file that's equivalent to the integer value -1. Then you can reference it in other dimension values like so, using @dimen/match_parent. And hey, remember key lines from Lesson 3? On smaller devices the standard keylines are 16dp and 72dp, but once you get to larger sizes you can start using the standard tablet keylines of 24dp and 80dp. This too can be done with varying dimension resources. In this example we're telling the toolbar to inset the title from the left edge of the screen. To the second key line. So we're going to inset by 72 or 80dp, depending on which device we're running on. And finally, you can even imagine switching from a full screen activity to a dialog at 600dp. Dialogs are often a good way to maintain some context for simpler detail screens, keeping part of the previous screen visible, and relieving some of the pressure to fill up the screen with more information. Since an activity's theme controls whether or not it's shown as a dialogue, we can switch between themes using resource qualifiers. Here's a quick example of some code for that. We have my MyTheme, which inherits from BaseTheme. And BaseTheme inherits from the standard Theme.AppCompat, or Theme.Material, or whatever theme you want. But for larger screens, we replace the definition of base themes, such that it inherits, from Theme.AppCompat.Dialog. The reason we don't just replace, MyTheme, here is so that we can put our theme attributes in one place. This kind of clever two step theme inheritance really helps minimize code overlap. And another quick note here. We use the smallest width, or sw qualifier, instead of just the width, or w qualifier. This ensures that the value won't change when you rotate the screen. After all, it'd be a little weird if, turning your phone from portrait to landscape, popped your screen into a dialog. That was an introduction to some of the standard things you can vary in your UI to make better use of space. This is by no means an exhaustive list. The key is to work out when your UI no longer works, at a certain size, or when it breaks, and to make to changes to adapt it to the available space. Let's go to Nick to see some examples of this in action. So now we know about the when, what, and how of adaptive design. Let's look back at those suboptimal tablet UIs, and see what we can do to improve them. So this Gmailesque example previously let's uncomfortable reading experiences on wider screens. We can use the divide pattern to show message details on larger devices, to make better use of the space, and contain either column from becoming too wide, and uncomfortable to read. Here we're capping the list at a maximum width, and then filling the remaining space with the message details. Notice that we are also using the expand pattern within the message details. Where it also caps the body at a maximum width, to ensure a comfortable reading, by introducing margins beyond that point. This adaptation could also help with context. We can read a message within the larger context of other emails. For example, seeing if a new message comes in. If we don't have more content that we can reveal, then we can restrict the width of the surface. And use generous margins to stop it from becoming unbalanced. Before this example felt unbalanced on larger devices, leaving large areas of white space. We can apply the extend pattern, and introduce this new surface, to contain the form on larger screens. We center this surface, and apply generous margins within it, to maintain balance. In our last example, we previously had a number of issues with unbalanced layout, overly wide buttons, and poor use of imagery. When adapting to wider devices, we can set a maximum width on the buttons. And here, we reflow them to the right, preventing them from reaching awkward sizes. We can also use the expand pattern on the content, to center on its own surface, beyond a certain width. And lastly, we switch to a more immersive image position, with the content overlapping it, to prevent the issues we saw before. Android devices come in all shapes and sizes, and tablets are popular too. You want to make sure to provide the best user experience for those users. The great thing is, it's easy to do. The next time you design and implement an Android UI, make sure you remember to think about adaptive design. Think about when. At what point does the UI start to break? Think about what? What elements should you change and in what ways? And then work on the how. Implement your adaptive UI using resource qualifiers and the techniques we described here. And for more information, check the link in the instructors notes. So that's Android design in a nutshell. We hope you've learned a lot. We started with lesson one. A crash course in Android design fundamentals. In lesson two, we learned about tangible surfaces. How they establish a clear visual hierarchy and make your UIs immediately comprehensible. In lesson three, we learned how to apply the principles of space, color, typography and imagery to let your brand shine through and make your app's content look beautiful. In lesson four, we discussed how deliberate meaningful motion helps to tell your app's story and make it feel alive. And in this lesson, we learned how to adapt our designs to the different screens your users have in their lives. Now go and design the next great app for Android. Using the techniques in this course, you're sure to build something delightful and awesome. We can't wait to see what you come up with.