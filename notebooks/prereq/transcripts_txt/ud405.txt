Welcome to 2D game development with Lib GDX. Before we do anything else, I want to show you the game you'll make in this course. It's called Icicles. We can select a difficulty, and then we use the arrow keys to dodge the fallen icicles. We keep track of our score as the number of icicles that we've dodged And when an icicle hits us, the game resets. Even better, once you've made this game it'll run anywhere. >From your desktop computer to web browsers to your phone, either Android or iOS. So want to make awesome 2-D games that run anywhere? Let's get started. Hi, welcome to 2D game development at Udacity. I'm Peter, Developer Evangelist of Amazon. And I'm Jeremy, a Course Developer at Udacity. With the explosion of mobile gaming, there's never been a better time to get your games into the hands of players. And 2D cross-platform game development libraries make it easy to write games that run anywhere. Hey Peter, what was the first game you ever worked on? Actually, my first project was the Amiga port of Red Baron which was one of the first World War I flight simulators for PC. How about you? Well the first game I ever touched the source code of was actually Asteroids on my graphing calculator. I hacked it so I got an unbeatable top score. But the first game I ever wrote from scratch was a Choose Your Own Adventure for the TI83+. Hm, how about you you? Have you made any games in the past? Or if you're brand new to the gaming industry what's the first project that you're itching to write? Thanks for introducing yourself. We can't wait to read through what you're interested in building. So, down to business. I'll be walking you through the nuts and bolts of using a libGDX game framework to make awesome, cross-platform 2D games. And I'll be stepping in from time to time, to offer perspective as a game industry veteran. So, let's get to it. So what makes games different from other types of apps? It's a hard question, because there are so many different types of games. But here are a few of the things that make writing games different from writing other types of apps. The first thing is that games are often built around an update loop or a game loop. This is as opposed to an event-based application where the application basically sits around not doing much of anything until the user provides some input. Games on the other hand, are built around a timer that fires 60 times a second. When that timer fires, it means it's time for the game to go look at the user input, update the state of the game world, and then draw a new frame to the screen. This means, games often need to deal with pulling for user input. Next, games often involve a ton of custom drawing. While you can make an Android app using entirely off-the-shelf user interface components, it's rare that you can do so with the game. You'll have to create your UI and your game world using either primitive shapes like lines, rectangles and circles, or your own custom image aspects from pixel art all the way up to complex characters. Many games also feature your special effects and animations which are a ton of fun to make but also a lot of hard work. There are whole fields of study that are much more relevant to games than other types of apps like physics and AI. There's also exotic input devices to deal with, like game pad controllers or, more interestingly for this class, accelerometers like the one you've got in your phone. Finally, my favorite part of game development is the fact that you get to create a lot of objects that have visible representations in your game world. Designing an elegant object oriented app is a lot more fun, when your objects can run around hitting each other with swords. Welcome to the second of many quizzes in this course. If you've taken a Udacity course in the past, then you already know the drill by now. If you haven't, you're in for a real treat. These quizzes are Udacity's secret sauce, and they're totally different from what you'd find in a traditional classroom experience. There, the point of a quiz is to figure out if you're remembering what the instructor is saying. Here however, the quizzes are an integral part of the learning experience itself. And we give the solution to every quiz, either as a video where we explain the answer, or as solution code in the course repository. Some of these quizzes are super easy, some are very hard. And you're not always expected to get the answer right on the first try. That means you shouldn't feel bad at all, if you need to go check out external resources, watch the solution video or look at the solution code. So let's do an easy quiz, just so you get the hang of it. Why do you want to make games? Is it because it's too much fun not to? Is it to make a little income as an indie developer? Is it because you want to prepare for a job in the gaming industry? Is it to make the world a better place through educational games? Or do you just fight for the user? So games are complicated. They often end up being way more code than you expect. So to get an idea why, let's try breaking down a classic game into it's components, and it's behaviors. If you haven't played Tetris, go play it like right now. It's an essential part of gaming history. If you just google for Tetris, you'll find a dozen versions you can play online for free. Let's do an object oriented analysis of Tetris. What we're going to do is write down a paragraph describing exactly how Tetris works. Then we're going to underline all of the nouns to get an idea of what classes we might need to implement Tetris. Then we'll underline all the verbs to get an idea what methods those classes might need. So, what is Tetris? Tetris is a game where colored Tetriminos, that's the technical term, fall down a field of play until they collide with the previously placed Tetrimino. As a Tetrimino is falling, the user can rotate it and can drop it into place. Once a Tetrimino comes to rest, if a line of blocks in the field of play is complete. It is removed, and all blocks placed above it are moved down. Removing a line earns points. Points are displayed on a scoreboard, along with a preview of the next tetromino. Now that's a super cursory description But even here we have a bunch of classes we would need in order to implement the game. We would need a game class to set everything in motion and coordinate the rest of the actors. We would need a class for the falling tetromino to represent its position and its rotation and also what shape it is. We would need a field of play to represent where all the blocks are and to put the tetromino somewhere. Speaking of attributes of the tetromino, you probably also want a class to represent colors, scanning through some more for some more nouns. We find blocks, all right. So we might want a class for blocks or perhaps blocks is just part of the field of play. I don't know it's hard to say how to design it best. Then we see we have points. We need a class to represent how many points we have. We'd also need a scoreboard to display those points and we need this whole preview pane thing. Now let's scan through for some verbs to find what methods these various classes would need. So the tetrominos need to know how to fall. The tetrominos also need to know how to rotate and how to drop. Some class needs to know when a tetromino collides with blocks that are already in the field of play, maybe the tetromino's responsible for that, maybe the field of play is responsible for that. Then there's this concept of coming to rest, where a falling tetromino just turns into blocks in the field of play. Scanning through some more, we need a way to remove lines of blocks from the field of play. We need a way to move down blocks after a line is removed. Then there's the fact that all of this needs to know how to draw itself, and that's a big task. So again, this is just a short description of Tetris, and an incredibly simple analysis of it. We could keep going here. Point is, games are complicated. And decomposing them into their component parts is essential to making any headway in actually implementing them. Now it's time for you to practice decomposing a game on your own. As your subject, you'll take one of the first games ever, Pong. If you haven't played it, go play it now. There's a link down in the instructor notes where you can find a version you can play online for free. Once you've played it, it's a pretty simple game, right? Well, do the following. First, write out a couple paragraphs describing as precisely as you can how the game of Pong proceeds. Then go through your paragraph and underline all the nouns you can find. >From that list of nouns, come up with a list of classes that you think you'd need in order to represent the state of the game of Pong. Then go through your paragraph again, underlining all the verbs this time. And from those verbs, come up with a list of methods that your classes would need to have in order to actually play the game. When you're done, write in this box the number of classes you came up with. And then write down the number of total methods on those classes. Now because this is such a subjective exercise and I have no idea what description you wrote down, this isn't actually going to be graded. I'm just curious what you come up with. I came up with between seven to ten classes, including the paddle, the ball, the score display, the dividing line, the field of play itself. And anywhere from like 20 to like 100 methods. Again, the point of this exercise is just to show you that even a pretty simple game involves a lot of code. In the last quiz I mentioned that Pong was one of the first video games, but it wasn't the first. So, what was the first widely available video game, according to Wikipedia anyway? As a hint, we will require correct punctuation in the name of the game. The first widely available game was Spacewar! Written in 1962 at MIT. You can check out some game play footage down in the instructor notes. It's usually comforting to break down a complex task into small doable steps. For instance, build Tetris isn't a doable task so let's try breaking it down a bit. One of the sub-tasks of building Tetris would be to draw the tetrominos. Then we need to make the tetrominos fall. Another aspect would be to make it so that the tetrominos rotate when you press the left or right keys. And another aspect of Tetris would be to play a sound when a line in the field of play is complete. Especially if you're newer to programming, this might just look like breaking down one impossible thing into a whole bunch of little impossible things. So, as lazy programmers, what do we do when we come across an impossible problem? Well, of course, we go find a library that just does this for us. Actually, since there are a bunch of capabilities that are often used together in games, we can usually find a game engine that packages up a ton of libraries into a whole system we can use. Game engines are not really libraries. They're more properly classified as frameworks. And frameworks have this important concept of inversion of control. When you're using libraries, you've got your code that is doing most of the work. However, you have a couple of places where you're going to need some help. So you plug in a couple different libraries, your code's running along. You call into one of the libraries for help with something specific, like drawing or playing a sound. And then your code resumes control and keeps doing what it's doing. On the other hand, when you're using a framework, the framework is doing most of the work. And then has one particular place where you insert your code. So, the framework is going along, allocating resources, determining when things get called. And then, eventually, when it's time for your application-specific logic, the framework calls into your code to do something and then, your code returns control back to the framework. This is called inversion of control. Or, more colloquially, The Hollywood Principle. Fantastic audition, kid. You're a real talent, you're going to be a star, so I'll call you when we gotta roll. No, no, you don't call us, we call you. For instance, the game engine handles stuff like starting up the app, setting up a place to draw, allocating various resources. And then only when it's finally time to draw a frame of the game, then it calls your code to provide the game specific logic needed to draw that frame. When you're done drawing, you return control back to the framework. In the old days, games were written to run on one particular model of computer or gaming hardware. These days, people will play games on any device they can cram a microcontroller into. There's still dedicated gaming hardware, like handhelds and consoles, but there's also mobile phones running primarily Android and iOS. There's desktop computers running Mac, Windows, and Linux. And, of course, there's the bane of middle school productivity browser based games. With this wealth of gaming platforms, the issue arises that all these platforms use different programming languages and different systems for drawing, networking, input, and pretty much everything else, including in what form that these applications take when they're actually distributed to end users. For instance, Android apps are written in Java and get packaged into an APK archive for a distribution. iOS apps are written in a completely different language, in Objective-C or more recently in Swift. iOS apps then get packaged into an IPA file for distribution. Web apps are a really complicated and diverse beast. But the code that actually runs the game on the client side needs to be in JavaScript or a language that compiles down to JavaScript. Then to distribute your web app to the servers that are going to run it there are a ton of different ways to do it, one of which is a web archive file. Desktop apps can be even more diverse and can be written in any language that runs on a desktop computer, which is pretty much all of them. For distribution, there are a ton of options, including EXE files for Windows, JARs that are executable jars, DMG disk images for Mac or really anything else. As an indie developer, you would like to make cross-platform games so that you can distribute your awesome new game on as many platforms as possible. But you also don't want to write your game three or four or five times over. Enter LibGDX. LibGDX is a Java game engine an application framework that makes making games so much easier. It provides a bunch of useful functionality, including great drawing APIs, sound and asset handling, user input management and a ton of other features that make writing a game super fast. LibGDX does one better though. Games written for LibGDX can be deployed on Android, IOS, browsers, and anywhere else the Java runs, like your desktop computer. So, lets check out how LibGDX works. Up at the top of the stack here, here's your game, and then here is LibGDX. LibGDX provides a bunch of functionality related to calling into your game when it's time to do stuff. But it also provides all of these libraries for drawing, sound, storage, networking, a bunch of other stuff. So when your game needs to draw something, you call into LibGDX to ask it to go draw something for you. Now whenever you call a library to go do some drawing for you, that library doesn't actually do the drawing itself. It delegates that task to the underlying hardware it's running on. So, either that it talks to the video card driver directly, or it talks to some other abstraction offered by the host operating system. So here's the trick. When LibGDX receives a request to go draw something, it can go and dispatch that command to an Android system it's running on, but it also knows how to tell if it's running on iOS instead of Android. It will dispatch a different set of drawing commands to iOS. Or LibGDX has an HTML backend, where when your game requests some networking to be done, LibGDX Intel, I'm running as a web app this time. I'm going to go do my networking using a different set of commands than I would if I was on Android or iOS. And LibGDX has a background that runs on desktop computers as well. So, the APIs that your game uses, look identical to you, regardless of whether your game is running on Android, iOS, as a web app, or on your desktop computer. That means you only need to write your game once and LibGDX will allow it to run anywhere. [SOUND] [BLANK_AUDIO] We're going to do our best to layout exactly how LibGDX works and how to build these games, but we do have to start from some baseline level of knowledge. Or else, as Carl Sagan would almost certainly not say, if you wish to make an Android game from scratch, you must first invent the universe. Specifically, we assume you've got a good handle on Java and object-oriented design. We won't do anything super crazy, but we will be extending abstract classes and implementing protocols pretty much off the bat. You'll need to be comfortable looking up documentation and code snippets. This course will teach you a lot of the basic libGDX API, but mostly this course contextualizes the official documentation. It doesn't replace the official documentation. More practically, you'll also need a computer where you can install Android Studio, and the computer literacy required for that installation process. If you want to test your games on Android or iOS, you really need the corresponding physical device. Games don't tend to work well on emulators, since they're relying on specific hardware to make drawing fast enough. Also, we'll be using the accelerometer, and that's awkward to use on an emulator for obvious reasons. That being said, we will do most of our prototyping on the desktop build, so you can definitely do this course without a mobile device. Finally, some real talk here. I know that people take online courses for all sorts of reasons and in all sorts of different ways. Hey, I make online courses for a living, and even I don't finish the vast majority of courses I start. If you're just here to get the flavor of game development, that's fantastic. But if you're here to complete the course from beginning to end, well, you're going to have to write a lot of code, learn a ton of new things, and display some real resilience and grit. You ready? All set? Fantastic, I'm glad you're set up to succeed. When I was a Udacity coach, I saw a lot of students do amazingly well, and some students disappear. The differentiator wasn't ability or free time or age or gender. It was consistency. The best students had a consistent schedule and they stuck to it, always making progress, even if it was sometimes slow. So, if you're serious about completing this course, there's one more thing I want you to do right now. And that is figure out when during the next two weeks you're going to be working on this course and write it down somewhere. I recommend an hour every weekday ideally before worker class. If you've got a scheduler or a Google calendar, that's a great place to write this down. But even if you don't, write it down somewhere, even if it's on the back of a receipt you're about to throw away. Thanks for setting up that schedule, seriously. I know it seems a little silly, but writing down your commitment to yourself makes it so much more real and, so much more likely to happen. [SOUND] [BLANK_AUDIO] Congratulations on finishing the first level. You've learned a little bit about game engines, gaming platforms, how to break a game down into its component parts, and how LibGDX allows you to write cross platform games. Finally, you made sure you were set up for success in this course. Well, sorry for making you stare at my face so much in this level. That won't be a problem in future levels, since you'll actually be programming instead of staring at me. In the next level you'll set up your tools, load up your first LibGDX project and get your first game running on your computer and on your phone. The next two levels are all about drawing. You'll learn about the computer drawing pipeline, draw some simple shapes, and to spice things up a bit, we'll also be drawing some fractals. Level five is all about making those shapes move around the screen. We'll learn about the game loop and we'll also set up some cool fake physics. In level six, we'll learn how to handle user inputs including touches, key presses and device orientation. Level seven and eight will wrap together everything you've learned so far into the finished game. When you look around these days, it's easy to forget the mobile revolution is really a few years old. Smartphones were becoming popular in the US by 2003, 2004 and even earlier in Japan. But, it wasn't really until 2007 when Apple released the iPhone that mobile apps became a thing. Now, it's hard to imaging life without them. They fundamentally changed how we communicate with each other and how we interact with everything from banks to newspapers to taxis to your neighborhood pizza boy. And, they've created a whole new way to play games. Over the last decade, mobile gaming has grown into a huge market. Developers have embraced it and mobile game popularity has exploded along with the new platforms. At first, writing games for phones or a tablet was much harder than for PCs or gaming consoles. The hardware was there but gaming libraries and tools hadn't caught up. Today, all the pieces are there. Powerful hardware with stunning graphics and audio capabilities. Tools and frameworks to enable fast and easy game development. Widely accepted monetization options to support many different business models. And most importantly, a world-wide base of customers who love to play games on their mobile devices. It's an amazing time to learn game development. Welcome to level two. This level will go super fast if nothing goes wrong and even if you have to do some troubleshooting, in under an hour you should have a libgdx game up and running on both your desktop and your android phone or tablet. We'll learn a little bit about the kind of complex structure of a libgdx application. Learning where to find the code that is shared between all the back ends. And where to find the code that is specific to each back end. We'll also learn a bit about the tool that handles all of the compiling of code and processing of resources that goes into a libgdx build. Then we'll build the android and dust out versions of the app and we'll call it a day. You'll be encountering a whole ton of new tools and programs in this level. And it might seem a bit like tool overload. While you could go ahead and read a book on every new tool you encounter, it'd be really hard to get anything done that way. So the best way to learn a tool is really just to start using it. And for my part, I'll do my best to contextualize every new tool we encounter so that they don't seem so mysterious. Getting stuff set up is always tricky, and software tends to change over time. We'll do our best to keep these instructions up to date. But if you come across a snag that we didn't anticipate, or if some important detail of one these tools has changed since we recorded this, please let us know. You can get a hold of me in the course forums or by using the Report an Issue button in the classroom. The code for this course lives in a Git repository, hosted on GitHub.com. While you don't really need to know anything about Git or GitHub for this course. I wanted to explain a bit, so that Git doesn't seem like some scary black box. A Git Repository, or repo, is just a folder full of stuff, usually code. As well as a history of snapshots of that code. These snapshots are knows as commits. If this repository is sitting on a server somewhere, it become super easy for a bunch of people to all talk to the repository. Potentially, all making changes at the same time in such a way that no ones steps on each others toes with their changes. The very, very short version, is that you clone a repository. You make some changes to your local files. You commit those files to your local repository. Merge in any changes that anyone else has made in the meantime. And then push your version back up to the main repository. Git is what's called a version control system, and it makes creating software projects, like the code for this course, super, super easy. If you're interested in learning more, Udacity actually has a whole course on Git, which you can find at udacity.com/ud775, or by following the link down in the instructor notes. Bookmark it and check it out later. Git is a crazy useful tool. Anyway, at Udacity, we use a service called GitHub to host our Git repositories. The code we're going to share with you has actually been on GitHub the entire time we've been working on this course. It's just that we flipped a switch to make the repository public when the course went live. That also means that all the messy history from when this course was in development is still in there. Feel free to poke around and find all the embarrassing commit messages. Also, to you GitHub masters out there, if you find errors in the course code, pull requests are gratefully accepted. Let's go download the code for this course. It lives on github.com. So first we need to open up a browser. The address is github.com/udacity/ud405. So here we are, code supporting the free Udacity class 2D Game Development with LibGDX. Looks like we're in the right spot. Looks like there's a bunch of folders that are numbered and labelled either Demo, Exercise, Solution. Okay, cool. If we scroll down here, we find a nice little ReadMe that says you can download this code using the grey download zip button on the right. If we actually scroll up a little bit to find that, here we go. Download zip. All right, while that's downloading, let's have a look around. Looks like the ReadMe also says that instructions for importing and running these projects can be found in this directory. All right, let's have a look. If we check out the ReadMe down in this directory by scrolling down. Let's see, we have instructions for importing and running your first LibGDX project, description of the app architecture, instructions on installing Android Studio, and instructions on running the desktop and Android versions of the game. This seems suspiciously like what the rest of this lesson is about. Well really, you can think of the course code as being the textbook for this course. People learn best in different sorts of ways, so if you want to listen to me talk about LibGDX, that's a great way to take this course. But if you'd rather just read instructions and play around with code, well, you could actually get pretty much everything I have to teach out of this course, just by looking at the course code. So that's an option for you. Looks like our download is finished, so let's go extract that somewhere useful. So here we are in our downloads folder. We have the UD405 master zip, that's what we just downloaded. Lets move that to the desktop. And we'll go ahead and extract it. And you should see that same directory structure that you saw back on GitHub, just a bunch of numbered and labeled folders. All right that now that you've seen me do it, it's time for you to download the course code. Navigate to github.com/audicity/ud405 or follow the link in the instructors note. Download as a zip. Or if you know what you're doing with Git and GitHub, you can just fork and clone it. Extract it somewhere useful, I recommend on the desktop. And when you finally see the contents, check off this box here too. Before we import our first project, let's take a peek at what we just downloaded. You'll see a ton of folders. Each one contains a LibGDX project that's either some demo code, the starting point of an exercise, or our solution to an exercise. That's right. All the answers to the coding exercises are right here in the course code, just means we can give you a tougher problems, right? Each folder is numbered by where it goes in the course. So the demo code for the first lesson, second level, which is what we're doing right now, is in 1.2. If we open up this folder, it looks like there's a ton of different files in here. But just staring at this file list for a moment, the word that pops out is gradle? Let's see there's build.gradle, gradle.properties, a gradle folder, a bunch of other stuff. What is this gradle thing? I thought we were working with LibGDX? It might feel a little weird that we're going to be using Android Studio to load up a project that's only partially about Android, but it'll make a ton more sense once we talk about the Gradle build system. So how does a game turn from source code in your editor into a form you can run? Well there's actually way more code in a LibGDX game than just the code you're going to write. There's all the middleware that defines the LibGDX APIs, and then there's all the code for whatever backend you're building. To compile your game, all the relevant code will need to be collected, compiled, and linked. Not only that, but your game will likely feature resources like images and sounds, which will need to be processed and packaged. Building an Android project is even more complicated. As it needs to know about all of your resources before any of the Java gets compiled. This is starting to sound like a nightmare, right? Well, thankfully, the Gradle build system knows how to handle pretty much all of this. A Gradle project is described in one or more build.gradle files, which define what sort of project is being built, where the code lives, and what external libraries are being used. Finally, how to package the output. Gradle also exposes a list of tasks that define what Gradle knows how to do with the source files and the resources it has. Full disclosure, the course I made before this one was all about Gradle and how it makes Android builds awesome. So what does this have to do with Android studio? Well, Gradle is very tightly integrated into Android Studio. In fact, Android Studio will happily import and build any project that uses Gradle. Android Studio maintains its own internal model of what your project looks like, which is how it does cool stuff like auto-importing and code completion. This also means that when it imports a Gradle project, or when one of the .gradle files changes, Android Studio has to synchronize its internal model of the project with the model of the project as defined by Gradle. So, if you ever see Android Studio complaining about having to sync with Gradle. That's what's going on. Before you can import and run a LibGDX project, you'll need to get Android Studio set up and get your phone talking to your computer. If you haven't already done this, then setting up Android Studio is your side quest for today. Now, I know what you're thinking. Isn't this a cross-platform game development class? Why are we using Android Studio? Well, Android Studio is actually based on another integrated development environment called IntelliJ Idea, which is a powerful general purpose Java IDE. That means you can build all sorts of stuff in Android Studio that has nothing to do with Android, like for instance, the desktop backend of our games. And of course, Android Studio will make deploying the Android version of our games super easy. And it doesn't even blink at deploying the iOS and HTML versions as well. For specific instructions on how to install Android Studio, I'm going to hand you off to Lyla, another one of our course developers, who made an awesome lesson all about Android Studio installation. You can check it out at udacity.com/ud808 or by following the link in the instructor notes below the video. Install Android Studio, and get to the point where you can go ahead and deploy a test app on your phone. Nice work getting Android Studio installed. If this was the first time you've set up Android Studio, well done, you deserve a rest at the end. When you're refreshed, let's dive into importing a LibGDX project. [SOUND] [BLANK_AUDIO] One of the functions of Gradle is to define what version of various tools and libraries your project needs, before it can be built. Gradle can usually go download those libraries for you. But it's not able to do that with Android Build Tools and SDK platforms. The version of the Build Tools and the SDK platform that LibGDX uses, ag slightly behind the latest and greatest versions. So, you might not have the slightly older version that LibGDX wants. So the last thing to do before we import our first project is to install the correct build tools in the SDK platform. To open up the SDK manager, you can start on this Android Studio Splash Screen. If you can't see this, then just click close any open Android Studio projects you might have and you should get here. Then we want to click on configure and then go to SDK Manager. Now, on the latest versions of Android Studio, it'll open up this preferences pane, but I really prefer to use the older Standalone SDK Manager. So, you can click down here to open that up. The SDK Manager will probably want to install a whole bunch of system images that you probably don't want. So, first of all, you want to click deselect all to get rid of those. Now what we do want is under tools we want the Android SDK build tools for vision 20. And then scrolling down a bit, under Android 4.4W2 or APL level 20, we just want the SDK platform. Click and install these two packages. Accept the license, and wait a bit for it to download and you should be ready to import your first project. So, your turn to go ahead and install those SDK components. Follow the instructions below and take another pass through the instruction video if you need. If you run into anything unexpected, I want to hear about it so I can make these instructions better. All right, give it a try. Perfect, let's move on to importing a project. It's finally time to import your first project. So, we're going to do is we're going to open up Android Studio and get to this splash screen. If you can't see it, then go ahead and close any projects that you have open and you should get back here. Then you want to select import project Eclipse ADT, Gradle, etc. Now, you want to navigate to wherever you put the downloaded code. If you put it on the Desktop you can just click this button to jump straight to the Desktop. So here's my ud405 folder. If you can't see it you might try hitting these blue arrows. That'll refresh Android Studio's view of your file system and that might make it pop up. Anyway, I'll open up this folder and we'll start with Getting Started With LibGDX file. Just go ahead and highlight it and hit okay. Now this next step might take a while. This is where Android Studio is talking with Gradle to figure out what source files and resources are part of this project, and what tasks can be done with this project. Also, Gradle is telling Android Studio what dependencies this project has, what other libraries it's going to use. And Gradle is downloading those libraries from the Internet. If all goes well there will be no errors and we've successfully imported our first project. If you want to see the files in the project you can open up this project pane. If you have something that looks like this then you did everything right. All right, it's your turn to import your first LibGDX project. Open Android Studio, close any open projects so that you get to the Android Studio splash screen click on the import project to Eclipse ADT, Gradle, etc. Button. Then navigate to wherever you put the course code, /1.2.01-Demo-GettingStartedWithLibGDX, and click okay. That's all there is to it. Fantastic work, getting your first project imported. Let's see if it runs. [SOUND] [BLANK_AUDIO] Now that our project is imported, let's get it fired up. We'll do most of our prototyping using the desktop back end since it launches the fastest and doesn't require an external device. So, what we need to do is tell Gradle that we want to run the desktop version and we can do that with this console command right here. If we run ./gradlew desktop:run, and wait for Gradle to do its thing, there we go. Beautiful Udacity orange. And if we click and drag around, whoa! Super sweet particle effects! All right, so it's not really a game yet. We'll get there. While you certainly can run all your games from the command line like this, it's really convenient to be able to hit the green Run button and have your project run. You can also use the Ctrl+R keyboard shortcut, however, to do that, we need to set up a run configuration. Don't worry, it's not too complicated. We simply click on this drop down and select Edit Configurations. Then we can hit the plus button. Since we want to run a Gradle task, we'll click Gradle. We'll give it the name Desktop, and then the task we want to run is in the desktop project and the task is called run. If we click OK, now we see that the current selected run configuration is Desktop. And if we hit the green arrow, there we go. Our game runs just as before. So now it's direction to run the desktop app. To set up the run configuration, you can go to Run > Edit Configurations, click +, select Gradle, name your new run configuration Desktop, give it the task, desktop:run, click OK. Then you can hit the green arrow in the toolbar and poke at your screen for a while, which I guess will make you profit. Awesome work getting a lib GDX game running on your desktop computer. Let's have a closer look at the files involved in a lib GDX project, then we'll try running it on a phone. Time to check out what we've got loaded up. Let's open up the project pane by clicking the tab at the top left, or by hitting Cmd+1 if you're on a Mac. By default the project pane only shows the source and resources that are relevant to an Android build. That can be nice sometimes, but for now let's use the drop-down at the top of this pane to open up the project view. There we go. Now we can see all the files and directories in our project directory. Let's open up the settings.gradle file. This shows us all the modules that make up this project. Looks like this build has desktop, Android, iOS, and HTML modules. So that's where the code for each of those specific platforms lives. Then there's also the core module. That's where we'll write the code that will run everywhere. Not all of these files and folders will be super relevant to you, but I want to go over what all of them do just so that there's nothing that seems magical in here. First the .gradle folder. Gradle is a very smart build tool. And when you ask it to compile something, it checks to see if it's already compiled that file. And if so, it says that that compilation task is up-to-date and skips it. The .gradle folder is where gradle caches that sort of information. The .idea folder is where Android Studio holds its information about the project and the state of the workspace. It's just a ton of complicated XML you don't need to touch. We already talked about the android, core, desktop, html and ios folders. Then there's the gradle folder. The gradle folder, works together with the gradlew and gradlew.bat files to form what's called the gradle wrapper. Basically, the point is, that gradle knows how to download itself, so you can version control what version of your build tools your actually building the project with. It's something super fancy you don't need to touch, but it's also why you didn't have to install gradle in order to build this project. Pretty, cool, right? The .gitignore file tells git which of these files shouldn't be checked into version control. These consists mostly of files that are user specific settings, like everything in the .idea folder. And, of build outputs like everything that's in each of the build folders where gradle spits out its outputs. gradle.properties and local.properties store more gradle specific configuration. Finally, there's a README file that explains all this in much more detail. So, that's it. That's all of the files on a libGDX project. Nothing really magical. All right, now lets do something that is a little bit magical. Without changing any code at all, we're going to run the exact same game we just ran on our desktop, but on an android device. If you've worked through our mini course on installing android studio, then you should already have installed a hello world app on your phone. And if you haven't done that yet, then follow the link in the instructor notes to learn how to set up your phone for USB debugging. Allright, so I've got my test device. And we'll go ahead and plug that in. There we go, this little icon says that we're now doing USB debugging. All right, now we'll switch our run configuration from the desktop run configuration back to the android run configuration, and hit run. When this device picker dialog pops up, we want to select the actual test device we want to use and hit okay. And there we go, we've got our game running on our phone. Check it out, it even does multi touch tracking. Now it's time for you to try running the Android version of the app. Set up your phone for USB debugging. If you haven't done that yet you can check out the instructions in the instructor notes. Change the run configuration back to Android. Hit the green arrow. Select your phone and in the device choose your dialog. And then you just get to poke at your phone for a while. Nice work. Super cool that we can run the exact same game on two totally different devices, right? Now that we set up the desktop and Android backends, you are probably wondering about the iOS and HTML backends. Well, the HTML backend is kind of hard to run because you need to be running Gradle tasks from the command line. The IOS backend is even more difficult because we need to first provision a device for debugging, which requires Xcode and some time. Also, as you might be aware, all the iOS system APIs can only be accessed from Objective-C or Swift, which makes running a Java game kind of tricky. We're not going to set up the iOS or HTML backends for now. But we've created bonus levels explaining how to set up both, which you can check out by following the links in the instructor notes. Whenever I'm learning a new framework, I never quite feel like I've really got it set up until I can start making changes myself. So before we quit for the day, let's make one simple change. That background seemed a little too, well, orange. Let's swap that out for a nice blue. If you open up the TODO pane down at the bottom of Android Studio, you can see that there's a to do item to make this UDACITY_BLUE instead. Let's double-click on that to see what it's talking about. So now we're in the actual game code itself which we haven't talked at all about yet. We'll be getting into that next level. But looks like there's a TODO to make this UDACITY_BLUE instead. Think you can take care of that? Go ahead and make this first project your own by swapping out these colors. Open up the TODO pane in Android Studio. Double click on the TODO make this UDACITY_BLUE instead item. Follow those instructions. Then try launching the Desktop run configuration to see the new game running on your desktop, and run it on your phone again and enjoy the nice blue color. By the way, if you can't quite figure out how to do this, there'll be a solution video following this quiz that shows you exactly how to do it. So, if you run in to any troubles, just hit view answer and I'll show you how to do it. All right, so we're back in our source file where we had the to do item to make this UDACITY_ORANGE into UDACITY_BLUE. And if we scroll up to the top of the file we actually see that we defined a couple of constants for UDACITY_ORANGE and UDACITY_BLUE. So all we need to do is highlight UDACITY_ORANGE and make it into UDACITY_BLUE instead. Let's try running this on our Android device. So we've got the old orange version running. Let's go ahead and tell Android Studio to launch the new blue version. Aha, there we go. Much easier on the eyes. In this level, we set up Android Studio which was a big operation. Then we learned a bit about the Git version control system and downloaded the course code from GitHub. Then we learned about the structure of a libGDX project and about the Gradle build tool that actually compiles and packages the games we'll build. Then we imported our first libGDX project into Android Studio and set up a new run configuration to launch the desktop backend. Next, we launched the Android backend. Finally, we made a small tweak to the game and got some more practice launching the desktop and Android backends. That was a lot of work. Awesome job taking care of all the setup and background work. Next level is all about drawing. We'll start with some basic shapes and work up to some crazy fractals. See you there. My very first job in the game industry was porting a popular PC flight simulator to the Amiga computer. This was ages ago. There was a steep learning curve. I'd been programming for maybe ten years, since junior high school by this time. But this was my first real professional programming experience. I was learning about 93 new things every single day. And there were new tools to understand and libraries and systems to integrate. Hardware issues and near faces, not to mention the game itself. It had been written for a completely different computer architecture by some super smart industry vets including one of the company founders. Oh, and did I mention, I didn't know anything about flight simulators? Well, I remember one of the first issues I ran into. There's a problem with the 3D renderer. On a PC, it worked great. It was pretty much bulletproof, super fast. It had been used in several titles and it just kept getting better as it was refined over time. On the Amiga, though, the renderer was brand new, never been used in production. And, there was a glitch. Sometimes, unpredictably, a polygon would tear and it would just blow up and overwrite half a screen. Looked terrible. And since I hadn't written the code and had no idea how our 3D engine worked, I wasn't sure how to debug it. I turned to one of those super smart industry vets, one of the creators 3D engine in fact, and asked him for advice on tracking down this bug. And he said, I would just step through all the code. Well, from my point of view, this was insane. I just didn't see how I could possibly learn and understand how the system worked from top to bottom, which is essentially what he was telling me I needed to do. To step through the system and figure out which part wasn't working, I had to know what each and every part did when it was working. He was right though, and it was hard. But I learned more than just how that 3D engine worked. I learned that I could tackle a really hard problem and solve it. You can always look for the easy answer, but it's important that you not give up if there isn't one. You have what it takes to succeed, even if it doesn't seem like it at first. Welcome back. I hope you're refreshed after importing your first libGDX project and I'm sure you're dying to learn how to create those sweet particle effects. Before we get to that, though, we should start out with some simpler drawing. So in this level we're first going to learn a bit about about how the computer drawing pipe line works. With a brief detour into color theory, and how your eyeballs work. Then we'll talk about the main entry point into libGDX games, the Application Listener Interface. We'll implement an application listener, and then use ShapeRenderer to draw some simple shapes, some pretty flowers and even some fancy fractals. Let's get started. Back in the day using a computer monitor was dangerous business. It meant sitting without flinching while an electron gun shot charged particles at your face at nearly the speed of light. Only to have them slam into a thin layer of glass covered in poison. Depending on where and how many electrons were shot at you, they would produce explosions of different colors and brightnesses. Which your eyes would see as an adorable paperclip, or whatever. This system is called a cathode ray tube, and it was the bane of LAN parties everywhere. Since the screen is a big rectangle, and the electron gun can only paint one dot of color at a time, the gun had to traverse the whole screen many times a second. Well I'm sure you can think of many cool space villan curves that would get the job done. The chosen solution was a lot simpler. The chosen solution was to divide the screen into horizontal scan lines. Much like the lines in a book. And the traverse the lines from top to bottom. This was called Raster scanning. >From the Latin Rastrum, or rake. It's like raking a zen garden, but instead of having a rake with many tines you have to draw each line individually. The roster scan implies that the colors in the screen have to be laid out in a rectangular grid. While this might seem obvious, it didn't necessarily have to be so. You can certainly imagine a hexagonal grid of colors, and that might well have been better from a human perception point of view. Turns out though that the math of drawing to a hex grid is super frustrating, so maybe it's best we stuck with rectangular grids. So ultimately, for a computer to draw it constructs a two dimensional array of colors and memory and ships those colors to whatever device is going to be ultimately displaying the colors. Be that a monitor, a projector, or some sweet virtual reality device. Note that these roster elements are also referred to as picture elements, or pixels, for short. When we draw on a computer all we're really doing is assembling an array of colors. If you've ever looked at your computer monitor under a magnifying glass you've probably noticed that each pixel is actually three vertical rectangles. One red, one green and one blue. And yet, when you take away the magnifying glass the pixel can look like any color at all. Pretty weird right? This works because the human eye isn't as good as distinguishing colors as you might think. Our eyes can't actually tell the exact energy of an incoming photon. So here's our eyeball and here's the cornea and here's the retina and here's the optic nerve. Now the actual sensors in the eye are three types of cone cells. And each of these type of cone cells collects photons of a particular range of wavelengths. If a photon falls in the range of the l, or long wavelength cone cell, our brain perceives it as red. If the wavelength is a little shorter, and it falls into an m, or medium cone cell, then it looks green. And, if the photon has a super-short wavelength and stimulates the s cone, it appears blue. All other colors are just how our brain interprets photons that stimulate multiple types of cone cells at once. Since red, green, and blue light each directly stimulate one of the types of cone cells, this means we can simulate any other color by replicating how that color would simulate the cone cells. For instance the color yellow is the results of stimulating both the l and the m cones, but it doesn't matter to our brain exactly what photons were involved. It could be a yellow laser where every photon has exactly the same energy. Or it could be an even combination of green and red light. The response of the l and m cones is the same either way. So to our brain, it's the same color. The unintuitive result is that any visible color can be generated by a combination of red, green, and blue. Human color vision is a crazy topic. And you can check out the instructor notes to learn more. We'll be representing colors using a color class provided by libGDX. To find out how it works, let's check out the libGDX documentation. You can find the libGDX website at libGDX.badlogicgames.com, or just by searching of course. There's a link to the documentation in the nav bar. Let's click it then, if we scroll down a bit, we find a whole bunch of awesome resources. But, what we're looking for is number 8. Read the Javadocs. And now, to find information on the Color class. We can just search the page for a color. There we go. Let's check it out. Awesome. We've got a color class holding the RGB and alpha components as floats in the range 0 to 1. Scrolling down we see that there's also a whole bunch of predefined color constants. Why don't you go check out the libGDX color documentation and see if you can figure out which of these is not a predefined color constant? Firebrick, periwinkle, goldenrod or chartreuse. I think you'll find among these lovely colors that periwinkle is the one that's not predefined. If you want to get that perfect shade of blue, you're going to have to figure the RGB components yourself. Good job looking at the LibGDX Documentation. This will be a great resource going forward. Probably want to bookmark it somewhere too. >From our discussion of human color vision, we know what's going on with the r, g, and b in the color class. But what's this alpha thing? Alpha is another component of a color that computers use for compositing, which is a fancy way of saying, what happens when you draw stuff on top of other stuff? If you draw a shape with alpha equals one, then it's totally opaque. Whatever the background color was, it's totally gone. If you draw a shape with alpha equals zero,then you haven't actually changed anything. The new color is totally transparent. If alpha equals .5, then the new color is half the background color and half your new color. So your drawing looks translucent. For now, we're going to be drawing everything fully opaque. So any time you see an alpha field, just set it to one. Everything you see on your computer screen is just a rectangular grid of colors. This makes perfect sense for some things. For instance, a digital photo is captured using a rectangular sensor grid. So, the color samples you see on your computer are just the colors that were captured by the camera. But what about something else, like a line drawing? A smiley face is made up of circles and arcs, it's not made of a rectangular grid of colors. So, how do we draw it to the screen? It seems impossible, right? To draw shapes like lines, triangles, circles, and other polyhedra, they have to be rasterized. To draw a black arc on a yellow background, we have to determine for each sample on the raster, whether that sample is part of the arc or part of the background and then color that sample appropriately. If you want to get super fancy, you might determine what percentage of the sample is part of the arc, and what percentage is part of the background, and then mix the two colors to get your final output color. Doing is this is called antialiasing for reasons beyond the scope of this course. Anyway, only once we know the color of every pixel, can our shape be drawn to the screen. This process is also called rendering. This presents a huge challenge though, which we'll explore by way of a quiz. So, how much work is rasterization? Let's say our raster is 1080 x 1920, so that's standard HD. And let's say we're drawing 20 shapes to this screen. Let's then say for each pixel and each shape, it takes 10 processor cycles to determine if the shape changes the color of that particular pixel. Then, since we want a silky smooth frame rate, we need to do all of this 60 times a second, so here's the question. How many processor cores running at three gigahertz would we need to render this screen? All right lets head over to WolframAlpha and type in our equation. So we've got 10 80 by 19 20 pixels times 60 frames a second times 20 shapes times 10 processor cycles per shape, per pixel. Divided by 3 times 10 to the 9th cycles per second. So, looks like even if all of our assumptions were correct. And they're really not, that's a super conservative estimate. It would still require 8.3 processor cores in order to render that super simple scene. So even if you have the latest crazy octa-core processor you still couldn't even render 20 shapes. Well, not using your CPU anyway. There's gotta be something more interesting going on. The central processing unit on your computer can do just about anything. But even the craziest computers' CPUs only have about eight cores these days which isn't enough to render a complex scene in real time. Fortunately, your computer and phone also have say, graphics processing unit, or GPU. GPUs are chips purpose built to pump out pixels, and some can have thousands of cores. Each of these cores is pretty limited in what it can do, though, and groups of these cores have to work together in a lock step, each executing the same instructions each clock cycle. So while the GPU is less flexible than a CPU, it can spew out pixels at some absurd rate. So the code we run on the CPU determines what we want to draw. And then we send those instructions over to the GPU which will actually figure out the pixel colors. To do this we need a language for communicating between the CPU and the GPU. The most common language for this purpose is called the Open Graphics Language or OpenGL. Smartphones use a slightly scaled down version of this language called OpenGL ES, where the ES stands for embedded systems. If in a Microsoft universe you've ever heard of DirectX, that's a language that serves essentially serves the same purpose. So to sum up the CPU uses OpenGL to tell the GPU what to draw. The GPU builds up the actual array of colors and ships it to the electronics that run the screen. Brief aside, I'd be failing as a nerd if I didn't mention that you can actually do far more with GPUs than just color pixels. There's a whole field of general purpose GPU computing. Algorithms that run on GPUs need to be very clever about how they get those lock-stepping cores to work together. But when they do, they can be extremely fast, and as is often even more important these days, extremely energy efficient in terms of power per calculation. Back to business. The first thing we're going to do, is draw some very simple shapes to the screen, like points, triangles, and rectangles. Ultimately, these drawing instructions need to make it to the GPU, and we know that the way that the CPU talks to the GPU is via OpenGL. Thankfully, we don't have to interact with OpenGL directly. Instead, we're going to use a LibGDX abstraction called ShapeRenderer. We ask ShapeRenderer to draw shapes for us. Then, it figures out all the complicated OpenGL stuff that needs to happen under the hood to finally talk to the GPU to get our shapes drawn. ShapeRenderer works in batches. It's slow to ask OpenGL to draw shapes one at a time. But it's much faster to bundle up all our drawing instruction into a batch, then send that to OpenGL all at once. Further, ShapeRenderer has three shape type modes and a batch can only contain shapes of one of those types. Those modes are, well, I'll let you check out the documentation to figure that out. So, what are the ShapeRenderer shape types? If you just Google for a LibGDX shape type, you should get to the right page in the documentations. Or, you already bookmarked the documentation right? Should be easy to get back there. Write your answers in these boxes. All right, if we search for a libGDX ShapeType, the first result is exactly what we want. And, if we scroll down a little bit, we see that the three elements of this enumeration are filled, line and point. Filled draws solid shapes, line draws lines or outlines of solid shapes, and point, well, draws points. The libGDX Javadocs are a fantastic resource. For instance, if we jump up a level to ShapeRenderer, we get a ton of background information and even some code snippets to get started. Pretty cool, right? So LibGDX provides us a with a way to talk to the GPU without needing to actually use OpenGL. LibGDX also provides us with a rectangular area of the screen we can draw to. On a mobile device that's generally the entire screen. Now we need to thing about how we're going to position stuff on that screen. We clearly need an x, y pair. And the easiest way to position stuff is by having the x value be the number of pixels from the left edge of the screen, and have the y value be the number of pixels from the bottom of the screen. That's the approach we are going to stick with for the rest of this level, but next level we'll start using a much more flexible system called an orthographic camera. Let's check out how to use Shape Renderer to draw some points. I don't just want to show things off of my computer, though. I want you to follow along on your own machine. Let's walk through loading up a libgdx project one more time, just to make sure you got the hang of it. So we'll open up Android Studio, close everything until you get to this flash screen. Go to import project. We'll navigate to the ud405 folder that you downloaded earlier and then open up 1.3.01-Demo-DrawingPoints. Now Android Studio and cradle will think about things for a bit. All right, there we go, we're all loaded up. Now let's set up our desktop ring configuration again. We click on the right configuration drop down. Hit edit configurations, hit the plus button, select Gradle, give our new run configuration the name Desktop and then give it the task, desktop run. Then one more thing so we can see the files we're working with, we'll open up the project pane. Then switch this drop down from Android to Project. Awesome, now we're ready to get started. Walk through these steps again and we'll get to some actual drawing. Nice work. I hope you remembered how to do most of that from last level. We'll assume from here on out that you've got the project import process down. All right, now that we've got the first demo loaded up let's see what we've got here. Well first what we've got is a README file that actually contains the text version of everything I've said so far this level. So if you need a refresher, well you know where to find one. To find the real meat of the demo though, let's open up the the TODO pane down at the bottom. Find a nice entry that says TODO: Start here to learn more about ApplicationListener and ShapeRenderer. Sounds good. Let's close the rest of these panes so we have some room to work with. If you open up this file on your own machine, you may notice that there's a whole bunch more comments in here. And again, that's more or less the text version of what I'm about to tell you. So the entry point into your code that you write for a game is a class that implements ApplicationListener. ApplicationListener has six required methods that we'll walk through. We've also inserted logging messages that fire when each of those methods is called. So in this demo, first thing, we're setting up a tag so that we can identify our log messages. And then we declare a private shape renderer. Create is the first one of the required methods on an application listener and that's basically where you do anything you do in a normal constructor. This will get called when the host application is ready for your ApplicationListener to come alive. And of course, this is where we initialize our shape renderer. Immediately after our application listener is create, resize will be called to let us know how big the screen is. We won't be doing anything with resize just for now, but next level we will be using it to make sure our camera doesn't go out of whack. Next, we have the dispose method. Now, you might be thinking this is Java, don't we get automatic memory management? I thought garbage collection was a thing. Well, while it's true that Java can usually be relied upon to clean up your memory for you, a garbage collection event takes a long time. And when you have a game that trying to render itself 60 times a second, a garbage collection event can easily make you drop a whole ton of frames. That makes it look like the game is just frozen and users don't like that. So, there's a number of places where we have to manage our own memory. In this case, when our application listener receives a call of dispose, we should dispose of any resources that we are using. All right, the render method. This is the real heart of the operation. This gets called every time our game should draw itself. So, you know how I said we didn't have to talk to OpenGL directly? Well, that's mostly true. These two lines clear the previous screen. These lines get repeated pretty much verbatim at the start of every render method throughout this course. The first line tells OpenGL, hey, what's the background color? In this case it's black, that's opaque. And the second line actually tells open GL to go ahead and clear the screen. All right, then we tell shape renderer to start a new batch and we pass in the shape type we want to draw. In this case we want to draw points. Then we draw point at location 100 100. So that's going to be 100 pixels up from the bottom of the screen, 100 pixels right of the left of the screen. And then, we've got to remember to end our shape renderer batch. Pause is the second to last of the required application listener methods. And it gets called right before our application is disposed of. It can also be called when our app goes offscreen and is no longer active. This will usually happen in Android when you hit the home button. Pauses where we want to save anything we want to persist about the game like how many lives the player has left. Resume gets called if the game comes back to life after being paused. Again this is pretty much an android specific thing and we'll talk much more about this later. All right so we expect this code to draw a single point to the screen. Let's give it a try. All right, it's not much, but there we go. We've got a single point illuminated. It's kind of pretty kind of like a star in the night sky. So let's try something a little more difficult. And we'll make it the first coding exercise. Instead of drawing just a single star, let's fill the screen with the star field. Let's go ahead and import the project. So it looks like in the course code, we have Exercise-DrawStarField, and Solution-DrawStarField. You know what, let's open up the solution first to see what we're aiming for. For a project that I don't think I'm going to be running a whole ton of times, I'll sometimes skip setting up the desktop run configuration and instead, just open up the terminal and type ./gradlew. On Windows, we just leave off the ./ and then tell Gradle, hey I want to run the desktop run task. All right, there we go. I cranked up the star density pretty high in the hopes that you can actually see this. All right so this is what we're going to try and make. Let's jump over to the starter project. All right here we go again, import project, and this time we're going to open the exercise project instead of the solution project. All right, we've got the exercise project loaded up. Let's open up the TODOs to see what we need to do. TODO, start here, sounds good. Looks like we got some instructions in this exercise. We'll draw a star field of white points on a black background. The number of points will be defined by a density parameter that states what proportion of the pixels should be white. All right. TODO: Run what you've got before making any changes. Since I do anticipate to be running this project a while bunch of times, I am going to go ahead and create a run configuration for it. If we run it, we get red. The sky is not supposed to be red. I presume we're going to have to fix that later. Oh well, at least we've got a running project. Opening up the TODOs again. We've started here, we've run what we've got. All right, next thing, initialize a shape renderer. Okay, well that's easy enough. shapeRenderer = new ShapeRenderer, done and dusted. All right, the next toTODO, call initStars. All right, initStars takes this density parameter. And looks like we have a constant defined for that, okay? All right, easy, we're on a roll. Let's do one more. Let's say I'm confused, instructions unclear, got charging cable stuck in ceiling fan. Well, not to worry, we've got the solution to this exercise as well. Here we are back in the reference solution, and if we open up the TODOs, we see the exact same TODO list as we had over in the exercise. So here is the TODO we were stuck on. And let's see, we get the screen width using Gdx.graphics.getWidth, okay. We get screen height using Gdx.graphics.getHeight, all right. And then starCount. All right, so that's the height times the width times the density. All right, that makes sense. So this is the total number of pixels on the screen. And then this is the proportion of them that should be stars. And then we just cast it to an int. All right, seems straightforward enough. Now we can hop back over to the exercise code and replicate what we saw here. Or we can just copy and paste if we're feeling particularly lazy. All right, time for you to tackle the rest of the TODOs on your own, using the reference solution whenever you need. When you're done check out the reference solution anyway, as there will be useful tips, best practices, and maybe some extra challenges to try. If your version doesn't look exactly like the reference solution, that's totally fine. There are always a lot of ways to accomplish the same goal. Awesome work. The solution videos in this class will be pretty short since the actual solutions are all in the course code for you to read on your own. I do want to show you one thing though, and that's the importance of making sure you don't put stuff in the render callback that you don't want called 60 times a second. Let's say we accidentally put initStars inside the render callback. Any guesses on what's going to happen? Let's give it a try. Whoa, warp speed initiated or something. So what's happening here is the position of the star is being recalculated every single frame. Remember, be careful about what you put in the render callback. [SOUND] [BLANK_AUDIO] Let's move on to drawing lines. You can follow along by loading up 1.3.03 demo drawing lines. So first, let's get start up as usual by declaring and initializing a ShapeRenderer. Also, we gotta remember to clean up after ourselves and get rid of anything we're not using. Also note, instead of using ApplicationListener, we're using ApplicationAdapter here. ApplicationAdapter is just a convenience implementation of ApplicationListener. It stubs out all of the required methods with implementations that don't do anything. So all we've got here is actually create, dispose, and render. All right, as always, all the interesting stuff happens in render. So first, we clear the screen. We actually clear the screen and then, we start a new shapeRenderer batch. This time, using the Line ShapeType. All right, now we're going to draw a line from 0, 0 to 100, 100. Let's give it a try. Well, that didn't go according to plan. There's nothing on the screen and we actually got an error down here. Let's see. Illegal state exception. Call end before beginning a new shape batch. Oh, right. So all we did here was start the batch and then draw a line but didn't end the batch. Then the next time render got called it tried to begin a batch but shape render was already in the middle of a batch so we got a crash. All right, let's try this again. Awesome. We're in business. Let's try something more interesting. Let's try drawing a line of a different color, by using shapeRenderer.setColor, and then using one of the pre-defined color constants. Then we'll draw another line slightly offset from the first one. Hm, whoops. Well we got our magenta line, but the first line we drew also ended up magenta. The way colors work with shapeRenderer is it will assume you want white until you tell it about some other color. However, if you tell it about some other color, it will retroactively assume everything you wanted you draw before that, you wanted to draw that color as well. Lets try this setup. Hey, there we go, that's what we were looking for. We can also set colors using our RGBA values. Now before we draw this line, what color is this? So it's fully opaque because alpha's one, so that's good. All right there's no red and there's no blue, so the line must be green. Let's run it and see. Our predictions were correct.. We can even do fancy things like drawing lines with gradients by specifying the color at start of a line and the color at the end. And there we go. We got a nice fade from blue to red. One more useful thing for drawing lines. If we wanted to draw a whole series of line segments, it would get really tiresome to draw each one individually. So we also have polyline. Polyline takes an array of floats, where the floats at the even positions are the x coordinates, and the floats at the odd positions are the y coordinates. If we give this one a try, we see this crazy path with a bunch of connected line segments. Let's play a game of connect the dots. Instead of drawing lines by hand, though, we'll use a polyline. So here we are in 1.3.04 ConnectTheDots. Let's try running just what we start out with. Hmm, not sure, well maybe that's some legs? Well, let's draw a line and figure it out. The TODOs in this file will explain further what you're going to need to do to draw that line. But it looks like the dot positions are wrapped up in this array of Vector2s. What's a Vector2? Well, if we right-click on it and we say Go To, Declaration, we see that Vector2 is a class provided by lib GDX that just holds an X and a Y component. Super convenient. So what we're going to need to do is convert this array of Vector2s, into an array of floats that polyline will accept. And then we'll go ahead and start a shape render batch, with Shapetype.Line. Actually draw the poly line and then as always, remember to end the batch. Try connecting the dots and when you're done, what animal do you see? Remember, if you get stuck, or just when you're done with your solution, I'd go ahead and check out our solution as well. Nice work. If you're interested, in the solution directory you'll also find a project called generator. This is how we drew out that elephant in the first place. Let's try something that will require a bit more problem solving. Given some code that draws a bunch of concentric rectangles, could make some small changes so it draws a spiral instead. Open up the exercise project and give it a try. All right, because this one's pretty tricky I'm going to give some visual spoilers. So I'm going to show you how to move some line segments around here so that these rectangles instead turn into a spiral. So all we're going to do is move this little chunk of each rectangle so that it faces this way instead. So we're going to connect and then erase, and connect and erase, connect and erase, and erase, and now we've got a spiral. Nice work figuring out how to draw a spiral. I hope that stressed both your geometrical reasoning capabilities and your libGDX abilities. All right, let's move onto drawing rectangles now. The first interesting thing about rectangles, is that they can be drawn with two different shape types. They can either be drawn with shape type line, just to get the outlines of the rectangles, or shape type filled to fill in the rectangles. Let's go with filled for now. shapeRenderer.rect is overloaded with about a dozen different functions to do different things. Honestly, to have a look at them all you should probably just check out the documentation. The basic version though, draws an access aligned rectangle, starting with the lower left corner and then giving the width and the height. Let's try running this. So far, so good. Let's do something more interesting. We can do some super fun stuff with the colors and rectangles, like specifying a color for each corner. Let's try this. There we go, the rectangle smoothly transitions between the colors at the corners. These next two rectangles are being drawn in such a way that one's going to overlap the other. So, which one do you think is going to come out on top? Is it this red one, which is being drawn first, or the green one that's being drawn second? Ha, look like the green one wins. When shape render is asked to draw things on top of each other it uses what's called the painter's algorithm. Just like the initial layers of paint laid down by a painter get covered up by what gets pained later, similarly, shapes that are drawn later on will cover up shapes that were drawn earlier. We can also use shape render to draw rotated rectangles. Now here's where the signature of rect starts getting pretty crazy and the documentation will come in handy. Again, here is the bottom left corner, and here's the width and height now. And this entry is the origin about which we'll be rotating. So if the width and height are both 100, then 50/50 is right in the middle of the rectangle. Then we have the x scale, the y scale, and rotation. So, we're drawing this 100 by 100, but then we're going to squash it by 50% horizontally, and rotate it by 45 degrees. Same thing with this one, except we're going to rotate it 135 degrees. Let's check out what this looks like. Cool. So we've got two rectangles that were drawn at the same spot. They were smashed by 50% horizontally, and then the yellow one was rotated by 45 degrees. So it was initially straight up and down, and now it's tilted to the left. And the green one has been rotated by 135 degrees. To more easily understand what's going on with this origin parameter, let's try something very similar. The setup is almost identical, but instead of the origin being in the middle of the rectangle, the origin is now down at the bottom left corner of the rectangle. So now, the rectangle's instead of being rotated about their center, are being rotated about this bottom left corner. OpenGL has an interesting quirk. It knows how to draw in filled shapes, but it doesn't know how to draw thick lines. So if we want a thick line, what we actually need is just a rotated, super skinny rectangle. Thankfully, shapeRenderer gives us a super simple way to do this. It's called rectLine. We give it the x and the y position of the start of the line, the x and y position of the end of the line, and the thickness. And there we go, we get a fat line. [LAUGH] All right, last thing, time for some silliness. Let's draw a rainbow flower, this might come in handy for the next quiz. Pretty cool, right? In this next quiz you're going to draw a flower. You're going to start out by drawing the stem, with a rect line, and then draw a couple of leaves using rotated rectangles. Then finally, you're going to generate a bunch of petals by generating rotated rectangles in a loop. Check out the code in the course repository and give it a try. Nice work. Mixing drawing commands with normal control flow statements seems pretty awkward at first. But, you'll quickly get used to it. There was so much complicated stuff in this level. You learned all about the structure of a lib GDX game, and now you can draw whatever you want. However, you may have noticed that what we've drawn so far, doesn't really adapt to screens of different sizes. So in the next level, we'll learn a few more drawing commands, but, more importantly we'll make our game world scale to what ever size device our player is using. See you there. When I started in game development, state of the art graphics were based on pallets. So, you have a certain number of slots for the different colors you could display at once, and typical screen resolution was tiny. Imagine how chunky a game would look at 320 x 240, or even 320 x 200. Just a few years later, there were flip phones with higher resolution. It was certainly a challenge to make games look good. Especially when you were limited to 32, or 64, or even 256 colors. If you wanted to shade an object, for example, you had to make sure to reserve space in the palette for the color gradations. Usually just a few inches each for the major colors like red, yellow, and blue. It's also made anti-aliasing tricky because it's basically just color blending. So there goes more of your palette. At the time we were using dot products to do rudimentary light source shading. Everything had a very cartoony look since the colors didn't change smoothly over the surface of an object, and they tended to pop between values as objects moved in the scene. We didn't care. We just thought it was cool that shapes were more realistic looking, even if they were really crude. We just did something artistic with that flower, so let's do something a little bit more mathy and draw the Cantor Gasket, also known as the Cantor Carpet. To make the Cantor Gasket, we take a square and then consider it as a three by three grid of smaller squares. So there's nine squares total. Then we remove the center square, like so. Now for the eight remaining squares, we repeat this process, punching out the center of each of these squares. Well, I'm freehanding this but you get the idea. Starting to look pretty cool right? Let's do it one more time. Now we're getting some serious fractal action. All right, I can't draw this any further by hand, but you should be able to write a program that can draw this to a arbitrary level of depth. This is going to be quite the challenge, but give it a try. Drawing with a recursion? Super cool right? Fantastic work. We've got one more even bigger challenge in this lesson though. So, you know how to draw lines now. Let's try drawing a really, really complicated line called the dragon curve. The dragon curve is a fractal with some really cool properties, and it has a reasonably simple rule for producing it. The base case is just an elbow like this, and we'll call this L for a left turn. Now the recursive rule is to produce a dragon curve of order N, you take a dragon curve of order N minus one, turn left, and then reverse and reflect the dragon curve of order N minus one. Sounds straightforward right? Let's do a few examples. So, the dragon curve of order two is the left turn that we got from the dragon curve of order one, followed by another left turn, and then we reverse and reflect this left turn, which is just a right turn. This is what this looks like. We make a left turn, we make a left turn, we make a right turn. The third order dragon curve is already starting to get pretty complicated. We've got LLR from the second order dragon curve. We've got an L and then we have LLR reversed and reflected, so LRR. The fourth order dragon curve is starting to get pretty squiggly. And the fifth order dragon curve is starting to get just ridiculous. You can start to see some interesting properties though. The curve will touch itself, but will never actually cross itself. Once you get up to the tenth order dragon curve, it starts to look pretty beautiful, like a crazy galaxy or something. So to draw the dragon curve, we need to first work out the turns the curve will take, translate those curves into line segments, and then use ShapeRenderer to draw a polyline. Sounds easy enough, right? Well, give it a try, but this one's a lot harder than anything else we've done today. If you just want to check out the reference solution, that's fine too. Congratulations, seriously. This is some hardcore drawing. The more comfortable you get with drawing these primitives, the easier it will be when we're talking about game logic later on. Well done. The mathematics behind computer graphics is fascinating, especially when it comes to 2D and 3D projection. Whether you are creating a side-scrolling platformer or a first-person shooter, it turns out that how the graphics are transformed and manipulated before they reach the screen is very similar. As you might expect, 2D can be considered as just a special case of 3D, and, in fact, that's how many frameworks and development tools treat 2D objects and scenes. It's a question of perspective, literally. We usually think of perspective as a feature only of 3D games, like driving games or first-person shooters, because they tend to look like the physical world looks. There are vanishing points where lines converge, and objects appear smaller the farther away they get. This is because they rely on perspective projection to render objects on a flat screen, but there's another whole category of projection called parallel projection that produces very different results. In fact, one kind of parallel projection called orthographic can turn a 3D scene into a typical platform or side view or a top-down 2D map. This allows 2D game developers to use today's, powerful feature-rich 3D development tools, then achieve the look and feel they want simply by changing properties of the main camera view. This is the approach we'll take for our game. We'll use an orthographic projection to render it in the style of a classic side-view platformer. Later, you might experiment on your own with other kinds of projections. They're fun to play around with. Isometric projection is popular right now. Think of Crossy Road or Monument Valley. At first glance, it looks like objects are drawn with perspective, but then you notice that there's no foreshortening, which is a classic feature of perspective drawing. One time, in a hare-brained attempt at optimization, I accidentally created a rather exotic projection in which all straight lines curved subtly, kind of like a fish eye lens, but not exactly. I was trying to simplify the math for speed and was experimenting with spherical coordinates. The result wasn't really practical for my purposes at the time, but it found its way into other projects later on. It was cool. In the last level, we learned a ton about libGDX's drawing capabilities. In this level, we'll warm up by drawing some circles and a stick figure using shape renderer. Next, we'll create a camera that allows us to zoom in on parts of a larger scene. Cameras can require you to keep track of a lot of details, especially when you need to support screens of any size. So we'll learn about viewports, which can manage a lot of these details automatically. Finally, I've got a few more drawing challenges for you, which will be made a lot easier using viewports. Before we dig into the camera perspective, viewport awesomeness that is the rest of this lesson, let's learn one more shape. The shape renderer can make for us. Circles. Also partial circle or arcs. We're going to explore more code in the course repository. You can load up this project yourself and follow along. To dig in, let's check out the TODOs. Here's the most basic circle you can draw, specifying the x position of the center, the y position of the center, and the radius of the circle. And there we go, it's beautiful, right? We can also draw a partial circle or an arc, by specifying the number of degrees counter-clockwise from the positive x-axis that the arc should start And how many more degrees it should keep going from that point. So this line is 45 degrees from the positive x-axis in the counter clockwise direction. And then 270 degrees is three quarters of a circle, so we get this Pac-Man shape. Circles have a dirty little secret though. They're not really circles, they're a fan of triangles where all their triangles have their points at the center of the circle. ShapeRenderer will pick how many triangles to use so the circle looks smooth. But if you make super small circles, it might choose to use too few. This optional last parameter sets the number of segments to use. Let's see what happens when we set the segment count too low. If we set the segment count too low, we end up with a circle that looks like a stop sign. This can also happen if you're drawing very small circles but you're zoomed way in on them. Circles can be drawn using either ShapeType filled or ShapeType line. The ladder draws just the outline of the circle. If we want to draw both solid circles and the outlines of circles in the same render callback, we first need to end our filled batch and begin a new batch in line mode. Lets give this a try. There we go, a circle drawn in line mode is just the outline of the circle. Lets try something crazy and draw some target rings. Bam, there we go. We can also draw just the outline of an arc just like so. And if we draw the outlines of a bunch of arcs stacked up on top of each other, we can draw some funky snail shell like thing. Remember, if any of this seemed too complicated or went too fast, don't just take my word for it. You've got all this code sitting on your computer so check it out and play with it yourself. In this exercise you'll set up a shape renderer and use it to draw a stick figure. At a minimum you'll need a circle for the head, and five lines for the torso, the two arms, and the two legs. Remember in order to set up a shape renderer you need to declare it, initialize it, and dispose of it. Then to actually use the shape renderer, you'll need to start a batch of the appropriate type, whether that's filled or lined, draw your shapes, and then end the batch. We don't really have step-by-step to-dos for this one since the aim is for you to remember the steps for setting up a shape renderer and be able to set one up on your own. Of course, the solution is still available if you run into anything confusing. Give it a try. So, to figure out how to do this, we can open up the 1.4.02 Solution-StickFigure project. Then if we go to the TODO pane we find the proper file to draw a stick figure. As you should be used to by now, we declare our ShapeRenderer, we initialize it, we set it up for disposal when the application example is disposed of, then we start a filled batch, we draw the head and we end the filled batch. Then we start another batch for the lines where we draw the torso, the legs and the arms. That's all there is to it. Before we dive into what an orthographic camera is, and how to work with it, let's see one in action. This demo creates a simple scene, which you can view through two different cameras. The first camera just displays an overview of the scene. But the second camera, the close up camera, you can move and zoom. Give it a try. So, once the demo's running, you can use the arrow keys to move the close up camera around the scene. Now here's the interesting bit, if you hit space, you can see the scene from the overview camera, along with a blue rectangle showing what the close up camera sees. You can zoom the close up camera using z to zoom in and x to zoom out. What's really happening, is we're reducing the portion of the scene that's visible to the close up camera. You can also change the viewport height using w and s. And the viewport width, using a and d. When the viewport is wide and short, the world looks super vertically stretched. When the viewport is tall and skinny, the world looks horizontally stretched. You can hit f to set the aspect ratio of the camera back to the aspect ratio of the screen. You can also rotate the camera using q and e. Be aware that very strange things happen when you rotate a camera that's super stretched. Finally, note that you can easily zoom the close-up camera out to the point where it can see more than the scene overview camera. So, no matter how deep we get into matrices and viewports and what not, remember that this is what cameras do, determine what portion of the world you can see. Now that we've seen what an orthographic camera can do for us, let's see how to create, manipulate, and apply one. In this demo, we've got a game world with a huge star, a tiny planet, and an itty bitty satellite. Let's see what this looks like, without using a camera. Using the default camera, we can just barely see the edge of the star. We can see just half the planet. And we can't even see the satellite. It's actually right here, but it's so small, it's not even one pixel wide. So, let's use an orthographic camera to zoom in on each one of these objects in turn. So, what is a camera? Well, camera holds on to two matrices. One matrix encodes the camera's position and orientation in the game world. For 2D games, this is usually kist a simple x, y pair, but for 3D games, say, a 3D flight simulator, the camera can hold the plane's 3D position, its pitch, its roll, and its yaw. The other matrix encodes how the camera translates positions in the world into positions on the screen. This includes how much perspective to include, that's fisheye lens versus telephoto lens. And how big an area on the screen the camera will ultimately draw to. To use a camera, we first need to declare and initialize it. Then there are two things we have to do down in the render callback. The first is calling camera.update. Whenever we adjust the properties of a camera, like its position, it needs to fold those changes into the matrices that define how it looks at the world. The easy way to ensure this happens is just to call update each frame. It's a fast operation, so no worries. The second thing we need to do is tell our shape renderer that we want to use our camera. We do this by setting the shape renderer's projection matrix to the camera's combined matrix. The combined matrix is the culmination of the camera's view and projection matrices. Yeah, there's a lot of matrices flying around. Basically, shapeRenderer doesn't have a notion of position in some larger world, so all it's got is a projection matrix. One more thing is we need to handle screen resizing correctly. The resize callback gets called right after create and any time the screen size changes. Which could be because a mobile device rotated, or because we're running the desktop app and the user is changing the window size by dragging around the corner. When the screen size changes, we need to make sure our camera is updated. If the camera thinks that the screen is smaller than it really is, shapes will be way bigger than we want them to be, and vice versa. This call setToOrtho updates the camera with the new screen size. The first argument is whether an increase in value of y should mean going down the screen and we don't want that to be true. All right, let's see what code it'll take in order to get the camera to zoom in on each of these objects in turn. To get our camera to zoom out so we can see the whole star, we need to set the camera's viewport size. So here we've set both the width and height of the viewport to be doubled the radius. So the star should fit comfortably in our camera. Note the distinction between these two lines, the setToOrtho call tells the camera how big a window we're using to look the world. The viewport size is how much of the world we are looking at. Then we set the camera's position to be the center of the star. Let's see what it looks like. Whoa, the star's all stretched out. Let's see if we can figure out why this happened. So we set the viewport width and height to be equal, but our window doesn't have equal width and height. It's wider than it is tall. Anticipating this occurrence, we already calculated the aspect ratio of the window up here. Now we can just set the camera's viewport width to be the aspect ratio times the viewport height. Let's try it now. Much better. I thought stars were supposed to be circles. Let's actually do one more thing and nudge our camera to the right a little bit, and now we can see both the entire star and the itty bitty planet next to it. Let's try zooming in on this planet next. So we've set the viewport height to be double the planet radius so the window should just contain the planet. Then we set the viewport width to be aspect ratio times the viewport height. That way the planet stays a circle. Finally, we just set the position of the camera to be the center of the planet. And there we go. We've apparently got a very heavily forested planet or something. All right, lets do this one more time. This time with the satellite. So, setting the viewport height and width should be pretty familiar, and then we set the position. Lets see what we've got so far. Cool, so we've located the satellite out in space, but looks like the satellite is rotating as it orbits or something like that. Let's match the rotation of our camera to the rotation of the satellite. So here we go. The satellite's rotation is contained in this constant, and then camera.rotate will rotate the camera by that number of degrees counterclockwise. Let's give it a try. Awesome, docking ports aligned. Now it's time for you to use an orthographic camera to zoom in on the portion of a game world. We've got a circle moving around in a figure eight and we'll create and apply an orthographic camera that perfectly contains the vertical range of motion while maintaining the aspect ratio of the world. Check out the to dos in the course code to get started and remember the solution code is always there if you need it. Handling your own orthographic camera is often necessary, but there's quite a lot of fuss involved with getting the aspect ratio right and in positioning your world on the screen. If you don't need to move your camera around in your game world, it's often easier to use a viewport to manage your camera. We've set up a little demo project to show off the various viewports. What we're doing is, we're drawing a little checkerboard that's 16 units wide by 9 units tall, which is intentionally not the same size as the window we're going to use to display this world. So here in create we've made an orthographic camera, and the first viewport we're going to explore is the ScreenViewport. The ScreenViewport doesn't care about the size of the world. It just sets the camera up for pixel for pixel drawing. This is great if you need that in particular, but it's not super useful for most games. Let's check out what it does. So our checkerboard is down here on the bottom left and it's 9 pixels tall and 16 pixels wide, and you can hardly see it all. Let's try another viewport that might be better for this task. Here we've switched over to a stretch viewport. StretchViewport makes the world exactly fit the screen, but it doesn't respect the aspect ratio of the world, so things might look stretched, either horizontally or vertically. Since our world is 16 units wide by 9 units tall, and the aspect ratio of this is squarer than that, that means our world gets stretched vertically or squashed horizontally, depends how you want to think about it. Now we've switched over to a FillViewport. FillViewport does respect the aspect ratio of the world, but it might clip some parts of the world in order to make that true. For instance, this world is now only 12 by 9, instead of 16 by 9. The extra is offscreen to the left and right. A FitViewport makes sure that the entire world is visible and at the correct aspect ratio. However, it does this by adding black bars at the top and bottom or left and right to pad out the rest of the window. This is also called Letter Boxing. It's what happens when you watch wide screen movies on old TVs. This is a great choice when the exact size of the game world is essential, but it can look bad on devices that have very different aspect ratios from what you intend. The last viewport type is the ExtendViewport. The ExtendViewport also ensures that the entire game world is visible and at the correct aspect ratio. It just makes the game world bigger in the smaller dimension in order to fill up the rest of the space. So if you remember from the ScreenViewport, we had this green apron all around. You can see it in this version because we're actually allowed to draw up here. Back when we were using the FitViewport, those black bars, we weren't allowed to draw anything out there at all. When it comes to making games that work across a whole range of devices with different aspect ratios, ExtendViewport is almost always the best choice, when you can get away with it. Remember, the ScreenViewport makes the size of the world match the size of the screen, pixel for pixel. StretchViewport makes the world fill the screen, regardless of aspect ratio. FillViewport also makes the world fill the screen, maintaining the aspect ratio but cutting off bits of the world. FitViewport fits the world inside the screen, adding black bars to pad out the extra space to maintain the aspect ratio. And finally, ExtendViewport makes the short axis of the world larger to fill the screen, maintaining the aspect ratio. Time for you to use a FitViewport to ensure that an entire game world is visible and at the correct aspect ratio. Check out the course code to get started. Lets put together what we've learned to draw a smiley face. We'll use ShapeRenderer to draw the circles and arcs, and we'll also use an orthographic camera and an ExtendViewPort to frame the scene. The tricky part is going to be drawing the mouth. Since we can't draw lines thicker than a single pixel without Open GL monkey business that doesn't work everywhere, making a thick line for the mouth is going to be hard. The trick is to draw two arcs. First, draw a black arc, and then you can draw a slightly smaller yellow arc. The portion of the black arc that isn't covered by the yellow arc becomes the mouth. All right, check out the course code to give it a try. One more topic before we finish up with drawing, and that's text. Text is actually a super complicated topic. So we're just going to do the minimum necessary to get some text on the screen. First thing, text in LibGDX is actually made of bitmaps. That means instead of describing the shape of the characters, we describe the actual pixels that make up the text. We'll discuss bitmaps and textures in more detail later on, but the short version is just that we use a SpriteBatch instead of a shape renderer. Everything else is almost identical. So in this demo, we'll create our SpriteBatch and we'll use just the default bitmap font. Then we'll set the scale so the font appears a little bit bigger and then we need to set the filter. Now texture filtering is a complicated topic all on it's own. We'll talk more about that later. But it's how we determine what a bitmap looks like when the bitmap gets drawn at a larger size than it was originally designed to be drawn at. This linear filter makes sure that the text doesn't look all pixellated when we draw it large. Sprite batches and fonts need to be disposed of, just like a ShapeRenderer. Finally down in renderer, we clear the screen just like normal. We begin a batch of the sprite batch just like with a shape renderer except there's no mode. Then to actually draw, we call draw on the font object passing in the batch, the text we want to draw and the position. Also remember to end your sprite batches. And there we go, we've got Text on the screen. In this exercise, you'll create a Word Cloud. Now we've created a lot of the infrastructure for you, but this is kind of a complicated exercise, so I wanted to walk you through it a bit. So we've already set up the SpriteBatch and the BitmapFont. And we've also created this array, Array words, where the words are a static inter class. If we jump down to the bottom of this file, we'll find the word class, and you see it has five member variables, the x and y position, The scale in which to draw the word, the color of the word, and then what letters are actually contained in the word. So, for each of these word objects, you need to set the font's scale. Set the font's tint and then, actually draw that word. All right, check out the to-dos in the course quota and let's see if you can draw a Word Cloud. Awesome work. In this level, you learned how to draw circles and how to manage multiple shape renderer batches. You then learned how to create and manage an orthographic camera. You use view ports of various types to make cameras easier. And finally you learned how to draw text. You're not quite done yet, though. I've got a couple more drawing challenges for you that will strain your brain. And, put your shape renderer, orthographic camera, and view port knowledge to the test. Let's do it. [SOUND] [BLANK_AUDIO] Usually, the painter's algorithm works out fine. Shapes drawn later on appear over top of shapes drawn earlier and that's the end of it. However, there's an interesting condition called cyclic overlap. It mostly comes up in 3D applications, but consider these three shapes. Red is partially underneath green, green is partially underneath blue, and blue is partially underneath red. How would you draw this? Check out the to-do's to get a closer look at this problem and see if you can add a hacky fix to get this to appear. Your final challenge should you choose to except it is to draw the Sierpinski Triangle. I offer no hints beyond the fact that shape render has a very convenient triangle function and that using a fit view port can simplify your life a lot. Good luck and check out the solution project if you get stuck. Last fractal, I promise. Frame rate is the key to making your game feel smooth and responsive. The faster you're able to update the screen, the smoother objects will move and the quicker they'll appear to react to collisions, bullets, input from the player and so on. A low frame rate, makes a game seem jerky and slow. The simplest game loop, gets input from the player, does some game calculation, then updates the screen. The problem is that updating the screen usually takes the most time, so time the games behavior to screen updates, tends to make the whole game feel sluggish. A better approach is to keep track of how long it takes to update the screen each time. Then use that value to predict how long it will take to render the next frame. Now, you can collect player input, then update the game world in a tight loop, perhaps a millisecond at a time, effectively fast forwarding the state of the game to that future point. In effect, this approach allows you to tie your game processing to a universal wall clock instead of how often the screen is updated. The result feels smoother because each frame is now a snapshot capturing the game state as it changes independent of screen updates. This is such a common practice that most pre-built game engines and development frameworks will handle it for you or make it very easy to implement yourself. So far, we've been drawing static images. But in a game, we want things to be flying all over the place. To make things move, we need to know how to keep track of time. We'll also learn more about the LibGDX game architecture, and how we can set up a game that has multiple different screens. Finally, we'll learn how to fake some very basic physics, so we can make objects move in a more realistic way. In order to create motion, we first need to be able to keep track of time. LibGDX provides a fantastic TimeUtils package to make this easy. There are two main methods of interest, TimeUtils.milis and TimeUtils.nanoTime. Let's say this is a timeline and this is right now. What TimeUtils.millis() gives you is the number of milliseconds between right now and January 1st 1970. This is great if you want to know what time it is, like the time on a wall clock, but it's not always the best choice for measuring time intervals. When games are rendered at 60 frames per second, individual milliseconds start to matter. So it's often best to use the more precise TimeUtil of nanoTime. nanoTime gives the time in nanoseconds. That's billionths of a second. But it doesn't have a definite reference time, so if this is right now, TimeUtils.nanoTime might give you the number of nanoseconds since like sometime in 2005, or it actually might be a negative number of nanoseconds from now until sometime in the future. However, what nanoTime does allow us to do is to measure time intervals. So our general procedure is to save the time that our game was created, and then all future times can be measured with respect to that creation time. Let's check it out. So, let's use these TimeUtils tools to create simple movement. Just a ball moving around in a circle. The first thing we need to do, is set up some constants that determine what the movement of the ball looks like, including how many seconds the ball should take to go all the way through one cycle. Then we need to store the time at which the application adapter was created by declaring a long called initialTime. And then setting equal it to TimeUtils.nanoTime in the create callback. Now, down in the renderer callback, we can figure out how long it's been since the game started running by subtracting the initial time from the current value of TimeUtils.nanoTime. This gives the number of nanoseconds that the game has been running. But seconds would be a lot more convenient. LibGDX provides a very nice MathUtils.nanoToSec constant to help with that conversion. Now we need to figure out where in the cycle we're at. If we take the elapsedSeconds and divide it by the period, we get the number of elapsed periods since the game started running. We can then take the modulis with 1 to determine what fractional part of a cycle has elapsed. So we now have a number that counts up from 0 to 1 and then resets back to 0. And we need to map that interval to a position on a circle. Don't suppose you remember the parametric equation on a circle? You can check out the link in the instructor notes for a short refresher on some trigonometry. To figure out the x position of our ball, we take the center point of the world, and then we add the movement radius times the cosine of the cycle position times two Pi. For the y position it's almost identical, except we're taking the sine instead of the cosine. And there we go, we've achieved circular movement. Even with something so simple as balls moving in circles, we can make some surprisingly beautiful patterns. Check out what we can do with 20 balls, each moving at a different harmonic speed. [MUSIC] Try putting together a simplified version of the circular motion demo. Instead of circular motion, you'll just create reciprocating motion or back and forth motion. Remember to check out the solution project if you run into anything confusing. Check out the to-dos in the starter code to get started. So far we've been making games that only display one logical thing to the user. But real games have lots of different sorts of stuff to display. There's the game world itself, but you might also have menus, settings, inventory screens, and so on. You could accomplish this by putting switch statements everywhere, but there's a better way. Libgdx provides a screen protocol and an implementation of application listener called game, which delegates all the application listener callbacks to an implementation of screen. Then to change from the game world to a menu, you just have to call set screen on your game. Let's check it out. All right, let's use these games and screens to create a game with multiple different screens it can display. Instead of a ApplicationAdapter here, we're using a Game. If we right click on Game, and say Go To > Declaration, we can jump into the source code of the Game class inside LibGDX. As we see, Game implements ApplicationListener. It seems that the Game class has a screen member variable, and then for each one of the ApplicationListener callbacks, if it has a screen it then delegates that callback to the screen. Here we've declared two screens, one of which displays the number of frames displayed per second. And the other display is the number of seconds between the current frame and the last one. To set the active screen, we just need to call set screen on our game. Let's check out delta screen. Screens are very similar to application listeners with a couple differences. Instead of create, screens get a show call. Screens can receive a hide call when another screen becomes active and the render call received by a screen includes this argument called delta. The argument delta is the number of seconds after the previous frame that this frame is expected to hit the screen. In a normal game running at 60 frames per second, this will be approximately 0.0167 seconds or 16.7 milliseconds. However if your game is running on old hardware or is just trying to draw way too much stuff you may end up with a delta that's larger. In this screen we've created a bitmap font and a sprite batch, and we're just displaying the delta that's been passed into the rendered callback. Also we've included logging on all of the life cycle methods so that we can investigate what happens when we switch screens. Now, let's go back to checking out FPS Screens. In this screen we're doing almost the exact same thing as in delta screen, except instead of displaying delta, we're displaying number of frames per second which we can get using this handy Gdx graphics get frames per second column. All right, let's try running this game and see how the game slash screen life cycle works. So when we start the app, first the game is created, and then we set the actor screen to be delta screen. So delta screen was shown and then resized. Now we set this up so that we can hit space to switch between the two screens, so let's do that now. When we switch the screens, delta screen had hide called. Then FPS screen had show called, and it was resized. Also in that process I accidentally clicked into and out of the screen, so pause was called and then resume was called on the screen. Let's see what happens when we close out of the game. When we close out of the game the active screen is first paused, then dispose is called on the game which automatically calls hide on the screen that was active. >From here on out we really won't be using ApplicationAdapters anymore. We'll just be using games and screens. So, it's time for you to learn how to transition from using an ApplicationAdapter to a game. We've created a simple demo product that's just displaying some text. You'll need to create a screen. Move that drawing from the application adapter to the screen. Convert the application adapter to a game. Call setScreen on the game with your new screen. And, you should see that everything still works now with the drawing happening in the screen, not in the application adapter. In this exercise we'll get more practice drawing from a screen. And this time we'll use the value of delta for something useful, in this case to draw the frames per second. If delta is the number of seconds between frames, then one over delta is equal to the frames per second. There is a lot of tasks left up to you to do this time. You're not expected to be able to remember all the little details from memory. Check out previous exercises and demos, and the solution code, as you need to. Previously, we have just been setting the position of objects based on how much time has elapsed. Basically, the x position is some function of time, and the y position is some other function of time. More interesting, however, is to set the position of objects based on their position in the previous frame using their velocity. If we just do that, however, we just get motion at a constant speed in a straight line. To get really interesting motion, we need to take into account acceleration as well. Acceleration is the change in velocity over time. Let's take the simple case of a falling object. Let's say we've got some object in freefall. And last frame, its position was x and y, and its velocity was vX and vY. To figure out where it will be this frame, we first need to update its velocity. vX will be unchanged since gravity is only acting vertically. To find its new vertical velocity, we need to add the elapsed time of this frame, multiply it by the acceleration due to gravity. We can then use these new velocities to update the position of the following object. In the next exercise, we'll see these equations in action. Consider these two games. Both boulders are falling from the top of the screen. But on the left they're not moving very realistically. They just move at a constant velocity down from the top. On the right however the boulders start out moving slow and they get faster and faster as they move to the bottom, just like a real falling object would. Well, it's up to you to take the game on the left and turn it into the game on the right. Check out the to-dos in the course code and see if you can make some realistic falling objects. In this exercise, you'll create a bouncing ball screen saver, just like the kind I'm sure you spent hours staring at, hoping the ball would hit the corner of the screen. Right now everything's in place for you to finish up the screen saver. But the ball doesn't actually move yet, and it's doesn't bounce off the top or bottom of the screen, it'll just keep going forever. So it's up for you to fix it. Check out the to-dos to get started. [SOUND] [BLANK_AUDIO] In this level, we learned how to make things move. First, by just keeping track of how much time had passed. And then, by updating the world based on how much time passed between frames. We also learned how we can make a game that can easily switch between different screens. So, this has been fun and all, but everything we've made so far has pretty much run on autopilot. So in the next level, we'll tackle interaction. We'll learn how to detect and respond to all sorts of inputs, like key presses, touches and device orientation. Now that we know how to make stuff move, let's make it interactive. There are a ton of different ways to interact with libGDX games, key presses, your mouse, touches, and even device orientation and acceleration. In this level we'll learn to detect user input of all kinds, and respond to it in our games. Let's get started. The simplest form of input is just key presses. They offer the user the tightest control over the game. And even if you're building a mobile game where key presses aren't relevant, they're still incredibly convenient for debugging. There are a couple different things you might want to know about a key press. Say you're building a platformer, and you want to control the left or right movement of your character using the arrow keys. Each frame, you check if the left or the right key is pressed, and then move the character in the appropriate direction. On the other hand, say you want the character to fire a grappling hook when the space bar is pressed. In this case, you don't actually want to check the state of the space bar every frame, you're only interested in the moment the key is pressed. If the user holds down the space bar, you don't care. We have two different approaches, one where we want to know the state of the inputs every frame, and one where we want to be notified when certain things happen. The former approach is called pulling and the latter approach is known as event based input. We'll start with pulling as it's a bit simpler but we'll get to even based input later on in the level. To explore these various input methods, we'll use the same test bed throughout this lesson, which is based on the screen saver we built last level. Now, instead of the ball just moving in a straight line forever, we'll control its movement with key presses, touches, and the accelerometer. Let's explore the test bed a bit. First, our application listener is called InputTestBed, and it extends Game. The only thing we have to do in this file is set the game screen, which we set to a new instance of BallScreen. Let's check that out next. BallScreen is responsible for setting up a place to draw, and then delegates all the logic about what the ball actually does to this BouncingBall class. BallScreen extends ScreenAdapter which is a convenient implementation of the screen interface. ScreenAdapter provides blank implementations of all the screens required methods, which means we can just override the ones that we're interested in. There's a few new things here, the first of which is this AutoShapeType. When ShapeRenderer is in AutoShapeType mode, that means we can change shape types in the middle of a batch. This is incredibly convenient when you are passing your shape render into other objects to use for drawing. Note we use an extend viewport to make the shortest access of the world equal to WORLD_SIZE. Also note that every time the window is resized, we just reset the ball. Then down here in render, we do all the normal stuff. Applying the viewport, clearing the screen, setting the ProjectionMatrix. Then we tell the ball to update itself, we start a shape renderer batch, and we tell the ball to go ahead and draw itself using our shape renderer. Let's check out what the ball is doing. So this BouncingBall class is quite long and I encourage you to just open up this demo in the course code and check it out for yourself. The behavior of this ball should be pretty familiar from the screen saver example. There are two new things, drag and the periodic kicks that the ball receives to show off that drag. Down here in update If its been sufficiently long since we last gave the ball a kick, then we go ahead and give the ball a new kick. And here is where we apply drag. Every frame the velocity is reduced by an amount proportional to the current velocity. Let's see this all in action. So, we see we've got a little red ball that occasionally gets kicked in a random direction. Then, it slowly comes to a stop. It kind of looks like an air hockey table, and if we resize it, it just resets itself to the middle. All right, so this is fun, but it's not interactive yet. Well, let's fix that. Let's our first bit of interactivity to this demo. LibGDX provides a very simple way to check if a key is pressed using Gdx.input.isKeyPressed and passing in a constant from the keys class like Keys.Z. If we do this check every frame, then we can make some change to the world based on this input. In this demo the ball radius is determined by multiplying a radiusMultiplier by a BASE_RADIUS. So we can see, if z is pressed, we grow the radiusMultiplier by the RADIUS_GROWTH_RATE. If x is pressed, then the radiusMultiplier is shrunk by the RADIUS_GROWTH_RATE. Also, we check that the radiusMultiplier doesn't go below some minimum value. That way, we don't end up with invisible balls of negative radius. Let's give this a try. So, here's our demo again. And now, if we hold z, the ball grows bigger and bigger and bigger. And if we hold x, the ball shrinks and shrinks and shrinks until it's just a point. In this exercise, we've taken out the random kicks the ball is receiving, so that you can make the ball move around in response to the arrow keys. We've added two new constants, acceleration and max speed. If, say, the left arrow key is pressed, what we want to do is subtract from the velocity in the x-direction the acceleration times the frame delta. If the right arrow key is pressed, we want to add the acceleration times the frame delta to the x velocity, similarly with the y velocity. When we're done changing the philosophy, we also want to cap how fast the ball is going with a call to the clamp method on vector two. While there's no physically inspired reason to do this, and the drag in the system does a good job of slowing the ball down, anyway. Allowing arbitrarily high velocities in your game often sets you up for some very strange behavior down the road, like, things teleporting through walls and so on. All right, time for you to add arrow key movement to a game. As usual, the real story's in the course code. Check out the to-dos to get started. So far we've been working with user input by polling for it each frame. The other approach to user input, is an event based approach, where we ask to be notified when certain things happen. To do this in LibGDX, we need to create an implementation of the input processor interface and tell LibGDX to send events our way. Let's check out how we've done that in this demo. We've now declared our BouncingBall class to extend InputAdapter. InputAdapter, just like ApplicationAdapter and ScreenAdapter, is a convenience implementation of input processor. One of the call back methods of InputProcessor is keyDown, which is called any time a key is pressed. The argument is the keycode of the key that was just pressed. In this case, we're just reusing that randomKick function, and we'll fire it any time the space bar is pressed. The return value of all InputProcessor methods is a boolean signifying whether the input event was handled. This becomes relevant when you're dealing with a more complex game, where there may be multiple classes responding to input events. In this case, this is the only class that cares about input events, so we can go ahead and say that we dealt with the event. There's one more thing we need to do before this works and that is we need to tell LibGDX that this class is interested in receiving input events. The best place to do that, is back in BallScreen, where we used GDX.input.set.InputProcessor, passing in our new ball object. So here's our ball again. And we can grow it and shrink it, just like we could before. And we can also move it around, just like we could before. But now, if we hit spac ebar, it moves. And if we hold down space bar, it doesn't continue to move. It only receives that event when the space bar is initially pressed. Remember playing with your virtual ball and it's just growing out of control and flying all over the place and receiving random kicks? You ever just want to go back to the simple days when it was a normal sized ball sitting in the middle of the screen? Well, in this exercise, you're going to add a Reset button. Go ahead and check out the to-do's in the course code to make the R key into a Reset button for our ball. Input processor provides three call backs for dealing with touches and clicks. Touches and clicks are actually handled in the same way and are just referred to as touches. Actually, this program I'm drawing on uses a very similar system to determine when to draw the lines. For instance, as my pen touches this screen, a touched down signal is received. That means it's time to start drawing a line. As I move the pen the program is continually receiving touch dragged notifications, meaning that it's time to draw a little bit more of the line. Finally, when I reach the end of my line and I remove the pen, there's a touch up call that says alright stop drawing the line now. Note that the touch or click coordinates provided in these call backs is always provided in terms of screen coordinates. If you want to get the position of a touch in your world coordinates, you will need to convert from screen to world coordinates. Let's check out how to do that. In this demo, we allow the user to move the ball around by flicking it. Here's how we define a flick. If a touch or click starts inside the ball, then we've started a flick. When the touch or click is released, then we give the ball some velocity, proportional to the vector between where the flick started and where it ended. Let's check out the demo in the course code to see how this is done. So here we are inside our BouncingBall class, and we've overridden the touchDown method from InputProcessor. The first thing we need to do, is to translate the point that the user touched from screen coordinates to world coordinates. Since the viewport handles the projection from world coordinates to screen coordinates, it also has an unproject method that does the opposite. Next, we use the dst method on Vector2, to see if the distance between the position of the ball and the worldClick is less than the radius of the ball. If the touch is inside the radius, then we start a flick. And then we save off the coordinates of the touch. We've also overridden touchUp. When a touch is released, if we were in the middle of flicking a ball, we unset that flag. We unproject to the location where the touch was released from screen coordinates to world coordinates. We compute vector between where the flick started to where the flick ended, and then we add that vector to the velocity of the ball, multiplied by this FLICK_MULTIPLIER. In this exercise, you'll set up the ball to follow your finger or your cursor around the screen. Check out the to-do's to get started. This is a really tricky exercise, so don't forget the solution code is always available. The accelerometer is an incredibly flexible and intuitive way for your user to interact with your game. The accelerometer reports the phone's acceleration in meters per second squared. So if the phone is stationary, the only acceleration it's experiencing is the acceleration due to gravity, which is equal to about 9.8 meters per second squared. Does this sound at all familiar from physics class? Now regardless of the orientation used by your game, the accelerometer data is reported as though the phone is in portrait orientation, with the positive z-axis coming out of the screen. That means if the z-axis of the accelerometer is reading about 9.8, the phone is flat on its back. If the z axis is reading negative 9.8, then the phone is resting on it's face. If the y axis reads 9.8 then the phone is upright in the portrait orientation. Note we have tilted the phone a little bit and the y axis is reading positive. If we tilt the phone this way a little bit, now the x axis is reading positive. Libgdx allows you to pull for accelerometer readings using gdx input get accelerometer x, y and z. We can compute the total acceleration using the good old Pythagorean theorem. Down here we're drawing those red bars you saw, and this is actually the horizontal bar. Notice the x position of the end of that bar is being determined by the negative y axis. That's because we're looking at this game in landscape mode. And all of the accelerometer readings are reported as though the phone was in portrait mode. Here is the vertical line. And the end of that line is determined by the positive x axis. You'll get a hold of this quickly enough. But if everything is sliding sideways in your game, this is probably why. In this demo, you'll use accelerometer readings to create a bubble level, like the kind you'd use in carpentry to make sure that a board is flat. This exercise is very similar to the previous demo, where we drew lines representing the magnitude of the acceleration in the various axis. In this case, however, we'll combine those magnitudes in a single vector and we'll draw a bubble there. First, we'll draw a circle centered in the middle of the world with a radius equal to a quarter of the world's size. We want to scale the movement of the bubble such that when the phone is vertical, the bubble will just be resting on this line. So obviously you can't see it when the phone is vertical, but as I tilt the phone, the bubble will be approaching that red line. Then we'll just draw a little green bubble right in the middle that just barely holds the bubble when the phone is level. All right, give the bubble level a try. This is another tough one. So feel free to refer back to the previous demo or the solution code. [SOUND] [BLANK_AUDIO] In this exercise, you'll allow the user to move the ball simply by tilting their phone. You'll first need to get the accelerometer readings, compensating for the fact that the readings assume the phone is in portrait orientation. Then you'll convert the accelerometer readings into the actual acceleration to apply to the ball, taking into account the acceleration and accelerometer sensitivity constants. Finally, you'll apply that acceleration to the ball's velocity. Give Accelerometer Movement a try. Check out the to-dos in the course code to get started. Awesome work incorporating user input into your game. In this level, you learned how to pull for key presses and accelerometer readings as well as how to create an input processor to listen for incoming events like touches. Now that we've covered a drawing, movement and input, it's time to create some actual game play. In the next level, we'll start working on our first real game. See you there. The rise of mobile platforms revolutionized gaming in more ways than one. Not only did it put a powerful game device in everyone's pocket, it also introduced two major technological improvements to the way we interact with computers and games. Touch and orientation detection. Touch, including multi touch and gestures, can make game controls feel natural and totally seamless. They allow you to provide a direct physical connection to your game. If it's done right, it can make all the difference to the feel in gameplay. Games like Angry Birds and Fruit Ninja showed everyone what can be accomplished with this funky new input method. And there's really no question that touch made those games successful. It's hard to imagine either game without it. Accelerometers allow for a second new form of input, orientation detection. Knowing how the phone or tablet is positioned or moving through space, opens up all kinds of opportunities to make your game more immersive. Whether it's a driving game you have to steer, or an augmented reality app, the accelerometer gives you control options that have really never been available on PC. You've learned so much, drawing, view port management, movement, user input. And now it's time to build a real game from scratch. Icicles is a game where the player first selects a difficulty. And then can use the arrow keys or phone accelerometer to move their character left and right to dodge the falling icicles. This seems pretty easy. So we can tap the screen again to go back to the difficulty, select screen and select a harder difficulty. Wow, okay, that's a lot of icicles, oh, oh, no. Oh, this is a lot harder. So you can start building your own games once you're done with this course. Well, start this level using the LBGTX project setup utility to create a totally fresh project. Let's go. When you want to create a fresh libGDX Project, you can actually use the super-convenient libGDX Project Setup utility. We actually included it at the root of the course code. It's called gdx-setup.jar. If you want to download the setup app for yourself, you can just search for libgdx. This first result's the one you want. Select Download and select Download Setup App. If you get this alert saying that gdx-setup can't be opened because it's buy an unidentified developer, you can fix that by opening up your System Preferences, going to Security and Privacy, and checking the radio button for Allow apps downloaded from Anywhere. Now the setup app needs some information to configure our new project. We'll give it the name Icicles. We use the package com.udacity.gamedev.icicles. We'll name the game class IciclesGame. Destination is where the project setup utility will crate your new project, we'll just say Desktop/Icicles. Next, the project set up utility needs the path of your Android software development kit. If you don't remember where that is you can open up the Preferences pane of Android Studio, search for sdk and then up in this box here you'll find the path of your SDK. We'll just copy that and we'll paste it into the libGDX Project Setup utility. Next you can select what version of libGDX you'd like to use. You'll almost always just want to use the most recent. Then you need to decide what subprojects you want to include. Unless you're using some particular extension that doesn't support all the different subprojects, you should probably just include them all. It's much easier to remove a platform you don't plan to support later, than it is to add in a new platform. Finally, you can include various extensions. Box2D is included by default. It's a super powerful 2D physics engine and we'll end up using that in a later course. But uncheck that for now. Finally, hit Generate. 42 seconds later, we have a successful build. Let's go load up our new project. As usual, we open up Android Studio and select Import Project. We can hit this button to jump to the desktop. Here's the Icicles folder we just created. Now it looks like we're all loaded up. Let's open up the Terminal. And we can run the desktop run task to see what we've got. [LAUGH] All right, looks like the default project just comes with a red background and the Bad Logic Games logo. Awesome, now you can create whatever new projects you want and you don't have to rely on our starter code in the course repository. Time for you to use the libGDX project set up utility to create the blank project that we'll turn into Icicles. Check out the instructions in the course code. Let's talk a bit about the Icicles project architecture. By which I mean the classes that will make up Icicles. First, we have IciclesGame, which is our application listener, the entry point into our code. IciclesGame will delegate its application listener callbacks to one of two screens. DifficultyScreen,, which allows the user to select the difficulty of a game. And IcicleScreen, which contains the actual gameplay. IciclesScreen uses two other classes to hold the state of the game world. There's Player, which handles the position of the little stick figure down at the bottom of the screen and also manages user input. And then, there's Icicles, which manages the position of all the icicles. Icicles itself, is basically, a collection of a bunch of icicle objects. Finally, we'll be very careful to keep all constants in their own class. There's two reasons for this. The first is that when constants are spread all over the place, it becomes incredibly frustrating to find the number that you want to tweak. If you want to change, for instance, how fast the icicles drop, you might need to drill down into IciclesGame, and then go find an IciclesScreen, and maybe it's in Icicles, maybe it's in the Icicle singular class. Who knows where it is? We'll just keep all of those constants in their own class. Even more important, is the fact that when you develop games in a professional context, you're often building a platform that allows artists and designers to easily slot in their content. You need to design your game in such a way that your game designer can add a new weapon, or change some balance easily. Or your artist can swap out some art assets, all without needing your help. Rigorously using a constants class is a baby step in this direction. With the icicles project created, it's time to stub out all the classes that we'll be using to build up icicles. Check out the to-dos in the course code to get started. With our stubclasses in place, build out the drawing infrastructure so that you can draw the first icicle of winter. Check out the to dos in the course code to get started. We've achieved first light or first ice, whatever. Now it's time to draw our player. I hope you remember the stick figure exercise from back in level one dash four. Check out the to dos in the course code to allow the player object to draw itself. [SOUND] [BLANK_AUDIO] The player needs to be able to dodge the icicles, so let's move the player using the arrow keys. This should be familiar from the exercises in level 1-6. Remember to make sure that the player can't escape the screen. Check out the TODOs in the course code to set up arrow key controls. Arrow keys are great and all, but this is supposed to be a mobile game. Let's move the player using the device accelerometer as well. Check out the to-dos in the course code to set up accelerometer controls. Our character is all set up to dodge stuff, so let's give them something to dodge. It's time to add in the icicles, much like the falling boulders back from level 1-5. Check out the to-do's in the course code to start the avalanche. [SOUND] [BLANK_AUDIO] If you run the game for long enough, you'll notice it start to slow way down. That's because we never get rid of the icicles that the player has already dodged. They just keep falling away below the bottom of the screen. Let's add some logic to remove icicles as soon as they're no longer visible. With a simple change, we can make sure that the game keeps running at a silky smooth 60 frames per second. No matter how long we let it run. The trick to removing the stale icicles is that we want to remove elements from an array while we're iterating over it. Thankfully, libGDX provides the incredibly convenient DelayedRemovalArray. Check out the to-dos in the course code to get started. Wow, that's a lot of progress. First, we set up a new project and then set up the game architecture. We created the player, added two ways to control the players movement and added the eponymous icicles. We also learned how to use a fancy data structure to clean up icicles we no longer need. In the next and final level we'll detect when the player runs into an icicle and add a head-up display for the player's score. We'll even add a whole new difficulty select screen. See you there. When you first start out, having never created a game before, it feels like there's a bunch of stuff you don't know, you're not doing right, it's not working out, but games are really like other forms of art. You use the skills you have to create something for yourself, and then you decide when and if you want to share it with others. Some people are comfortable putting their raw work in progress right out there. Others work privately for years before publishing their first game. As you learn more about how to make games and you get better at it. The games you create just naturally tend to become more sophisticated. Maybe you start with really rudimentary bad guys, but then you figure out how to do AI or pathfinding. Or maybe at the beginning, you do all your own artwork, even though you're not really an artist. While later on, you might collaborate with someone who really knows what they're doing and can contribute amazing art direction to your project. But hey there's nothing wrong with program work. Regardless of how big or complex though the best games you'll ever write are the ones that you think are fun the play. And you can make a fun game no matter how little experience you have so don't get too hung up on doing it the right way or being an expert on everything related to game development. It's more important that you just keep building games. You'll learn what you need to know as you go along, and eventually it will all make perfect sense. In the last level, we set up our player and added the arrow key and accelerometer controls. Then we added the icicles. I hope you've been having fun with the game already, but you kind of have to use the honor system to keep track of when you've been hit. In this level, we'll add collision detection, so you know when the player's been hit by an icicle. And we'll add a head-up display to keep track of how many icicles you've dodged. Finally, we'll add multiple difficulty levels, and a whole new screen, to allow the user to change the difficulty level on the fly. Let's dig in. Let's reset the icicles when the player gets hit in their big, circular head. Like this. It's a little tricky to check for collisions between a circle and a triangle so, we'll just check for collisions between the point of the icicle and the player's head. Check out the to-dos in the course code to set up icicle/head collision detection. Now that we know when the player gets hit by an icicle, let's start keeping score. We'll say that the players' score is the number of icicles that fall off the screen without hitting them. Right now though, we don't have a way to tell the user what their score is. Let's fix that by adding a head up display or HUD. That's really just a fancy way of saying, let's throw some text into the corners of the screen showing the score. Check out the to-do's in the course code to add the HUD. You're probably getting pretty good at icicles by now. So, let's turn down the heat and add way more icicles. Actually, let's add a difficulty enum/gs that we can specify a variety of icicle spawn rates. Check out the to-do's in the course code to add difficulty levels. Now that we can change the difficulty of the game, let's allow users to change the difficulty on the fly. To do this, we need to add a new screen to our game, and to allow users to switch between these two screens. Each of these circles acts as a button, so we can select cold to play an easy game. We can tap again to go back to the difficulty select screen, and select Colder for medium difficulty, or Coldest for hard difficulty. This last task is pretty tricky but I am sure you can pull it off. Follow the to-dos in the course code to add the difficulty select screen. Amazing work. You've polished Icicles into a real playable game, adding scores, a HUD, and a difficultly select screen. Do you realize how much you've accomplished? Icicles is a simple game, but you coded everything from the ground up. You know Icicles better than the stickers on the back of your laptop. You've had to pay attention to tiny details, like how fast the icicles drop and how big the font in the HUD should be. This kind of line by line, pixel perfect mastery, is what it takes to build something new and awesome. And you've proved you can do it. I can't wait to see what you build next. [SOUND] [BLANK_AUDIO] A computer game is like any other creative endeavor, it takes a lot of effort and it's hard to know exactly when you're finished. You may have heard of the 80/20 rule for software development, that 80% of the effort goes to completing the last 20% of the features. That's true for games too, to an extent, but there's another factor. Good games have more than just lots of features, they also need good gameplay. While Future Creep blows a lot of development schedules, with games, it's less a matter of adding features and more about making sure the features are tuned so the game is actually fun. In a way, it's like painting or writing. You're always tempted to tweak some character stat or rearrange those two sentences. Does this change make things clearer? Do I need to rethink how I present this piece? Games aren't like other software. They're not necessarily function driven, right? They're meant to entertain and engage and these are fundamentally subjective goals. So, you may find yourself near the end of a game project, making less and less progress towards the finish line. Don't be surprised and don't let it discourage you. You're doing what every creative person on the planet does, which is second guess yourself and tweak and edit and revisit and change. And just like those creative people, you're going to eventually decide you're satisfied with the final product. And after all that work, there's nothing quite like the feeling of actually releasing your game.