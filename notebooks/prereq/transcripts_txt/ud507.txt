Hi and welcome to class. I'm here with Jonathan and Ryan of academy which is an immersive program for students to learn all about data science. We're super excited to teach you guys about data visualization and we want to kick off this class with one simple question. So Jonathan, Ryan, what is data visualization? Great question, Chris. To me data visualization is about conveying a story or an idea as efficiently as possible. It's often said that a picture is worth 1,000 words and I think data visualization works the same way. Data scientists used data visualisation every day to explore patterns in their data and to ultimately convey their results. So we're super excited to share some of what we teach our students with you today. Cool. And Jonathan, what about you? What do you think about data visualization? Yeah, so I think the title of Edward Tufte's classic book, The Visual Display of Quantitative Information actually get's at a core of what many people think of as data visualization. Simply, how best to represent visually some underlying data using things like color, size, shape to convey some information or some insight to their audience and their reader. And I think it actually goes a little bit further than that incorporating storytelling and narrative elements, like Ryan mentioned, to let the author of data visualization tell some interesting insight they've discovered on their own and they want to share it with their audience. Interesting, thanks for sharing that guys. In trying to define data visualization, I consulted some experts to learn more about the field. Here's what they had to say. Hi everyone. I'm here with Scott Murray. Scott, could you introduce yourself? Sure. I'm an assistant professor here at the University of San Francisco where I teach in the design program. I teach some of our intro classes, but I also teach interaction design and information visualization. And I'm author of the book Interactive Data Visualization for the Web An Introduction to Designing with D3. So, Scott, what is data visualization? Well there's obviously a lot of different possible answers to that. But I like to think about data visualization as mapping. Not sort of making geographic maps, like traditionally how we think about maps. But mapping values to visuals. So teach a class on information visualization, it's, it's sort of about information broadly, but when we're talking about data visualization, I think of data as being kind of structured information. So if you have a spreadsheet, you have rows and columns, you have sort of information that's not just loosey goosey, but it's organized in some sort of structured way. So the visualization part is taking that data and figuring out ways to translate that into visuals that are more readily understood. So instead of reading these columns of numbers, we can look at you know, these pictures of bars, or lines, or shapes, or whatever, different colors. Okay, great. Hi everyone. I'm here with Cole Nussbaumer, who's a blogger with storytelling with data. She's here to share some insights about data visualization, and share some tips about how you can get started in the field. So Cole, first tell us, what is data visualization? So for me data visualization is about turning numbers into pictures and into stories. There's something about making data visual that allows us to explore and understand the data in a different way. Our visual system is actually really fast at processing information. So good data visualization can lend itself to this sort of ha moment of understanding. Great. What do you think are some of the best qualities of, good data visualization. So for me, it definitely depends on the purpose of the data visualization. I tend to draw a distinction between the exploratory and the explanatory. Hm. Where exploratory you're really trying to get a sense of wh, what the data is, what it can tell you and, it's a process of turning over maybe 100 different rocks to try to find those, one or two interesting nuggets. Then once you've found the interesting nuggets you're in the explanatory space of wanting to then communicate those things to somebody else. So when it comes to effective data visualization on the exploratory side, it's about allowing your users to be able to connect things in interesting ways and look at data from different angles. In an unbiased and unleading way. On the explanatory side which is where I spend most of the time in my work teaching and writing, I typically cover five key lessons for success. Hm. So the first is having a really robust understanding of the context. Who your audience is and what they need to know or do before you really even start thinking about how you're going to show the data. Hm. Then when it comes to showing the data, the second lesson is around choosing an appropriate type of visual. So you want to think really about what is it you want your audience to do with the information, and what sort of graph or other visual types are going to allow them to do that in the most easy, straightforward fashion? Third lesson, is around clutter. Getting comfortable identifying and eliminating those things that aren't adding informative value to our visuals. And cutting those. Doing so decreases cognitive load, and also causes our data to just stand out more. And when it comes to our data standing out more, the fourth lesson is around, drawing your audience's attention to where you want them to pay it. So using color, and size, and placement on page. Strategically as indicators to your audience that say hey, this is most important, look here first. Or this is next most important. Pay attention here next. And so on and so forth. And the final lesson is around story. For me the most successful explanatory data visualizations, make themselves a pivotal point in a story or a narrative that's being told. Hm. Before I show you the next part of my interview with Cole, I'd like you to read about a blog post that we're going to discuss. You can find a link to that blog post in the instructor notes. This post was shared by Andy Kriebel, a data visualization guru over at Facebook. He's got an interesting blog named VizWiz and he's also got a really funny quote on his main page. We'll talk more about why this is true towards the end of the course, but I just wanted to show you this humorous quote. For now, what I would like you to do, is to read through each of these tabs by clicking on the Next button. In each of these panels, Alberto Cairo is going to walk you through the design process for creating data visualizations. He lays out how he created the graphic for the cover of his book. In the final tab, you'll actually get to see that graphic, and I really want you to take some time to play around with the final graphic that he arrives at, and then, answer these next questions. What's the average percentage of obese people in all the states? Which state has the largest percentage of its population that obtained a Bachelor's degree or more? Enter that two letter state abbreviation here. And then finally, do more states have a majority of obese people or educated people? Choose one of these. The average percentage of obese people in all states is 27%. With the help of some interactivity on this graphic, I can hover over this black middle line and see that. Here's the figure. For the second question, we were looking for DC, or the District of Columbia. This question was a bit easier to answer. We can determine these rankings by looking at the state that's on the left side here. So if I just hover over, this would be the least educated state by population, West Virginia. The most educated would be up here, the District of Columbia. And finally, most states have higher percentages of obese people. This one is harder to notice from the graph, but it's recognizable from the color of the lines. Looking at our plot, we can tell that slightly more lines are red rather than blue. So, slightly more states have larger pair of percentages of obese people, compared to percentages of people with higher educations. And in terms of narratives and stories, do you have any examples of a visualization where you think this was a great story, this told a really amazing story? Yeah, one that struck me relatively recently is the slope graph that's on the cover of Alberto Cairo's book. So here what we've got plotted is, on the left hand side, the percent of higher educated population by state. And then on the right hand side, the percent obese again by state. And then a given state's connected by the line. Which allows you to see relatively quickly the sort of inverse relationship here across the blue states you know, positive relationship here in the red states. And can allow you to really in a straightforward manner without really having to explain too much about it get an understanding and pick out interesting things, and again, start to form that story or narrative. This was the, actually, the first time I encountered a slope graph, or at least the first time that one stuck with me. And I found it inspiring because there are actually a lot of different use cases for graphs like this. Which I hadn't really anticipated. because you're really only plotting two data points, right? Really. Yeah. One way is you know, to look at things over time, and again, with only two data points you think that's not that interesting. But depending on your data it can be. Or also the comparison of groups. so, for example here in this little graph, I'm plotting feedback from employees' survey. Where on the left hand side, we have the percent favorable you know, a summary metric for the survey for the overall company. And on the right hand side, for a given team. This can be your engineering organization, for example. And you can see really quickly a whole lot of things, right? Right. So, on the left hand side you get the absolute values, you get the relative rank ordering of the different dimensions. You get those things on the right hand side as well. And then via the slope of the lines here, you get the percent difference between the groups without ever having to explain what a percent difference is. So it's just a really efficient form of communication for the right circumstance. Yeah, that's great. When I look at this graph, one of my key takeaways is this. When I look at this graph, one of my takeaways is just sort of, just looking at the, the slopes and I can see that, you know, five of the seven categories are doing really well. And so, the team's doing really well in those. Yeah. Compared to the company, let's say overall. But, for two of them. Looks like management and career development not so much. so, I think it's really interesting how you mention that there's so few data points, yet the rankings are there and it's really easy to see sort of like how the team is doing in comparison to the company. Yeah, there's actually a whole lot of information. Yeah. In a relatively straightforward manner. Yeah. Hi. I'm here with Jonathan and Ryan again of Zipfian Academy. And I want to take a step back before we dive too much into detail about data visualization. I really want to get your guys' insight into sort of the background of students and what it takes to be successful in creating data visualizations. So I guess for you, Jonathan, what sort of things do you want students to now after their time at Zipfian? Yeah, it's a great question Chris. And seeing so many students work on so many projects here at Zipfian coming from a diverse set of backgrounds I would say the most common hang up I see with students is focusing too much on some complex analysis, or optimizing some model without thinking about the larger process as a whole. And I often like to tell my students your greatest insight is only as good as your ability to communicate it. So if you spend weeks optimizing a model to be 99.9% accurate, but don't think about how someone might use it or derive some value from it, it's basically useless. Oh, interesting. And for you Bryan I guess what sort of things do you think students need to know in order to be successful in creating data visualizations? Yeah I think data visualization is really interesting because it's both an art and a science. So, students not only need to know how to code, to work with the libraries, and explore your data, but you also have to have a really good sense of visual design and storytelling to craft something that's compelling to the audience. We're going to cover both aspects in this course, in order to students to think really critically about the visualizations that they create. Great. Thanks so much guys. Take a minute to think about your background in design, code, and storytelling. How much do you identify being a designer, an engineer or a storyteller? Rate yourself on each of these occupations, from zero to ten. What advice do you have for beginners who may not have a lot of programming experience? well, on one hand it is an awesome time to be doing that because the field's kind of exploding right now. There's sort of a whole data movement, big data, like everybody's talking about data and at the same time, you know, there are just as many people trying to make sense of all that data and usually are [INAUDIBLE] so. In terms of advice it's, it's really hard to give general advice because you know the good news and the bad news is there's so many different ways into this field. If somebody's like a student wanting to go to school looking at programs you know there are programs like this Udasity program there aren't a ton of sort of you know majors, or even Graduate programs yet in information visualization. So there's no, kind of obvious one place to get all the skills that you need. And, and what I think is exciting about the field, is that people come into it from so many different areas. Like I know, you know, architects, industrial designers, graphic designers, statisticians, mathematicians. Like, everybody has some sort of core prior background, and they bring that with them to the field. So, you know, one thing I encourage people to do is, take advantage of whatever your personal background is. And, like, bring that to the field, and see what you can do with it. Hm. now, on like, a more practical level, usually, people want to know, well, what book should I read or what program should I learn or how do I, you know. And again I think that depends like, I work with students who are coming from a design background, and so for them it doesn't make sense to dive into like, the most technical code heavy projects. It makes sense to build on what they already know, so for somebody with a design background I would say you know, start with, with illustrator. Start doing things manually and like, figuring out ways to connect the things you know how to do to data. Somebody who's coming from computer science, mathematics, something like that. Obviously if you leverage you know, your skills being able to use some of these more advanced tools. But you might have to learn like the design language and the visual principles and looking at human perception and psychology and like how do we interpret colors, and scales, and size, and proportion and all this stuff. So, unfortunately, the answer is a whole sort of, it depends and it's going to be a little bit different for everyone and I think that's okay. It's actually what's kind of exciting about the field is everybody has their own perspective. Great. So why are we focused on a designer, an engineer, and a storyteller? Well, we think these roles serve as a great entry point for learning about and creating data visualizations. Some of you may be coming from design backgrounds with a portfolio of projects, while others of you may have more coding experience and can port to software, GitHub, or other websites you've engineered. And still others may be familiar with writing journals and/or communication. Whatever your background, we hope to teach you something new in this class and we hope that you get to share your experiences and your expertise with our udacious learning community. Now I'm going to hand it off to Jonathan, who's going to cover data visualization in the context of data science. Nothing happens in a vacuum, this class included. Now, while many of you may be taking this course because you're interested in data visualization theory and practice using open source tools like D3, this class is actually part of the much larger data science track at Udacity. What I've shown here is a graphic from Ben Fry's PhD thesis, Computational Information Design. In it, he describes the larger process surrounding data visualizations, including acquiring, transforming, and eventually visualizing data to create engaging and effective graphics. This whole process maps quite nicely to the data science process as a whole. On the left he puts what most people often think of as the first part of this process, acquiring and munging data. And often this is what takes the most time. On the right, Ben places interactive data visualization, which is typically what people think of as the final product. A pretty chart, a graphic once all the hard work has been done. Ben places the domain he thinks most naturally fits above each stage. The first of which being computer science. In the larger context of data visualization, or data science as a whole, the acquire and parsing stages are often concerned with data ingestion be it web scraping, log collection, database accesses, et cetera. And building scalable extract transform and load pipelines, or ETL. A second group here of filtering and mining represents what is often most associated with data science, and many people consider it the most exciting. This includes modeling, data mining, and exploratory analysis, and applying statistical and mathematical theory to discover insights. Because of this, Ben Fry labels the second stage as associated with statistics and data mining. While people often think the second stage is, so to say, where the magic happens and the models are built. I really want to stress the importance of the process as a whole. After all, if you didn't have any data in a readily accessible form, you couldn't model it. And even once you have a model, if you can't present and communicate your results. They might as well never have happened. The third stage here focuses on the visual representation of your data, and how you present it graphically, thus is most associated with the fields of graphic design and visualization theory. It is in this third stage that we experiment with different visual encodings to present our data in the most effective manner. And the fourth stage here is concerned with how a reader or your audience might interact with your visualization. Techniques from the field of information visualization and human computer interaction apply here, to determine how best to design your graphic or visualization such that it enables your user to potentially discover insights for themselves. Each of these stages happens to map very nicely to the Dat C data science track. What the first stage is concerned with, you will encounter in the data wrangling class with MongoDB. The second stage, is often the domain of what people consider exploratory data analysis. Which you'll encounter in the data analysis with our class, but other classes such as modeling, statistics, and machine learning also apply to this stage. And the last two stages are what we will encounter in this data visualization class. Lessons one and two will focus on data visualization theory where you'll learn how best to visually represent your data. And how to sketch or prototype a visualization to arrive at a final design. And finally, in lessons three and lesson four we will learn how to construct narratives around your data and leverage interaction to create engaging experiences for our audience and reader. And while this diagram might be biased towards the visualization process, since Ben Fry got his PhD from the Aesthetics & Computation Group at MIT's Media Lab, I don't mind since that's what this class will focus on. What I want to stress is that, like a painter goes through many iterations of his or her final masterpiece, going back to re-sketch, re-draw, change canvases, layer paint, etc. The data visualization process is not simply just the frosting on a data analysis cake after it's been baked, but a fundamental and integral part of the process as a whole. And while you may read this graphic from left to right, each stage is often iterative and you will find yourself traversing this process in a somewhat nonlinear fashion. One step, may better inform what you have done in a previous step. For example, maybe only once you visualize your data that you realize that there are way too many points to make sense of and you need to go back and filter and mine your data. To transform it into a new form that might be much more easy to understand from a visual perspective. Also, you can imagine some insight that you might discover in an earlier stage, that you might want to incorporate in your final visualization. Or some new data that you find online that you think will add more context, and bolster the narrative you've created. And while data visualization in and of itself is a very expansive discipline, ranging from interactive art installations that data artists produce, to business analytical dashboards and charts. One of the running themes throughout this course will be, how to best leverage the principles that we learned about visualization theory combined with technologies like D3 to communicate our data and insights in the most effective manner. Now you might be asking yourself what's the difference between something like exploratory data analysis and data visualization. In the previous diagram I drew a pretty big distinction between the two, but to students new to visualization, they can often seem very similar. Chris, how would you describe the difference between EDA and something like data visualization? Yeah I think of it as the difference between notes and lecture. It is a conversation between yourself and the data. While data visualization is a conversation between data and your audience. Yeah, I think Kathy O'Neil puts it really well in her book Doing Data Science. She says that EDA is what happens between you and your data when you're not trying to do prove anything to anyone yet. When I get a piece of data, the first thing I do is make some basic plots, scatter plots, histograms and things like that, and it's important for a variety of reasons. Let's look at one now. It's always important to plot your data. Let's go through an example y. I've got here eleven data points, which I've plotted on the right. We might want to compute some summary statistics about this data set. Such as its mean, variance, correlation coefficient, and line of best fit. Now suppose I give you three more data sets with exactly the same summary statistics, like this. You'd expect that since these data sets have the same mean, variance, correlation coefficient, and line of best fit, that they look very similar when visualized. Let's have a look now. How similar are these data sets? Not very. We can see here the effect of curvature and outliers have drastically thrown off our summary statistics. This is something called Anscombe's quartet. And demonstrates how important it is to always plot your data, rather than relying on summary statistics alone. Tools like matplotlib in Python or ggplot in R are great ways to plot your data visually, allowing you to pick out visual patterns, trends, and outliers during your analysis. Hopefully, this example has shown you the power of data visualization and why you should use it every day. Thanks Ryan. For exploratory analysis like these plots, we can clearly see patterns or deviations in the data that we might miss from a table or summary statistics. But there's still an even more important reason for creating graphics like these in the first place. The key lies in the immense power of our visual processing system. Danish physicist Tor Norretrander converted the bandwidth of our senses to computer terms to help us understand this power. In this visualization, I can see that sight takes up the majority of the frame here. In fact, it's been said that sight can process information up to the speed of computer networks, or an Ethernet cable. Sense of taste has the bandwidth of a calculator. And the small white box at the corner of this frame is only 0.7% of the area, and it's what we are aware of when all this processing is happening. Before we can begin to create or even recreate visualizations, we need to understand data and data types. Almost anything can be turned into data. Let's take a look at a well noted graphic, and see its data types. This visualization comes from Hans Rothstein's work with global health data. If you have five minutes, I highly encourage you to watch Hans narrate this visualization in the video linked in the instructor notes. Han gives a charismatic performance that makes this data come alive. Now, I want to highlight the different data types that can be found in this visualization. Let's start with the quantitative data, or any variables that have exact numbers. These include variables like life expectancy, income per person, total population, and year. Quantitative data can be discreet or continuous, and typically, variables that are countable are considered discreet. In this case, total population would be considered a discreet variable, while income per person would be a continuous variable. Another data type that appears in this visualization is categorical data. Nominal data is a way of labelling or categorizing the data into groups. In this case, the countries of the world are grouped into regions. The Americas are colored yellow, and sub-Saharan Africa is colored blue. Categorical data may take on numerical values, but these numerical values won't necessarily carry any mathematical meaning. One final type of data not shown in this visualization, is ordered data. Ordered data is similar to categorical data, except that the categories are ordered or ranked in some particular way. One example would be is if I took the populations of each country, and then split them up into bins. For example, I could have four groups where each of the countries falls into a population bin if their population is between 0 and 10 million, 10 and 100 million, 100 and 500 million, or greater than 500 million. In this example, we're pretty much just taking quantitative data, and splitting it into groups. So we have bins or categories of other types of data. A slightly different example would be class difficulty, such as beginner, intermediate, and advanced. Those three types of classes would be a way that we could label the classes, and they have a natural order in increasing difficulty. As data scientists, it's important for us to know that each of these data types can be encoded visually. And in the next few videos, we'll dive into how we can make appropriate choices for visual encodings, based on the different data types. This was just a brief overview of data types. And if these concepts are still a bit fuzzy for you, we recommend that you watch the three videos from the Instructional Data Science class. These videos are linked in the instructor notes. Now that you've learned about data types I want you to take a look at this image, which is linked in the instructor notes. I've gone ahead and identified the different variables in this visualization, but what I want you to do is identify it through data types. For example, is this variable, doctor visits per year, a nominal data type, an ordered data type or a quantitative data type? Choose one of these for each of the variables. Here were the correct answers. Doctor visits per year is an ordered data type, life expectancy is and spending per person are both quantitative data types, and has universal healthcare is a nominal data type. Now among these four variables, I think doctor visits per year was probably the hardest to identify. Let's take a look at why. Average number of doctor visits per year is represented by the size of these circles. And if we look closely we can see that each of these circles corresponds to a range. So basically we've taken quantitative data and split it up into bins which makes this data type an ordered data type. Average life expectancy at birth and spending per person are both quantitative data types just like in the graph we saw before. And whether or not a country has health insurance is really just a nominal data type. It's really a yes or no question. So that's two categories Now that you have been introduced to data types. Let's look at the many options of visual encodings that we have. Simply put, visual encodings are mapping from data to display elements. The visualization that we saw before shares the correlation between income per person and life expectancy, in many different countries. This graphic is rich with visual encodings. Let's take a look at some of those visual encodings now. Life expectancy is encoded visually along the y axis, while spending per person is encoded along the x axis. For our data visualization this means that countries that are located in the top-right corner of the graph, like Qatar, had a high income per person and high life expectancy, the opposite would be true for the countries in the lower left of the graph. Position is considered a planar variable because it locates points in space. It's probably one of the most prominent visual encodings that you'll see in data visualization. And it's also a display element that we can perceive with great accuracy. So we know that position can be good for encoding two variables, but what do we do if we want to visualize higher dimensions of the data, say a third variable. Well, we could visualize a third variable in the third dimension, so along the z axis here. However, 3D models are generally poorly perceived by our eyes, as it's more difficult to make quantitative comparisons between points. For example, I'm not so sure which of these two points has a greater y value, or height. So we need some other way of encoding some third variable for our data visualization, fortunately, we have some other display elements that we can use instead. We can use what are called retinal variables to encode additional variables for our data set, size is an example of a retinal variable, and it's particularly good for ordered data. Going back to our world health data visualization, we can see that population is encoded by the size of each of the circles, or more precisely by the area of each point. In combination with color, the size attribute makes some countries more recognizable such as India, China and the United States. Size and color hue, which we just saw in the visualization, are both examples of retinal variables. And if we wanted to, we can even encode additional variables and these other retinal variables. Size, orientation, and color saturation are particularly effective for order data. However, it maybe difficult to perceive quantitative differences using these visual encodings. The perceived value difference between say light blue and light light blue isn't so obvious. These other retinal variables such as color hue, shape, and texture, are great for encoding nominal variables. For our gap minder visualization, we can see that color hue encodes the geographical regions of the world. This choice of color makes it easier to compare income and life expectancy across developed and less developed countries of the world. The last variable we need to address is time. Now, time isn't a static display element like color, size or position. Instead time is animated through individual frames in our visualization. The quick succession of these frames shows change in life expectancy, income per person, and population over time. It is the remarkable and engaging aspect of this visualization, and we will learn how to incorporate this type of dynamic visualization in lesson four. Now that you've seen one example of how map data to display elements, we`re going to see if you can do it for two more visualizations. Our first visualization comes from the World Cup. We've been pretty jazzed about the World Cup in our office here. So, we thought this was pretty appropriate. You can find a link to this graphic, and then shut your notes. Take a minute or two to review the graphic, and ask them questions about the data. So, you can get a feel for how this graphic is working. Once you're ready, I'd like you to determine, how some of the variables are encoded visually, in the graphic. You'll choose one of these Visual Encodings, for one particular variable. So, for example, for Country, how is it encoded in the graphic? Is it an angle? Is it by length, orientation, or some other choice? Write that answer in this box. And then choose another Visual Encoding for each of these other Variables. Be aware that you can choose multiple Visual Encodings for each of the Variables. In other words, you can reuse a Visual Encoding, as an answer here. For the visualization, countries and player were encoding along the x axis. Time encoded along the y axis. Goals Scored was encoded by the size of the circles. And the Top Scorer was encoded by color hue, which was yellow. And now, let's see on the graphic. We can see that time is encoded along the y axis. Country and player is encoded along the x axis. The number of goals is encoded by the size of the circles, indicated by this legend and the top score is indicated by color hue, which in this case is yellow. Now I know this might seem trivial, but these were deliberate choices. The person who designed this graphic, thought very carefully about the most important variables. And how to place them in the graphic, and represent them visually. Here's another example that comes from the World Cup. I like this visualization in particular because it uses small multiples. Small multiples take advantage of the same layout and visual encodings from one slice of the data to the next. This allows us to make comparisons across the data or across the different views of the data quickly. You can find a link to this visualization in the instructor notes. I'd like you to do the same thing for this graphic as you do with the last one. I want you to determine how the variables are encoded in the visualization. The encodings for this graphic are somewhat harder to decipher because a variable may be encoded in more than one visual encoding. We've set up the grader to accept a variety of answers, but when you go to integrate your answer, I only want you to choose one visual encoding, one of these, for each of the variables. So what do you think? How are these variables visually encoded? Country was encoded by color hue. Game win or losses was encoded by position y or orientation. Scoring margin was encoded by position Y or length. World Cup winners were indicated by shape, and time was encoded by position X. Let's see these on the graphic. We can see the country is encoded by the color of the bars, or really each country has its own panel of data. So, Germany would be red, Brazil would be green, Argentina blue and The Netherlands orange. Each of these bars represents an individual game and the scoring margin for that game. So, whether or not a game was a win or loss depends on the Y position, or the orientation of the bar. Bars that point upwards indicate wins for Germany, while bars that point downward indicate losses for Germany. The actual scoring margin for each game is the length of the bar. In this case it looks like about positive 3. We also accepted position Y since the scoring margin could be positive upward, or downward negative. Time is encoded horizontally along the x-axis for each of our small multiples. And then finally, whether or not a country was a World Cup winner is encoded by shape or a star, which we see for Germany in 1954, 1974 and 1990. Now I think this visualization is quite successful. And what's incredible is that there's even more going on in it, such as the annotations that you see here, and the alternation between this white and light tan background encoding the years. If you find other things that you like about this visualization, share it on the discussion threads. We've seen a variety of graphics and their visual encodings up to this point. But we haven't discussed which of these is most effective. How should we know whether to encode a quantitative variable, in color saturation, or rather than, say, position? Fortunately, some passionate researchers have answered this question for us. In a 1985 paper, William Cleveland and Robert McGill share the results of a series of experimental user studies. These studies were designed to compare the effectiveness of display elements like position, length, angle, and others. They were trying to see how effective using codings were in terms of users being able to interpret quantitative information, that is exact numbers from the graphs. This paper was the first of its kinds to validate the ranking of encodings using, empirical evidence and as it turns out position along a common scale is the most accurate of the encodings. Color saturation or density on the other hand was less accurate. For the Gat Minor visualization, this is why the most important variables, Income per person and Life expectancy were encoded using position. It's the most accurate of the bunch. The key takeaway here is that if you want to design effective visualizations, then you need to understand the rankings of visual encodings and choose appropriate encodings in your designs. Now that you've got a handle on visual encodings and data types, we'd like you to go find your own visualization to decompose it. Here's what I mean. This graph shows medals won by each country during the Summer Olympics. This graphic is actually a cartogram, where the geography, or the area of each country, has been distorted by the number of medals won. Larger bubbles indicate a country that's won many medals, like Russia and China, while smaller countries have won fewer medals, such as Singapore. For whatever data visualization that you find, I'd like you to indicate what are the variables, what are the data types, what are their visual encodings and to what extent are those encodings effective? You can find eight examples from the link in the instruction notes. But be sure to find a different graphic than the ones provided here. We want you to go two steps further, though. The examples here only describe the encodings for the variables. Be sure you also identify the data types and describe the effectiveness of the visual encodings. Do you think the display analogs aid in the interpretation of the visualization, or do you think they distract from the viz? So take some time to find a visualization and answer these questions. Once you've posted a link or image of the viz with your response in the discussion thread, check this box to continue. You've learned a lot about visual encodings and visual perception. Now hear from Johnathan as he breaks down a very complex graphic from The New York Times. Thanks Chris. The visualization that I'm going to be focusing on comes from The New York Times, and was created by Jeremy Eskinouse, Matthew Block, Shan Carter, and Amanda Cox. This entire visualization was built in D3 and can be found in at the URL in my browser at the top here, and all you need to play with the graphic is simply any modern web browser. I really suggest that you go to the page to play with the interactive graphic. I'm just going to talk through a few visual encodings and elements of why I think this is a very effective visualization, but you do not really get the full effect until you experience it yourself. As you can see here, if you hover over each circle, you should get more information about each company. And at the top here, are next bud ins to progress through the animation and the narrative of this visualization. One of the quickest, easiest, and clearest ways to communicate with your reader and audience is through the effective use of a title. As you can see here, the visualization is very obviously trying to communicate how Facebook's IPO compares to the IPOs of every other tech company in recent if not all of history. Of the visual encodings we talked about earlier, this visualization uses size, shape, x and y position, and color to encode its information. Though this visualization uses five visual encodings to convey its information and data, not all these encodings I would say are equal. Two of these encode the same information and was typically referred to in visualizations as double encoding. In this case, the y axis, representing company value, is encoded both in the y coordinate or y position of its circle, but also in the size or radius of that circle. The greater a company's value, the larger its circle will be, and the higher it will be placed on the y-axis. This double encoding of the company value, really emphasizes its importance in this visualization, especially since, as Chris just covered, positional encodings are the most accurate encoding. Also in this case, the x axis, or x position, encodes the year of the IPO, but also color, at the far left, is encoded by the brightness of the red and at the far right we have the bluest blues. So, in this case, color and x position both encode the year that the company IPOed. In this visualization, shape does not encode any concrete information since there are only circles. Since you always have to choose a shape for a bubble chart like this, a circle is a neutral shape, at least until you start using other shapes in conjunction. But if there were circles, squares, maybe triangles, each of those can encode a different type of company maybe by its industry but in our case, again, since there's only circles, shape does not encode much concrete or valuable information. A fifth encoding that we haven't explicitly covered and is sometimes not formally thought of as a visual encoding is opacity. Opacity is very similar to color saturation or density, as we covered previously, but it is not exactly the same. The opacity in this case, refers to how transparent each of the circles are. And while the opacity doesn't communicate any information about the data points, in our case it does allow us to se the relative distribution of the data points and how they overlap. Since there is many companies that apparently IPOed in the year 2000, they all had relatively small company values at the time. We see a very dense dark purple, but if you notice as we go up, we have a few circles where we can notice the overlap, and some circle that are off on their own, with no overlap. The last feature of this visualization I want to cover is animation. Animation isn't technically a visual encoding, but you can think of it as encoding some information, or rather, change of information in a certain sort of way. As we can see here, the animation really highlights how drastically different the Facebook IPO was in value compared to the history of IPOs that came before it. Not only does the animation convey some of the process the RS went through in creating this visualization, such as discovering that the Facebook IPO was so drastically greater than all the other IPOs. Or the fact that using different scaling, in this case logarithmic, makes the graphic much more interpretable, but also gets across some of the relative change of the companies in the years after they've IPOed. While you might be able to encode this sort of information, such as how much a company's value has changed after its IPO, in another dimension of visual encoding, let's say the z axis, it is much easier, and I think much more effective, to communicate that information through the animation. We have just learned about the theory behind what makes an effective data visualization. We saw how color, shape, length and scales, among other visual elements, can contribute both to the aesthetics of a data visualization, as well as how the underlying information and data is communicated. Now I want to talk about how we might make some of the visualizations we have seen and put the theory we talked about into practice. Throughout this course, we will encounter a variety of technologies and tools, that enable designers, artists, developers, and data scientists to express their views and communicate their insights with the world at large. And while we will try to expose you to, what we think are the most relevant tools, to help you create data visualizations,. There are far too many technologies out there, to cover them all. However, you may encounter them, or at least people who use them, so it's a good idea to have some sense of what is there. At the bottom of the spectrum, are low-level graphics formats and specifications. These are some of the most efficient, performant, and flexible of your options when choosing to create a visualization, but a very low level and have significant overhead, not only to learn, but to develop in. Think of these as the assembly language of visualizations. While these technologies, are very flexible in what you can do. They force you to specify what you want done, in terms of pixels and lines, or rather place a point at xy and create a path, to point wz. This is much like if you were instructing a painter or robot how to draw. As you go up the spectrum, to higher level languages and libraries, it becomes much easier and faster to develop your graphics. Though the tool you may use, may be slightly less flexible, than raw HTML5 canvas, WebGL or SVG. A hop, skip and jump up, we have our beloved D3.js. We will get more into the specifics of D3 in just a second, but as a data visualization library built atop open web standards, it is implemented in JavaScript and allows for seamless binding of data, to HTML and SVG elements, or actually anything on a webpage really. Since you can style HTML and SVG with CSS, CSS works very naturally with the whole stack of technologies that D3JS is built atop. D3, contrary to what most people may think. Is actually pretty low of an abstraction. For continuing our analogy of programming languages and what they're built atop I would say that D3 in the spectrum of visualization technologies is actually at a similar level to where C or C++ is in the whole spectrum of programming languages. And just like people use C and C++ to build operating systems, programs, and compilers for other languages, D3 really shines when you use it to build higher level abstractions and libraries on top of it. And this brings us to the suite of D3.js libraries. This layer represents. The plethora of high level libraries built atop the building blocks of D3. Although there are far too many libraries to list or even fit on this screen that are built atop D3, three of the most common or ones that we would mention in this class are Rickshaw,. Dimple.js and NVD3. People often like to think of D3.js as data visualization library legos. You can very easily compose D3.js components. To build higher level abstractions and libraries on top of it. While it might seem very daunting to navigate the space of every library built on top of D3 they usually fall into one of two categories. They are either high level charting libraries like NVD3 and Dimple.js or they're tailored to a specific type of data. Like Rickshaw. Rickshaw was built to most effectively and easily visualize time series and real time streaming data. In the same vein of visualizing a specific type of data are also geographic libraries to help plot data on maps and add interaction to maps. We will use Dimple.js in this class in the later lessons. And really experience the power of using a higher-level abstraction than straight D3. And again, going back to our spectrum of programming languages, if WebGL, Canvas, and SVG are analogous to assembly language, D3 is analogous to C and C++. I would say the higher level libraries built atop of D3. Are similar in abstraction level to something like Python or Ruby. Python and ruby are fairly high-level languages, they're interpreted. You don't have to deal with memory collection, and many times they're implemented in C or C++. And, just like these higher level languages. Are implemented in a lower level language, NVD3, Dimple.js, and Rickshaw can be thought of as implemented in or on top of D3.js. At the very top of this spectrum, are libraries that have graphical interfaces for creating verializations, such as Raw or Chartio. Raw is an open source library built on top of D3 that allows you to very easily and quickly build predefined charts. Chartio is a web-based product similar to Tableau that allows you to very quickly and easily explore your data to build dashboards and charts hence the name. Chartio. Since these libraries are so high up on the spectrum, they have very limited flexibility and can usually only produce a set of predefined charts. The upside to having a set number of predefined charts. The creates those almost effortlessly, and quite seamlessly. Think of these as the Excel of data visualization libraries. They're incredibly useful for about 90% or 95% of the use cases you most likely will encounter. And they make those 95% of cases quite effortless. If their charts happen to match what you're looking for. But if you stray from this path of predefined charts it may be cumbersome, if not impossible, to customize them. If none of my silly analogy to computer programming languages made any sense, do not worry. You will not need to know any of this for the class. Hopefully, however, it helped some folks get a better sense. Of where each of these technologies stands on the spectrum of abstraction and visualization. I sometimes like to thing of these technologies existing within a pyramid of abstraction. Think of the width of the level of the pyramid representing how flexible each of the technologies at that level are and the heighth of the pyramid. Is how easy it makes it to create visualizations and how much developer productivity they enable. At the bottom of the pyramid are technologies that have quite a lot of flexibility and offer a lot of games in performance and efficiency, but maybe very difficult to use, and slow to develop in. At the other end of the spectrum, and at the top of the pyramid. You have taken all these like Raw and Chartio. Which are very easy to use, allow you to develop visualizations very quickly. And iterate on those visualizations. But may be much less flexible than something like Web GL or D3. One thing you always have to consider as a developer, especially if you're working on a data science project. Where the entire scope of the project is much larger than just the visualization portion is the trade off between developed productivity and the efficiency of your solution. Due to recent trends and the performance improvements in the browser and of all technologies involved. And also in the abstractions created by higher level libraries, developers are quite fortunate and get something the best of the best of both worlds between very productive and having quite flexible and efficient libraries. Because of this, you can have your cake and eat it too than rather code in a high level library. And still get decent performance and flexibility, and while each of the many data visualization libraries out there have their strengths and weaknesses, in this class we will focus on the particular JavaScript library D3. You've just learned about some of the reasons why you might chose D3. Part of this is based on the technologies that D3 is built upon and leverages. Select all of the technologies below, which D3 uses or is built atop. D3 can interface with many of these other programming languages and libraries, such as Python and Java. The core technologies that D3 uses are the open web standards, such as SVG, CSS, HTML, and JavaScript. D3, I want to unpack that name a bit because I think that speaks to why the library was created and how it integrates data with a webpage. Data driven documents. Data in this case refers to some information we are trying to visualize. Be it CSV or JSON, loaded externally, or simply a JavaScript object or variables. Documents is a reference to a webpage or web document, rather, a collection of HTML, CSS, JavaScript, and SVG often. But hey, data driven html or data driven pages, just didn't have the same ring to it. And driven, D3, binds data to the document, or rather more concretely, rows of a CSV or JSON to SVG elements. More formally, documents doesn't only refer to the source of the page, and the content of the HTML, CSS, JavaScript, or SVG, but it could also refer to what's called the Document Object Model, or DOM. Web browsers can be thought to store two versions of the web page or rather two views. One of which is the initial source, as I mentioned, that gets returned from the web server, and the other is a parsed DOM object. The Document Object Model is a specification, much like HTML and CSS, that specifies a common programming interface for HTML and XML documents. Once the source of the HTML is returned from the server, the web browser parses the file and transforms it into a hierarchical object that can accessed programmatically, most often through JavaScript, called the DOM. D3 actually binds data to the DOM rather than the source or visual elements of the HTML. But since the DOM actually represents and can interact with what's displayed visually, when we bind data to the DOM, D3 drives the document, in this case the visual representation of the DOM, and creates a chart based on the data that's in the DOM. The process of the browser creating and building the document object model can be fairly complicated. But if we're going to be precise about things, it happens during the page load as it receives HTML source. So, even before the page is fully loaded, the browser begins to start constructing the document object model one piece at a time. Other answers I would consider correct, are simply after HTML's been received, or after the page has been loaded. For part b, while the DOM can be accessed through a variety of different means, the main answer I was looking for is through its JavaScript application programming interface since we're going to be working in the browser and with JavaScript in this course. And in the third part, while you can access the DOM through JavaScript, as I just mentioned, the DOM itself isn't a programming language, or JavaScript, but is merely a specification of an interface. The DOM is also a hierarchical object, and what I mean by this is that it has a tree structure and this is due to the nested nature of HTML itself. We will now dive into some of the specifics of how D3 works, and why it is becoming the go to tool for anyone who wants to visualize data. Rather than obscure and hide the Document Object Model, D3 embraces it by directly manipulating HTML modes and SVG objects, Through common conventions like CSS selectors. By doing so, D3 has enabled much more expressive visualizations and allows designers to directly interact with developers, by separating the style of a visualization from the mechanics of it. D3 visualizations, Since they operate directly on HTML through the DOM and SVG, can be styled in the exact same way as any other web page, such as with CSS. And D3 code can actually manipulate already created and HTML documents. We will see an example of this when we get to the live code portion of this lesson and actually manipulate this very web page and change some of the stylings and elements. One example of leveraging this power might be to pre-render HTML and SVG objects for a complex visualization on the server side, and then simply use JavaScript for any sort of interaction or dynamics that we need on the client side. If you have the libraries built on top of D3, actually do exactly this and allow you to render on the server side D3 objects to static images or JSON. The last benefit I will mention, though there are quite a few more, is that, since D3 visualizations operate on the DOM and HTML directly, they can leverage all the improvements and advances of the open web, such as browser enhancements, JavaScript speed increases, and newer standards, such as HTML5. And also, developers can use all of their familiar tools to work with D3. Such as debuggers, text editors, existing libraries. In this class, we'll be leveraging D3 to create interactive data visualizations. Since D3 stands on the shoulders of HTML, CSS, JavaScript, and SVG, we will need to get comfortable with these technologies before we start using it. Although it's not required to know these technologies for this course, much of the live code and exercises will assume that you have a basic proficiency with each of these technologies. If you don't feel comfortable with these technologies, we've included many exercises and tutorials in the resources portion of the course or in the instructor notes for each video. I recommend taking a break now and going to the resources section of this course now in order to understand the code that is going to follow or if you want after this lesson to brush up on anything that I may have covered that is unfamiliar to you. We'll be experimenting with D3 on the Udacity course page for this class. Since D3 is a client side JavaScript library you can load it onto any web page that you're on and start playing around with the elements of HTML or SVG contained on that page. If you're on any of the web pages of the data visualization class. D3 should already be loaded. But if you're on a web page that does not have D3 loaded, you can simply copy the D3 source and paste it in the web console. I will be using the Google Chrome browser throughout this course. But, any modern browser should have all of the same functionality of a JavaScript console and an HTML inspector. To open the JavaScript console, we can go to the Tool bar of Chrome accessed from the upper right corner of the browser window, scroll down to the sub menu of Tools, and from Tools you can see here that we can view source, access the Developer Tools or go into the JavaScript Console. As you notice here it pops up a window on the bottom of my browser that lets me enter and execute JavaScript. Unfortunately at Zipfian Academy we do not have the engineers or great production team that Udacity has to create such a compelling online education platform. What we do have, however, is a knowledge of D3 and JavaScript. So instead of building our own platform, let's usurp Udacity and pretend that we have their own platform as well. We can do this by changing the branding of Udacity's logo, maybe some elements with the course, and actually change anything else on the webpage that we may want to. Whenever faced with a new technology or library, I always like to interactively explore it. Whether that be in a in my terminal or the console in a webpage. I find that having immediate feedback, and in the case of the Chrome developer tools method auto-complete, greatly increases the speed in which I can learn. Again go into the top menu bar in the upper-right of the window, scrolling down to the Tools sub-menu, and then opening up the Developer Tools, or Cmd+Option+I, we'll see a split pane. In this case, we have the HTML of the page, the JavaScript console, and the visual display of that page. We are fortunate that we're learning about HTML, CSS, JavaScript, and D3 since we can access and inspect all the code used to construct a web page. Simply by opening the browser's console or looking at the source. If we would like to look at the raw source file, we can click on the menu again, go back to Tools, and simply click View Source to see the textural content of the page without any of the other Chrome tools. When we request from udacity.com the course and the exact HTML page we get returned the HTML source content which the web browser then parses. Well it looks like the HTML source displayed in the web console of the developer tools is actually the DOM representation of the HTML source file I just showed you. Notice as you hover over specific elements they get highlighted in the visual display of the corresponding visual element. We have just seen the power, of the Chrome developer tools and how we can inspect our page, to learn what visual elements correspond to HTML elements. What technology, do you think makes it possible for us to either inspect elements, through the developer tools by hovering over HTML, and seeing which visual element it corresponds to on the page. Or vice versa, to right click on a visual element on our webpage, and find out the HTML tags that compose it. While the other technologies listed here are related to this ability, and while you could argue that without the HTML source there would be no web page to display, the best answer it the Document Object Model. The reason being that the document object model is the abstract representation of the HTML source and allows us to programmatically interface with HTML elements, enabling the browser to create this link between the visual display of an element and the HTML source tag. The JavaScript console in the Chrome Developer Tools can be accessed by clicking on the Console tab, if it's not already open, and is actually a full featured JavaScript interpreter. We can execute any arbitrary JavaScript, 5 plus 7, and we get returned 12. Or we can even create functions, and when executed, gets add to the scope of the console window. Here, we can see I defined a function named my_fun, and when called, simply returns hello world. So inspecting that in the console. Notice as I start typing my, the Chrome console knows that my_fun has been defined and tries to auto-complete it. Typing tab, I can auto-complete it. And if I leave the parenthesis off, what gets returned is simply the definition of that function. This is a subtlety, but fairly important point. The definition of a function, in this case, what should get run when it's called is separate from actually running that function. As you can see here, my_fun without parenthesis, simply returns the definition of that function. But if I called my_fun with parenthesis, it signals to call the function and return hello world in this case. If your console window is getting too cluttered, you can use a clear function, or if you're on a Mac Cmd+K to clear out everything that's been run before. Also, if you type the up or down arrow keys, you can scroll through the history of commands which you've run in the console. We actually have full access to the DOM in the JavaScript console. If you type document, you can see what is returned is the entire DOM document. Contained within it, is the HTML of the page and the HTML tag. The other top level object available is the window. The window corresponds to the browser window and the document corresponds to the HTML page that's been loaded. One thing that you may want to do when working with D3 is select elements of a web page either by something like their class, their ID or even just what type of tag they are. But the way that D3 actually does its selections, is based on the native DOM selection API that gets exposed through native JavaScript. If we would say, like to access a DOM mode by its ID, we can call the appropriate selector function on the document itself. If you notice here, if I type document.get, Chrome is smart enough to auto complete what function I might want, but if there's multiple options it shows me all of them. As you can see here I can get an element by its ID. I can get multiple elements by their class name and get multiple elements by their name. I can get multiple elements by their tag name and so forth. Typically you never need to access the DOM from this low level of a function, due to the wealth of libraries that make selecting elements much more convenient. One of the most popular is jQuery D3 has a very similar method of selecting DOM nodes as jQuery does. But for now, let's start with the simplest and try to get an element by it's ID. If we try to get a footer, this is going to look for a DOM node that has ID equal to footer. And what we see here, is a div tag ID equal to footer, and we can expand this, and see everything that's contained with in it. The second and last query function, defined in the DOM is what's called querySelector. querySelector is actually much more general than getElementById, and is what D3 uses internally. querySelector allows us to use CSS select our syntax to grab DOM elements. If you're not familiar with CSS query selector syntax I recommend looking it up as its a very powerful syntax. The simplest and most commonly used CSS query selector is probably the class selector. If you prepend a dot to whatever class you're searching for, the document .QuerySelector, will find the DOM nodes that have a class, in this case of Viewer, Maine. As you can see here, Viewer, Maine, corresponds to the main window that the video player is in. And this is actually the same object that gets returned down here. Notice if I hover over the DOM node in the console or in the HTML frame up here Chrome's smart enough to know that I'm trying to inspect the DOM node, in this case a div with class viewer maine, and highlights it for me in the left pane To get some more practice with CSS selectors d3. And how to find HTML tags and elements that you're interested in manipulating. In the box below, input a CSS selector that will correctly select the top nav bar of the page. Again, this is the bar that contains the Udacity logo and is dark blue. And there may be many ways to select this element due to the flexibility of CSS selectors, but any selector that correctly selects the navbar is fine. I chose to use the CSS selector header.navbar-static-top, which selects the header tag with class navbar-static-top due to its simplicity. But there are a few other CSS selectors that will correctly select the navbar element. And again, any selector that properly selects the navbar is fine, but often you want to look for the simplest and most concise. One downside of using the native dom selectors, such as document.querySelector or document.getelementbyID is that what is returned is a dom node and not a D3 object. If we try to call any D3 functions on what's returned from the dom selectors, we'll get an error saying a method is not defined. In order to leverage the full power of the D3 chainable API, we need to create a D3 element from a selection so that the selection is wrapped with all of the functions D3 defines. The d3.select function looks very similar to query selector defined in the api of the dom. And just as we passed in .viewermain as a CSS selector to signify that we want a dom node that had class viewer-main, we can do the same with d3.select function. Notice what gets returned is an array rather than a single dom node. Using D3, we can create, remove and manipulate DOM nodes programmatically. Lets try to change the background color of the navbar in the audacity player. First, we need to find some identifier for the navbar. A shortcut I like to use to finding which DOM element is represented by a visual element is to right click and select inspect element. This is going to bring me to the navbar or a portion of the navbar. But if you notice here, the selection doesn't extend the width of the window, which leads me to believe that we've actually selected a child of the navbar that we're looking for. Going up, we see a header tag, and when we hover, spans the full width of the window and has classes defined on it. Which might mean that we can select it by using the D3 select function, since the header is actually a header tag, we can be more specific in our CSS query and look for a header tag with class navbar-static-top, which returned is another one of these D3 arrays. If we open it up, we see its actually the header element we want and again hovering over it in the console highlights it in the window. In order to manipulate the selection, D3 defines a set of transformation functions. To change any of the CSS styling, we call the .style method on the D3 selection. The first argument to style being the CSS property we'd like to change or return. If we don't pass a second argument to .style and many of the other D3 transformation functions work the same way. This actually accesses the appropriate style, in this case background color, and returns it to us. As you can see here, the D3 syntax says, using D3 select a header with class navbar-static-top and return to me the background color styling defined on the header element. As you can see here, returns a string of RGB values. If we would actually like to manipulate and change the background color, we simply need to pass a second argument which will replace the current background color. In this case, as a second argument, I'm simply passing a string, corresponding to the color I would like to change the background to. In this case, green. Two things to note of what just happened. One, the bar did indeed change to green. But another strange thing is that the style method actually returned to me another array that's the same object as returned from select, corresponding to the navbar. This is what I mean when I say D3's chainable API. Most methods defined in D3 return whatever object they were called on. In this case, D3 select finds and returns a D3 selection object. .style mutates that object and then returns the mutated object, and so forth. So we can call a somewhat arbitrary number of functions. Chaining one after each other, and D3 knows how to handle it, changing at each step of the chain the object being passed through. One thing that might have made you uneasy, is that when we selected our header element, we simply chose a class name and assumed it to be unique, or hoped it was. Typically, you cannot make the assumption that a class name is unique to a given element. IDs are typically reserved as unique identifiers that don't show up on any other HTML or DOM nodes throughout the page. But classes could, and often are, applied to many different HTML tags. We can test whether navbar static top was indeed unique by using d3's selectAll function. SelectAll works in just the same way as select. Except for instead of returning one, it returns all the elements that match the selection. As you can see here, I'm trying to select every header with class navbarstatic top on the page. Luckily for us, what gets returned is a single element. There are a few more methods that D3 defines on a selection object that allow you to transform and mutate DOM nodes. If you're curious about all the possible options, I suggest reading through D3's API docs on their site, or by simply exploring the selection objects using Chrome's autocomplete. In this case, I'm going to store the return value of the selection into a variable header. And now with my header dominoed, I can try to call a function on it and see what the Chrome console tries to autocomplete. Calling header dot shows not only the functions D3 defines but any function I could possibly call on the object I'm working with. Now that we've seen how we can use D3 to manipulate HTML elements, I want you to take a moment to explore some of the functions defined on a D3 selection in order to change the title of the course on the webpage to Jonathan's pretty pictures. And just for a little bit more clarification, the title I'm referring to is the data visualization compensation element right above the video player. Just like some of the earlier quizzes and due to the flexibility of both D3, CSS selectors, and JavaScript, there's many right answers to this quiz. To change the title of the course, all we need to do is figure out what type of class or ID we can select the title with. In this case, I'm going to right-click and Inspect Element. As you can see here, it's in h1 with classes h-slim, left-hand-nav-title, and another one, ng-binding. I'm going to assume that left-hand-nav-title is fairly unique, if I call it on a header tag. As you can see here, calling d3.select on h1.left-hand-nav-title returns to me another d3 array. And if we open it up, we see the element hovering just to be absolutely sure that we've selected the right element. Now when I just mentioned, we're looking for a header tag. There's a distinction between a header tag defined as so and the h1, h2 all the way to h6 tags. You may see and hear people talk about both, so be sure that when someone is talking about a header tag, or an h1, h2, and so forth you know exactly which one they're referring to. To change the intertextual content of this h1 tag again, going to find my selection, store it in a variable, and try to auto complete any method defined in my selection. As you can see here, I'm going to scroll down and hopefully find something that I may think can help. As you can see here, there is an HTML, which might work. There's a property method. Which is also a possibility. And at the bottom here we have text. Let's see what text actually does. Again, if we run this or execute this statement here without parenthesis, we can see the inner definition of the function. As you can see here, this is actually somewhat complicated as d3 tries to be as general and applicable to any sort of value passed in. As you can see here, on my title selection, calling text with Jonathan's Pretty Pictures, changes the title to Jonathan's Pretty Pictures. And if I open up what's returned from the .text method, I can see the DOM node I called it on and hovering hovers over the correct title in the window. Something I've been leaving off in all of the console commands I've been running is an ending semicolon. The inclusion or exclusion of a semicolon at the end of every line of JavaScript has caused some disagreements in the JavaScript community. In the language specification, it requires you, if you're trying to be perfectly correct, to end every statement with a semicolon. What's happened since JavaScript's come out, though, is that people often forget semicolons, and the JavaScript interpreter, or the browser, tries to make a best guess effort as what you meant. You can get by without using semicolons, but it's best to be explicit. Again, I want to stress that one of the most powerful features of D3 could be considered its API and how it makes you think. Since every method in D3 returns the element or elements that it was called on, you can naturally chain methods one to the next. Don't worry about all the changes we've been making to the page. Any changes we make are purely on the client side, meaning only within our local browser, and of we refresh the page Udacity's site goes back to normal. So now, let us refresh the page and then start manipulating with a fresh HTML page. After we've refreshed the page, you can see that the navigation bar has its original background and the title is back to Data Visualization rather than Jon's Pretty Pictures. I wanted to walk through how to actually change the logo and what's happening behind the scenes in more depth. The first step, as always, is to inspect the element and try to find some unique identifier, either a class ID or tag, to use with D3 select function. As you can see here the logo is in image tag but it doesn't have any classes or ID's defined on it. Does this mean that we will not be able to select it? No, we simply have to look one level up or as many levels up as we need and navigate the dom tree from the closest identifiable element. What does that mean exactly? Well, going one level up to its parent, the image tag is contained within an a tag, and this a tag, as you can see when you hover, highlights the Audacity logo, meaning that the image is indeed a subselection of the a tag. And looking at its class of logo and navbar brand, I'd be willing to bet that if I search for a with both logo and navbar-brand, I'll find a unique element which returns this selection. So calling d3.select with a.navbar-brand.logo, which again is looking for both navbar-brand and logo classes defined on the a tag. Again, as you see here, we get a return with a D3 Array object. And inspecting inside we see indeed there is an a tag that has .logo.navbar which uniquely identifies it and corresponds to the logo that we're looking to change. Since this a tag also has an id, header-logo, we can select it using a CSS selector for the id. The syntax for CSS selectors to select an ID is simply the hash or pound symbol, and then the ID following. Let's save this selection into a variable. Let's call it, parent_element. And now let's try to find a way to get the image tag to actually mutate its source. Again, because what's returned from the selection has all of D3's methods defined on it, we can make another sub-selection. Scrolling through the list of methods defined, we find select. We can select within this element and arbitrarily select however deep we may need to go. In this case, we're lucky and only have to go a single level down. Also in this case, since there's only a single item within the a tag, we know that subselecting an image tag on the previous selection of the a with ID header-logo, we're guaranteed to get the element of interest. As you can see here, the image tag we hover and it corresponds to the logo. To finish our remodel of Udacity's site, we simply need to change the source attribute defined on the image tag. You can change any attribute defined on any HTML tag using the .attr or attribute method defined on a selection or D3 object. While we're interested in just changing the source, you can actually change any attribute, alt text, maybe a class, or an ID. In this case, let's just try to change the alt text and see what would happen. Notice as we change the alt to Jon's logo since was displayed in the chrome developer console is the dom and not the stated source of the page. The alt name actually changes in real time to Jon's logo. To change the source you simply need to change alt to the string source. And in our case, I've already found the URL for the Zipfian logo and stored it in a variable zipf. Running this line, the source should dynamically update and that logo image should change. And voila. As you can see here the logo has changed to Zipfian Academy's logo, and if we hover over the dom representation of this we can see that indeed the source has changed and it corresponds to the Zipfian Academy logo. You can change Udacity logo on the page simply by selecting the element and changing the source of the image tag. Here I've used a nested selection. So first, I select the a tag that's the link with class navbar-brand and .logo so the a tag needs to have both navbar-brand and logo and within that selection. So within the a tag, we then select whichever image tag is in there. Change the attribute of the source to what here is a URL to the zip [INAUDIBLE] academy logo. As you can see here but it's a little bit hard given the background of the nav-bar. The logo is now pointing to [INAUDIBLE] logo. Now that we have some basic familiarity with d3's basic functionality, we can begin creating more interesting visualizations, and start applying some of the things we learned earlier in the lesson with regards to visual encodings. To start inserting some SVG elements into this page, we might have to make some room. As it stands, it looks pretty cluttered with all of the other elements on the page. Since you probably want to watch the instructional video of me guiding you through this, let us try not to remove the video frame element. There does, however, seem to be a sidebar with the discussion that we might be able to temporarily make our canvas. Let's now clear this side column inspecting the element we can scroll up until we hover over the correct element that highlights the entire box. In this case, it's a div, but going even higher you can see there's another div with class call-access-three. Selecting this element we can inspect what is returned and indeed again it is the correct element. If we want to wholesale remove this element we can call d3's.remove function, but since we actually want to insert some SVG and SVG elements into it, we only want to remove it's contents. The dot HTML method defined on its selection either returns the inner HTML of a selection, in this care here you can see a string of HTML, or if we patch in an argument it replaces that string of HTML with that value you pass in. In this case, since we want to empty out the selection, you simply pass in the empty string. And as you can see here, the discussion has disappeared and the DOM elements have been removed from the selection. Again, if you'd like to know more about the methods and functions defined on selections or any d3 object, I suggest looking at the API documents that are linked in the instructor notes. And to this SVG, we can begin inserting shapes. Let us revisit what we know about visual encodings, and try to recreate one circle from the Gapminder Wealth & Health of Nations example. Let us start by trying to recreate the circle that represents China. As you can see here, China has a life expectancy of 75 years and income per person, GDP per capita of 8,347 and a total population of 1.35 billion. When faced with creating any visualization based on data, you need to figure out a way to transform data values, in this case, life expectancy of 75, income per person of 8347, into the appropriate coordinates on the x and y plane. Since we're building a visualization in the browser, we often have to map the values of our data to pixel values. Since D3 was created exactly for this purpose, it has many convenience functions for converting data values into its corresponding pixel value. The most commonly used functions for this purpose in D3 can be found in the d3.scale module. To use scales in D3, you specify the range of your possible input values, a function that transforms these to output values and the appropriate limits on your output range. Going back to our Gapminder example, one last time, we notice that the x-axis ranges from around 250 to 100,000, and it's a log scale. And the y-axis ranges from around 15 to 90 on a linear scale. To plot our circle using D3 and its scaling functions, we need to remember that the expectancy is a value of 75. The y-axis is on a linear scale. The income per person is 8,347. And the x-axis is on a logarithmic scale. In just a second, we'll see with some live coding the functions in D3 that actually help us produce and manipulate scales. For now I wanted to talk from still a relatively high level and using a lot of graphics to help explain what's happening behind the scenes. This green rectangle here represents the scale of the life expectancy of the Gapminder plot. We see at the bottom, there's a minimum value of 15 and at the top, is a maximum value of 90. The green score on the left represents the value of our data, in this case, the actual numeric representation of what the life expectancy is. And this blue rectangle represents what pixel values you want to map the data values to. D3 refers to the input values as the domain of your data often are represented by the minimum value and the maximum value, but the domain actually refers to the entire extent between the min and the max, and D3 refers to the pixel values you want to map the domain to the range also represented by a minimum and a maximum value. In order to transform our domain into the range, we often have to specify what type of function you would like to use to convert the values from the data into pixel values. In the case of the life expectancy, this scale was linear in a Gapminder plot. So we want to use a linear function to map the domain values to the range. In the very mathematical sense and literal sense of a function that maps from our domain into our range, we can think of the transform, that converts the values from our domain in the data to pixel values as an equation. In this case mapping the domain as x into the range as y. Since we are using a linear scale, the function is simply the equation of a line. You do not have to worry what the value of m or the value of b are in this case. That is one of the very nice conveniences that D3 provides for us. All we need to specify are the minimum and the maximum of our domain, and the minimum and maximum of where we want to map our values to. And the D3 scale function figures out the appropriate values and constants for the linear function that maps the domain into the range. So far we haven't actually specified the values we want to map our domain into. For the live coding example we will get into, we will simply pick a max and min for the range. In our case, we can simply set a max and min of where we want to [INAUDIBLE] range to be. In this case, I choose a maximum of 200 pixels, since that's around the size of the box we would be working with on the web page. A minimum range value of zero. Does not mean we plot our point in one of the corners of our webpage, it's simply an offset from the root SVG element which we will be working with. One less quark I want to cover is that the coordinate plane in the SVG in the webpage actually has a value of zero at the top left, and as you go out. Right from that origin, x values are increasing and as you go down from the origin, y values are increasing. So a value of zero actually corresponds to the upper left and a y value of 200 actually will correspond to the bottom of our SVG elemen. Now that we have some conceptual idea of why D3 scales are important, and how to map data values into pixel values to display on the screen, we can get into some live code and actually see this put into practice. Now that we have a blank canvas, we can begin inserting SVG elements and start drawing. In order for any SVG elements to render on a page, we first need to insert them into an SVG tag. Again, let's select the sidebar where the discussion used to be with the selection. We can append whatever element we want, in this case an SVG element. And then with the returned SVG element stored here in an SVG variable, we can then begin inserting shapes, points, lines, whatever we want. As you can see, looking at the DOM tree, we have inserted an SVG element. Hovering over it, Chrome tells us that it's 300 pixels by 150 pixels, but nothing's actually displayed in the window. Part of that's because SVG elements by default don't have any visual representation. We could change the color of its background. We could change other properties and attributes defined on it if we would like to see the bounding box around the SVG. In order to create a circle similar to the circle that represented China in the gapminder visualization, we'll first need to figure out a way to map data values to pixels. As I just mentioned, d3's scale module allows us to map from data values to pixel values, or rather, from any arbitrary domain to any arbitrary range. As you can see here in the auto complete that Chrome provides for us, there's a linear scale, a log scale, ordinal, power, and so forth. For the y axis, we'll be using a linear scale. And with this scale, we'll be mapping a domain from 15 to 90 into a range corresponding to the height of our SVG element, in this case 150 pixels. One quirk I just mentioned is that since SVG's coordinate space actually has zero values for y near the top and as you go down on the page the y value increases, we actually want to flip the bounds for the range. Such that they properly get mapped. What this says here is create a scale that's linear, maps to the domain 15 to 90, and to the range 150 and zero. So in our case, the greatest domain value maps to the highest pixel value, in this case zero being closest to the top of the browser window. As you can see here, what's returned is actually a function. And as I previously mentioned, a scale can be thought of as a functional mapping from a domain to a range. And that's exactly what d3 returns to us. A function that, if given an x value, maps to a range appropriately, and returns the value it's been mapped into. Let us store the scale this time in a variable y, corresponding to the scale of the y axis. Since D3's API is very general and adaptable I'm simply going to reuse the functions I just called but this time to create an x scale. Since the XScale, as I mentioned, is a logarithmic scale, we'll change the linear function here to log and the domain this time maps from around 250 to 100,000 and their range we want on map2 corresponds to the width of our SVG element, in this case, 300 pixels. But let's put a little bit of a buffer on the right end of the SVG element. In this case, since the x coordinate isn't inverted for SVG, we simply want to map from zero to, let's say, 250. And what this says is the value of 250 in our domain maps to a range value of zero. And the value of 100,000 in our domain maps to a range value of 250. And in between 250 and 100,000, we apply a log arithmetic transform to find out how it should scale saving this scale in a variable x, we now have a scale for both our y, and our x axis. In our case, I don't want to deal with the radius of the circle for simplicity's sake. But you could also define a third scale that corresponds to the radius of the circles you draw. And in the get minder case it will correspond to the population of the country. In order to append a properly scaled circle on the X and Y position, we'll have to use the two scales we just defined. Before I actually append a circle to the SVG element, I just want to make sure the scales are somewhat sensible. For China, remember, the life expectancy on the y axis was 75, and the income per person on the x axis was 8,347. The consoled out log function in JavaScript simply prints its arguments to the console, in this case the Chrome developer console. As you can see here 75 mapped to 30, and 8,347 mapped to 146.4, approximately. These seem sensible, since on the Y axis. I have a range of 0 to 150 pixels. The lower the value actually corresponds to a higher pixel position. And in the x axis, we have a range from 0 to 250. Now that we've checked that our scales seem to be doing what we expect them, let's try to append a circle into our SVG element. Remember, we stored our SVG element in a variable, so we could access it later. Into this SVG element, we want to append. What do you we want to append? In this case an SVG circle element, and in order to make sure that that circle actually shows up, we have to give it some attributes. The first attribute I want to add is the constant radius of ten. The second attribute, and one of the easiest, is the fill color, and the last two attributes we have to add are the x and y position. As you can see here, again, D3's chainable syntax allows me to just pass the circle element from one method call to the next. And keep adding different attributes as it goes down the chain. The SVG circle element has cx and cy which correspond to the center x and center y. Running this code, we see that a red circle has spontaneously showed up on our page, which means that we've done something right. Unfortunately, out of the context of every other circle from the gap minder plot, we aren't too sure of how correct this is, but if we hover over our SVG to see the borders. And if we look at the gap minder visualization. We see that the red circle is in approximately the right place. That is all I wanted to show you for now, in the console playing around with the three, but hopefully I have shown you some methods that you can use to create visualizations of your own. Again, if anything I have showed you, you would like to know more about there is a few resources in the instructor notes. Or the D3 site itself and Mike Bostock's blog, the creator of D3, have some great examples to go off of. Now that we've implemented some d3 code and put what we learned about visual and coding into practice I just wanted to recap where we are quickly. In addition to being readily acceptable to a large audience, d3 has a very nice API, or application programming interface. This allows the library to function in a declarative manner. Or rather, you tell d3 what you want, not how you want it to accomplish the task. By decoupling the specification of an operation from the execution of that operation, d3 allows the user, you. To focus on the specific application you're developing. While still enabling engineers to possibly optimize the processing of those operations. Another interesting side effect of this is that the back end or the graphics engine that d3 renders to could possibly be swapped out. I mentioned d3 renders the SVG and HTML. But you could imagine it rendering directly to HTML5 canvas or even webGL for increased performance. What do I mean by a declarative API exactly? Well, for example, you do not need to tell the browser to draw a circle at pixel 50 by 100, and then another circle at pixel 100 by 175. And finally a line that connects these two circles. For every data point you may have in let's say a JavaScript array repeat this process and continue drawing circles and lines between them. This process would be very tedious and possibly error-prone if for every datum you have, you have to tell it exactly where to draw the circle. And then, exactly how to draw the lines connecting them. I wanted to take a brief diversion to quickly cover how the web works. What exactly happens when you type a URL into a browser and why all of this matters if you want to use D3. So far we've been experiencing D3 through our web browser's console, and have been manipulating elements that have already been on the page. While this is all fine and good, this isn't anything we can't do easily with existing libraries of technologies. What makes D3 special is the ability to easily load and manipulate data, often from external files or sources. And in addition to being the way that the D3 data loading functions work. What I'm going to cover with the respect to the client-server model is actually how most of the internet and the world wide web is possible and work so well. Typically everything that happens in the internet, happens between two or more computers. Most often your laptop, and some external server. And without going into too much excruciating detail, the way the world wide web works is by creating a network of all the computers on the internet, so that they can intercommunicate. Let's say, for example, that you want to go to the D3 homepage, located at d3js.org. And load the index.html page. When you type the address into your browser, represented here by the blue square, the web browser is local on your laptop. And needs to send the request out to the internet, asking for the HTML of the d3.js homepage. Typically it can be found on one, if not many servers on the world wide web. And the good analogy, of how to think about this process, is actually quite similar to the way the postal service works. Let's pretend for a second that phones and actually the internet doesn't exist yet. If you wanted a package from a friend in the old days, the really old days, you would have to send the letter to your friend, requesting that they send you, let's say, a package with your favorite book that they've borrowed. You can think of the host name, in this case d3js.org, as the address of a building or a hotel. Or even in apartment complex and the port of a server can be thought of as a room or apartment number. So, in this case in the analogy of the really old days where we're sending a letter, we would say send the letter to address d3js.org room number 80. I wanted to simplify the diagram a little bit, to show this process and exchange much more clearly. Again, continuing the analogy of requesting your favorite book from a friend, assuming that the Internet and telephones don't exist, you would have to send the letter. Let's assume that you are the client, or in this case, a laptop, and you send the letter with both the destination address and the return address. In this case your destination is d3js.org port 80. And where your friend, in this case the server should send your book as in this case a somewhat arbitrary IP. So this is just an identifier for your laptop and a somewhat arbitrary port number to send that package to or other address and room number. Your friend the server receives this request or the letter for them to send your favorite book back. And this is called the request typically. And then the response your friend or the server sends you your favorite book back. Or in the case of oh, web response it'll be a bunch of HTML to the return address. And once you receive your favorite book, in the olden days you can start reading or in the modern age of computers when you receive the webpage, HTML. You can render it on your browser. And now hopefully that you have an idea of the general request and response model of the client server model where you, the client, or your laptop and its web browser requests a webpage which is server on the internet located at the address you request, send you back some HTML. In the case of D3 code, let's say that we request the index page from d3js.org on port 80, which is the default for all web communication, or at least HTTP. The server sends you back an index.html web page, composed of HTML, JavaScript, CSS, and some D3 code, and on that page is a chart for it to render. Remember that I mentioned any time D3 loads an external file, through its data loading functions, such as json.csv or .tsv, it makes a secondary request to some address. It doesn't have to be the server that it came from, but it often is, and what the server sends back when the web browser makes an AJAXrequest for some data file, in this case, data.json, the server sends back the data in another response which D3 then loads into its callback function to either bind to your HTML or SVG and draw a chart, or visualization based on the data sent back. So, just to recap, when you initially request a page, your browser requests of the host import, some web document, in this case, index.html, that the server sends back. In that html page, if there's an external data loading function in D3 such as d3.json. An AJAX request is made, which then goes back to the same server or whichever address you specify in the background, once the page has loaded, and wait to run its callback function. Until the server sends it its data so it can then build a visualization with the data and the JavaScript, HTML and SVG that was sent in the original response. Now we have had some experience with D3 in the console. I wanted to cover some of the basic structure of a typical D3 visualization. I will be explaining an example from Mike Bostock's tutorial, on creating a basic bar chart and the fundamentals of D3. I chose this example for three reasons. The first, is the tutorial is very clear and thoroughly explains all of the fundamental concepts of D3. Once you finish the tutorial, if you decide to go through it and create this bar chart you see here. You will have been exposed to all of the concepts in D3 necessary to build more complication visualizations, as you will encounter later in the course. The second reason I wanted to go through this code and the tutorial is that it's very easily accessible on the web, so you can go back and review if you feel unsure about any of the concepts covered. But also it's quite ubiquitous and very common to other people have encountered the tutorial. This makes it very easy to share what you've learned and collaborate with others. And the third reason is simply the fact that Mike Bostock is the creator if D3. And by virtue of having built the library knows all the most important concepts. I wanted to give you a high level overview of the structure of Mike's code, to give you a sense of how to organize your own, and also I wanted to explain some of the elements we may not have encountered in the console, in the examples we've been through. At the very top here, we have a script tag, which actually loads our d3 library. Right below the script tag, we have a style tag, which can be used to add styles to the graphics and elements created through d3. Much of the logic of the visualization comes next, wrapped in a draw function, and just a small point, all of these first three things I've covered, are contained within the head tag of our HTML page. As soon as we open our body tag, we put an SVG with class chart to hold the visualization. And finally, the last bit of JavaScript. Loads our external data file and then calls our draw function. Because JavaScript is asynchronous. The code you see here isn't necessarily executed in the order it is written in here. Whenever a browser reads an, an HTML file, it reads it from top to bottom, and parses each line of either HTML, CSS, JavaScript or SVG. But even though a JavaScript function may be parsed, doesn't necessarily mean it will be executed. And one last point of frustration often for newcomers to JavaScript, is the idea of a callback. All a callback is, is a function that gets executed. Once another function completes. We will see in just a second how D3 leverages callbacks. The first line of JavaScript that actually gets executed in this html is the last line that loads our external data file. Once the data file is loaded. And only then does the draw callback function get executed. And again, the draw function is what contains most of the logic to build our visualization. And since the draw function and all of the code contained within it need some data to bind to and visualize. And only when the data is fully loaded as it passed as the argument to the draw function. I don't want to focus on the CSS code above or the data loading below. For this example I only want to focus on the draw function. If you're curious about what exactly the CSS or the data loading functions were doing, I suggest reading through Mike Bostock's tutorial, which is linked to in the instructor notes. We have already seen many of the functions that Mike uses in his tutorial. We have scales and range, select and attributes, a domain, and also .text. The first two lines define the width for the chart and the height for the bars. A second chunk of code here creates a linear scale and sets the range to be zero to the width of our chart. If you think about these values of zero and width, it makes perfect sense. We don't want any of our data points to get placed past zero on our chart, or in the negative region. Nor do we want any data points to extend beyond the right most edge of our chart. A subtlety of this code here is that while I've labeled it as the x-axis scale and while the variable of storing is x, there is nothing specific to this code or its functions which define it as the x-axis. We will see later that how we use it, however, creates the x values. The third group of code sets the width on our SVG chart element. If you remember we hard coded into the HTML an SVG element that had the class chart. So, here we're selecting that chart with d3.select and then changing the width attribute to the width variable. In this case, 420. Keep in mind that this code corresponds to the blue bars I showed earlier, and the blue bars extended from left to right horizontally according to the value of the data. On line 28 here the call to the domain method on X has quite a lot of things going on with it. First off, X was created above here as a linear scale. Remember, however, what I said earlier about d3's chainable syntax. Even though d3.scale.linear.range is a method call, it returns the scale object. So x is actually a scale and not a range. So this call here is actually calling domain on the scale of x. The domain of our data represents the min and max of our data values. You can see here that we simply hard code a value of 0 as the minimum of our domain. The d3 max function takes our data as the first argument and a function to call on that data as a second argument. Notice here that the function takes a single argument, d. What gets passed to this function is actually every datum, so a single piece of data, from our data array, and the function gets executed once for each. So inside of this function, d actually corresponds to a single data point and we get its value. The reason we need to pass a function is that d3, being the data-driven library it is, could have different ways of defining the max of the domain for a given data. So this function, passed as a second argument, allows a generalized max function to work no matter what your data looks like or what the structure is. Inside this function, you simply need to return whichever value from each data point you want to use as the value to compare in the max calculation. Notice also that we don't store the return value of x.domain in any variable. This is because both domain and range mutate the internal state of the scale object, setting some properties on the object itself rather than returning a value. These next three blocks of code are actually where a lot of the magic happens with d3. This first block binds our data to our SVG elements. Now, this is one of the most confusing parts of d3, for newcomers to the library. We first access the SVG chart element. Find every possible group tag that may be in there. And the group tag can be thought of as analogous to the div tag in HTML. It has no visual display, but serves to group and organize content that may be contained within it. We then bind data, passing in the data that our draw function receives, to the .data function, which binds it to the groups. .enter actually returns a sub-selection of the call to .data, which represents every datum that has not already been placed on the page. In this case, in the first call to .data, there are no elements on the page which have bound data to them. So .enter actually contains one element for every point in our data. .append g instructs the browser that for every point in the enter selection append a g element to the chart. And then for each of those group elements we want to transform them according to this function. Now there's a lot going on there I want to unpack it a little bit, but we'll get much more into the details of what's happening with .data and .enter in later lessons, and also learn about other types of selections that aren't necessarily .enter. >From a very high level, this code basically says, look into my SVG. Find whatever g tags there are there. If there are zero g tags, the selectAll will be an empty selection. Attach data to our selection. A .enter basically says, for every point that's in our data which doesn't have a corresponding element in the initial selection. In this case, since our initial selection was empty, because there weren't any g-tags yet. .enter, again, contains one element for every point in our data. .append instructs D3 and for every one of these new group elements, change the transform attribute. Which is unique to SVG according to whatever gets returned from this function. Again if that wasn't perfectly clear we'll get more into those details and specifics in later lessons. I just wanted to show you what it looks like and how to create a data driven chart And these last two chunks of code actually add the visual elements to the page. Notice here that bar is simply a bunch of g tags that have some transform on them. We have not actually put any rectangles on the page or any labels on those rectangles. But since d3 has this nice chainable syntax. And since any call to append puts elements within the element append was called on, in this case bar. We can add direct angles inside of the group tags. And this last chunk of code simply adds the textural label which corresponds to the value of the data point. That was all I wanted to cover from a high level of this code. And just wanted to expose to some of the d3 functions and methods that we haven't encountered yet. And how to apply them to data loaded from an external file Now there are just a few more nuances to the library and steps we need to take before we can go from the source code of our D3 visualization to a pretty graphic in the library. We have seen the source of a complete D3 visualization, in this case a horizontal bar chart, and we have played around with D3 in a web browser console. But how exactly do we go from a source file to what's displayed in the web browser? Every URL has four basic components. Sometimes, if you're using a modern browser, Chrome included, they hide the first part of http:// since it's often common across all URLs. HTTP in this case, corresponds to the protocol that was used to load the page. If you simply double-click on HTML file, with out going to a web server, you may see file:// meaning that it was loaded with the file protocol. The second portion of the URL, in this case, localhost, corresponds to the host or server from which the file was loaded. Since we're running a local web server to serve both our HTML and our data, it's simply localhost, meaning the current machine. The next section of the URL, which come after the colon, in this case 8000, refers to the port. If we think of our host, or our server, as an apartment complex then the port would be which individual unit of that apartment complex we would like to access. So again the host might be the address of the apartment building and the port might be the number of the apartment unit. And finally what comes after the port in this case let's_make_a_bar_chart.html is the file you'd like to load. Up to this point you've learned a lot about the basics of data visualization. You learn what constitutes good data visualization from and you learned what types of visual and coding choices you can make to represent your data. You've seen where data visualization fits into the larger process of data science. And you have also been introduced to some of the technologies that data scientists and data artists choose when they're creating graphics and visualizations of their own. We've had a chance to play with D3 in the browser and work with some code so hopefully I have what your appetite for the types of visualizations we'll be creating in this course. Next we're going to be going over some more design centric elements of data visualization and also how to choose the right type of visualization for your data type. We'll also arm you with a few tools to think critically about the data visualizations that you create and also analyze data visualizations that you see in the wild Your next big goal in this course is to recreate a visualization to improve it. In order to do that, I'm going to be teaching you some design principles that can enhance your graphics and help you prototype. I'll also take you through how to refine a design, and also a few metrics that'll help you measure their effectiveness. We'll be seeing all the different options we have for choosing a chart or a graphic depending on our data. And learn some of the formalism and theory surrounding how to make that selection. We'll also be building a much more complicated graphic, using a library built upon D3, and see how we can engage our audience more. Let's go learn about charts now. In the last lesson, we saw how we can leverage visual encodings to effectively represent and present data. Think of visual encodings as building blocks of graphics. These are components that we can combine in creative ways to construct a visualization. An analogy can be drawn to how we communicate information through text. When writing prose or an article, you construct sentences and a narrative through using different parts of speech. So try to think of the different visual encodings we've covered. As the nouns, verbs and adjectives of graphics Now, you might be wondering why we care about parts of speech. I thought this was a visualization course. Well, I would argue that parts of speech are to sentences what visual encodings are to charts. Just as sentences are composed of parts of speech, which each contribute differently to the overall message of the sentence, charts are composed of different visual encodings, each of which most effectively convey a specific aspect of the underlying data. Wikipedia defines a chart as a graphical representation of data in which the data is represented by symbols. It then goes on to give examples, such as bars in a bar chart, lines in a line chart, or slices in a pie chart. I'll be using the word chart in this lesson in a slightly more constrained manner to mean a common pattern or convention for combining visual encodings or symbols. And while there might be an infinite number of ways you can create a sentence through different parts of speech, in practice, there are a limited number of combinations that make sense, and an even smaller number that people use in practice. Part of this is due to the constraints and rules of language and grammar, but part of it comes from the fact that it's easier to understand patterns that are familiar. For example, you'll never see a sentence that has no verbs and only nouns. I just mentioned that the rules of grammar enforce certain constraints on written and spoken language. Later in the lesson, we will get into a similar set of rules for visualizations and charts called the Grammar of Graphics. But for now, I simply want to show you a few of the most common chart types. I mentioned that there are a finite amount of possible charts. But even so finite can still be quite a large number as you can see here and there are even more charts that are not included. This is a flow chart created by Andrew Abela to help navigate the somewhat overwhelming amount of different chart types. Which in and of it's self, is quite effective. You can find a larger PDF of this graph on extremepresentation.com. Which is Andrew Abela's site. And all the choices of possible chart types, I've seen very great. You always have to consider how familiar an audience is with a given chart type and how long a graphic takes to digest. When I say digest here, I really mean understand and interpret. In the context of data science, when creating visualizations, you should almost always focus on communicating in the most effective manner to solve the problems at hand. Although data artists, or even a data journalist, may be interested in creating a complex graphic to creatively convey information, data scientists' first priority is solving problems. Whether that be through models, algorithms, analyses, or visualizations. When faced with a dataset that you want to visualize, you should inspect your data, the columns, the variables, inspect what types they are, and always choose the right tool, in this case chart, that best represents your data. We will see in just a second all the options and how to determine which chart might be best for representing our given data and conveying a certain message. While each chart type might be slightly better for slight differences in your data, and what you're trying to communicate, in practice you can get by with only a few. In navigating this jungle, I like to often start from first principles. Chart types are simply a set of visual encodings applied to data types, and combined with some relationship between those data. For example, a scatterplot is an x coordinate and y coordinate with a shape, in this case a circle as applied to two continuous variables, continuous being their data type, in which the y value is dependent on the x value, which corresponds to the relationship between them. And combining all three of these things. You get the chart type of a scatter plot. As you can imagine, there are quite a few combinations of these three sets. A set of the Visual Encodings possible, a set of Data Types possible, a set of Relationships between your data types. I think this flow chart does a fairly good job of categorizing the different chart types by utility. But I'll also add that I think a few are missing. And I do have a few qualms about how Andrew chooses his branches about which chart to use given which situation. When choosing a chart type, I usually either start with the type and dimension of my data, or what relationships I'm trying to convey between my different columns. For example, I might ask myself, how many dimensions do I have? One dimension, two dimension, three dimensions. And what type is each? Continuous, categorical. Am I trying to compare two variables, am I trying to show how one variable is distributed? Let's take that last question as a starting point. Let's say I have one dimensional data that I'm trying to see the distribution of. I would use either a histogram for continuous data, and I might possibly want to bin it. Or a bar chart for categorical data, if I might have some discrete values along the x axis that don't have any intrinsic order. If I want to show a comparison of distributions, I'll use either a box plot, or small multiples. As they represent distributions of multiple variables, side by side with each other. We'll get into what each of these looks like in just a second. But I want to mention them as you were talking about chart types to represent distributions of data types and variables. To represent a correlation between two variables where the y variable is dependent on the x variable, a scatter plot is the most effective way and the most commonly known. A scatter plot can be generalized to a bubble chart [INAUDIBLE] Additional dimension in visual encoding to represent, in this case the bubble chart uses size of each of it's circles to represent a third variable. A subtlety of the scatter plot, that the x variable is usually assumed to be independent and uncorrelated with the other x values. What does this mean exactly? Well let's consider time series data. When dealing with time, every data point is implicitly dependant on all the data points that came earlier in time before it. In this situation. We want to use a line chart or a multiple line chart to represent time series data. That one has intrinsic order. And two has data points that are dependent on what came before them. With line charts the fact that every point is connected. Shows a trend in your data and implies that every data point does have this inherent connection between them. A small multiple, sometimes known as a trellis or a lattice plot is a series of charts laid out in a grid. They often represent common data faceted by different categories. In this case we have engineering, operations, accounting, HR, IT, and manufacturing. On the X axis we have different months of the year. And on the Y axis we have different salary expenses for each department. I really love small multiple plots because you can embed any type of chart and they generalize to any type of comparison. Here we've embedded line plots to show how salary expenses vary over months of the year for each department. But we could have just as easily embedded different histograms, maps, or even pie charts. The small multiple was popularized in coin by Edward Tufte, a leader in the field of data visualization. We'll learn more about him later in the lesson. And we'll hear about him throughout the course. Box plots are another technique to visualize multiple distributions in one graphic. Just like a small multiple, a series of box plots allow us to visualize different distributions all in one graphic. The box plot was invented by John Tukey and comes from the field of exploratory data analysis. While small multiple and box plots are often used for exploratory data analysis to learn how your data's distributed. They can also be used to convey certain points and relationships between your data and your variables. For example, in the box plot here, we have a series of experiments, one, two, three, four, and five, measuring the speed of light. And for each experiment we take a series of measurements that are visualized as a single box plot. Here we can see the quartile ranges, and the mean. And we can plot these side by side to see what we likely believe the speed of light to be after a series of experiments. We can see here, the true speed of light is actually plotted in the red line, and is quite a bit lower than all the experiments shown here. Just one last point on the difference between EDA and data visualization, typically in EDA you're trying to discover some information about your data for yourself, whereas with a data visualization you're trying to communicate some information about your data to others. Depending upon your intention, you can use both box plots and small multiples to either learn more about your data or try to convey something to others Here we can see a time series plot of U.S. civilian unemployment rate over time. The data goes all the way back to about 1950, and all the way up until the present time. On the Y axis we have unemployment percent. If you notice it tops out at around 11% and the lowest value is around 3%. Something to always be careful of with your plots is to clearly label and be aware of what the ranges of your data are. Both on the Y and on the X. In this case, since we are plotting a time series, every point is not completely independent of every other point. The X variables here depend on one another. Since the value at time X depends on X minus 1. In more concrete terms, the unemployment in 1970 is some delta from the unemployment in 1969. And the unemployment rate in 1969 is some change from the unemployment rate in 1968. Since we're trying to convey how something's changed over time, a line plot is the most natural and easily understandable of all the chart types. The last relationship I want to cover, is that of proportions or comparisons. If you have multiple categories and want to show how the magnitude of each compares to every other, you can use a stacked or unstacked bar chart. These bar charts, however, can also be used to show how a distribution changes over time between the categories. If you remember from the previous video, much into our charts in this case what the author labels as a column chart can be used to represent a distribution. And if we simply put every column of our bar chart side by side and visualize how it changes, we can compare each of the categories. And last but not least, we get to deal with some food. Pie charts and donut charts convey proportions of a whole. I tend to shy away from pie charts because they can be visually misleading and rather use a stacked bar or simply a table to represent the proportions of the whole. Noah Lorang of 37signals wrote a provocative blog post stating that he only need three charts. At the end of the post, he has a fun quip asking, what three charts would you take with you if you were stranded on a desert island. Before I cover my slightly more than three favorite charts, I want you to use what we have talked about to think about which three you would take with you to best represent any sort of data that you might encounter. In the post, Noah says he would take a line chart, a histogram or bar chart, and the table on his island. For me, I would take a scatter plot to represent relationships between variables, a stacked bar plot to represent comparisons, and finally a line plot to represent trends in time. I often think the most interesting insights come from comparisons and juxtaposition of data and time, so my charts might be slightly biased. Two of my favorite charts, they were not listed in the flow chart, are tables, or simply just text and maps. A table isn't traditionally thought of as a tool for visualization. But sometimes if your data doesn't have any inherent structure or order, a table is the most natural choice. Tables typically are used to represent summaries of data or somewhat disjoint facts. In this example, we'll be looking at states and their corresponding state bird. Since states do have some geographical representation, we may want to represent them on a map. But since State Bird is simply a label or category, it may be hard to represent in one of the other visual encodings that correspond with a geographic map. Typically, with a map, you have either the size or color of some geographic region, or some points to plot. In our case, we simply want to look up what state and find the corresponding state bird. Tables work well when there is no in-hand relation between the data you're conveying. Since we simply want a state to state bird mapping, we can use a table as something of a look up mechanism. Maps are interesting, because they are something of a compound visual coding. A map is simply an x and a y coordinate combined with some geographic context, often the case of latitude and longitude. And when combined, we get a mapping of an x and a y pixel coordinate to some latitude and longitude, which equals a map. I quickly wanted to go over one of my favorite visualizations for its simplicity and power, by Dustin Cable from the Wilden Cooper Center for Public Service. With this visualization, we have many visual encodings going on in the same space. Every point on the map is actually one person from the U.S. census. The color of the dot corresponds to their race as reported on the census. And the x and y pixel position of the map correspond to the latitude and longitude of the census block from which the person reported their race. What's truly stunning with this visualization is that nowhere in the graphic are state or city borders drawn. The natural structure of the United States and the population density across the United States naturally falls over the fact that every dot represents a person, and most the people in the United States are reported on the census. The map we have drawn here only uses two visual encodings, the x and y coordinate for position, and one visual encoding, the color, for the race. There are just a few other geographic charts that I want to talk about. A choropleth map represents some value by color and plots it geographically across a region. Typically, you may see this as States of the United States, which have a different color representing the intensity of some value. Going back to the previous example of unemployment, we might represent the unemployment of every state as some range of colors. A map that's very similar to a choropleth, but uses a different visual encoding to encode its value is a cartogram. A cartogram represents some geographic data, and uses the size of the geographic region to encode often some continuous value. Again, going back to the unemployment example, rather than representing the unemployment rate of a state by its color with a choropleth, we can represent it by the size of the state, geographic region that we draw. And just reviewing what we just covered with the dot map, a dot map could actually represent any shape. In the case of the example I've shown, it was similar to a scatter plot where we represent our data with circles, and how it corresponds to some geographic change. The map we just went over is an interesting combination of a choropleth and a dot map in a way, since it uses some geographic data with a shape, in our case a circle. And some color to encode another secondary value for each point. And as always, there are many other chart types that I'll not cover here but are typically some sort of compound chart in the way a choropleth or a chartogram combines elements from two simpler chart types. In the resources section of the class, you can find an exhaustive list of most every comment chart type that people use. Matt, what are some of the most popular visualizations that you see on Poly? yeah, I think just kind of like the most often used ones because they're so familiar and also because, you know, they're kind of the classics. We see a lot of line charts, bar charts and scatter charts and then a lot of histograms. But it also depends a lot on the user. Like certain users will only make bubble charts, or only make, you know, hit maps. so, if you scroll through our feed, you can see a lot of different types of graphs. But those are the, the most often made types. Okay. And other any unconventional chart types that you see? Yeah. So one fun thing about Plotley is you can kind of invent your own chart types if you like to. We've tried to make it a really flexible environment for being able to use different languages or different programs to be able to draw your graphs. So we don't natively support maps, for example. But people have made maps using different packages from Python or R. People have made network visualizations, which we don't natively support, but Someone has made a couple of those using a language called Julia. And then we've also seen people make sort of just their own out of the box data visualizations. That mimic some type of event that they'd like to show a visualization of. That doesn't even necessarily have a name with a graph type. Okay. As you can see visualizations can take many different forms. And as an author, it is up to you to choose the right chart type based on your data and the types of insights you want to convey to your audience. Choosing the right chart type is an important part of telling your story, but there's more to the story. You have many more choices to make as a designer. Let's look at those. In addition to choosing the right chart type to show different relationships in your data, you can leverage good design principles to communicate clearly and efficiently. Let's examine one aspect of perception that can aid us in the design process. This topic is called pre-attentive processing, and it allows us to instantly recognize parts of a visualization. Let me show you what I mean. Take a look at all these digits, and I want you to count how many times the digit nine appears. How many nines do you count and how many seconds do you think it took you to count them? Enter those numbers here. You should have counted five nines, and I'm note sure exactly how long it took you to count them, but my guess is that it took less than 30 seconds. I think anything underneath a minute would have been reasonable. Now take a look at this set of digits and count how many times the digit nine appears. How long did it take you to recognize the number of nines this time? Much faster, right? It's pretty incredible that such a small change, such as color, can allow us to recognize and instantly process this digit nine more quickly. I want you to take a guess at how fast pre-attentive processing just happened for you. Now, you may not know which of these is the correct answer, which is fine. I encourage you to try each of them out and see how the real world compares to these short timespans. You'll see what I mean when the site gives you feedback. Pre-attentive processing usually occurs between 200 and 250 milliseconds, the same amount of time it takes for humans to recognize emotions in facial expressions. Preattentive processing taps into our automatic processes of vision and perception. When preattentive processing occurs, we are able to instantly recognize an element in a visualization. It's the same reason why this blue bar becomes instantly apparent in this forest of orange bars. Here I'm using color, in particular, hue as preattentive attribute. I could also use color intensity to create the same effect. Here two bars pop out from the page. So color hue and color intensity can be used as preattentive attributes. But there are also other preattentive attributes that can, we can use to highlight information or to lead the eye in visualizations. In Colin Ware's book Information Visualization Perception for Design, he describes four general categories for these attributes. And they are color, form, movement and spatial position. We can change the form of objects, such as their line width, curvature, size or, in this case, the shape. Movement is another form of preattentive processing. For these squares, I'm using a flicker effect to draw attention to one of them. You might have similar fade ins or fade outs for portions of your visualization that are interactive or those that highlight particular data values or trends in a visualization. Finally, spacial position can be employed as preattentive attribute. You might find this useful for drawing the eye towards titles, legends, or annotations. For more examples of preattentive processing check out the links in the instructor notes. As a side note, preattentive attributes can be used together but they may achieve different results. Here, color and form are used. Notice that form either a square or a circle is randomly distributed throughout the grid. But the color attribute creates a clean boundary down the grid. In this example, the reverse is true. Color is randomly distributed to shapes throughout this grid, but notice that form does not do the partitioning of the grid as well as in this previous example. In this second example, the horizontal shape boundary is masked by color or hue. Another yet more subtle technique that you can employ as a visual designer is the use of negative space. Negative space is developed around and between the shapes or forms of objects. Take, for instance, this classic example of Rubin's vase. Are we actually looking at a vase here or are we looking at two people face each other? You might be more familiar with examples of negative space in company logos. For example, FedEx hides an arrow between the capital E and the letter x. This design reinforces the company's function as shipping service. Other logos include the television network NBC with its peacock shown here. And the white panda from the World Wildlife Fund. What designs or logos have you seen that use negative space? I'd like you to share an example in the discussion thread titled negative spaces. After you've posted your example, check this box to continue. You might wonder why we should care about negative space and its relation to data visualization. And well, we should pay attention to negative space, because it communicates something about our data. Let's look at two examples. This first one explores the London's cholera outbreak in 1854. John Snow documented deaths around the community to determine what might be the cause of the epidemic. He created this stop map by recording the location of each death by a bar. The height or the length of these bars indicate that more deaths occurred in a particular location. Knowing this information, I'd like you to answer a question. Which of these locations have no recorded deaths? You can use the map that's linked in the instructor notes to figure it out. The answer is the Brewery. Looking at the map, you'll notice that Edward Street and Portland Street have a couple deaths along them. The Workhouse shows exactly five deaths over here, but the Brewery has no deaths along its borders. So what is exactly so special about the Brewery? Why would no one have succumbed to cholera there? The lack of deaths in the brewery is perhaps a less salient part of John Snow's map, but it's certainly an interesting one. As it turns out, the brewery gave an unlimited beer allowance to its workers, and since the fermentation process killed the cholera bacteria, none of the workers contracted the disease. You can read more about the outbreak and John Snow's discovery in the instructor notes. His work in visualization with a start of modern epidemiology. John Snow demonstrated how data visualization can be used to trace the spread of disease. In this case, a single pump carrying contaminated water throughout a community. Here's a different interactive visualization that comes from The Guardian, which encodes missing values in a slightly different way. This visualization dis, displays the extent to which gay rights are protected by law in each of the states as of May 2012. States that have no laws or that are unclear about the laws have this light grey coloring. And states that prohibit or ban gay rights have the striped pattern. For example, many states in the northeast have employment laws which prohibit discrimination based on sexual orientation and gender. While most states in the southeast and many in the midwest lack such employment laws. This is an interesting visualization because it makes use of texture or pattern to represent different aspects about the states. For example, this outer red ring displays many states that prohibit or ban same sex marriage. And this darker blue inner ring shows a few states that do not permit adoption by a single person or joint adoption by same sex couples. Between this visualization and John Snow's map we can see that there are many ways to encode values of zero, missing values, or perhaps other categorical values of data like in this visualization. So now I'd like to turn it over to you. Another design component that can aid you in your work when creating visualizations is color. This bar chart displays the count of certain cuts of diamonds, and it was made using the R programming language. I'd like you to take a few minutes to think about how color is used in this chart. Do the colors add to the visualization or do they distract from the visualization? Come up with a few reasons for yourself. Once you're ready, check this box and submit the answer to continue. Keep in mind that you don't need to submit an answer here. I just want you to think about those question for a minute. Overall, I would say that these colors distract from the data. The colors shown don't appear to be chosen for any particular reason. In fact, they're actually the default rainbow colors for the ggplot2 package for the R programming language. These colors are also quite bright, which strains the eyes, and above all, each color doesn't actually convey any additional information about the data. The labels on the left side of the bar plot are enough to indicate which bar belongs to which type of diamond cut. This actually makes the use of color redundant since both the labels and the color are indicating the cut type. You also might have thought that the legend at the right here is unnecessary. We could simply design this visualization with the labels at the left in the graph, decreasing the time for the reader's eye to bounce between the legend and the main data display. Now, I know this is a small display, but this makes sense for larger visualizations where the eye would be scanning across an entire page. So, when it comes to color, what should you do? My first piece of advice comes from the design field. Get It Right In Black And White. Before you begin adding color to your data visualization, you should determine if you need color in the first place. Many times, black, white and shades of grey will be enough to effectively convey your information. Secondly if you are going to use color, consider using less intense colors, such as natural colors or pastels. You can also add some gray value to bright colors, to make them less vibrant. Colors with higher gray values have a softer feel, and the eye can concentrate on them for longer periods of time. Rainbow colors, primary colors, and other bright bold colors, can create noisy visualizations which strain the eye. Even if all these bars were a bright red color, I probably wouldn't want to stare at it too long. As you encounter graphics, you should look for this to determine how this is affecting you as a viewer. My final tip is to make color selections thar facilitate communication. In this example, I used a complimentary color to draw attention to the count of ideal cut diamonds. You could use a similar strategy if you want to highlight particular data points in a graphic. Perhaps you've come across some good and not so good examples of color use in data visualizations. I'd like you to go grab a data visualization from the wild, be it the internet, a newspaper, magazine, or perhaps even a scientific paper. I want you to describe how color is used in the graphic, and whether or not you think the use of color is effective. Maybe you can think of some ways the designer might have done something else. Share your example on the discussion thread titled, Communicating with Color. In your post, describe how color is used. And how it encodes data, or maybe it's doing something else instead. Once you've written your post and submitted, check this box to continue. Here's one final piece of advice before we dive into the code of data visualizations. Be careful with color. Color can be a tricky component of data visualizations, but it can also encode data and help you viewer understand what's most important about the graphic. Stephen has written an excellent article on practical tips on using color. I've included a link to it in the instructor notes. I'd like you to read this article and then answer this next question. Which of these statements is true about color? I want you to select any of the statements that apply. The first statement is not correct. High contrast, rather than low contrast, between text and background is optimal for viewing data within a table. The same is true if you plan to display values directly on your own graphic. The second statement is true. A sequential palette like this one, would indicate lower amounts of sales and low levels of saturation, and higher amounts of sales with more saturation in the green color. This third statement isn't correct though. Darker and brighter colors would work better for smaller data points. If the points were large enough, pastels might be a good option. But if you don't have too many points in a graphic, you could also enlarge over the points to aid the viewer's perception. And finally, this last statement is correct. There's no value in using cylinders, lighting effects, or drop shadows in your data visualizations. All of these effects simply obscure the data. Here's another bit about color. Contrary to popular belief, the rainbow effect is not an optimal color scale for human visual perception. This visualization displays the endothelial sheer stress, or simply the pressure on different parts of artery walls. Areas of low pressure, as shown in blue are troublesome and can lead to heart attacks. Michelle Borkin, a researcher at Harvard School of Engineering and Applied Science, conducted a study to determine whether visualizations like this rainbow model, could be improved to increase the accuracy and speed of the diagnosis of heart disease. In her study, she tested whether two-dimensional models were better than the three-dimensional models. So here's the three-dimensional model, and here's the two-dimensional model. But you might notice that she also tested something else. She tested whether the standard rainbow colors, which are found among many default settings in visualization software outperformed the type of color palette shown here. So, what type of color palette is shown here? Type in your answer here. This is an example of a diverging color palette. Steven Few's article mentions color palettes towards the end, on page nine. Diverging color palettes or dual-ordered color palettes typically have two colors that are saturated on either end, and then a white or a grayish color is located in the middle. The results of this research were staggering. Diagnostic accuracy increased from 39% to 91% for the two dimensional model shown here. In terms of perception, this should make sense. The two dimensional model readily reveals all portions of the arteries, while the three dimensional model can hide links in the artery from view. Some might argue that the 3D model can be rotated, but it's important to note that the 2D model can be viewed all at once within the span of the eye. This allows us to make comparisons more quickly and easily. I think one of the key takeaways from this research, is that simple visualizations are generally better. You can read more about this visualization and all of Michelle's research in the instructor notes. For a Readers Digest version, I recommend looking at the slides she put together for the 2011 InfoVis conference. Maps can suffer from poor coloring as well, let's look at a few examples on this catastrophe blog. This first map was submitted by a wind energy company looking to build more wind farms. The map shows the expected amount of noise that the wind farm was going to generate. As you can see, this map suffers from high contrast and bright colors. This map further down is just a sea of black labels. You can't actually make out many of the labels in here. If you have more time, I recommend reading through some of these examples to get a better idea of how you can utilize color in your own visualizations. The good news is, is that even if you're not sure which colors to use, there's a wealth of resources at your disposal. Cynthia Brewer, a Professor of Geography at Penn State, developed ColorBrewer. Which contains a set of web, print, and color blind friendly colors. While her work mainly focused on maps, many of the color sequences, including sequential, diverging and qualitative can be effective choices when creating most data visualizations. And if you want even more color palettes, you can check out Adobe's cooler to either pick popular ones, or create your own. The links to those websites can be found in the instructor's notes. My final and perhaps most important piece of advice is to respect your audience. Use color scales that everyone can see. If you're looking at the circle on the screen, then you've likely noticed the number 74 disguised as green dots among the many red dots. If you can't see the 74, then you may be part of the approximately 10% of males and 1% of females who suffer from a color deficiency known as colorblindness. Red and green colorblindness is the most prevalent, but there are other types too. Check out the Wikipedia article in the instructor notes to learn more of the details. We've also included some colorblindness tests in the instructor notes and a link to some recommended color palates. Here's a specific example I want to show you so you can see how other audience members might view the graphic. You don't want to create a visualization that confuses or alienates your readers. And that's why you want to avoid using standard red and green colors. They're often hard for those who are color blind to interpret. The difference between these red bars and this green text may seem obvious to you, however, not everyone will see it this way. Some viewers in your audience will see this. Here there is little to no difference between the red bars that we say before and the green text. And now I want to make a subtle distinction, here. I'm not saying that you should never use red or green hues, because they can be used in visualizations. This graphic was re-released after a color correction from the Wall Street Journal. It's a heat map that shows historic trends for unemployment in the United States. The rose represent the months of the year and the columns represent one year of time. The key here is that hues of red and green were used in such a way that people even with color blindness could still make out the differences. Now this is a pretty incredible interactive graphic. And it also makes use of a diverging color scale. But, if you want to see something even more incredible, I highly recommend that you check out the remake of this visualization in the instructor notes. Alberto Cairo, a professor at the University of Miami, redesigned this graphic, and you can also find it in his book, The Functional Art. To wrap up this bit about color, I'd like to leave you with a quote from Edward Tufty. He summarizes the difficulties with color well. In his book envisioning information he writes, and leaves us with this bit of information about color. Above all, do no harm. You just learned about some design principles that can enhance your communication of your data story. Including pre-attentive processing, negative space, and color. But there's actually more that we can do. It's important to think about data visualizations as a cohesive whole, and how they might be perceived by the viewer. In this next section, we'll go over how to remove elements from visualizations and also a few metrics to measure their effectiveness. Let's go over a few examples now. Previously, we learned about how to represent data using different types of graphs. When you're choosing which type of graph or chart in order to display your data, it's not only important to think about what you're going to put in, but also what you're going to leave out, which brings us to chartjunk. Chartjunk is a term that refers to all visual elements in charts and graphs that are not necessary to comprehend the information represented on the graph. Or, that distract the viewer from this information. Markings in visual elements can be called chartjunk if they're not part of the minimum set of visuals necessary to communicate the information understandably. Let's go through a few examples. Examples of unnecessary elements, which might be called chartjunk include the use of heavy or dark grid lines, unnecessary text or inappropriately complex font faces, ornamented chart axes or display frames, pictures or graphics within graphs, and the use of shading or 3D perspective. This visualization shows how chartjunk obscures the data, which is just five simple numbers. One, two, three, four, and five. We see here ornamented chart axes which obscure the actual numbers underneath, and also the use of shading and textures on both the bars and the background. Another kind of chartjunk skews the depiction and makes it difficult to understand the real data being displayed. Examples of this type include items depicted out of scale to one another, like the monstrous teeth shown here. Let's look at one more example. In this visualization, we're looking at the average price of one carat diamonds between the years 1978 and 1982. What this is trying to convey, is that while the price of diamonds peaked in 1980, there's been a sharp decline in the two years leading up 1982. We can see here that the price has fallen from $60,000 to $20,000 given the decreasing demand. There are a few problems with this visualization, which makes it hard to interpret as a viewer. Let's start with the picture of the woman. While this particular visual is interesting, it takes up a great deal of space and isn't adding any additional information. Also, the underlying chart axes make it hard to detect where each point on the line is in relation to the year and price. The grid lines, which show something like graph paper, are meant to convey this is something chart-like but they detract from the main visualization. Here, the data is actually only represented by this red line, everything else about this visualization, including the picture of the woman, the grid lines, and the background, are all detracting from the main event. Which is that the price of diamonds has fallen from the years of 1980 to 1982. Let's look at an example of how we can improve this visualization to make it something that is much more clear. Here we see the same visualization with the woman and the price of diamonds between the years of 1978 and 1982. By removing the elements such as the picture, the gridlines, and putting standard axes for both X and Y, we can see the same information much more clearly. We've also added dots to indicate the data points for each of the x and y values. This graph while not as salacious as the original is much easier to read. And much more clearly shows the relation between the years and the price of diamonds over time. Great! Now time for a quick quiz. Which of the following could be considered chart junk? Please select all that apply. In the previous example, we saw how we could make visualizations more clear by removing extraneous elements. We can conceptualize this relationship using something called the data to ink ratio. The data to ink ratio was defined in 1983 by Edward Tufte, and describes the ratio of ink used to describe the data to the ink used to describe everything else. So what is a good data to ink ratio? Typically, we think of high data to ink ratios as being very good. It means that a large portion of the ink used in a visualization is used to describe the data points themselves. A low data to ink ratio is usually very bad. And describes a visualization in which the majority of the ink is not used to describe the data, but is actually describing something else. In general, we want to have the highest data to ink ratio as possible. If we have a low data to ink ratio, we have extraneous elements in our visualization that should be removed. Let's look at an example. In this example we look at two graphs that are representing the same information. On the left hand side, we have a visualization that has a low data to ink ratio. Notice, the extra elements in the visualization that can be removed, such as the blue background, the horizontal and vertical grid lines, and the outer black border. What this shows is that a large amount of the ink used in this visualization does not directly describe the data at hand. On the right hand side, we see a visualization with the same data with a high data to ink ratio. The only ink used is ink that is actually describing the data directly. Comparing both visualizations side by side, the one on the right is not only more pleasing to the eye but it is also much easier to understand. When we're building data visualizations, we always want to strive for as high of a data to ink ratio as possible. Let's go through a few more examples of how we can take a visualization with a low data to ink ratio or extraneous elements, and reduce it down to something that is simpler and much easier to understand. In this example, we're going to take a visualization and try to improve it's data to ink ratio. Here, we have a bar chart showing the number of calories for various types of foods. At first glance, we can see examples of bad visualization techniques that we've discussed previously. Such as this busy background, poor color choices, and the use of 3D shadow and gradients. Let's walk through step by step how we can simplify this visualization and increase it's data to ink ratio. First, let's remove the wood background from the outside and the gray background from the inside, increasing contrast and legibility. We can also remove redundant labels, such as the legend and some of the titles as this information is encoded elsewhere. Now that we have removed the background, the heavy borders separating the various elements are no longer necessary. So let's take those out too. Remembering our color theory, we shouldn't use more than one or two colors in the visualization unless it is encoding some value in the data. The color of these bars don't reflect any differences between the foods. So let's remove all of the colors except for the food of interest. In this case, bacon. Great. We've already improved the data to ink ratio quite a bit, but there's more that we can do. Recall that 3D graphs, including gradients and shadowing, can be misleading. So let's flatten out those bars and remove the drop shadows to make it more clear. We can also make the data stand out by reducing the boldness of the labels and the gridlines. If we want to go even further we can remove the lines entirely, and encode the values directly into the bars themselves, like this. Comparing the two visualizations side by side, you can easily the effect of improving the data to ink ratio. The visualization with the high data-to-ink ratio is far more clear, more interpretable, and that's all the elements you need for a great visualization. Now let's do an exercise called Junk Yard. Find an example of a data visualization that contains chartjunk and describe the elements that are considered chartjunk. Post your original image, your description and a sketch of the improved version of the visualization. You don't need to re-create the data visualization precisely, but you can if you're familiar with visualization software. The next thing we need to cover is something called the Lie Factor. The lie-factor is a metric that was created by Edward Tufte that describes the integrity of a graphic, or how well a graphic actually represents its underlying data. You compute the lie-factor by dividing the size of the effect, as shown in the graphic, by the size of the effect shown in the data. Typically, we want the lie-factor to be within 0.95 and 1.05. A lie-factor of one is ideal, because we would have the exact same effect shown in the graphic as it is in the data. But due to some jitter with we how we represent data in graphical form, having a lie-factor within this range is typically seen as very good. A visualization with a lie-factor in this range has high integrity, and is representing the data accurately. Now that we know what lie-factor is, how do we calculate it? So, let's recall that lie factor measures the difference between the effect shown in the graphic and the effect seen in the data. First, let's look at how we would calculate the size of the effect shown in the graphic. First we'll find the difference by subtracting the second value from the first value seen in the graphic. Then we'll compute the change by dividing by the first value. We'll need to add absolute value bars here, to account for negative change. Multiplying this by 100 gives us the change as a percentage. We apply this method toward the graphic and the data and then divide this entire quantity to get our overall y factor. Now let's take what we've learned about calculating life factor and apply it to a real-world example. Here we have a graphic from the New York Times that is showing the fuel economy standards for autos between the years of 1978 and 1985. We have all the information that we need to calculate the life factor for this particular graphic. We have the second and first value for the changes seen in the graphic, and also the second and first value for the change that is seen in the data. Let's use these four numbers to calculate the live factor. Given that the second value is 27.5 and the first value is 18, what is the size of the effect in the data? Good. By taking the second minus the first and divided by the first, multiplying that all by 100, we see that the changes shown in the data is 53%. Given that the second value is 5.3 inches and the first value is .6 inches, calculate the size of the effect as shown in the graphic. Good. Using 5.3 as our second value, subtracting it from the first, dividing and multiplying by 100, we see that the change, as shown in the graphic, is a whopping 783%. Using 53% and 780%, calculate the lie factor for this graphic. Great! By dividing 783 by 53% you get a lie factor of 14.8, which is very large. Given this lie factor, we would say that this particular visualization is not representing the data accurately and has very low integrity. Thanks Ryan. Edward Tufftee, is one of the preeminent data visualization experts alive today. And formalized what we often associate with good effective graphics. I now want to talk about Leyland Wilkinson, another prominent statistician, who formalized a theory surrounding the components of graphics. And how we might use them to create effective and engaging charts. The grammar of graphics is a formalism surrounding the principles of creating visualizations. Leland Wilkinson invented the theory in his seminal book, the Grammar of Graphics in 1999. To make reasoning and thinking about graphics and charts easier. You might be asking yourself, what exactly do you mean, when you say the grammar of of graphics is a visualization theory? I thought visualizations had to be physical, with lines, circles, axis, and represents some underlying data. Well, Leland Wilkinson invented this theory in his seminal book titled by the same name to make reasoning and thinking about graphics easier. Think of it as defining a set of best practices for developing and iterating on a data visualization. At its most fundamental level, the grammar of graphics makes a distinction to separate content from aesthetic. Or in our case our data from our visual presentation of it. Now this may not seem like a groundbreaking theory but before the grammar of graphics researchers, artists, and developers often coupled the information they were trying to communicate very tightly with their medium of communication. In this example, we're going to be graphing school attendance over days of the school year. You can see here our data represented as dates and attendance in a tabular form, and if we try to apply the grammar of graphic and apply a line plot aestethic to this data, we get the green line we see here. Can you think of an advantage of using a visual representation of data as opposed to a tabular representation of data. One thing that's much easier to interpret from our line plot is any trend in the data. We can see here the short dips in attendance, that occur fairly regularly with some period, these might be weekends. And we see another fairly large drop towards the end of the year. And while the flu may be apparent in the tabular data due to the sharp and somewhat extended decline in attendance. It is much easier to spot with the visual representation of the data. And other more subtle patterns, such as weekend dips, may be impossible to notice from the tabular representation alone. This is due to the fact that is it not dipped to zero or close to zero. Let's say because there is weekend classes or extracurricular activities, and is only apparent when you look at the pattern over time of the periodic activity of ups and downs. Let's say, however, that I want to know how many students were in school on January 14. Since we're interesting in simply looking up a specific attendance on a specific day, the table is much easier to understand as we can look to the exact row we need. And look across to the single number that represents the attendance for that day. Often this behavior of drilling down to a specific datum, in this case January 14. Can be incorporated into a visual graphic through animation and annotation which is actually what Dimple.js, the library we will use in just a second allows us to do. But in this example of a static chart is much easier to look up the attendance for a single day in the table. Rather than have to look at a potentially large and nuanced plot of days and go across to attendance. Let's assume that the school also kept attendance per grade. In this case, we've added a third column, grade, to our data. So each row now represents for a given date and a given grade. How many students attended school on that day. Now if d3 or whichever library we're using, they implement some of the principles of the grammar of graphics wasn't so flexible. If we've added another column to our data and it was tightly coupled to how we represented it. We may have to redo a bunch of work we previously done to draw the same lines, to draw the same axis's. But in our case, and we'll see later when I go through some live code examples. Adding another column, or in this case a categorical variable, allows us to keep a lot of aesthetic and reapply that aesthetic. In this case, three times. One for each grade. And if our data set had grade 12 in it, we would have a separate line for 9th, 10th, and 11th grade. Something interesting we see hear is that it appears 10th graders were not affected by the flu. While we have 9th and 11th graders with a severe dip in attendance during the later winter months. 10th graders, for whatever reason, have seemed to avoided the flu. Due to the flexibility of the grammar of graphics, we were able to apply the same aesthetic, in this case, a line, and the same axes to different data. In this case, data that has a great column added and is categorized by day. So instead of having to redo all the work of specifying how to draw a line. And how it integrates with our data. We simply split up our data by grade and draw in one line for each category. In this case, the grade Now that you've seen how the theory of the grammar of graphics applies to a concrete data visualization what advantages might there be in separating the underlying data from the presentation of that data? And what problems might arise if you try to couple the data you're trying to visualize with the method of visualization and the aesthetic of that visualization? The grammar of graphics was not created purely for logistical reasons though it does have that nice side effect of not having to repeat work if specifications change. By separating the underlying data from the means of presenting that data, you can think separately about each visual element and the structure and form of that data. This allows us to both transform and manipulate our data without having to worry about the visual representation and what might get messed up. And the last great effect I'll go over of separating our data from the visual presentation of that data is to allow for very interesting collaboration across teams. Let's say possibly between a designer who works on the visual aesthetic separately from developers or engineers who might work on transforming and merging data. I don't want to go into the specifics of each of the grammar of graphics very abstract principles as seen here as variables, and algebra, scales, statistics, geometry, coordinates, aesthetics, and our renderer. And even though you may think you're familiar with variables, in the context of the grammar of graphics this is slightly different than JavaScript variables for example. And while you may think you understand geometry and possibly have studied it in school, the geometry of the grammar of graphics specifies is slightly different than the geometry many people are familiar with. Hopefully by tying each of these very abstract principles to associate d3 concepts, such as the d3 data loading, the d3 scale link. Appending rectangles, circles and lines and using CSS to style a graphic we can make the grammar of graphics theory much more concrete. Also, since d3 has a very chainable API this concept of a pipeline fits very naturally with how d3 creates graphics to render on a webpage. On the left side here, we have a box labeled Source, which we can think of as our raw data file. Maybe a CSV, or in this case a JSON file called my-data. And as we go through the pipeline of the grammar of graphics, we can think of it as applying a different transformation to each step. Going from source, to variables, to algebra and so forth, until we render the final graphic on a web page. In D3's case, the renderer is simply the web browser and the browser displays the final graphic in the form of a webpage. Going from a JSON source file, in this case my-data.json, into what the grammar of graphics calls Variables, is implemented by D3's data loading functions. Specifically, D3.json if loading a JSON file. When called with a data file, D3 makes an Ajax request to load whatever your data file is. In this case, my-data.json, and turns it into an array of JavaScript objects. I don't want to get too hung up on the specifics of each stage of this grammar of graphics pipeline, or try to relate them to d3 junctions that we may not have encountered yet, such as nest, scale, and layout. But I did want to cover some of the more common d3 functionality and how it relates to the grammar of graphics. In this pipeline, once we have our JavaScript array of JavaScript object literals, nest is a function that I encourage you to look up. But it simply groups our data, d3.scale transforms a continuous or a categorical variable into something that a web page can display, such as a pixel value or a color. The d3 layout function is a convenience function that allows us to apply a common transformation, according to a set of predefined chart layouts we might want, such as a pie chart, a histogram or a graph. .append in d3 is what actually inserts our SVG or HTML elements, which we've already seen. In this case, .append rect puts rectangle SVG elements. For every data point, .attr changes some attribute of whatever we're appending. In this case, rectangle .attr x, changes where we want to position our rectangle, its x coordinate, and specify the value where we want to position it. And last but not least, we can control the aesthetics of our visualization, either through d3 and specifying attributes on the style, or by using CSS selectors and CSS specification to, in this case, fill our rectangle with a green color. Once we chain all these functions together, according to this pipeline the web browser takes this specification and renders a web page filled with all the graphics that we've specified across the chain. At its most fundamental level, the Grammar of Graphics makes the distinction to separate content or data from the aesthetic. In this case, the web page we're visualizing. This may not seem like a ground breaking theory, but before the Grammar of Graphics, researchers, artists, and developers often coupled the information they were trying to communicate with the medium of communication. That is all I want to touch on the Grammar of Graphics for now. But I encourage all of you to look at the extra resources provided if you either want to dive deeper to what some of these specifications of the Grammar of Graphics mean, or the d3 functions that correspond to them. We will re-visit this concept of separating data from presentation throughout the course, and is one of the most powerful design decisions of the d3 library. In the boxes below, input what D3 function or web technology transforms data from one stage of the Grammar of Graphics pipeline to the next. For example, in the first box, what D3 function or web technology transforms a source data file into variables? And the dot, dot, dot here represents the middle of the chain, which for sake of simplicity I omitted. But the second box represents the transformation from coordinates to aesthetics. To go from a source data file to what the grammar of graphics calls variables, we can use any of D3s data loading functions. Here I input .JSON. But you can also have put in D3.CSV, or D3.TSV to load data. And to go from coordinates to the aesthetics of our visualization, you could either use CSS or D3 style function to attach styles directly to the elements. Now that we've seen some of the most common types of charts and learned about how the grammar of graphics helps us separate data from our visual representation of that data. I want to show you to how to put this theory into practice using D-3 and Associate Technologies. As covered in Lesson One. The visualization stack for different technologies can go pretty deep. At the top of this spectrum, we have graphical tools such as RAW or Excel. They let us very quickly and easily create predefined charts for our data, but lack flexibility. At the low end of the spectrum are technologies like Canvas, WebGL, and SVG itself. These low level tools at the bottom of the spectrum are the most flexible but give you an interface similar to a painter. You must specify pixels and colors to do something even as simple as drawing a line. And just forget about making dynamic charts and binding data. Since we will be working somewhere in the middle of this spectrum when working with charts, I do not yet want to deal with all the complexities of raw D3. D3 is often confused for a charting library, when in fact they exist at one level lower and also one level below the grammar of graphics. And think of D3 as the building blocks that someone might use if they want to create a charting library with Excel-like plotting functionality. And that is exactly what many people have done. We will be using a library called Dimple.js for the slide coding example. It's implemented on top of D3, which in turn is implemented on top of SVG, JavaScript, and HTML. And provides us a very nice abstraction for building charts, and allows us to think in the way that we might want to when concerning the grammar of graphics. Shown here is the homepage for dimple js. You can find it at dimplejs.org. As I mentioned, dimple is a library built atop of d3 that allows us to work at the abstraction level lower chart. Rather than lower level abstractions like visual end codings, such as shape, scale and positioning. The reason I'll be using dimple.js instead of another charting library is three-fold, as outlined on their site. Dimple is built atop d3. Has a very gentle learning curve and designed for analysts. And the last reason and what's pretty unique to dimple is that it exposes the native d3 objects. So if you do want to get more complicated and ween yourself off of using all of dimple's convenience methods. You can access the underlying d3 objects themselves. As I mentioned dimple.js exists as a tool to make business analysts more productive with charts. But to allow the flexibility to extend the visualizations for power users. Even though we saw d3 in lesson one, we only manipulated HTML objects and a little SVG, and did not get into any data driven operations. We will be using d3 itself to create interactive visualizations and animations in lesson four. But for now, since we're only creating charts and since many awesome libraries exist. They abstract a lot of the complexities of building charts yourself with d3, we'll be using the libraries instead. This pattern that d3 defines to bind data to some elements on the page is often one of the most confusing topics for newcomers to d3 to understand. Most often due to the .enter and .exit commands you can call on your data. These are only really relevant if you're adding and removing elements on a given webpage in an animation, transition, or interaction. They are necessary, however, for any simple visualization you do, even if you don't have any interaction or animation in it. Rather than explain this pattern now and having you wonder why there's this dot enter, or how it could be used. I'll save the explanation for lesson four when we will fully understand what's going on behind the scenes here. And how we can leverage it to create some pretty awesome interactive animations and visualizations. For much of this class we will be working with the data set of World Cup game statistics. Each row of our data set represents a single World Cup game, excluding preliminary games. And each column represents some piece of information on the game. Here we have the year of the World Cup in which the game was played, the time the game happened at. The full date including the day and the month. The two teams that played, team 1 and team 2. The number of people who attended the match in person at the stadium. Which stage of the World Cup the match occurred in. The final score of the game. The first number representing Team 1's score. And the second number representing Team 2's score. And whether or not the game went to penalty kicks. One point on this is that penalty kicks only happen if the game was tied by the time it ended. Which chart, type of the charts we've covered earlier in this lesson do you think is most suited to present the total attendance for a given year of the World Cup? In other words, you would aggregate all the rows of the games for the same year and sum up the attendance for every one of those games. And also think about, why would you choose that chart? Please choose only one of the chart types below that you think best represents the data, and also think about why you've chosen that chart. Rather than telling you which chart I would choose and why, since we have the power of a web-based visualization library at our disposal, dimple.js, you do not have to take my word for it. We can experiment with each of the chart types. A common theme that we will be bring up over and over again throughout the course is the process of iterating on a visualization. This is often called prototyping or sketching. I wanted to show you the process I went through to come to my own conclusions about the chart type and hopefully make designing visualizations seem much less mysterious. And since there is never truly a right answer with visualizations, just like there's no right way to write a book or a news article, once empowered with the insights I will now go through, you can hopefully extend and adapt my visualization to make it your own. We will see later in this lesson why some of the design decisions that the creator of D3 made makes this process of iterating and experimenting with visual displays quite seamless. And sometimes, even if there is a right or best chart to visualize your data, you often don't know ahead of time how the data will interact with the aesthetic of your visualization, including things like layout, color, scales, and how will it interact with the web page itself. We have already seen which aspects of the grammar of graphics the creator of D3 chose to implement in his design decisions for the library, and how this makes the process of iterating and experimenting with visual displays quite seamless. If we try to navigate to local host, port 8000 with our web browser, you see that nothing's being loaded. This either means that we have not started our server yet, or there is running on a different port. In our case, we haven't started the server, so let's go ahead and do that. Switch over to your terminal application. And first check which directory you're in with the Unix present working directory command. You can see here we're in the Udacity home folder in the data visualization folder. So this I think's where our files are, but let's just double check again using the LS Unix command to list the files. We can see here we have basic_charts.html, which is the file that contains our HTML and JavaScript to display our visualization. And we also have world_cup.tsv, our data file with information about the World Cup games. Next we need to start the web server to serve both the data file since D3 uses AJAX to load external files and our HTML file so that we don't run into any cross origin request issues. I'll be using Python's built in module, SimpleHTTPServer, to serve my files on local host port 8000. As you can see here, Python tells me we're serving HTTP on 0.0.0, which is an alias for local host and port 8000. One last note here is that we need to load in the dimple.js library in addition to D3. Let's go to our text editor and look at our template file that we'll be working with. As you can see here, it's a pretty standard HTML file as you've seen in lesson one. And as you can see at the top here, we first load in d3.js from D3's site. And the second script that we're loading in is dimple.js from dimple's site. Now it may not seem like a big deal but it's important that you put the script to load the dimple library right below the script to load D3's library. Since D3 should be loaded before dimple.js gets loaded. As you can see here, in the head of our web page, we have the familiar draw function which will get called with D3 loads in data. And what we have here is a bunch of code to create a chart in Dimple.js. I don't want to go through this just yet, but I want to show you the structure of the file we're working with. And just at the bottom here we have the familiar script tags in the body which makes a standard call to D3 to load in our tab separated values file world cup.tsv. And once our data gets loaded we'll pass the data to our draw function which we defined above. For this live coding session, I want to make it interactive. And I'll actually be working from Chrome's debugger and JavaScript console, once the AJAX request has finished, and my data has been loaded. To do this, I can put a debugger statement inside the draw a callback function. To make sure that the AJAX request has completed, and that my data has been passed to the function. You can set up any JavaScript debugger, by the keyword debugger, and end the line with a semicolon. When Chrome loads the page, it'll first call our d3.tsv function to load world_cup.tsv. Once the AJAX request has returned, it will pass the data file in a JavaScript object to our draw a callback function. And once our callback function is called, code will execute until it hits the debugger statement, in which execution would stop, and it will put us into the Chrome debugger at this exact line. Well for the debugger to actually catch, you first have to open up the Chrome JavaScript console. I can do this on a Mac by using Cmd+Option+I or by simply navigating to the toolbar, looking under the Tools menu, and going to JavaScript Console. As you can see here the console's load in the bottom, but since our page is already loaded there's no debugger to catch. Let us try to refresh the page and see if the debugger will catch. As you can see here in our code the debugger stopped execution at line 19. To actually play around with the execution context of our draw function and inspect what our data is, and what variables are in scope, let's navigate to the console tab of the debugger. Inspecting some of the variables just for a sanity check, we can print out data and see that we have 836 data points. Opening up this array, we can inspect what each object looks like. In this case we see attendance, date, goals, and so forth. So every property of this object represents one of the columns of our data set. But this might be hard to see if we want to inspect our entire dataset, since we have to open up every one of these objects individually. A little trick of the Chrome debugger is it has a utility function called .cable that we can call like we can call console.log. This is very similar to console.log. But rather than just printing the naive string representation of a variable, if the variable is in some collection, be it an array, JSON, or what have you, the table function instead prints out a nicely formatted spreadsheet in the console window. Let's go ahead and call console.table on our data array. This takes a second since we have so many data points, but if you can see here, council.table has printed out all of our data in a nice tabular format. It's easy to scroll and inspect. Scrolling to the top of this, you can what the field names are. In this case, attendance, goals, penalty kicks, referee, stadium, and so forth. And we can also see here that we have the year, the time, and the date. You might want to be careful with the console.table function. As you noticed, it took a second to load. This can get quite unwieldy and potentially crash your browser if you try it with a large data file. As you can see, the structure is similar to what we mentioned in the quiz, and all the columns should be identical. The variables of interest here are the year column and the attendance column. How might we best represent attendance as a function of year? Remember what we mentioned when choosing a chart type. We need to think about our data types of our variables in the abstract sense. I don't mean what JavaScript type they are. And also we want to think about what type of relation between attendance in the year we want to convey. The first chart I will try is a bar chart. To do this with Dimple there are a few steps to go through, but many less than doing this with D3 itself, which we will see later in the lesson. I want to talk through my coding the editor, before we move back to the browser and interactively explore what each of these lines does. The conventions that Dimple works with are axis, series and fields, which I'll call them here to not confuse them with JavaScript variable, though they are more closely related to what the grammar of graphics calls variables. And fields simply refer to columns in our dataset. Here, attendance is the attendance column. These three features are the essential building blocks of any chart and by manipulating each of these we can create a wealth of diverse charts. As you can see, Dimple.js's API is much closer to what the grammar of graphics specifies than d3 itself. This is because Dimple.js exists at a higher level of abstraction than d3, and since the grammar of graphics is at a little bit of a higher level of abstraction as well. Dimple happens to fit nicely with the grammar of graphics specification. The first few lines of code here are simply standard JavaScript, which set up the variables for the width, height, and margins of the chart. As well as the d3 code, which append an SVG element on our page. The declaration here to use strict lets the browser know that you want to enforce a restricted subset of JavaScript within this function. The most important feature of strict mode is that it forces the browser to throw explicit errors anytime JavaScript might silently fail. Similar to what we saw in the first lesson for HTML elements. These lines of code simply tell the browser to find the body tag, append a new SVG element, add appropriate attributes for the width and the height and then add a group with class chart. We haven't seen a group yet. But all the group does is, groups the SVG and everything within it, into a single element. Think of this is as the same way as webpages often use div tags to group common elements together, such as, paragraphs or side bars. The Dimple code to draw the bar chart is only actually five lines of code. In D3 this would take around 30 lines, and introduces many more sources of error if we have to code 30 lines of code, rather than five. This really goes a long way to show how proper abstractions can go a long way towards developer productivity. The first line here simply creates a new chart object in the specified element with the specified data. The first argument is a D3 selection that represents the SVG element. Which we would like to append our Dimple chart to. And the second argument is a JavaScript object representing the data which we would like to display. In this case, the SVG is, was returned from the d3.select call. Or what is rather returned from the D3 code that initially appends the SVG object. And the data object passed to dimple.chart is simply the same JavaScript object, in this case, an array of JavaScript object literals, that gets passed to the draw function callback. >From our data loading function. The data loading function is below our window here but its simply D3's.TSV function which loads a tab separate value file in this case world cup.tsv. And once it gets loaded via AJAX, passes that data content, to the draw callback, which we see here. So the flow, which sometimes takes some getting used to, is a call to d3.tsv pass in a data file. Once loaded, the data file gets passed to draw. Which we can see here in our callback function. And this data object is the same as the contents of our World Cup file which then gets passed in to the dimple chart constructor. There are a few other ways to manipulate the chart object itself if you are interested. And I definitely recommend always reading the documentation of any function you use. The second line here specifies what type of data our x-axis represents. Which in this case, is a continuous time value as indicated by the Time Axis function. Notice that we call this function on the chart object return by the dimple constructor function. We could potentially have multiple charts on a single page and this allows us to specify which chart we would actually like to manipulate and add an axis to. The first argument is the axis which we would like to add, in this case, x. In the second argument, the string representing the column name of what we would like to plot on that axis in this case, the year. So this line of code says, add to my chart a time axis which will be represented by the x-axis on our chart and correspond to the year column of our data. The third line here specifies what type of data our y-axis should represent, and has an identical interface to the add time axis function. In this case, we have a continuous value we would like to plot on our y-axis specified by add measure axis. The third line says add to my chart a continuous value on the y-axis which corresponds to the attendance column of my data. The fourth line here, with a call to add series, simply specifies what type of chart we would like to make. In this case, we pass a dimple.plot.bar chart to the add series called on my chart. In nuance here, that we'll get into later, this first mysterious argument that we pass in as null. Dimple J S, being the high level charting library that it is, allows us to facet our data or droop it by another column. If we wanted to say plot our data by attendance per year but also droop it by let say the stage of the World Cup, we could pass as the first argument to the series stage, which will first group our data by stage and then make a bar plot of the specified axes on the chart. And the final line here actually draws the chart on our webpage similar to a call in D3 to append HTML and SVG elements into a webpage. And that's it. A five line bar chart. Now, it might seem like a lot of overhead to learn a new library to do something that D3 already does for us. But using Dimple will not only allow us to iterate much quicker on our visual design process. But it'll allow us to actually think how we want to when designing charts. In columns, axes, data types and the relationships between them. And that is the true power of a well made abstraction or interface or API. Let us now play with this code in the browser and actually see what it's created. I'll be stepping through each line of the dimple code that I just explained and inspecting what gets created at each step of the way. I'll be using the same technique of stopping using the debugger in the middle of the draw function. So, I can run the code line by line. Just to make sure, let's open up our console here, navigate to the Console tab and then refresh our browser so that the JavaScript Debugger catches. And you can see here, again, on Line 19, the JavaScript Debugger caught. We can go back to our console. Make sure that our data has properly been loaded, and now we're ready to start diving in and creating some charts. As I just mentioned, you're going to use the dimple.chart method. To initialize a new dimple JS chart, with the svg element we want to draw the chart into and your data object. We tried running this code, it's going to break. And it's going to tell us that we cannot append to undefined. Now this might seem like a cryptic error but if you go back to our sublime text, what we can see here is that the debugger caught, before we created our SVG. Now when you're working in this interactive fashion. You have to be sure that you know exactly what's in scope and when. So simply copying this code that creates a new SVG element and append it to the body. We can paste that into the browser console and now we have an SVG element. Re-running the chart creation code, forward dimple JS. We now see undefined returned. If we inspect what myChart is, we can see a new object, dimple.chart, that has a few properties defined when it prints the console, and a whole assortment of methods here, which represents everything we can call on a chart or access from a chart. So use our methods and properties for like width X and Y. There's quite a bit here. I don't want it to get too deep into it, but I simply wanted to show you that you should not be afraid of libraries and the code that they may generate, but you should be curious and inspect anything. Especially if you're working with JavaScript. Since things are quite easy to inspect, and quite dynamic. If you're interested in knowing the specifics of what each of these methods or properties represents, I recommend reading the API documentation on the dimple.js site. We can add an axis to our chart simply by calling an axis method and the chart object. Since our x axis represents years, we use the addTimeAxis method and specify that the x axis should correspond to the year field of our data. Let's finish this by adding a semicolon, which is not only a good JavaScript best practice, but in some cases your code will run into errors if you don't include one after every line, and then add an axis to our chart. Previously, we tried to inspect my chart and it was quite hard to understand what all the methods and properties meant, but let's inspect our x axis. If we look here, its a dimple.axis object, and it specified the chart it belongs to, the position, in this case the x axis, and also what fields it corresponds to. Something to note here, that the chart property define our axis actually is a reference to the chart object we created earlier, rather than just an identifier string. And we've tried printing out what this chart object is x.chart, we get the same object as we got when we printed out myChart. As you can see here, they're both dimple.chart objects and they both have all of the same properties. Now this is possible even if two objects aren't identical, but if they have the same properties defined. Going one step farther, we can actually compare the myChart object with the triple equals to x.chart. In this case, it says myChart is exactly equal to the axis chart property. To add our y-axis the method and function signature are identical to what we did with our x-axis. Here we are adding a y-axis that corresponds to the attendance field of our data. Much of the magic with the chart happens with the ed series method. If you notice, as I type the method call under myChart object for the addSeries method, Chrome actually tries to help me out and autocomplete the method I might be trying to call. We can actually scroll this here, and see every method that starts with add defined in the myChart object. This can be very helpful if you're interactively trying to explore a library or object that you're not familiar with without having to go to external documentation. The addSeries method call is where we actually specify that we're going to make a bar chart. A quirk of the addSeries method, that the first argument specifies a field to create categories for the chart to group the data by. In this case, if we gave the method something like stage of each game, then we create a stacked bar chart, or whichever chart we specify where it facets the data based on the field, that you pass in as the first argument. In this case, and we'll see in just a minute, if we specify stage, we'll actually be representing the attendance for each stage of the World Cup for a given year. Since we want to first see the attendance across all games for each year, we're going to pass in null, which just means to not group the data on any other field. The last step is to draw our chart and see all the hard work that Dimple has done for us, here we just call the draw method on our myChart object, which we added all of our axises and the series to. If you are not familiar with object-oriented programming or its counterpart, the functional programming paradigm, this may seem weird to you. We called a few methods on an object. The methods returned some values, but now, when we wanted to actually draw our chart, we call the draw method on our original myChart variable. What's happening behind the scenes, the, the dimple library actually implements an object-oriented interface for its objects, in which the method calls on the myChart object and you take the internal state of the object. What does this mean? Well, when you call the series and addAxis functions, they actually add the axis and series objects into the chart that they're called on. So now, when we call draw on myChart, myChart's been mutated by the addSeries addAxis calls, such that they have all the data and specification they need for the draw function to operate. The fun thing about working in the debugger with Chrome is that as soon as we call the draw function, the chart will immediately be drawn into the Web page. Keep an eye on the Web page in the background here. And even though we're pausing the debugger, all the code we execute here has access to the Web page itself. Calling the draw method, we can see that a bar chart spontaneously appeared in our Web page window. One last thing to note before we move on to better and different charts, that the returned object from the draw function is the chart object that we called it on. If we inspect draw_chart, which we stored the return value of myChart.draw into, we can see here that it's dimple.chart and has all the same properties as our original chart. And again, we can actually check whether it is equivalent to our initial chart by using the triple equals operator in JavaScript and comparing it to myChart. And we can see here that it is indeed the original chart. This style of returning the object that you would call the method on is exactly how D3 works and allows you to chain methods without having to go through an intermediate representation or variable. Let us now close out of the debugger and look at the chart that was drawn. You may notice something strange happen here. We actually have two identical charts. Can you think of why this might be happening? Well, if you remember, we stopped execution with the JavaScript debugger, in the original HTML source file. Looking back at the code, here, the debugger in line 19 paused execution. In the web console, we created and appended an new SVG, which we then drew a chart in, all before continuing from the initial debugger statement. So when we stepped past the debugger statement at line 19, the original code got run, which appended another svg to our page and added a second chart to it. Usually, this isn't too much of an issue, because in practice you don't develop your final chart in this interactive way where you pause execution, write some code in your interactive console and then continue execution. Usually, a visitor comes to your graphic, the HTML gets loaded, and the JavaScript code gets run once. Going back to our browser, we'll refresh the page and see here that only a single chart was drawn. And before we finish with this bar chart, I just wanted to point out some of the benefits of using a high-level library like Dimple. If you notice, by hovering over a bar, we can see both the date and attendance of the game. And we get this horizontal bar that gets animated out. The tooltip's great, because it gives us a much finer look into the actual values of our data. And the horizontal bar the projects out is useful if we want to compare one bar to all the others and see if its value's greater or less than. Are there any things that look off with this plot? Or possibly things that could be improved? A quick fix for this is to be much more explicit in how we want to format our dates, rather than using some intelligent default that Dimple chooses. Going back to our editor, a quick fix for this problem is to simply add a date parts format to our x-axis. In this case, setting it to % capital Y. And while these strings might seem mysterious, it's actually an old Unix standard called strftime. And most programming languages and libraries implement it. So if you ever worked with a date in another language, such as R or Python, this should seem familiar. What this line tells us is to parse the date on the x axis, which corresponds to year according to this format, %Y. %Y actually stands for a four digit year, for example, 1966, 1970, and there's many other ways to interpret your dates. But I don't want to spend time now going over every possible way to use this STRF time string. So I've left a cheat sheet in the instructor note, and if we refresh our page now, you'll notice that as we hover over any bar the dates are correct. In this case 1962, in this case 1966. One quirk of this is that there's stale placed at the first of the year, in this case January 1st, which isn't the exact date the gain was at. Or this World Cup was held, since most of them happen in the summers. But for simplicity, let's not worry about this. And as long as we have the year, that's all we're interested in. And again, since Dimple operates at a higher level of abstraction and follows some of the principles of the grammar of graphics. To make these changes it's very simple, and we simply have to manipulate some properties on our axis and Dimple does all the hard work and heavy lifting for us. But beyond these small formatting changes, to make our chart more readable, there's still some fundamental issues with this bar chart. Name one thing that you think that the bar chart does well and give one reason why a bar chart may not be ideal to represent this data. Put your answer about the good reason in the top box, and the reason why the bar chart may not be the best chart in the second box. I'll start with the good. One thing that the bar chart does well, is highlight the years in which the data is missing. Both in between World Cups, so it's very obvious the World Cup only happens every four years. But also through the use of negative space, we can see complete years in which there was no World Cup at all. Can you think of what major event occurred in these years? Somewhere between 1938 and 1950 that would cause the World Cup to be canceled. Well, this is exactly where World War II took place, between the years of 1939 and 1945. And thus, both the 1942, which would occur here and 1946 world games were canceled. And one of the reasons why a bar chart like this is very good at highlighting this missing data that's strict rigidity of the chart layout. Evenly spaced bars, with evenly spaces widths for each bar. The only variable we're working with in this case is the height of a bar. So if we had fairly regular and periodic data, it becomes very apparent to a reader when a single periodic event doesn't occur. But it would also say that this is one of the failings of the bar chart for our data. One fundamental reason why the bar chart in our case doesn't work is that the x axis is an intrinsically ordered variable. Year 1932 comes before 1933, comes before 1934, and so forth. A bar chart is typically best suited to represent categorical data where these might be things like labels or groups, such as a state. For example in our case might be the country or continent in which the World Cup was held in. And while years could be considered discreet values. 1932 can be thought of as a category in some sense. There's a natural order to time, which makes a bar chart suboptimal. Now after all the setup for these few lines of code in Dimple, to make our bar chart, we can start having some fun with different chart types with very minimal changes. And experiment with different types of charts, and different layouts. To change which chart type we're using to represent our data, we simply need to pass a different chart object, to the addSeries method. In this case we're passing dimple.plot.bar. But let's try and look at what a scatter plot looks like. We simply have to change dimple.plot.bar to dimple.plot.scatter, save our file, and reload the page. And if we reload the page, you can see here that the bars have been converted into circles, and the axes remain the same, in this case, years, with the label every four years. And the y axis represents attendance in millions. And with our scatter plot if we hover we still have the interactive features, but this time there's both a horizontal and a vertical guideline to animate out. My ideal choice of chart type in this case is a line plot. Since the x-axis represents time and has a natural sequence to it, for any time series data a point at time t on the x-axis somewhat depends on the time that just came before it. In this example, 1948 somewhat depends on 1947, which depends on 1946. And this natural ordering from one year to the next or from one data point to the next, represents something of a transition. And the line plot really evokes this interpretation by linking each data point from one to the next with a graphical element. In this case a line or a path between the two. If we go back to our editor. Remember, we can change what type of plot we're making, or chart, by simply changing what we pass to add series. In this case, let's change scatter to line, save our file, and go back to our browser. If we refresh the page, we can see here. Every dot has disappeared and instead we have a line representing the trend. But one slight formatting quirk of this line plot is that we no longer know how many data points we actually have. Especially if dimple didn't provide us with hover interaction. We wouldn't really know which years and how much attendance in those years is represented in our data. And without the hover interaction it would actually be impossible to know that a World Cup didn't happen in the year 1942, in the year 1946. Quick fix for this is to actually combine a line plot and a scatter plot to get the best of both charts and almost none of the down sides. And dimple again, being the flexible and powerful library that it is, to achieve this effect we simply just need to add another series. In this case, with a line and our scatter. And to draw them on the same set of x and y axes. Going back to the browser, now we have both the line showing the trend over the years, and the circles to show us which years games actually happened in, and what the precise attendance was for those years. And with our scatter dots we can now see that there were no games between 1938 and 1950, or rather, that the 1942 and 1946 games were skipped. One point I want to stress in the distinction between sketching with the visualization and something like EDA is that exploratory data analysis is typically performed, when you are exploring the structure and values of the data to find insights, erroneous values or are there features of your dataset. That are inherent to the form of the data itself. Sketching in contrast is performed to experiment with the visual display of the data and explore the best visual encodings for the given data values and types. One last point about the distinction between something like EDA and sketching. Is the EDA is often thought of between yourself and the data. It's for you to discover insights in your data and figure out the right questions to ask. Sketching, on the hand, is to communicate some insights to others. This is iterating and prototyping the best way to visually display some insight that you have all ready found. This is somewhat similar to the distinction that the grammar of graphics makes between the data and the aesthetic. Think of sketching as iterating on the visual aesthetic, and EDA as iterating on the data, itself. Do you think a scatter plot is better suited for this data than a bar plot. Often people use a scatter plot to display time series and distributions. And while it can work for these types of things, just like a chef wouldn't use a butcher's knife to cut vegetables. I think that scatter plot is better suited for data, where each field on the x axis is not correlated with itself. What do I mean by this exactly? Well, given time, one year is implicitly dependent on the year that came before it. A subtle distinction about why not to use a scatter plot for this data set. Is similar to a lot of the choices that front-end designers, make for common user interface best practices. For example, it's very rare that you see a site with the horizontal scroll going left to right rather than vertically up to down. If you've seen MySpace's new site redesign. You'll know that they're an exception, and the reason why sites often don't do this is, because it can be very disorienting for a user, since 99% of sites, probably more out there, scroll vertically if a user scrolls the mouse up or down rather than horizontally, and they come to expect this behavior for every site. If a site maps scrolling up and down to actually horizontal action on the page, from left and right. It's not wrong or incorrect, but simply just unconventional. And in this same vein, if people come to know a scatter plot to represent data where the x values are uncorrelated and independent, they might assume that the data that you've chosen to represent by a scatter plot has x values that are independent and uncorrelated. So in this case, a scatter plot actually succumbs to the same issues as the bar plot, and actually doesn't highlight the missing data as well. So it might be even a little worse in my opinion. The last point I want to touch on with the Dimple library. And usually this is possible with any library built on D3, is how we can interact with the dimple-created charts with native JavaScript, CSS or D3 code to add additional customizations. Here we can see the chart that we created as a combination of a dimple scatter and a dimple line. But one improvement that I wanted to add is to color the scatter circles red to draw more attention to them or we can do this through dimple code D3 code or Java Script code. The simplest way to make this slight change is to use CSS. When customizing a chart created by another higher level library, we often need to find some class or ID to select the elements. In this case the circles. If we inspect element and look at the SVG created by dimple we can see here that its a circle element with the ID equal to the date. And going over further, we can see that there's a bunch of different classes added to it. Since, we want to make all the circles red, the ID won't work. So we have to pick one of the classes, or a few of them to change the styling on all the circles. In this case, it looks like all the circles are dimple series-1 class. Which is probably a good guess for a class attached to all of the circles and none of the lines. Which we can then use in a CSS selector. In our HTML file we simply need to add a CSS style to the page as a whole. That selects circles with dimple series-1 class. Here we are selecting the circle elements with dimple series-1. And we're changing the fill property of the SVG circle to be red. Saving our file and reloading our page. And you can see here that the fill of the circles is now red, which makes them a little bit more distinguishable. And the last fix that I wanted to perform was to add a title, so that our reader of this chart knows what they're looking at. As we saw in lesson one, we can manipulate both SVG and HTML elements with D3. So let's add a header tag using D3 and then changing the text of that. We want the title to come before our chart. So right before SVG element we can append our header. As you can see here the code is pretty standard. We select the body, append an h2 tag, and then change the internal text property or in this case just the internal text of the h2 tag. Refreshing our page you see here that it correctly appended the header to our page but that it's slightly off. Again we can make a simple fix with CSS to center our header. Back in our code we simply select the H2 elements on our page and change the text align to be center. And going back to our chart we see here. The World Cup Attendance title has properly been centered on our page. And hopefully this shows you the benefit that d3 provides us by allowing us to use standard CSS and HTML knowledge that we might have gathered from web development to create great data visualizations. I just want to recap what we did in this lesson and remind you of the iterative process of sketching a visualization. We started with our bar chart. Notice that while it does some things well, such as highlight when games were not held, it doesn't really convey the trend in time that well. And also it looks a bit strange since the bars are so thin, since they represent only one year. We then went to a scatter plot, which shows the trend a little bit better, as we can follow the circles as they rise and fall, captures the missing years in which a game was not held. But not nearly as well as the bar chart. But is typically used to represent things where the values on the x-axis aren't necessarily correlated or ordered. While the scatter plot has some of the benefits of the bar chart and some of the benefits of a line plot, it does a bit of a mediocre job at both. We then tried to iterate with a line plot, since it is most suited for time series data, and conveys trends very well. Here we can easily see the trend in attendances over the history of the World Cup, but tends to obscure dates where there was no data or a game was not held. So to remedy this, we're going to add our scatter dots back in to show that because of where lower two, there were no World Cups games held. And then to make the data points, in this case the circles more striking, we can style them with CSS to make them red. And to add context, we added a title. I kept the title in here the whole time through the duration. Since it's usually a good practice. You start with both a title and labels on your axis. So that even though the visual display of your data may not be the perfect ideal, you or a reader still has the sense of what data you're looking at. And that concludes the live coding example I wanted to go through. And hopefully, you have a better sense of the process involved with reaching a final graphic. We have just created a graphic using DimpleJS around the World Cup attendance throughout it's history. We have learned about how to best choose a chart given our data and its structure, and some of the theory and formalism around this process both from Edward Tufte, and LuAnn Wilkinson's Grammar of Graphics. You also saw many examples of data visualization. In particular, you saw how the design choices that you didn't make can either enhance or hinder you ability to communicate effectively with an audience. Next we'll be going over a few ways that you can effectively tell your data story. Also, different narrative structures that you can use when creating complex interactive visualizations. Now that you know a few design principles, and how to compose graphics, let's go through a few different narrative structures that you can use to walk your viewers through your visualization. In addition to narrative structures, I'll teach you about the data collection process and data processing. I'll also show you some examples of bias, and what you should avoid when creating graphics. In all the visualizations we've created and encountered in this class, one thing that was absent, was any idea of context or narrative. Often when you're reading a newspaper, a blog post, or an article, there's some story that connects all the pieces together. Think of narrative as the invisible string that ties the frames of a movie together, or the binding of a book that glues the pages together. Let's walk through how journalists approach this problem and create stories of their own. Before we dive into techniques to add context to our visualization, and see how to create a narrative around our data, I wanted to take a step back and first go over some approaches traditional journalism takes when treating its stories. Nate Silver, of blog FiveThirtyEight fame, who correctly predicted all 50 states in the 2012 presidential election, describes approaches to journalism, with the following spectrum, in opening post of the new relaunch of his blog. Nate sees journalism as neither wholly quantitive or qualitative. When talking about approaches to journalism, it's not a binary categorization to him. Rather than being either quantitative or qualitative, he sees it as more of a spectrum. Numbers without context is just as meaningless as words without numbers, and you need both to create effective data stories. And Nate actually goes one step further, and labels each of the quadrants. The upper left is where organizations like 538 stand, that produce very rigorous and empirical articles based on some quantitative data. When talking about the upper right quadrant, I'm referring to the traditional articles. That the Washington Post or the New York Times might put out, that have extensive research backing the qualitative story they're trying to tell and narrative, but may not necessarily contain charts, interactive graphics, or some data collection or experiment they're testing. But, as I mentioned earlier, the quantitative and qualitative divide isn't necessarily as black and white as I might have drawn it in this graphic. And organizations like the Washington Post and the New York Times do have very data driven articles and interactive graphics just like 538. I publish more qualitative articles in line with traditional journalism. The bottom of this chart, the bottom left and the bottom right quadrants, Nate doesn't think too highly of. The reason being that the bottom half of this graphic represents anecdotal and ad-hoc stories. The bottom left here, might represent sports writers or other journalists, who take numbers and statistics out of context and don't have the rigorous research to back them and verify their facts. And finally the bottom-right quadrant is reserved for op-ed columnists and pundits who disseminate solely their opinions, without any research, data, or hard facts to back up their claims. In this class, we will focus on the upper-left quadrant and techniques that organizations like 538 take when writing their articles and crafting their narratives. In this lesson, we will try to create a compelling data narrative around the history of the World Cup. Using quantitative facts and data to support our claims to convey potentially some qualitative or subjective view of the World Cup, but before we go farther, I want to expand on this idea of the upper left quadrant of quantitative and rigorous analysis in the context not only of journalism, but how it tied into data science as a whole. One of the most common reasons for incorrectly interpreting data stems from the difference between correlation and causation. If we use some logical notation borrowed from math, a correlation can simply be stated as both A and B either go up or down. You could also have an anti-correlation, where when A goes up, B goes down. The difference with causation is typically one event happens before the other. In this case, if A, then B. In this case, causation is often a much stronger assumption in effect than merely a correlation. To make this a little bit more concrete, I want to go through a simple example. Let's say that as the number of movies produced in a year increases, the observed incidence of cancer in a population increases as well. Now, you might be able to say that as the number of movies produced increases, people go to the movies more often and thus exercise less, increasing cancer incidence in the population. And while that may be true, an analyst might conclude a stronger relation between the number of movies produced and cancer incidence in a population to be a causation instead, perhaps leading to some serious actions being taken erroneously. If the relation between movies produced and cancer is completely spurious, and the true cause of the cancer incidence increase is due to some completely separate event. If the results that the analyst found are presented either on potentially wrong media, let's say an academic paper, rather than simply on their personal blog or maybe in an article, some serious consequences might be taken based off of, again, the spurious correlation. Let's say the doctor sees a paper published based on this connection in relation that some analyst found, and then decides to recommend to all of his patients to stop watching all movies and TV because it increases cancer incidence. By misinterpreting a correlation to, in fact, be causation could lead to many misleading conclusions, and thus, serious consequences that others might take based on those conclusions. Now that we have some sense of how traditional journalism approaches creating stories and crafting narratives. I wanted to contrast it with the new approaches that data journalism takes to create engaging and often interactive visualizations. Traditionally, journalists have used data and charts as evidence to support a claim. Often in the form of a static image embedded within the larger body of text. For example, you might be reading a news article that uses a chart to support some claim it makes in the overall narrative. I say here data around narrative to refer to the fact that the narrative is the focus of the journalist piece and the data merely exists in a secondary and supporting role. Data journalism on the other hand places the data front and center and builds a narrative around the data. For example, a data journalist might have some interesting data set. And try to tell a story about what's happening in that data set. In comparison to an article that has a static chart embedded to support claims made, a data journalist might have an interactive chart, which they then use labels, annotations, and sidebars to add context to the data. And by adding context to the data, they'll create a narrative around the story they want to tell with their chart. The second difference I wanted to point out is that traditional journalism often presents its information as a sequence of events. A then b then c to create a linear narrative. Data journalism on the other hand leverages interactivity to enable much more complex and varied narrative structures. Allowing the user to discover their own data story possibly from going from event A, to event C, back to event A, maybe going to some external article or other information Z, which leads back to conclusion B. In this case. The structure of the story and the narrative that you tell may be different and customized for every reader. Whereas in traditional journalism you might write a single story with a single linear flow so no matter who's reading it, the story stays the same. And the last aspect that I want to compare is the method of delivery or dissemination. Traditional journalism is published either in a physical form like a newspaper or magazine or on the web, but often only as static html. Thought of like a digital book. The new visualizations coming out of data journalism outlets like the New York Times or 538 leverage many of the open web technologies that we discussed in lesson one to create both more accessible articles. And also interactive visualizations then enable much richer interaction from the reader. Now that you have a high level overview of the data visualization process, let's dive a little bit deeper into how we might start collecting data for ourselves. But before we dive deeper into learning about getting cleaning data, I want to you hear from Scott Murray again. Scott is going to share with you one common misconception that people have about data visualization. What are the most common mistakes that you see people make when they're just starting with data visualizations? Well the, yeah, most common is probably thinking that it's mostly about visualization. Because that's like the fun, pretty, cool, exciting part for most people. It's, typically there's a lot of like the data part that's involved. You know, like maybe your work is going to actually be 90% finding the data, verifying the data, parceling the data, filtering the data like exploring the data. And the visualization is often just kind of like that last step. Which can sometimes be really disheartening especially if you're you know, coming in expecting to like, make great graphics or whatever, which you can, but there's sort of all this leg work that, that happens right before that. So, that's kind of, I think one, one issue is about expectations coming in. So in terms of any other stories or graphics I think this one tells a really direct story, it's really clear to get that information out of it. Are there any examples that you have where, that's not the case, let's say the data visualization is misleading. Yeah. Absolutely. So one repeat offender when it comes to breaking rules of data visualization is Fox News. We'll look here at an example that I typically look at in my workshops. So, here what we're looking at, we have to imagine ourselves back in the fall of 2012. And we're looking forward to 2013 to say what's going to happen if the tax cuts expire? So on the left hand side we have what the top tax rate is now at 35%. On the right hand side what it'll go to as of January 1st at 39.6%. Do you notice any issues, with this graph? I should, I guess be worried because there's a big gap difference between the two bars. Yeah, your data spidey sense if probably going off here, right? Because this increase looks huge. Why does it look huge? For me it's the, the length of the bar. The one on the right is much bigger than the one on the left. Yeah, and if we look at the details here which are small and off to the right, maybe so that we miss them. It's because our y axis doesn't start at zero. Hm. It starts at 34. Which means the way this is plotted, the visual increase between the two is 460%, versus the actual increase if we plot this you know, with the bars going all the way down to where they should be, the increase is something like 13%. So the specific rule that Fox News is breaking here is, bar charts must have a zero baseline. When we're looking at bar charts, what our eyes are doing are comparing the end points of these bars. So it's actually really important to have the entire context of the bar there to do that. In the right way. More generally this brings into question sort of ethical concerns, right? Hm. And they're breaking the rule here, also don't lie with data. So beyond ethical concerns, it's just a really dangerous space to play in, because all it takes is that one discerning audience member to say. Hey yeah but that y axis doesn't start at zero, and whatever message you're trying to communicate then gets thrown out the window. Well, I know this was probably true for bar charts with like the perception that we have here. Are there any cases where we don't necessarily have to start the y axis at zero? Yeah with line charts you can get away with not starting at zero. You still want to be very careful when doing so. Because our eyes are comparing the sort of relative points in space rather than to an axis, the way that they are with bar charts. In general, you want to try make it clear to the audience that you're doing that. And not zoom in so far that you're making minor changes appear to be really big. Right, so you want to take the context of what it is you're showing into account there. So, what's an example of a data visualization, that tells a subjective story, rather than an objective one. Sure, a popularly sited one is actually one that we have up here which is one that Steve Jobs showed, and it's a 3D pie chart, and It's confusing really when you kind of just look at it. Because, as you can see here, so the 19.5% represented by the green part of the pie, visually if you didn't have those cues of the annotations. It looks to the eye almost the same size as the 39% here, and definitely larger than the 21.2%. And so it's just really confusing because pie charts can be a little confusing, especially in this way if it's 3D. Because it doesn't let the eye effectively take in the data. So it can be pretty confusing and let folks use graphs in a way that might be misleading or confusing. Especially if you aren't able to understand what the data behind it is. So what sort of things do you think we can do to improve this graph? So if we we're doing 100% of data I think a cool and youthful way often to show data is by using a stacked barchart. And so you can still show 100% of the data. So in this graph for example we're looking at the population of New York over time and it lets you see changes. For example here you can see the green space, which represents Manhattan, changes from being. What is this? 83% of the population. And then drastically reduces over time. And so you can still make a, a meaningful comparison. In fact, I think more meaningful because it's showing 100% side by side. And it's a lot easier to, to take in the distribution of that. In a line and in a stack bar chart type format then it would in a pie chart. What's an example of a data visualization that you've seen that tells a subjective story, rather than an objective one? There's a bunch. Probably the most well known one that I would fit in that category, are Nicholas Felton's annual reports. Mm. They're super beautiful. And, you know, I guess you could argue about their objectivity. But they're, they're very much personal, extremely personal information. They're just personal, they're personal annual reports. So, hard to describe them. But if you go look at them you'll, you'll see what I mean. I think in that vein, there's been a lot more kind of personal data reporting, which is interesting. He sort of set the standard with these annual reports. But, there are more and more people doing kind of personal data tracking. And then doing interesting visual things with that data. So there's a new project, I'm going to forget the guy's name who made it, but I think the website is aprilzero.com. And it's this really, really in-depth sort of personal data reporting platform. And the interface is really beautiful. I'm not sure what I can kind of learn from it. But just aesthetically, it's like quite stunning. And you can see you know, his, his travel information. And sort of, how much he's working and what his calendar schedule is. And I think you see he has, you know, Fitbit, or whatever these different like, wearable technologies. And so those pieces of information are reporting in there too. I think, you know, it's really interesting, this kind of stuff. because it, it's not, I don't know if that makes it subjective or objective. But it's, it's very personal. So in that sense, it's sort of just taking the view of that one, that one person or that one experience Something that Nick Felton talked about at the last Eyeo Festival, with his new annual report that just came out. He collected so much data, for this project. In, in the past he's collected the data in manual form on paper and then he developed an app so that he could record stuff himself. For this year he collected data from like all kinds of news sources. So it was like all his emails, all of his text messages all of his phone records, plus a bunch of stuff that he was collecting manually, plus all of his geographic locations. So for the phones we're doing a lot of this tracking for him, and what I think was really interesting about that project is that the number of data sources were or number of values were so big that he could no longer manage it in the manual form. Like, he used to do this project with Excel sheets, and to me that's when that project became like a big data project, because he had to relinquish some control to the algorithm or to the software. We said, okay, well make me a map of all the places that I've been and he could make this, like he could let the software make this map. And, then as a human being who had, who lived through this he could look at the map and say, well I know that's not right because I never went there. So this was a glitch in the GPS or this was, you know, this was a glitch in my email system or something. But I think it's really interesting that he's made the decision to leave those glitches in there. Like, the things that I am calling glitches are really just kind of side effects of the data tracking process. Mm-hm. And side effects of the algorithm, and how it's being applied. So I think, connecting that to the question. What's interesting about that to me is, when you're talking about what's subjective and what's objective. It gets really fuzzy when you get the algorithm involved, right? because you have. You have sort of my point of view. You have maybe like a more balanced objective point of view. But then you also have the point of view that's being represented by your code or by the tools that you're using. [CROSSTALK]. Yeah the data itself right? And how it's collected. Yeah the data itself. The process that we use, use to collect it. The technology that was maybe reliable or not that was used and collected. So, yeah I don't know. So I don't know what, what is like an objective truth in that, you know, in that kind of project. Yeah but it's, it's really interesting. I'll mention one other project too. Jen Lowe is an artist and data visualizer based in New York, and she has this project called One, I think it's called One Human Heartbeat and she has a device I forget if it's, you know, I don't remember if it's something she puts on her wrist or something, but it's a device that like measures, tracks your heartbeat. And if you go to this website, you can see your heartbeat visualized with a 24 hour delay. So, like every night, she plugs the device in and it syncs up, and it cuts the data off, and all you see is just this, like, pulsing, but it's like an ac, it's, it's a really intense, because it's an actual representation of her actual heartbeat, and so if it's going faster or going slower. And I think it's such a beautiful visualization. It's more like conceptual art than, you know, it does, doesn't give you this history, like this histogram over time. It just gives you here's my heart beating. This is like a real person that you're seeing translated on to your screen When you learned about storytelling in school, you probably learned that good stories have a predictable arc. They typically start out with an introduction, followed by a rising action, a climax, and finish with a final resolution. This is the way storytelling has been done for years and works well in a variety of formats such as oral and written stories in TVs and movies. The dawn of new mediums, namely computers and the Internet, have given rise to new narrative structures that can often be much more nuanced and complex. Let's first talk about author-driven narratives. Author-driven narratives typically have a well-defined start and endpoint and proceed in a linear flow that's directed by the author of the visualization. Viewer-driven narratives on the other hand, while still having a well-defined start point, allow a freedom of choice for the viewer to choose the direction in which the narrative progresses. In this way while each user starts in the same place there are various endings that they could end up depending on how they look at the data or the choices they made along the way. This type of narrative is very powerful because it allows the user to choose their our narrative. You can think of it like a choose your own adventure book, where you're writing the story as you're experiencing it. Visual narratives, often called narrative visualization, combine conventions of communicative and exploratory information visualization to convey an intended story. We often see stories fall within a spectrum, between author-driven and viewer-driven. Visualizations that have few exploratory elements, are often called author-driven. And are useful for narratives that have strong ordering, heavy messaging, or have a need for clarity and speed in the narrative. Viewer-driven narratives on the other hand, take a very different approach. Rather than dictating a specific narrative, it allows the viewer to freely interact with the data. Allowing you to ask questions, explore, and tell their own data story. Now let's look at a few examples of author-driven data visualizations. In this example, we're looking at the spread of Syrian refugees to neighboring countries during the Syrian uprising in 2011. There isn't much we can do here other than press play and watch the story unfold before our eyes. So let's press. We can scrub through time on the bottom here, and mouse over the line plots to get more exact numbers, but largely, the author has predetermined how we view this data set, as a particular narrative that is to be conveyed. Remembering back to our spectrum, we see here this is an appropriate use of a author-driven visualization. The author is trying to impose a strict ordering, the ordering being time, and wants us to see how the refugees have spread out between the years of 2012 and 2014. Let's look at a second example. In this example from the New York Times, we're looking at the Facebook IPO and how it compares with other IPOs in the last 30 years. We saw this in lesson one when talking about double encodings. But now, let's take a look at its narrative structure. Like the last example, a strict ordering is imposed as we're walked through a specific narrative with the above text. We see here that there are five stages that we're supposed to click through. As we move through the stages, we see the data stretch and transform, allowing us to dig deeper into each data point. Annotations also appear, drawing our attention to specific data points of interest. Viewer driven narratives, on the other hand, take a very different approach. Rather than dictating a specific narrative, it allows our user to freely interact with the data, and tell their own story. This is the excellent crime-spotting visualization, created by Statement Design. Here, there's no specific ordering a particular narrative. Instead, the data's presented to the viewer with various filters for zoom level, time of day, time of week, and various crimes. Let's say I live in the Mission, and I want to look at crime during my walk home from the Bart station everyday. Let's go ahead and zoom in there. I use the 16th Street in Mission Bart. So, we'll zoom it no this particular area. I'm only re, really worried about days of the week where I work, so I'll select Monday through Friday. I typically get home between 6 PM and midnight, so let's go ahead and select that there. We can see here that there are two thefts, a narcotics, and simple assault violations in this area. I can click into each one of these and get more information about the particular crime. With a few simple interactions, this visualization allowed me to ask a question that was important to me, and tell my own story with this particular data set. Another example of a viewer-driven visualization is Paths to the White House, also by the New York Times. Here we're presented with a decision tree that highlights the outcome of the presidential election, given how each candidate fares in key swing states like Florida. The overarching narrative is presented in the beginning. That Obama has 84% of the paths to win, while Romney only has 15%. But the viewer is invited to explore various outcomes by mousing over the different paths. If I'm interested in a particular swing state, such as Ohio, I could see that if Romney wins Florida and Obama wins Ohio, Obama wins. This is a great example of a hybrid between an overarching narrative and a viewer-driven visualization. This allows the viewer to mouse through and look at each aspect of the data, and tell their own particular story. So far, we've talked about author-driven visualizations that are typically linear and have predetermined narratives. We've also talked about viewer-driven visualizations, that allow viewers to interact with the data directly to craft their own data story. I like to call these types of visualizations Choose Your Own Adventure. There's a third narrative structure, common in more complex data visualizations called the martini glass. It's called the martini glass because of its unique shape. Think of a martini glass set it on its side. It has a base, a long narrow stem, with a wide mouth. Viewers start at the base and work through the neck of the martini glass. Typically through a single path that is author-driven. When they reach the mouth, the visualization opens up and allows the viewer to freely explore different paths within the data. And to tell their own narrative. This way, it combines with the author-driven and viewer-driven narrative structures in a single cohesive whole. Let's look at a few examples. Here we're looking at a visualization about drone strikes from pitch interactive. As we enter the visualization, we're taken through an author driven narrative step by step with the accompanying drone strike animation. This is the narrow stem of the martini glass. As we click through, the final visualization starts to build. Each element fades in slowly, with annotations about notable events during that period. Notice that up until now, it's been linear, with a single path. We're still on the stem of the martini glass. After the visualization is finished building, we're invited to look into the data more closely. We're now in the wide mouth of the glass, and it's become a viewer-driven narrative, instead of an author-driven one. I can mouse over specific data points, and a tooltip appears, allowing me to dig into the data more closely. I can also click on the tabs in the upper left to pivot the data and look at it in other ways. Recent news about drone strikes is included below, keeping the visualization relevant and current. Hopefully, you can see how this particular visualization combines with the author-driven and viewer-driven elements to make a compelling narrative. Let's look at one more. In this example, Parascopic shows us a visualization of the number of gun-related deaths in 2013. It starts with a few victims and projects out the number of years they would have lived without gun violence. It keeps a running tally, and the visualization builds exponentially. Similar to the previous example, there's a clear narrative as we enter the visualization, and then we're invited to apply various FilterSense data. For example, I wanted to look at males that are over 30 in the Southeast. I can either look at their projections here, or look at a graph. Also included is two major insights, that the majority of victims are men and boys, and that the young people are a significant portion. Returning to our narrative structures, we've now seen a few examples of author-driven, viewer-driven, and martini glass visual narratives. Think about these narrative structures and how they can be utilized in your own work when creating or improving data visualizations. There's no one size fits all approach to storytelling, and what structure you choose will depend on the narrative and ultimately the data itself. Great. So, now that we've learned the differences between author-driven and viewer-driven visualizations, let's go through an exercise. In this exercise, we're going to be analyzing the narrative structure of different visualizations. We provided some examples for you, and we want you to ask four simple questions and write your answers in the discussion form. First, we want to know what is the narrative structure of the visualization that you've chosen? Secondly, how does the visualization lead you through the data? Third question is, what is the story being told with this particular visualization? And last, how could this have been improved? Please pick a visualization from the examples provided, and answer these four questions in a discussion form. I wanted to revisit the chart that we created at the end of the last live coding session. Hopefully one thing that you noticed that was conspicuously absent was any sort of context around the chart. The most extreme example of this might be a chart without any labels or axis, or even a title, but this may seems silly. Most charts would at least have axis and tick marks, but even with axis and tick marks, and values at those axis and tick marks, unless we label with the y and with the x coordinates, represent. It's very hard for a reader to interpret what's actually being displayed. You always want to make sure that any chart you create has both clearly displayed units. In this case, millions for the attendance, and years for the x axis. As well as informative labels. That shouldn't require any additional explanation. If I label the x axis year, it should be readily understandable to a reader. And the same applies to the y axis of attendance. But even with these additions of label tick marks with clear units. And labels on the y and x axis. A reader still left in the dark about what's actually being displayed. For this chart, before we add the title, even the [INAUDIBLE] some attendance plotted against years between 1930 and 2014. We don't know what the attendance actually represents. The chart's quite meaningless. As you can see even the simplest additions, can have profound effects on how interpretable your chart is, and how effectively you convey your overall message. And while dimple.js might be great for many common chart types, and allows us the flexibility to adapt them by exposing the underlying d3 objects. We will begin to start customizing and adding to our chart, enough so that it makes sense to work at the level of d3 itself. Part of this is due to the fact that d3 is much more flexible, and allows for complex interaction and animation in your graphics. And the third point while it may not be relevant to someone who's creating graphics in production, or has already learned d3, this being a course to learn about visualization by working with d3, it really helps you to understand what higher level libraries are doing such as dimple JS. How to debug their issues when they do arise, and to feel more confident about what's going on with the library itself and how to adapt it. You might have been wondering this whole time how exactly is D3 data driven. And when do we manipulate our graphic based on our data? Well without using Dimple JS we have to be rather explicit and a little bit more verbose. But are afforded much greater flexibility. And you could pose a chart as a question like this. How do I draw circle for every row of my data at the appropriate place on my axises? And the most natural answer to this question, at least in java script, is exactly that, a for loop. Again how do I draw a circle for every row of my data? Well, we could iterate through every row in our data and for each row draw our circle with the value of that row. And while this is partially pseudocode, this could be a perfectly sensible way to think about drawing a chart. Dependent on data in a very JavaScripty way. Notice how we have to be very explicit and procedural in how we tell the computer to draw a circle for every row in our data. But this seems a little bit cumbersome especially if the structure of our data changes. We want to use a different data file. We want to draw a different shape altogether. Or if we want our chart to adapt to some interaction from the user. Very early on when I introduced D3 I told you that one of the strengths of the library it's declarative syntax. Or rather you tell D3 what you want rather than how you want it to do it. Again in a pure JavaScript approach. We have to be very procedural with the computer and specify step by step what it needs to do to create our chart. With D3 on the other hand we simply specify what we want, circles, data in an SVG element. And D3 figures out how to best draw our chart. And one of the most mystical, yet powerful, features of D3 is the data bind, performed through the .data function. The data variable here is the same data variable that's passed to the call back of our data loading function, such as D3.json, D3.csv, or D3.tsv which loads our data file. And if we inspect what data actually is, which we'll see in a little bit, just as with our dimple example, it's simply a JavaScript array. Filled with JavaScript objects that represent our external file we loaded. Again, this chaining syntax is hopefully very familiar to you now. Each subsequent function gets called on the previous return value, transforming the object as it gets passed down the chain. The first statement here find the SVG element on the page which we want. And since there's only one, we simply need to use select. We then sub-select all the circles contained in that SVG element but let's pause here. This is usually where it breaks down for people. How can you select circles when if this is our first time drawing this chart there won't be any circles on the page until we append them? What are the circles that we're actually selecting. Well if we simply select circles when there are none we get the empty selection. Well then you might be asking, if it's an empty section how can you bind data to nothing? Well, I would argue, you bind the data to the circles that will be there. Well, this might seem somewhat circular reasoning, no pun intended. But let's break down and really understand what's going on in this snippet of code. The key to D3's magic is in the selection before the data binding, the data binding itself, and the selection after the data has been bound, in this case the .enter selection, which is actually a very special type of select which we then eventually add shapes or circles, SVG, or HTML to our page for every element in this enter selection. Many tutorials out there gloss over this detail of what exactly is the enter, at least to start off. But I think once you have a solid understanding of the data join, these selections that come after data join, much of the rest of the library, d3 that is, and the complexities involved with adding interaction and animation to your graphic fall into place quite nicely. Mike Bostock, the creator of d3, has one of the best posts on the subject, not surprisingly, and it's titled Thinking with Joins. I'll take a short diversion to explain what a join actually is and what it means in the context of d3. The idea of a join has its roots in SQL, a declarative database language. If you're not familiar with databases or SQL, don't worry. If you are however, hopefully you can make some connections to previous concepts you are familiar with. Joins emerged out of relational database theory as a way to associate two different tables or spreadsheets. Now to understand what a join is, imagine we have two tables. Or in this case, you can think of them as CSVs or TSVs. Wherein the first table, in this case, the employee table, each row represents an employee's last name and a department ID which they are employed in. So, in the case of the first row, employee Rafferty works in department 31, Jones works in department 33, and so forth. One thing to note is the value null here, which represents an empty value. So let's just say that John doesn't work for any specific one department. These tables are example tables from the Wikipedia article on joins, which explains all of the concepts I'm going to go over in much more depth. A join can be thought of as a union of two different tables combined in someway such that they make sense. Now, the most natural way to join these tables might be on the common column in this case DepartmentID that they both have. So to join these two tables, we would simply go down each row in the first, and for that DepartmentID match it to the equivalent DepartmentID, in the department table. And we would do the same for every row. One thing to notice is that two employees can be mapped to the same department, in this case, both Jones and Heisenberg belong to department 33. Or there could be no employees for a given department, in this case department 35. Or if an employee doesn't have a department, he can't get mapped to any And this is very similar to how D3 does its joins. In the case of two tables, let's think of Table one as our data file, in this case data.tsv, where every row is a row in our file. And Table two here for the department are all the HTML and SVG elements on our webpage. And when we perform that magical data join, we simply associate every row in our data file with the corresponding element on our web page. In the case of our scatter plot, we're adding circles, based on some common key, that associates the two elements. The question actually arises, what happens to rows in the tables that either don't have a match or elements on our webpage that don't have corresponding data to bind to? Well, that is exactly what the special selection .enter that follows the data bindings for. And before moving on, just to make this example a tiny bit more concrete, in D3 there's the idea of a key that maps data to elements. As long as the data has the same key, in this case the department ID, as to an HTML element that has previously been bound, they'll map to the same. Let's say, for example, on the first time through our code, we have an empty selection for the circle elements before the data bind. When we bind our data to the empty selection, think of it as creating something of an imaginary placeholder. That has the value of our data, so in this case, for every row in our data table it will actually create an adjacent second department table. The .enter selection corresponds to all of these elements. In this new mirror table that the databind creates. Which then get appended to whatever we first selected, in this case, the SVG element. So on the first time through, there's no circles on the page, we bind data, select all the bound data through placeholder circles that are not yet on our page, which there won't be any, and then for every one of those, we append a circle to our SVG element. Now if we wanted to re-run this code, without changing data, or without changing our selections, nothing will happen. The reason being is that since the data never changed, the key of the bond data never changed. So our enter selection which corresponding to all the new elements to draw on the page will simply be empty. So we dont append anything new. In theory, we could run this line of code 100 times and our chart won't change, as long as our data and our selections don't change. And again this is one of the strengths of the declarative syntax and allows us to build complex animations where only some elements of our data or some elements of our web page actually change from one frame to the next And just wrapping things up here, I want to cover a few of the other special selections besides .enter using a Venn Diagram that Mike Bostock uses in his great blog post, Thinking with Joins. We can think of these circles and their overlap representing the state of things right after our data bind when we're considering what type of special selection to make. The left circle here, shown in blue, represents our data file. In this case data.tsv. And the red circle here represents our HTML page or SVG elements on that page indexed.html. And the intersection between these two represents the HTML elements currently on our page that have already been bound to and associated with a row from our data file in the previous join made with .data. And knowing what I've mentioned about the .enter selection, everything in this blue corresponds to all the rows of our data that are not yet present on our webpage. Which we will then add elements to a webpage for each one. The purple can be thought of as the update selection. And while there's not an explicit .update we need to call, this section simple corresponds to elements already on our page from our prior selection to the data bind, which you might update their data values, or their styling implicitly by leaving out a .enter or .exit selection. We've talked a lot about what the blue section here .enter represents, and also what the purple update selection represents. Using what I've told you about .enter and update, and also what the left circle and the right circle represent. What does the red section on the right side here, labeled exit represent? The .exit selection called in just the same way as .enter after data bind, represents something of the inverse of .enter. The right circle here corresponds to every HTML or SVG element on our page. It might have previously been bound to data, but in a new call to .data, no longer correspond to a row in our data file. So rather, every part of the right circle, which represents elements currently on our page, which don't overlap with anything in the left circle, which corresponds to rows of data, which simply leaves us. HTML or SVG elements currently on the page which are not bound to rows of our data. Dot exit's usually used if you initially draw a chart and have subselections where users can filter based on a category or some animation where the data from one point in time to the next changes. And often .exit is used to remove elements from the page which you should no longer display. Now, that we are armed with the knowledge of how d3 binds data and how to work with enter selection, let us recreate the dimple JS chart in d3, and then extend it to add further context. Here we are back in the terminal. And before we can see our chart, we have to run a HTTP server. Again, I'm going to be using the python built in, simple HTTP server. And we can see here, it's serving up our current folder. Local host port 8000. And as you can see here. We have our world cup attendance scatter and line plot that we created in lesson two where attendance is on the y-axis, and the year is on the x axis. And each of these circles accurately represents the total attendance for the World Cup held in that year. Going back to our Sublime text window, I want to step through the Dimple.js chart creation code here, and replace, line by line, what Dimple.js does for us with native D3 itself. One thing you'll notice is that even simple things, such as creating the chart object or adding a y axis in D3, will end up being much more verbose. Then there are in Dimple.js, but we'll have much more flexibility on what our chart looks like and how to customize it. I want to painfully step through this one line of code here, which in Dimple, binds our data to the SVG that we want to draw the chart in. Replacing this line of code in dimple.js with the equivalent d3 statement, we can see here that in d3 there's actually five functions we have to run. While using d3's chainable syntax, we could write this all on one line. I think it's much more clearer of what's happening when you write each new function called on a separate line. I wanted to step through each one of these function calls, and then the web browsers chrome console. I want to inspect what gets passed in and what gets returned from each. As you can see here, I put a debugger before and after the d3 code that binds data to our SVG object in circles. And I also comped out adding the header title since we're not actually going to be drawing the entire chart, but walking through only the data binding process. In the last bit of code I've added are some diagrams visually explaining the data binding process to the webpage itself as an image. Opening up the Chrome debugger tools by going to the top right menu, scrolling down to Tools then JavaScript Console. We can see here the console threw an error since we removed the dimple.js code that actually created the chart. Let's refresh the page. So our debugger touches before any of our chart code. After reloading the page we can see here the first debugger statement caught. What I'll be showing on the webpage itself are some diagrams I created that visually explain what's happening with the d3 code here. Before we call the .data function, all we have is SVG on the page and the worldcup.tsv data file, which has been loaded via AJAX using the d3 convenience function. If we inspect our data variable, just like previously, it's a JavaScript array. In this case with 836 elements, each of which is an object with a bunch of fields. Remember that the Chrome Developer Tools provided a convenience function to print out a tabular representation of a data file such as this. Shrinking our data variable with console.table we can see each row in the TSV file. The file we'll be working with in this lesson and the next, has actually been enriched with some geographic information. The important columns added here, are a latitude and a longitude, a home column, which represents the team of the home hosting country. And then many of the other columns, which we previously worked with. Including, the attendance of each game, and the year in which the game was held. Shrinking the two window back and clearing the console output. Since with such a narrow window, the table becomes unreadable, let's start inspecting what gets returned from each of the function calls in the D3 data binding chain. As you can see here, d3.select passing in SVGselects the SVG element on the page, which in our case is at the bottom of the window, below the image of the data binding process which I'll be talking through. And currently there's no elements contained in it. Correspondingly in the image, we have an SVG element on the page that's not bound to any data. And we have our data variable which contains all the data in worldcup.tsv. Running the next function here, the select all circle, which is a sub select, looking for circle SVG elements contained within the SVG, we can see here that actually returns an empty selection. And this should make perfect sense since we haven't added any circles, to our page, and our SVG is empty. What happens next with the call to the .data function, passing in our data JavaScript variable, representing all the rows in our world_cup.tsv, is where D3 binds the rows of our data file to the elements on the page. But what I've just said, probably doesn't make a whole lot of sense. How can we bind data to an empty selection, since there aren't any circles on the page? And even stranger, is what gets returned. Here we see we have an array of 836 elements. Which got returned from the data bind. What are those elements? Where did they come from? And where does the data reside that we've bound to it? Well, this is where things get strange and magical. I've updated diagram to reflect this process. Since there are not yet any elements on the page corresponding to either our rows of the data or circles on the page, which are bound to data. D3 essentially creates empty placeholder nodes, which you can think of something like a virtual HTML node that exists in our JavaScript scope or in the console but is not yet visible on the page, as an SVG element. And each one of these virtual placeholders, gets associated with one row in the data file. So this mysterious array that got returned is actually an array of placeholder elements, that have been associated with some data. In my graphic, I've only shown four for clarity but this essentially has all 836 rows of our data bound to 836 placeholder elements. And to prove if there aren't yet any circle elements on the page, I rerun the select statement, again, d3.select("svg").selectAll("circles"), and again, an empty selection returns. So while we have told D3 we're going to be inserting 836 of some element, associated with some data, D3 has not yet added anything to the page. Well you might be asking yourself, now that we have some data bound to some virtual or placeholder elements, how do we actually draw them on the page? Well, this is where the mysterious .enter selection comes into play. .enter corresponds to a D3 selection of all the virtual nodes, or placeholders, bound to some data, which aren't yet on the page. In our case, since there isn't anything already on the page, this enter selection simply corresponds to every placeholder bound to every row of our data. And if we inspect what's contained in the enter selection, we get returned something even more interesting than what gets returned from .data. Here we see we have an array of 836 elements, but instead of corresponding to these mysterious placeholders, the enter selection corresponds to actual JavaScript objects, which contain a data field, which represents a single row of our data file. But also, more interestingly, has the __data__ property, which corresponds to an object. Opening up that object, we see we have the fields of a single row from our data file, which we saw earlier, as the .enter selection. But now instead of corresponding to only __data__ with the fields, it now is actually bound to a circle. So the combination of the enter selection with the append, merges the data from our data file, with the svg circle element. And this is where the mysterious data of d3's magical data bound lives. It's simply, a JavaScript object, attached as a property to the svg node, living in the DOM. And as we can see here, on the left again is the selection of what lives on the page either as HTML or SVG. Starting with the select of the parent SVG element, which contained in it has a SVG circle element, for each row of our data file, worldcup.tsv. Which d3 binds with it's data function, as we can see here corresponding to the link, to a row of our file which was loaded and stored in the data variable which again is a single row from our worldcup.tsv data file. So think of these linkages, as the magic data bind. Everything on the left side, as what's present on the page. Either as SVG or HTML. And everything on the right side, as either a JavaScript object, or some piece of our data file. And here, I represent all 836 rows simply by the dotted arrow, which means that this extends all the way down, binding every row to every circle. If any of this was unclear, I encourage you to read through Mike's post on the subject, which is contained in the lecture notes. Or if you want a more complete treatment of the subject, look at the book reference in the lecture notes, Virtual Storytelling With D3, by Richie S King, which inspired this graphic and explanation, of the mysterious databind process. The next line of Dimple code we have to replace, is the axis construction code. In Dimple, this actually happens in two places. First we added a time axis, corresponding to the year of our data, which we made the x axis. We also added a y axis, corresponding to the attendance for that year. One subtlety of the X axis that we did in Dimple, was that by specifying the parse format as only the year, Dimple automatically aggregated all the games for a given year, and summed up their attendances. D3 won't do this for us, but we actually may not want it to. As we add more context to our visualization, instead of visualizing a single year and the total attendance for that year, let's try visualizing every game. Before we go any farther, deconstructing this chart we created in the previous lesson, I wanted to take a step back to talk about what type of narrative we might want to build around this data, and also how we might achieve it. It is important to keep in mind as we iterate on this graphic here, that it's okay to make mistakes. And when I say it's mistakes are okay. I mean that the process of creating an affective and engaging visualization, is often a winding road. We may not perfectly deconstruct and build upon this chart to achieve the affect we want. We might have to backtrack, try a new approach, and go down a different direction. Again, this is all part of the process of prototyping and sketching of visualization. I've said it before and I'll say it again, is that the difference between something like EDA and the process we're about to go through with data visualization, is that EDA typically helps you find a message you want to tell. In my case, the message I want to convey to my audience is that we're in an increasingly global and capitalist age. What do I mean by that? And how might I tell it? Well, even from looking at this simple chart of total World Cup attendance over the years, we can see that the trend of the World Cup attendance games. An aggregate is steadily increasing over time. Proving causation is very hard, as we've seen previously, but what I want to propose is that early on in World Cup history, it was one less known and less popular. But also the past was a world much more constrained by geographic and logistical issues. As we've seen advances in transportation, such as, planes and trans-Atlantic and Pacific flights, maybe people from all of the world are able to attend a World Cup Held in a single country. And the capitalist side of it is that as the games become more and more popular, both FIFA the organization that organizes the World Cup, and the home country itself could benefit economically from the influx of visitors and tourism. But also from the games itself by creating more stadiums and more public works projects to help support the influx of people. But I'm sure you're thinking it's a far journey to go from this simplistic line plot to convey this message is a succinct and effective way, but that's what the next series Of videos and code will address. This iterative process of data visualization, which helps us communicate our message in the most effective and efficient manner. We've already done our EDA, and have the message we want to tell. We just have to work and iterate, on visualization such that, we can communicate that message to our audience. To address the places where our current visualization is lacking in terms of communicating our message, one of the key things to focus on is how do we efficiently and effectively communicate a change over time. Our static chart shows the trend over time, but what doesn't come across as clearly are some of the nuances in the data. One way to address this might be to try visualizing our data with finer granularity. Instead of showing the aggregate attendance for a given year, let's see how it comes across if we visualize every individual game and its attendance. As I mentioned before, the next task at hand is removing the code in dimple.js, that deals with axis, and coding it up in D3 itself. Well, with this code here, both creates axis and changes how the x axis is formatted. We're simply going to remove all of it and build it back up in D3. In lesson one we saw how to work with D3's extend and scale functions to convert data values into proper pixel values. The first step in figuring out how to draw our x and y axis in D3 is to first find the extent of each of the columns which we'd like to visualize. In this case our x axis is going to represent the date column, and our y axis is going to represent the attendance. Remember that the extent function finds the minimum and maximum for a given data based on what you return from the assessor function. In this case, as applied to our data, extent runs the function we've passed on each element of our data, in this case the argument D. And based on what you return from this function, extent internally keeps track of the minimum and maximum values its seen. The same principle applies to our attendance. And notice that we're using the same function, d3.extent in both of these cases, but since the function we're actually running is slightly different, in the first case, we're returning date, in the second case we're returning attendance. time_extent and count_extent are actually very different objects. And to map the date and the attendance from their initial data values to an actual pixel value, we use D3's scale function. One thing that we haven't seen before is how to deal with time in D3. Notice, rather than just using d3.scale, we're first going into the d3.time module, and then calling the scale function contained within. For our attendance, or our count scale, since attendance is an integer, we can directly use d3.scale and then use a linear function within. And for both the time scale and the count scale, the domain we're mapping from is the minimum and maximum dates, in this case the time extent for the attendance, it's the minimum and maximum attendance. In this case, count_extent, which get mapped into the range for the x axis, the margin to the width. So basically, the left-most part of our chart and the right-most part of our chart. And for the y axis, the quirk of SVG where it has an inverted coordinate plane, a y value of zero is actually at the top of the webpage. And as the y value increases, you go down the page, so in this case, the minimum value of attendance starts at the height of our chart. So at the very bottom. And it goes up into the top of the chart, in this case, margin. Now something that I glossed over that I want to return to is, in finding the minimum and maximum date, I simply accessed the date column. If you remember, from when we previously inspected our data in the console. The date column is actually a string representation. In order to ensure that when we're comparing dates to find the minimum and maximum that the comparison actually returns the correct date. For strings, there may be some ambiguity in what's greater or less when referring to a date. So, to be safe, you should always work with a JavaScript date object itself. To do so, you can either use d3's built in date parsers, which I'll show you in just a second, in-line in the functions which we need to do any sort of comparison. Or, since we will most likely always need the date column to be a date object. We can parse it as we load in the data. Scrolling to the bottom of the page here, we're going to revisit the D3 tab separated value file loading function. In this case, d3.tsv. And previously reloaded our data file. In this case, again, remember it's not simply the World Cup data set but it has geographic enhancements to it. The latitude, the longitude and the home team. Which once it's loaded will run the draw callback function which contains all the code to draw the chart. One thing that I haven't covered previously, but that's very powerful, is that in this function that initially loads the data, in addition to the file we're loading and the callback we run, in this case draw, once all the data's loaded, we can run an intermediate function. That can transform our parser data before our draw function gets called. In this case, this intermediate transformation function that we pass functions in much the same way as the functions we passed to our extents where the function gets run for every data point. In our data file. One at a time. The argument D in this function is simply a single row of our data file. And whatever we return from this function is what actually gets passed to the call back. Just to illustrate what I mean by this, I'm going to always return the same thing for every row of my data. In this case, a JavaScript object that has a single key, i_love and a single value, data visualization. And again this is just a toy example that'll hopefully clarify what's going on in this intermediate function. And if we save our file and refresh our page, remember there's a debugger in our code right before much of the main, drawing logic it's called, so we can inspect our data there. We stopped at the debugger. If we put right after our D3 SVG data binding, with our data, and let's look at what's actually contained in data. The data has the same number of rows in this case 836. But if we look at what each one of those is. We have the object that we returned in our intermediate function. In this case an object that has a single key, i_love, and a single value, data visualization. If we use the internal pretty printing function in the Chrome console. The console.table function on our data we can see our data has a single field, in this case i_love, that for every row has the same value, in this case data visualization. This happened because as we load our World Cup_geo data for every row, we first call this function. And since we always return an object to have a single key, I love, in the single value data visualization, which has the affect of making every row exactly identical. But now let's do something a little more useful and rather than returning a single somewhat nonsensical data object from our transformation function, let's parse our date. To parse the date column, we're going to be using D3's built-in time formatting accessed through d3.time.format and similar to the time format extreme we used in our dimple.js code for d3's formatting. We give it a similar string, which uses strftime variables. In this case, the things here, which are preceded by a percent. %d-%m-%Y and so forth, which each correspond to a day, month, year or time format. And then d3 simply pattern matches the pattern we told it to expect our dates in. And the actual date string. Here I've put an example of the format of dates in our data file where we have the day as a two digit integer, a dash, the month as a two digit integer. A dash, the year as a four digit integer and then the hour and minute of the day contained within these parentheses. So going to our format string, percent d corresponds to a two digit day. The dash corresponds to a dash. And since we don't want it to actually. Pull out the dash into the date object that gets returned. It simply skips over that. %M corresponds to the two digit month. A dash simply says skip the dash. %Y matches a four digit year and then we have a space left parenthesis two digit hour between zero and 23, a colon, and then a two digit minute, and then rest, a space, H, and right parenthesis, are simply the trail of the string. And to use this formatting, we simply, on the format object, call the parse function and pass in the string we'd like to convert. In this case, D bracket date corresponds to some string that'll look similar to this that I've shown here as an example date. Gets patterned matched to extract the appropriate day, month, year and time. And then we restore that in the date column. So in this case we're over writing the data column which is a string initially here, with a date java script object. One little nuance that I feel I should mention is that the time of the game is actually the local time of the country where the game's held. Or for simplicity. And since, for a single year or a single World Cup we only care about the relative times of each game, we can simplify things and not worry about converting all of the local time zones across all of the years. And the other field that will be good to transform for all of our data, is the attendance field, which is stored as a string. In this case, we transform the attendance field and then overwrite the value on that same JavaScript object, in this case D. And then we return D, which gets passed into the function. So the way to think of this, to go from our initial data file world_cup_geo.tsv to our draw callback function, which actually draws our chart. The .tsv function of D3 reads in a row of world_cup_geo. In this case let's say the date is a string 27-05-1934, space 1600 hours and the string, 25,000 for the attendance. It then gets passed to the transformation function. In this case, an anonymous function that doesn't have a name. We perform some transformation on that row or JavaScript object that gets passed to it. We transform the string that represents the date using D3's date parsing into a JavaScript date object. And also transform the string of the attendance into an integer representation of the attendance. And then past this new object to the draw fallback. What operator did we use on our attendance field to transform it, and what does it do? In other words, what data type was our attendance field initially and what data type did it get transformed into? You can use any place on the internet to find the answer but I highly suggest using the Mozilla Developer Network, or MDN to find the most up to date and accurate documentation under JavaScript language. Answer in the box below. The operator I've used here, simply a single plus prepended to the attendance field, is what's called the unary operator. It's a little JavaScript trick to convert a string into an integer. I'm sure if you've used JavaScript or other programming languages, you've used the unary plus operator's sister, the unary negation operator. In this case, a single minus sign. In this case, with a single minus sign, we're simply negating the value. Which usually makes pretty intuitive sense. The unary plus, on the other hand, looks a little bit more strange. Again, whatever you put it in front of, it tries to convert into a numeric form. In this case, since attendance is an integer, it will convert it into an integer and then update the value of the attendance column. If we try to use the unary plus or the unary negative on something like a string that doesn't have a natural numeric representation, we'll simply get not a number back. And if you're curious, I encourage you to experiment in a web browser console or other JavaScript environment And now I want to return to the extent function, and inspect what d is in this case, now that we've transformed the date and attendance column. Notice how I've put a debugger statement in the anonymous accessor function here. So the execution will stop, and b stopped for every row in our data. Let's go back to the web page and see what that looks like. Refreshing the page, we see here, our first debugger got caught. If we click the Play button, we'll jump past this break statement and happen to catch the break statement in the extent. Since execution stopped in this function, the scope is the same scope at this point in the code. Notice here that there's a single argument d to this function. So we should be able to access d in the console since we have a debugger statement there. Here we can see d corresponds to an object that has the following fields in it. One of which is the attendance and there's also a date there. Notice that this happens to be the first row in our data set, game_id 1. And as we continue past this debugger statement. It'll catch at every subsequent row. Looking at the date here, we can see that our returns a more complicated date object. In JavaScript, to check for a specific data types, it's somewhat cumbersome. And we have to basically use the instance of operator to do a Boolean check of what's on the left side with what's on the right side. So in this case, if d bracket date is indeed a JavaScript date object, this will return true. If not, it will return false. As you can see here. It has returned true. Now if we didn't have any assumption of what the variable on the left should be. We'll have to go through each of the JavaScript primitive types continuously running the instance of check. And looking at the attendance column here, we can see that it's 25000, rather than the string 25000. And just a note in JavaScript, it being the flexible language it is. We can actually use dot notation to access the field of an object or the bracket notation. The one limitation with the dot notation is if your field happens to have a space in it. If so, you'll have to use the bracket notation with the string argument. But it's usually good practice to have all the keys of your object either be a single word, or instead of spaces, to use underscores. In this case, d.attendance returns the same value as d{*attendance*}. And you'll notice, if we try to continue the debugger repeatedly gets stopped within the extent function. Each time d actually is a different object. In this case, I've continued a few times, so we're at game_id 6. Continuing one more time d is now game_id 7 and so forth. So let's remove this debugger from our code since we don't want to go through all 800 plus rows of our data. And then continue to actually create the axis objects from these extents and scales When creating axis in d3, I would say the hard part is finding out the proper scales for both your axes. Once you have them, as we do here, creating a d3 axis object is quite simple. Since our code's getting slightly more verbose. At least compared to the Dimple JS code we had earlier. I've added comments to each section of the d3 code, to describe what functions performed with N. I've also moved the debugger down from the top of the file to right before we create our axes. In this case, the axis function.axis is in d3's svg module. To create an svg axis, and we need to specify a scale using .scale to tell d3, what the range of the axis represents. In this case passing in time_scale for our x axis. And since d3's so flexible, we can chain other functions to our axis, to customize its appearance. In this case, we want our ticks to be, every two years. In this case to specify years we go into the d3 time module and specify years. If we wanted a finer grain we could specify a different time object. For example, let's say days. But in our case, since the World Cup happens only every four years, specifying every tick mark every two years, should be more than enough. And here we do the same thing for our y axis. Passing the scale of count_scale, which represents our attendance range and domain, and since this is the y axis, we specified that we want to orient it on the left. So we now have our d3 axis objects, but what we don't have, is the axis in svg on our page. So similar to what we saw in the data binding, we can have D3 objects which exist in our JavaScript scope, but it is not until we actually choose to select some elements on the page, either HTML or SVG. And append something to them which has some visual representation that the actual axis objects themselves get rendered as SVG. In this case we first select the SVG which contains our chart, we append a group in this case SVG g-element. And again you can think of this analogous to a div tag in HTML, simply a way to group other SVG elements which doesn't have intrinsic visual display itself. So think of a group in SVG. As some invisible fence around a bunch of other SVG objects. We add a class to it. Actually two classes. Both class x and class axis. And then, change the transform attribute on the group to move everything contained within the group, zero pixels in the x direction, and height pixels in the y direction. Since SVG has an inverse coordinate space by translating rg we move it zero in the x and height in the y which corresponds to the bottom of our chart in this case. And for the y-axis we do the same. This time, instead of giving it the classes, both x and axis, we give it the class y and axis. Notice that the axis class is common between the two. This allows us to apply CSS selectors to both the x and y axis. But since we also attached a separate x class and a separate y class we can then further specialize the x and the y styling independently. For the Y axis, remember we oriented it on the left, and then also translate it margin, in the X direction. In this case just a few pixels, and then zero in the Y. In this case, touching the top of our chart. So in indigo here we have the Y-axis and the X-axis which is margin over and height down from our coordinate space which starts at 0,0. Remember, however, when we created our Y-axis count scale. The range was height to margin. So even though we don't translate our y axis as Fiji object any it only extends to margin from the top. And before when I drew the x axis it's translated zero in the x direction. But again if you scroll back to the timescale, you'll remember that the timescale range went from margin to width. So again this starts not at zero, but margin pixels over. The call function that actually gets past the time axis and the count axis is a way to pass the access object through the function call chain. However understanding this JavaScript function and its nuances is beyond the scope of these videos, but I've left some resources in the instructor notes if you'd like to dig deeper. One key paradigm in D3 that we haven't explicitly covered, since dimple js abstracted it away from us, and in all the coding we did in lesson one, we didn't have any bound data, is the anonymous function as a call back, to access an element's bound data. It's an anonymous function, because it's not given a name. And if you come from other languages like to Python, it's very similar to the lambda. And I call it an accessor function because it allows us to change the behavior of a generic D3 function. Here I'm working with the extent to act differently depending on what we return. So again this anonymous function is accessing the attendance in our data. So pulling out the bound attendance values. And since we're returning them. The extent happens across the attendance column and returns the minimum and maximum values. Again in this case we're using the same d3.extent, we're passing the same data. And hopefully you were wondering previously how do we get a time extent and the count extent from very similar code? Well the answer is the anonymous accessor function. For the time we return the date and for the attendance or count extent we simply return the attendance. And while this function's quite simple in both these cases. You can perform all sorts of complicated logic within. And this is exactly how d3 makes its charts data driven. The data bind, or .data function is only one side of the coin. The other side is the anonymous accessor function, because after all. What good is bound data, if there's no way for us to access and use it? The next and somewhat final piece of the, puzzle to convert our Dimple.js plot to pure d3, is to actually draw circles on the page. I put a debugger right after all the code we've written so far. And let's check in and see what our page actually looks like. Going back to the browser, we can see the debugger's paused here. You can see we have a y an a x axis. Though they still look pretty crude they are in the right relative range going from zero to probably looks like a 180 thousand for attendance and the years even though they're very squished and scrunched together if we actually read them go from 1932 to 1934 to 1936 and so forth, all the way to 2014 if we look to the far extent of this axis. And now we're so close to having our chart done. And I've happened to save the best for last, the actual circles we want to draw. For the sake of simplicity, I'm only going to recreate the scatter plot. Now the way the sense of where we are in terms of the axis, let's jump back to sublime text and actually create some circles for our data. In dimple, we simply need to specify that we want to draw some series corresponding to some shapes, in this case, scatter or line. Removing these two lines and also since we don't have any dimple code left, we can simply remove the draw. In d3, there's not an explicit draw function or rather, every SVG gets appended to the page whenever we create it. Remember, in dimple, since it's much higher level than d3. You simply have to specify what axis this series corresponds to, and it automatically knows the extent, the scale, the axis of that. Now here's another quirk of d3, if you remember from above. When we bound data we actually appended circles to the page, and now we're selecting the circles already on the page to add an x position, a y position, a radius and a fill. Going back to the browser, you'll notice here that there aren't any circles actually drawn, but if we look back at the code. >From where we started when we bound our data, we actually appended circles. So what gives? Where are the SVG circles which our bound to data which should be on the screen? Answer in the box below where you think the circles are on the screen or why they're not showing up visually in our chart. There's a few answers to where are all the circles, but the shortest and simplest is that they're simply on the page. If we do a D3 select all circle, we can see that it returns an array of 836 elements that correspond to circles. SVG ones. When I hover however, notice that the circles show up at pixel zero by one in the top left of the screen. If you actually inspect the DOM, you'll see that they are indeed there. So our data bind in append has correctly worked. It appended 836 circles to our webpage which are bound to data. And again, if I access one of those circles, let's just get the first one, so select all circles, get the internal array and then get the first circle. It returns to us a circle DOM element. But remember when we did data binding, I told you that every element with bound data has an __data_. And as you can see here, by accessing the .__data__ attribute of the first circle SVG object, you get returned a JavaScript object with all the data that's been bound to it. D3 isn't necessarily magic, but it hides a lot of complexity for you. So it might seem mysterious. But if you dig deep enough, you can always find out where the source of what it's doing is. In this case, the data attribute in the DOM. And something I don't advise, but you can do, is you actually mutate the data of this circle by changing individual fields on the .__data__attribute. And again, this is a somewhat bad practice unless you know exactly what you're doing since it could lead to issues of data corruption, here we've simply changed the attendance of the first gain to 1 million. But enough fooling around. Let's get back to the code and actually draw some circles. And the way to mae the circles properly displayed is by this block of code here. Currently all the circles are overlapping in the top left of the screen and visually don't have any representation, because we haven't set a radius or a fill for them. So what's happening in this code here, is we're saying find me all the circles on the webpage which there's 836 of them there. Change the .cxf attribute of the circle, which stands for center x, so change the x position of the circle, according to the anonymous accessor function. And again, since this function gets past to d, a different bound data object, every time it's called, we can position every circle at a completely different place on our chart corresponding to what's actually contained in its bound data. In this case, the pattern to do this in d3 is to take your scale object and pass in the column that corresponds to, in this case, the x axis. So, since our x axis corresponds to the date of the game we pass the date, which in this case is a JavaScript date object, to our time scale which converts it from a date object to a pixel value and return that from our anonymous excessor function to set the exposition of that circle. Again, that was quite a lot, so let's explore this in the web console by inserting a debugger statement. Refreshing the page and jumping to the debugger inside of our anonymous accessor function, we can now inspect what d is. In this case, we've broken on the first game. So game one, which has attendance 25,000. Looking at d[date], was have a JavaScript data object corresponding to May 27th of the year 1934. But again, d3 needs a pixel value to know where to actually draw the circle. We can't say draw the circle at position May 27th. And the way to go from a date, in this case, to a pixel value for our given chart is to use the time scale we created earlier. So in this case May 27 1934 happens to correspond to x pixel position 132.6 and so forth. And looking at the rest of the code here, we set the x position of the center of the circle to correspond to the attendance column. So again, whatever attribute we're trying to set in this case cy, gets set to be whatever gets returned from the accessor function for an individual data point. And just one last point of note. I set the radius and a color variable earlier on in my code, where I also set my margins, such that if I need to change one, let's say I want to make all the radiuses of my chart bigger. Or change the color in some flexible way. I don't have to change at every place in my code. In this case, it's only in one, but let's say I had a line the same color as the circles. I want to be able to make one change, and have that propagate through all my code. So I've left color and the radius of the circle again as variables. To continue through all the debuggers, I'm simply going to close the web console and see what gets displayed in my chart. And as you can see here, we've drawn one blue circle for every game of the World Cup throughout the years. Now, there's a few style issues, I'm going to clean up simply with some CSS. Mainly, the width of the access lines, the years on the x-axis, and something you may not be able to notice here, is that there's a lot of overlap in the circles. So by adding some opacity to the circles, you can see similar to what we saw in the Facebook IPO example, some overlap to know the density of points. So again, using CSS to style my axis and my SVG circles, in my text, the chart looks much nicer and much crisper. I don't want to go, spend the time to go through every one of the CSS changes I've made, but if you're interested, and you're comfortable enough with CSS, I encourage you to look back at the files and use the CSS resource we have provided, to understand better what's going on. So after all of these updates, that we've made in D3, we finally have a equivalent chart that we made in dimple js, with its short five lines, but again by converting our previous chart to D3, it's going to allow us much more flexibility to add both interaction and to customize the look and feel of the chart. And when all is said and done, took only approximately 40 or more lines of D3 to recreate what we've done in dimple in five. But if you're going to be a stickler about it, each of these statements here technically is one line, one long chain of functions. But for clarity's sake, I've written every new function call on a new line So just to recap, our circles, while we bound them and they were on the page, they had no x or y position, radius, or fill color. So what this chunk of code basically says in English is, for each data point or circle, change its x position, according to its date and its y position according to its attendance. Add an attribute of radius. In this case it's a radius of three as we said previously. And fill it with a color. In this case blue. Before I move on I just wanted to make one more point about the anonymous accessor functions. I'll go over rather a different way of looking at them. While you can think of these as any other function it takes some input in this case D which corresponds to an individual row from our data and gives some output, in this case, for the exposition of pixel value returned from the time scale. I often like to think of the accessor functions as analogous to the properties of a class, for folks who are comfortable with object-oriented programming, or in a more simple sense, simply a variable. In this case, the accessor function for setting the exposition returns a variable value depending on what data point gets passed into it. So again while you can put some logic to transform your data or perform some other actions inside of the accessor function, typically I only use in the sense of pulling out some data. And returning some value, that's dependent on that value I pulled out. So in most of the uses of this anonymous accessor functions in D3, it's often useful to think of them as some data dependent value. Based on what the bound data is, the accessor function should return some value derived from the data. And again this allows us to customize each function for each data point. In this case for datum one placed at the x position of datum one's date. For datum two placed at the exposition of datum two's date and so forth all the way to datam 836 or however many pieces of data you have in your data set. So, since d3's very declarative we only have to specify what we want, in this case the exposition. Using this knowledge about data accessers and what you already know about d3 functions to change the properties of HTML or SVG elements to add some more context to our chart and make a comparison, add d3 code. To make the home country a red circle and leave every other country a blue circle. And also for each of the games in which the home team is involved in, let's make them slightly more visible and increase the radius to five. And remember, as I showed you previously, we've augmented this data to have both a latitude and a longitude. As well as a home column that represents the team name of the host country. Just touching up some of the code here its fairly simple so I'll explain it quickly. But instead of setting the radius automatically equal to some radius constant. And setting the fill to the constant color, in this case blue. We've put an if conditional in our accessor function to basically make the radius dynamic or dependent on the data. Again, we're letting the data, in this case the bound data, represented by d for each circle, drive how the visual representation of our graphic is on the screen. In this case, if the home column correspond to team one or team two so the home country, is one team in this game. So we return the radius. And what I've set here as the multiplier, again I create a variable earlier on, so I can have a more dynamic size increase. In this case, my multiplier is simply set to be 1.5, which has the effect of creating your radius of 4.5. If you want it exactly five. I could simply return five instead of the radius. But this multiplier let me play around in a more flexible way with the visual representation. And a very similar process for the color. We simply check whether the home team is involved, and then return either red or blue. Since we've copied a lot of the code for each of these, we could actually abstract this further into a common function to basically return true or false of whether or not the home team's playing. And then possibly pass in two different values. Again, for sake of clarity I kept it verbose. I want to just take a step back to remind you what direction we're going in, the iterative process, and what our end goal is. One of the more common techniques to add context to our graphics and data is the use of juxtaposition or comparison. In the case of our scatter plot, we want to draw attention to the games involving the home team by making them red and slightly larger so that someone reading our graphic could compare them to the games which don't involve the home country's team. Doing so leverages some of the theory of pre-attentive processing by drawing the reader to those games which do involve the home team so that the audience can implicitly compare them to every other game. Again, reminding you of the message of what we're trying to convey is one of globalization and capitalization. A priori, we may not know what effect making the home games red and slightly larger will have, and whether or not the comparison it creates helps communicate our message. So let's go back to our web browser and see what effect this actually had. As we can see here, early on in the World Cup games, the games involving the home team were actually very well attended. But as time's gone on, depending on the year, sometimes the home team's not even in the tournament. Or there's other potentially more interesting games which have a higher attendance rates than the ones involving the home team. One hypothesis for why this might be happening very early on is that many of the fans who show up to the games are from the home country, due to the fact it might be hard to get to a given World Cup with the current state of transportation and technologies. As flying became more commonplace, as airlines have blown up, maybe over the years it's just much easier for teams and fans to get around the world. One way we can actually fix this problem of the red circles and not being able to know what they represent is by a very simple addition of a legend to our chart. The legend is useful to associate a label to each of the circles here. Let's see what that looks like in D3. A very simple but powerful way to add context to your visualization or graphic is through the simple use of text to add labels or annotations. I wanted to go through and show you how to add a legend using text. But this process can be extended to adding any sorts of labels or annotation to any point on your graphic. What we have here is pretty standard. And we've seen it before with all the circles. Is we simply append to an SVG some group element, giving it a class of legend. We simply move that group to be x position 100 less than the width, so it's going to correspond to the width minus 100 and a y position of 20. So again, y position of zero is the top of our chart. So, this is going to be 20 pixels down from the top. Again, this is one of the quarks with D3, so we've appended a group. And then select that same group we've appended. We bind data to it, in this case simply the strings home team and others. And this is also to show you the flexibility, that your data doesn't have to come from a file, doesn't have to have many rows in it. In this case it's simply a JavaScript array with two strings in it. Since we don't already have a legend on our page the .enter selection is going to return two group elements. One for the home team and one for the others. Or rather placeholders. And then for each of those placeholders bound to Home Team and Others we append a group element. And again if that seems confusing in words look back to what we did with the circles. Or run each of these functions in a web console to see what values are passed in and out at every step of the chain. So now we have a legend with SVG group elements bound to some data. But we don't have text yet. What we have here is somewhat similar to what we did with the circles, for each one of our data points. Since we use this over and over again, in practice, I would most likely abstract this IF conditional into some function outside of this block of code. But, for clarity's sake and understanding, I've written it out, and with this legend, these groups we've just created. I'm going to append a circle for each of the bound datapoints. Set the y attribute of that circle to be some variable i times 30. Previously we've only used accessor functions like this to access the datum that was bound. But if we specify in our function, two arguments, (d, i) in this case, we actually get the index of the data point. In this case, we only have two data points, home team and others, so i of zero is going to be home team. I of one is going to be others. And depending on which position we're at in the array we passed to the data binding function, we're simply going to increment the y position by 30 pixels. This might seem silly, for a legend that only has two items in it. But let's say we had a complex chart that maybe had ten different lines or types of circles or shapes we've drawn. We wouldn't have to want to specify either in the data some value or hard code in the exact pixel every one of those ten lines should show up at in the legend. For the radius and the fill, nothing new here, we simple check, is the datum home team, if it is, we're going to draw it to be the same size as the home team circles. Radius times multiplier. And if it's not the Home Team just draw it the same size as all the other d circles. And for the fill, if it's the home team fill it to be red and otherwise make it blue. I'm going to comment out this last bit of the legend code that appends text, save my file and see what shows up on the page. Refreshing the page. We have our initial chart and here we see two circles that seem to be floating in space. But again we haven't appended the text that corresponds to what each of these circles represents. We've only drawn a circle the same size and color as the one we want to label. So now let's go back to the code and actually add text so that a reader knows what the small blue circles are and what the larger red circles are. So this last bit of code with the legend, we've put our circles in. Now we want to append text. For the text SVG instead of cy it's simple y, there's no center to the text. Instead of cx, it's simply x, since we only need to specify the y and the x of where we want to draw the text. In here, while it may seem somewhat arbitrary we've actually drawn the text at the same position i times 30 as each of the circles, but this is actually going to draw the text. Slightly higher, since it's going to draw the bottom of the text at position i 30, and we actually want the center of our text to be in line with the center of our circle. So in our case, the default text is 10 pixels tall, so half of 10 is five, and this will position it perfectly. In line with the circle, and for the radius what might seem arbitrary of five, we simply drawn it five radii over from the circle itself, and again, for these values, they might seem hardcoded here. We can simply experiment and change them up or down to achieve a different effect and once we visually are happy we can set them in our code or abstract them into variables higher up. The last bit here simply changes the text attribute of the text SVG element. And since we've bound strings as data. D, in this case, is simply a string, either home team or others, and we can just return the datum itself without any further transformation. Saving our file, let's go back to the browser. And voila, we now have proper labels, home team and others, so that our readers know which the red circles represent, what the blue circles represent. It can draw their own conclusions given the information we've presented them. Well we may have seen red circles early on being much higher attended. Every reader might interpret this chart and find something different and new depending on where they're coming from. What their pre-existing biases are, and what relation they might have to the data. Just to recap and tie in some of the things we've covered earlier in this lesson, I would say that this is very much an author driven narrative. Partly because it's static, but more importantly, I as in author decided to make the red circles slightly larger and to represent the home team. So I dictated what information I wanted to draw attention to, which other information may not be as striking. And even by the simple fact of making the home team red, and every other team matches blue, as an author, I've influenced how a reader might interpret the graphic I've presented them. And in closing, I just wanted to come back to where we started before were even live coding. We're trying to communicate our insight and our message. In the case of this chart relating to the globalization of the world, and also capitalization of the gains in an effective manner. And again, just to remind you, always be aware of biases in your data, yourself, and your audience. And always consider how your audience might interpret or interact with your visualization. And I'll leave you with one last open-ended question. Have we achieved what we set out to by communicating our message? I encourage you to think about and post your thoughts in the forum about, what works about this visualization, what could be improved, and also whether the next step is an iteration on the scatter plot like this or something more drastic where we change. The complete form and structure as we take one step closer to best communicating our message. You have just seen how to add context and narrative to your data through the process of visualization. We've also seen how journalists traditionally do this. And how data journalism reimagines this process. You also learned how important it is to verify and validate your data. You learned a little bit about the different types of biases that can exist, such as data bias, author bias and reader bias. Now that we're comfortable with different types of narrative structures within visualizations, let's see how we can apply these to our own. We'll use interaction and animation to add a new depth of field to our particular visualization. In this case, the World Cup example. Congratulations on making it this far in the class. These next series of videos will cover two important topics, interaction and animation. I'll be showing you specific examples of how these ideas are played out in narrative structures overall. You'll see how D3 enables you to add both animation and interaction to your visualizations. And we'll really push the boundaries of what's possible by using geographic features to create a map with D3. But first, let's go through a few examples of how others have used interaction to add additional depth to their visualizations, and also tell a compelling narrative. What's an example of an interactive graphic that you've seen and that tells a really compelling story? One of my all time favorites is by Amanda Cox, Sean Carter, and Kevin Quealy of the New York Times. I'll pull it up over here. It's actually from 2009, so you know, it seems like a long time ago, at this point. But it's an unemployment graphic. I think people just talk about it as the unemployment graphic. But it's called The Jobless Rate for People Like You. Well as, as you can see. So it's, it's really interesting. First of all it starts out giving you this line. So we can see over time from January 2007 to September 2009. We can see kind of okay the jobless rate has gone up. Unemployment has gone up. For all men and women overall. Right. But what's really beautiful and compelling about this is that you can sort of you know, as soon as you mouse over this piece you know, you can interact with it, and you can start seeing like these different categories or groupings of people. And you can use these toggles up here. So I guess, okay well. You know, I'm interested in white women in this age group who, you know, are college graduates. So we can say, well, for that group, it's like, okay, the, the employment rate is really pretty low, 3.6%. But we could change. Maybe we could say Hispanic men who are younger, for example. We can see the fluctuations over time for that group, and see that they, how much higher unemployment rate, at least as of 2009, right. So I think this is, this is really let's see. If we click into some of these I think this rescales to, yeah, so You know, unfortunately, you can see who has the highest unemployment rate. Like it's so high that we have to rescale the chart, right? It's a black man, 15 to 24 without a high school degree. So, and it's really compelling because you can get a sense of the, kind of massive inequalities here? But also, you know, the graphic works. Just on its own. Like, even if it weren't interactive, this is the kind of thing you could see published in the paper. Like a static version, right? And so you could say, okay, well, I can see, I can see the unemployment is going up. But as soon as you have a graphic and you can kind of, you know, find yourself inside that graphic, I think it makes it really. Really compelling. And just by tapping in a couple different categories and say, oh wow, I'm in this group. This represents me and now I can see how I compare to the average and how I can compare to everybody else. So Matt, why is interactivity so important for data visualization? We think it's really important because it lets you understand a lot more about the actual data that's shown in a graph. So instead of not being able to see what the actual name or object or company that you're looking at in a graph is, if you have, let's say, text on the hover, and the ability to zoom and toggle. You can really explore the graph and the data further. So we actually have an example here that shows why this works pretty well. So here we can see four degrees of data about this graph. So across the x axis we see per capita GDP in various countries. And across the y axis we see life expectancy in years for folks who live there. And we can do things like pull this up and down, we can zoom in and check out the bubbles themselves. And what you can see here beyond the actual X and Y axis is the bubbles are sized for the population of a country. And they're colored for the continent. And so you can see in the legend here the different clusters based on the continents that they're a part of. And so by being able to see more than just the normal x and y plotting, you can see things about clusters of continents, for example. If like here, you can see. These are mostly continents that are, or countries that are in Africa. And then up here, you have more of a concentration the Americas and Europe. And then also, by being able to, by it being web-based, we can do things like embed live graphs or live links into it. So you can link back to the source of the, of data if you'd like to show where it comes from. We can also show the actual data behind the graph. So any time you make a graph, you don't have to worry about whether your data's lost. And then we can actually show the code for it. So you can see how to remake that from different programming languages. And so the fun thing is then once you've made that graph you don't just have to share it at a link here, though you can. You can actually just put it in iframes. And so it, you can then just put this on to a website so other folks can also get that same interactive experience. I just want to give you some context as to where we are before we move forward. We have seen examples of different narrative structures and what effect they have on our overall visualization, including both author-driven and reader-driven narratives. And we've also seen what flexibility and power interactivity affords us when creating a customized graphic that we want our readers to explore. And we have seen how to add context to our World Cup visualization, but in doing so, have learned that both a line plot and a scatter plot may not be the best form to convey our data story. In this lesson, we will further iterate on our graphic and continue this process of sketching to arrive at our final visualization. The first step in this process will be to add geographic context to our visualization by plotting our data on a map. And throughout, I'll show you how to enhance an author-driven narrative by leveraging temporal effects through animation with D3. And we will finish by creating the mouth of the martini glass structure by allowing a reader to explore a graphic interactively, in addition to being able to drill down and inspect data at a much more finer grain. The first step in this process of adding context is to create a map. D3 has some of the best geo capabilities out there, and there is one area where it really shines. Well you can create charts using other libraries. We would be hard pressed to find another tool that makes creating data-driven maps, as powerful and fun. We will start simply, and build up, by applying knowledge we've already learned, to create our interactive map. The first step of which, is to simply acquire data, to draw map, which we can then plot the data we already have, the attendance data for the World Cup. Historically, working with maps has been a bit cumbersome since the files you need to work with, are usually large complicated data formats, such as Shapefiles, or other proprietary formats. The reason being, that Shapefiles typically encode a lot of data when you think about it. If we wanted to draw a map of all the countries of the world, we would need exact boundaries of every country, as a series of paths or coordinates. A few other formats have emerged, somewhat hand in hand with d3. Two of which are very related. GeoJSON and TopoJSON. When working with web technologies, JSON can be thought of something as the lingual franca, and acts as a common interface between libraries, languages and technologies. Almost every programming language and environment, has facilities, to work with native JSON, in some form or another. And especially when working with d3 in JavaScript, JSON's the most natural format. So, when working with maps in d3, it seems only natural to use a JSON based format to encode the coordinates you need to display. And that's exactly what GeoJSON is. One issue with Shapefiles is that they encode their information in a binary format, which isn't readable by a human, unless you use a special program to interpret the shape file. GeoJSON on the other hand, encodes very similar coordinate information, using valid JSON, with some minor extensions. And it results in much more interpretable, and human readable, and inspectible data. One very nice feature of GeoJSON, is that it's very easy to explore and debug using many of the common development tools, such as simple text editors, or even in the browser console. One of the issues with GeoJSON however, is that to achieve these features of being valid JSON and human readable, the data file itself is often a bit more verbose and substantially larger than a binary Shapefile. And since often when building maps on the web, we need to send this information with any web request. For our graphic, it can put a strain on both our server and the browser, and increase loading latency. And one of the final issues I want to go over with Shapefiles, is they can have some storage limitations, in the number of properties you can attach to given shapes, such as names or other data. And Shapefiles are limited in their maximum file size, limiting how precise the coordinates in the shape of the map can actually be. The third data format that we didn't cover, TopoJSON, is an extension to GeoJSON. It's actually much smaller than both GeoJSON, and Shapefiles in raw file size, but also encodes topology, hence the name TopoJSON. Which Shapefiles and GeoJSON, unfortunately, cannot do. For the sake of simplicity, and since we won't be using a whole lot of topological information in this lesson and class, we'll be using GeoJSON, which in many cases, is good enough. Check all of the following which are benefits of GeoJSON over shape files. It is a more compact format, it is human readable, it can be parsed by most programming languages, and it can encode topographic information. Two benefits the GeoJSON has over shape files is that it is human readable and inspectable, and since it's valid JSON it can be parsed by most programming languages. One downside of GeoJSON however that achieved these two things it's often more verbose, resulting in a larger files size. And neither GeoJSON or shape files actually can encode topographic information. To display a map in D3 you do not theoretically have to do anything much different from when we displayed points in a scatterplot. We simply need to convert from some data representation to a screen representation, or rather go from the domain of our data to some range of pixels to draw on the web page. In the scatter plot we went from years, represented as a date, and attendance, represented as floats, to pixel values. Or rather, x coordinate and y coordinate on our chart. And for our map, we do exactly the same thing except this time we're going from geographic coordinates to an associated pixel range. Or more specifically, we're going from a latitude and a longitude coordinate to pixel values. The latitude actually corresponds to the Y coordinate, and the longitude corresponds to the X coordinate. In the scatterplot we used D3's scale to go from our data domain to our pixel range. And in a very analogous way. To convert our geographic coordinates to a pixel range we have to use a projection, or more specifically in our case, we'll be using the Mercator projection. But let's take a second now and really understand what a projection is. Coordinate data that represents points on a sphere, or our case the globe, actually encodes information in three dimensions, and since the Earth, being a three dimensional object or a sphere, there is no perfect way to display it on two-dimensional surface, such as a computer screen or a piece of paper. One approach that you could take, and is often used out there, is to simply render a globe or a three-dimensional object in a webpage using three-dimensional graphics, but this has its own set of complexities in addition to the fact. You can usually only see one face of the globe at a time. The other, much more common approach is to use a projection, which actually has been done for centuries to draw maps on parchment or canvas. The act of projection can be thought of as cutting the surface off of a three dimensional object, or globe, and trying to flatten it out into two dimensions. And there's never a perfect way to present something in greater dimensions in a lower dimension without some loss of information or distortion. So when you're going from a three dimensional globe to a two dimensional map the question then becomes, where do we distort our map? And what's often done depends on the region of geographic interest. If you're only looking at countries on the equator, you want to try to best preserve the spatial representation around the equator. And you might be willing to distort near the poles. And the Mercator projection does just that. It decides to distort the least populated regions. More simply, regions near the poles. To imagine this projection, think of trying to flatten this globe out. And in order to get a square you stretch the areas near the poles so that the Earth can be represented by a rectangle. Which also has the effect of straightening out the latitude and longitude lines. So the Mercator projection sacrifices the poles to preserve countries and areas closer to the equator which have a much more accurate representation in two dimensions. And here's a map in addition to showing the globe has plotted circles on the map to show the relative distortion at different latitudes. As you can see here, as you go south and north, the distortion increases. And it's a bit subtle, but the distortion going from circle one to two is much less than going from two to three. So there's not equal distortion going from the equator, North. But it does it's best as close to the equator as it can, to preserve area. And once you get far, far North. The Mercator projection is much more lenient in its distortions. One thing of note is that the Mercator projection actually preserves area across a latitude line. So even if you are very North, going across the same latitude line, all the circles are equally as distorted. If you've ever wondered why Alaska looks about as big as the entire United States, and Greenland looks bigger than Africa, it's simply because the Mercator projection vastly distorts countries or area so far North and South of the equator, and is often one of the most ubiquitous map projections you see out there, regardless of this distortion effect. But for our purposes, we're interested in countries in the middle region. One, because they're the participating countries in the World Cup and most frequently participating and two, the locations near the center of the map are the ones where the World Cup's actually been held. So let's return to our code and start drawing. Now that we have some sense of what things are slightly different and more complicated and we need to be concerned with geographic data, even with something as fundamental as the file type, we're going to start building our map step by step in D3. As you can see here, the familiar skeleton of code that we've always started with. Here is our function named draw that takes a single argument geo_data, named, so because this function's actually going to get passed our GeoJSON at the bottom. Notice, rather than loading our TSV of World Cup data, we're simply loading world_countries.json, a GeoJSON file that contains the outlines of all the countries. Since we are displaying a map of the entire world, there are ready GeoJSON data files for many common geographies. The most common being the entire world and the US. So I was able to find a GeoJSON of all the world countries online. If a GeoJSON file does not already exist of the region you would like to visualize you can use a few different utilities to convert shape files into GeoJSON. There's a few resources and tutorials in the instructor notes of this video, which can show you how. So what exactly does GeoJSON look like especially once we load it in with d3? Just as with our previous charts, we simply set up our margins, our width and our height and we append an SVG element this time with class map to our page. And now we can put in a debugger, so we can pause execution and expect what geo data looks like and the structure it has. As you can see here we've loaded our globe.html file, that we were just looking at in the browser and execution has paused at line 22 in the debugger. Looking at what geo data is you can see here. There is a JavaScript object with top level keys, type with value feature collection and features that corresponds to an array. And again, another one of the benefits of using geoJSON is that it simply a JSON file that we can pass around like any other. In this case, we can even load it in with d3's standard JSON data loading function, and when we inspect it in our console, we can see here the Crowoop console treats it like any other JSON and gives us this nested structure to inspect through. We can see here that in the features array there's 177 items. Each of which it's self is an object that has a geometry key and properties key. The properties in this case as a single key value pair is the name of the country. In this case the first one is Afghanistan. What makes GeoJSON unique is it's shape extensions. Here we can see each country has a geometry key that corresponds to an object that both has coordinates and the type, in this case the geometry of a country is a polygon, as we can see here. And coordinates is an array of values, or rather an array of arrays of two elements or pairs of coordinates representing the longitude and latitude of the country. One thing to note here, and it's not explicit, is that longitude actually comes first, in this case what's labelled with zero, and latitude comes second, what's labelled as one here. And that's just a quirk of the format. And there's geometry object that has coordinate points and the type, polygon represents the border of a country, in this case, Afghanistan Now hopefully you have a little more context into the process of projecting three dimensions into two for the purpose of creating a map. And now we can begin drawing our world map in d3. So to recap, we have a GeoJSON file, world_countries.json, that we load in with our typical D3 JSON data loading file. Calling our function draw once all the data's loaded. And in our draw function, we've already set up the Mercator projection. Now, we need to draw the SVG path to actually visualize the map. Think of the projection in this case analogous to the scales we used for our chart. With scales, we converted a data value. Either an integer or a float into a pixel value. The mercator projection, while internally, is much more complicated than something like a linear or logarithmic scale, performed the exact same function, given a coordinate of longitude and latitude. It spits back an x and y pixel. And to actually create the SVG object. That will represent the polygon of our map. We used D3's geo.path. Now even though the projection converts from longitudes and latitudes. Into the pixel domain, we still need to construct the SVG objects, to correctly render those pixels, and that's exactly what the D3.geo.path does. And to let it know we're using the Mercator projection, we can simply call the .projection method on the path, passing in the projection we would like to use. So let's put all these pieces together to actually draw the map with our data. This bit of code I added should look very familiar to you by now, and is similar to the code we used to draw our chart. First, we select all of the paths in this case, in our SVG since those are what were going to be adding. And bind our GeoJSON data to this empty selection, it's empty again since it's the first time we're drawing the map on our page, and notice here that I'm not just using geo_data, but I'm using the .features already. Remember geo_data actually at two top level keys. And the .features key corresponded to the array of country coordinates. And now with our bound data. And again remember that this is an array of placeholder elements. We then make the enter selection to select all the paths of countries. That are not currently not on the page, which is all of them since this is the first time we're drawing the map. And for each of this, we want to append the path to our SVG that has its d property set to this path object we created above. SVG path elements are quite flexible and can represent most any shape, and you simply pass the S series of vertices or points in the d attribute that can be thought of as the data of the path, to specify the SVG path to actually draw. Notice here that we simply pass. The d3 path object without any arguments or without using any callback successor function. How does it know which country to draw then? Well, remember, that if we leave the parenthesis off of a function name, it simple returns the function object rather than calling that function. Let's see what this looks like in the Chrome console. So, I need a debugger for right after our pack is created, and I'll pause execution and inspect the path object itself. Here we are in our code. Right beneath the path object. And if we simply type path without any parentheses, we can see here that a function is actually returned and not called. And if you notice that a path is actually a function that takes a single argument. And acts very similar to the access or call back functions, that we've explicitly defined ourselves. In this case, it gets past the data bound to each element, and to make this a little bit more explicit. Let's pass our first GeoJSON country, in this case Afghanistan, to the path itself. As you can see here, we're passing a GeoJSON object to our path function. And what gets spit back is a jumble of strings. In this case, scrolling to the top of this string, we see a strange stream of numbers. Prefaced by the letter M, separated by commas. This is simply the SVG way to specify which path to draw and which pixels to connect on the screen. Again, d3 being the great library that it is, makes it so you don't have to concern yourself with any of this messiness. And continuing through this debugger statement, we should have a map drawn on our page. As you can see here, we have a map of the world. And while there's a few quirks, in this case Greenland and then top of the Northern Hemisphere slightly cut off, and Antarctica is huge, we've drawn an SVG map of all the countries in the world with just a few lines of D3 in JavaScript. This is quite an accomplishment. To better position our map, we can use the scale and translate functions on the projection. These both allow us to move and manipulate the visual display of the map. Think of scale as similar to the plus and minus zoom buttons on something like Google Maps, and translate as dragging the center of the map to a different location. In our case, we're setting the scale to be 170, and we're translating the center of our map to be half the width and half the height of our SVG element already on the page. I encourage you to play around with the values of scale and translate to really understand how they effect the visual map that our reader looks at. If we then reload the page, we can see here that our map has been centered and has been zoomed out slightly so that we can see all of the Northern Hemisphere and still all of Antarctica. For the rest of this lesson, I'm going to translate the map down so that Antarctica gets cut off since it's not in any World Cup games. And the important parts of the map for us, in this case the participating countries in the World Cup, will be a bit larger and easy to see. And the last change to make the map slightly more readable and a little bit more aesthetically pleasing, is to change the fill of the countries from black to udacity blue. In this case, to change the outline of each country border to a darker black line and to make the stroke width slightly thinner so we can see more detail in the borders of countries. Going back to the map, we can see here there all the countries are filled in with blue, and the black stroke that's slightly thinner makes it much easier to see the different countries on the map. You should be quite proud of what you have accomplished. Before D3 and the work of its community to replicate a map like this in the browser would be quite an arduous process and require many tools, and we are now done with the first step of creating our map of the World Cup games. The next step is to add some context to our map and add in the attendance data of each of the World Cups throughout the years plotted on our map. To do so, we're going to be plotting circles on each country in which the World Cup was held with the radius proportional to the total attendance for that year. This is often referred to as thematic mapping, which refers to the fact that maps with such data often represent a specific topic or, you guessed it, theme. In our case, the theme will be the World Cup. And thematic maps are often implemented by adding some additional context, by leveraging some data plotted on the map. There's a few common types of thematic maps, many of which we have covered previously in the lessons. What we have seen previously are dot maps, which simply plot dots, potentially of different colors in a map, and can leverage negative space. Choropleth maps, which color areas such as counties, states, or countries, depending on the data they represent. And a cartogram which distorts area, shapes, and sizes, depending on some data value. And what we will be covering in this class is a graduated symbol map. It is a symbol map because we place some symbol, in our case circles, on the map and it is graduated because the area or radius, in our case from the symbols varies depending on the data they represent. Now that we have our map drawn, we need to draw circles representing our attendance data on top of it. The first step in doing this is to actually load our attendance data. Remember, we used our initial d3.json load function to load the GeoJSON data, but we never loaded the attendance data that we've been working with all along. In order to load our attendance data, we can do exactly what we have previously done. In this case using an intermediate data transform function to convert our attendance to an integer and our date to a JavaScript date object. Which we will then pass to a function as a call back that I've defined as plot points. The plot points function is going to act similarly to the draw function of previous lessons that gets past a single argument, in this case, data, which corresponds to our attendance data. And inside of it we will put the code that will draw the circles corresponding to the attendance of each World Cup. The only difference from what we've done before is that we're actually calling a d3 data loading function. In this case, d3.tsv. Inside of our other call back function, with loads the GeoJSON. This is perfectly alright and simply has the effect of saying, first load my map data, with d3.json, world countries, GeoJSON. And once that file's loaded call the draw function, passing the GeoJSON data to it, and then inside of the draw function you make another call to a data loading function. In this case d3.tsv, that says when you get through this line of the draw function, load the world_cup_geo.tsv file. And once that file's loaded, call the plot_points function so that the order of functions is called in the following. First, d3.json is called to load world_countries, which gets passed to draw. And inside of draw, towards the end, we call d3.tsv. Which asynchronously loads the World Cup data for the attendances. And once that file's loaded gets passed to the plot points function. And in theory, if we wanted to do more data loading, we can simply put another call to d2.json or d2.tsv inside of our plot points, and can nest these somewhat infinitely, but I would say it's a bad practice to go too far deep down this nesting of callbacks. And if we put a debugger inside of plot points in our console, we'll see that data looks exactly like the data we've worked with, with our scatter plot. But for this next step of drawing our map, we're going to need to group our games by the year they were held since the start. We're going to compare the total attendance from one year of the World Cup to the next. As I mentioned previously, d3 has some great functionality to manipulate data. To do this, we can use the d3 function nest, which does exactly what we need. Rather droops our data and performs some aggregation on that. I don't want to spend too much time getting into the specifics of all the possibilities of what can be done with the nest function. But I'll cover the basics that we'll be using for our map example. The nest function has two main pieces. As you can see here, we call a dot key function and a dot rollup function on the nest object. In order to specify how you want to group your data, you use the key function and you pass it in accessor callback. In this case, I've left, left it empty, but whatever this callback returns is the value that nest groups by. And once you have your data grouped in some way, you need to aggregate it in some meaningful fashion, which is where the rollup function comes into play. The rollup accessor function is slightly different than the key accessor function in that it gets passed what I've called here, leaves. Or rather, a nested and hierarchical set of our data organized by the group we previously specified. And the last function call here simply passes our data through this nest pipeline. What we can see here, is that the debugger caught inside the plot-points callback function, which gets called after our data gets loaded, that represents our attendance data for all the games, and just as standard you check if we use the console .table function, to display the first ten rows of our data set. We can see here that it looks the same even though some of the columns are smushed. But we have a game ID, attendance, team one, team two, goals, tie and so forth, so it appears that our data's loaded correctly. Stepping once more through to the key function. If we inspect what D is, we can see here that it's game ID one represents the first game, Italy versus the US and so forth with all the other data of our first row. If we call the getUTCFullYear function on our date object, we can see here that returns correctly 1934. Stepping through to our roll up function, we can see here [NOISE] that leaves represents an array. And here we can see there is an array of 17 objects. If we inspect each of these, we can see that it is one game, in this case, from the tournament in 1934. The second one is another game from the year 1934. So what gets past the roll up, is one group at a time of the grouping specified in the key function. And it is the job of the roll up function to distill, in this case, the 17 object or games into a single value, or a single aggregate. Going back to our editor, to fix up our roll up aggregate function, we need three things from each of these groups. The first of which is the sum of all the games attendances for a given year, the second is the longitude of where to draw the circle on our map, and the third is the latitude of where to draw this. To get the sum of the attendances, we'll be using the D3 sum method, which takes both sum array or list-like object, in our case, leaves, and an accessor function that defines what to actually sum. To get the sum of the attendances, we'll be using the d3 sum method, which takes both some array or less like object, in our case leaves, and an accessor function that defines what to actually sum, in our case the attendance. Hopefully, you're starting to see a pattern here and even for something like a sum. D3 defines it over some collection of data. In this case, leaves with some accessor function to customize the behavior of it. In this case, every element of leaves gets passed to the accessor callback as d. And whatever we return from the successor callback, d3 adds up and returns from the sum. The second piece of data we need from this group, is the longitude, which we'll get from the coordinates of each game. Here we're using the map function, defined on JavaScript arrays, which simply transforms every element of an array, and returns an array back. So again, in the callback function we passed a map. It gets passed d, which is every elements of leaves, and whatever we've returned gets stored in the return array cords. In this case, we want to go from the latitude and longitude of our data point to some pixel value, which we get from our projection here. So again, the projection can be thought of just like a scale that takes as input a longitude and latitude pair. And gives as output a pixel X and Y back. Now you might be wondering what we're actually doing with the coordinates here. Well we could have of looked up the home country name from our data. And centered each circle on our map and the center of that country. But for maximum flexibility, especially since West Germany is no longer a country. And the 2002 World Cup was held in both South Korea and Japan. I simply chose to compute the central location of all the locations of games for a given year. Or, more visually, if there were four stadiums for a given year, we first convert the latitude and longitude of each stadium to a pixel value, since averaging latitude and longitude can be slightly more complicated. And since in the end we want to a pixel value to plot on our webpage anyways. We're going to simply compute the average x-value and the average y-value of all the games to get some point they'll be placed centrally. Since we have all the coordinates of the games in an array, we can now use D3's mean function to compute the average. The D3 mean function, just like everything else we've been seeing, follows the exact same pattern where we pass it some array, and some callback function, which defines the operation we want to perform. In this case every element of coordinates gets passed to our callback function, and whatever we return from this callback function gets averaged by the D3 mean function and stored as a single value. In our case, in center_x. And remember the coordinates array represents the X and Y coordinates. Return from the projection function, which gets stored in an array where the first element represents the x value and the second element represents the y value. So our coordinates array is simply a bunch of x,y pairs representing the pixel values. Where each game occurred. And by summing and then dividing by the total number of all the x values, we simply get the mean, which gets stored in center_x. We can do exactly the same to find out the center_y pixel value, to then return from our rollup function. So we know the attendance to plot. And the x and y, to actually plot it out. For center_y, we simply return the second element of the x y pair stored in coordinates and mean, does all the heavy lifting for us. And the last thing to do from this aggregation here, is to return some object which will then get stored in the final result returned from our rollup. And here, we simply returned the attendance, the x and the y, which correspond to the total, the center x and the center y that we computed. And again the last part of this, is to simply pass our data using the .entries function through all of these transforms. We put a debugger right after all of the nest function, we can then inspect both the input to the nest pipeline and the output. Again, we can examine what data is, before we pass it through nest, in this case, all the rows of our attendance data, which corresponds to an array of 836 elements. And if we examine what gets returned and store it in our nested array, you can see that nested is an array of objects, of length 20, which happens to correspond to the total number of World Cups that have been held over the years. And if we inspect each nested Object, you can see here, that it has a key corresponding to what we defined in our Key Function, or rather the year of the game, and it has a values Object which corresponds to what we returned from our rollup function. Which has the total attendance for the year, the x pixel coordinate and the y pixel coordinate. And while this may seem like a lot of data transformation work to be doing in our JavaScript and in d3, if you understand these types of grouping and aggregates, it allows you to create very powerful interactive graphics, where the data you load might have to take on many different forms depending on how your user interacts with your visualization. But, enough data munching in the browser, let's get back to our map. For a map, we'll now add some context around the history of the World Cup, by plotting a circle on the map for each year of the World Cup. Where its radius represents the attendance for that year. One thing to note is that I abstracted our roll up aggregation function, into a function defined above as agg year, for more re-usability and clarity. The process of overlaying circles on our map is identical to what we did when we create a scatter plot. The only difference in this case, is that we're using our nested aggregation of our data, and if you remember internally, our aggregation used a projection. In our scatter plot, we used a scale to convert from our data domain to our pixel range. But since we're dealing with geographic coordinates. We use a projection to convert from a longitude and latitude domain, to pixel values, which we've already computed in center x and center y. And just as in most of the charts we've made in D3, we first append a group, we're going to be labeling it with class bubble. We select all the circles in that group already, which in this case is empty. Bind data to those circles resulting in empty place holders, of which then make an enter selection corresponding to all of the empty place holders with data bound to them. And for each of those we append a circle on our map. Since we already computed the center x and center y pixel. in our nested object to set the center x and center y of our circles we simply need to access that value. In this case nested in d.values with key x. And nested in d under .values at key y to determine where on our map to place the circles. And for simplicity's sake, to verify that the location of the circle is correct, we will plot the circles with a constant radius of five to start We reload the map. It looks like the circles are placed in reasonably right locations. We can see the South Korea and Japan World Cup, the South Africa World Cup. A number of World Cups in various countries in South America, a number of World Cups in various European countries and then two World Cups in Mexico and one in the U.S. and good news that no circles were plotted in the middle of the ocean. Means that the center pixels that we calculated, are approximately correct and what's left to do, is to properly scale the circles, so that they correctly represent the attendance. So, rather than using a constant value, set the attribute r, while passing an accessor function, which in this case will set to the aggregate attendance, for a given year of the world cup. Going back to our map and reloading the page, however, we can see that something has gone very, very wrong and the whole screen is black. Can you figure out what went wrong with the visualization, when we tried to set the radius of our circles? Well what's happening, is that the attendance, is on a scale vastly different than the scale of the web page's pixels. Remember, attendance was on the order of millions and while we properly scaled the center x and center y, to correspond to the correct x and y pixel of the latitude and longitude of the game, we never created a scale for our attendance values. The code to do this is almost identical to the code we've used in our scatter plot. First, we create an extent, but in this case we're using our nested object. And in our accessor function, we have to first reach into the values attribute of our object and then grab the attendance, which we then use in our D3 scale. In this case, we're setting it up to be a square root scale with input domain equal to the extent we just created, and range on the order of 0 to 12. Now, both for the type of scale we use. Whether it's the square root, logarithmic, linear, and what output range we choose. It often takes some experimentation and playing around with values to find out what visually looks the best. And now we can properly scale our attendance values, returning them in our accessor function for the radius, and reload our page to see what affect this has had. Well, as you can see here, the circles have shrunken back down to a manageable size. And we can see that there's some variation in how big they are, which corresponds to the attendance for each And to make the map more aesthetically pleasing, as well as slightly more readable, you can change the color to be more striking. In this case, setting the fill to be Udacity's orange, and adding opacity so that we can see any overlapping circles. Your last change, is to simply make the stroke of the circles black. And to make it slightly thinner. Going back to our map, you can see now that the circles with some opacity, we can see countries in which the World Cup was held multiple times in, which might be overlapping. And while for our data set, the smaller circle always looks like it's on top. There might arise the issue of larger circles getting on, drawn on top of smaller circles, even with our opacity. So again, while for our specific data set, there doesn't look to be any of these larger circles drawn on top of smaller circles hiding them, mostly for the reason we saw in our earlier plots. Simply, later World Cups had more attendance than earlier World Cups. In the interest of making our map more robust, we want to make sure this will never happen, if we add new data. We can make sure this will never happen simply by sorting our data, using the built in JavaScript.sort function to find on all arrays, and make sure that our nested data set is in the correct order before we bind it in our data binding function. To sort our data, the elements I've nested get passed to our call back accessor function two at a time, a and b. And based on the return value from this function, either a gets placed before b or b gets placed before a. If the return value is less than zero, a gets placed first or rather, the first argument to the function. If the return value is greater than zero, b gets placed first. Or rather, the second argument to the function gets placed first. And if what gets returned is zero then there's no change. Simply leave a and b in the order that they originally were in. In our case, if the attendance of b is greater than the attendance of a, the return value will be positive and b will get placed first. Thus having the effect of drawing the larger attendances first. If a happens to have a larger attendance. Then b, the return value will be negative. In this case, a will get placed first. And again, this is correct since a would have the larger attendance. And now that our map is on a take shape, we have geographies of countries plotted as well as data, we can begin adding animation to encode the passage of time. We now have some context around how the location of a World Cup affected its attendance, but since we overlaid circles for all the years at once, the context of time has gotten lost. Or rather, we have sacrificed time for space, or geography in this case. As we saw with our previous plots and charts, there's quite a big dependence of the total attendance of a World Cup with the year it was held, with the trend being as time went on, World Cup attendance has steadily increased. One way to get the best of both worlds, geography and time, is to leverage animation to encode the passage of time. Remember previously that we mentioned animation can be thought of something of another visual encoding that helps convey the change of some data over time. I wanted to take a step back also so that we can remember where we are in the process. We will be creating a drill down story following the martini glass narrative structure, but currently we only have a static map that represents the base of our glass. While this is a great foundation and starting point for what we will be building, we still need to construct the stem of our glass, as well as the mouth of our glass. We will now begin building up the stem of our glass, through an author driven narrative with animation. And we will finish the mouth of our glass, with a reader driven narrative, enabled through interaction, and remember, we're at our starting point with our base map. We'll be narrowly guiding the reader with our author driven narrative, and then allow them to open up and explore their own narrative through interaction in the mouth of the glass To animate our map over the years of the World Cup, we need two things. The first of which, is a function to update our map, since we'll be repeatedly calling the updates we need to for every year, we want to encapsulate it into a function, that we can easily call whenever we need to. And the second thing we need, is a way to cycle through all the years that the World Cup was held, and pass those years to our update function. For now, let us just focus on writing this first function. I have scaffolded an empty function here called update, which takes as a single argument the year which we elect to update the map with. In order to update our map for a single year, we need to perform the following steps. First, we will be filtering our data for the given year that we pass to our update function. And once we filter our data we need to remove any elements on our map which no longer belong there. And the last piece of our update function is to add any new elements on the page that weren't already on their before the update. In D3 we'll be filtering our data with its built in filter function, then select the given year we want to plot. To find any elements to remove, we'll be using the special exit selection after the data bind, and to add any new elements for a given year. We'll use the familiar enter selection and the last bit that we haven't talked about yet. But an additional feature I want to add is to only show the countries that are participating in the World Cup for the given year. Now let's see what all of these functions might look like in d3. In this case I want to start with finding the countries that participated in a given year since it's a litte bit more complicated than simply filtering our data by year. And once we see how to select the countries of interest filtering the years should be quite easy. In order to find every country that has participated for a given year, we're going to go back to our aggregation functions that we've defined for use on our nested object. We can see here in the agg year function. Which will get passed leaves, and if you remember, in this case, it's all of the games for a given year grouped, and after we compute what we've already found of the sum of the attendance. And the coordinates to draw, we can simply group the teams together into an array to return in the end. D3 actually has a lot of great built in data structures, and functions to filter and transform data. In this case we're going to be using d3's built-in set data structure which functions just like other sets in math or other programming languages. It's a collection of distinct or unique objects. It has the property that if you add an element to a set is already contained in it, it doesn't add a duplicate. Here we've initialized an empty set, which we can then iterate through our teams for a given year, adding them one at a time. To do this, we can use JavaScript's built-in forEach function called on our leaves array. ForEach is similar to map, except for instead of returning an array, as we did when we found our coordinates. It simply runs an accessor function and passes every element of our array, one at a time. In this case, we're not actually returning anything from our for each, we're only adding team one and team two to our set. And again, since the set automatically de-duplicates anything, we don't have to worry about adding teams multiple times, the set takes care of that for us. So in the end, the set will represent a collection of unique teams for a given year. And to pass our teams to our return object, we call .values. On the teams set, which turns the set of team names, into an array that we can handle easily in the rest of our code. Now that we have the teams for a given year, let's go back to our update function, and put all the pieces together. Remember, our update function takes a single year as an argument, and with this year, we have to filter our data. In this case, we'll actually be filtering our nested object. Remember, when we grouped our data by year, the nested object had its key property set to the year. And then our filter function, all we need to do is strip out the key and compare it to the year we want to filter by. In this case, the nested object actually has its keys as strings, so we first need to convert the string back into a date, pull the year out, and compare it to the year passed to our update function. And the filter function works just like a map except for instead of returning every element of the array it's called on, it only returns ones where, in our accessor function, we return true. In this case, true will only be returned for the elements d, where the key is equal to the year passed to our update function. And now that we have the correct data filtered, we can begin updating our map and the circles drawn. To do this, we'll use data binding and the special enter and exit selection that we covered in the last lesson. Here you can see, we're back at the data binding function, for when we added circles to our map. All this time when we were binding data, you might have been wondering to yourself, how does D3 know which data's on the screen, and which data's changed? Well, since we're going to be animating and updating our map, we want to be very explicit about what each piece of data bound actually represents. Here we'll be adding a special function, as the second argument to data bind. It has the familiar syntax of any other accessor function in d3, and based on what we return from the function, d3 binds that value, to the elements selected above. In this case, our nested grouping actually did a lot of the hard work for us. Remember, the key to our nested groups represents the year of the World Cup. In this case, in our key function, all we need to do is simply return d key of the passed in nested object. In this case, d key is going to represent a string corresponding to the year of the World Cup, that the given data point d, represents. If we do not specify a key function, D3 uses the datum's index in its array. And while this works for most static use cases, where you're not changing your data array, since we'll be filtering and manipulating our data, we don't want to have to rely on that being in the same order every single time. I also wanted to point out that the nested key is not associated in any way to the key function itself. To use a key function in a data bind, we don't actually have to use a nested object, or any object that has a key field. We can simply return any arbitrary value, or any value that depends on our data point. We could have just as easily, instead of binding our data by year, bounded by attendance value. In this case, just to make a point, we're grabbing the attendance value of a given year, and the value's object, it gets attached to every nested object. So remember, the key function is much more flexible than the key property attached to a d3 object. And now that we've properly associated a given data row with an object on our screen, in this case circles, by some unique key, we can begin removing and adding circles as we cycle through our years. Now that we have filtered our data by year in our update function and bound our data using a key function keyed on the year, we're ready to start updating what's on our map as we iterate through our years. While it might seem like overkill to use a key binding function since we're only visualizing a single year with a single circle, we could imagine a scenario where we would have multiple elements on our page interacting in a complex way through updates, exits, and enters. To begin updating our map based on a single, we start, as we most always do, with our svg elements. In this case, we want to select all the circles that are currently on the page. Which in this case, is going to be every circle for every year. And then, rebind our new data. In this case, our data filtered by year. And to properly update our map we will use a key function. The same key function that we used when we initially bound our circles. Because we often would want these two to be the same. I'm going to abstract this away into a function defined above. In this case again, remember, we're simply extracting the key of the nested object that gets passed to the key function, and in our initial data bind we can simply pass in key_func. So that we're sure that when we update our data and rebind our filter data we can use the same key_func as well. Now we've been through a lot of code since we've explored it in our browser. So I want to take a moment to pause, place a debugger inside our update function and start inspecting where we are. Since update isn't being called currently, I'll also place a debugger at the end of our plot points function so that I can experiment with the code defined within it. Here you can see we have our nested object, which corresponds to the 20 games of the World Cup, and each nested object. If you remember has the key set to the year and the values with the total attendance x and y coordinate but also our new teams array, which in this case you can see the nice array of all the team's countries who participated in the World Cup for the given year. And I've added a call to the update function, with a given year so that we can then step into it, and see the debugger cache insider update function. And now if you look at our source here you can see that we're in the update function. We have filter data, which represents an array with a single object. That object represents a single year. In this case I ran update with the year 1930. And the values is what we would expect. And notice that we have this year argument available as well throughout the update function since we passed it in as the argument. Do you understand a little bit better how D3 updates work? Let's see what the selection currently looks like. A d3.selectALL on circle, returns an array of 20 circles which makes sense since there's 20 World Cups plotted on the map currently. And let's put a break point right after we bind data to circles to see what it looks like after we've bound new data to it. And if you look at the circle's variable now, where before we bound data, the svg.selectALL above were turning in array of 20 elements. With the newly bound data, filtered in this case, since it only has one element, returns an array with only one circle in it. Remember, from our previous Venn diagram. We know that the exit selection corresponds to every element present on the page that does not have any corresponding bound data in this new data bind. Or in our case, data bound and filtered. If we were to look at the enter selection on the newly bound circles, you can see here this corresponds to an array of a single element, which has an update property. The update property has a circle and that circle corresponds to the new data we're going to be adding. In this case, the year 1930. And if we inspect the exit selection on the circles it says we have an array of 20 elements. But notice near the bottom here that we have a parent node as part of the array. So if there's 20 elements and there's also an additional parent node element that we didn't have can you look at the list of circles here and figure out which year of the World Cup is not contained in the exit selection? Remember we have run update with year 1930, and I've shown you that the enter selection is one element under the update key. If you carefully inspect the exit selection, you'll notice here that item 17 happens to be missing. It jumps from 16 to 18. And here I'm re-running the SVG select all code. On just circles to see all the circles, and what they're bound to. Scrolling down we can see here item 17 happens to correspond to a circle that has data with key 1930. So as you can see, since we're updating the year 1930. And we're binding the filtered year, which only corresponds to 1930. The exit selection is everything that doesn't belong on the page. Basically, every circle except year 1930. And in this binding we simply tell d3 to update year 1930 in case any of the data that was bound to it has changed. Now that we have a better handle on what these selections actually represent, let's go back to our circles. Get the exit selection on it. Again, which corresponds to every circle except year 1930. And call the D3 function remove. So this has the effect of finding every element on the page through the exit selection that doesn't belong there and simply removing them. If we run this code and look at our map, how it's been updated, it's hard to see since the attendance was so small, but there's a single dot remaining here. I'll try to zoom in. And you can see here, it corresponds to the 1930 games. So our exit and remove have worked correctly. Going back to our text editor, now that we've removed every element that doesn't belong there. Let us add or update any element that should change on the page. As you can see here much of the code is identical to the code that drew our initial circles and this is very intentional because we want all the circles representing the attendance of games to look similarly. As you can see here for the circles new data bound, which is all the circles on the page, bound to new data filtered. And our key function we take the enter selection, so anything that's not currently on the page we want to append a circle to the page, and then set all of the same properties. Notice here that I didn't include any of the calls to .style, and I've abstracted all the styles of circles up into CSS in the head of the page rather than duplicate a lot of the same code to change the styling on the circles as well. It's cleaner and easier if we're going to be adding and removing a bunch of circles on the page to not have to specify every time that we want the same styles that every other circle had. So now let's put all the code together that we both run in the console and that I've shown here, to first remove the circles that don't belong there and then add any circles that need to be there. As you can see here, we're simply removing any circles in the exit selection and appending any circles in the enter selection. Let's go back to our console and just test that this circle adding and removing works as we expect. And here we've stopped right before we called the update function. So let's see what happens if we call update with the year 1930. As expected, every circle disappeared except for the tiny, tiny circle representing the year 1930. Let's try to show the most recent World Cup in Brazil, passing update of 2014. As you can see here, the 1930 World Cup was removed and we've added the Brazil World Cup. So it appears that our update function is working correctly. GIven what I've shown you, what do you think happens if we try to update a year in which there were no World Cup, for example the year 1969? If we run update here with the year 1969, you can see that every circle for the World Cup has disappeared. I'll close the web console so we can be extra sure, and while it may be hard to see for yourself, trust me there are no more circles on the page. So what's happened is that the filtered selection that we've made for the year 1969, was simply empty. So when we made an exit selection, it contained every circle those on the page and we removed all of them. Now that I've shown you, that we can easily remove an add circles, based on some selection. Let's get to the last piece that our update function needs to perform. As I mentioned previously in the lesson, we want to highlight which countries participated in the given year of the World Cup, and hide every other. To do this, rather than removing and adding paths of countries, I'll simply change their fill and stroke, accordingly, depending on whether or not, the country for the given year of World Cup, is present in our teams array. Remember, in our nested object previously, we used a d3 set, to create a list of the teams that played for a given year. Since every path has previously been bound toward GeoJSON country data, included in that data, are properties such as the name of the country in addition to their coordinates. We can simply selectively update a give path, based on the accessor function we used. In our animation, we'll be leveraging negative space to highlight which countries played in each year. In other words, if a country is not in a current year, that we're updating, simply make it white. And if it is, keep it the light blue we've made it. Going through some of the code I just added. First we want to get a list of the countries that participated in the given year they were updating, which we can access through the filtered data. Get the first and only element, access the values property, that was created when you used the nested object. And then select the teams array. So in this case, countries is an array of strings corresponding to the names of the countries. And the code that I'm running here, while slightly complicated, is easy to understand once you break it down. Every JavaScript array, has this method index of defined on it, which, if its argument is contained in the array, returns the index in which it is present, and if it is not contained in the array, it simply returns negative 1. Again, remember, every path has GeoJSON bound to it. Every GeoJSON, in this case d, has properties defined on it. And inside the properties object, it has a name. So altogether, this has the effect of going through every path with corresponds to a country. For each of those, compares the name of that country, to the teams in our countries array for a given year, and if it's present, keep that country light blue. If it's not present, turn it white, effectively hiding it. And since we'll be doing the same thing with our stroke property, we can abstract this function outside, of the style fill. And as you can see here, now that I've created an update countries function, I can simply pass that, to both the fill update and the stroke update. Let's save this and inspect our complete update function, in the web console, before we animate for all the years. Again, let's start to update it this time. For the most recent World Cup, the year 2014, when we ran update in the console, again, right at the bottom of the plot points function. We can see that many of the countries have been turned into white, but many of the countries have remained blue. Closing the bugger, we can see here that what's shown for a given year. Are all of the countries, that participated in the given World Cup, which was held in the home country indicated, with attendance indicated by the circle. Now that our update function is complete, let's animate this so it cycles through every year of the World Cup. So now that we have completed our update function which takes a year, filters our data, updates our data bind, removes and circles that the previous updated data bind would cause to be irrelevant, access through the exit selection, add any new circles that need to be on the page based on what happened in the updated data bind by simply taking the enter selection and appending circles. And then effectively filtering the countries we show by changing the styling, such that only the countries that had a team in the World Cup are shown. So just to recap where we are, we completed the first task that we needed to get done before we could animate our map by writing an update function that takes a single year and manipulates the elements on our map. To properly represent the given year and the attendance in that year. Remember, the second part of animating our map, was to simply cycle over all the years of the World Cup. There are many ways to perform the type of animation that we want to do in d3, but for simplicity's sake, I'm going to use one of the most explicit, even though there's more efficient and robust ways to do this. I've linked to a few examples in the instructor notes with some resources an tutorials that cover other ways to create animations in D3 For our animation we could use the Javascript native function setTimeout, which simply runs a function after a specified number of milliseconds. Even better for our use case we will use the function setInterval, which can be thought of setTimeout's sister, which function in the same way and runs a function after a specified number of milliseconds. But in setInterval's case, it repeatedly runs that function. For our case, this is exactly what we want to do to run our update function, repeatedly, once for every year of the World Cup. And to know what years to loop over, we're going to use an array, that stores all the years of the World Cup, and to populate this array, I'm just going to loop through the years, between 1930 and 2015. All I'm doing here is looping from 1930 to 2015 in increments of four. This says start at 1930, increment in steps of four and stop once you reach year 2015. Inside this loop, rather than just adding every year. Remember, there wasn't a World Cup in 1942 or 1946 because of World War II, so we want to exclude these years. And for every year that's not 1942 or 1946, add it to our array. And now that we have our years in addition to our update function, let's put them together in setInterval. The syntax for setInterval is that the first argument it expects is a function to run. And the second argument is the number of milliseconds for the interval to run at. So for this example we'll run this anonymous function every second or every 1,000 milliseconds starting one second from when set interval gets called. And the way to stop an interval, so it doesn't go on forever, is to remember in a variable, what interval you set, and inside our function for the interval. We need to put our code that runs the update function and pass it one year at a time. In our code here, we're creating an index, so we know which year we're at. Inside our function is called at the specified setInterval of 1,000 milliseconds. We're running our update function with the specified index to get the correct year from our years array and running update with that year incrementing the index by 1. And then if the index happens to be greater than then number of elements in our years array, meaning we've going to through every year, past the year interval, the JavaScript function clearInterval. ClearInterval is simply a built in JavaScript function, that takes as a single argument, an interval variable created with setInterval. And stops it so that we don't run for ever, update after update of the World Cup map. To make this a little bit more clear, calling setInterval, it returns an interval object which we're remembering in our year_interval variable which we then are going to pass to clearInterval to stop or function from getting called every 1,000 milliseconds. And now let's save our file and go back to our browser and see how our map animates. Notice that we start with all the countries initially on the map and then go year to year plotting the game of the World Cup as it changes host country. And only showing the countries that were involved in that World Cup for the given year. So this is going through every year of the World Cup, in which there are twenty, and plotting the home country's attendance numbers as an orange circle. And every other participating country in the World Cup for a given year is shown in light blue. If the country did not participate in a given year of the World Cup, this year being 2014, since it was the last World Cup, we simply make it white. And the last bit of context that I want to add at this point is to display the year being shown so that as it animates through, we know what World Cup we're actually looking at. Let's use the same code we used in our chart example and append an h2 tag to the top of our chart and use some CSS to center it. And if we refresh the page here, we can see we now have a static title, World Cup, and the animation still works. But let's go back and make this title dynamic. And now in our update function that's going to get run for every year. We can select our h2 tag and change it's text to represent the World Cup and the year variable that we're updating. Going back to our browser, we can see here the year properly animates and we have much more context as to what we're looking at as the map changes. And now we have a link between what year we're actually visualizing, the attendance, how it's changed from one year to the next through the animation, but also how it's changed depending on which country's hosting the game. And how the geographic spread of participating countries changes from one year to the next, and one host country to the next. And we're just about done with our animation, and have a great author driven narrative that represents the stem of our martini glass. Before we leave this animation, I just want to touch on D3 transitions, which would make any changes to our graphic much smoother and aesthetically pleasing. We've already done all the hard work of creating our animation with our update function. Including things like filtering our data, removing and adding any new elements that need to be placed on the page. As well as dealing with the data binding key function which determined which elements to add or remove, d3 has great support for built in transitions. And all you need to do to make the transition smooth is use d3's special built in functions. One of which is transition which kicks off a transition. And the second most used is the duration. In this case we make our selection, we append anything that needs to be appended, and then kick off a transition that takes 500 milliseconds. And what actually changes during the transition? Well that's what comes after it. All of these attributes which move the circles and set the radius take 500 milliseconds to complete and operate on the enter selection and the circles we are appending. So now when we're adding circles they'll transition more smoothly, but also potentially more importantly we want the countries to transition smoothly. So following the exact same syntax we place transition with a duration of 500 milliseconds. Right before we change the fill and the stroke of countries to update and hide or show based on the year of the world cup. I would say this is one reason to use D3's built in style functions to add style to our elements rather than using CSS. So we can have much more flexibility in how we animate and apply those styles. As you can see here, the countries transition out and in much smoother than they did before since we added the transition to the styles applied to the countries as well as the circles. As they come in and get placed at the respective home countries they belong on top of. And now that we have finished our map, or at least the animation of it, we can start to see a little story unfolding. Can you find a narrative in the graphic we've created? The story I hope to tell, by leveraging the negative space, is that as time's gone on, what started as a small, somewhat local tournament or event, has evolved into a global phenomena, both for the countries participating and the home countries in terms of how much visitors they're looking to attract. Notice in the early years when there may not have been such good transportation, especially across the Atlantic, the participating countries were often somewhat local to the game and where it's being held. But as time's gone on, we can see that more countries from across the globe are participating. And the last point I'd want to draw your attention to before we leave, is that in the beginning, and still somewhat recently, Europe and South America often dominate participation in the game and dominate who hosts. Well that concludes our map, so let's go and try to add some additional features to make it more interactive. Now we've finished adding the code to create our author-driven narrative by animating the World Cup. Now I want to enable the reader to be able to drill down further into our data by using D3's event binding to enable interaction. While it's great to see the year's animates by us. In succession it's very hard to compare one year to the next. Especially if they may not be sequential. For example, if I want to compare what happened in 1930 with the world cup with what happened in 2014 in Brazil. I would have to wait for the animation to go through, or dig into the data myself. To remedy this, I want to add some buttons that correspond to all the years of the World Cup, where if a user clicks on one it jumps to that individual year and updates the map. In this case, we're going to be adding some div elements based on the years of the World Cup. To start, we're simply selecting the body. Appending a parent div with class years button, which is then going to contain 20 elements corresponding to every year of the World Cup As you can see here, after I've created or appended this div element to contain all my buttons, I'm simply selecting all the divs in that parent div, binding data corresponding to all the years, making an enter selection which will grab me all the elements that are currently not yet on the page. Which in this case is going to be all of them since we are near the top of our file, and append div that has text equal to the data itself. And as you can see here, I've moved the code that we wrote earlier up to the top of the file to find all the years in which there was a World Cup. So that for the buttons I don't have to hand code every year one at a time. I can simply bind the years array to my div elements. I've also added some CSS styling above to make the buttons somewhat pleasing. If we reload the page, we can see here that we have a list of buttons with an orange background containing all the years of the World Cup, starting with 1930 and going to 2014. Now this looks great, but I still want to be able to animate through all the years before a user will select and possibly interrupt the animation. To do this, I need to make sure that the animation finishes before I append these elements, and before I start adding some interaction to these buttons. To make sure that the buttons do not appear in the page until after the animation has run through, thus preserving the author driven part of our narrative. All we need to do is put the same code that I just showed you that creates the buttons in the conditional statement that clears our interval. So again, if you remember, we set our interval and once we run out of years, to show an update, we call clearInterval and exited. But in our case, we want to first clear the interval, and now add some buttons. So let's see what that looks like. And as you can see here, as the animation draws to an end, the buttons show up on the left side. So the first part of adding interactivity has been completed. Now we need to actually allow the user to click our buttons. Here, we are still in the conditional that clears our interval. And once we've created our buttons, we want to attach some event. If you're not familiar with JavaScript events, there's many ways to do them with native JavaScript. But most libraries out there allow you to interact in some way with user events. The most common library, and what might have driven its rise to fame, is jQuery. Where it made it effortless to attach events and functions to elements on the page. But there's many other libraries. In our case, the most notable D3 which implements a similar style of adding events to given HTML elements. In this case, we've created our buttons. And with those, we want to enable some interaction on a click event. The syntax for this is to call the on-function. With some D3 selection, in this case, our buttons, in the first argument is the event that you want to trigger your callback function. In this case, we want to attach the click event to our buttons, but there's many others, some of which I've included in the instruction notes for this video, such as mouse over. Mouse out. And even custom events, and any other event that JavaScript itself supports. The second argument, to on is the function you want to run. When the given event happens on your element. Sometimes you might see it refer to as the event handler. The argument D passed to the event handler function is the same D that gets passed to most assessor functions in D3. That being the data. So in this case d, when a button is clicked, corresponds to the year that was clicked. In our case, when a user clicks on a button of the given year, we want to call our update function with d, or rather. The year of the button that was clicked such that the map updates. The line above that I've written is D3's way of accessing the element that was clicked on. In this case we use a D3 select but we pass it the special JavaScript variable. This. There's a lot of confusion around when and what this actually represents, and again I've linked to some many good resources in the instructor notes, but for the case of what we would encounter in this course, this most always represents the element itself that was clicked. In this case, the HTML button, and the reason I'm accessing this, or rather, the button clicked, is because I want to indicate to the user in some way what button actually was clicked? In our case we want to indicate visually to the user and provide some immediate feedback about what button they clicked and whether or not that click actually happened. And in this case we're going to update the styles and change the background to be blue. And the color of the text to be white, also to make it smoother and more aesthetically pleasing, we can add some animation and transition to this effect. Going back to our browser, we can refresh the page. And we see our buttons as they were before, now let's try clicking on one. If you noticed, I clicked on the year 1958, the map has updated, the circles moved, and also the year and the titles changed. But also the stylings on the buttons have changed. Let's compare the year 1958 to the year 1994. Again we can see the update happening. But one quirk is that now both buttons are blue. And every successive button we click stays blue. Do you know what might be happening here? So one thing, if you remember back to what we did when we needed to update our map that we forgot to do with the buttons, was make sure that we properly update any elements that are no longer active. I say active, in this sense, to mean any buttons that don't correspond to the current year, and any countries that don't correspond to the current year of the World Cup that we're looking at, and any circles that don't correspond to the current year we're looking at. For our map, we did this update through the exit selection. We filtered our data for the year of interest, we removed elements from our exit selection and we added elements from our enter selection. For the buttons, for the sake of simplicity, we can make all the buttons change to their initial state and then selectively change the one button we need. So to update all the buttons we first simply select the years button container. Again, which is the parent div that we attached a class to. And then select all the divs contained within our years buttons div, which corresponds to each individual button, which we can then add our styling to. And once we've selected all the individual buttons, again, a select all should return 20 buttons. We make a smooth transition using D3's animation functions and then set the initial stylings on the buttons that they have before they're clicked. And since we're adding this code before we update the button that is actually clicked. We don't have to worry, about having the clicked button, not be updated. So first we change all the buttons back including the button that was clicked back to their initial styles and then once everything's reset, we can go back and find the button that was clicked, and only update that single button. So as you can see here, we've refreshed the page, we have our map which represents the state of the World Cup in 2014. And we have our buttons. Now let's see what happens when you click and individual button. As happen before the map has correctly updated and the buttons color has correctly changed. Now let's see if our updates to the buttons, which shouldn't be clicked has worked. As you can see here the previous button we clicked. Has gone back to its initial styling. The map is updated. And the current click button has changed to blue. And again, going to 1930, we can see this transition happen smoothly. And everything seems to be working. Now that's the end of the LiveCode example. And everything we'll be covering in this course. But don't feel like this is the limit of what we could do with a map or D3 in general. I want to just recap what we did in this lesson since we did a lot of coding. And hopefully I've inspired you to go out and create your own visualization or adapt what we've created in this course. We started off and we create a static map of only the countries and drawn them without any of the data from our World Cup attendances. The next improvement we've made is that we added bubbles or circles corresponding to the home country and the total attendance for that year. Making what's often called a thematic map by combining our static geographic map with some data. The theme in our case being the World Cup. The next step of this improvement was to create the stem of our martini glass and an author driven narrative. Where we leveraged animation to cycle through all the years of the World Cup, displaying both the participating countries and teams and where the world cup was hosted and what its attendance was. And remember, through both the animation, and the negative space created by only showing the participating teams. We could see that in the early tournaments of the World Cup, the participating teams and countries, were often localized to where the tournament was held. Now, I'm sure there's plenty of causes for this, and I don't want to fall victim to confusing correlation with a cause, but intuitive exclamation that world travel wasn't what it is today. In crossing the Atlantic and the Pacific, especially before airplanes became commonplace, could be considered quite difficult. The second takeaway from our author-driven narrative is that in addition to conveying all the attendances of the World Cup have changed over the years, is that we could see in the early days, the World Cup was mainly hosted either in South America or Europe. And perhaps this is one of the reasons why South America and European teams, often dominate the World Cup, both historically and in modern tournaments. And the fourth iteration of our map was to enable a reader driven narrative through interaction. We did so by adding buttons which correspond to every year of the World Cup so that a reader, who might be interested in one years as compared to another, could very easily see how the participants and the attendances and the host country or rather what data we have represented on our map has changed from one year to the next. This also enabled us to compare disjoint years, which may not be sequential, for example, comparing 1938s games with 1982s games through animation alone we would have to wait for the entire sequence to go through. And we may not be able to remember what it looked like in 1938 compared to the year of interest, unless we've seen the animation go through many, many times. So while in the author-driven narrative, we've communicated our interesting insights from the World Cup Games, be it that early tournaments were often localized in the participating countries. And the tournament mainly started off both being hosted in South America and Europe, but also having many of the participating countries from South America or Europe which might be a reason for their dominance in the games today. They've simply been doing it for longer. The reader-driven narrative allows the user to approach our visualization and discover their own story. And by combining both the author-driven portion and the reader-driven, we've created a very powerful and dynamic story around the history of the World Cup. And returning to our martini glass, remember that the static map and the bubble map or thematic map create a very solid foundation for our interactive narrative to come. Our author-driven narrative, enabled by animation, took our reader along a narrow stem of the glass, conveying the interesting stories that we found in the data, before the interaction of our graphic. Enable them to explore and discover their own insights in our data through a reader driven narrative. And through all of these components, we've created an engaging and effective visualization. Now there's a wealth of resources online and classes you could take to learn more about these things, many of which you can find in the resources section of this course. But my best advice to learning more when I encourage all of you to do this, is to simply start creating your own visualizations, your own graphics and your own projects, and put them online for others to see, either in the form of this course, or on a personal blog or public site. And with that, I'll bid you farewell. I hope to see some of your awesome projects for this course and things you create outside this course. Sumat, what type of advice could you give students who are looking to integrate maps into their data visualizations? So I think maps are a different and difficult category of data to show. But they can also re, be really powerful. So I think, like with many other graph types, one of the most important things about when you're making a map is, to decide in advance what you'd like your audience to know. And to decide how you're going to show that. so, that involves things like, you know, deciding what scales you're going to be showing. You know, what the variation is. Making sure that you have a clear outcome, for the people who are going to be looking at it. So, I think a lot of times when you're making any graph, it's really useful to think in advance. What's it, what's the main thing that I want people to take away, because as a data scientist, it would be your job to tell people what they need to know. Hm. And so, often times it can be useful to do something like, even just like titling, or using on of the axis labels to say, what the main takeaway point is. And using an annotation to point out what a particular event or an outlier was. So we have a couple examples up here that we can show. So this one is a, a contour map that's on top of a scatter chart. That shows temperature anomalies in July with respect to 1981 to 2010. And so it lets us see variations between temperatures in very cool and meaningful ways. And you can see it scaled from over here, to show differences in temperature. We also here have a bubble chart that lets you look at, different sizes of Canadian cities and the population that lives in them. And so this is a fun one because it lets us just kind of like visually get a sense for, the overall population of Canada. Hm. Which you can see is just heavily centered around the border here. And then also where the most populated cities are. For making these maps folks have used the maps package. Or a maps library, n r, and then use Basemap from Python. Mm-hm. For making maps if you would like a GUI Tableau and Data Wrapper both have really good tools. Hi, I'm here again with Scott Murray. And when you think about the future of data visualization what are you most excited about? Can I start with what I'm not excited about? Yeah. Not excited about more tools, more data. That's like, usually I think what people are excited about, but it's like every week some new tool gets announced. And every week, you know, some government releases and some new data set and like, it's all very good, but it can just be so overwhelming, I think especially for people who are new. Mm-hm. So I have to say, on one hand, I'm excited about that. And on the other hand I'm like, not very excited about that. I guess what I am excited about is having better resources for new people, and, and having like all, so much excitement. Like just, just getting these new people into the field. because kind of like I was saying earlier, like everybody brings their own experience, and it's been, you know? I think visualization actually has this really long history, but it's sort of because it's kind of blowing up in this whole new way just recently like with this convergence of, of open data, and tools, and open source, and all the sort of things you need to practice at getting more and more accessible. Plus of course kind of the, the, the buzzwords of big data and like all the stuff we're excited about. So, all these things have converged to make this like a really hot exciting field right now. Which is great, but I think we forget that there's this whole history. You know, of this field and that this, this history is related to kind of representations of information before we started calling it data vis. And it goes back to, to design and like how we evolved written language, and you know, hieroglyphics and all this, all this stuff. So I think, kind of in the, the early days in this new resurgence of data visualization, practice was limited to kind of some academics, and then a handful of, of really specialized design firms but now it's, it's much, much bigger than that. So we have lots of people. We have people internal at companies who just do data vis for that company. We have more and more of these kind of boutique design firms that do kind of data design, data visualization. We have existing firms like design firms, graphic design who are getting into doing data. And so, and then of course we have like students, and academics, and just kind of people who don't fit into any of those categories who are practising. So I think that's really really exciting, but it's also, like I said, challenge for us because we have the existing books, and resources, and things are great, but not totally adequate because they, they address kind of different audiences in, in that vain. Edward Tufte's books are fantastic, but, like he's a statistician, and they're coming from this one point of view. And I, I still recommend the books to everyone, but they don't address all of the latest kind of developments in interactive design. And, what does this mean translating these ideas to a mobile experience? What does this mean translating this idea to a dashboard or a billboard, or you know, something in advertisement? So, there're all kinds of these new considerations, and I guess I'm, I'm excited about us sort of together gradually figuring out ways to address all those considerations. What are you most excited about when you think about the future of data visualization? I think what we're most excited about at Plotley and we think a lot about, is what it would be like to be able to have massive, worldwide collaboration in doing data analysis and graphing? And so, a big part of what we thought about for Plotley, is making everything web-ready. So, if you already know, let's say, MatLab, or you're really good at using Excel, we don't think that it makes a lot of sense for you to also have to learn how to do web development. So we've tried to make it so it's really easy to keep using the tools that you're using, but then being able to get a web and collaboration layer for sharing your work with people from any language who are using any different type of technology, any different data type. And so it can really kind of be a translation layer, because if you have really sophisticated, let's say, political scientists, and engineers, and data scientists, who are all able to collaborate between their respective preferred development languages, and tools, and able to discuss things, and make reproducible graphs, and data, and work on massive research projects. We really hope that it would be able to further, you know, science and collaboration in really any field. You know, so we've thought about what if folks from NASA were streaming flight data and showing live satellite data. What if groups that were doing research on cancer were able to share their resu, results with the world, so anyone can reproduce their work and get involved with what they're doing? So experts can collaborate naturally even if they didn't necessarily plan to do so from the beginning. Because if you make data, and if you make graphs, and you make tools available, and free, and easy to use, we think there's a lot of power behind that. The future of data visualization looks very bright. And I hope that you've learned a lot in this class. Ryan, if there's something that a student taking this class walks away from learning in this course, what would you hope that would be? The one thing that I want everyone to walk away with is that anyone can do data visualization. You don't necessarily need to be the best coder or the best designer. But with a few simple tools and concepts, you too can create a data visualization that is both beautiful and compelling. I want to thank you for taking this course, and I hope you had as much fun going through the material as we had producing it. And while we covered a lot of ground, both on the theory and practice of data visualization, we learned how to code using D3 to create visualizations for the web, there's still much more to learn. I encourage all of you to join us at Ziptheme Academy or use the wealth of online resources to continue learning and creating visualizations of your own to share with the world. Before you answer questions about all that you've learned so far, I want you to hear from Scott and Cole again. They're going to share some amazing resources so that you can create great data visualizations. What tools or resources would you recommend that students use? There are things like D3, right. There are like JavaScript libraries and these tools that are built. To help you build totally customized visualizations. So that's sort of like on the advanced end. On the other hand you have tools that are a little more like create, kind of create a canned visualizations like a chart wizard built into Microsoft Excel. Mm. Or. Or also like OpenOffice or LibreOffice, like these other sort of office type programs, which are really great, or Apple's Numbers does more things. Tableau I think is a fantastic tool for starting out and they just came out with a Mac version, which is great, as it opens it up to a lot of us who use Macs, and Tableau, I, I don't want to say it makes like, they're not like canned visualizations but it lets you just like, really fast, drop a data set on there and give yourself like a number of visual representations of that data. So you're like, oh show me this as a bar chart. Show me, to me as a area chart, line chart, whatever. Or if this is geographic data like, show me this data on a map. Like in a really fast way. So that's an awesome, sort of like exploratory tool and on the technical side, you know, there's like the other end of the spectrum from D3. Now in-between, there's a lot of stuff in-between like other chart libraries or online tools. The tools I think I'm excited about right now are sort of in this. In between place where, where they let you sort of dump your data in and generate some sort of visualization. But it's not trying to be the final visualization. And then you export that, bring it in to some other tool, and start adjusting it. So for example there's a tool out of the Density Design Lab. In Italy called RAW. Hm. That's capital R-A-W. Mm-hm. And you put some, basically drop your data on it and it figures out sort of this is a representation I think will work. But it doesn't give you, and, and it's all, like ,in one page. It's kind of like one, two, three. You just go down this list and then you get, like, a graphic of some sort. And then you take that graphic, and you export it, and maybe bring it into Illustrator, or some other program where you can do kind of the manual steps. So then you can say, oh can we not set my, my fills and strokes and then reposition things. I think that's like, really nice and really powerful, because it, it doesn't involve any coding. It doesn't involve a steep learning curve. And it also doesn't burden you with an interface that gives you a million like, options for customization. Mm. It's just saying I'm just going to get you started and like get you past that initial push so you have this one graphic and then you can take it and tweak it. So there's a lot of exciting stuff like that I think that you can use. So what tools or resources would you recommend for students who are getting started be it maybe it's a blog or a particular software tool that you use. Sure so when it comes to tools I think my number one piece of advice is try not to let your tool be a limiting factor. Mm. Right. Take the tool that you know and get to know it as well as you can. Most tools can be bent to meet your needs and you can add more tools to your repertoire over time. But, the knowledge of fancy tools need not be a barrier for entry in this space. I, for example, do almost all of my work in Excel. Because, it's still the most pervasive for business communications, which is where I spend the majority of my time. When it comes to other resources out there, there is a wealth of information in the blogosphere, an a lot of really great content. One word of advise, is there's a lot of not great content as well, so be a discerning. Purveyor of data visualizations, right? When you come across a graph in a newspaper or in a blog, study it and note what you like and what you don't like. And work to emulate those things that you see in other people's work that works well and avoid the bad. When it comes to some specific blogs that I'd recommend, and again there are a whole lot of good ones out there, but I'll go through just a couple of my favorites today. First off is the Functional Art. So this is done by Alberto Cairo, he has a book of the same name that we talked about briefly. Next is Visualizing Data which, which Andy Kirk runs. Flowing Data is Nathan Yau's blog and he curates a lot of stuff that other people do and. Yeah, another good example. And then I would be remiss not to mention my own blog at Storytelling with Data. And actually one more resource while we're flipping through pages here is John Schwab's Help Me Viz. So we talked earlier about seeking feedback. This is a place where you can actually submit data visualizations and get feedback from the community and has been growing and has some really good content. Also if you're interested in just looking for data visualizations and examples of good stuff and bad stuff, it's, a nice place to flip through. Wonderful. I'm here with Matt from Matt it's so good to have you here. It's great to be here. You know I I came here to two things. Chew bubble gum and talk about graphing and I'm all out of bubble gum. [LAUGH] So, excited to be here. Great so tell us, what is So we're a graphic and analytics platform and the idea behind it has been that we want really two things. One is for anyone at any level of tech, technical sophistication to be able to make a really pretty interactive and collaborative graph. So in the same way that you might make graphs, you know, with Google Docs, or you know, editing documents with Google docs, we want people to be able to edit and analyze data and make graphs there online. And we'd like that to be something that's useful for high schoolers and then also all the way up to folks who are working on technical and sophisticated projects that we have corporations and folks at the Washington Post who are using it too. So first part is anyone at any level making and sharing graphs. And then the second part is being able to have it be a hub for your data and your graphs and your code and your collaboration. So typically when you make a graph, you have some data and then you analyze it, and then you use either code or maybe a program like Excel or Tableau to make your graph. And then you email about it. So you have to put all of those things into an email or into you know, shared folder. And then other people kind of have to look at it locally and check out the data themselves. But for us we've tried to make it so, that all of that happens off code, graph, data, and collaboration all in one place. And it happens between languages. So you can add a graph with any language or just a web app. Before you tackle the next mini project, I want you to hear from Scott Murray again. Scott has some excellent advice for breaking into the field. If you could go back and sort of give yourself advice for when you first started in the field. When you first started making individualizations, what advice would that be? My advice would be. To just find topics I'm really excited about and go pursue them, which I sort of did. But secondly, to get that stuff published and out on the web and start sharing it, like, sooner. I know with sort of my personal experience there's this feeling. Like, I can't put something out into the world until it's, like, polished and finished and perfect and really exciting or amazing. I know students get that a lot, too. It can be really intimidating. Especially if you're studying works by people who are doing you know, at least on paper having all kinds of a success. And like, doing all these amazing projects. It can be really intimidating to be like, oh, here's this little chart I made. Or here's this you know, thing that's so, feels so insignificant or it might have problems. But I think really that's how you get established in this, probably in a lot of fields. But especially in this field where it's all about sharing and this visual communication. And then, having people respond to that graphic. because the graphics are not just kind of endpoints, or the visualizations aren't just endpoints. But they're really sort of you know starting points for the rest of the conversation. So one thing this is especially true I guess for design students as in you have to do it now. You know, you have to have a web based portfolio. You have to have something on the web where you can publish things and get it out there. And like engage people and get a response. So I would say you know, start making stuff as quick as you can and start putting it out there as quick as you can. And certainly engaging with other practitioners and you know, critiquing in a helpful way. So trying to provide helpful advice and not just It's kind of too easy to cut down the things that aren't very good. like, there's been some discussion, kind of in the community, about this recently. On what's the value of critique? And what kind of critique is helpful? Somebody uses you know, quote, unquote, bad colors it's very easy to be like, oh, well those are you know, horrible colors. It makes it too hard to read, or something. Instead of saying, those are horrible colors. Say you know, maybe this is somebody new who's coming in. And they're trying to learn how to do a good job. Encourage them with hey, why don't, can I suggest these better colors? Or, can I suggest this other visual representation. So I think part of it is, you know, getting your stuff out there. But it's also being friendly and supportive and you know, hopefully kind and empathizing with the people who are new, who are just coming in. Okay. Great.