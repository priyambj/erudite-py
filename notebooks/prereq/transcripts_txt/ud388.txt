Hi, my name is Lorenzo. I'll be your instructor in this course as we explore the design and implementation of web APIs. Throughout this course, you'll work on several mini projects that each focus on a specific concept you'll learn. At the end of this course, you'll use all the skills learned to create a final object called Meat and Eat, a social application for meeting people based on their food interests. By building the back end of this application you will gain some insight into how these social applications work underneath the hood. In addition you will learn some tips when it comes to designing API endpoints for clientside consumption of your code. In order to get the most out of this course, you should have a good grasp of Python programming. If you are comfortable making and using functions, classes, dictionaries and understand the basics of properties, decorators and lambda functions, you're in good shape for this course. A few links for brushing up on these topics are available in the instructor notes. We will be using the Flask web development framework. And SQLAlchemy extensively in this course. If you're not familiar with the basics of Flask, please check out the official Flask documentation or Udacity's full stack Foundations course. Links to both of these can also be found in the instructor notes. An understanding of OAuth 2 flows will also be very helpful when it comes to securing our web API. I highly recommend completing Udacity's authentication authorization course, or reading through some of Google's Oauth 2 documentation before attempting this portion of the course. I highly recommend using a Vagrant environment for this course. Vagrant will allow you to work in a virtual machine with a shared folder you can access on your host computer. This way, if anything accidentally gets messed up in the vagrant machine, it won't affect your host machine. A link to downloading and installing a Vagrant machine, pre-installed with all the necessary libraries for this course, can also be found in the instructor notes. We will be delving into the Google and FourSquare documentation, and playing with their APIs later in this course. You will need developer accounts for both of these applications, which can be created free of charge. Links for creating these accounts, if you do not previously have them, can be found in the instructor notes as well. The acronyms API get's thrown around a lot in the computer science community, but what is an API and why is it so important? Well, APIs are Application Programming Interfaces refer to any method of communication between two entities of code. You can think of APIs as connection points in code that allow one application to talk to another. When you copy code from a browser and paste it into a word processing application, an API inside your computer helped make that transfer of data happen. If you listen to music on your computer, like with Itunes or Spotify, the music-playing application communicated with your operating system's API in order to send that music to your speakers. APIs are a great way for controlling the exposure of code, allowing internal functionalities of an application to be used from the outside world without exposing all of the internal code. Companies that want to keep their code bases private, like the makers of Microsoft Windows or Mac OS X, use APIs to make it possible for their applications to still have interactions with other applications without having to reveal the actual code. Even for open source code projects, like the Ubuntu operating system, APIs make easy entry points to code that other developers will most frequently use. So, you've seen some examples of how API's can work within the same machine. But what this course is really going to focus on, is how API's can enable communication between several machines. This is where Web API's come into the picture. Simply put, Web API's make it possible to invoke the execution of code on another machine via the Internet. A machine can use multiple web APIs to create a new application, sometimes called a Mashup, providing users with a new experience that leverages existing applications. Soon, you'll be making a Mashup of your own. But why is all this important? And what do companies gain by allowing their content to be accessible via API's? By opening up code over the Internet, API providers are not only helping other developers who want to use their code, but are also promoting their own business. API's for social media applications, for example, allow users to share content, logins, and personalized data between web applications. Gaining popularity, and giving users more functionality with their accounts. This means more traffic, and more users for social media applications with publicly available APIs. So, implementing accessible web API's, isn't only just a nice thing to do, it's also a lucrative investment for many companies, and in some cases a companies proprietary money stream. An example of a company that depends heavily on it's API, is Twilio. A cloud communications company that allows developers to make, and receive phone calls, and text messages using its web server's API. Twilio has free, and paid access versions of their API, forming a key revenue stream for the company. Check out Twilio's developer's sight, and see all the features of their API. Udacity has an API too, but before looking it up, see if you can guess what data we provide through our own API. Visiting Udacity.com/catalog-api we can see that overview page of the API endpoints Udacity makes available to the public. Access to course descriptions, materials, and nanodegree information is all available. Wow, look at this. Even code snippets for accessing these APIs using several different programming languages is also provided. Billions of machines connected to form the World Wide Web, all run using different operating systems, specifications, and data structures. So, how do we make sure these devices can all communicate with each other? A set of rules must be in place in order for machines to speak the same language. We call these sets of rules, protocols. A common abstraction for conceptualizing this is with the open systems interconnection or OSI model. This model characterizes the communication functions of the computing system, without getting too caught up with the specifics of each different type of computer. This allows the model to focus on the interoperability of diverse communication systems with standard protocols. The model partitions a communications system into abstraction layers. The original version of the model defines seven layers, as shown here. A layer serves the layer above it, and is served by the layer below it. A variety of protocols can exist within in each layer, but they all have to be able to receive and hand off data to the protocols in the adjacent layers. A good analogy to conceptualize this, is like sending a message inside of multiple envelopes. The application layer is the code that makes the original message. It is then passed on to the layer beneath, which wraps this message inside an envelope. Each layer adds another envelope with more information about preparing the message, breaking it up into small packets, routing the message to its intended final destination, and rebuilding the message once it arrives. Once the message reaches the physical layer, it is transmitted as a stream of bits over a physical medium. Physical media are the wires, fiber optic cables or wireless signals that you use to connect to the Internet. Once the message reaches it's intended machine. It is now processed in reverse order such that the application sitting on the receiving computer gets the message the same way it was created by the sender. When it comes to developing web applications in API design, developers mainly focus on the application layer in the OSI model. Operating systems can handle the complexities of the lower levels for us in most cases. But, if you're interested in learning more about the lower layers of networking, please check out some of the links I've provided in the instructor notes. In the previous video, you learned that virtually every device that communicates across the Internet has a physical layer, and these intermediate communication protocol layers that sit on top of it, in order to enable the transmission of packets and data streams. Sitting on top of these layers is the application layer. This layer is responsible for setting all of the protocols in which applications exchange data. The most popular application level protocol is the Hypertext Transfer Protocol, or HTTP. HTTP functions via a series of requests and responses between clients and servers respectively. You may be familiar with other acronyms like FTP, IMAP, SSH, and POP. These are also some other popular application level protocols. The original OSI model has the application layer sitting as the highest level set of protocols for communicating across the Internet. But other protocols and technologies for sending and receiving information via APIs also exist. In order to better understand and organize these technologies, I would like to introduce two more layers to our existing model. Let's call these two layers the web service and message formatting layers. The web service layer refers to the protocols that can sit on top of the application layer and can determine the format in which APIs are sent and received. One of the most popular protocols at this level is the simple object access protocol, or SOAP. SOAP uses the extensible markup language to transmit sets of information in the form of objects. SOAP most commonly sits atop the HTTP application protocol, but can also function with SMTP, or the simple male transfer protocol. REST, a representational state transfer, is the up and coming alternative to SOAP. REST is more of a set of styles and guidelines than a protocol, since it leverages the features of HTTP in order to transmit information. HTTP verbs like GET, POST, PUT, and DELETE, handle the management of a server's resources. So we've covered ways to communicate between machines, but how do we format the sets of information that we want to send and receive? This message formatting layer contains the languages that address this concern. These protocols focus mainly on the data structures that contain the information we want to communicate, like the protocols in the other layers. There are several implementations already out there, but the most two common formats are XML and JSON. XML stands for the extensible markup language. It looks very similar to HTML and is readable by humans and machines. JSON stands for JavaScript object notation. It was designed to resemble JavaScript code, and has attribute value pairs, making it also very easy to read from the human eye. With all these technologies out there, we've got to do some side-by-side comparisons in order to make the choice that best suits our web application. In the last video we covered quite a few acronyms describing many of the different protocols out there for implementing web APIs. In this video, let's do some side-by-side comparisons in order to determine which technology is best for what we want to accomplish. SOAP and REST have both been proven as two viable options for implementing a web service. Soap was originally developed by Microsoft in 1998. For SOAP we are obliged to use XML for our data structures, but can choose HTTP or another underlying application-level protocol. REST was more of a description than a development project. The acronym first appeared in a dissertation by Roy Thomas Fielding in the year 2000. REST uses the HTTP verbs in order to access and manipulate resources, but can use any type of messaging protocol to structure the data it sends. In order for an application to be truly restful, it must adhere to a set of constraints Fielding defined in his dissertation. So it seems we still have two good options, but let's take a look at the popularity of the two implementation options over the years. >From this data gathered by programmableweb, we see that REST has gained an outstanding popularity over the past decade. A major reason for this is because REST is generally easier to implement than SOAP. And for web developers, working with HTTP is already a familiar practice. For these reasons, this course will focus on designing RESTful web APIs. So now that we've decided to go with a restful architecture for our development needs, what about the structure of our data? XML and JSON are two very viable options, so let's compare them side by side as well. XML was developed in 1997. It uses identifying tags similar to HTML and provides a rigid way of structuring data. JSON was developed in 2001 and is derived from the JavaScript language. Similar to HTML, it is easily human readable, but can be condensed with less characters to be very lightweight. Once again, it seems like these specs aren't really helping in making a decision if one is better than the other. But since our APIs are made to best suit the developer, we should use a data structure that is most friendly to our end user. Looking at this chart, we can see that XML started as the data structure of choice, but JSON has been quickly gaining ground year over year and is now the more popular data structure amongst new APIs. By piggy backing off the popularity of JavaScript, JSON has been readily accepted by the web development community as the most common way to structure data sent across restful APIs. So for this course, it's JSON for the win. Previously I mentioned that REST is more a set of guidelines than a protocol itself. This is because it takes the HTTP protocol and applies a few constraints to clarify communication and resource management. In this video, I will go more in depth as to what these constraints mean for us as API developers. The first constraint of a REST full implementation is the separation of clients and servers. A client is defined as a machine requesting a resource where the server is the machine that responds with the requested resource. A machine can function as a client and as a server, but for the duration of an HTTP request and response cycle, it must assume the role as either the requester of the information or the holder of that information. A stateful architecture remembers a client's activity between requests. If you've ever used a website where you have shopping cart or login session, it appears as though the server is remembering your activity throughout the duration of your time on the website. A truly RESTful architecture, however, is not allowed to retain information about the state of another machine during the communication process. Each request from a client to a server must be treated as though it was the first request the server has ever seen from that client. A server should not remember its clients and readjust its state accordingly. The server may only give back up to date state about its state to the client and allow for modifications, if it is authorized to do so. In lesson four, you will see how using tokens is a good way to have a stateless design that can create an experience that seems state remembering to the user. Response messages from the server to the client are explicitly labeled as cacheable or non-cacheable. This way, responses can me cached by the client if the information on the server hasn’t changed since the last request. RESTful architectures must have a uniform interface between all clients and servers. For example, a server must not require a different way of accessing data if a client has a Windows laptop verses an iPhone or a Unix server. Gaining access to these end points is the same for any machine trying to access this information. A layered system means that a client can have access to endpoint that relies on other endpoints without having to understand all of the underlying implementations. If client A wants to communicate with server B and that server goes out to Google or some other database in order to generate a response, client A should not have to accommodate for any other technologies besides accessing server B's endpoint. Layering allows very complicated tasks to be completed without having to understand all of the underlying complexities that are required to generate the response. Code on Demand is an optional constraint for RESTful applications, but it opens a possibility for code like JavaScript, for example, from the server to be sent off to the client for execution. For more about the RESTful constraints, feel free to follow some of the links I've provided in the instructor notes. That wraps it up for lesson one. In this lesson, we discussed some important features of APIs, and came to the decision to implement a restful API with JSON. In the next lesson, we will get some hands-on practice, working with the endpoints of a few popular companies. In the second lesson of this course, you're going to explore the APIs of some popular online applications. I will point you to some documentation, introduce you to a few tools for API exploration and testing, and then you will write code to utilize these APIs inside of your own Python applications. So let's get started. A fundamental part of understanding restful APIs is understanding the components that make up the client-server flow of HTTP. HTTP can be described as pull protocol. Communication is always initiated by the client sending an HTTP request to the server. In turn, the server responds with a response message. These messages are just bodies of text that the machines can later interpret into actions, images, and even multimedia content. Let's briefly discuss some of the major components of HTTP requests and responses, starting with requests. Every HTTP message consists of a message header, and an optional message body. These two entities are separated by a space, like in the diagram here. In an HTTP request, the first line of the header is called the request line. The request line contains the HTTP verb, the URI, or Uniform Resource Identifier, and the HTTP version number. Take a look at these examples of request lines. We see the verb here, the resource we want to access via the URI here, and the version of HTTP we are using at the end. After the request line we have the optional request headers. These are perimeters that can be used to describe specific properties about a request. Request headers appear in name value pairs. Multiple values can be separated by commas, like so. A blank line separates the header and body of an HTTP request. In the body, we can add any other information about the request that we want to send along to the server. An example of a complete HTTP request message is shown here. When a server receives an HTTP request it returns a response message to the client. This response can contain the information requested or an error message if there was one. Similarly to the HTTP request message, the response consists of a message header and optional body. The first line of the header is called the Status Line. Followed by optional response headers. The status line contains the HTTP version, status code, and a reason phrase that explains the status code in English. Here are some common status codes and reason phrases. The optional response headers take the form of name value pairs, similarly to their request header counterparts. the response message body contains the data that the client requested. If the client asked for a web page, a sample response might look something like this. When you search the web, your web browser takes care of creating HTTP requests and rendering responses onto your screen. But as an API developer, there will be times when you have to create and dissect these messages yourself. You'll learn some ways to do this in the next video. So your web browser does a great job of concealing a lot of the complexities of HTTP, such that the user can focus on the web surfing experience. But as developers, we need to be able to dig deep to see what is going on with requests and responses. Luckily there are several tools out there that we can use to generate HTTP requests and view responses. In this video, I will point out two of my favorites. If you're a big fan of command line applications, Curl is one of the most popular command line tools for sending and receiving HTTP messages, even though it can also transmit on several other protocols. If you prefer a graphical user interface, Postman is an easy-to-navigate Chrome extension you can use to build and view HTTP messages. Documentation for using these tools can be found in the instructor notes. I recommend choosing one of these tools and getting familiar with it for future exercises. In this exercise, you will download and run the API server Python file, and run it on your vagrant machine. It will start up a web server listening on local host port 5,000. Use Curl or Postman to send messages to this server, and paste the response of the requests in the boxes provided in the next screen. So now that you've sent requests to a local host server, let's try seeing if we can get information from other servers out on the Internet. Let's say I want to try to access the API for SoundCloud, an online audio distribution platform that enables its users to upload, record, promote and share their originally created sounds. In order to figure out what requests I can send to the SoundCloud server I will go to their developer website and search through the documentation. To control and protect their resources, SoundCloud requires developers to register each application they want to create that will communicate with their API. Once my account is created, I'm provided a Client ID and Client Secret. I can embed these credentials into my request in order to successfully access the SoundCloud API. Now, searching through the documentation, I see the resources that are available for me to access, along with some examples on how to create requests to access this information. Many of the post, put and delete methods are protected with access tokens. Since my app would need permission from end users in order to post information to SoundCloud on their behalf. So for now I'm just going to build a get request to view the contents of a playlist with the following playlist ID. I must also add my client ID so SoundCloud could recognize that it's my application trying to communicate with the server. I can build the request using Curl or Postman, send if off, and see that I received a successful response. If I open the permalink URL provided in the response, I can also see the HTML page that contains this playlist information in my browser. In this next video, you'll be able to delve into some APIs on your own. So, enough watching me tinker with APIs online. Now, it's time for you to try and experiment with API providers on your own. These next two quizzes will not only help you get more accustomed to working with APIs, but they will also serve as code snippets, to help you complete the final project. Google Maps has a geocoding feature that can take in a stream representation of a location. And try to find the latitude and longitude coordinates of that place. Use the Google Maps API documentation to geocode the following cities into latitude and longitude coordinates. Use Corel or to help you make these requests. Foursquare is a local search and discovery service application which provides search results for its users. By taking into account the places a user goes, the things they like, and other users' advice, Foursquare provides recommendations for places to go around a user's location. For this exercise I want you to use the search feature in Foursquare to find a restaurant based on the latitude, longitude and search queries provided on the next screen. Using Postman and Curl were great tools for building our http requests. But let's create these requests and responses in Python so that we can embed those functionalities into our server-side code. Let's start by writing a simple Python application that does the geolocation API requests for us. I'm going to name this Python program geocode.py. I will import the httplib2 and json libraries into my program. Httplib2 is a comprehensive http client library in Python. And the JSON library in Python is for converting in-memory Python objects to a serialized JSON representation. Now, I will create a function and call it getGeocodeLocation. It will take in an input string, that is the name for the place we want to get the coordinates for. Then, I create a variable for storing my google_api_key. You should paste in your key here. Having your secret keys visible in your Python code isn't the safest practice for live code. But it's fine for this activity. Now, in my input string, I need to replace any spaces with plus signs, such that there are no breaks in my URL path, and the server can read it correctly. I do that with the replace function here. I then build the URL here and pass in the location string and my Google API key. Next, I create an instance of the http class and name it h. I can now create a GET request with the request method here. This request will return an array with two values, the http response and the content. I will call json.loads on the content to format it in a way that is easier to read, but still in proper JSON format. Now, just so we can see what the response header looks like, I will have it print to the terminal. And then I will return the result variable which contains the formatted content that I requested. Now, I will save my code and start a Python instance in the terminal, in the same directory where my geocode.py file is. I import the getGeocodeLocation method from the geocode file, and we're trying to get the location of my hometown, Dallas, Texas. Here, we can see that our response header contains a successful status code along with a lot of other meta data that Google provided with our request. Looking at the actual content of the response, we see that we got a lot more data than just latitude and longitude coordinates. But nevertheless, the information we requested is in the response somewhere. In this next video, let's see if we can figure out a way to parse through all of this information in this response. So you've seen some of the responses we get from these APIs, and they're kind of unwieldy. Although they are somewhat readable, at first glance it's difficult to extract something useful from these responses. But these JSON responses are easily parsable in Python. I'm going to call the getGeocodeLocation function again, but this time, store the result in a variable named Dallas. So when I call Dallas, I get this huge JSON object again. Looking at this response, I can try to better understand the data that google maps is providing to me. All of the data that looks like coordinates is in this portion of the response. I see quite a few coordinates though, so which ones are the ones that I need? Well, reading through the response, the first thing I notice is that Google is giving me an approximate set of coordinates, that correspond to the Northeast and Southwest bounds of the city. Then it provides a suggested viewport for viewing the entire city on the map. But this final set of coordinates seems to correspond to a central set of coordinates for the city. These are the ones that I want to extract. By typing dallas.keys I can navigate through the keys of the JSON response like a Python dictionary. In some cases, I see that keys contain lists of values. So by using the square brackets, I can reference to an index inside of these lists. After navigating through this response for a little bit, I found that going into results, then the zero's index, then geometry, location, and lat, gave me the latitude that I wanted. Similarly, going down the same path and then using lng, returns the longitude coordinate I wanted. So I'm finished extracting just the latitude and longitude coordinates from my geocoding request. I modify my geocode.pie file like so, such that now it responds the latitude and longitude coordinates. I'll also comment out the response header for now as well. The code for this activity can be found in the instructor notes. In this challenge, you will create your own API Mashup. Write a function called findARestaurant that will take an extreme representation of a mealType and location. This function should first geocode the location and then pass in the latitude and longitude coordinates to the Foursquare API. After that, it should parse the JSON response, such that it returns the first restaurant in an easy to read format for the user. You will have to explore the Foursquare documentation a little bit to figure out a way to retrieve an image of your restaurant if Foursquare has one. If no image is available, then provide a default image for the restaurant. The image should be sized to 300 by 300 pixels. A starter template is provided in the instructor notes. I have added the following lines of code such that non non-ascii characters, or characters not common to the English language. Also render properly in your code. I also strongly recommend using the browse parameter when you send off your URI to Foursquare. This will search in a much wider vicinity than just the latitude longitude coordinate you provide the API. Your code should print the results to the terminal, when run from the command line. And also return a dictionary with the restaurant's name, address, and images. This challenge is intended to be tough, but don't give up. Use your resources and other students if you get stuck or have any questions. Step one for the findARestaurant function was to geocode the location into latitude and longitude coordinates. Using the getGeocodeLocation function I previously created, I can simply call it here, and store the coordinates in latitude and longitude. I can now build the URL to access the Foursquare API. Passing in the necessary Foursquare client ID, client secret, latitude, longitude and meal type to query the search. I send off the request using the HTTP library, like I did with geocoding, and store the response in the result variable. By exploring into the result object and then going into response and then venues, and finding the zeroth item, I found the first restaurant of my query to Foursquare. And then extract important information about that restaurant as well, here. I enclose this declaration inside an if statement to make sure at least one result was found. The venue_id will be necessary to find pictures taken in that particular restaurant. And the name of the restaurant is always helpful. The address of the restaurant is a list that breaks up each part of the restaurant, such as the street, state, and country into a different entry. I want to make my address one long string, so I'm going to loop through the values and catenate them into an address string, separated by spaces and then update my restaurant address. Now I need to create another API request to the photos API in Foursquare in order to grab a photo from the restaurant. The venue ID gets passed in along with the client ID and client secret in order to communicate with this API. Some results can contain multiple images, and other results can contain no images, so my code needs to account for that. If images are available, I can retrieve the first one by referencing the zero index value of this entry in my response. As stated in the foursquare documentation, this image contains a prefix and suffix string. Between the two sub strings I can append dimensions for scaling the image. So I'm going to make it 300 by 300. And save this as the image URL variable. If no images were found, I will just use this stock photo of a cheeseburger in its place. I'm now going to create a dictionary that contains the restaurant name, address, and image. I'll print these results so that they're in an easily readable format from the terminal, and also return the restaurant info. Outside of my if statement, I can now handle the case that no restaurants were found. I'll just make a print statement saying no restaurants found, and return a string saying the same thing for now. Now if I save and run my code, the find a restaurant method is called on several different meal types and locations, which I can see from my terminal. Code for this section is available in the instructor notes. In this lesson you got some hands-on experience working with real APIs. I encourage you to keep exploring other APIs, and get used to going through documentation so you can use them for future projects. I listed some of my favorite APIs in the instructor notes. In this next lesson, you're going to learn to create your own APIs, that you and other developers can implement. Ready to start making your own APIs? Great, in lesson three we'll do just that. Using the Flask web development framework, we will start building some web API endpoints, complete with a functioning back end and database. If you aren't familiar with Flask, or would like to brush up on your Flask skills. Click on some of the links below for reference on some of the basics of Flask. If you're familiar with the flask web development framework, you should be no stranger to the app.route decorator. This decorator in flask can be used to make URLs to render webpages and API endpoints alike. You should also import the jsonify package from flask into your application. Jsonify can convert dictionaries into JSON objects that can then be sent to the client. The jsonify function in flask returns the flask response object that already has the appropriate content type header for use with JSON responses. In this next exercise, you'll familiarize yourself with making basic API endpoints with flask. In the downloadables section there's an endpoints project dot pi file that contains code for starting a web application about puppies. This file already contains the code for setting up a Flask web server but is lacking the appropriate F dot route end points for some of the methods. Create the appropriate app.route function. Test and see if they work using the end points tester dot pie file. Pace your URIs in the boxes on the next screen. Let's use the comments in the code to indicate the types of routes we should build for each method. The first puppyFunction doesn't take in any inputs. This should serve as an indicator that our app.route function doesn't need to take any variables in the URL either. So we can build the route for the puppyFunction as so. Now for the second method, we're passing in an integer to represent the id number of the puppy. This means we must build the route for the puppies function with an ID variable like so. The solution code for this exercise is provided in the instructor notes. By default, the app.route decorator only responds to GET requests. Other requests, like post and delete, must be specified inside the app.route using the Methods property, like so. In this next exercise Add POST, put, and delete methods for the appropriate endpoints in the new version of your inpoints project2.pi file. Run endpoint tester2.pi, to check and see if these requests were successfully executed. >From the if statement here, we can see that the puppies route should respond to get and post requests. So we can add the methods here. A get request to the slash puppies route represents a request to view all of the puppies already in the database. So get all puppies is the appropriate method to call. The post request represents making a new puppy entry in our web application. So let's return the make a new puppy method accordingly. When the puppy's route is accessed with an integer variable, this represents an operation on a specific puppy that has already been created and assigned an ID number. So then get, put, and delete operations can be used to read, update, and delete a specific puppy entry. So let's call the get puppy ID, Update Puppy ID, and delete Puppy ID for this exercise .Solution code for this activity is available in the instructor notes. Now that we have working end points, let's add a database to our application. In the downloadable section there's a new version of our web app, called end points project three dot pit. Along with a models dot pie file that contains our database configuration. The code has been refactored to use SQL Alchemy in order to execute actual crud operations. On a puppies.db file, instead of just returning print statements. Your assignment is to add a serialized decorator to the database model. In order to properly creat JSON objects from the results of the database queries. Add the serialized property to your models.pie file, and run the tester found in the instructor notes to see if your serializer works properly. Let's create a property decorator in the models.pie file just after defining the columns of our puppy class. I will define a method called serialize that takes in itself as the only input. Now all we have to do is return the information in our puppy class in the following format such that it can be easily serialized into a JSON object. The code for this exercise is available in the instructor notes. It's now time to put together everything you've learned thus far into a single mashed up web application. Let's leave the puppy application aside for a moment ad go back to the restaurant menu application. It's now time to put together everything you've learned thus far into a single Mashup web application. Let's leave the puppy application aside for a moment and go back to the restaurant menu application. In this exercise you will first have an endpoint that takes in a city name and meal type. Geo codes the location, finds a nearby restaurant with that meal type, stores it in a database, and then returns a JSON object of that restaurant to the user. And this should happen on a post request. On this same route, handle a get request that returns all of the restaurants in your database, along with their name, ID number, Address and Image inside of a JSON object. Then you will make another end point that takes in a restaurant's ID in the route. A get request to this route should return the name, ID number, address, and image of a specific restaurant. An update along with any or all of the name, location and image parameters should update this restaurant information in your database. And a delete to this route will remove this restaurant from your database. In the instructor notes, you will find a collection of Python templates to help you get started. FindARestaurant.py has the API methods created in lesson two. Be sure to update this file with your client ID and client secret. Inside views.py you will add all of the routing and Python code, /restaurants to view all the restaurant in your database and post a new restaurant. And /restaurant/id to get the specific information about a restaurant, update its name, address, or image or delete it from the database. When you are finished, use the tester.py file to test the functionality of your web app's API endpoints. Let me go ahead and show you my implementation for this exercise, although your code may be a little bit different. Let's start with the /restaurants route. If I'm receiving a get request from the client, I should return all of the restaurants currently stored in my database. I can do that by making a query with SQL alchemy like so. And then serializing and jsoning the results. Now, if I'm receiving a post request, I will want to extract information from the url parameters in order to find a new restaurant. So I retrieve my location and mealType in the code here. Next, I will call findARestaurant on the mealType and location and start in a variable called restaurant_info. So long as restaurant_info isn’t empty, I can create a new restaurant row in my database with the restaurant_info object and commit my changes. If I find a restaurant did not come up with any results, I can return a json message like this one indicating the error. Now for my /restaurants/id route. For all of these requests, I'm going to want to find the restaurant with the matching id number of my route. So I will execute that query here first. If I received a get request, I will simply return the restaurant in a serialized json object. If I received a put request, there should be some parameters to update the information about this restaurant. I will grab these parameters from the URL here. I will only update the restaurant if there was actually a parameter provided in the URL. So I'll check first and then update. Finally, I return an updated JSON object, once I've committed these changes. And finally, I add the functionality for the delete request. I delete the restaurant, commit the change, and return that the restaurant has been successfully deleted. Running my tester.py, I see that all of my tests run successfully. The solution code for this activity is provided in the instructor notes. Please make sure you are able to get your own version of this web application running and understand the code written thus far before continuing on. Don't hesitate to ask for help in the forums if you have any questions. You've reached the end of lesson three and created some fairly complex API endpoints thus far. In the next lesson, you will add some security to your API endpoints, as you learn to implement token based authentication, and rate limiting to control the bandwidth users have access to. [SOUND] Thank you. See you there. In this fourth lesson we will discuss some security concerns for restful API endpoints, and implement a few features that allow authentication and authorization to be handled from endpoints. In the quiz portions of this lesson, you'll be helping a few small businesses in the food industry by beefing up the security of their web APIs. So let's get started. For most applications that you'll want to create, you'll want to have some concept of users to provide security and custom information based on each individual person using your application. So for this exercise, I will create a new models.py file with a user class like so. It is not considered a safe practice to store actual passwords in your database. For this reason, I will store the hash of a user password. A hash is the result of a mathematical algorithm that can be used to map digital data of arbitrary size to digital data of a fixed size. If my user database were to be compromised or opened by an attacker, it would be extremely hard to decode the real passwords from the hashes. Hashing algorithms are one-way functions, meaning that they can only be used to generate a hash from a password, but they cannot be used in the reverse direction. These algorithms are also deterministic. This means that given the same inputs, they will always generate the same output. In order to create these hashes, I will use a library called Passlib, a package dedicated to password hashing. Passlib provides several hashing algorithms to choose from. The custom app context object is an easy to use option based on the SHA256 hashing algorithm. To add password hashing and verification, I'm going to add two new methods to the user model. I'll use them later on in my code. This hash_password method takes in a plain password as an argument, and stores a hash of it in the user table. This method will also be called when a new user is registering with the server or if the user changes her password. This verify_password method takes a plain password as the argument and returns true if the password is correct, or false if it's not. This method is called whenever the user provides credentials that they need to be validated. All Passlib needs to do to verify a password is to hash it with the same function that was used during registration and then compare the resulting hash against the ones stored in the database. This means that we never have to store a real password in our database. So now that i have my user model in place, I will make a use.pi file to handle the logic of actually registering a new user. I will structure this inpoint such that a client can register a new user with a post request to slash users. The body of this request needs to be a JSON object that has username and password fields. Let's take a look at the implementation of this flask [INAUDIBLE]. The user name and password arguments are obtained from the JSON input coming from the request. And then validated. If the arguments are valid, then a new user instance is created. The user name is assigned to it. And the password is hashed using the hash_password method. The user is then finally written to the database. The body of the response shows the user representation as a JSON object, with the status code of 201, so let me run my application and try registering a new user with Postman like so. We'll build this request in curl by using the following command line text. My server response that a new user has successfully been created. The views dot pi and model dot pi files are available in the instructor notes. It's also important to point out that in a real application, login should always be done over a secure HTTP connection If the login credentials are going to travel through the networking, clear text, they're are easily visible to a potential hacker. If you are interested in learning more about HTTPS and FLASK, check out some of the resources provided in the instructor notes. Now that users can log in to my system, I should make a way to protect the resources they can access. For this example, let's assume there's a resource exposed by this API that needs to be available only to registered users. This resource is accessed at the end point /protected_resource. To protect this resource, I'm going to use an extension in Flask called Flask-HTTPAuth. Flask httpauth is a simple extension that provides basic and digest http authentication for Flask routes. With Flask httpauth, an end point is protected by adding the auth.login_requried decerator to it. Flask.httpauth needs to be given some more information, to know how to validate user credentials, which is implemented through the verify password call back. It is given a username and password and returns true if the combination is valid and false if not. Flask HTTP off invokes this callback function whenever it needs to validate a username and password pair. This function simply finds the user by their username, verifies the password using the verify password method. And if the credentials are valid, then the user has stored it in FLASK's G object, so that the view function can use it. Let's send a request to my server now, and first see what happens if I use an incorrect username or password. I can't access the resource. But using the correct username and password, my request gets the protected resource for the user. Check out the instructor notes to see the code implemented in this video. Mom and pop are working on building a backend Flask web API for their bagel shop. Download the code in the instructor notes to see the code they have thus far. There's a /bagels route that exposes all of the bagels in their inventory. A feature that only users that are Mom & Pop's Bagel Shop members can view. Don't worry. Becoming a member is free and easy. Help Mom and Pop by adding a user class in their models.pie file that securely stores user names and hashed passwords. Add a route for users to register their accounts by sending a post request to /users. And protect the / bagel's endpoint such that only members can view a bagel directory. When you are finished, use the bagel tester,py file to test and see that your code works. We first add the user class to the models.py file, like shown here. Functions to hash and verify a password are also provided. Now, in the views.py file, we will add the logic to create users. I will add the user route so that it will either create a new user or identify an existing one. Now I will add the auth.verify_password decorator. So Flask http off knows how I want to validate my users. Once that is done, I can protect a route like /Bagels with the off.login required variable, just like I did here. With all of the code modifications in place, we should now be able to pass all the tests in our Bagel tester.pie file. Check out the instructor notes to view this code. In the previous exercise, we had to sent the username and password with every request that was protected by the off.loginrequired_decorator. This is inconvenient and can be seen as a security risk even if the transport is secure HTTP. Since the client application must have those credentials stored without encryption to be able to send them with these requests. When rendering HTML pages with Flask, we had the ability to use the login session object to store information about the state of the client between requests. Flask did this by creating an encrypted cookie for us that the browser could append to each HTTP request. But since our RESTful API may not always work with the browser or a client that can securely store and transmit cookies, we need another method for storing and communicating credentials. A popular solution to this problem is to create tokens. A token is a string that the server generates for the client that can be passed along inside an HTTP request. The idea is that the client application exchanges authentication credentials for an authentication token and in subsequent requests, just sends the token. When the server receives the token, it can then look up the credentials of the user and determine whether or not it is authorized to the information it is requesting. Tokens are usually given out with an expiration time after which they become invalid and a new token needs to be obtained. The potential damage that can be caused if a token is leaked is much smaller due to their short life span. A server can easily determine if a token is to old and decide to reject it, if it doesn't view it as valid. So how would we go about creating tokens? A straight forward implementation is to generate a random sequence of characters of certain length that is stored with the user and the password in the database. Possibly with an expiration date, as well. The token then becomes sort of a plain text password in that it can easily be verified with the string comparison plus a check of its expiration date. A more elaborate implementation that requires no server side storage is to use a cryptographically signed message as a token. This has the advantage that the information related to the token namely the user for which the token was generated is encoded in the token itself and protected against tampering with a strong cryptographic signature. Flask uses a similar approach to write secure cookies. This implementation is based on a package called itsdangerous. In the next video, we will use the itsdangerous library as we take on adding token generation and verification to our user model. In this video, I will walk you through an implementation of token-based authentication in Flask. There are several ways of implementing this functionality in your code, but this is one solution I have to be found rather easy to understand and secure. I have a new models.pi file that contains the user model and the basic HTTP authorization code from the previous exercise. Here I have a secret key, which is just a random string of 32 characters that I will use to sign my tokens. I will also make a new method here called generate_auth_token. I will make the token be an encrypted version of a dictionary that hides the ID of the user. The token will also have an expiration time embedded in it. Which by default, will be of TEN mins or 600 seconds. The verification is implemented in a verfy_auth_token static method. A static method is used because the user will only be known once the token is decoded. Now in my views.pi file, I'll make a new end point that the client can use to request a token. Note that this inpoint is protected with the auth.loginrequired decorator from Flask HTTPI, which requires that the user name and password are provided. Next I'll add code for handling a token when my server receives one. The HTTP basic authentication protocol does not specifically require that user names and passwords are used for authentication. These two fields in the HTTP header can be used to transport any type of authentication information. For token based authentication, the token can be sent as a user name, and the password field can be ignored. This means that now the server can authenticate requests with the user name and password. And request with just a token. The verified password callback needs to support both authentication styles. This new version of the verified password callback attempts authentication twice, it first tries to use the user name argument as a token. If that doesn't work, then user name and password are verified as before. I will run my web server again and send the following kernel request. In order to get an authentication token, I will run my web server again, and send the following kernel request, in order to get an authentication token. Now the protected resource can be obtained authenticating with the token. Note that in this last request, the password is written as the word blank. The password in this request can be anything, since it isn't used. the code, end request, can be found in the instructor notes. In this next exercise, you're going to help Regal Tree Foods by adding token-based authentication to their existing log-in system. Users don't want to have to log in each time they access a different product in their catalog, so tokens could be a solution to this problem. Use the fruit_tester.py file to test your application. First let's add the generate_auth_token and verify_ auth_token methods in our model [INAUDIBLE] file. Remember that verify_auth_token is a static method since it gets called before we create a user object. We also need to add a secret key that we will use to sign our tokens. [INAUDIBLE] I'll add the token route, which the user can access to get a token in exchange for their username and password. Let's then refactor our verified password method. Such that it checks for a token and then looks for a username and password. Running the tester, I can now use the token to view and create new products in the Regal Tree Foods database. As always, the solution code is available in the instructor notes. So, we now have a token based authentication system that will authenticate a user based on their user name and password or a token. But if we were going to actually store passwords, users will be forced to make accounts and remember another password in order to use our API. In a real application, we would need to implement some sort of account verification and password recovery for our application, since users can often forget their passwords. And users would need to fill out another profile and probably upload another profile picture, adding more delay time for the user to access our application and potentially introducing a place for a loss in user retention. If we add OAuth 2.0 to our application, we can let users log in with their existing accounts, like Google and Facebook, and quickly gain access to our application. In this next video, I will show you how to add an endpoint using Google signin that will allow users to log in with their existing Google accounts. In this example, I have a client side application that logs in with Google and is provided a one time use auth code. The client sends this auth code off to my server in which in turn communicates with Google in order to exchange the code for an authorization token. The client then sends off this code to my server, which in turn communicates with Google in order to exchange the code for an access token. If the exchange is successful, then I create my own token, which I can send back off to the client to authenticate with my application. Let’s start by registering our application with Google in order to get a client ID. We can download our credentials into a JSON file our code can then point to. A more detailed walk through is provided in the instructor notes. Now in the code, let's start by refactoring my user model to take advantage of some of the profile information I can get from my OAuth access token. A user's name, email and profile picture can be easily obtained with OAuth. So, I will add these fields now. I can look up users by their unique email addresses, so I will index my database based on emails as well. Now that I've used that pi, I will add a new endpoint called /oauth/provider that responds to a post request. We will first get the one time auth code if the parameter is set to Google, then we'll take this auth code and send it off to Google in exchange for an access token. Once I've successfully received an access token from Google, I can use it to send an API request to Google to get my users' information. I will look up an user based on the provided email address from the Google API. If a user exist, I will receive that user object. Otherwise, I will just make a new user object and store their information in my database. Now that I have a user object, I can generate an off token to allow that user to access protected endpoints without having to provide a user name and password. And since this course doesn't focus on creating the client side application that will send off this authorization code, I have added a template that signs into Google and displays the one time auth code. View the Instructor Notes to see and play around with the code from this video. Pale Kale Salads and Smoothies wants to allow users to access their API using their existing Google accounts. Make an endpoint at /oauth/ that takes in Google's one-time auth code. Exchange this auth code for an access token. Use the access token to look up the user's email address, or create a new user. Then create a new token and return it to the client. Use the veggie_tester.py file to make sure your code runs properly. To complete the first step in this activity I will re-factor the models dot pi to accommodate for the credentials I can obtain from google. Then in my views file I'll add the o op provider in point. Using the same codes from the previous video I can exchange my off code for an access token and use it to look up a user or create a new one. Finally, I'll create my own token and send it off to the client. Solutions for this activity are available in the instructor notes. So with tokens in OAuth we can now control authentication and authorization for our API Endpoints. But what happens when users are using the endpoint too much? If we have one data hog constantly pinging the API, our other users might experience drops in performance or may not be able to access our API at all. Or maybe our API isn't available for free and users should be paying for a certain amount of access over a period of time. With rate limiting, we can give our server a bit more control over the amounts of requests we will request from a user over a certain time period. In this next video, I will make a rate limited inpoint in a Flask web application. This exercise uses some more advanced topics in Python. I've added some links in the instructor notes that cover some of these topics more in detail. I will create a new views.py file with a route called rate/limited. Later, I will create a limiting decorator to restrict the number of requests. I should point out that for this example, I'm using the IP address as the identifier of the client. This way rate limiting works even for non-logged in users. But you can change this for your implementation of future projects. Redis is an open source in-memory data structure that can be used as a database, cache and message broker. Redis provides us with a fast way to keep track of end point requests, that is also scalable. Your vagrant machine already has Redis installed. Just run Redis server from inside your vagrant machine to fire up this Redis instance. You can now point to your Redis instance with the code here. Now, I will make a class called RateLimit that takes in the new object model introduced in Python 2.2. I will make a variable called expiration_window that will give my key an extra ten seconds to expire in redis, so that badly synchronized clocks between workers and the redis server do not cause any problems. I will now create an init method for the RateLimit class. Taking init self the variables key_prefix, limit, per and send_x_headers. Key is going to represent a string that I will use to keep track of the rate limits for each of the requests. Limit and per define the number of requests we want to allow over a certain time period. And send_x_headers is a Boolean option that will allow us to inject into each response header the number of remaining requests a client can make before they hit the limit. I would define reset here to make a timestamp to indicate when a request limit can reset itself. Then I will append this to my key. We use a pipeline to make sure that we never increment a key without also setting the key expiration in case an exception happens between those lines. For instance, if a process is killed. I will now increment the value of my pipeline and set it to expire based on my reset value and expiration window. I'll add two lambda functions to calculate how many remaining requests I have left and another one that returns true if I've hit my rate limit. I'll define the get_view_rate_limit function which will retrieve the view_rate_limit from the g-object in flask. I will use this function later on inside of my decorator. I'll also make a function called on_over_limit that returns the message that a client has reached their limit of requests along with a 429 error which means too many requests. Now I will create a rate limit method that will wrap around my decorator taking in the following values as arguments. The key is constructed by default from the remote address and the current endpoint. Before the function is executed, it increments the rate limit, with the help of the rate limit class and stores an instance on the g object, as g._view_rate_limit. If the view function is indeed over the limit, we automatically call a different function instead. Now, I will append the number of remaining requests, the limit for that end point, and the time until the limit resets itself, inside the header of each response, that hits the rate limited request. This feature can be turned off if send_x_headers is set to false. Whenever the rate limit decorator is called and speaking of ratelimit decorator I can now add the rate limit to my route. Here it is currently set to allow 300 requests per 30 seconds. So if everything worked well I can fire up my flask web app and run this hungryclient.py file I made in order to see how well my rate limiter works. I will tell hungryclient to send off 2000 requests per minute or as fast as it can. As you can see, hungryclient is successfully reaching the end point until it hits the limit. Then it waits five seconds and tries again. Once the time limit is reached and reset, more requests can be made until we reach 2,000. Code for this activity is available in the instructor notes. BargainMart wants to create an API to allow third-party developers to create apps that list out the supermarket's inventory. However, querying the database can be resource expensive, especially if a greedy client is overflowing the server. This hungry client.py is a perfect example of one of those greedy clients. It will try to make requests to your server as much as possible if no rate limiting is put in place. Add a rate limiting decorator to the inventory endpoints such that after 60 requests per minute the hungry client is denied service and must wait before sending anymore requests. For this activity, we can simply add the RateLimit class to our file along with the necessary imports. Set the RateLimit decorator on our /inventory end point with 60 requests per 60 seconds. If you fire up the server and launch Hungry Client, you'll see that our server keeps Hungry Client from gobbling up all of our resources. Solution code is available in the instructor notes. You've reached the end of the lesson on API security. If you're interested in delving deeper into making secure API endpoints, I found a few references that will help you get started in the instructor notes. In the final lesson, you will focus on some API developer best practices, before working on the final project. Now that you've learned about the importance of APIs, used providers' APIs and created your own APIs, it's time to use all of these skills in conjunction as you take on the final project for this course. But before you do that, let's talk about the art of making good APIs that your developers will love. I want to motivate you to start thinking about API design from the perspective of the developers who might be using them. I will talk to you about some good practices when naming your APIs. As well as some tips from the pros about supporting your developers with proper documentation and communication streams. In addition to coding APIs that are functional and high performing, documentation should be easy to navigate, and aesthetically pleasing. If your documentation looks like classified ads from a newspaper, developers are not going to be eager to navigate through it. Let's take a look at Twilio's documentation for using their API. Tulio has this overview page, which easily guides developers to the major aspects of their API without getting lost in the documentation. Some API providers like Udacity, for instance, use what we call Hello World documentation containing boiler plate code for using their APIs quickly. Having a section for frequently asked questions, like the Google Maps API, makes it easy for developers to quickly get answers to their most common questions. In some situations a good FAQ section can be just as informative as the original documentation. Since it addresses constraints and common corner cases of a system. Playgrounds and sand boxes are also great tool sets many API providers are adding to their documentation. Developers can test out API end points by executing sample API request directly on the providers web site. When developing your own APIs, consider taking time to make fun, interactive and develop-friendly documentation in order to gain popularity amongst your users. The URI or uniform resource identifier is the path to find resources provided by your API. This means that our URI should always refer to resources and not to actions being performed on those resources. And it is recommended to use the plural form for each resource name. HTTP provides us with eight verbs, or methods, we can use to indicate the desired method of action. We want a server to take on an API endpoint. There's no rule forcing you to use all of these verbs. But it's a good practice to use them responsibly. Head and get requests can be called by search engines and web crawlers exploring the Internet. Make sure these requests only provide information, but never modify your database, or the state of your backend. HTTP also has status codes to indicate the different types of responses a server can send back to the client. A good API should take advantage of these status codes for successful and erroneous HTTP responses. Error messages you send to your users should be concise, clear, and informative. Proper URI paths, HTTP verbs, and error messages are all important components for making your APIs understandable, and easily implementable. Let's say we have an endpoint at /puppies that returns a collection of puppies with their date of birth in the format of month, date, and year, like so. Later on, we realize that we can also include the information of the time of birth for each puppy. But we must change the format of the date of birth like so. How do we add this feature without causing problems for users already using our endpoint? Versioning allows you to make new functionalities without breaking features for users still using older implementations. If your application renders webpages and has API endpoints, specifying the API in your URIs is also helpful for users. Another method of implementing versioning is by including the version number in your HTTP header. GitHub implements versioning this way. Whichever method you choose, versioning is an important consideration for your users as your application grows and changes. Being able to reach out to your developers is an invaluable asset to having a popular API. Having blogs and forums allow back and forth communications between client side and server side developers, creating a community around your product. Publishing content via social media and having code available on GitHub is also a great way to accumulate followers and evangelists for your product. And even when things go wrong, developers respect a company that doesn't go into hiding, but rather, openly communicates major bugs and outages, so that they can respond quickly and accordingly. So, as you're making your own APIs, make sure there's still a component for human communication in order to better support your users. Some of these features presented in this lesson may be a bit advanced for your first API, but are definitely things to keep in mind when you're ready to take your next application public. But one of the best pieces of advice I've heard in regards to making developer friendly APIs is to learn from the best. Check out the in point design and documentation from providers you like. Or popular among the large developer communities. Figure ou the things they are doing right. And try to figure out the ways to implement those good practices in your own applications. It's now time to put all of the pieces together. The final project is intended to be a challenge, but you have all the tools and practice necessary for completing it. In the next node, you'll find an outline describing the requirements for your final project and a list of helpful resources. Please read through this carefully before you begin. It's now time to put all of the pieces together. The final project is intended to be a challenge, but you have all the tools and practice necessary for completing it. In the next node, you'll find an outline describing the requirements for your final project and a list of helpful resources. Please read through this carefully before you begin. Congratulations, you've reached the end of this course. Having the fundamentals of API design under your belt is a crucial skill of any backend or full stack web developer. I encourage you to delve deeper into API design by joining active community groups and pushing yourself to take on more and more complex web API projects.