In this first final exam problem, we were tasked with writing the Lexar for a new programming language. There are seven types of tokens, and four of which are simple operators. We have plus, minus, times and divide. So, here I've written the token rule for the plus operator. The first line is a regular expression that matches the plus symbol. And then we return the token unchanged. And for the rest of the operators, we're going to follow that same format. We're just going to change the name of the function and we're going to change the symbol to which it matches. Our next token is the identifier. In our programming language, this will be the names that we have for things. So it can be something like. My _variable or something even more interesting like just the word Andy. More precisely, in our program language, an identifier is a non-empty sequence of letters and underscores, where the first character is not an underscore. So, we can write our rule for that pretty simply. Here I have a function, t_IDENT. And the regular expression is pretty simple. The first character, and it has to be at least one character because it's a non-empty string, it's just going to be some letter. And then we're going to be followed by zero or more letters or underscores. So strings in this language are very similar to strings in Python. We can have single or double quotes, but in this particular language, for which we are designing our Lexar, we don't have any escape sequences. This actually makes the expression to match the strings much simpler. So, the first rule I'm writing is just for single quoted strings. The rule for double quoted strings is going to be very similar. It's just that the right of expression to which we are matching is going to be slightly different. When I go over the code at the end and I show you the finished product, I'll show you what that looks like. But for now let's just concentrate on single quotas strings. Here I require that the string begins and ends with a single quote and is a sequence of zero or more, kind of an empty string, characters that aren't the single quote. Since we don't have escape characters that's all we need. So here I'm taking out the quotes from the beginning and end of the string, that way the value of this token is the string itself. And I'm setting the type to string. All caps. Numbers in this language are a little bit different than Python. First off, the only numbers we have are positive integers. So negative 5, and 5.5 are both not valid numbers in this language. So, one example of a good one would be 5, we're also allowed to put underscores anywhere in the number, as long as it's not the first character in the number. So, 5_5 _ _ _ is going to be equivalent to just 55. A lot of languages actually have this feature because it's easier to read 1, 2, 3, _, 4, 5, 6. Similar to how we often put a 123,456. So here I've started writing out the token rule for numbers in this language. The first character has to be a digit, zero thru nine. And afterwards we can have zero or more digits or underscores. Now we want the value of the number token to be the number, the integer, that it represents. However if we just return the string, or try to call some. Integer conversion on it, we're just going to get a lot of underscores and it's not really going to work and it's not what we want. We want to take 5_5_ _ _ and just get 55. So, my strategy is going to be to go through each character in our string, append any digits to a new string, ignore any underscores. And once I'm done call ent onto that string, to get the integer that the original token represented. So, here I have the finished function. I want to go through each character like I planned. If it's not an underscore I'm going to append it onto our temp string and then call ent on that temp string to get the new value. And here I have the finished code. We have our basic operators, plus, minus, times, and divide, the identifier function we wrote, single and double strings, [UNKNOWN] the only difference here is that we have single quotes right here, double quotes right there. And lastly, the number token function that we wrote. In the first problem of the exam, we wrote a lexer for a new programming language. In the second problem, we're going to write a parser that will create an abstract syntax tree for something similar to the listening tuples that we find in pie-pon. We're only going to consider numbers, but we are going to recognize the difference between a list that has brackets and a tuple that has parentheses. So in our parser, we have expressions. And let's say an expression can be a number, a list of expressions and lastly a tuple of expressions. So let's start off with numbers. Here's our parsing rule for the number expression. We simply take in the number and put it in tuple where the first element is the type following our convention in our web browser, and our second element is going to be the value. So, here I've written up the function for Tuple expressions. We have a left parenthesis, this new thing, called expcomma and then a right parenthesis. So basically a tuple surrounded by parentheses. Here, I haven't defined this yet. And what this is going to be is going to be a sequence of expressions where there is a comma separating each expression. We'll define that last and we'll also be using it in the list expression. Here, I have a special rule that takes care of the case, just a single expressions surrounded by parentheses. In reality, we want our language to take this as just an expression, which is what happens in python. In python, if you wanted to make this a tuple, a tuple of one element, you have to add a comma. Otherwise, we're going to set this element in our abstract syndextry to be a tuple, where the first element is the string tuple, followed by the value. Here's my function for the list expression. It's a going to be expcomma, which is. That construct right up here surrounded by brackets. And we don't have the special case that we had right here because we want our language to have singleton less. So we want the character a, or, I guess since we have just numbers, five, to be an out list. This is not the same idea as doing. Five surrounded by parentheses, we want that just to be five. So we have the basics here, let's just go to the code to finish it up. So here we have the problem description. And I've filled in the solution. We have the number expressions, the tuple and the list which are unchanged from what I did. But I've also added the expression comma where an expression comma is an expression, a comma. Followed by an expression comma, where an expression comma can also be just an expression. So far in this final exam we've written a lexer, a parser and now in this problem we're going to write an interpreter. However, we're mixing it up a bit and we're not going to write an interpreter for a programming language per se, but rather for a market. We're going to be given a list of how much money people have, things that they want to buy, and things they're willing to sell. And we're going to simulate the market and the result is going to be the amount of money that people have left over. So let's take a look at an example input into our interpreter. So here I have our abstract syntax tree for our market. At the beginning we declare how much money Klaus and Andreas, are two participants in the marketplace, have. And then we talk about what are they willing to buy and sell. Within each element, we generally say, who is the person that this element applies to. The what, this element is dealing with, and then some amount of money. So for the has elements, we're saying Klaus has 100 coins. And we're saying Andreas has 50 coins. Down here we're saying Klaus wants to buy a sheep for 50. He also wants to buy another sheep for 50, you can have more than 1. Andreas wants to sell a sheep for 50, and he wants to sell another sheep for 50. So Klaus wants to buy two sheep, each for 50. Andreas wants to sell two sheep, each for 50. We should probably be able to make a deal here. Note that after the has elements, the buys and sells can be in any order. So let's step through this by hand and see if we can come up with an algorithm for which to write our interpreter. So here we're saying Klaus has 100 coins. We should probably keep track of that since the output of the entire interpretation is going to be a list, of how much money each person has. Or actually, we're going to store it as a dictionary, but, so let's do that. I just wrote Klaus for short. So, we say Klaus has 100, okay. We are done with this, we don't need it anymore. This next line says Andreas has 50, so let's update our dictionary. All right, we're done with this. Now that we see Klaus wants to buy a sheep for 50. Let's see if anyone is willing to sell a sheep. So, let's go through the rest of them one by one. So we, in this next line it's about Klaus buying. We don't really care about buying, we're looking for selling. Okay, here we have a sell, it happens to be for a sheep, and it also happens to be for the exact amount that we want. So, these three elements match perfectly for what we're looking for. One more thing that we have to check is to make sure that Klaus has at least 50 coins to make the transaction. So, we look up here, Klaus has 100, that's more than 50, he's able to afford it. So, now we do the transaction, Klaus now only has 50 and Andreas now has 100. We should cross off the elements that we used. Now let's continue the process from the top again. So, we only have two things left. So, the next one is Klaus wants to buy a sheep for 50. We do the same look up, go to the next element, see sell sheep 50. Yay. Klaus has at least 50, we're all good. Let's make the transaction. Okay. We've gone through everything in our parse tree. There's nothing left to do because there's nothing left. So, our output is just going to be this dictionary. So, we went through that algorithm, it's pretty straightforward, it's a matter of just stepping through what is available, and doing what we can until there's nothing left. So, now you're probably thinking, where's the code? Well, let me show you. So here I have the solution. It may look a bit messy, but it's actually pretty straightforward. The first thing we do, is declare the dictionary that we store how much money that each person has. And the basic strategy like I went over is to continue going through elements in the parse tree until there's nothing left to do, until we didn't do anything and so nothing's changed and we should just stop. In the case of the example that I went over, that just meant that we were out of elements, but it could also be the case that no one can afford to buy anything, so we should just stop. So let's assume that there's nothing left to do, and then only change it once we do something. We're going to go through each element in our abstract syntax tree. We're going to pull out who is involved in the element. That's always the zero index, the first element in the tuple. We're going to do what kind of type it is, okay. If it's a has. So those are going to go first. We're going to put that person in our environment. And then what I'm doing right here, is we're just marking off it as skip. We're changing the type to skip. Skip isn't has, buy or sell, so we're just going to ignore it. This is equivalent to me crossing it off. An alternative way of doing a similar process would be, to recursing onto the parse tree and removing parse tree elements, as we use them. But this is, just as easy. If we're in a buy scenario, if we find an element for which we want to buy, we're going to take out what we want to buy and how much it's for. And then we're going to go through the abstract syntax tree again. If we find an element in the abstract syntax tree that is a sell, it's what we're looking for. I can afford it for that price, and it's the price that I want to pay for it. We're going to do the transaction. This involves skipping, crossing off. Both elements in the parse tree that are involved in the transaction. Subtracting off the new cost, and adding that amount of money to the person that sold it. And we're also here putting finished equals false, because we did something. The state has changed and we should do another pass. And once we're done, we just return the dictionary that we started with. Here we have a gruesome problem. Although the title is a bit menacing, all we're really going to do is color words. Sounds like fun. So, we're going to use two colors to start out with, blue and green. Now, we say a word is blue if a lower case b occurs before a lower case t within the word. We say a word is green if a lower case g occurs after the occurrence of a lower case t. Within the word. So an example of a blue word would be wombat, because we have a lowercase b, occurring before lowercase t. As an example of a green word, we have racketeering, because g occurs after the current lowercase t. As one last example, we have the word abating, which is blue, because b occurs before t. And green because g occurs after t. So, yes, one word can be both blue and green. And, lastly, we just find a new color. I will call is grue. It may look like some purplish-pink. But, it's a brand new color that you've never seen before because I say so. I word is grue if it's blue or green. And it can be both blue and green and still be grue. So all three of the words I used here are grue. So those are our gruesome words and we've been asked to identify all the grue words within a given string. And we're going to use our regular expressions skills to do that. So what is a regular expression going to look like? My basic strategy is going to write it like this. Where I'm going to define what a blue word is like and a green word is like and match both words using the regular expression or operator. So first let's look at blue. Here I have the regex for blue words. We have zero more characters followed by a lower case b. And in between the B and the T can be zero more characters, and after the B and the T can be zero more characters. We're going to do the same thing with green. Here I have a T and a G with zero more characters before and after and in between. So, here I have a solution to the problem. I import the regular expression library, and then I just use re dot find all, with the completed regular expression. First we identify. Blue words and then afterwards we do the green words and we just feed in the string that we passed into the function. In this final exam problem, we are given a regular language in the form of a non-deterministic finite state machine, and we want to construct another non-deterministic finite state machine that accepts exactly the same strings, but backwards. So, let's say we have this regular expression that accepts strings that begin with an a and end with a c and in between, have one or more occurrences of bx and by. An example string that that regular expression matches looks like this. a, bx, bx, by, and c. So we do a, bx, by, and then c. So here I have a finite state machine representation of that regular expression. We start with an a, we require at least one bx or by. And then we can repeat the bx and by afterwards as many times as we want, and we finish with a c. Remembe,r the finite state machine we want to generate will have to accept strings like this, where we begin with a c, we then have yb, xb, xb, and then a. Our strategy for doing that is going to be basically reversing all of the edges. In this finite state machine, to go the other direction, and finishing it off by changing the start state with the accepting state. Okay, so the first thing I'm going to do is change the start state and the accepting state. So now we start at 6, and finish at 1, and now I'm going to change all of the arrows. And we're done. If you look closely, you'll see that this finite state machine. Matches exactly the same set as the original one, finite state machine, but backwards. So, let's apply that same methodology to coding our solution. So, I've started coding the solution, and the first thing I do is create a dictionary to contain the reversed edges, and I switch the start and accepting states. Now I'm going to go through each of the original edges, and right here on these three lines, I'm just extracting the data from the original edge and the original finite state machine to make it easier to manipulate later. So, for this edge in the original finance state machine I'm looking at, I'm going to go through each of its destinations, so that I'm going to create an edge that goes the other direction. And because the way we structure a data structure. I'm going to have to do it in kind of a continuing fashion. I can't just finish the edge. I have to look at every edge in the original one before I can be certain that I've finished the edge in the new finite state machine. So this line of code sees if we've already created the beginning of this edge, and that's going to overwrite the empty list we had before. And either way, we're gong to set the new state of this edge in the new finite state machine to be the concatenation of the before list with the added state we got from this iteration. And once we're done going through the original finite state machine, we just return the result. In this problem, we're going to not repeat, repeated work, by implementing a relatively simple optimization technique. In this optimization, more commonly known as Common Expression Elimination, let's say we're given this snippet of code. If we look closely, we can see that the values of a, b and c. Don't change, yet we re-compute it when we calculate z. So, we're doing two additional, addition operations that we need to, It's perfectly possible to replace that sub-expression with the variable x. That way, we can take advantage of the fact that we calculated x, and avoid the additional work. Keep in mind that optimization was only possible because the values of a, b and c hadn't changed since the last time we used it. Here I've changed the middle statement to be b equals 2. That means that if I did the same optimization where I replaced this. With X, it's very much possible that X doesn't actually equal a, b and c added together. So our strategy for solving this is is going to be very similar to what you would do by hand. We're going to go through each statement one by one and in this scenario, let's say we're going to remember that we've already calculated the values of a plus b plus c and that happens to be stored in X. That way if we see a request. For a plus b plus c, we can simply replace it with x. However, at each step we also need to keep track of what values have changed. Here we can see that b equals 2 now invalidates a plus b plus c, because we used the value of b there. Let's get started. Code time. So here I have the code for a solution. The first thing we have here is a helper function. That returns a list of all of the variables used in an expression. That way we can feed it a plus b plus c, it'll return a, b and c in a list. That way, it makes it much easier to check if new statements invalidate a cached response. So here we have our optimize function that takes in the abstract syntax tree. First thing we do is declare our empty data structures. First thing is the dictionary that has the saved calculations. And then we have the resulting. Optimized abstract syntax tree that starts out empty. So we're going to go through each statement in our abstract syntax tree. And extract a little bit of info from that statement to make it easier to reason about and write the code. The first thing we do in this loop is to check if the right hand side of this. Statement has already been computed. And we have a version of that right hand side, that doesn't have any values that have been changed. That means that we can use it. If that's the case, we are going to create our new statement. With the simplified right hand side. Otherwise we're going to remove. The saved expression calculations that use variables that we modify in this statement, and then we're going to update our available dictionary of safe calculations. And before we're done with the loop, we're going to add this new statement onto our abstract syntax tree, and once we're done with everything, we're going to return the result. In this problem we've been tasked with finding a bug. Sounds pretty straightforward, and we've done this before, but this time we're mixing it up a bit, and not giving you access to the source code. We didn't really give you too much guidance on how to do this, but, believe it or not, this is actually a pretty common thing you're going to have to do in the real world. Having access to the source code, or the implementation itself, is often more rare than it is common. Plus, sometimes even with the source code, it can be so unfamiliar or poorly documented that it's, might as well not be having it all. With that said, let's look at the problem. So here we have the code to test the problem and below we have the give and test case. Now e told you somewhere in here lies the bug. One way to narrow it down, was to look at each of these hypotheses and then test them one by one. I'm going to show you a quick test case that gets right to the bug. Here, I've inserted the code from homework six, debugging environments and when I run that code, I see the same bug that we saw in homework six. This implies, and you can further verify on your own, the problem is right here, where we're not passing in the right function environment when we're executing a function. So, bug equals seven is the answer and just in case you're curious, here's the source code for the expression evaluation, and if we look at call, we'll see that the environment that we call the function on is the same environment from which its called and not from which the function was defined. In this problem, we're given an input string and the parse chart that was created from parsing that string. And we're tasked with finding the grammar on which that token was parsed. So let's look at the problem. Here we have the given string, and here we have the parse chart. Our strategy is going to go through each line of the parse chart and look through the rules that explicitly appear for the first time. Say, this one right here that indicates E goes to parenthesis E parenthesis, is explicitly in the grammar. Add those to the grammar. Run the parsing algorithm. And then we're going to see if using that grammar on this token generates this exact parse chart. So let's get started. Looking at chart state zero, we see six rules right here. Each of these six rules has to be in the grammar because no tokens have been read, and we're at the beginning of each of them. So let's add those to the grammar. Okay, here's the six rules we were given in the first state of the parsing chart. And if we run this through our parser, we'll see the chart that it generates is not exactly the same. So we're missing something. Let's keep going. Here, we have the continuation of five rules. And if you look closely, there are no new rules here. These are all just shifts of the rules that we found in chart state zero. The minus comes from the minus, the plus comes form the plus, and so on. So let's move on to chart two. Here we go. A goes to nothing, that's new. A goes to NA, also new. And lastly, we have the two rule, two rules for NA. So let's put that into our grammar. If we run this grammar in our parser with that token, we'll see that we get the same exact chart that we were given, meaning that we found the answer. Throughout the course, we repeatedly mention that regular expression libraries simply use finite state machines underneath. So, in this last problem, we've asked you to implement the lexer, parser and interpreter for a basic regular expression library. So, given a regular expression as a string, you need to generate a non-deterministic finite state machine. That accepts the same exact strings as that regular expression. So, this is going to be a lot of code, and I'm not going to go through it line by line. But I'll give you an overview for one way to solve it. So, here I have a solution. Here's our five types of tokens, and four of which are defined right here and the letter is defined in the regular expression. Then we have our typical ignore and error rules. And here we have the precedence ordering for regular expressions, and then our parse rules. These should all look pretty straightforward, although you could have organized your abstract syntax tree any way you wanted. And here's the core of the solution, and that is the interpreter. We have, basically, three helper functions. To help us generate a non-deterministic finite state machine out of our abstract syntax tree that came out of our parser. We have one that adds edges to the finite state machine, one that creates new states, and the last one that walks the abstract syntax tree. So, if we see a letter on its own, that means we're going to have to take a transition to the next state. If we have two entities concatenated, we're going to have to go from the current state we're at to some middle state, and then lastly, to the goal state. We have a bar, that means we're going to go two possible directions in our finite state machine. And a star is going to loop back on itself. In our function that does all the magic, lex is the input, takes out the parse tree using our parser, and then interprets the parse tree, returning the finite state machine that resulted. [Wes:] Welcome to Programming Languages. I'm Wes Weimer. Together we're going to learn the theory and practice of programming languages, culminating in the construction of a web browser. Our web browser will accept as input HTML and JavaScript, the primary languages of the web, and use that to produce an image of the web page. You may already be familiar with HTML, which describes the basics of web pages. We'll certainly go over it in this course later on, but you may be a less familiar with JavaScript, which allows one to describe computations that take place on web pages. This gives us a lot of power and also a lot of flashy graphics. Let's see some examples. This particular webpage, chosen more or less at random, uses JavaScript to animate these tabs for its title bar at the top. This is a second example of a webpage that uses JavaScript, both here at the top for this sort of floating tool tip, but also down here at the bottom to animate the differences between these textual boxes. If we look at the source for one of these webpages, we can see that it contains both HTML and JavaScript right from the start. Let me give you a brief overview, in pictures more or less, of how this course and the overarching project will go. We start with the source to a webpage, which is in HTML and JavaScript. Our next main step is to break that source into important words, just like we could break and English sentence into important words. Then we'll understand the structure of the words that we found. For example, focusing on this part down here, it may be easier to understand 1 plus 2 plus 3 as a tree, showing all of the computations. Then finally we'll figure out the meaning of that structure. For example, in this case maybe all of that adds up to 6, and that's what we'll display in our resulting webpage. Building a web browser will be a lot of fun, but the overall goal of this course is not actually to build a production quality browser, but instead to use the goal of building a browser as a way of structuring our exploration of computer science. Let's get started right here in step 1. Hi, I'm Peter Chapman. Last semester I TA'd for CS101 where we built the search engine. This time around, we're going to build a web browser using the power of programming languages in CS262. When I'm not working on my start-up search engine, searchwithpeter.info-- you should check it out--I'm going to be helping you with homework answers and answering questions in the forums, so I'll see you in class. [Wes] Ok, I'm here at Mozilla, which is responsible for the Open Source Firefox web browser. And it's also where we find Brendan Eich, the designer of JavaScript. Let's go in to learn more about that language. So in this class we handle a very restricted subset of JavaScript. For example, we don't pay very much attention, or any attention to the Document Object Model. One question that one might have is: how really useful is to focus on a subset of Javascript or HTML. Can the skills that we'll learn in making a lexer, a parser, an interpreter for a smaller language carry over for important tasks in the real world. [Brendan]The answer is yes. Mozilla and other working browser in the Web often are doing with a subset of JavaScript. There is a subset, not quite a subset, called JSON that is quite popular, for describing trees of data. And it turns out that we want to parse JSON very quickly in order to have Javascript to "eval()". So, in our implementation we actually do a very quick subset's parse in the middle of line for JSON, because that's such a common case. And if we can parse this JSON, which is asubset, JavaScript would be much more efficient. I also observed a lot of JavaScript libraries, that have almost 'query' in their name, are doing a sort of compiled generated functions that are optimized to match certain queries against the Document Object Model. And so there's co-generation going on. There are some partial evaluations going on, there is a subset of the language been used to construct simple matches and rules, for matching trees. We want to break up strings like the source to a webpage into important words, and we're going to use Python to do it. We're given as input part of a webpage like this-- "Hello 1" with some syntax over here on the left that we'll get to in a bit. One approach to breaking this up would be to use Python's string.find function to find this space and then split up the string into everything to the right of the space and everything to the left of the space. You may already be familiar with Python's string.find function from previous experience with computer science. But if you're not, it's often described as finding a needle in a haystack. For example, let's say that I want to find the "fun" in "Mifune Toshiro." This is our needle, and we're going to look for the first copy of it we can find over here in the haystack string on the left, and there is some "fun" hidden in there. The answer we get back will be the string index of the beginning of the fun, which for us is 2. You may be wondering why this is 2 and not some other value like, say, 7. Remember that Python strings--and, in fact, almost all Python collections start counting at zero. The "m" is at position zero, the "i" is at position 1, and the "f" is at position 2, and that's where the fun starts. Toshiro Mifune is a Japanese actor, and one of his most famous roles is the bandit in Rashamon. Well, we found the fun, so snap, the rest of the job's a game. Let's see a few more examples of this. We want to find a space in "Hello world," and there's one right here-- position 0, 1, 2, 3, 4, 5. Our final answer is 5. You can also find a starting position. Here, if we're trying to find 1 in "1 + 1 = 2," the first occurrence can be found at position 0, but if we only start around position 2, then the answer we get will be 4. If the needle you're looking for does occur in your big base string Python returns negative 1, which is out of range for the string, to indicate as much. Let's review and test your knowledge of string.find with a quiz. In this class, quizzes are for your benefit. They check your understanding. They don't count for your grade in any way. They are not meant to be stressful, and you can try them as many times as you like until you get the right answer. Here I've written two Python expressions-- "Ada Lovelace" dot find space. Let's say we're trying to break this up into words. And "Alan Turing" dot find "n" starting at 4. I'd like you to fill in each blank with the answer we would get from the Python interpreter. You can use Python if you'd like to get a better feel for how this is going to turn out, but you can also just try to solve it on your own by thinking hard about the structure of the problem. Let's go through the answers together. We're looking for a space in "Ada Lovelace", and there is a space right here. This "a" is at position 0, "d" is at position 1, "a" is at position 2. So this space is at position 3. Now we're looking for an "n" in "Alan Turing", and there are two. The first one is at position 3, but here we're asked to start from position 4, so the one we'll get is this last "n" at position 9. Ada Lovelace is widely regarded as the first computer programmer. In fact, she wrote the first computer program for computing some mathematics before computers themselves even really existed. They were just plans or blueprints. Similarly, Alan Turing is often regarded as one of the leaders or founders of computer science. The Nobel Prize in computer science is called the Turing Award. Now we know how to find positions, sometimes called "indices," in strings. What we want to do is chop up those strings into substrings. Once I know where the spaces are, I can start splitting a sentence into words. The Python syntax for this is to put square brackets after the string, and the interpretation is "I want to get this substring that starts at this first number and goes up to, but not including, this last number. Here if I'm starting at 1 and going up to but not including 2, I'll get the "e" and the "l", and that's exactly what we'd get in Python. You can also leave out one of these numbers specifiers. Leaving it blank means go as far as possible in that direction. Here we're starting at position 1 and going all the way to the right so we get "ello." Now that we know how to find strings and how to chomp them up, let's combine that together and write a Python procedure. Let's say that you're given two strings, each of which itself contains two words separated by a space. These strings might be "bell" space "hooks", "grace" space "hopper", or "alonzo" space "church". I'd like you to write a Python procedure called myfirst_yoursecond that takes two arguments, p and q, and returns true if the first word in p equals the second word in q. For examples, myfirst_yoursecond of "bell hooks" and "curer bell" would return True, because the first word here matches up with the second word there. Submit it via the interpreter. Let's go through a possible answer together. Here I've written out a candidate example. Let's image that "bell hooks" is p and "curer bell" is q. The first thing we're going to do is find the index into p of the first space. Pindex space 0, 1, 2, 3, 4. This'll be 4 in our running example. Qindex--the location of this space in q might be different--0, 1, 2, 3, 4, 5. In fact in our example it is. Now what I want to do is select out the first word in p. I want everything from the beginning all the way up to, but not including, the space. This selection goes to the left as far as it can but does not include pindex, so it will be "bell." I could also have put a 0 in here. That would have been exactly the same. For q I don't want to start at position 5. I actually want to start at position 6, starting with the b and going to the end of the word. This is q's second word, which in our running example is also bell, since bell equals bell, we'll just return True. Curer Bell was actually a pseudonym, a false name, adopted by Charlotte Bronte, an author. Splitting up words by spaces is such a common task in computer science that Python has a built-in function, string.split(), that does just that. For example, suppose we take one of Charlotte Bronte's books as a string and we call split on it. We'll get out a list where each element of the list corresponds to one of the words in this string separated by spaces. This space here leads us directly to this comma, separating these list elements. Let's take a moment now to get a little more practice with this new approach to splitting by whitespace. Whitespace is just a more formal name for some series of spaces or tabs. Here I've written three Python expressions, each one of which is a constant string. We're calling split on it. I'd like you to fill in each box with the number of elements in the list returned by the split expression. You can use the interpreter if you like, but try to reason it out no your own. For the first one, Python is fun, there is a space here and a space there. There will be three elements in the return list--Python, is, and fun. This next one reminds us that split only splits on spaces. We might be tempted to break up July and August, but the split function won't. There are only two elements of the return list--"July-August" and "1842." Finally, down here we might like to break this up into 6 times 9 equals 42, but officially there are no spaces in this string. We'll just get out a singleton list--a list containing one element, the original string. "July-August 1842" is probably within a year of when Ada Lovelace wrote the first computer program for the difference engine or analytic engine at the time. It was to compute some mathematics. Also, if you're not sure why 6 times 9 would be 42--don't panic. But you may want to check out the works of Douglas Adams. Those last two examples--"July-August 1842" and "6*9==42"-- suggest that we need more control over splitting strings, because we might want to split on things other than spaces, like hyphens or punctuation. I'm going to introduce a tool that will help us do just that--a tool called "regular expressions." Suppose we want to find all the numbers in a string. We could make 10 different calls to string.find, look for 1, look for 2, look for 3. We don't know what digit the number begins with, so we might have to try all of these, but that could get really tedious really fast. Instead we're going to use this new technique that I'm just about to teach you--regular expressions. The word regular has special meaning in mathematics and computer science theory, but for now it just means simple strings, and expression is just a concise notation. You may have already seen this in some math classes, but not thought about it in this manner. If I write a mathematical expression, like x is equal to the square root of 4 or 5 is less than x is less than 9, each one of these admits or corresponds to some possible values for x. For example, if x is between 5 and 9 then it could be 6 or 7 or 8. All of those are good. All of those satisfy this mathematical equation. All of these match this mathematical equation. Similarly, we often think of the square root of 4 as being just 2, but actually negative 2 works just as well-- -2 times -2 is 4. These mathematical equations are concise notations for a possibly large set of values, especially if I do something like this. There are a large number of possibilities--51, 51, all the way up to 89-2 and just writing this out took much less room. Just as mathematical expressions are very concise and let us match or describe a large number of integers or numbers, regular expressions are going to be very concise and let us describe a large number of simple strings. Here is our first regular expression. Bracket 1 hypen 3 closed bracket. This is associated with the three strings 1, 2, and 3. Formally we say that a regular expression like this matches or denotes all of these three strings. The basic idea here is there is some symbol on the left and some symbol on the right, and this regular expression matches each one of those plus everything in between. For example, the regular expression 4 hyphen 8 matches 4, 5, 6, 7, 8, and the regular expression A through B matches the string a and the string b. Perhaps surprisingly, regular expressions are very popular and very useful online and in computing in general. Credit cards, phone numbers, addresses, e-mail addresses-- these are all handled by regular expressions on websites you've probably all ready used under the hood. Let me show you a compelling example. Here I have the form from the U.S. State Department for applying for a U.S. passport. Regular expressions are very common when you want to enter structured data or structured strings. For example, over here they regular that your birth date be specified as two digits, two more digits, and four more digits corresponding the month, the day, or the year. By contrast, your place of birth is more likely to include letters rather than numbers. A U.S. social security number involves three numbers, two more numbers, and then four more numbers sometimes separated by a hyphen or a blank. An email address has to have this special @ character in it. Regular expressions can help us do that. Then an American phone number also has some number of digits broken up into various groups. A billing address might have letters and numbers and number signs combined arbitrarily. Regular expressions are going to allow us to make sense of this type of data and also process it when we see it on web pages. Let's practice a bit more with regular expressions. I'm going to write out a bunch of strings, and I want you to check all of them-- there may be multiple--that exactly match 0 through 9, the regular expression. Down here I've written seven strings. Check each one that matches the regular expression 0 through 9. One way to reason about this is just to write out all of the strings that this matches-- 0, 1, 2--all the way up to 9. Ten different 1-digit strings. Zero is certainly in this set, so 0 matches 0 through 9. One matches 0 through 9. Remember the interpretation is everything between and including the beginning up to and including the end. Ten, however, is a 2-letter string. It's too big. This regular expression only matches ten strings that are each 1 letter long. This one doesn't match. Similarly, 11 is just too large. 05 is very tempting, but regular expressions are string equations, not mathematical equations. While 5 and 05 might have the same mathematical meaning, our regular expression, which is concerned with strings, matches this one-letter string "5" but not this two-letter string "05". Then "9"--well, that's right on the border. We totally match it. "Isak Dinesen"--we don't match this for a number of reasons. First, it doesn't contain 0 through 9, and second it's much too long. "Isak Dinesen" was a pseudonym adopted by Karen Dinesen, a Danish author who wrote Out of Africa. Let's imagine that's Africa. These regular expressions sound super cool, and I'm going to show you how to use them in Python programs, but that's going to require one more step. Industrial software is often so big that it doesn't all fit on one page, so people have to break it up into chunks just like a book is broken up into chapters or the body of human knowledge is broken up into many books. In computer science, a module is a repository or a library of code-- functions and data that do useful things. In Python, import brings in a module. It turns out that there is already a bunch of functions related to regular expressions. We won't have to reinvent the wheel. We can just import them into our own Python programs and get their benefits for free. Python's regular expression module is called, imaginatively enough, "re"--regular expressions. At the beginning of a Python program, just write "import space re" and then you'll have access to all of the regular expression functions. I'm going to show them to you in just a minute. If we're going to write down regular expressions in Python, we need to know what they look like. Python regular expressions look just like strings. They start with double quotes or single quotes, and they have contents, except that to separate regular expressions from strings regular expressions begin with a lowercase "r" outside of the double quotes. Up here this is a--zero, one, two, three, four--a five-character string 0 through 9. This one down here that begins with an "r" is a regular expression that matches 10 different one-letter strings. Writing regular expressions is a creative process. You the programmer have to do it. I'm using "creative" here in the same way that people often describe mathematics as elegant. Just as there are many different equations that could get you the number 4-- 2 plus 2, 1 plus 3, 8 divided by 2, absolute value of the square root of 16-- in fact, and infinite number--there are often an infinite number of regular expressions that could serve a purpose. Picking the right one, the small one, the simple one, the concise one, the elegant one, requires creativity. It's a skill. It's something you'll learn in this class. Let's say you've written a regular expression, though--like this one. Now we need to use it. One of the most common functions involving regular expressions is findall. It takes a regular expression and a string and returns a list of all of the substrings that match that regular expression. Here if we're looking for single letter strings that are between 0 and 9, the 1 matches, the plus does not, the 2 matches, the equals does not, the equals does not, and the 3 matches. The return value of re.findall is a list--1, 2, 3--of all of the substrings that match the regular expression. The list could be empty if you didn't actually match anything. This "re" means it comes from the regular expression library. We really need that import statement at the beginning for this to work. In this example, I'm using the same haystack string--"1+2==3"-- but I'm using a different regular expression. This one only matches two single-letter strings. We'll get out 1 and 2. These two match. The 3 does not, because it's not between 1 and 2. It's not specified or matched by this regular expression. This last example is a little more tricky. We're looking for the letters a through c, but if you look carefully, these are the lowercase letters a and c. So even though this "B" is very tempting--this capital "B" in "Barbara," it's not between lowercase a and lowercase c. We'll match this a, b, a, a, and then there's nothing over here in "Liskov." Barbara Liskov is a well-known computer scientist, famous for her work in object-oriented programming and systems programming. Among other things she invented the language Clu, which I'm showing here with a bit of a magnifying lens. She received the Turing Award--the highest honor is computer science. Let's make sure we're all on the same page about these simple regular expressions and the "findall" function in Python that allows us to manipulate them. I've written out three Python expressions involving re.findall that returns a list of substrings that match the given regular expression. What I'd like you to do is for each of those lists write out the elements in the list in the correct order. Fill in the boxes with the elements of the return values of the findall expressions. We're looking for single letter strings, 0 through 9, in Mir Taqi 1723-- nothing, nothing, yes, yes, yes, yes. This 1, 7, 2, and 3 are four separate one-letter strings. Over here we're looking for capital letters A through Z in Mir Dard 1721. This capital M matches. These are lowercase, so they don't. Capital D does. M. D. Down here we're looking for 0 through 9 in 11 minus 7 equals 4--1, 1, 7, 4. Mir Taqi and Mir Dard are often regarded as two of the four pillars of Urdu poetry. Check it out if you get the chance. [Wes]So I'm very happy to be here at Mozilla with Brendan Eich, the CTO of Mozilla, and the designer of JavaScript. So u could tell us how that language came to be. [Brendan] Sure. So I can say more about how I got ready to make JavaScript. It was when I wrote Netscape. I didn't have much time to do that, and I had to have the skills already. And I've been just seated writing programming language implementations for my entire carreer. When I got into Computer Science it was for Physics. First studying theory of formal languages and automata theory. Regular languages, regular expressions. This was the early 80ties and I loved the cleverness of the theory and rather direct way of implementing theories as algorithms. So you can make a parser or a lexer , semi-automatically or automatically. It was strange to me, and it was useful too. I think every practicer in programs should take some time to invent a language at some point. There's often a need you have that no typical language is perfect for, or you have some leasure time and you can use that. It's educational and can often solve your problem in a better way than any other language. And so, I encourage that. I did that myself and there is something that helped me to get ready to write JavaScript because when I got into Netscape and the heat of the moment was there, with Java looming. Questions about if we needed two languages: a scripting language versus a big language as Java. I had to go fast. I had to have all sort... in my muscles I had to have some practice already on the way. [Wes] So in this class we will learn a lot of the things he have just mentioned. in various points. Regular Expressions, Finite State Machines, adding a lexer that follows them automatically, Context Free grammars, parsing, having a parser thet flow through automatically. And I can only say that I really agree: I have written a number of little languages in my time to scratch various hitchies. I think it's a very important tool to have under ones' belt. Now that we've mastered single character regular expressions, let's look into gluing them together. We're going to need to find important bits of punctuation like slash greater than or equals equals, to reason about JavaScript and HTML and thus write our web browser. Thus we really need the ability to concatenate or put right next to each other in repeat regular expressions. Well, with regular expressions that's actually as simple as just writing, two regular expressions right next to each other. This matches the string a1, a2, b1, b2, c1, and c2--six strings in all. In each one, the first letter comes in the first regular expression, and the second letters, 1 or 2, matches the second part of the regular expression. We've concatenated a through c and 1 through 2 together to match more complicated strings. You may have noticed that we suddenly had quite a few strings from a relatively small regular expression. In fact, if we 0 through 9 next to 0 through 9, there are a huge number of strings that we would match--100 in total. Just as this matches 10 and this matches 10 when you put them together, you match 10-squared strings. So let's look for a two-digit number in the string July 28, 1921. Here is a two-digit number, here is a two-digit number, and here is another one. We'll end up getting 28, 18, and 21. Now I'm looking for two-digit numbers in 12345--12 is a two-digit number, 34 is a two-digit number, but 5 actually does not qualify. This regular expression requires that both subparts be matched. July 28, 1821 is a good day for Peruvian Independence. Let's brush up on matching these compound regular expressions. Down here I've written a Python fragment or Python program involving re.findall. We're looking for a through z followed by 0 through 9 in this artificially constructed string designed to be a bit tricky--a1 space 2b space cc3 space 44d. I'm going to write out a bunch of possible answers, and I want you to tell me-- check all that apply which of the following are elements of the return value of this expression. Here I've written nine possibilities. Check each one that's a member of the list that's return by this Python expression. For one of these things to be in the return value, two things have to be true. First, it has to actually match this regular expression. Second, it has to be in this string. So a1 does match this regular expression. We're looking for things like a1, a2, b1, b2, c1, etc. There's actually an a1 in this string. So, yes. 2b does not match this regular expression. For this particular regular expression, the first letter always has to be a letter and not a digit. This doesn't work out. b2 looks very promising. It's one of the strings we would match, except that it's not actually found in our haystack string. It can't be part of the return value. cc doesn't match, because we're looking for things like a1, b1, c1 that have a digit in the second position. This is not a digit. cc3 does not match because it's three characters long and we're looking for strings that are two characters long. 44 doesn't match, because it doesn't start with a through z. d4 looks very good. It's the sort of thing we would match from this regular expression, but it's not actually in our haystack string. Instead we have 44d. The empty string--this was a bit of a ringer or distracter thrown in-- doesn't match our regular expression. It's too short. It's zero characters long, and we're matching things that are two characters long. But finally c3 matches our regular expression and it's present in the string, so yes. All right. I'm here at Mozilla with Steve Fink, who has worked on regular expressions and languages and parsing, just-in-time transformation and optimizations for Mozilla and other opensource projects. I was wondering are there any times where you've used regular expressions in the real world? [Steve Fink:] Yeah. Just yesterday I was at the grocery store, and I could not find the sugar shelf. Sorry, that was a dream. Let's cancel that. So we have been having a problem recently on the Firefox browser where we get periodic stalls. Often this is some event that happened-- a key press, a timer fires off, something like that. We take 100 milleseconds or something to service it. I pulled out my standard tools, which are Perl, regular expressions, and I wrote a little script. It's like one regular expression to identify that this is a class declaration and another one to find what an error is from, another one to find a run method, which has to exist on all these, which just gives me a good place to stick my code in. And it kind of worked. That's one example where I've done this. I tend to do this fairly often. Excellent. It's time to introduce a new regular expression--plus. This is really handy when we want to match one or more of something. This is a very concise way of listing, actually, an infinite number of possibilities. If I write the regular expression "a" followed by a plus, it matches "a," "aa," "aaa," "aaaa." The plus looks back to the previous regular expression and changes the meaning. Instead of just matching that once, you match it once or more--as many times as you'd like. Here I've shown another example. We're looking for 0 through 1 repeated one or more times. The interpretation here is every time you repeat you can make a different choice. This matches "0" and "1," "00" and "11," but also "01." This required us to pick a 0 the first time and a 1 the second time. That's totally fine with the plus. "1010" is a favorite year of mine. It's about when Murasaksi Shikibu wrote The Tale of Genji. She is often credited with writing the first novel--the first psychological novel, although this is the subject of some dispute. There is a minor bit of ambiguity I need to clear up with this plus. Let's say that we're looking for numbers 0 through 9 plus in the string "13 from 1 in 1776." One possible answer is 13, 1, and 1776, but this plus just means 1 or more. Is there anything that says that I have to match them all at the same time or could I break up 1776 into four different one-letter strings. It turns out that there is a rule in regular expressions called "maximal munch," which says that a regular expression should consume, or eat, or match the biggest string it can and not smaller parts. So we and Python and other people studying regular expressions are going to get this answer: 13, 1, 1776, because 1776 is the maximal munch we can get here for 0 through 9 plus. Don't stop early. Go all the way. All right. Let's get a little more practice with compound regular expression matching, including the plus. Down here I've written a regular expression dot findall expression in Python and a bunch of possible answers. I'd like you to check the ones that could be elements of the return value of this Python expression. We're looking for 0 through 9 followed by--oh, what does this mean? I haven't shown this to you yet. We just have open brackets, a space, and a closed bracket. That means just match space. Then finally 0 through 9 plus. Remember the plus only applies to this last 0 through 9. We're looking for all of these in that torture string I made up earlier. Let's try it out. A good way to get started with such a problem is to write out what sorts of strings are matched. There are things like 1 space 1, 1 space 123, because of this plus, 2 space 456, and so on. One of the things that we notice quickly is that they all have a space, they all start with a single digit, and they don't have any letters in them. Is a1 space 2 part of the possible return value? Well, it would have to match this regular expression and be in the string. It's in the string but it doesn't match this regular expression, because it starts with an "a" and none of our things start with an "a." How about 1 space 2? That looks pretty good. We have 1 space 1, and we could pick a different digit, and it's in the string. It could be a part of our return value. 1 space 2b--it is in the string, but we never have any letters in this regular expression. It doesn't match. 2 space 3--this has the right format. It matches our regular expression. But it's not actually in the haystack string, so it can't be part of the return value. 44--this has the wrong format. We need a space in the middle. 3 space 44--this has the right format, it matches our regular expression, and it actually occurs in the string. Great. 3 space 44d--this has the wrong format. Again, we're not matching any letters. So just these two. We want to do even more with regular expressions, such as matching a word or a number. To do this, we're going to introduce a visual representation for regular expressions that actually shows exactly what's going on behind the scenes, and then we're going to follow along in Python. Suppose we have the regular expression [0 - 9] + % sign. Any character like this that just appears on its own is matched directly, so this catches strings like 30%, 99%, 2% and various other things we might find describing sales or the fat content of milk. Here I've drawn a finite state machine, a visual representation of this regular expression. Often there's an arrow coming out of nowhere on the left that's not connected to the rest of the picture. That indicates where we start. These 3 circles are states. They represent what we're up to when we're matching a string against the regular expression-- what configuration we're in, what our current state of mind is, what we've seen so far. I've labeled my states 1, 2, and 3. These other arrows are called edges or transitions. They tell us when to move from 1 state to another. I start in state 1, and if I see a 0 - 9, I move over to state 2. This 0 - 9 is the label associated with this edge. Finally, you'll notice that 1 of my states has a double circle. That's an accepting state. If we end up in an accepting state at the end of the input, this finite state machine matches the given string. Let's trace through what happens on input 23%. We start in the start state, and the character we see is a 2, so we follow this edge to state 2. Now the next thing we see is a 3, so we follow this edge back to state 2. These are sometimes called self-loops. It's a loop that takes me back to right where I started. Now we see the % sign, and we end up in state 3, which is an accepting state, so our finite state machine accepts this string '23%' just like our regular expression would. Let's try just the string '2'. We start in the start state. We see a 2, so we move over here, and then we're done. We ran out of input, but we're not in an accepting state. Our finite state machine rejects this just like our regular expression would. Finally, let's consider the string '2x'. We start here in state 1. We see a 2, so we go over to state 2. Then we see an x, and there's no outgoing edge from state 2 on an x, so we fall off the finite state machine and die. This is very sad, and when this happens our finite state machine does not accept the string, just like the regular expression would not. Now that we know the basics of finite state machines, let's change them up. Suppose I have this finite state machine from before. It matches a - z, followed by 0 - 9. I want to change it into a new finite state machine that's going to accept [a - z] + [0 - 9]. That is, 1 or more copies of a - z and then exactly 1 copy of 0 - 9. We're going to be able to do it by adding just 1 edge. My questions for you--fill in the blanks-- which state should get the edge by state number, and what's the label for that edge going to be? Well, here's one way to do it. In state 2, I could put another edge for a - z, and now if there's a new input, like abc1, we would start here, a, b, c, 1, and accept. However, there's an alternative answer where we add this edge to state 1, still labeled a - z. Now if we see the abc1, it's a, b, c, 1. Both of these approaches work, and you'll just have to decide which one you like more. This is an instance of creativity. Typically in computer science, we prefer the green solution because the red solution is a little ambiguous. Here in state 1, we have 2 edges going out of state 1, both labeled a - z. That could get a bit confusing. By contrast in the green solution--solution going off of state 2, we don't see as much. We can either transition here on 0 - 9 or transition on a - z, but we have to always know just what to do. Let's explore a bit more in this brave new world of finite state machines. Over here, I've drawn a different finite state machine, again with 3 states. I'm going to draw some possible strings down here, and I want you to check each one that would be accepted by this finite state machine. So in this multiple multiple-choice quiz, mark each one of these that's accepted by this finite state machine. Well, let's go try them out. This "put your finger on the state method" is actually pretty much how you do it. You start here in the start state, and then we see an a, so we move over here. We see a 1. We move over here. We're out of input in an accepting state. This totally works! How about 'aa'? We start in state 1. We see an a. Great! We move to state 2. We see the next a--oh! We fall off the finite state machine and die. No such luck. '2b'--we start here in state 1. We see a 2. We immediately fall off and die. Not very good. The empty string--we start in state 1. We don't go anywhere because we're out of input. But state 1 is not an accepting state, so we don't accept this string. 'cc3'--start here in state 1. We see a c. We go to state 2. We see another c. We fall off. '44d'--we start here in state 1. We see a 4. We fall off immediately. In fact, only 'a1' matched out of all of these. Consider this spiffy, new finite state machine. It accepts both 1 or more letters like word--w-o-r-d--and also 1 or more digits--1, 2, 3. In fact, there's a sense in which it accepts either [a - z]+ or [0 - 9]+. Note its 2 accepting states. Such power! Can we do the same thing with regular expressions? It turns out we can with a new regular expression operator, a nubitive syntax in regular expressions that I'm going to teach you. This vertical bar means I match either the thing on the left or the thing on the right. It's formally called 'disjunction' sometimes, but we can just read it as 'or'. Match [a - z]+ or [0 - 9]+. For example, let's say we want to find all matches of lowercase [a - z]+ or [0 - 9]+ in "Goethe 1749". We'll get both 'oethe' and '1749'. We don't get the capital G because we asked for lowercase letters over here. One of Goethe's most famous works is Faust, in which an old man makes a literal deal with the devil in an incredible surprise move. It does not go particularly well. And in fact, the phrase Faustian bargain has entered the modern English lexicon meaning a deal that you really don't want to make or where you're giving up too much to get something. While we're here, our old friend regular expression [0 - 2] is really just 0/1/2. So I could write out [a - z] as 26 different choices, but that's not very concise. Let's test our knowledge of this notion of disjunction or choice or options in finite state machines. Here I've drawn a potentially familiar finite state machine, and what I'd like you to do is check each box that corresponds to a string that is accepted by this finite state machine exactly and fully. FSM stands for finite state machine. Try it out. Well, it turns out that this finite state machine accepts [a - z]+ or [0 - 9]+, but we don't need to know that to answer the question. We can just start at the start state. We see an 'a'. We end up in state 2, and state 2 is an accepting state, so we accept. The empty string--we come in here in state 1, and we don't go anywhere because we're out of input. State 1 is not an accepting state, so, no. 'Havel 1936' starts with an uppercase H. We actually don't have any outgoing edges on uppercase H, so we fall off immediately and do not accept. Lowercase 'havel 2011'--that's just looking good. h-a-v-e-l, and we're still in state 2, and then we see the 2, and now we fall off because this accepts either words or numbers, but not combinations. Then finally '1993'--1-9-9-3. Yes! Vaclav Havel was a Czech writer/intellectual and the first president of the Czech Republic in 1993. Now let's turn the tables a bit and attack the problem from the other direction. This time, I'd like you to use the interpreter, and you're going to create your own regular expression. Assign to the variable regexp, a common abbreviation for regular expression, a regular expression that matches either the exact string ab--2 letters in ab-- or 1 or more digits. To help clarify this specification, I have 3 positive instances-- you should match ab, 1, and 123-- and 3 negative instances--don't match a alone, don't match abc, and don't match abc 123. Well, here's one possible answer. The regular expression starts with r and then quotes, with either one to match ab. We mentioned before that any character that was left alone is matched exactly or [0 - 9]+. So now we have a way with regular expressions to choose either a or b. Another very common choice is to choose between a or nothing That is, to have a part of a string that's optional. For example, when you're writing out numbers, it's possible to put a negative sign at the begining of a number. But you don't need to, depends on which number your trying to get across. Here I've drawn a finite state machine that accepts numbers with no leading negative sign and numbers with leading negative sign. Lets see how it goes. For something like 1,2,3, we start here. 1,2,3, and we're in state 4, which accepts. For something like -57--negative, 5, 7--we're in state 3, which accepts. But you may have noticed quite a bit of duplication in this finite state machine. These two red areas are the same. It's an edge labeled 0 - 9, an accepting state with a self-loop labeled 0 - 9. And one of the things we really wanted was to be concise. So conceptually, it might be simpler to have an edge that somehow consumes no input. This new finite state machine will still accept 1, 2, 3. Here we start in state 1. I don't consume anything and move to state 2. And then it's 1, 2, 3, and we accept. -57, I take the negative, 5, 7, and then we accept. We have a particular convention for indicating that an edge accepts no input. We use the Greek letter Epsilon. You can either think of Epsilon as meaning "consume no input" when you go across this edge, or you can think of it as referring to "the empty string", at which point you can consume the empty string all you want, but since it's of size 0, it doesn't effect what you're trying to recognize. This idea of using this Greek letter--this is totally arbitrary. This is just an artificial convention. But it's a commonly used one, so it's worth knowing. Continuing our theme that anything that can be done in finite state machines can be done in regular expressions and vice versa--we'll firm that up later on. I'm going to give you a new regular expression--the question mark, which we typically read as optional or the previous thing 0 or 1 times. In that way, it's a lot like plus, which was the previous thing 1 or more times. So I might write a regular expression that accepts numbers that may optionally have a leading negative sign. This negative sign may be present 1 time or 0 times. It can be there or not. We definitely need the [0 - 9]+. And the string we're looking for this needle in is "1861-1941 R. Tagore". And on this particular input, we will find 2 substrings that match. 1861 matches without the leading negative sign, and -1941 matches with the leading negative sign. Rabindranath Tagore is a Nobel Prize winning Bengali poet, perhaps best known for his work, Where the Mind is Without Fear. Just as we can get a lot of use out of + for 1 or more copies, sometimes it's nice to have 0 or more copies. So we'll introduce the star regular expression for that. You can convert between the 2 of them. If you wanted 1 or more copies of a, you could have a, followed by 0 or more copies of a. Some classes or texts will teach the star first and then move on to the plus. We teach the plus first because it's more common for specifying Python and Javascript. So now, the plus, the star, the question mark, the open square brackets, the closed square brackets--they all mean something special in regular expressions. They help us to note sets of strings. What if the string I want to match is actually just a + sign. How do it do it if + means 1 or more copies of what came before? We need some way of saying, "No, no--I really mean it! Actually +, not 1 or more, just +." We're going to solve this by using something called escape sequences, but before I get into them, let's introduce them by way of analogy. In Python, you can declare a string using double quotes or single quotes. So if you want to have a constant string that reads, P & P is Jane's book. If you use single quotes, Python will get confused because you have 1 here, 1 here, and 1 there, and it will think your string ends at the "e" in Jane. No problem, you say? I will just use double quotes.That's what they're there for. But what if you want to include quoted dialogue in your string? So now I want to say, "I said, P & P is Jane's book." So now I'm using both the single quote and the double quote for their actual meanings. What do I put on the side? Well, Python will actually let you bypass this by using triple quotes, but what if I really wanted to have triple quotes in the middle too? We can't do this forever. Well, it turns out that if I just put a backward slash, a backslash, in front of a quote or a double quote or whatnot, Python will treat it as being part of this string and not as being the end of the string. We're escaping out of treating quotes as string delimiters, so this is Python's way of saying, no, no, I really mean it. I actually have a quote there. Now when you actually go to write this down in Python, you may not get different colors or different fonts, so this maybe a little hard to read, but it does work. I can use these escape sequences to literally write down a special character. The backslash is sometimes called an escape character and the 2 of these together are an escape sequence, a sequence of characters that are treated as if it were just the double quotes, just a single quote. Note that Python is throwing away this backslash. You won't actually see it. Just to show you how this sort of thing plays out in Python, I've written down 2 different versions of P & P is Jane's book-- one using double quotes and one using an escape sequence. We're going to print out both of their values and then check to see if they're actually equal. And in fact, they are. Even though we entered them slightly differently, Python treats them both the same internally and indicates that they're equal. Here's 1 more example of this. This time with a double quote being escaped twice. And again, the 2 strings are equal under the hood as Python deals with them. It turns out that we can do the same thing in regular expressions. Suppose you want to find the string '++'. This regular expression "\+\+" has 2 escape sequences, and it finds only the string '++'. So now that you have a large number of tools in your regular expression tool belt. Let's put it together and build a new regular expression. I'd like you to submit via the interpreter. Assign to the variable regexp, a Python regular expression that matches lowercase words-- letters (a - z) or singly-hypenated lowercase words. Let me show you what that means. So we could have just a word like html or a hyphenated word like well-liked. But we don't want doubly-hyphenated words like a-b-c or 2 hypens in a row, just these 2 options. And it's worth noting that it may not be possible to get this perfect yet. Not all problems are solvable. Just do your best. Here's a pretty good answer. We definitely want to match single words and then you can possibly have 1 hypen and then you can have more letters if you like. This regular expression definitely matches well-liked. It also matches html--maybe the h, t, and m will match the first part, and the l will match the second part. It definitely rejects a-b-c and a--b. However, 1 problem with this regular expression is that it does not accept single letter words like "a" or "i". To see why, just look at these 2 plus signs. This requires 1 or more letters here and 1 or more letters there, That's at least 2 letters. We might be tempted to fix it up by making 1 of these a star, but now we mistakenly accept things like just "-a". No letters here, the hypen, and then some more letters-- well, that didn't work. What if I try to make the other one a star? Well, dual problem--now we'll mistakenly accept things like "a-". Well, this is a bit of a challenge. What we really want is for this hypen and the second word to be grouped together, and either they're both there or they're not. It's as if I really want this question mark to apply to both the hyphen and also the [a - z]+. We don't know how to do that yet, but you'll get a chance after we've learned how to fix this up in the homework. So as we saw, this quiz was particularly tricky. It wasn't obvious how to work out the right answer. We're really interested in supporting phone numbers from a bunch of different countries or formats, but we're really only interested in that hyphen if it's followed by more digits. Conceptually, you might think "Wow, I really want to group the hyphen and the digits together and then have either all of them or none of them." We don't know how to do that just yet, but we will in a few more minutes, and then you'll get a chance to show off your mastery in the homework. Let's try our hand at crafting another regular expression. It's a creative activity. It's fun stuff. And this one is designed to be a bit tricky. I'm going to ask you to write a regular expression that matches single-argument mathematical functions. Let me be more specific about that. First, the function name is a lowercase word made up of 1 or more lowercase letters, [a - z]. The function argument should be a number made up of 1 or more digits, [0 - 9]. And there may, optionally, be spaces before and/or after the argument. So here you've got a function name that's lowercase letters--cosign--c-o-s. It has parenthesis, and then it has a single argument that's a number. Here we've got the same thing, but I've got these spaces before and after the argument. These 2 are not matched. This one has a space between the function name and the parenthesis. For this particular exercise, that's not allowed. We're only allowing spaces just before and just after the number. This one is square root of x, but we're looking for functions that have numeric arguments, not word arguments. Submit via the interpreter, a regular expression matching this specification. As a hint, you may find that you have to escape the opening and closing parenthesis to make sure that they're treated correctly. Well, let's go through 1 possible answer together. We're assigning to the variable, regexp, a regular expression. Those start with r and then double quotes. The first thing I want to do is match the function name. That will be [a - z]+. Now I want to match immediately an opening parenthesis. I will escape that opening parenthesis just to make sure that it works. Now I can possibly have spaces or not, so I could have 0 or more spaces, so I'll leave a space and then put a star. The star will refer back to the space, and we can have 0 or more of these. Then there's a numerical argument--1 or more digits-- and then more space, 0 or more, more spaces. I close off the parenthesis, escaping the closed parenthesis just to make sure. Now I'm done, and this regular expression works well in practice. Quoted strings, that is, strings that are surrounded by double quotes, or the like, are a tricky issue that comes up in both JavaScript and HTML. Let's bring all of our regular expression power to bear to see about separating quoted strings from other words. Here I've drawn an evil quoted string that contains a bunch of double quotes. We really want to get to just the heart of it, just the contents and peel off these 2 double quotes at the end. There like the rind. I want to get to the core. However, if I just repeatedly use string.find to look for double quotes, I'll find this one, but also this one in the middle. This one in the middle, and this one in the end. So I might mistakenly think that it's 2 quoted strings-- I said, and nothing over here. Oh no! Find isn't good enough! In a shocking twist, we'll have to use regular expressions instead. But first, to make our job a little easier, let me introduce to you some new regular expressions. The first is the dot, or period, which matches any character except a new line, or what you get when you press enter or return. For example, here I'm looking for any decimal digit [0 - 9] and then any character-- anything except a line break--and then another [0 - 9]. So for example, this is a decimal digit. This is another decimal digit. And the "a" between them is any character. This 2 is a decimal digit. The 2 between them is any character. This 2 is another decimal digit. This "cc3" doesn't qualify because this "c" is not in [0 - 9]. And one more--sometimes it's nice to be able to say anything except a digit or anything except a number or anything except p. Here we're looking for [0 - 9], followed by anything that's not "a" and also not "b". So here--oh! That immediately didn't work because the next thing was an "a", and we're asking for not "a". Right over here we've got a 1 and a space, and space isn't "a" or "b", so that looks good. Then here we've got a 2 and a 2, and this second 2 is not "a" or "b", so that looks good. Here we've got a 2 and a space, and this space is not "a" or "b", so that looks good. "C" is not [0 - 9]. "C" is not [0 - 9], 3 is [0 - 9], but then we're at the end of the string. So that's it. In mathematics, when an expression gets complicated, we can add parenthesis to show structure or grouping--(x - 3) x 5 is different than x - (3 x 5). Python regular expressions have similar parenthesis, but they're written a litttle differently. The closing parenthesis looks just the same, but the opening parenthesis--the version you'll be using in this class--is 3 characters-- (?: ). There's a simple example. This regular expression makes a group around xyz and then this whole thing can be repeated 1 or more times, so some strings are xyz, xyzxyz, and so on. Suppose we want to find words made up of combinations of musical notes. In Western music, the notes are often given names--do, re, mi, fa, so, la, ti-- and you could put them together in various combinations--re, fa, fa--do, do, re-- stuff like that. Let's say we want to recognize words that are made up of these syllables in order, or these syllables not in order but in any combination. So we set out to try it. We can have a bunch of do's or a bunch of re's or a bunch of mi's. Let's say we're looking for all of the matching strings in mimi, rere, midore, doo-wop, and we want to see which ones we get. We'd like to get mimi as 1, rere as another, midore, and then maybe do, just sort of as a corner case, but mostly these 3, but we will be unpleasantly surprised. We would really expect something like mi+ to get mimi. Maximum munch rule, why have you betrayed us? If you look over here, you'll see that actually everyone of these little musical syllables-- 'mi', 'mi', 're', 're', 'mi', 'do', 're'--seem to come out separately. Why? Well, if you think about it, in the regular expression 'mi+", the plus only effects the "i", so really this is getting mi, mii, miii-- an entire virtue of selfishness--rather than the thing that we wanted. You can actually see this over here at the end where do+ got us doo from doo-wop. So here, the + isn't applying to the right thing, isn't binding correctly. This isn't quite the right way to do it. This, however, is. Note our use of the parenthesis in regular expressions-- (?:--marks the beginning of such a group--), and then here in the middle we have do/re/mi. Anything inside this group can be repeated 1 or more times. This gets us just the answer we were looking for. For a more thorough investigation of musical notes and the associated words, I recommend The Sound of Music, but it's also worth pointing out that a very popular computer musical format or interface M-I-D-I--MIDI, the musical instrument digital interface used for recording things like pianos or synthesizers or drum sets, is more or less exactly what we've seen here. Basically, a list of notes and modifiers and combinations over and over again. By contrast, formats like MP3 or other audio compression approaches for recording voice, do not follow this general pattern, or at least they don't look like they do at first blush. Let's put our hard one knowledge of these new regular expressions like any character except new line or set compliment of what we've been talking about to the test. I'd like you to submit via the interpreter, assign to the variable regexp, a Python regular expression that matches double-quoted string literals and--this is the sticker--allows for escaped double quotes. Let me just jump over to the interpreter briefly to show you what I'm talking about, and then we'll come back here. It turns out that there is 1 of those gritty details in this problem that makes life fun, but also complicated the first time. The sorts of strings that I want you to accept are like this one down here. "You say, and then there's a \yes\, I say, no. We've got \no\ and then it ends. This is a well-formed, well-balanced string literal with double quotes and some escaped double quotes. However, to get it to Python, remember that Python is going to treat the escaped sequences, meaning no literally the next thing. But what if you want to literally have a backslash? Then you need to escape the escape sequence. It is turtles all the way down, my friends. So if you want to do some testing on your procedure, here this string 1, this is what you'd have to enter into Python in order to get it to be the sort of string we're looking for. Here I started with single quotes, and then I've double escaped this backslash, then the double quotes, double escape again. Here I've added 2 more, just to make this extra clear. All 3 of these are positive examples--whoops! I'm so wrong! I have forgotten the closing double quote at the end of '"I say, \\"hello.\\"'. This is a negative example. Let's go fix it. There we go. Add in another quote. Now all 3 of these are positive examples of the sorts of strings you'd want to match. You say, yes. I say, no. I do realize that there should be a quote here, but I've intentionally left out the apostrophe in don't, so as not to confuse the issue since we're already talking about quoted strings. So here just to remind you, I've written out a positive example and a negative example. On the left is what you'd have to say to Python and on the right is what it means. And the big hints are that you'll probably want to escape the double quotes and the backslash, just like we did here. You may want to consider having parenthesis nested inside other parenthesis. This one's tricky. Good luck! Let's go through this one in parts. Any regular expression starts with r' or r". I'm going to use the single quotes this time so that I won't have to escape quite as many of these. Then we want to match the blue " here at the beginning, and somewhere way at the end, we'll want to match the closing one, and that will be the end of our regular expression. So now we just have to think of what goes in here in the middle, and this may not be enough room. I may have to erase it and write it again. Now whatever it is, it's going to be 0 or more of something, and as we're going across the string, there's sort of backslashes, which are important, and everything else, which is not so important. So if there's any character that's not a backslash, and here I'm escaping the backslash, we can just read right over it--that's no problem inside of our string-- or you could actually have an escape sequence, like this \". That looks like a literal backslash, followed by anything, and then it's done. So let me just diagram this a little more. Say this opening quote is 1, that matches things like this opening quote in the string. Then in here, we have anything that's not a backslash--that's 2. That's I-space-say-s-a-y-comma, but then eventually we do get to a backslash. Over here, we have a 2-character sequence that's a backslash followed by a dot. These 2 characters--the backslash, followed by the quote--they are 3, and then we're back to matching 2's--h, e, l, l, o, dot. Now we have another backslash and a quote, so these 2 together will be another 3, and then this part at the end is number 4. So I have 0 or more copies of my string body. The elements of my string body are either normal characters or 2-character escape sequences. All of this looks like 3 characters. It's really just 2. I have to escape the backslash. As a minor aside, after the Beatles and Sound of Music examples from above, you may not be surprised to know that a number of English songs of enduring popularity--ABC 123, BINGO--seem to have a regular expression sort of feel. Repetition is very common in songs, and you get the same thing out of it that you get out of a regular expression, a concise notation versus in choruses, but then when you expand it out, it takes a long time to sing. However, there is 1 song that is actually too complicated for regular expressions-- the dreaded 99 Bottles of Beer on the Wall. If you actually want the counting to work out correctly-- 99 to 98 to 97--we can't fit it in a regular expression framework. We'll have to return to that later, and eventually we'll be smart enough to sing this song. For more info on this, Don Knuth, the computer scientist has written an essay on the complexity of songs. Let's zoom back to finite state machines at 88 miles an hour. Here's a finite state machine that corresponds to the regular expression "a+1+". Let's just verify that by tracing out the input, aa1, on this finite state machine. We start in the start state. We haven't seen anything yet. We see the a. We're in state 2. We see the a, self-loop back to state 2. We see the 1. We're in state 3. Oh! State 3 is an accepting state. Ha-za! Surprisingly, this super high-tech sounding "tracing with my finger" approach is actually pretty much exactly what computers do under the hood to check strings against regular expressions or evaluate finite state machines. You really only have to keep track of where you are in the input and which state you're in and not much else. So let's do this together. We'll write a computer program in Python to check to see if a finite state machine accepts a string. So if I somehow give it this finite state machine an aa1 as input, it should say, true. If I instead give it aa1b, it should say false because that string is not accepted. But the first big design decision is, how do we represent this finite state machine? By now, we know how to pass a Python program a number or a string or a list, but how do I pass in a picture? Well, for the states 1, 2, 3, presumably, I could just pass in a list of the states. It's these edges, these arrows that go anywhere. That's what really matters. What we really want to know from an edge is, if I'm in state 1, and the next input is "a", where do I go? So let's use Python dictionaries or maps to do this. I'll make a Python dictionary or map called edges, and I'll just pass in my current state and the input letter, and it will give me the new state at the end. Before we dive into it though, let's have a little refresher on maps and also tuples. You may have seen them before in a previous CS class, but if you haven't, I'll just go over them right now. You make a new map or dictionary in Python using open curly braces and closed curly braces. The purpose of a map is to associate 1 thing with another. For example, here I'm making a map that's going to help me keep track of which things in the world are flowers because I might easily forget this critical knowledge. So I can update my map by saying, oh, 'roses' should map to true in the is_flower dictionary. But 'dog' is not a flower, so that should map to false. Then if I go look it up later, is_flower of 'rose' will return true. There's an alternative notation for specifying a map. Inside the curly braces you use to make a new map, you can actually just put all of the bindings--'rose' maps to true. Colon. 'Dog' maps to false. There's a colon in the center. Now at this point you're probably thinking, what's in a name? Is this word, 'rose' really important, or would a 'rose' by any other name still smell as sweet? Well, we may be able to tell synonyms, but Python cannot. So if I try something like, is_flower 'juliet', that's not defined in this mapping, so we will get some sort of key error element not found exception. For Python dictionaries, you need to get the name exactly right. Dictionaries and mappings are synonyms. They both refer to the same thing. A Python tuple is just an immutable list. Immutable means you cannot change it. Once you make it, it is etched in stone. For example, I can make a tuple to hold the Cartesian coordinates of some object. Maybe my point on the grid is at (1, 5). I can access its elements the same way I would for a list. The 0th part of point is 1. The 1th part of point is 5. And while Cartesian points may not be super exciting, many of you may have done navigation or taken long trips and used GPS coordinates or longitude and latitude. The Taj Mahal is a UNESCO world-heritage site in India. These are its actual GPS coordinates. Go check it out! With all of that in mind, let's encode our finite state machine in Python. Here I've redrawn our finite state machine for "a+1+", and we said before that we were going to make the edges a mapping or a dictionary. Well, one of our edges is at state 1 on 'a.' State 1 on input 'a' goes to state 2. And another one is at state 2 on 'a' stays in state 2. That's our self-loop. If we were on state 2 and we see a 1, we go to state 3. State 3 on 1 stays the same. Let me just highlight one of these. This particular edge from 2 to 3 on 1 corresponds to this entry in our edges mapping. I also need to know which states are the accepting states. Previously, I denoted that by drawing double lines, but again we can't pass a picture into Python, so I'll just make a list of all the things it accepts. Then actually that's it. You'd think we'd need a list of nodes, but you're going to see that we're actually able to finesse it because all the nodes we really care about already appear in this edges listing. So here we are writing our finite state machine simulator, and this is actually super exciting because it previews one of the concepts that we're going to have later in the course--interpreting another program. It's like the junior grade version of it, even this will be a lot of fun. So together, we're going to write a procedure called fsmsim for FSM simulation, finite state machine simulator. You pass in the input string, the start state or the current state, the edges, and the accepting states, and it returns true if that string is accepted by the finite state machine and false otherwise. We'll do it together. Submit via the interpreter--I'll write the first half of this procedure with you. So let's get started on our finite state machine simulation quiz. Here I'm just recopying the edges definition so that we'll have a test input to work with. These 2--the edges and the accepting state--correspond to the regular expression "a+1+", and now we're going to define our procedure, finite state machine simulator given a string, the current state, the edges--these ones up here--and the accepting state. What do we do? Well, one possibility is that we're already at the end of the input, at which point we should just check to see if our current state is an accepting state or not. If we're at the end of the input and we are state 3, then we return true. Otherwise, we should be returning false. If the string isn't empty, then I can get the current letter as the 0th position from the string. And now, here's your part. We know the current input letter we're looking at, the current state we're in, all of the edges are available to us-- you fill out the rest of this code. Here's a hint. Find out if there's a valid edge leaving from this state on this letter. If there is, you should take that edge and keep walking. If there is not, we fall off the end of the finite state machine and die, so you should return false. And the big hint for you is recursion, which is always the hint in computer science because it's the secret of all power and knowledge in the universe. Recursion, use it. Oh, and I can't even spell it! Alright, recursion. You should use it and spell it correctly, unlike me. Alright, let's go through a possible answer together. To see if there's an outgoing edge, we'll just check to see if the tuple (current, letter) is in edges. If so, our destination state can be obtained by just looking up the tuple (current, letter) in edges. We've already processed letter, the 0th element of string, so we want to peel off the 0th character, retaining only the rest of them. For example, if the input was "aaa111", we've used the "a", so now we want it to be just "aa111". Now we just call ourselves recursively, call finite state machine simulation on the remaining string, starting from the destination node, and the edges and accepting states are unchanged. Otherwise, we fall off the finite state machine and return false. Alright. The moment of truth. We want to print out this answer. Oh! Just as we expected, "aaa111" is accepted by this string. What if I try to mix it up and make it something like "a1a1a1"? This should not be accepted by our finite state machine, and it is not. The output changes to false. How about the empty string? Is that accepted? It's not because we're looking for "a+1+" so this should also be false. And it is, but how about the smallest string we do accept, "a1"? That one is accepted. Great! So we can check any finite state machine to see if it accepts a string. You may have noticed as we were going through it, that edges and accepting never change. I defined them once at the beginning of the file. So our finite state machine simulator is really just recursive in the input and the current state, and that matches our intuition because those are the 2 fingers I was using to work it out on paper. So now let's really prove the power of our finite state machine interpreter by showing that we could figure out any finite state machine. You should submit, via the interpreter, values for edges and accepting those 2 key variables that encode the regular expression "q*"-- so the empty string, "q", "qq". For convenience, name your start state 1. Well, let's go through one way to do it together. I find it helpful to draw the finite state machine first. So here's my start state. We'll call it 1. And because "q * " accepts the empty string, it also has to be an accepting state, but I can see any number of q's that I like and still accept, so it looks like we've got 1 state, 1 edge, and our state is also an accepting state. So just to show that this program really works, we're going to run it in the interpreter. Over here, I have defined edges, just as we suggested. In state 1 on a 'q', you loop back to state 1. State 1 is our start state, and it's also our accepting state. Let's try out our simulation on a bunch of q's, the empty string, and a bunch of q's with an evil interloper. We've got this 'A' hiding here. This should be true. True. False. Oh, and it is. So our finite state machine simulator matches our intuition exactly. That worked so well! We should do it again! I actually find simulating state machines suprisingly satisfying. This time, I'd like you to define edges and accepting to encode the following regular expression, definitely [a - b], followed by optionally [c - d]. Name your start state 1. Well, once again, I recommend getting started by drawing the finite state machine. So on a or on b, we go over to state 2, and we could end there because this is optional, or on c or d, we could go to state 3 and end there. Here at the top, I've encoded the edges from state 1 on a we go to state 2. From state 1 on b, we go to state 2 as well--a or b. From state 2 on c, we go to state 3. From state 2 on d, we go to state 3. And both states, 2 and 3, are accepting. Then down here, I have 3 test cases. "ac" which should be accepted. "aX" which should not. X has no business in this regular expression. And just "b" alone, which should be fine because the c - d part is optional. Let's go see. And we get exactly the output we were expecting--true, false, true. Now you might have been tempted to have a c - d self-loop back to 2, instead of this right-hand side of the finite state machine. However, this self-loop changes the meaning to "[a - b][c - d]*". If you have this self-loop, acc is accepted--a-c-c, and it shouldn't be, so the self-loop is not the right way to go. So now let's look at the problem another way, in reverse. Suppose this time that I give you the encoding of the finite-state machine. I give you the accepting states, just 6, and also all of the edges. What I would like you to do is provide me with not 1 but 2 strings that are accepted by this finite-state machine, starting in state 1, but they have to be different, so apply all of your knowledge, but trace it in reverse. What would a string have to be in order to get to state 6? As always, I find the easiest way to answer such a question is to draw the finite-state machine. We come in in state 1, and on a we go to state 2. And on b we go to state 3, and then from state 2 on c we go to 4, and state 3 on d we go to 5, and 5 on e goes back to 2, and 5 on f goes to state 6, and 5 on g goes all the way back here to 1, and our only accepting state is 6. Well, how can we get to state 6? If we go up here to the right, this is like the place of no return. We go here, and then there's no way to ever get back down or get to 6, so we don't want to go to 4. We don't want to get to 2. How about instead if we go 1, 3, 5, 6 or b, d, f? But now I need to give another string that's different but that's also accepted. One way to do that would be to take this go to start back loop here, pass go, start again. 1, 3, 5, 1, 3, 5, 6. So b, d, g, b, d, f. Those are 2 strings that are both accepted but that are different. And if you are feeling exotic, you could actually have gone around these loops more times. You can add b, d, g, b, d, g, b, d, g at the beginning as often as you'd like and make longer and longer strings. It turns out that Python's regular expression module actually uses something very similar to FSM sim under the hood. You just take the regular expression, turn it into a finite-state machine, which you've done forwards and backwards many times, and then check with a simple recursive procedure to see if the finite-state machine accepts a string. However, our simulation did not handle epsilon transitions or ambiguity, and what I mean by ambiguity is what if there are 2 outgoing edges labeled a? Let's say one of them leads to an accepting state, and one of them doesn't. What should we do? Well, there is a formal definition for this kind of ambiguity. However, it's not going to solve our problems. We see that a finite-state machine accepts a string s if there exists even one path from the start state to any accepting state that follows s. This finite-state machine accepts a because there's one way to do it where a causes you to end up in an accepting state. If you like, you can say that finite-state machines are generous. If there's any way to accept, we will make that work. However, our finite-state machine simulation didn't code that up, so we're going to have to return to both of these issues. Suppose we want to use regular expressions to recognize phone numbers with or without hyphens. This is super common in electronic commerce. Here I have 2 positive examples from the American phone system, 123-4567 and 1234567. But we want our business to be international, so we also want to accept numbers in other formats, like these French telephone numbers, which have 5 groups of 2 if they're separated by hyphens or just 10 digits otherwise. And in general, we want to allow any number of groups of any non-empty size separated by 1 hyphen where each group is 0 through 9+. And my hint is you should remember to accept a super small phone number like 5--presumably from many years ago when there weren't that many phones-- but do not accept -6 because there is nothing on the left of the hyphen. This problem is tricky, and you should submit via the interpreter by defining a variable called regexp that encodes this. Well, let's take a few stabs at it. It seems like we definitely want 0 through 9+ to get the first part of any phone number. What about this regular expression? We have 0 through 9+, and then as many times as you like we have a hyphen, and then 0 through 9+ again as kind of a group. This actually works quite well. However, if we were to put a star here instead of a +, this one accepts -6 by just skipping this part and doing this part once, -6, and then we're done. We don't like this. And as we've mentioned, regular expressions admit room for creativity. What if I want to do this interesting grouping at the beginning? What if I say you can have as many of the 08-78-88- things as you want as long as you end with some final numbers? This one also works. You may remember the hyphenated word problem we had from before. This hyphenated phone number problem is actually quite similar, but now that we know how to do grouping with parentheses, it's much easier to solve. All right, let's practice this again, but this time, we've flipped the problem around. I've drawn the finite-state machine accepting that phone number language that we were just dealing with in the last problem. However, I have left the label for the edge between 4 and 5 blank. Your mission is to fill it in. What should this edge label be so that this finite-state machine accepts those phone numbers? Let's do some simple tests. We want to be able to get things like 1, 2, 3, 4 and also 12-34. Let's try the first one. 1, 2, 3, 4, we win. Oh, no problem there. How about this one, 12-34? Well, 1, 2--I can't take the hyphen here. But I could take this epsilon transition for free and then take the hyphen. That sounds good. Now I'm in state 4, and I see a 3. So probably there should be some sort of digit label on this edge. 3, 4, and then back here, and I accept. Just to check our work, let's do something a little more complicated. 1, 2, 3, hyphen, 3, 4. Free, free again, hyphen, 5, 6, free again, accepted. Excellent. These easy-to-write FSMs that we've been using that involve epsilon transitions or ambiguity-- remember, ambiguity means that I can go to 2 different places on the same input-- are formerly known as non-deterministic finite state machines. Non-deterministic here just means that you may not know exactly where to go or where to put your finger. It's not lock-step. You have choices. You have freedom. A lock-step FSM with no epsilon transitions and no ambiguity by contrast is called a deterministic finite state machine. Everything is determined from the start. Given the finite state machine and the input, you always know exactly what will happen. Our finite state machine simulation procedure can handle deterministic finite state machines. That makes them really useful for implementing regular expressions under the hood. Let me just show you an example of this non-determinism just to drive it home. Suppose we were back here in this previous finite state machine, but now the input is 1-23. Where are we? We started here, and on a 1 we went here, and then I guess if we're supposed to stay alive and there's a hyphen, we must have gone here and taken the hyphen. And now there's a 2, but now this is really not obvious. I could stay here on this self-loop for a 3, or I could have gone back on this free epsilon transition and done the self-loop here on a 3, so I could be in state 2 or state 5. Since there isn't one single answer for where I could be, this is non-deterministic. As a bit of a fun aside, this notion of determinism or non-determinism can be related to the question of free will in philosophy. Can we actually make independent choices? Or is everything preordained by the current state of the world and forces acting on it, like a lock-step game of billiards or snooker or pool? Some philosophers will approach this by suggesting that we have the illusion of free will--that's a disconcerting thought-- which is handy for describing subjective experience. We certainly often feel like we have free will. Regardless of what's going on in the real world, we're going to see that something similar holds for finite state machines. Although non-deterministic finite state machines look like they have much more power and much more freedom, anything that could be done with them could also be done in our deterministic billiard ball world. In fact, you can watch me suck free will out of this world right now. Every non-deterministic finite state machine has a corresponding deterministic finite state machine that accepts exactly the same strings. Non-deterministic finite state machines are not any more powerful than deterministic finite state machines. They're just more convenient. It's easier to write them down. Let's see an example of this extraordinary claim. Suppose we have this regular expression. There are only 2 strings in the language of this regular expression, but here I've drawn out a very elaborate finite state machine for it that has epsilon transitions coming out the wazoo. This is very non-deterministic. We definitely need to see an a, but then here these 2 epsilon transitions represent the explicit choice. Do I do the b, or do I skip over it? On the top road, we need to see the b. On the bottom road, we skip entirely past it. And then in any event, we need to see the c. I'm now going to write a deterministic finite state machine that does exactly the same thing, and I'm going to hint at how this conversion works. We'll see this again in just a minute. After I see an a, I could be in 2, or I could take the epsilon to 3. I could have taken the epsilon down here to 6 or all the way over to 4, so there are 4 places I could be in. That's a lot of fingers. I'll just record all of them as the name for my new state, 2364. From here, if I see a b and I survive--remember, finite state machines work if there's any path that gets to the end--it must have been that I was in state 3, at which point now I'm just in state 4. By contrast, if I was back here and I saw a c, it must have been that I was in state 4, and now I'm in state 5. And then finally, if I'm in state 4 and I see a c, I end up here, so this deterministic finite state machine accepts the same language as the one above. The 2 strings, a, b, c, and a, c are both in it, but it does not have epsilon transitions or ambiguity. In any particular node, there are never 2 edges going out labeled a, and there are never epsilon transitions. Let's see another example of how this works. Again, I'm going to build a deterministic machine where every state in the deterministic machine corresponds to a set of states in the non-deterministic one. Again, to restate that, you give me a non-deterministic machine, I'm going to build you a deterministic machine d that accepts the same language, and the way I'll do it is every state in d is going to correspond to a set of states in the non-deterministic machine you gave me. Let's do one more bit of practice converting non-deterministic machines to deterministic ones. Here I've written a non-deterministic machine. It has ambiguity. Right in state 1 there are 2 ways to go on a. It also has epsilon transitions, and I'll start making its deterministic equivalent down here. Well, when we enter the non-deterministic machine, we could only be in state 1, but after that we could see an a, and if I see an a I could be in 2, 4, or I could take the free epsilon transition to 5, or I could keep going and take the free epsilon transition to 6. I'll label my new state 2456 because it keeps track of everywhere that I could have my fingers if I'm simulating this non-deterministic machine. Now, should this state be an accepting state or not? Well, remember that a finite state machine accepts if there's any path to an accepting state, and 6 is one of our accepting states. Because the original machine could accept a, a, epsilon, epsilon, win, we want our new machine to also accept a. A, win. In my converted world, the state accepts if any of its corresponding original states also accept. Let's say that I'm in either 2, 4, 5, or 6 and I see a c. If I'm in 2 and I see a c, I fall off the world. If I'm in 4, fall off the world. 5, I go to 6, looking good. 6, fall off the world. Here if I was in 2, 4, 5, or 6 and I see a c, I end up just in state 6, and that's definitely an accepting state. Now, there's some other ways to get out of 2, 4, 5, and 6, and when we do, we might be in states 2 or 3. Since 3 is an accepting state up there, 2 or 3 is an accepting state down here. If I'm in 2 or 3, on a b from 2 I go to 3, and c I'd fall off the world, so we'd end up in state 3. If I'm in 2 or 3 and I see a c, I must really have been in state 3, and I stay in state 3, so either on b or c we end up in just state 3, which is also an accepting state. And if I'm in state 3, there's a self-loop back to state 3. Now, I've filled out almost all of this deterministic equivalent. But I forgot to label an edge. Help me out. As the quiz, what should the label for this edge be so that this deterministic equivalent and this non-deterministic machine accept exactly the same language? Well, let's make ourselves a little scratch room and work it out. There are only 1, 2, 3 letters, a, b, and c involved, so let's take a look at each one by one, see if it fits. Suppose I was in state 2456 and I saw an a. If I'm in 2 and I see an a I die, 4 and I see an a I die, 5 and I see an a I die, 6 and I see an a I die. That's not good. 2456 on a goes to failure. It does not go to 23. All right, well, what if I see a b? If I'm in 2 and I see a b, I go to 3. That looks pretty good. 4 and I see a b I die. 5 and I see a b I go to 2. 6 and I see a b I die. Oh, b took us to exactly 2 and 3. 2456 on b went to 2 and 3. But let's just finish checking up on c just in case we missed something. I'm in 2456. 2 on a c goes nowhere. 4 on a c goes nowhere. 5 on a c goes to 6, and 6 on a c goes nowhere, so 2456 on a c goes to 6. Actually, we already have that edge, 2456 on a c goes to 6, and since this machine is deterministic, we only want 1 outgoing edge here labeled c. It looks like b was our winner. The label for this edge is b. Now, this is not a proof, but it just so happens that any non-deterministic machine can be converted to a deterministic machine using exactly the same steps. Let's wrap up what we've learned in this unit. Strings are just sequences of characters, and manipulating strings is going to be critically important for making a web browser. Modern programming languages support regular expressions, which are just a concise notation for specifying sets of strings, and using regular expressions is more flexible than using fixed string matching like string.find. With regular expressions, we can define phone numbers, words, numbers, quoted strings, and given a regular expression, we can search for and match it in a bigger string. Finite state machines are a pictorial equivalent to regular expressions. Every regular expression, concatenation, plus, question mark, star, has an equivalent finite state machine. And in fact, although I didn't show it, vice versa. Every regular expression has a finite state machine, and every finite state machine has a regular expression. And then every finite state machine can be converted to a deterministic finite state machine. No epsilons, no ambiguity. Once we have a deterministic finite state machine, we can simulate it, and it turns out it's very easy-- about 10 lines of recursive code--to see if a deterministic finite state machine accepts a string. In fact, you've written that code. Now that you know how to implement regular expressions, take the regular expression, make a finite state machine, make it deterministic, call FSM sim. We'll just use Python's regular expression library, but it's doing exactly those steps under the hood. It works the same way you would. In our next exciting episode, we're going to use this knowledge to specify important parts of HTML and JavaScript like string constants or hypertext tags. As the first step to writing our web browser, one great resource available to you as you revise this material and work on the homework is the forums. Be sure to check them out. If you were wondering about something, almost certainly someone else was wondering as well. Post your question. Others will benefit from seeing it answered. Be courteous, but be curious. We all benefit from questions. And let me just leave you with this xkcd comic. While they're talking about Pearl, everything said applies to Python, and soon you will be using regular expressions to save the world. We've just finished learning about sets of strings, regular languages, regular expressions, and finite state machines, a beautiful formalism and a lovely way of implementing it in actual Python. This idea, this tool of regular expressions specifying sets of strings is a really powerful and really expressive way of writing quite a few programs. We're going to see this come up later on in everything from mail to web servers to web browsers to writing our interpreter for JavaScript and HTML. You've learned quite a bit in Unit 1, and I'm really hoping that you'll stick with me and learn even more in Unit 2. Last unit, we learned about regular expression and finite state machines. In this unit, we're going to put those concepts together to make a lexical analyzer--a program that reads in a web page or a bit of JavaScript and breaks it down into words, just like I might break and English sentence down into words. This is going to be a really important tool in our arsenal, and it's one of the first steps towards making a web browser, Welcome back. In our last exciting episode we learned about regular expressions, a concise notation as a way to write down or denote or match a number of strings. This 4 through 7 in brackets corresponds to 4 different strings 4, 5, 6, and 7. We learned to write more complicated regular expressions like this one-- "b a +."--this plus means one or more copies of a's, yielding words like ba, baa, baaa, and eventually yielding my sheep. I assert that it's a sheep. You can tell because of the label. Those labels never lie. We also learned how you can use regular expressions in Python by importing, bring in, the functions and data types from the regular expression library. An example of such a function was findall, which, given a sort of needle regular expression, would return all of the places in the haystack that it matched. We also learned that you could turn regular expressions into finite state machines. This finite state machine accepts the same language as our ba, baa, baaa regular expression from above. Starting in a start state, on a b we transition to the middle state, on an a we end up in the third state, which is an accepting state. You can tell by the double circle. Then there's a self loop back. That was last time. Now, we're going to learn how to specify important parts of HTML and JavaScript, and, in an incredible surprise move, we're going to do this specification using regular expressions. Just a quick reminder, an outline of the overall project, we want to start with a web page and then break it down into important words. Maybe the less than and the greater than sign used for the tag are important words, the 1, the plus, and the 2, but we're largely ignoring this sort of white space or these new line characters. Then we want to take those words and diagram them into this cool tree-like structure. Of course, this tree is growing upside down, but that won't be a problem at all. Finally, we're going to interpret that tree to figure out what it means to get the result. HTML stands for the "hypertext markup language." Many of you may have some previous experience with HTML, but that's not necessary. HTML as w know it was invented to Tim Berners-Lee, a British computer scientist working in Switzerland around 1990. For our purposes, HTML just tells a web browser how to display a webpage. In fact, HTML is not all that different from using symbols like stars or underscores to emphasis text that you're writing to someone else. In HTML this emphasized plain text becomes "I," and then this special punctuation that means let's do some bold now, "really," this special punctuation that means I'm done with bold, let's go back to normal, and then "like you." The "b" stands for "bold." Let's go see how that pans out. Here in this particular window, I'm showing the raw HTML source on the left and how it might look in a web browser on the right. Here when I've added the bold tags around really, we see "I really like you." The "really" is rendered in bold. Other comment approaches in HTML for emphasis are the use of underlines, the "u," and italics, "i." Each one of these is called a "tag." This special syntax with the "b" in angle brackets and the "b" sort of similar angle brackets, the "u," the closing "u," the "i," the closing "i," is a tag that's associated with that word, or that span of text, and tells the web browser how to render it. This part here, the left angle bracket and the right angle bracket-- that's a starting tag, and this other part--the left angle bracket followed by a slash, the slash is super important, begin an end tag. That's a little complicated to say. Mark the start of an ending tag and tell you that the current tag is about to stop. Here's a beginning bold tag. Here's an ending bold tag. You can see that play out on the right. Only the word "really" is bolded. Let's check your knowledge of that with a multiple choice quiz. Here a number of times I've written the sentence "George Orwell was really Eric Blair." You might think I've written it, say, 1984 times, but really, just four. I hear if you repeat something like this enough, it becomes true. What I'd like you to do is mark in this multiple multiple choice quiz which of these will end up showing the world "really" in bold. They can show other words in bold, but I want to know that they'll show "really" in bold. Let's go through these together. This is well-formed HTML, we're beginning the bold tag. It ends after the word "really." This looks great. Unfortunately, in this next sentence we end the bold before we start it, and then we start it over here with Eric Blair. That's not going to work out well. I will show you in just a minute what that looks like. Here, we begin the bold tag and then we have lots of space and then the word "really." It turns out that is totally fine. Web browsers use the same sort of techniques we talked about in the last unit to break up sentences like these into words based on white space. All this extra space doesn't matter. Finally, down here we start bold at the beginning of the sentence, so all the of these words--George-Orwell-was-really-Eric-Blair"-- they're all bolded. Notably "really" was bolded as well, so this works out. Let's go see how this plays out. Here we have the first option--"George Orwell was really Eric Blair"-- and really is definitely bolded. If I reverse these, it's harder to interpret. This bold tag closes nothing. It's ill-balanced. This makes me super unhappy. But this next one applies to "Eric Blair," and then falls off into the end of the universe. This isn't very good. I can put huge numbers of spaces here, and as we see, this does not influence the rendered web page at all. Then in this version I have the tags at the start and the end of the sentence, and the whole sentence is bolded. George Orwell is perhaps best known for writing 1984, and I hear that HTML has always been at war with JavaScript. As we hinted before, this special syntax in HTML is called a tag. It's kind of like a price tag you might attach to a shirt or another item you're buying. This modifies nearby text and tells you how to interpret it, whether you can wash it or not in a machine, how much it costs, whether or not it should be bolded or underlined--that sort of thing. Another super common kind of tag is the anchor tag, which is used to add hyperlinks to webpages. In some sense this is the defining characteristic of what it means to be a webpage. Here I've written a fragment of HTML that includes such an anchor tag. It begins here, but unlike the relatively simple bold and underline tags, it has an argument. This means pretty much the same thing it did when we were talking about functions in Python or math. Here the argument or my sine function is pi. Here the argument or modifier for my anchor tag is href equals. This stands for hypertext reference--the target of this link. Here I've given a string that is a URL, a web address. Hypertext transfer protocol google.com. This text in the middle is often rendered in blue with an underline, although it doesn't have to be. Then over here we're ending the anchoring tag. Let's see how this plays out. Here I've the old "Eric Blair was really George Orwell" text, but I've added a new sentence--"Click here for a link to a webpage." Right after the anchor starts, the text is rendered in a slightly different color. If we were to click on it, you can potentially see down in the lower left that it goes to google.com. Just to break this down, if this is a fragment of HTML, then the words "Click here and now" will all be drawn on the screen. This syntax marks the beginning of the anchor tag. This syntax, left angle bracket slash a right angle bracket, marks the end of the anchor tag. This part in here is the argument of the tag. It contains extra information for things that are more complicated than simple bold or underline. Here I've written a significantly more complicated fragment of HTML, and I would like you, gentle student, to help me interpret it. In this multiple-multiple choice quiz, check each box that corresponds to a word that will be displayed on the screen by the web browser. Let's go through it together. Href is actually one of the arguments to this anchor tag. It's not displayed. If the user clicks on this link, they'll go to Wikipedia.org, but they'll never see the href. This is not shown. Mary, on the other hand, is not the name of a tag or the argument to a tag. It will be shown. Similarly, Vindication will be shown. It'll be shown as part of a link and italicized, but it'll be there. Wikipedia is part of the argument to this anchor tag,so it will not be shown. Wrote, however, will be shown, and then this i, the italic tag, isn't shown. Instead, the next is actually slanted. Here we're taking a look at how it would render in a web browser. We can see Mary Wollstonecraft wrote A Vindication of the Rights of Women. Href, Wikipedia, and i are not printed on the screen. Now that we understand how HTML works, we want to separate out these tags from the words that will be displaced on the screen. Breaking up words like this is actually a surprisingly common task in real life. For example, ancient Latin was often written or inscribed without spaces. This particular set of letters "SENTATUSPOPULUSQUEROMANUS" is inscribed on the arch of Titus, which I've doodled over here as a column, but what can you do? Arches are apparently beyond my power. I know. It has just become an arch. Those labels never lie. Roman inscriptions like this were written without spaces, and it requires a bit of domain knowledge to know how to break this up. "Senate and the People of Rome." That inscription was made quite some time ago. Similarly, in many written Asian languages, they don't explicitly include spaces or punctuations between the various characters or glyphs. In this particular Japanese example, and both my handwriting and my stroke order are very, very poor--have pity--some amount of domain knowledge is required to break up "ano" from "yama"--"that mountain." Finally,even if you're not familiar with Asian languages or ancient Latin, you might have seen the same sort of thing in a much more modern guise, in text messaging. Some amount of domain knowledge is required to break this up into "I love you" even though no particular spaces are given. We will want to do the same thing for HTML to break it up into words like "Wollstonecraft" and "wrote" that will appear on the screen or this special left angle bracket slash maneuver that tells us that we're starting end tag, this special word in the middle that tells us which tag it was, and then this closing right angle bracket. Once again, for this HTML fragment we want to break it up into this first word, the start of the closing tag, another word, the end of the closing tag, and then another word. We're going to need to do this to write our web browser. In order to interpret HTML and JavaScript, we're going to have to break sentences down into their component words to figure out what's going on. This process is called--dun, dun, dun, dun-- lexical analysis. Lexical here has the same roots and "lexicon" like a dictionary. This means "to break something down into words." You'll be pleased to know that we're going to use regular expressions to solve this problem. Here I've written another one of those decompositions. We might have broken an HTML fragment down into these word-like objects, but this time you're going to help me out by doing the problem in reverse. So in this multiple multiple choice quiz, I'd like you to mark each one of these HTML fragments that would decompose into this sequence of five elements. Let's go through it together, and this first one starts with a left angle bracket, which looks super promising, but then it has this slash which we don't see reflected up here, so this one doesn't match, could not have produced this sequence of 5. Over here we have a left angle bracket, a b, a right angle bracket. Looking great. Salvador, looking good. Dali, looking great. Oh, yeah, this totally matches. Down here we have almost the same sentence, but there's no space between salvador and dali. This is very close, but instead of getting 2 separate words at the end, it would break down into just one word at the end, salvadordali, so this one doesn't match. Over here we start with a bold tag, have salvador and then dali, but then we have a few more characters that aren't shown in this list of 5, so this doesn't match exactly. Here we have salvador followed by the bold tag. That's getting the order wrong, and the order of this breakdown is really going to matter. We really need to know the order of words in a sentence. Super important, it is. Finally, over here we start with bold, and we have salvador dali again. This looks great. No problems there. Notice the spacing was a little different. Here we had a space between the bold tag and salvador. Here we had kind of a space over here. These spaces don't matter very much. Salvador Dali was a Spanish artist famous for his surrealist paintings, probably most famous for painting The Persistence of-- I can't remember. Let's just go on. Since HTML is structured, we're going to want to break it up into words and punctuation and word-like elements, and we use the special term token to mean all of those. In general, a token can refer to a word, a string, numbers, punctuation. It's the smallest unit of the output of a lexical analysis. Remember, that's what we're currently working on. Mostly tokens do not refer to white space, which is just a formal way of referring to the spaces between words. We're going to be focusing on lexical analysis, a process whereby we break down a string, like a sentence or an utterance or a webpage, into a list of tokens. One string might contain many tokens in the same way that one sentence might contain many words. Here I've written 6 HTML tokens, given them names on the left and examples on the right. Now, the naming of tokens is a bit arbitrary. In general, though, tokens are given uppercase names to help us tell them apart from other words or variables. Here this left angle corresponds to an angle bracket facing left presumably--not quite sure how to draw that. The smaller end is to face. Left angle slash is a < followed by a /, division sign. The right angle bracket, > facing to the right. Here's the angle. Here's the face. The equal sign is just =. A string is going to have double quotes around it, and a word is anything else, welcome to my webpage, punctuation like that. Now, it turns out that the naming of tokens is not quite an arbitrary matter. You may think I'm as mad as a hatter. No, that's a different story. We're just going to go with these token names for now, but if you were designing a system from the ground up, you can rename them to be anything you like. We're going to use regular expressions, which are very good at specifying sets of strings to specify tokens. Later on we'll want to match a bunch of different tokens from webpages or JavaScript, and this is how we write out token definitions in Python. The t_ tells us--and it tells the Python system-- that we're declaring a token. The next letters are the name of the token. You either get to make this up yourself, or in the homework I'll tell you what I want it to be. Tokens are in some sense going to be functions of the text they match. More on this a bit later. Skip me for now. Next, we have a regular expression corresponding to this token, which in this case, for the right angle token, there's really only 1 string it can correspond to, so we've written out the regular expression that corresponds to a single string. And then here on the last line we're returning the text of the token unchanged. We could transform it, and you'll see us do that for more complicated tokens like numbers where maybe we'll want to change the string 1.2 into the number 1.2. Now it's your chance to define your first token. What I would like you to do is write code in the style of the procedure I just showed you before for the LANGLESLASH token. The LANGLESLASH token is surprisingly important. We really need it to know when all of our tags end. Use the interpreter to define a procedure t_LANGLESLASH that matches it. Let's go through a possible answer together. I have to name my procedure with t_. That tells the interpreter that I'm defining a token. Now I give the name of the token, LANGLESLASH. That was given as part of the problem. All of our tokens are actually functions. We've been eliding that bit. We're still going to skip over it. Next I have to have a regular expression for the string that matches the token, and here again there's only 1 string that matches, and I'm going to return the token unchanged. It's not enough to know that a string contains a token, just like it's not enough to know that a sentence contains a verb. We need to know which one it is, and formally we refer to that as the value of the token. By default, the value of a token is the value of the string it matched. We can rebuild it, however. We have the technology. Let's see how that plays out. Here I've written a definition for a slightly more complicated token, a number, one or more copies of the digit 0-9, and now I would like you, our last, best hope for victory, to help me understand it. If the input text is 1368, what will the value of the token be? Check all that apply. All right, let's go through the possible answers together. We're definitely going to match 1368 because it's in the language of this regular expression. It's 4 copies of 0-9 together. By default, the value of the token, that is, when it comes into us, it's just the string 1368. But we're going to convert it to an integer using this cast or conversion here, so at the end of the day, it's going to be 1368. It's not going to be the string 1368 because we have this special conversion. It's not going to be the string 1 because the maximal munch rule means that we're not going to match just one. We match all 4 digits. Similarly, it's not going to be the integer 1 because we match 1368. It's also not going to be the empty string. We definitely match 1368, and 1368 is a good number to match. That's the approximate year when the Ming Dynasty started. They featured a strong central government in China, but perhaps they're best known because most of the Great Wall that we can see was either built or repaired during the Ming Dynasty. This is my Great Wall sketch. You can tell it's the Great Wall because it's got a label that says "Great Wall." When reasoning about HTML, it's critical that we understand quoted strings. They come up in almost every anchor tag, and anchor tags are the essence of hypertext. They're the interlinks between documents, so we really need those. They rely on quoted strings. That means we're going to need to understand quoted strings. It is convenient then that we are amazing at quoted strings. You have plenty of practice with them from the previous unit. Once again, it's time for a quiz. Suppose that the strings we care about start with a double quote, end with a double quote, and in the middle they can contain any number of characters except double quotes. I'd like you to write a definition for the Python function t_string and submit it via the interpreter. And just to make this a bit clearer, we should definitely accept quoted strings like cuneiform or sumerian writing. But we should not accept 30th century BCE because it doesn't start and end with quotes, and we should not accept this string which has an escaped double quote. We may want to get to that later, but for now, don't worry about escaped double quotes. Go to it. Submit via the interpreter. So let's go through a possible answer together. Once again, the real trick is just coming up with a good regular expression, so we can't have a space, a left angle, or a right angle, but we can have 1 or more copies of anything else, and we'll just return the token unchanged because that's what we are asked to do. So we're using these token definitions in regular expressions to break down HTML and JavaScript into important words. As we've seen before, there can be lots of extra space between various tokens. We really want to skip or pass over spaces and possibly newline characters and tabs. More on that later. We do that using the same sort of token definition as before, so here I've made a regular expression that just matches a single space, but instead of returning the token, we pass it by. This is the power. Let's test out our knowledge with a quiz. We've already seen how to do left and right angle bracket sorts of tokens. We've taken a look at strings before. And now let's do words, which are almost everything else on a web page. Let's say that we want a word to be any number of characters except a left angle bracket, a right angle bracket, or a space, and here I really mean the single character pressing the space bar, not this 5-character word, but it's hard to write out. And when you're writing your function to match word tokens, you should leave the value unchanged. Submit a definition for t_word using the interpreter. Let's go through the answer together. We definitely want to name our procedure t_string, and now the real trick to this is just writing a good regular expression. Here I've written a regular expression that starts with a double quote, ends with a double quote, and can have anything that's not a double quote-- remember that super useful carat character--0 or more times. You've now seen a bunch of these token definitions, one for words, one for strings. A lexical analyzer or lexer--this is a term of art-- is just a collection of such tokens. You tell me what makes a word, what makes a string, what makes a number, what makes white space. You put it all together, and the result is a lexer, something that splits a string into exactly the token definitions you've given it. For example, once I put these 3 rules together, they become a lexer, or lexical analyzer. And in fact, suppose we passed to this lexical analyzer the input string 33 is less than 55. Oh, gentle student, tell to me which one of these token output sequences could result. In this multiple choice quiz, indicate which of these 3 possible output lists could correspond to the values of the tokens extracted from this input string using these rules. Let's put it all together. Let's take a look at the answers. This 33 is definitely going to match, we hope-- we're going to get to this in a minute--our numbering rule. And then we're going to end up converting it into an integer. 33 looks pretty good. Is will match the word is. Less will match the word less. Than will match the word than. 55 could be converted to a number, give us the integer 55. And all of this white space in the middle will be dropped. This is a possible answer. Here we have pretty much the same thing except that we appear to be returning a space as a word. That's not going to happen because our words can't include spaces, and this white space rule would skip over it beforehand. That's not it. Here looks a lot like the beginning, but instead of matching 33 and 55 as numbers, we appear to have matched them as words because we've returned this string unchanged. This isn't really what we wanted, but actually, nothing prevents that from happening. 33 could match either our word regular expression-- 33 is not a space, it's not a less than, it's not a greater than-- or our number definition, and I haven't told you how to resolve this sort of ambiguity. Oh, that word is back from the dead. This is also a possible answer. Now let's take a look at the same concept but do it backwards. Let's assume that we've fixed the problem from the last quiz. We're going to assume that number is preferred to word. Whenever we could match something as a number, we'll match it as a number instead of a word. What I'm going to do is write out a few phrases, a few sentences, and I want you to notice which of them could produce, could be decomposed into a word followed by a word followed by a number. Multiple, multiple choice. Check all that apply. Which of these 4 inputs could break down into word, word, number using the rules that we've been going over so far? This first one looks very promising. Grace is a word. Grace is the word? Grease is the word. Hopper is a word, and 1906 could match a number. This looks very good. Here grace is a word, some white space, hopper is a word, some white space, 1 is a number, but because there's white space between the 1 and the 9, this is going to register as 4 different numbers instead of just one, so it doesn't match this specification exactly. Here we have grace followed by hopper in quotes, and as we've defined things previously, this actually does qualify as a word. Let's go back and see why. Remember that our definition for word was anything that's not a space, a left angle bracket or a right angle bracket, and the double quote certainly fits in there, so it may not be what we want right now, but if you are sharp and notice that this qualifies as a word under our rules, good eye. And then 1906 is a number. Here we have grace is the word, hopper is a word, one nine oh six is a word, so this is 3 words rather than 2 words and a number. And grace hopper is of particular significance to programming language and compiler people because she's the origin of the word "bug," meaning mistake in program. She is credited with finding the first computer bug, a moth that had worked its way into the machinery and removing it and recording it or what-not and thus repairing the problem. As we saw in that last quiz, it's not quite clear what to do when our token definitions overlap. The 7-character sequence "hello" matches our regular expression for word but also matches our regular expression for string. This is a problem not just with computer languages but also with natural languages. As the hypothetical owner of this restaurant would notice, we don't just serve hamburgers, we serve people could be interpreted the wrong way. Presumably those hamburgers are soylent green flavored. We want to have definitive rules for figuring out which of these we prefer. In fact, we're going to use a very simple rule. The first one you list wins, the one closer to the top of the file, so this is our big winner and is going to take priority over string. If you're making a lexical analyzer for HTML or JavaScript, ordering your token definitions is of prime importance. Let's investigate this issue in the form of a quiz. Suppose we have the input string hello, "world," and we really want that to yield word, the word hello, followed by a string. I'm going to list 3 rules for you, and I want you to tell me which one has to come last for us to get the desired effect. And here, because you've seen it all before, I'm eliding some of the details like the colon, token, blah, blah, blah. Instead what I'd like you to do is tell me which one of these functions, which one of these rules, would have to come last, bearing in mind that the one that comes first wins all ties in order for hello, "world" to break down into a word followed by a string. Well, let's take a look. Suppose our word rule comes first, just like it does here on the page in some sense. Hello is definitely a word, but actually, world in quotes is also a word because this quotation mark is not a space, a left angle or a right angle. If this comes first, we get word, word, which would make us very unhappy. On the other hand, if it comes after string, then we'll end up getting the behavior that we're expecting. However, probably this whitespace rule actually has to come first lest we confuse whitespace and the body of strings. Our word rule precludes us from including spaces as parts of words, but our string rule really does not, so we probably want our whitespace rule to come if not first, somewhere near the top. That means that our word rule is the one that comes last. If our final ordering is either whitespace, string, word, string, whitespace, word, we'll get the output we expect. Let's walk through the first one and see how it goes. We'll start with the h in hello. Does that match whitespace? No, it does not. We'll try our next rule. Does that match string? No, it doesn't start with a double quote. Could it match word? Oh, it totally could. And now we'll use our maximal munch power, and it will eat up the e, the l, l, o, comma, but it's going to stop because whitespace has higher priority. We'll see the word hello, then we'll see the space. Does that match the whitespace rule? It does, so we'll pass over it. Then we'll see these double quotes. Does that match the whitespace rule? No. Does it match the string rule? Yes, it does. Maximal munch will take us all the way to the end of this token, and we get the output we expect, and the second case behaves similarly. So you may have noticed a bit of redundancy in our handling of "quoted strings". We return the entire matched text, which includes these double quotes at the end. But, in some sense, they're not as much part of the meaning, as they are beginning and ending markers to tell us when the string starts. This is our default token value, but we might want to take a small pair of scissors to this string, and snip off the quotes at the beginning--and at the end. Here we have an example of a token definition that does just that. After matching the right kind of string, we take the token value-- the entire thing-- and we're going to use substring selection, starting at character 1-- this is going to be character 1-- and going up to, but not including, character negative 1. Now if you haven't seen this trick before in Python this might surprise you a bit, but you can count back from the end of the string, using negative numbers. So this is actually the negative first character. And remember that substring inclusion starts at 1 and goes up to, but not including, the negative 1. So this is going to get everything from the "q" over to the "s" in strings-- or in other words, have exactly the effect that we wanted. Cute little trick, huh? So now I'm going to show you how to make a lexical analyzer--which, recall-- is just a bunch of token definitions put together. I'm going to write it out in Python and we'll follow along. This top line--the import statement--is a lot like Import RE. It's telling Python where to find our lexical analyzer software or libraries that we're going to build upon. Just like regular expressions were called RE to save space, a lexical analyzer is just called "lex"--to save space. And now I'm going to give a list of all of the tokens that I care about. Here, I'm just going to be concerned with the 6 that we've previously spoken about: the Left Angle bracket; the Left Angle bracket, followed by a slash; the Right Angle bracket-- these 3 make tags-- an Equal sign, Strings that are surrounded by quotes, and every other word. I'm also going to use a little shortcut. Before, we used a Whitespace token, but if you like, you can write the word t_ignore instead and, implicitly, we'll ignore everything matching this regular expression. Here's my first token definition rule. It's for LANGLESLASH. Here's the regular expression that it matches. We return the text, unchanged. Here's another rule for the Left Angle bracket, the regular expression that it matches--and we return the text, unchanged. And you'll note that I have the LANGELSLASH rule ahead-- before it--in the file. And that's because I want this one to win, on ties. If I see a Left Angle, followed by a slash, I want it to be the LANGLESLASH (token)-- and not the Left Angle, followed by--say--a WORD(token). More on that in just a bit; I'll test that out and show it to you. Here's our rule for the Right Angle bracket. Here's our rule for the Equal sign token. Note that while these are long-- they take up a bit of space--they're not actually particularly complicated. This has mostly been listing 5 regular expressions. Here's one now. This one is a little bit more complicated--here's are rule for STRING(token)s. Here's our regular expression that matches it. And there I am, dropping off--shaving off-- the surrounding double quotes, just as you've seen before. Finally, there's our definition for the WORD(token). And now what we want to do is use these regular expressions, together--these token definitions-- to break up a Web page. So here, I'll make a variable that holds the text of a hypothetical Web page. "This is my webpage!" Let's make it more exciting; Ho, ho--this is at least 10 percent more exciting! This function call tells our lexical analysis library that we want to use all of the token definitions above to make a lexical analyzer, and break up strings. This function call tells it which string to break up. I want to break up this Web page: "This is my webpage!" Now, recall that the output of a lexical analyzer is a list of tokens. I want to print out every element of that list. This call, .token, returns the next token that's available. If there are not more tokens, then we're going to break out of this loop. Otherwise, we print out the token. Well, let's go see what sort of output we get. The odds of me having written this, making no mistakes the first time, from scratch, are about zero. Let's go see what happens. Oh! I actually don't really believe it! We can see the output here at the bottom: LexToken (WORD, ' T ',' h ', ' i ', ' s ' but it's not quite the output I was expecting. Oh, here's the mistake that I made-- right now, I only have one character in t_WORD and if you look down here, instead of seeing the word, "This"--for "This is my webpage!"-- I have each letter spelled out separately. Let me fix that. And now we get more of the output that we were expecting. Our first token is ' This '; our next token is a word, ' is '. Then we saw the Left Angle bracket, a word, ' b '--for bold, the Right Angle bracket; a word, ' my '; the LANGLESLASH, and then the word, ' webpage '. So this is a demonstration of a lexical analyzer. And what I'm going to show you is how to test things out or change things around. For example, let's go up here and turn "This" into a quoted string. So previously, our first token was the WORD, ' This ', but when I rerun it, I'm really expecting to see the STRING, "This"-- because I've put This in quotes. And now it is the STRING, ' This '. These other numbers, after lexical analyzer token STRING, with token value, ' This ' are the line and character number information. The token corresponding to ' This ' starts on line 1, at character zero. The token corresponding to ' is ' starts on line 1, character 7-- zero, 1, 2, 3, 4, 5, 6, 7--yep, that's where the "i" starts. So let's say we made a mistake, we got one of our regular expressions wrong. Let's say that I mistakenly put in a Greater Than sign here, for LANGLESLASH. Well, then right after "my", I would expect to see the output change. I'm going to expect to see us get the wrong answer. Currently, right after ' my ', we see LANGLESLASH. Let's rerun it. Oh! Now we don't see quite the right thing at all. Right after the ' b ', we see an LANGLESLASH, but it's associated with the wrong text. After ' my ', we just see an LANGLE. The slash is made its way into this WORD, ' /b '. By looking at this output, we can notice mistakes in our lexical analyzer and help fix them. I repair the problem, rerun, and the world looks like a bit better. Here, I've used Python's triple quoting approach. We have the word Tricky; the quoted STRING, "string"; LANGLE, word, RANGLE, output, LANGLE, slash, i, RANGLE, word-- and then we're done. Let's go see how this comes out. We've got the word Tricky; the STRING, "string"-- and if you've noticed, we've shaved off the 2 double quotes, which is just what we wanted, an LANGLE, the i, the RANGLE, the word ' output ', LANGLESLASH, Bang at the end. You saw in the simple lexer that we wrote that tokens come, not just with a type of token in their value, but also their line number and column number. That sort of information is very handy to keep track of for users. At some point, you may have written an incorrect Python program--nah. I've only written about a million of them. And it's really nice when the interpreter tells you which line the mistake is on. Unfortunately, the lexer won't do this for us--entirely automatically. It will keep track of columns, but it won't keep track of lines-- unless we do some work. Here's an example of a rule that matches new lines. You may not have seen this before, but we've already seen how the backslash can be used to Escape special characters, like the quote. And this basically just means: quote. However, when paired with something else, the backslash often has a special meaning. \ N is the string equivalent of pressing the Return or Enter key on your keyboard, and we call this the "newline" key. It advances your Editor, by 1 line. So this rule--t_newline-- matches a new line that appears. And when we see it, we take the token and increment its line number by 1, and then we pass over the new line, as if it were Whitespace. Here you can see that I've added the newline rule, just as I described on the previous slide, to our old lexer from before. Let's go all the way to the bottom, and now I'm going to make my Web page much more complicated. And here, I'm using triple-quoted strings, showing line1 on the first line and line2 on the second. Unfortunately, the output shows Line1, followed by the new line. I'm going to have to go up here and remove newline from the list of things that it's possible to have in a Word--just like we had to remove space. And now we see that Line1 starts on LIne1 and Line2 starts on Line2, and it's the seventh character from the beginning of the file. Zero, 1, 2, 3, 4, 5 is the newline, 6 is the space, 7 is the capital L. All right. All right. So now that we understand all of that, it's: a QUIZ! Written a little differently than normal, but a quiz, nonetheless. I would like you to define a variable called (webpage) that holds a string that causes our lexical analyzer to produce exactly these 6 bits of output: ' This ', ' is ', bold, ' webpage '-- but pay careful attention to the line number offsets. Notice, for example, that this Left Angle starts on line 2, character 11. Try it out. Define a variable, (webpage), that holds this string. All right. Let's go take a look at the big reveal, for how it actually started. Up here is our string; we start at characters zero, on line 1, with ' This '. 1, 2, 3, 4, 5--now we're on line 1, character 5, with the ' is '. 6, 7, 8, 9, 10, 11--we're on line 2, character 11, and we're starting the Left Angle, then the ' b ', then the Right Angle, then the ' webpage '. And to reverse engineer this, you might note--for example-- that you know the Left Angle is 1 character. If it starts on character 11, and the ' b ' comes right after it on character 12, there must be no spaces between them. Similarly, since the ' b ' is 1 character and it starts on character 12, the RANGLE, there must be no spaces between the ' b ' and the RANGLE. So the real trick here is figuring out what happens after the "is" and before the ' b ', and knowing that you need these 3 extra spaces ao all the action's happening here. Just as we have to separate words in HTML and JavaScript based on white space, we also have to take into account comments, and comments in HTML serve the same purpose that they do in Python, documentation or removing functionality. You can add a comment containing English text to explain what a program should be doing. You can do the same with a webpage or with a JavaScript program. Or you could comment out a function or a line to see how things behave without it. In HTML, comments start with this interesting 4-character sequence and end with this 3-character sequence. Left angle, bang, hyphen, hyphen begins a comment. Bang, bang, right angle ends a comment. They look a bit like tags. Here I have an HTML fragment, "I think therefore," and then there's a comment, "I am." Je pense, donc je suis. We're going to see how to implement this in our lexical analyzer, but recall that our lexical analyzer was just based on regular expressions. I could recognize these comments with another finite state machine, and all I have to do is just merge these 2 finite state machines together conceptually. If I could have one set of rules describing comments and another set of rules describing all of my other tokens, I'll just put them together into one big machine. It might have too many states for us to be comfortable with, but it is entirely fine for a computer. When we're processing a comment, normal rules don't apply. Let's consider a super tricky comment example. Here we have "Welcome to <b> my," comment that closes the bold tag, "webpage," close the bold tag again. My question for you is how will this render? Which of these words will be bolded? Well, it turns out that when something is in a comment, we ignore it entirely. It's as if it weren't there, so even though this looks like it's closing the bold tag, it does not, and the words "my" and "webpage" will both be bolded. In fact, it's almost as if everything in the comments were entirely erased and had no impact on the final rendering of the webpage at all. And now without the distracting text, it's relatively clear that "my" and "webpage" should both be bolded. Here I've written another HTML fragment that includes a comment, and the quiz for you is--in multiple, multiple choice fashion-- to tell me which of the following HTML tokens--and I'll draw them now-- could be found by our lexer. Check all that apply. Based on this string, assuming that we've added the right rules for comments to our lexer, which of the following would be found? Well, let's go over it together. It looks temptingly like there might be a few left angle brackets, like this one or that one, but if you look carefully, you'll see that those are both part of the comment, so it's as if they were never there, so we don't see any left angles. We do see a left angle slash over here at the end of the string. Any right angles? Yes, right here at the absolute tail end of the string, but note that this one in here did not count. Any strings? "World" looks super tempting, but again, it's inside the comment, so it does not count. Word--and I've intentionally chosen these so that they conflict a little-- word, both "hello" and "confusing" totally apply. So now I'm going to show you how to add HTML style comments to our lexer so that it gets the behavior that we want. Just as we had to list all of the tokens, we're going to have to list all of these possibilities for things we could be doing. Either we're breaking the input down into tokens, or we're handling comments. These 2 possible choices are called lexer states, a word I really don't like because it's super ambiguous. We have states in finite state machines. Let's not have states elsewhere. This particular syntax for specifying them is arbitrary. It's just a function of the library we're using, so I'm going to declare a new state called "htmlcomment," and that's exclusive. If I'm in the middle of processing an HTML comment, I can't be doing anything else. I'm not going to be finding strings or words. Here's my rule for entering this special mode for HTML comments. If I see the beginning marker, <!--, then I want to enter this special HTML comment state and not find words or strings or numbers or tags but instead ignore everything. When I reach the end marker for an HTML comment, I want to jump back to the initial mode, whatever I was doing before, that time when I could find l angle slash and l angle and r angle. By default, that mode is called "INITIAL," all in capital letters. I'm actually going to do one other thing all at the same time. When we're in our special HTML comment mode, we won't use any of our other rules, even our super happy newline rule that's counting the line number, so what I'm going to do is call this string.count function to count the number of newline characters that occur in the token in the entire comment and add those to the current line number. This is a little tricky, so don't worry if this doesn't make sense the first time. Now, we've said what to do when an HTML comment begins, and we've said what to do when it ends, but any other character we see in this special HTML comment mode isn't going to match one of those two rules. Anything that doesn't match one of our rules counts as an error, and what I'm going to say is just skip over that single character in the input. It's part of the comment. I don't even want to see it. This is a lot like writing "pass" except that it gathers up all of the text into one big value so that I can count the newlines later. Again, this is a pretty tricky maneuver. Now I've changed my webpage so that it says "hello." There's an HTML comment with the word comment in it, and then there's the word all, and if I've written all of this code correctly the first time, which really that does not happen in Lake Wobegon, then we'll get a chance to see how this plays out. There was an error on line 22, this line number increment, and it's yelling at me. Let's go back up to line 22. I had split these onto 2 lines so that it would be easier for you to see. But let's not do that because Python hates it. And now with that one simple syntax error fixed, our webpage produces exactly the 2 tokens we expect, hello, starting at position 0, and all, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, all starting at position 23 on line 1. Excellent. So given that we've just seen how to code up HTML comments, let's test out that knowledge. Suppose we have our definition of HTML comments plus a rule for word tokens that are anything that's not a space, a left angle, a right angle, one or more of the above. We return that token, and now I give you the following HTML input fragment, "ob fuscation tuse tangle." For this blue string, for our lexer, we've got word tokens. We've got HTML comments. How many word tokens are we going to find? It turns out that the answer that we're looking for is 3. Ob is one and tuse is another, and it's really tempting to put obtuse together because they're separated by a comment. You think "Boy, if I just remove that comment, they'd be one word, obtuse." But remember, you really want to treat comments as if you were totally erasing them so it leaves a gap. The lexer is entering the HTML comment. Mode, it's coming back. Ob and tuse are really quite separate, and then we've got tangle as the third at the end. All right, so now that we've mastered lexing or breaking up into words HTML, let's turn our attention to JavaScript, the other language we'll be considering in this class. And I'm going to introduce you to JavaScript by jumping right into an example by way of a parable. Over here on the left we see some webpage code, apparently a webpage owned by Steven. Welcome to Steven's webpage. And Steven would really like to compute five factorial, 5 times 4 times 3 times 2 times 1. Over here on the left, we see the HTML source code, and on the right we see the result as it would render. This p tag I haven't introduced you to yet, but it means begin a new paragraph. We'll write out the words "Welcome to." We'll show "Steven" in bold. We've got this five factorial, this bang. The exclamation mark often means factorial in mathematics. Printed in italics you can see it slanted. But unfortunately, Steven is super sad. He can't remember the value of five factorial. Well, this is exactly the sort of thing that a programming language like JavaScript could help us out with. It can carry out computations just like Python, so we can do work in the middle of a webpage. Let's write our first JavaScript script together. Here, this line starting with script type= "text/javascript" and then this document write line, and then ending here with this closing script tag, all of this, these 3 lines together are a JavaScript program embedded inside an HTML webpage. JavaScript programs always begin with this special script tag, and this tag has an argument because there might be multiple types of tags out there in the universe. We've seen tag arguments before with the anchor tag. Here I have an anchor tag where the argument is a hypertext reference. Here I have a script where we're telling the web browser you should treat this as a JavaScript program. This JavaScript program is very simple. It's the equivalent of print "Hello World" in Python. JavaScript's name for the print function is document.write, which we'll sometimes just abbreviate as write. But the semantics, the meaning is largely the same. It's also worth noting that we've put parentheses around the argument to document.write almost as if it were a mathematical function. We can do that in Python. It's allowed, but often we don't. And we've ended the line with a semi-colon, whereas at the end of a Python line we often don't have a semi-colon, but again, you can put semi-colons at the end of Python lines. We just typically don't. Now we're going to try to use the full phenomenal cosmic power of JavaScript to compute five factorial. To do so, I'm going to make a recursive function called--surprise, surprise-- factorial that's going to compute the value. Let's walk through every part of this JavaScript code together. The word function means I'm declaring a function. This is very similar to def in Python. Then I give the name of the function, and then I write the arguments just like I would in Python. In Python I'd have a colon here, but JavaScript requires slightly different punctuation, this open and curly brace, and in this regard it's more like languages such as C or C++ or Java or C#, curly brace languages. Our factorial function is going to be recursive, and every recursive function needs a base case, a time when it stops. Our stopping condition is when n is 0. We could have picked n is less than or equal to 0, n is less than or equal to 1, so I have an if statement that's checking that. Again, in Python this would probably look very, very similar except that we'd use a colon instead of an open and curly brace. If n is 0, we return 1, and I have a semi-colon at the end of all my statements. Then in Python, I would know that I'm done with the if statement because of the tabbing. JavaScript doesn't use that sort of readable tabbing rule to figure out the control flow when an if statement ends, so instead you have to explicitly close off this open and curly brace just like you'd have to close off a tag in HTML or close off parentheses once you start them. We're going to study this a lot more as time goes by. I close off the then branch of my if. I have a semi-colon, and now I have a new return statement, and this is basically just the formula for factorial. It's n times the factorial of n - 1. This part here is a function call, in fact, a recursive function call, just like you'd expect to see in Python. I'm ending the whole thing with a semi-colon. This is the end of my function definition, and at the end of the day I print out-- and the JavaScript version of print is document.write-- factorial of 5, and over here on the right you can actually see it. We've got the 120, which is the correct value for factorial, so what that tells me is that if prettiness matters, I should delete those question marks because now we are super happy because we can compute five factorial using embedded JavaScript in the middle of a webpage, or to put it another way, a way that's a bit more puntastic, [singing] it's a good thing JavaScript can run on the page of Steven. And basically my voice is telling me not to quit my day job. Many of the differences between JavaScript and Python are similar to the differences between American English and British English. Sometimes the spelling changes a bit, or the pronunciation changes a bit, but in general, they are mutually intelligible. It should look very similar, but with 1 or 2 extra letters. JavaScript is big on curly braces. Python is big on tabbing. JavaScript is big on semi-colons. Python not so much. JavaScript really loves parentheses. Python could take them or leave them. Python could have these, could have these, but doesn't have to. They're somewhat optional. And in some sense, preferring one over the other is a bit like preferring Brutus to Caesar. I've heard that Brutus is an honorable man, or at least so Mark Antony told me. They're both entirely reasonable from our perspective. Is this a dagger I see before me? I guess this one must be Brutus, and this one must be Caesar, and you know which one is which because of these convenient labels. Here I've written a new JavaScript function called "ironcrutchli." This one is not recursive, but it takes a formal argument x and then does some reasoning based on x and returns values as a result. I want to make sure that you're following along with JavaScript, so I'm going to have you tell me what this function evaluates to based on a few different inputs. In this fill-in-the-blank quiz, for each one of these inputs, imagine we're calling ironcrutchli on 0, so this 0 is bound to the value of x. What would the output be, similarly for 1, 2, and 9? Let's go through the answers together. If we call ironcrutchli with x as 0, then 0 is less than 2, so we're going to return 0. If we call ironcrutchli when x is 1, 1 is also less than 2, so we still return 0. This function not so exciting thus far. But now we pass in 2 for x, and 2 is not less than 2. It is equal to 2, however, so we're going to return 2 + 1, or 3. And then over here if we pass in 9, 9 is not less than 2, so we're going to return 10. Iron Crutch Li was one of the 8 immortals of traditional Chinese mythology. Not a particularly nice guy, but he did help out the sick. In the previous example, I had highlighted ironcrutchli and x in red. They were identifiers, which is a formal way of saying variable name or function name. Identifiers are textual string descriptions that refer to program elements. Things like factorial, s and tmp are all identifiers. We often call them identifiers because they identify a particular value or storage location. We're going to allow our identifiers to start with lowercase letters or also uppercase letters, and they can finish out with any number of upper or lowercase letters. Here we have another uppercase letter as time goes by, and sometimes people like to use underscores to add readability. That's totally allowed in the identifier, but we'll say not at the beginning. You have to start with a letter, but after that you can have underscores. Here I've shown 6 examples of identifiers, and I would like you to use the interpreter to write an identifier token rule for these sorts of JavaScript identifiers. Try it out using the interpreter. So let's go over the answer together. First, we're going to define a procedure, named: t_identifier. It takes a token as an argument. And the most important part of a token definition is always the regular expression, declaring the class of strings that it matches. We definitely want to allow lower case letters. We also want to allow upper case letters. And you can't start with an underscore or a digit, so this is all, for now. But after this, you could have more lower case letters, more upper case letters--or underscores-- and you can have as many of those as you want. So there's our answer. JavaScript also has support for numbers, and just like in Python they can be whole numbers. They can have decimal fractional parts, or they can be negative. I like all of those, but all of these examples here in blue at the bottom, 1.2.3.4, that has too many decimal points. This is not a number written using digits. This is not a number at all, although I may have its number. That would totally work. Now that we have an intuition for what numbers look like in JavaScript, there's a quiz. I'd like you to define t_number that matches the examples in red but does not match the examples in blue, but normally the value of a token is a string. I want you to convert it to a float before returning. Let me walk you through one way to do this. As always, the most important part of a token definition is the regular expression that it corresponds to. Here we can optionally start with a minus sign. Then we definitely have one or more digits, 867, 3, 1. And then there's a big optional part. We can have a dot and then some number of digits after that. We could have the dot and then some number of digits. -1. is okay or 3.14159. Here we've got 5 trailing digits. Here we've got 0 of them. And this whole dot followed by digits is optional. But remember that the dot has special meaning in regular expressions, so I'm going to need to use a \ to escape it to say we literally mean the period and not any character. Then we turn that string into a floating point number. Then we return it. Just to walk through these again, this part, the optional minus sign, catches either this minus sign or the nothing that's in front of this 3. And this part here is this 1, this 3, or 867. This dot, literally a dot, is this dot, that dot, and I think there was one under here, and then this part is 14159, 5309, or the nothing that's here after this dot. In Python, we can write a comment that extends to the end of the line by prefacing it with the # sign or the pound sign or the hash sign. JavaScript has this same idea, but instead the comments start with // and then continue to the end of the line. This time I'll write the rule for you. Here's a rule corresponding to comments that go to the end of the line in JavaScript. They start with a slash and then another slash, and then you can have anything that's not our special newline character, as many of those as you want, and the maximal munch rule means we're going to eat up all of those characters that we possibly can. And then rather than returning that as a token, we throw it away because it's a comment, documentation for the user. Let's test our knowledge of this rule with a quiz. I've written out 4 sequences of input, and I'd like you to indicate which of these 4 sequences would yield identifier, identifier, number given the rules we've been talking about for JavaScript. You've seen how we define identifiers, how we define numbers, and what starts an end of line comment. Here are 4 different lines. Which ones give us identifier, identifier, number? Let's go through the answers together. Perhaps the easiest to look at is good old Ralph Waldo Emerson. Ralph is one identifier. Emerson is one identifier. 1803 is a number. It's transcendental-tastic. This totally matches the pattern we're looking for. By contrast, Henry is an identifier. Thoreau is an identifier, but these 2 slashes begin an end of line comment, so we'll never see the 1817, so this one does not match. Down here, Marie Curie 1867, this would be identifier, identifier, number, except that the whole thing is canceled out by this end of line comment that starts over here. Then up here, her daughter, Irene, this is one identifier. This connected by an underscore is just one more identifier. Here's a number. We match perfectly so far. It looks like we'd stop matching because of this fourth number, but since it's in a comment, we ignore it, so both of these work. And Marie Curie is relatively well known as a Polish physicist and chemist. She was the first person to hold Nobel prizes, quite a feat, one in physics and one in chemistry, and in fact, she named the element polonium after her home country. Thoreau wrote "Walden," which is relatively well known, a book about being self-reliant and dependable in which he starts on the first page by borrowing an ax from his neighbor. Marie Curie's daughter, Irene, also went on to win a Nobel prize for the discovery of artificial radioactivity. Alright, so you've just finished learning how to specify tokens for languages like HTML and JavaScript. At this point, you might be thinking, boy, so those HTML and JavaScript designers did not make pretty tokens. I just want to mention an experience from my own life. It could be much worse. I once had the opportunity to work on software that did, let's say, collaborative edits. Say that a bunch of people wanted to make changes to a book like Pride and Prejudice by Jane Austin. Suppose that you really want to make it about pandas instead of people, and I really want to make Mr. Darcy nicer because he's a bit snappish in the book as it stands. In theory, we should be able to apply both of these edits together as long as they don't conflict and then someone could download that new version of the book and read it with happy pandas all around. Because I didn't know much about language design at the time, I made all of these editing commands very long and very verbose, including 1 key word token that now lives in infamy for me-- BUTONLYIFITCHANGES--all separated by underscores, 1 word, must be capital letters, which meant oh, if there's nothing that would change in this scene, for example, because it doesn't have Mr. Darcy in it, there's no way to make him happier, then don't do anything so that people don't think they have to redownload the book or redownload that chapter. Because I didn't have any experience with language design, I made this super long token name, and now I'm stuck with it forever. You, too, can find it on Google if you search. So although it may seem now like HTML and JavaScript are totally arbitrary, in fact, some effort has gone into making them concise and relatively easy. I just wanted to mention that it could be worse. I know from personal experience. So once again, it's time to summarize what we've learned in this unit. Just as English sentences could be broken up into words, so can HTML and JavaScript be broken up into tokens, typically separated by spaces. Some of the more complicated token types we looked at were number, word, and string. Since these correspond to sets of strings, we use regular expressions to specify them. I've introduced you to JavaScript and showed you how to use regular expressions to specify core parts of HTML and JavaScript. In the homework for this unit, you'll be given a chance to expand on that knowledge. It'll be fun! In our next exciting episode, we're going to continue our slow but steady progress towards an HTML + JavaScript interpreter. Fun stuff! Hope you join me next time. In this unit, we learned how to specify tokens using regular expressions. We could break down HTML and JavaScript into words, the smallest unit of meaning. In the next part of this class, we're going to learn how to combine those words-- combine those tokens into sentences, into utterances that are starting to make sense. We're going to check them using rules of syntax, just like the rules we have in natural languages. It's an exciting time, and it's a necessary part on our way to making an interpreter for HTML and JavaScript a web browser. I hope you'll join me for our next unit. Last time we finished up breaking up HTML and JavaScript into tokens. We'd specified them by regular expressions, which are implemented by finite state machines. And this has always been one of my favorite parts of programming languages, and it actually sticks in my mind when I was a student taking this in a more traditional classroom, the instructor asked after talking about regular expressions in lexing "Is there anyone interested in doing research?" And this was actually my first step towards becoming a professor, but actually, I was doing really poorly in the class at the time. I was not a very good student, so I went to the professor's office. He said, "Show up if you want to do undergraduate research." I was there, and when I came in the door, there was a second where I could see in his eyes this "You? Not you." But then he quickly sort of changed to a more positive attitude, and I continued to work with him, and that began my career pushing forth the boundaries of human knowledge by studying programming languages. And to some degree, what I want you to take away from a story like this is it's not necessary to have mastered these concepts right at the beginning or the first time you see them. What I really want is for you to master these concepts by the end of the course, so don't feel too bad if the original units have been giving you a bit of difficulty. They gave me a lot of difficulty when I learned them the first time. We finished up with regular expressions, and this time we're going to move on to context-free grammars, the sentences of programming languages. Let's get started. All right, everyone, welcome back. In our last exciting episode, we learned how to take a string or a sentence and use lexical analysis to break it down into a list of tokens or words. And lexical analysis was based on our old best friends regular expressions. And remember that we need to break down HTML or JavaScript source code into tokens and then into valid utterances in order to understand them and build our web browser. However, it turns out that just having a list of tokens or a list of words is not enough. We can still be confused. For example, I've written here 2 collections of words. The first, "Simone de Beauvoir wrote 'The Mandarins,'" and the second, "wrote wrote Simone de de de." Even though this second collection of words uses only words that occur in the first, we like this one, and this one makes us very confused, so just a list of words isn't enough. They have to adhere to a valid structure. There's a subject and a verb and an object, and down here in bag of words 2, it's not really clear what's going on. In particular, we're tempted to say that bag of words #1, "Simone de Beauvoir wrote 'The Mandarins,'" follows English grammar, follows the rules of how we construct sentences or thoughts in English, and the second does not. The grammar for any modern natural language, be it Mandarin Chinese, English, French, admits an infinite number of utterances. But not--and this is super critical--not all utterances, all interesting grammars, rule something out. Provide structure by saying that you can't say gibberish. You have to say something meaningful. Despite the fact that we're going to rule out quite a few bags of words, we're still going to have plenty of room for creativity, and you'll see how in just a minute. Noam Chomsky is a philosopher and a linguist, and in his seminal 1955 work "Syntactic Structures," he suggests that utterances have rules, syntactic rules, and they're governed by formal grammars. The problem with the wrote, wrote, wrote, de, de, de bag of words above is that they don't form a grammatical sentence. We much prefer grammatical sentences. It's easier to interpret them and figure out what they mean. We can write down these formal grammars using a special notation. Here these 5 lines together are my formal grammar, and each one is what is known as a rewrite rule. The words that I've written in blue are called non-terminals. If you have one of these things written in blue, you can rewrite it with whatever is to the right of the arrow. These words that I've written in black never occur on the left of any one of our rewrite rules, so they can never be replaced. Once you get there, you're stuck, and the process terminates. We call them terminals. Using these rules, if I start with sentence, I can rewrite sentence to be subject verb, and then I could rewrite that by picking any one of the rules that has subject on the left. Let's pick students. I've only replaced subject, leaving this verb non-terminal alone. But then I could replace verb with any one of these rules, and at this point I think we're done. The process terminates because I can't replace students or think with anything, so here I've used 1, 2, 3, rewrite rules to start from sentence and end up with a valid utterance. This sort of maneuver with all these arrows is sometimes called a derivation because I was able to derive "students think" starting from sentence using these rewrite rules. Even using this relatively simple grammar, however, I have a few options. Here I've shown another derivation starting with sentence. Sentence goes to subject verb, verb goes to write, subject goes to teachers, and I've produced another string in the language of the grammar. Both "students think" and also "teachers write" can be produced by that grammar. Here I've recopied the grammar. I've abbreviated the non-terminals a bit. Subject became subj, and probably whether or not these are upper or lower case has been a little iffy. Let's allow all of those details for now. I don't care about case. We just care about the concepts in grammar. And now down here I've written 6 possible utterances: students think, teachers write, plus 4 more. It's quiz time. In this multiple, multiple choice quiz, I'd like you to identify which of these 6 utterances could be derived using this grammar starting from sentence. And again, don't worry about exact spelling or upper or lower case. Let's go through it together. Starting from sentence, I can get to subject verb. One possible subject is students. One possible verb is think. We saw this one before. This is definitely in the language of the grammar. However, students teachers is not. That's 2 subjects in a row, and there's just no way to get there starting from sentence. We can turn sentence. We can rewrite it into subject followed by verb, so we can match students at the beginning, but teachers is not a verb. There's just no way to make this happen. Students write, this is one of our subjects, this is one of our verbs. That looks good. Teachers think. Teachers think, that's a subject followed by a verb. That looks good. Teachers write. That also looks good. Think write. These are 2 verbs, and our rules up here say a sentence has to be a subject followed by a verb. This just doesn't match the pattern. And in fact, in this particular grammar, these 4 are all of the strings in the grammar. There are only 4 possibilities. This grammar is perhaps not super exciting, but we're going to get to something, many things, much more exciting than this in just a bit. So in our original version of the grammar, only 4 strings were derivable. Here's our grammar from before. I'm going to add just 1 rule, and that one itty bitty rule is going to give me phenomenal cosmic power. Here I've added a rule to allow us to make compound subjects. This rule is super special awesome. Let me show you a new derivation that uses this new rule. Starting from sentence, we go to subject verb, subject and subject verb, students and subject verb, students and subject think, students and teachers think. Here, right here when we turned this subject into subject and subject, that's when we were using this starred rule. And notice that now, rather than a 2-word sentence, we've produced a 4-word sentence. Amazing. Do students and teachers think? That beggars belief. Both of us think? Teachers certainly don't think. Let's see how this plays out. This new power that we've discussed is called recursion in grammar. You're already familiar with recursion in programming where a function calls itself. Here we can replace a non-terminal subject with that same non-terminal and some other stuff, so just as we might define factorial in terms of factorial of x - 1, we can define subject in terms of subject and subject. This is a recursive rewrite rule, and thus the whole thing is now recursive grammar. Recursive grammars, that's where all the real power is because in essence, it allows a bit of a loop, and this gives us some room for creativity. This is how we can have a finite structure that admits infinite utterances but not all utterances. So now it's time to make sure that you're following along with a quiz. How many utterances, how many sentences, how many strings can our new grammar produce? Recall we've got this new exciting rule, subject goes to subject and subject. Is it 0, 4, 6, 8, 16, or infinite? Choose the single best answer. In fact, it's now infinite. I can reapply this subject goes to subject rule as many times as I want. Students and students and students and teachers think. And if someone were to challenge me and say, "Oh, there are only 5 strings in your grammar," I could always make a new one by using this rule one more time, so for any number you might think are produced, I can always get 1 more, so the number of potential strings I can produce is infinite. That's a huge amount of scope for creativity. And in fact, this general notion is one of the greater glories of context-free grammars. The grammar is finite. We can write it down. But for a non-trivial grammar, the number of possible utterances is infinite. Just by following simple replacement rules, I can make bigger and bigger utterances until I get tired and eventually pick terminals. And in fact, a number of academics, including Chomsky, argued that this is one of the ways or one of the reasons that our finite human brains--I myself am a bear of very little brain-- can produce an infinite number of potential creative ideas. A finite amount of matter can produce an infinite number of utterances. That's a relatively heady notion, so I'm going to skip past it for now. And it turns out that we're going to be able to see this same sort of infinity of possible utterances in computer languages like Python or JavaScript. Wow, my infinity symbol needs work. This gets a label because otherwise you might not be able to tell. In both of these languages, you can write down arithmetic expressions. You can imagine them being generated from an arithmetic expression grammar like this. Exp is just an abbreviation for expression. And in fact, were your student senses tingling? It's time for a quiz on this. Given this arithmetic grammar, check all of these utterances that are valid exp's, that are valid expressions. Starting from expression, which of these 5 options can I generate? Check all that apply. When I'm starting from exp, I can use any of these 3 rules, so in particular I could use the third one and just replace exp with number, so number is definitely in the language of the grammar. It's one of the strings that I can derive. Unfortunately, - number is not. There's no way to get a minus sign without an exp before it. If we take a look at all 3 of our rules, the minus sign only appears once, and there's something before it, so this isn't going to happen. Over here, number + number + number, it looks pretty big, but I could get it by applying this first rewrite rule twice and then turning each one of these expressions into numbers. I've drawn it in kind of this tree format. We will see more on that in a minute, but for now, just imagine I did this because I ran out of space in the corner. Poor planning on my part. Similarly, we could get number - number + number just by getting a minus sign here instead, using rule 2 and rule 1 in combination. Over here, there's no way to get number next to number. Whenever we get multiple expressions on the right-hand side, they're always separated by a terminal. This can't happen, so just to review, this uses rule 1, rule 2, and rule 3 three times. This is rule 1. That's rule 2. That's rule 3 three times in order to derive this string. Recall from our last few units that lexical analysis is the process of breaking up a string into a list of tokens. We are now getting into syntactical analysis, which takes a list of words and tells you if that list of words is a valid derivation in the grammar, follows the rules of the formal grammar, is in the language of the grammar. All 3 of those mean the same thing. Just as the process of doing lexical analysis is sometimes called lexing, the process of doing syntactical analysis is called parsing. Parsing or syntactical analysis involves breaking down a list of tokens to see if it's valid in the grammar, or breaking down a list of words to see if they follow the rules of a language. To make our web browser our interpreter for HTML and JavaScript, we're going to combine the lexing we've already learned about with the parsing that we'll be learning in this unit and the next, and that's going to give us a huge amount of power. Or to put this another way, lexing word rules plus sentence rules from parsing is going to give us a scope and a structure in which to express creative utterances. It's time to put those 2 great tastes together. Here on the left I have a simple expression grammar that mentions numbers as a terminal, and over here on the right I have a rule in our lexer for figuring out when a string is a number, if it matches this particular regular expression. If I put the 2 of these together plus a similar rule for what it means to write a plus sign and what it means to write a minus sign, then I can suddenly tell that more realistic strings like 1 + 2 are valid in our language. 1 matches our rule for number. The plus matches our rule for plus. 2 matches our rule for number, and then this whole utterance, number plus number, is in the language of our grammar for expressions, so this is good. Similarly, 33 is a number. 44 is a number. Minus is the minus sign. This is great. And over here I've got 7 + 2 - 2, or if you like, 7 + or - 2, which I hear is a magic number. Down here at the bottom I have a slightly longer derivation that shows off both the grammar part and also the lexical analysis part. Grammar turns expression into expression plus expression. Lexical analysis turns number into 5 or 6 or some such. Here I've written a slightly more complicated grammar that actually describes part of Python. We can make assignment statements-- stmt is a common abbreviation for statements-- by assigning to an identifier an expression value. Using the rules for identifier and number and +, - and = that we've established previously, I've written down 4 possible utterances. The question for you, multiple, multiple choice, is which of these are statements according to this grammar? Check all that apply. All right, let's go over the possible answers together. We say that a statement has to be an identifier followed by an equals sign followed by an expression. Lata, l-a-t-a, is definitely an identifier using our previous rules. That's a collection of upper and lower case letters that may include an underscore, but the underscore can't come first. This is an identifier, and expression can go directly to number, and 1 is a number, so this is totally valid. Here we have Mangeshkar = 19 + 29. Well, Mangeshkar is longer, but it's still an identifier. It's a collection of letters, and it may have underscores, but it doesn't. And then we have the equals sign. That matches. And now we're going to use this rule here, expression goes to expression + expression to get this + sign, and then expression will go to number for 19, and expression will go to number for 29. I like this. Here we have Lata = Lata + 1. This one is tricky because it's totally valid in Python, but it's not valid in this grammar. I haven't said that expression can go to identifier, so Lata is an identifier. The equals sign is an equals sign. But over here I need something like 1 + 1. I don't yet have a rule that would allow me to have Lata + 1. If I had this mysterious fifth rule, then this would be in the language of the grammar. But I don't yet, so it isn't. And then over here, Mangeshkar = 25,000 - 1, that's an identifier =, and now we're going to use this rule here, expression - expression. This totally works out. Lata Mangeshkar is a famous Indian playback singer. She's recorded over 25,000 songs, a world record for quite some time, and she's also received India's highest civilian honor. Often both natural languages and programming languages have optional parts that don't have to appear in every utterance. For example, "I think" is a totally valid sentence, but so is "I think correctly," where we've added the adverb "correctly" that modified the verb "think." You don't need to do this, though. You can leave it out. The sentence on the left is perfectly fine. We're going to want to represent this optional construction, this optional adverb, in our formal grammar. Here on the bottom half of the screen I've drawn a slightly more complicated grammar. Sentence goes to optional adjective, subject, verb. Subject and verb work a lot like they did before. This time our subjects are either William or Tell, and our verb is either shoots or bows. But our optional adjective can either be the adjective "accurate" or it can be nothing. It disappears. We can either leave this blank, or if you like, we could write that same epsilon we used to have there when we were talking about finite state machines that means the empty string or no input. Looking at this grammar, I have a quiz for you. Fill in the blank. Starting from sentence, how many valid utterances are there? How many strings can we make in this language? How many different things can this formal grammar produce? The answer is 8. Let's go through it together to see why. Sentence only has one re-write rule. These are sometimes called "production rules" as well. Only one production rule. Only one thing to do with it. We're always going to get started with optional adjective followed by subject followed by verb. This could go to accurate or nothing. The subject could go to William or Tell. The verbs could go to shoots or bows. We have two choices here, two choices in the middle, and two choices at the end. When we multiply that out, we get eight possibilities-- accurate William shoots, accurate William bows, accurate Tell shoots, accurate Tell bows, William shoots, William bows, Tell shoots, Tell bows--eight possibilities in total. William Tell was a 15th century Swiss folk her. Famously, he did not bow. He was requested to bow to the hat of a city leader or some such. In exchange, he was asked to shoot--or offered to shoot--the apple off of his son's head, using a crossbow. This is not a crossbow. At least two of the sentences above--William Bows, Tell bows, accurate William bows, accurate Tell bows--four of them didn't happen as far as the story goes. Even if you're not familiar with this story, you may have heard the overture. It's actually quite a bit of fun. In the past few units we've used regular expressions to classify or layout sets of strings. It turns out that grammars can encode all of these regular languages or regular expressions that we've been working with previously. Here I've written a grammar for number that's going to recognize exactly the same language, exactly the same set of strings as the regular expression above. We can rewrite number to be a digit followed by more digits. This construction is meant to mimic or get the same idea as this plus. We need at least one, but we could have some more. Down here I've just listed out all of the digits longhand. Well, I haven't on this particular page but you could imagine I could write out 2 through 8 as optional alternate re-write rules in our grammar. More digits is where a lot of the action happens. One possibility is that we have one digit followed by potentially even more, and another is that we give up. I could write epsilon. This means more_digits goes to nothing. For example, down here at the bottom, I have a derivation starting with number getting to the number 42. Number goes to digit more-digits, using our first rule--rule number one. Then we're going to turn more digits into digit more_digit, using rule number 2. Then--oh my gosh, classic professor mistake--you cannot take me anywhere. Shwoop--oh look. It wraps. That that amazing. The from digit digit more_digits, we're going to turn more_digits into the empty string, using rule three. Now we're left with digit digit nothing. I'm going to turn that second digit into a 2--this empty string isn't really there. Then I'll turn that first digit into a four. Huzzah. That was not a proof, but it just so happens that grammars are strictly greater, have more expressive power than regular expressions. Anything we could specify with a regular expression, we can also specify with a grammar. Let's try it out. Here's another regular expression: p plus followed by i question mark. I'm going to start writing out the grammar for it. Uh oh. Here I've almost written the grammar but I'm going to need you to help me out. I've left two blanks. What I want you to do is fill in the blanks so that the regular expression and the grammar have the same language, accept exactly the same set of strings. Now let's take a look. This was a potentially tricky quiz. Don't feel bad if you had a little trouble with it. We want this pplus nonterminal to correspond to one or more Ps. No matter which branch you take here, you're definitely getting at least one P, but we need you to have the chance to get more. This option, pplus goes to P, corresponds to picking just one. Pplus goes to P followed by pplus--this recursive rewrite rule Gives you the possibility to have as many as you want--possibly even infinite. We've seen that before with expression goes to expression plus expression. Over here, this i-question mark is supposed to relate to i-option. One possibility is that you don’t want to write an i at all, but another possibility is that you do. Here this question mark means have either 1 or 0, this the rule for having 1, and this is the rule for having 0. Some strings in this language or p, pi, ppi--that sort of thing. In fact, if you have a bit of a musical theater bent, you could imagine context-free grammars singing across to regular expressions the classic line from Annie Get Your Gun, "Anything you can do, I can do better. I can do anything better than you." To which, classically, the opponent replies, "Can you bake a pie?" "No." "Neither can I." But in fact, any regular expression relating to pi or something similar, as we've seen above, can be handled both by our regular expression protagonist and our grammar protagonist. Just a fun little interlude. Using formal terminology, regular expressions describe regular languages. Remember that officially a language is a set of strings. These grammars that we've been introducing describe something new-- context-free languages. For now, context free just means that if you have a rule A can be replaces by B in your grammar and you have an A, you can replace it with a B regardless of what this nearby context is as long as you hold the context the same. If I can use the rule now, I can also use it if there's no x on one side, no z on the other, if there's nothing on the left, if there's nothing on the right, if there are flying monkeys on the left and flying monkeys on the right regardless of the context I can apply this rule. The set of languages that can be described by re-write rules or grammers like this are called "context-free languages." All the formal grammars we are going over describe context-free languages-- a more powerful set of string than our old friends the regular languages. Here I've drawn a little chart showing three different regular expression forms and the corresponding context-free grammar forms on the right. If you had a regular expression concatenation-- regular expression a followed by regular expression b-- we could build a grammar than did the same thing just by putting a and b next to each other on the right-hand side. If you had a star--regular expression a*--we could do the same thing-- the same effect of having zero or more a's--with two rules. Either we have nothing or we have an a followed by zero or more a's. Finally, here we have regular expression disjunction or choice--either a or b-- that's easy to write with two separate grammar rules. G goes to a or g goes to b. For all three of these cases and regular expressions there is something corresponding we can do in the world of context-free grammars. Now, I haven't shown you how to do something like a+, but remember that a+ is just a a*. I've already shown you how to do concatenation and the star. In theory, you could compose it over here as well. At this point it might seem like regular expressions and context-free grammars are equal, but they are not. Consider this grammar. It's time for you to test your knowledge by thinking about which of these five utterances are in the language of the grammar. Check all the apply. Which of these give strings could be derived from P in this grammar. Here are the two rules in this grammar, P goes to open parenthesis, P closed parenthesis, or P goes to nothing and can be erased. Here I have various combinations of open and closed parentheses. Stare at it for a while and tell me which of these five sequences of strings could be derived from P in this grammar. Check all that apply. All right. The question was which of these five strings are in the language of this grammar. The first one looks pretty good. I just apply rule 1. P goes to open P close and then rule two to get rid of the P, and I'm in like Flynn. How about this? Well, I'm going to apply rule one twice. I'll end up with open open P close close, and then I'll use rule two to get rid of the P. Similarly, over here I'm going to apply rule one three times. Open open open P close close close. Then I'll apply rule two to get rid of the P. Totally in the language of our grammar. But this--tsk, tsk, tsk--this is going to be problematic. Just an open parenthesis. If you look over here, there's actually no way to make just a lonely open parenthesis that does not have a matching close parenthesis. There's only one rule that introduces the open parenthesis, and it makes just as many close parentheses at the same time. This cannot happen. Here this looks good. These parentheses match, open close open close, but if you take a look at this grammar, there is never a way to have an open after a close. I can apply this rule as many times as I want in this pattern, but I'm never going to end up making something like this--not as written. We could write a grammar for this, but not currently shown. This sort of system is known a balanced parentheses. The parentheses are balanced, because the number on the left equals the number on the right. One to one, two to two, three to three. In fact, you could imagine some sort of scale that'd have to be exactly equal-- two openings, two closings. Balanced parentheses. This is a super-important problem in computer science. It's going to turn out that balanced parentheses are one of the first things we've seen that are too complicated to be captured accurately by our old, dearest friend, the regular expressions. We're going to need something like a context-free grammar to do it. Here I've written a grammar for balanced parentheses, and over here to the right, I've tried to write a regular expression that catches the same sort of thing-- an open parenthesis possibly repeated and a closed parenthesis possibly repeated. Remember that these slashes are escape sequences to say, oh, I really mean the open parentheses, and I don't really mean some sort of grouping. However, it's going to turn out that the best-laid plans don't quite work out. My regular expression is a be too permissive, and there are going to be some strings that it accepts but the grammar does not-- some strings that it accepts that aren't really balanced parentheses. In this multiple multiple choice quiz, I'd like you to tell me for these five strings, for these five utterances, which ones are in "r," the regular expression, but not in "P", the grammar for parentheses. Think about it. Well, let's go through it. This is, again, a tricky quiz because it requires two kinds of reasoning. each string, we have to figure out whether it's in r or not and also whether it's in P or not. We just saw in the previous quiz that unbalanced parentheses, like this single open, are not in P. This is looking good so far. For it to be part of the answer we want, we'd have to show that it is in r. If we look carefully, in fact it is. Here's how I'm going to do it. For this first opening parentheses for this star, I'm going to repeat it one time. Then for this closing parentheses for this totally different star, I'm going to repeat it zero times. I'm going to end up with one open and zero closes. This unbalanced open parenthesis is in the regular expression, but not in the language of the grammar. How about this balanced open followed by close? Well, that is in the language of P. I apply rule one and then rule two to get rid of the P. I fails our second clause. How about this? Open close close? This is unbalanced. The scales would be tipped to the right. It's not in P. We're looking good so far. Is it in r? Yes. For this star, I'm going to repeat is once. For this totally unrelated star, I'm going to repeat it twice. Both of these--open-open-close-close and open-open-open-close-close-close-- they're all in P, so they're disqualified because of clause 2. In fact, all of the strings here are in the language of r. It's just that these three are also in the language of P. We've proved that one particular regular expression didn't do the job. It was too permissive, but that doesn't mean that there isn't a smarter, super tricky regular expression that would capture balanced parentheses. However, it just so happens that there isn't. It turns out that it's impossible to capture balanced parentheses with a regular expression. A formal proof may be presented in the supplemental material, but for now I'm just going to give the intuition. Here's what we want: an open parenthesis followed by a close parenthesis, each repeated the same number of times. This intuition or this notation is meant to remind you of mathematics. X-squared is just x times x, so open parenthesis raised to the power of 2 would just be two open parentheses next to each other in a string. What we really want is open parenthesis to the power of N, closed parenthesis to the power of N, but this has to be the same N in order for the parentheses to be balanced. Unfortunately, all we can write with regular expressions is open parenthesis star close parenthesis star. In regular expressions, these two stars need not be the same. In fact, if you think about the finite state machine interpretation of regular expressions, remember when we were simulating finite state machines the only thing we really had to remember was where we currently were and what the input was. We didn't really remember where we'd come from. In order to matchup the same number of opens and closes, we'd have to where we came from. Regular expressions just don't have that kind of memory. With regular expressions, I can say zero or more open parentheses followed by zero or more close parentheses, but those two numbers don't have to be the same. Regular expressions can't always remember to different numbers and force them to be equal. This notion of balanced parentheses is worth paying a lot of attention to, because balanced parentheses are everywhere in HTML and JavaScript. These tags for beginning bold and beginning italics, ending italics and ending bold, have to be perfectly nested for valid HTML. It's as if the beginning bold b were some sort of parenthesis and the ending bold b were a closed parenthesis. Then the italic tags maybe were angle brackets or some other type of parentheses that really had to match up. These have to be perfectly nested, and they have to open and close each other in tandem. Open the bold, open the italics, close the italics, close the bold. We can see the same sort of thing in a Python or Javascript assignment. These two parentheses match up. So do these two, and they're perfectly nested. Here we see an example of malformed HTML. The tags, the parentheses of HTML, don't match up properly. Let's see what happens when I try to draw that same sort of diagram. Oh, there's no way to connect these two i's without crossing the lines and crashing over each other. This tells us that the parentheses do not match. We could also look at it like this. If we view it as a mathematical formula, the normal parentheses and the square parentheses don't open and close in the right order. In order for something to be valid HTML, tag openings and tag closings must be perfectly nested. This is not valid HTML. For our web browser to work correctly, we're going to need to tell the difference. Let's check out knowledge of this with a quiz. Here I've written five different utterances or five different sentences variously in JavaScript or Python or in HTML. In this multiple multiple choice quiz, I'd like you to indicate to me which of these have well-balanced parentheses and/or HTML tags. Let's start here--palace minus walk. This is a lot like 5 minus 3 if "palace" and "walk" are identifiers. Here the parentheses are balanced. We like this utterance. Here we start a bold tag and right "naguib," but we never close off the bold tag. This is not balanced. Here we start an italics tag and write "mahfouz," and then we close off the italics tag. This is well-balanced. Here we write open "pulitzer" plus open "prize" close close-- open parenthesis, open parenthesis, close, close. This one matches there. This one matches there. These are well-balanced. You might think there's no reason to put "prize" in parentheses, and you might not if you were writing, but the grammar--the language-- allows it as long as the parentheses are balanced. Over here this one is particularly tricky. We have a close parenthesis followed by "1956" followed by an open parenthesis. Now, the number of open and close parentheses is the same, so you might think it's balanced, but they're in the wrong order. We need to do the opening before the closing. This does not match. "Naguib Mahfouz" is a relatively famous Egyptian writer. He wrote Palace Walk. It's set in about 1917 around the end of World War I in Egypt in Cairo. It details what goes on with Al-Sayyid Ahmad Abd al-Jawad and his family. My best attempt at doodling Egypt or Cairo is someone next to a pyramid. You can tell it's a pyramid because it's clearly labeled. Now that we have an understanding of formal grammars, we're going to need to use them to understand or describe HTML and JavaScript. We're going to design together formal grammars that exactly capture HTML and JavaScript or at least interesting subsets of them. If we were trying to understand English sentences, there is a special kind of diagram we could make. Here I have a very high level partial grammar for English. A sentence has a noun phrase, a verb phrase, and an object. A noun phrase is just a decorated noun, like maybe a noun with an adjective in front of it. A verb phrase is a decorated verb, maybe a verb with an adverb in front of it. Then the object could be a noun phrase or a noun or something more complicated. For example, here is a sentence: "Wes reads Romance of the Three Kingdoms." Now, there are various different ways to diagram English sentences. We'll do something relatively simple. We just want to indicate which part matches which grammatical form. Our noun phrase is going to be "Wes." Our verb phrase is "reads." The object is "Romance of the Three Kingdoms." We could divide it up so that the object falls under the phrase or that we draw these slightly differently, but mostly we want to know which part goes where. Who is doing the reading? Is it Wes or the book. This sort or diagram will help us figure that out. In fact, in formal languages or with a grammar like this, there is a more common way, a more pictoral way of representing these sentences. We can draw something that looks a bit like an inverted tree. I'm going to take each one of these productive rules and puts its left hand-side at the top, and then give it children, or branches, based on which rule is chosen and what's available on the right. Here we have a sort of a pyramid-like shape, or what's officially called a parse tree. Remember that syntactic analysis is sometimes called parsing. This might not look like a tree, but what you want to do is imagine the tree growing upside down. Here is our tree, and at various places--although it's starting with the trunk or the root-- it branches out, and all of these intermediate parts in the tree represent none terminals in the grammar. All of the leaves right at the end represent terminals or tokens in the final sentence or utterance. This is called a parse tree by longstanding tradition. We draw them upside down, starting at the root with the start nonterminal. While we're here, you too should consider reading Romance of the Three Kingdoms. Written in the 14th century, it's a Chinese historical novel about the end of the Han Dynasty. Good stuff. Here's one of our favorite grammars from before--a simple arithmetic expression grammar. Let's say that our input is 1 plus 2 plus 3. Here is a possible parse tree. We start at the top, at the root, with our nonterminal expression. Each time we have a number of children equal to the number of symbols to the right of the arrow. If I'm using expression goes to expression plus expression, I have one node with three children. I need to get 1 plus 2 plus 3, so I'm going to need to use this first rule at least twice--once to get this plus sign and once to get that one. Here I'm using it once--one instance of rule one. Here I'm using it twice--another instance of rule one. You'll note that they overlap. The first time we use this rule we started drawing this part of the tree. This expression node was the result. The second time, it was the thing we were choosing to expand. This is normal. This represents the recursive structure of a grammar. In a parse tree like this, these parts at the that have no children are called "leaves." The parts in the middle are called "nodes." Sometimes the leaves are called "leaf nodes," which is a bit ambiguous. These are always going to be terminals. The intermediate nodes are always going to be nonterminals. Here I have a grammar that we've seen before, but I've abbreviated it still further. Instead of identifier, I've just written "id," and instead of number, I've just written num. This sort of abbreviation is all too common in computer science. Programmers can't help it. Unfortunately, it's a bit of a vice, because while it's easy for me to see what's going on it can be hard for someone reading it later--myself included--to tell what my variable names mean. Whenever possible, you should take the time to make your variable names as descriptive as possible. Add lots of comments. It turns out that 90% of software is maintenance. Just like a popular book is read many more times than it's written, a program is read or maintained or executed many more times than it's written. It's worth taking the time to do it right the first time. That said, clearly I'm not, so this must be one of those do what I say and not what I do back professor sorts of maneuvers. Regardless, back on track. Here's the grammar. Statement goes to identifier equals expression, and expression is the same sort of arithmetic we've seen before. We're not going to consider this particular sentence "yggdrasil equals 6 minus 5. I've written out a parse tree--a bit squashed at the bottom but still recognizable-- for this phrase "yggdrasil equals 6 minus 5," but I've forgotten two labels. It's quiz time. Fill in the blanks. What would have to go in each of these blanks in order to this parse tree to match this input utterance according to this grammar? Well, our rule for statement is statement goes to id equals expression, so this box has expression in it. Then expression goes to expression minus expression. Since this number was 6, this number must be 5. By the way, Yggdrasil is worth knowing about. It's the World Tree in Norse mythology. My drawing of it is clearly not to scale. One trait shared by programming languages and natural languages is ambiguity. Consider the sentence "I saw Jane Austen using binoculars." It's relatively clear what this means, right? Here's me. I have binoculars or perhaps pants, but let's image that they're binoculars. I'm looking through them. Over here in the distance I see Jane Austen. We can tell it's Jane Austen, because she's in a park. Mansfield Park, let's say. I am using the binoculars to see Jane Austen. However, if you think about it there's an alternative implementation or an alternative interpretation of this sentence-- another way to look at it that's also perfectly valid. Here in this alternative interpretation, I see with my naked eye Jane Austen. She is using binoculars to look at something else. Maybe she's spying on an Abbey over here. Let's call it Northanger Abbey. Actually it looks a bit more like a barn that was badly painted, but let's imagine. Both of the interpretations are correct or the sentence is ambiguous. It's not clear whether using binoculars modifies Jane Austen. Is she the person using binoculars? Or whether using binoculars modifies "I saw." The picture on the left that's how I'm seeing. It's quiz time--a quiz on ambiguity. Consider the expression 1 minus 2 plus 3. Keeping ambiguity in mind, if this were a Python or JavaScript or even just on the whiteboard or on a piece of paper in mathematics, this is a mathematical expression. What might it evaluate to? I've got four choices in this multiple multiple choice quiz. Check all that apply. Let's take a look. Here is one possible reading. I'm going to take 1 and subtract 2 so I have negative 1 plus 3, and that's going to give me 2, so 2 is definitely an answer. If I do 1 - 2 first, I'll have -1 plus 3. However, what if I want to do this 2 + 3 first? I'll have 1 minus 2 plus 3 or 1 minus 5. That's going to give me -4. Zero and 4 aren't really reachable using this expression, but depending on whether you do the subtraction first or the addition first, you could either get 2 or -4. This sentence is ambiguous. We're not sure what it means or it has multiple meanings just like the Jane Austen binoculars example from before. As the previous example suggests, we can use parentheses to control ambiguity. Here I've taken our expression grammar from before and updated it with a new rewrite rule. Now expression can be replaced by open parentheses, expression, close parentheses. This should totally remind us up the P goes to open P close rule from before for balanced parentheses. It's going to behave mostly the same way. With this new grammar, both of these utterances-- open 1 minus 2 plus 3 and 1 minus open 2 plus 3 close-- both of them are in the language of this grammar. However, while both of these are okay, so is this one. It doesn't forbid the ambiguous one. It just allows us to have more precise renditions. We've solved some of the problem. If we're thinking ahead, we can use parentheses, but we're still allowing ambiguous phrasing. Here I've drawn our favorite utterance from before--1 minus 2 plus 3-- and I've written out two different parse trees for it. This one corresponds to 1 minus 2 plus 3. At the top level we're subtracting, and then the 2 plus 3 are grouped together. This one corresponds to 1 minus 2 plus 3. At the top level we're adding, and the 1 minus 2 is grouped together. Formally, we say that a grammar is ambiguous if there is at least one string in it-- 1 minus 2 plus 3 and that single string has more than one parse tree. Here I've drawn very stylized versions of the parse trees. If you can find even one string for which this is true, officially the whole grammar is ambiguous. Here I've written a number of strings and a number of utterances. We're going to use it to check our knowledge of ambiguity. We've got seven strings here, and what I'd like you to do in this multiple-choice quiz, is check each one that has more than one parse tree in our expression grammar. Let's go through these and find an example I'm going to focus my attention here. This could either be 1 minus 2 minus 3 or 1 minus 2 minus 3. This ends up being 2--1 minus -1. This ends up being -4. Very different answers. The parse tree for this interpretation looks a bit like this. It's left heavy with this other subtraction--1 minus 2--down and to the left. Over here the parse tree would be right heavy. Now, I'm not drawing all the nodes in the parse tree just to save a bit of time. Mostly, I'm highlighting its shape. This is an example of a string that has more than one parse tree in our grammar. Similarly, this bigger string has more than one parse tree in our grammar. It might even have four different parse trees, possibly even more. You'd have to try that and find out. Notably, it contains 1 minus 2 minus 3 as a subpart. Even if this -4 at the end is perfectly unambiguous, it still has exactly the same problems we saw here. It still has at least two parse trees. It's even worse than its friend two lines above. If you look carefully, all of the other examples don't demonstrate ambiguity. Each one of these has exactly one parse tree. Even this big complicated thing at the bottom only has one parse tree. It's perfectly balanced--1 minus 2 on the left, 3 minus for on the right. Since both HTML and JavaScript have some essential ambiguity, we needed to handle that before we could move farther with our web browser. But now that we know a bit more about grammars and ambiguity, we can actually move onto making grammars for HTML and JavaScript. Just to remind you, here's an example HTML utterance, "Welcome to my webpage!" Here I've drawn a relatively simple grammar for a surprisingly large subset of HTML. One of the first challenges that we'll have to deal with is that a webpage can have a list of words, like "welcome to my webpage." Our starting nonterminal, HTML, has a recursive structure. Using this rule, HTML goes to element HTML, we can apply rule one over and over again to get as many elements as we need. Maybe one, two, three, four for welcome to my webpage. Then eventually when we're done replace with epsilon or the empty set. Element can either be a word, like "welcome to my webpage," or the beginning of a nested tag. Here tag-open and tag-close are a lot like open parenthesis and close parenthesis. Whenever we make one, we're going to make the other. Then in here tag_open is <word> and tag_close is </word>. For example, this part matches a tag_open, and this text matches a tax_closed. Actually, as it stands, I'm only allowing a single word to be inside any tag. Inside these bold tags, we've got quite a lot of stuff going on. I'll show you the power of a recursive grammar. Watch this trick. Now at the top level, an HTML document is a list of elements, as many as you like. Each one of those elements may themselves be a tag, and inside tags we have another list of elements--another, in essence, entire webpage. Here at the top level, we just have one--tag_open for bold. But inside it there are four elements--the word welcome, the word to, the tag_open for my, and the word for webpage. I'm going to draw the parse tree for this utterance using our grammar. I'm going to use "elt" to abbreviate for element. I'm going to use "to" for tag_open and "tc" for tag_close. Now, I've only drawn or sketched out a small portion, maybe about half, of this parse tree, but we're still going to be able to see things match up by comparing the leaves-- remember a leaf is an node without any children-- to what we saw in the original string. Here my first leaf, working my way down and to the left, is this open left angle bracket, and that matches up here. My next is this b, which matches up here--match up there. Then after that tag_open, there is an HTML, which is an element list, and the first one is the word "welcome." The next one is the word "to." Now, although this tree structure is cumbersome for us, it's very convenient for computers, because it tells us exactly which part of the tree to draw or to apply in a certain manner. It might not be obvious which word should be bolded or which word should be italicized, but if I have a tag_open and a tag_close, this entire subtree is influenced by this tag. How much of the webpage is bolded? Exactly this part over here. The bold's great, great uncle or something like that. Go up a few, over one to the right, and then back down. We're going to use this special structuring to help write our web browser. Here I've written two partial HTML utterances, but I've left some blanks. This makes it entirely reasonable for you to come in and put things right by adding a small number of characters--the smallest you can-- to fill in each blank and make it valid HTML according to previous grammar. Remember that mostly means the tags have to match up correctly. Let's go through the answers together. For sentence 1, this open tag for bold--bold Baroque music!-- must be paired, must be balanced with a closed tag for bold. That looks like this. It's the left-angle slash token. Then the bold closes off. Down here Johann Sebastian Bach was-- this looks like the beginning of an italics tag, and you see that we're closing it off later. For this to be valid HTML, we really need to make this a well-formed tag. Johann Sebastian Bach was German. In fact, he was born around 1685 and is known for his fugues. They repeat in a structure that's actually surprisingly similar to regular expressions or context-free grammars. More on that later. Now that we know how to specify grammars for well-balanced expressions and arithmetic and well-balanced webpage tags in HTML, we're going to return our attention to JavaScript. JavaScript is actually very similar to Python. Just like I showed you a formal grammar for HTML, we're going to work our way up to seeing a formal grammar for JavaScript. But before we get there, I just want to make sure that we really understand how JavaScript programs are interpreted. I'm going to show you a few more in Python and in JavaScript for comparison. Over here on the left, I have a Python function that computes the absolute value of its integer argument. If you give me a negative number, like -5, I will return positive 5. If you give me a positive number, like +9 million, I will return 9 million. The return value of this function is always either a zero a positive number. Now I'm going to write the same thing in JavaScript to provide for a comparison. Everything I've drawn in blue is a special keyword or punctuation mark used by the language. For example, to define a function in Python we use "def." In JavaScript, we write out the word function, but then it's still our choice what to call it-- I'm called it "absval" in both cases-- and how many parameters it should receive and what they're names are. In both cases, we have one parameter named x. In Python we use colons and tabbing to tell what the body of a function is, what the then branch for an if is, what the else branch for an if is. In JavaScript, we use curly braces and closing curly braces to denote this sort of lexical or syntactic scope. This is sort of curly brace 1, and it matches up with closed curly brace 1 over here, 2 matches up with 2, and 3 matches up with 3. But in general the logical structure, the flow or the meaning, is the same. In both cases we check to see if x is less than 0, and we return 0 minus x in that case, or just x alone in the other case. One of the most important operations in any language is printing out information, displaying it to the screen so that we can see the result of computation or just to help us debug. In Python we use the print procedure. We pass it a bunch of strings. Here I'm adding together the strings "hello" and exclamation mart to make a very enthusiastic greet--"hello!" Over here on the right, I'm showing the same thing in JavaScript. The equivalent of "print" is "document.write" or perhaps just "write." In this class, we'll almost always abbreviate it down to just "write" to save space. If you're familiar with object-oriented programming, which is not required for this class, you might guess what the dot is about. We might talk more about that later. One of the key differences, though, is that all of our JavaScript functions have to have these open and close parentheses like a mathematical function has parentheses around its argument. Here I've written a Python procedure called uptoten. If the argument you pass in in less than 10, it returns that argument, so if you pass in 5, it's going to return 5. But it clamps values at 10. If you pass in 15, I'm just going to return 10. I just showed you the similarity between Python and JavaScript before. I would like you to write a JavaScript program. Because we're going to be write a web browser that deals with JavaScript as strings, I would like you to write your JavaScript program as one big string constant. Call it "javascript" and submit via the interpreter. You should declare a JavaScript function called uptoten that takes and argument x and does exactly the same thing as this Python one. Translate this Python code into JavaScript and then put it in this big string. Let's go through it together. The JavaScript equivalent of def is function. We write out the keyword function. Then we pick a name for our function. I asked you to call it uptoten. We mention all of its arguments, and then we use an opening curly brace instead of colon. The word if remains unchanged. Less than is unchanged. But again, instead of a colon we're going to use an opening curly brace. Here is our answer. If x is less than 10, we return x. Otherwise, we return 10. Again, the big differences are these curly braces, which must be balanced. They have to match up, but we already know how to do that instead of colons and indenting. It's worth noting that although we changed some keywords-- they had a different spelling where it's almost as if we had to translate them into a different language-- the underlying meaning was the same in both languages. We can translate programs, functions between Python and JavaScript provided that we know both of them. In linguistics, people will sometimes talk about a universal grammar as there may be some grammar that would sit behind and describe Python, JavaScript, English, and French. I don't want to get into that for natural languages, but we will see either in this class or in subsequent ones, that for computer languages like Python or JavaScript, C and C++, Visual Basic, C Sharp, OCaml, Free Basic, they're all the same in a very strong sense. They're all Turing-complete. I'm not going to much detail now, but it suffices to say that Python and JavaScript are equally powerful. Any thought that I can think in one I can also think in the others. Now I'm going to bite the bullet and actually write out a partial grammar for JavaScript. This is only a partial grammar because it only handles expressions, and it only handles some of the expressions. An expression can either be an identifier--like a variable name x or a function like sine or absval, a number--1, 3.5, -2, a string--like "hello" in quotes, literal constants--like True or even False. These are the equivalent of numbers, but for the Booleans there are only two numbers--True and False-- and then a large number of binary operators. If you have two expressions, you can add them together, subtract them, multiply them, divide them--watch out for division by zero. You can compare them to see if one is less than the other. You can compare them to see if they're exactly equal. If they're Booleans, you can check to see if the first is true and the second is true. Just a little note--if you haven't run into this before-- two ampersands means "and" and two vertical bars means "or." In Python where you might write and or or, in JavaScript you use these binary operator symbols instead. Just as we have less than here, there'd also be greater than, greater than or equal to, less than or equal to, and many more. This JavaScript expression grammar should be familiar to you, because aside from some minor details of spelling like the equal signs here or the capital word "TRUE" to mean true. It should be very similar to Python. Now it's quiz time just to show that a lot of your knowledge about Python's grammar and the grammar fragment I showed you before, will translate into you being able to write JavaScript expression. I've written here four JavaScript expressions--a, b, c, and d-- and each one contains a blank. I'd like you to fill in each blank with a single token, a single terminal, that causes the entire expressions to evaluate to True. Try it out. This is a bit of a puzzle, and you'll sort of have to work backwards. What would this blank have to be for 1 plus a blank to be equal to 2? Let's go through it together. 1 plus blank equals 2, this is pretty much just 1. 1 plus 1 equals 2. Just like in Python, JavaScript supports string concatenation using addition. I didn't tell you about this explicitly, but I did tell you to use your Python intuition. We're going to fill in this blank with one as well, but this one is a string O-N-E. The string P-H plus the string O-N-E will equal the string P-H-O-N-E. Over here this is perhaps the trickiest on the screen. In order for this whole expression to be True, both of these sub-expressions, both of these conjuncts if you prefer mathematics have to be true. X must be equal to 8 and this complicated math over here must also be true. Well, if x is equal to 8 then x divided by 2 is 4. X divided by 2 equals 4 should return True. This'll be true on the left and true on the right. Finally, over here, what's anything that we could put in this blank that would possibly make this expression turn true? J\ust write out the Boolean constant True. If we make analogy with natural languages, if expressions like "tmp" are noun phrases, then operators like "assignment" are verbs and entire statements like tmp gets 5 are sentences. This whole thing together is a statement. It involves two expressions--tmp an identifier, 5 a number-- and an operator--the assignment operator. Just as I might write the English sentence, j becomes 3--perhaps it's her birthday today, I can write the JavaScript assignment statement, j becomes 3. J is assigned the value 3. Similarity between the syntactic elements--the subject, verb, object, and punctuation. Subject- verb, object, and punctuation. Identifier, operator, expression, semicolon is relatively direct. Now that we have an intuition for statements, lets add them to our JavaScript formal grammar. One of the most common kinds of statements is the assignment statement where we have an identifier on a left-hand side of an equal sign and then an arbitrary expression on the right--x becomes equal to 5. Another kind of statement is the return statement. At the end of absolute value or Fibonacci or factorial or almost any function or procedure we want to return with the final value, return an arbitrary expression that becomes the value of the function. There are also statements that influence what gets executed and under which conditions. Formally, these statements are said to refer to control flow because they guard how execution flows through your procedure. The if statement checks to see if a certain expression is true, and if it's true, then we execute the then branch. There is also an if then else. If the expression is true the then branch else the else branch. I haven't said what a compound statement is, although since we've seen JavaScript before we're going to guess that it involves those curly braces. Let's write it out right now. A compound statement is an opening curly brace, a closing curly brace, and some statements in the middle. This is a list of statements terminated by semicolons. I'm going to show you how that works. Here I've added a recursive grammar rule. Statements can be one statement followed by a semicolon followed by as many more statements as you like, or you can decide that you're done and replace it with nothing. Or if you like, we'll draw the epsilon there to mean the empty string. For the subset of JavaScript that we'll be handling in this class, this grammar gives more details about what's possible. In addition to expressions, we have statements that build upon expressions. Here I have written six possible JavaScript statements. I ask you which are valid stmt according to our grammar. That is, if you start from the statement nonterminal, which of these six can you derive using all the rules that we've seen in our grammar so far. This is the happy-fun quiz. Well, x equals three is certainly a statement. We've seen examples like this before. You might have thought that a statement has to end in a semicolon, but if we scroll back to our grammar a bit, we see, no, a statement can be identifier equals expression, and those semicolons come in when we have multiple statements, like in a compound statement block. Similarly, x equals 3 divided by 2. Any expression can go on the right-hand side of the equal sign, and we saw that our grammar for expression earlier included binary operators like division. This totally works. This series of tokens, if x is less than 5 then open curly brace x equals x plus 1 curly brace looks very convincing. It's almost right, but it's missing a semicolon. Inside these compound blocks we really need those. This one doesn't work. The one right below it has that semicolon, so it can be derived from "stmt" in our grammar. Over here inside our compound statement we have two smaller statements-- x is x plus 1 and y is 3. Each one of which is an individual statement, and each one of which is terminated by a semicolon. That's the rule we established earlier. Finally over here we have an if-then-else statement. This was a little tricky. In Python conceptually this might work out, but in JavaScript we explicitly need the else token. This one is not derivable from stmt, even though the rest of it is well-formed. So now we've seen how to do expressions in our formal grammar for JavaScript as well as statements like the assignment statement or the return statement or if-then-else, but we are not done. There is 1 last key element of a computer program. We need functions, and this splits into 2 parts. We need to know how to declare functions, to list how many arguments they take and what their bodies are, and we also need to know how to call functions in expressions. We know from experience that a Python program is basically just a list of statements and function definitions. Luckily for us, a JavaScript program is exactly the same thing, also a list of statements and function definitions. We sometimes call statements and function definitions elements because they're the key elements of a program at the top level. Let's get started on the highest level of our JavaScript grammar. A JavaScript program is either a single element, possibly followed by another JavaScript program, which is another element, so this ends up being a list of elements. And at some point, we get tired and stop writing in elements. An element can either be a function definition or an arbitrary statement, just like in Python. A function definition in JavaScript starts with the word function instead of the word def. There's an identifier. That's the name of the function. You must have these parentheses. You can declare some optional parameters in there. Maybe it's a function of one variable x. I'll have to show you how to do that in a minute. And then the body of a function is just a compound statement, which we've already seen. That's a list of statements terminated by semicolons. You can also just have statements at the top level, like print hello if you're testing things out. Any statement you want followed by a semi-colon. When we're giving the definition for a function, it can have any number of formal parameters that we decide. It could be a function of x, y and z. It could just be a function of a, or it could be a function of no parameters. That's why this is optional, opt. An optional parameter declaration could either be some actual parameters-- this is the common choice--or nothing. If we're going to have 1 or more parameters, here's how it goes. You can declare the names of those variables. It's a function of x, y, z. And after each one, you have to have a comma until you get to the last one, which is not followed by a comma. We haven't hinted on this previously, but this is kind of a cute gem in context-free grammars. Note that our statements are terminated by semi-colons. In a compound statement, every statement is followed by a semi-colon. By contrast over here with parameters, they're separated by commas, so the last one doesn't have a comma after it. Pretty cute. And we have all the rules for expressions that we used to have before, but now we're going to add function calls. When you're calling a function, you have to give the function name, sign, print, abs val, and then you pass in some number of arguments. There could be none, which is why this says optional, or there could be 1 or more, and you're going to see this play out in a very similar pattern to opt params. The parameters in a function declaration are always just names like x, y, or z, and then you get to refer to them in the function body. But when you're calling a function, you can put in actual values. You can call sign of 3, so we can't just reuse params. We need to make a new set of rewrite rules for actual arguments. The arguments could be nothing, or it could be 1 or more arguments. If it's 1 or more arguments, they're going to be expressions separated by commas. Down here we had function calls, which are expressions. You could take sign of x and divide the result by 2. And up here at the top, function definitions. These happen more rarely. These are elements. This is actually pretty much it. This is the majority of our JavaScript grammar. The real devil is in the details. For example, you may have noticed that nothing in this grammar prevents you from declaring sign as a function that takes 1 parameter and then later on calling it with 2 parameters. Uh-oh. More on that later. All right, so here I have written out 3 JavaScript elements. Number 1, a function definition of a function mymin, given 2 arguments a and b, if a is less than b we return a. Otherwise we return b. We're returning whichever one is smaller. Over here, another function definition for a function called "square." It takes in a variable x and returns x times x. And then over here, number 3, a statement. We're calling write, or if you prefer, document.write, to display the result of calling mymin on the square of -2 and the square of 3. In essence what we're trying to figure out is which is smaller, -2 squared or 3 squared? And then we're going to print out that result. Your mission, should you choose to accept it, translate this to Python. Submit via the interpreter. Write a Python program that does exactly the same as this JavaScript. Well, to see how this plays out, first I'm going to show you what the JavaScript actually does. Here I've typed it out. Here's our webpage with embedded JavaScript in it. We declare the function mymin of a and b. If a is less than b, return a. Otherwise return b. We declare the function square to take x and return x squared. And then we called document.write of mymin of the square of -2 and the square of 3. Well, -2 times -2 is 4. 3 times 3 is 9. 4 is smaller than 9, so we expect 4 to be returned, and 4 is returned. How happy are we? So happy. All right, now we're going to get this same thing, a 4, in Python. All right, and now we're back at our Python interpreter, and I'm going to type out the same code starting here. Note again that in Python, instead of the opening and closing curly braces, we have tabbing and colons. We also don't necessarily need to terminate our statements with semicolons. The Python equivalent of document.write is print, and we print out the 4. Exactly what we wanted to see. Let's actually go try something out. Let's go put in a bunch of extra gratuitous semicolons in Python to make it look a little bit more like JavaScript. What do we think will happen? In fact, nothing special happens. Python is totally fine with you terminating statements with semicolons if you would like. You just don't have to. If you want to get in the habit of it in order to make it easier to transition between Python and JavaScript, no problem. Now we have our formal grammar for JavaScript, and previously we had a formal grammar for HTML, but there's a slight difference between the creative work of making up the grammar, thinking of the right one, designing your own language, making the new Esperanto, and checking utterances to see if they're valid. For example, we really want to accept expressions like 1 + 2 + 3, but we really want to reject random sequences of tokens like this 1 + + + ) 3. This makes us super sad. It's not immediately clear how you check to see if an utterance is in a grammar. We can do it in our heads, but how would we write a computer program to do it? Remember, we're making a web browser, and we want to render as much valid HTML in JavaScript as we can, but web designers sometimes make errors, and we're going to need to know how to detect that, so this decision, is it in my formal language, or is it not? Am I super happy, or am I super sad is something that we're going to need our web browser, a computer program, to do. We're going to need some sort of automated technique. One approach--and this approach is super slow. We're talking snail speed here. Actually, I think I may claim this doodle is so good that I do not even need to label it. We'll just know it's a snail. One approach would be to enumerate all strings in the language of the grammar and then just check to see if yours is in there. If it is, you win. If not, your string must have been invalid. Unfortunately, we mentioned earlier that often a finite grammar has an infinite number of strings, so spending an infinite amount of time to enumerate them all is probably not feasible, but let's try it anyway. We're going to try this approach first, even though we have some intuition that it's not going to work out, and the reasons are, 1, it's instructive--to see why we need more complicated parsing techniques later-- but also because it gives us a chance to learn a little bit more about Python and some cool programming techniques that will help you in this class and later on. Here are my power tools. This is a hammer, which I guess is technically not a power tool, but it's possible for me to draw it, and this is my--let's say--circular saw. It could also be an unhappy squid. This one definitely needs a label. Let's imagine circular saw. I'm going to introduce you to a new type of expression in Python, lambda, which is another way of defining functions. Here I've written Python code to make a function addtwo(x), which returns x + 2. You can put a Python function like this all on 1 line as long as it fits, and if I write addtwo(2), I expect to get 4 out. Here I've written something apparently completely different. I'm assigning to the variable mystery the result of a lambda expression. Here the word lambda is fixed. It's a terminal. And then you list some number of arguments, and then you have a colon, and then here you can put any expression you like. If I call mystery(3), I'm going to get out a 5 because the interpretation of this is that lambda has made a function that takes x as its argument and returns x + 2. We just take this 3, and we substitute it in for x. 3 + 2 is 5. 5 is what we get out. Mystery and addtwo are in fact the same, but now I can do cute things like saying pele gets mystery, and then if I write pele(4), I'm going to get 6. I can make up functions with this lambda expression and then assign them around. Pele was a Brazilian footballer, one of the best of all times. Lambda means make me a function, and it's very popular in a paradigm of programming known as functional programming. Functional programming sometimes contrasts with object oriented programming and imperative programming. You'll get a chance to learn about those in other classes. Lambda means make me a function. It's a lot like def. That's not the only new power we're going to introduce. Suppose that you wanted to square all of the numbers in the list 1, 2, 3, 4, 5. Here's one way to do it. The function map takes a function as its first argument and then a list, and it applies that function to each element of the list in turn, creating a new list. I'm going to make a new list down here that's the output of map, and we're going to take 1 and square it, so we get 1 x 1 is 1. Now we're going to take 2 and square it. 2 x 2 is 4. 3 and square it is 9. 4 and square it is 16. 5 and square it is 25. Each one of these led directly to part of my output. This function map is a big part of functional programming, and it's also a big part of how Google is able to make very scalable search engines and related services. Map reduced is an easily parallelizable functional programming paradigm, lots of power here. I said that map takes a function as its first argument. One way to make a function is to define it earlier and refer to it by name, but we can also make a function right now right in this expression when we need it and pass that in. This map is going to produce the same result as the previous one. 1 x 1 is 1. 2 x 2 is 4. 3 x 3 is 9. 16, 25. But I didn't need to have mysquare defined in advance. This use of lambda is sometimes called an anonymous function because it was an important function, but we never actually gave it a name. But now here comes the real convenience. I'm going to show you a third way to make that list that's even more natural than the previous two. This approach is called a list comprehension. You ask for a list, but instead of actually putting elements in it, you write out a little formula here and then say that you want that formula applied for every element in some other list or collection. This is saying for every x in 1, 2, 3, 4, 5, so x is going to be 1, and then it will be 2, and then it will be 3, then it will be 4, then it will be 5, for each one of those, put x times x in the output list. These formulas can be arbitrarily complicated, any expression you like. Here x is going to be hello and then my and then friends, and we're going to make a list out of the length of each of those, so that's going to be 5 and then 2 and then--actually, you tell me. What's going to show up here? We're just applying the length function to all these strings and friends--1, 2, 3, 4, 5, 6, 7--has 7 characters in it, so we're just going to get a 7. This approach to defining a list where you use square brackets-- but instead of explicitly listing the elements list a formula that's applied to every element in another list--is called a list comprehension. We comprehend the new list to be made out of transformations of the elements in the old one. Now that we've seen this one way, let's see this from a different perspective. [Brendan Eich, CTO, Mozilla] [Wes Weimer, Professor, University of Virginia] Let me ask you a question that's actually of personal interest and curiosity to me. I'm teaching in this class a number of elements of functional programming, list comprehensions in Python, filtering a list to retain only some required elements, and I noticed that in JavaScript you included the ability to create an anonymous function with the function keyword. And for students initially, that might be a little bit confusing because declaring a function at the top level also uses the function keyword, but we can get past that with the grammar. I'm curious, why did you think it was important to include the ability to have anonymous functions? JavaScript had to live in the shadow of Java, but it was its own language, and the original pitch-- the sort of fraudulent pretense for getting me to Netscape--was to do Scheme. Now, I didn't have time to do Scheme, and I didn't do anything as pretty as Scheme, but JavaScript is a language with first class functions, and functions are the main building block, so it's important not simply to have function declarations and require you to name them and put them at a certain level in nesting but to allow you to express them freely as anonymous functions or even named function expressions, and this is incredibly popular today. This is used in lieu of modules and to make sort of super constructors and class systems in JavaScript today using functions and function expressions. So let's make sure that we really understand list comprehensions by doing them backwards. Suppose what I really want is for the output to be the list 1, 2, 3. I have 5 expressions here, each one of which is a list comprehension. In this multiple, multiple choice quiz, mark each one that's going to produce 1, 2, 3 as its output. Well, the first one is in some sense the identity transformation. We're not actually doing any work here. For everything in 1, 2, 3, just put that in the output. That will totally work. Here we're going to take 0, 1, 2, but we're going to add 1 to each, so 0 + 1 is 1, 1 + 1 is 2, 2 + 1 is 3. That will give us the output we expect. Here we're going to do the reverse and subtract. This will be -1, 0, 1. That's not what we were hoping for. Here we're going to divide a bit. 3 divided by 2 is 1.5. That's kind of close, but 6 divided by 2 is 3. This is not getting us the answer we want in the right order. And finally, over here, length of a is 1. My is 2 and the is 3, so we get the answers we expect. Here I've written those answers out explicitly in Python in the interpreter, and we're just going to check and see that we got the answers that we expected. 1, 2, 3, 1, 2, 3. That's good. This was much too low. Here the division didn't work out properly, but in the last one it worked out fine. We could totally fix this last one. If we divide by 3 instead, we will get 1, 2, 3, 1, 2, 3, but it was off by 1. These list comprehensions are amazing. They are one of my favorite parts of Python. This is really a great way to program. It's very declarative. You just say what you want, and the system makes it for you. Unfortunately, they have a slight downside, which is that thus far we've had to write out the starter list, and that's almost as much work as just writing down what we need. If only there were some way to generate this list, especially if it's really big, without us having to write it down explicitly. For example, suppose I started with a big list like this, 1, 2, 3, 4, 5, 6, 7. I assert it's big. It's big for me. This is heavy lifting for your professor. And what I want to do is filter it down so that we only have the odd numbers. I want to get this part out. I'm going to show you a new way to do that in Python. Here I've written a procedure called odds_only in Python that takes a list of numbers, and it's going to iterate over them. For every n in that list of numbers, if that number is odd, we divide it by 2 and check the remainder. 5 divided by 2 is 4 with remainder 1, so it's odd. We yield that part into our results. Note that I did not write the word "return." Yield is a new special keyword that means we can use this sort of procedure to gather up multiple results. Let's imagine that this big list here was numbers. We'll yield 1, not do anything with 2, yield 3, not do anything with 4, yield 5, not do anything with 6, and yield 7, and that's exactly the output that we wanted. You can view this as sort of a convenient way of filtering. Here I've written out our odds_only procedure. I'm just going to show you in the interpreter how this plays out. I'm using a list comprehension. I want to print out every value of x that's in odds_only of 1, 2, 3, 4, 5, and we get 1, 3, and 5, as we expected. I'm also going to show you an even easier way to do this. Snap, it'll be so cool. Here I've written a list comprehension. I want [x for x in [1, 2, 3, 4, 5]. But over here on the right I've put this sort of if conditional, a guard or a predicate we might call it in mathematics, and this is saying I only want you to yield those numbers for which the predicate is true. Only include x in the answer if x was an odd number, and look, we get the answer we wanted. I've written x a few times, but I can make these formulas arbitrarily more complicated. Here I've said take all of the odd numbers, and multiply them by 2. Since 1, 3, and 5 were the odd numbers, 2, 6, and 10 are the multiplication by 2. I love list comprehensions, and you will too soon. A function like odds_only that uses yield to potentially return multiple answers is called a generator because you can use it to generate another list or another enumeration. So now let's have you try it out on your own. Using the interpreter, write a Python function called small_words that accepts a list of strings as input and yields only those that are at most 3 letters long. Since you'll be using yield, this is a generator function. Well, let's go write out the answer together in the interpreter. I'm going to start by defining my function small_words, and it takes a list of words as input. I definitely want to iterate over each one. The problem definition said that we want those involving at most 3 letters, so those are the small words that we yield. Now I'm going to add some debugging to see if I've gotten the right answer. I'm going to use one of these list comprehensions because I love them so much. I'm going to print out each word that's in small_words applied to "The quick brown fox." I'm just sort of eyeballing it. "The" and "fox" are at most 3 letters, so I hope to see these 2 in the answer, but "quick" and "brown" are too big to make the final cut, and that's exactly what we got out. Recall that our goal was to enumerate all the strings in a grammar. That was our super slow approach to check and see if HTML or JavaScript was valid. Well, unsurprisingly, these generators are the trick we're going to use to enumerate a lot of strings in a concise manner. We're going to write a Python program to check and see or to enumerate strings in this language so that we can check strings for validity. Here I've written a grammar, but it's on kind of a pencil and paper format with these arrows and what-not. I'm going to need to encode it so that Python can understand it just like we had to encode the edges in our finite state machine so that Python could understand them. Here on the right I've written a potential Python encoding for this grammar. Expression goes to expression plus expression. The way I'm going to encode this is if we had A goes to B, C, I'm going to make that the rule A goes to B, C. We've got the left-hand side and the right-hand side, left-hand side and the right-hand side. Expression goes to expression plus expression. Expression can also go to expression minus expression or expression in parentheses, or just number, and here I'm writing all of my terminals and non-terminals as strings just to make equality checking easier. Then given a seed utterance like print exp followed by semi-colon, we would represent that as a list of 3 strings, and what I want to do is take our grammar rules like this one and our utterances like this one and combine them together to get--I've replaced the expression that was already in here. Using this rule, I've replaced it with expression minus expression. Well, if I've stored this in a Python variable called "utterance," and the position I want to change is position 1--that's where I'm going to apply this rule-- I can get out this cool result with this Python that uses list selection. Utterance from 0 up to but not including pos, this part here corresponds to this part in our example, the word "print," something that came before the part we were interested in. The right-hand side of the rule was expression minus expression, and then the rest of the utterance, this semi-colon, something else we weren't concerned with this time. So let's start coding this up. There's our first grammar rule, expression goes to expression + expression. Our second grammar rule, very similar but for the minus. All right, so here I actually have quite a bit of Python code, and we're going to walk through it together, and then you're going to help me finish it out, so here's our definition of our grammar. It has 4 rewrite rules, and where I'm going to need your help is given a list of tokens and a grammar, I want to find all possible ways to expand it using those rules. Let me just show you what I mean by that. Here's our grammar again, and let's say that we started with "a exp." I would want us to come out with "a exp + exp," "a exp - exp," "a ( exp )," and "a num." For each of these possible token positions and for each grammar rule, we removed the starting token and replaced it with the right-hand side of the grammar rule. This is the way we're going to enumerate all of the valid strings in the grammar. Now, you'll notice that I've made more expressions in many of these cases, so I could go from here and start and expand it again and get a few more strings until eventually I'm full entirely of terminals. I'm going to call the number of times I do this the depth. If we start with a exp and we expand it to depth 1, we get 4 new utterances, 4 new sentences. You're going to have to help me write that expansion procedure. Down here I've got some code to help us print it out. For now, we're only going to enumerate things up to a depth of 1, and we're going to start with just expression, and then we're going to use your expand procedure to make many more utterances, many more sentences starting from expression, probably 4 more, so then we'll have a total of 5, and then at the end of the day we print them all out. If you do it correctly, this is the output you expect to see, our original sentence, but then it's been expanded with 4 more, expression + expression, expression - expression, open expression close and num. And in fact, if we go back up here and change this to a exp, the example we worked through in the comments, we get the expected output. A is unchanged because there's no rewrite rule in our grammar for dealing with it, but a exp becomes a expression + expression, a expression - expression, a open expression close, and a num. Your job, submit via the interpreter the correct definition for the expand procedure so that it does this. Here's a hint. You're going to need yield with high probability, and you may also want to end up using list comprehensions. By the way, this is a very tricky quiz. This is not easy to get right the first time, so you should not feel bad if something goes wrong. Give this your all, but it is very difficult compared to what we've been up to so far. So it's going to turn out that I can complete the definition of expand with just 2 lines if I use yielding generators and list comprehensions later on. Let's go take a look and see how this goes. Well, we're passed in a set of tokens like "a exp," and now we're going to consider each possible position, the zeroth position which is a, and the first position which is exp, and then for each rule in the grammar, we want to see if it matches. Now remember, none of the rules in our grammar match a, so we're going to need our program to deal with that correctly. If tokens[pos] might be a the first time and exp the second time. We have to check and see if that matches the left-hand side of the grammar rule and remember--let's go back up to our encoding of the grammar-- we always had the left-hand side as the zeroth element of this tuple, and the right-hand side was the first. We're going to check and see if these strings equal exp. Only if they do do we want to apply the transformation, so if we're in the right position, like we're in position 1, and we see an exp, great. Now what I need to do is for each of the rules in our grammar, yield or return one of those results. Conveniently, we've got this other for loop up here. For each rule in our grammar, I'm going to use this expression that I showed you before, and we take tokens 0 through the position. For us that's that a that's being unchanged. We're just carrying that along. I'm going to yield that. We're going to add to it the right-hand side of the rule, expression plus expression, expression minus expression, and then also any tokens that came afterward. We could have done a expression b, and we would have seen a b on the right-hand side of all of these. And actually, that's pretty much it, but here's the real power of this. Let's expand the depth up to 2 and start seeing what kind of answers we'll get, so now we're going to re-expand expression, expression, expression. There are 1, 2, 3, 4, 5, 6 places we could do this expansion. It's immense. It goes down quite a ways. But you can start seeing much more complicated expressions, like for example, here we have something that might be 1 + 2 + 3, but one line below it 1 + 2 - 3. Here we've got some uses of parentheses to help remove ambiguity, and you could imagine that I could go up to depth 3 and depth 4 and start enumerating lots of strings in this grammar. In fact, wow, there's a huge amount of output, and that's why I was suggesting that this is not a very efficient way of doing things because I could enumerate a lot of strings of length 3 or 4 or 5 or a lot of strings that have involved 3 or 4 or 5 rule rewrites. So we just saw a slow way to encode formal grammars in Python and enumerate strings in them. We will definitely need this power, but in our next exciting episode I'm going to teach you a more efficient way to encode grammar rules, like the rules for HTML in JavaScript that we will need for our web browser, and check to see if a string is valid without having to enumerate all possible strings first, because that might take, let's say, one more second than I have, so we're going to see very efficient ways to solve this problem. Super cool. Stick around, and I'll see you next time. So years ago, while I was working at a company that shall not be named, I was bored out of my mind, and one of the things that people at this company did to pass the time was playing Tetris. I ended up liking this Tetris game so much that I decided to try and write my own version of it, write a computer program to play Tetris, and if you haven't seen it before, Tetris is a Soviet falling blocks puzzle game with a number of different pieces, all of which are made up of 4 smaller blocks. I decided that I wanted to support not just the normal Tetris pieces, but because I'm a bit of a math person, the ability to have pieces that were 5 long as well. In order to do that, I ended up making a piece definition language, a way of writing out what a Tetris piece should look like that this Tetris program would then read in. Now, I didn't use all of the lexing and parsing techniques that you're going to learn in this class, but I did use the same sort of concepts, and the point I'm trying to get across here is that in some sense, learning how to create your own language is like learning how to read. It really opens up a world of possibilities. It's a new tool in your belt that will come up and help you when you least expect it. Welcome back! We're about to start unit 4, and one of the things we're going to cover is the suprising power you can get from just writing down something you've already computed and referring back to it later. That actually came up once in my life. A number of years ago, I had the priviledge of working for Microsoft Research on a project to try to find and fix bugs in Windows. Now most of you are probably watching from a moon based in the not too distant future, but in the present and in the past, bugs in Windows were a big deal. In fact, it would often crash and lead to the dreaded blue screen of death. It turned out that as much as we like to pick on Microsoft, most of the bugs weren't in Microsoft code, but in third-party code written to drive various bits of hardware, like screens or printers or memory sticks. This software was called Device Drivers, and it might work something like this memory stick that I have right here. Microsoft wrote a tool to put this Device Driver software through torture tests. If you're memory stick, I might add data to you and then in the middle of reading it out, pull you out or turn off the power, or in general, apply these normal operations very fast or in a surprising order. And this really worked. They found a lot of bugs. So many bugs that's it's now a shipping product--the Microsoft Static Driver Verifier. The heart of this idea was a computer science notion known as model checking, figuring out how a program behaves by looking at its source code. A key to that was remembering things that had already been computed. If I already know how you behave when I turn off the power in the middle of an operation, I don't have to recompute it, which might be very expensive. So this relatively simple notion of writing down things so that we don't have to recompute them, is formerly called memoization, and it's one of the gems we'll get to in this unit. Welcome back! This is unit 4 of programming languages, and if we turn the clock back to last time, we were posed the following question. Given a string S, like a webpage or some embedded JavaScript or any program, and a formal grammar describing our desired language, a former grammar for HTML or JavaScript, we want to know if that string S is in the language of G? To do this, we use 2 key techniques--lexical analysis, which broke the string down into a stream of tokens, and syntactic analysis or parsing, which takes a string of tokens and checks to see if they adhere to, if they conform to a context-free grammar. While we're on the subject of time and grammars--grammars that may possibly be ambiguous, let me introduce you to a phrase that you may not have run into yet. The phrase is, "Time flies like an arrow. Fruit flies like a banana." The ambiguity trick here is that time is a noun, flies is a verb--time flies-- and "like an arrow" is the modification. So here I've got time flying. You can tell because it's got labels, and those labels are always to be trusted. So you might think, based on parallel structure, that fruit is a noun and verb is flies. So here I've got a picture of an apple with wings, and their flying in the manner of a banana. But in fact, fruit flies is the noun. They are little insects that go after fruit, and this time, like is the verb. Fruit flies go after the banana. They enjoy the banana. This is the sort of ambiguity that we can run into in a natural language like English. We're going to have to deal with that same sort of issue in programming languages, like in JavaScript or Python. In our last unit, we ended with a brute-force algorithm for enumerating all the strings in a grammar, step by step. Brute force is actually a technical term, which means to try all of the options exhaustively. Typically, the brute-force solution is easy to code, but relatively inefficient. In fact, our brute-force solution was so inefficient, it might go on forever. Consider this grammar for balanced parenthesis. We know how to enumerate strings in the language of this grammar. Suppose I give you the input open, open, close, and we want to know if it's in the language of this grammar. Well, in our brute-force approach, we would just enumerate things. We'd say, oh, well, 1 thing is the empty string. Is your input the empty string? No. Another string in the language of this grammar is open, close. Are you open, close? No. Another string in the language of this grammar is open, open, close, close. Is that you? Nope. How about open, open, open, close, close, close? Still no! How about 4 opens, followed by 4 closes? You are getting farther away. So cold! This is the wrong direction. So the algorithm that we described would enumerate all of these strings and many more--infinitely many more. Never noticing that we're never really going to match this. We're making strings that are too big. This is all just wasted work. I don't need to check 5--1, 2, 3, 4, 5--if 5 opens, followed by 5 closes corresponds to this input string. This has 10 characters. It is way too long. So that's a clear inefficiency in our previous brute-force algorithm. And that key insight that we can stop somewhere around here is what's going to lead us to a more efficient parsing strategy. Thus, our key parsing idea. We're going to win by being lazy and not duplicating work. We don't want to do any unnecessary work. We want to be super lazy. And in fact, here we've got a lazy person on a bed sleeping. You can tell it's a bed because I can't sketch. In fact, this notion that laziness is a virtue for programmers is widely celebrated. Larry Wall, the designer and inventor of Perl--P, e, r, l-- the pathologically eclectic rubbish lister-- a language that we won't be describing in this class, claims in his text books, we will encourage you to develop the 3 great virtues of a programmer-- laziness, impatience, and hubris. Sign me up! Those sound like great ways to lead one's life. But perhaps for computer programming, they actually are. The notion for laziness is it's this quality that make you go to great effort to reduce overall energy expenditures. In other words, I want to spend 5 minutes now to save 5 hours later. Most of you probably ran into the Fibonacci sequence of numbers, named after filius Bonacci in a previous computer science class. It's a great way to teach recursion. Here I've written out a Python definition for the Fibonacci sequence. To get the Nth Fibonacci number, well, if N is less than or equal to 2, we just return 1, otherwise, we return the sum of the 2 previous entries. So we're going to get 1, 1, 2 -- 1 + 1 = 2. 1 + 2 = 3. 2 + 3 = 5. 3 + 5 = 8. 5 + 8 = 11. That sort of thing. Did I do that correctly? Let's imagine. [Laughs] No, I totally didn't do that correctly. Man, you can't take me anywhere. [Singing--hmm, hmm, hmm] Basic math. Don't mind me. There we go. This looks a lot better. You saw nothing. Alright, so there's our Fibonacci sequence. In an incredible surprise move, it actually shows up a lot in nature-- for example, in the patterns of seeds in a sunflower or in the whirls in a clamshell or in yellow chamomile plants or all that good stuff. However, Fibonacci involves a huge amount of work. Let's go see what goes on when we call Fibonacci. I'm going to abbreviate it with an f--Fibonacci of 5. Well, that's going to be based on Fibonacci of 4 and Fibonacci of 3. Now 4 is based on 3 and 2. 2 is a base case, so we're done. 3 is based on 2 and 1. Over here, 3 is based on Fibonacci of 2 and Fibonacci of 1. If you look carefully, a lot of these get repeated many times. We end of calling Fibonacci of 2--once, twice, 3 times I called it. Similarly, Fibonacci of 3 is called multiple times. We're redoing work. We're computing the value of Fibonacci of 2 and Fibonacci of 3 over and over again. That is wasted work. We want to be lazy and avoid that. Just to make sure that we're all up on Fibonacci and its recursive definition, here's a quiz about it. I've written 4 statements. Check each one that's true. There might be multiple correct answers. Let's find out what the right answers are. Fibonacci of 6 = 8. Well, if N is 1, 2, 3, 4, 5, 6. We said that Fibonacci of N was 1, 1, 2, 3, 5, 8. It does look like Fibonacci of 6 = 8. Great! Is Fibonacci of N always < or = N + 1? Well, 1 is < or = to 2. 2 is < or = 3. 1 < or = 1. 5 < or = 8. This is certainly true. The Fibonacci sequence is strictly nondecreasing. It either stays the same or gets bigger. This next one was a bit of a ringer--a bit of a trick. The vast majority of the time, almost always, albeit finitely often, Fibonacci of N is strictly > than Fibonacci of N + 1, except right here at the start when Fibonacci of 1 and Fibonacci of 2 are both 1, so they're = rather than <. So no dice there. Is Fibonacci of 20 > 1000? Yes. The sequence grows super fast. Let's just go check. I'll just write out the definition of Fibonacci right here. I'm declaring a procedure called fibo. It takes an argument n. Here's our base case: if n < or = to 2, return 1. Otherwise, we call ourselves recursively 2 times. And the answer is 6,765. Wow! That's immense. Notably, it's bigger than the 1000 we were asking about. True! You might have noticed that up here on the right, I made a very simple chart to try and explain how Fibonacci behaves to myself. We're going to use this same sort of chart to make Fibonacci much faster by voiding repeating a lot of work. Our official plan for this is going to be called Memoization. It's just like memorization, but missing an r. Here I've tried to draw 2 memos: a corporate memo and those yellow sticky notes you sometimes see, where you could write a little memo to yourself. A memo in English is just a document, a small document, that's written down-- memorandom. Why bother with this? Well, it's going to turn out that our current implementation of Fibonacci is super slow. Let me try to prove that to you. So let's see how long it takes to do 100 trials of the 20th Fibonacci number-- about .3 seconds. Let's up that a bit to the 24th Fibonacci number-- should take not that much longer, right? Oh! Significantly longer, from .3 seconds to 1.75 seconds. We went up a huge amount. Let's go up to the 25th Fibonacci number--oh! We almost doubled. We're now at about 2.8 seconds. In fact, we have reason to believe based on human studies that if a webpage takes longer than 6 seconds to get back to you, you go somewhere else and buy something different online. So we're already using up a huge fraction of that budjet just to compute the 25th Fibonacci number. And if you think about those trees I drew before, this is unsurprising. If we increase the number by 1, we almost double the work at each step. So this is untenable. We need something faster. Our solution we'll be to write it down in a chart, or a little memo, to ourselves. I'll just make a table mapping N to the value of Fibonacci of N. 1, 1, 2, 3, 5, 8. And when I'm going to figure these out, I don't have to do a huge amount of work. Let's say I'm trying to figure out this 6th Fibonacci number. I can just look back in the table, and reuse my old work. I don't need to recompute the 5th Fibonacci number. I already have it here. Just additional those 2 chart cells together and get the answer. This is going to be our trick for making Fibonacci so much faster. It's called memoization. So we can implement our chart as a Python dictionary, just filling in the numbers as we compute them. So I can make an empty dictionary, assign mappings to my dictionary, and then check to see if something like 6 is recorded in my chart, and if it is, print out the result. This is going to be super necessary now and maybe it wasn't before. One of the keys to memoization is looking to see if you've already done the work and written it down. If you have, great! You can just reuse it. But if you haven't, you're going to have to go and compute it manually the first time. It's quiz time. Let's show off our knowledge of memoization. Submit via the interpreter a definition for a memofibo procedure that uses a chart just as we described. You're going to want the Nth value in the chart to hold the Nth Fibonacci number if you've already computed it and to be empty otherwise. Let's go through a possible answer together. We initialize our chart to be the empty mapping, and I'm going to define a procedure named memofibo. If we're asked to compute the Nth Fibonacci number, and it's already in the chart, then we don't do any more work. We are super lazy. We just look it up in the chart and return that. Otherwise, we need to both set the chart and return the new value. So if n < or = to 2, the thing we want to write down in the chart is 1. Otherwise, we'll figure out the value of the chart by calling ourselves recursively on n - 1 and n - 2 and adding them together. In any event, since we set the chart here or here, we'll just return the value in the chart. Now I've asked us to print out the value of memofibo 24, and we get the answer that we're expecting. However, the real proof is in the timing. Using our timing code once again, I've now put in the code for memofibo instead, and we're trying to compute memofibo of 25. How long does it take to do this 100 times? Oh! Significantly less time! Remember before it was almost 3 seconds--almost half of our page budget. Now you can barely detect it--not a tenth of a second, not a hundredth of a second, but even smaller. This was a phenominal cosmic optimization. We are so much faster. It is not even funny. So this gives me a great idea! Let's use memoization to make parsing very fast. Let's cast our minds back to the glory days of regular expressions and finite state machines. In order to see if a string was accepted by a finite state machine, we'd essentially keep our finger on the state. So on input abb-a, b, b--I just sort of keep my finger on this middle state to see where things were going. If I stop here, then the string is not in the language. but if I add 1 more character, c--a, b, b, c--I just put my finger on it, and I can tell, we accept. We're going to use this same "put your finger on it" trick for parsing to keep track of where we are, to keep track of which state we're in. Now for finite state machine state, that was pretty easy. They were the circles. For our parser state, this is not so clear. We're also going to solve parsing by "putting our finger on it." But just like how how nondeterministic finite state machines might require 2 or 3 fingers, parsing might also require a number of fingers. It's going to be somewhat complicated. Consider this simple arithmetic expression grammar--has a starting nonterminal, but then quickly goes to E. E + E, E - E, and 1 and 2 instead of number. Let's just make it finite. Suppose the entire input is 1 + 2, which is in the language of the grammar. Currently, we've only seen the 1 and the +. Remember that to figure out if something was in the language of a finite state machine, we look at 1 character at a time. We're going to do pretty much the same thing for parsing. We're going to look at 1 token at a time. But the question is, where are we now? Well, we don't have states that look like circles, but we do have these rules. In fact, we've got 5 of them written over here, and if we've already seen the 1 and the +, we're about to see the 2. I claim that there are 1 or 2 of these rules that match more closely than others. For example, S goes to E--that doesn't seem particularly relevant. Now a minus sign--that doesn't seem particularly relevant. E goes to 1--if we've already seen the 1 and the +, we're kind of passed that. But these 2--E + E and 2--that's kind of where the action is. That's where we are now in some strong sense. In fact, I'm going to claim that we're right here. In the rules, E goes to E + E, we've already seen the E and the +. Here's my finger, and we're about to see the next E. Since I can't always leave my finger on the slide, we often formally draw a red dot in the middle of 1 of these rules to keep track of where we are. This is 1 example of a parsing state. The first E is going to correspond to or come from the 1 of the input. Ideally, the second E will match up with 2 in the input. We've already seen everything to the left of the red dot. We have not yet seen everything to the right of the red dot. The red dot is right where we are now. This is the past. This is the future. This is now. Let's trace what happens as we see a little more of the input. Let's say we actually walk over and we see the 2. Well, then our parcing state looks like this--E goes to 2. We've seen the 2, and there's nothing left. Everything important is in the past. There's nothing in the future. So conceptually, we can use this rule--this rewrite rule, E goes to 2 like we hinted at here with our purple text, we will also be here. E goes to E + E, but we've already seen the E, the +, and the E-- E + E. So we can go even further and go back to the first rule in our grammar where we were trying to parse a sentence, which could be an expression. We've already seen an entire expression--1 + 2--and now we're done. In fact, if you can get to the state corresponding to your starting nonterminal being completely finished, everything is in the past. Nothing to see in the future. Then you've parsed it! That string was in the language of the grammar. So formally a parsing state, a possible configuration of a parser, a world we could be in is a rewrite rule from the grammar augmented with exactly 1 red dot-- that's where I'm putting my finger. That's where we are now. The past comes before it. The future comes after it--on the right-hand side of the rule. You can never put the dot on the left. The dot is always to the right. Now for any given input as we've seen here, you could actually be in maybe 3 of these parsing states at once. One way of looking at the world is that I just finished seeing the 2. Another way of looking at the world is--actually I'm done with everything. Those can all be true at the same time. Let us check our knowledge of parsing states with a quiz. Here I've written 6 inputs and 6 corresponding states, but I may be leading you astray. What I'd like you to do is for each input state pair, check the box if this state is really a possible state, a valid state, for our parser on this input, given the grammar above. You'll need to look at the grammar and the input to check and see if the state is correct. Go forth! Alright, let's get started. We see just a 1, and we've seen all of it. Then we totally could be in this state. E goes to 1, and then there's my finger. That's where we are. We've already seen the 1. We're done with--we're ready to apply this rule, E goes to 1. Everything here is fine. Here the input hasn't changed, and we have another state, but remember that we said before, depending on your point of view, when you see a 1 you can either be reducing a 1 to expression or you could be completely done with parsing. 1 is in the language of this grammar. We normally think of things like 1 + 2 - 3, but the lowly 1 alone is in this grammar. S goes to E. E goes to 1. And this says, I finished parcing the string. Great! Now we just see a 1, but this state says, oh, I've seen an E, and I've seen a +, and I'm looking for an E in the future. This can't work because it requires us to have seen the +. If I put my finger here, the + is in the past, and I haven't seen any +'s in the input, so we can't make that work out. The next one has the same input, but a slightly different state. I've seen an E, and I'm looking for a + and then another E. Yeah, I could totally imagine a + followed by another E filling this out. That could work, so this is a possible state that we could be in. We see 1 + as the input, and this is a little more complicated, and now the one that we had to reject before suddenly becomes valid. My finger is here, and E and a + are in the past. Here's the E. Here's the +, and I'm looking for some new expression in the future. This fits very well. The last one was a bit of a ringer. This was a bit of a trick question. It required you to have the definition well in hand. This looks very promising. I put my finger here and it says, oh, there's a 1 and a + in the past, and we're looking for an E--that all sounds good. But remember that the definition of a parsing state is that it's one of the rules from our grammar, augmented with a single red dot. E goes to 1 + E is not a rule in our grammar. The closest rule in our grammar is 5, which is E goes to E + E. Every symbol matters. This can't be a valid parsing state because E goes to 1 + E is not a rule in our grammar. So just as we applied memoization to Fibonacci, we're going to apply memoization to our attempts to parse a grammar. When we were trying to compute Fibonacci, the Nth position in the chart corresponded to the Nth Fibonacci number. Let's say I'm trying to parse a string made out of a big list of tokens-- token 1, token 2, token N, all the way up to token last. We're going to try to figure out the string 1 token at a time. So the Nth position in the chart is going to be all the parse states we could be in after seeing the first N tokens--the first N words--in the input. This means that instead of our chart returning a single number, our chart is going to return a set or list, an entire collection. Here's a much simpler grammar to try out this concept on. E goes to E + E or E goes to INT. We use INT like we use NUM or number. It represents integer. So here the language of our grammar includes things like INT + INI, INT + INT + INT. Suppose, in fact, that the input is INT + INT. I'm going to draw out a chart showing N and chart of N. Suppose we haven't seen any of the input yet. Where could we be? Well, conceptually my finger is going to have to be very far to the left. I could be looking for E + E, or I could be looking for INT, but regardless, I haven't seen any of it left. There's nothing in my past, and the whole world is in the future. The reason I can't be sure yet is that I've only seen 0 tokens of the input. So even though we, the viewers at home, the studio audience, know that eventually we're going to be using this top rule, our chart hasn't seen enough of the input yet to make that determination. Well, after seeing only 1 token, we've seen the INT. One possible state I could be in is, well, I'm trying to reduce an expression to an integer. You gave me an integer. I'm done. If I think the input is going to go on a little longer, I might expect to see a + and an E coming up later. So this is the second state that I could be in. If I've seen the INT and the +, then among other things, my world probably looks like this. I've got an E and a + in my past. I'm looking for an E in my future. There might be a few other elements in this state, and we might continue the chart a bit farther to the right, but this is the basic idea. It's just like our chart for Fibonacci, but instead of holding a single number, it holds a list or a sequence of parsing states, and each parsing state is a rule in our grammar augmented with a single red dot somewhere on the right-hand side. Now let's dig into this notion of parcing states a little bit more. Let's say that our grammar is the same simple INT + INT grammar it was from before. If our current state is E goes to E + dot E, how many tokens could we have seen so far in the input? Remember a token is a terminal like INT or plus. Well, let's take a look together. Could we have seen 0 tokens so far? No, when we've seen 0 tokens the red dot has to be really far to the left. Currently, the red dot suggests that we've already seen an E and a +. The + alone takes up 1 token, so we can't be here. Alright, but could we have just seen 1 token? Well, since we've seen an expression and a + and the smallest expression is itself, 1 token, we need to have seen at least 2, so we can't be here. However, we could have seen just 2 if the input so far was INT +. We've seen 2 tokens and one of our states would be exactly this one. INT reduces to, or can be rewritten from, E using one of the rules in our grammar. The + is a terminal, so it always stays the same. Here's where we are. How about 3? Well, this is a little trickier. In our grammar, if we had seen 3 input tokens, our red dot wouldn't be right here after the +, it would be over one more. Something a little different would happen. It's very hard to have a string in the language of this grammar, where after 3 tokens you've just seen a +. But surprisingly, 4 tokens does. Let's make a little room and take a look and see why. E can be rewritten by INT. E can be rewritten by INT. This + stays the same. So the 3 of these together, E + E are themselves--one more E. So conceptually from the parsers point of view, what we've seen so far is an E and a +, assuming we've done all these rewrites over here on the left, and we're looking for a little more input. So in fact, we could have seen 4 input tokens INT + INT + and been in this parsing state. This might seem a little counterintuitive but remember the glory of parsing, or the glory of context-free grammars, is that a very concise grammar notation stands for an infinite number of strings. Even this very simple grammar has an infinite number of strings in its language, so it shouldn't be surprising that longer strings than 2 can have very concise parse states. 5 tokens isn't going to work for the same reason that 3 tokens didn't work. The dot would have to be in another place. However, if we were to add a few more INTs, this trick that I've done here of reducing INT goes to INT goes to INT--if I had 1, 2, 3, 4, 5, 6 tokens, I could also be in the same state. So 2, 4, 6, 8--the pattern repeats. Let's get 1 more view into how this relationship between grammars and parsing states plays out. I've written a new grammar over here on the left, but actually if you think about it, it's simpler than our old grammars. Since this one isn't recursive, there are only a finite number of strings in the language-- INT + string and INT alone. Let's say that the full input is going to be INT + INT, which is not in the language of the grammar, but thus far, we've only seen a single token--INT. Our parser has to handle good input and also malformed input. Not everything out there on the web is super clean. We're going to want to write a web browser that can tell the difference between the good and the bad, the wheat and the chaff. So what I'd like you to do is figure out after just 1 token of the input, what are some parse states we could be in? I've listed 7 possible parse states in this multiple multiple-choice quiz. I would like you to check each one if we could be in it, after seeing only 1 token of this input. Alright, how about this? We've seen just INT. One of our grammar rules is A goes to INT + string-- INT + string--and I've put the dot right here, so we've already seen an INT, and we're expecting to see 2 more things. This is consistent with the world that we've been presented. We know that eventually this won't work because the full input is INT + INT, but we haven't seen that much yet, so we can't rule it out. Right now we think this state is okay. In the future, we'll give up on it. Similarly, one of the rules in our grammar is A goes to INT. We've only seen an INT, so we could be in this state. The INT is behind us. There's nothing in our future. We're really hoping the input ends now. The input doesn't end now. You and I know that there are 2 more tokens coming, but our parser doesn't know that yet. It's only seen 1 token. In the next step, the next iteration, the next recursive call, it will know and throw away this information. But for now, we're keeping it. Alright, how about this? A goes to INT +--this requires us to have 2 tokens in the past, and we've only seen 1 token of the input. That can't be true. Similarly over here, there's nothing in the past, and there's 1 token to the right. Looking at our grammar. There's really no way this could play out. We've seen 1 token, and this assumes we've seen 0. Over here, similarly, INT + string--this parsing state only works if we've seen 0 tokens, and we've already seen 1. So that doesn't match. And in fact, similarly here, S goes to A. S goes to A is a rule in our grammar. That's a good sign, but this version requires us to have seen nothing, and we've seen 1 token. S goes to A, and here we are. Actually this could totally work. If I've only seen just INT from the input, then I could be finishing off-- I could be accepting the string based on S goes to A and A goes to INT. So I've already seen a full A. A goes to INT--and now I'm done with S. Yeah! That's where I could be. Now again, we're going to rule this out as soon as we see the next token in the input-- that it's not the end of the string, but for now, it looks very promising. This is the big trick with parsing, I said earlier, we'd have to keep our fingers in many spots because until we see the whole input, we're not sure what the picture is. So we just remembered that one of the great powers of grammars is that they can be recursive, just like procedures. You can have a grammar rule that expands to itself, allowing you to have an infinite number of utterances from a finite formal grammar. That gives us a huge amount of power, almost a magical amount of power, but it does mean that we'll need one more element of bookkeeping in order to correctly do parsing. We saw before in one of the quizzes that we could be in a particular state after seeing two tokens, four tokens, six tokens, eight tokens, so we'll need to keep track of one more number to know which one of those it was. We'll need to know where we came from or how many tokens we'd seen thus far. Here's a grammar we've seen before. E goes to E plus E or E goes to int. Our input string is int plus int. I'm going to start filling out that chart that shows us what parsing states we could be in if we've only seen a subset of the input. If we've only seen zero tokens, then we could either be looking for E plus E or we could be looking for int. Those are our two grammar rules. We haven't seen anything yet. There is nothing to the past. Everything is to the future. Once we've seen the single int, then we could either be in the middle of parsing E goes to int, and we're totally done with it. Or, if the input is longer, we could be expecting a plus and an E in the future. Here is where things start getting fun If we've seen the int and the plus, then we could definitely be in the middle of parsing E goes to E plus E with a dot right here. We've seen two things to the left. There is one thing in our future. But now we could also start looking for another int. We're expecting in int to be the third token. If we saw it, it would reduce or it would be rewritten from E goes to int. Our current parsing state is we have seen it yet, but we're really expecting it in the future. But here is where the potential ambiguity comes in. This states is exactly E goes to dot int. We saw that same state back here in chart position 0. However, they're not exactly the same. This one corresponds to the first int in our input. This one corresponds to the second int in our input. This is what we're thinking about when we haven't seen any tokens yet. This is what we're thinking about when we've seen two tokens by not the third. The parsing rule is similar, because the grammar is recursive. It has a small, finite structure. But we really need to remember one extra bit of information. When we're thinking about it this time, we've sort of seen zero tokens so far. Over here, we've seen two tokens so far. Or we decided to add this state based on reasoning about state 2. This fact that we could have two otherwise identical parse states means we'll need to augment our parse states with one more number of information. We're going to call this new information the "starting position" or the "from position" associated with a parse state. One last way to see way to see why we need it. Let's say one of our current states is E goes to dot int, and we actually see that int. It's part of the input. We need to know whether we should go on to sort of chart position one and start looking around here or whether we should go on to chart position 3, which I haven't filled in, and start looking there. We need to know where we came from in order to know where we're going. This is one of the reasons why context-free grammars are more powerful than finite state machines. Finite state machines did not really need to know where they were coming from. They were memory-less in some sense aside from the current state. We're doing all of this because we want to master parsing. We want to see which strings are in the language of a grammar, to see if HTML or JavaScript is valid before we try to through it to our web browser's rendering engine. Another way to think about this is that parsing is the inverse of producing strings. Rather than producing all the strings in the world, I want to see if this one string could have been produced by our grammar. Over here I've drawn a little diagram of parsing a simple sentence int plus int using our grammar. Well, one way to view this is to think about the parse tree, which I've kind of drawn here upside down. Conceptually, I could apply this E goes to int rule in reverse and rewrite this int with an E, changing the input string so that it has a nonterminal in it. Then I can do the same thing again over here, and now I have E plus E. I can rewrite that to be just E. It's as if I'm taking the rules and the grammar and changing the direction of the arrow. If I view this story this way, we're parsing. Magic trick of perspective--if I read from the bottom up we're generating or producing strings. Starting with E, I choose to apply E goes to E plus E. I choose to apply E goes to int. I choose to apply E goes to int. I end up with a string at the end of the day. This way, from the bottom to the top, is generating or producing a string. This way, from the top to the bottom, is parsing a string, applying the reductions in reverse order until you get back to the start symbol. If you could apply all the reductions in reverse order, then you know that the string is in the language of the grammar, because you have a script for generating it. Just do everything you did backwards. Now it's time once again for you to show your understanding of this forwards and backwards. I've got a relatively simple grammar up here in the upper left, but it's a grammar that couldn't be captured by any regular expression so it can't be that bad. P goes to open P close or P goes to nothing. You could imagine drawing the epsilon there. Our input is the four character string open open close close. I said before that we'd need to annotate each of our parsing states, and I have eight of them shown here with information about which state they came from, what the from position was, what the starting position was. What I'd like you to do is fill in each one of these blanks with a single number corresponding to the chart position that this state conceptually starts at. Another way to think about that is let's say that we're in a particular state like this one-- P goes to dot open P close. How many tokens must there have been beforehand for this to possibly make sense. We know we're in chart position one, but here it looks as if there's nothing in our past. How man hidden things would there have to be in our past for this to work out? Well, let's go try it out together. When we're in chart state 0, when we haven't seen any of the input yet, we started in position 0. there is no hidden input we're missing. There is no processing that we've already done. Even as we move initially into this first state in chart position 1, we've seen one token, and look, there's one token to the left of this dot. We got here by reading in the input, left parenthesis, from chart position 0. Oh, we were expecting a left parenthesis. Great. I just move my finger over to the right. Essentially, I copy this previous rule, P goes to dot open P close starting at 0, and I bring it down here into chart 1. But now I have the dot, I have my finger, before P. If I'm expecting to see a P in the future, I could see another open parentheses, because that's one of the things that P can rewrite to. I could also see nothing, because that's another thing that P could be rewritten to. I've included both of those--they're right here--one, two-- based on this rule and this P--one, two. Brought those two in. I brought them in based on thinking hard about chart one, and they assume that I've already seen this left parenthesis. These two rules start at position 1. Since one of the things I'm considering is that P is totally empty, up here I was thinking, oh, I could've seen a left parenthesis and been expecting a P and then a right parenthesis, but if P disappears then I'm already past it, and I'm expecting a right parenthesis. I got this from this rule up here, which came from chart position 0. Now, we just so happen to know what the actual next piece of input was. We saw an open parenthesis and then another open parenthesis. It must've been that we were looking at this very special rule right here. We saw the open parenthesis and this one was right, and all of the others were wrong. They were possibilities, but they didn't pan out. We took this rule here and move our finger over, shift it past this open parenthesis, so we get open parenthesis dot P close. That's right where we started here. It is bringing over this rule that had previously said starting at 1 it still says starting at 1, but now I do the trick and this is the part where the numbers change. If my dot is right in front of a P, then I could be expecting to see a left parenthesis, we're not going to in the input, but you never know, or nothing. Once again, based on this P, I'm going to start bringing in rules 1 and 2. P goes to dot open P close. P goes to nothing. But this time we started in position 2. This was a very tricky quiz. You should not feel bad if elements of this gave you grief. We're going to go over this in much more detail later on. It turns out that if we could just build this chart correctly-- and that's not going to be easy, but it's going to within our power-- then we've solved parsing. Let's say that our grammar has some special start symbol S. So goes to E, and then E could be many things. The state we really want to be in is this one. I have seen everything. S goes to E, and there's nothing more. We are totally done. I mentioned before that we have to augment all of our parse states with this starting add information. Just to be a little more specific, I have seen S goes to E, and there was no additional previous information. Starting from zero tokens of input, I have seen enough to make the judgement S goes to E based on this input string. So if the input is T tokens long, we just look to see if S goes to E dot starting at zero is in chart T. If it is, our input is in the language of the grammar. If it's not, our input is not. Parsing totally solved assuming we can build the chart, but building the chart is going to be tricky--tricky but possible. We know how our parsing chart starts on the left. Chart 0 starts with S goes to I haven't seen anything yet, but I want an E, and I'm starting from chart position 0. It'd be really nice if after all T tokens in the input we've got I have totally seen an E, and I'm done with it now, starting from position 0 in the input. I know the start of parsing, and I know the end if parsing, but there's a slight, huge, massive gulf in here-- the excluded middle of parsing that I just don't know how to construct. If only I had some intuition for it. Let's go see how that plays out. We need to know how to make additional entries in our chart. For example, we have S goes to dot E. What do we do? Can we bring some more stuff in? In the examples I've shown you we've added a few more things to chart position 0. I'm going to formally tell you how to do that. I'm going to formalize it using some abstract mathematics. Let's say that we're looking at chart position i. This means we've seen i tokens in the input. One of the things currently in that chart is the following parse state: S goes to E plus dot E coming from state j. This dot means we're expecting to see an E in the future. This is the future. This is the past. I'm going to need to look in our grammar for all the rules that start with E, because if E goes to elephant then I should be expecting to see an elephant in chart state i. If E goes to eggplant, then I should be expecting to see an eggplant in chart state i. We need to find all of the rules E goes to something in the grammar and somehow bring them in. Let me make this very generic to handle all possible situations. Let's say that we've got x goes to ab dot cd coming from position j in chart i. Normally for grammars I always draw nonterminals in blue and terminals in black, but I'm going to leave this a, b, c, and d. I don't know if they're terminals or nonterminals. I don't know what they are. In fact, a may even be empty. A may be nothing. B may be nothing. I'm going to be as generic as I can to handle all the possibilities. I'm not pinning these down to be either terminals or nonterminals. But I do note that our dot is right in front of c. I'm going to look in my grammar for all rules c goes to something. A could be empty. B could be empty. Pqr could be empty. Or they could be terminals. Or they could be nonterminals. Could be anything. For every such grammar rule, c goes to pqr. C goes to anything. Kumquat--oh, that doesn’t start with a c. C goes to chevalier. We believe ultimately that we're going to see a c in the future. If c goes to carbon then we should expect to see carbon in the immediate future. But we don't want to forget that we made this decision starting in chart state i that conceptually there were i tokens before us that we're sort of forgetting about or putting off to the side. Because even though it looks like this dot is right to the left, there are i tokens we've already seen in order for us to get to this point. We add c goes to dot pqr. We haven't see any part of c yet, but we think we might. It's a possibility. We're leaving our options open. We came to this idea from chart state i. That's how many sort of hidden pieces of input we're alighting before the dot. We add that to chart i. We do this for every grammar rule that starts with a c. If there are five grammar rules that start with a c, we're going to add five things to chart i. Formally, this operation of bringing in everything that c could become, because we're expecting to see a c, is known as predicting. I predict, because we want to see a c and c goes to cantaloupe, that we're going to see a cantaloupe. It's also called "computing the closure"--a more technical term from language theory where right before a c any rule that has c on the left-hand side should be brought in to close the state so that all possibilities are considered. Let's say we're in the middle of parsing--I've written new grammar for us, here on the left. This one has a new nonterminal F-- just to make things interesting. That is how we roll here, in programming languages. So here's our grammar; it has 4 rewrite rules. The input is: (int - int) but we've only seen 2 of those tokens so far: the (int) and the (minus). One of the elements of chart[2] is: (E --> E -), and Here We Are, and we're looking for an (E) in the future-- and we started this in chart state[0]. I have written out, down here at the bottom, five possible parse states. Why don't you tell me which of these parse states are going to be brought in by chart state[2], by computing the closure? Let's take a look at the answers together, It's going to turn out that we'll be able to compute this, fairly systematically, just by remembering the rule for how to compute the closure. We have a dot in front of the nonterminal E, so I go over to our grammar and find all of the rules that start with nonterminal E. And there are 3 of them, and I'm going to add all of them to chart[2] with a red dot right at the beginning and a from2-- because that's where we currently are--1, 2-- as they are little provenance information off here, to the right. So one of our rules is: (E --> int) so we will definitely add (E --> dot int from2). Again, the from2 is because we brought in or we computed the closure, starting in state[2]. Another possible rule is: E --> (F). So (E --> dot (F), coming from position 2) is a valid prediction we might make. We might see parentheses right after seeing a minus sign; that's valid for this language. Now our third rule is: (E --> E - E) so this option may look very tempting. It's got the (E - E). It's got the dot in the front, but it has the wrong (from) state information. It's included from0 instead of from2. We need to remember these 2 tokens we've seen previously--the (E) and the (-). We need to know which state we were in when we decided to take the closure. This one is not correct. Over here we see one that's very similar: (E --> E - E, with a dot in front). That's very good; it's a rule that starts with (E), and we need to start with (E) because the dot is before the (E). And this one correctly has from2. We computed the closure in chart[2]. And finally, this one's a bit of a ringer-- it has (F --> dot string from2). Well, the from2 looks pretty good; the dot at the beginning looks very good. But our rule is: since this dot was before an (E), we take all the grammar rules that start with (E) on the left-hand side, and that's it. So (F --> string)--that's out of place. I'm not going to predict seeing a string until I've seen an open parenthesis. If you think about this grammar, the only way to get to string is after an open parenthesis. I haven't seen one of those, so this is a bad prediction. All right. So we just saw Computing the Closure, which is one way to help us complete the parsing chart-- in fact, it's one of three ways. Now we're going to see a second that's sometimes called, Consuming the input or shifting over the input. Shifting over the input, consuming the input, or reading the input is one more way to help complete the parsing chart. We are going to need all 3 powers, combined, in order to make a totally complete parsing chart. But for now, let's worry about the input. So recall that, very generally, we could be in a parsing state that looks like this. This is a rule from our grammar, with a dot added and this (from) information or starting at information added. And I've drawn (a) and (b) and (c) and (d) in purple because we're not sure if they're terminals or nonterminals. We just saw what to do if (c)--the next thing we're expecting-- is a nonterminal. We compute the closure by looking at all the rules that start with (c) in the grammar. But what if (C) is a terminal-- a token, final part of the input? Well, then we'll just shift over it and consume it. If we were in this parsing state in chart[i], that means, after seeing (i) tokens, this is where we could be. I'm just going to take my finger and--whoomp--move it to the right one! So I can just move my finger over, so that instead of expecting a (c), I've seen the (c) if (c) was the ith input token. This is a prediction we're making: (c) may come in the future. I go look at what the user actually entered. If (c) was actually the next token in the input, the next letter they typed in, the next word in the program, then I can shift over it and say great--we have parsed that, that's just what we were expecting, that totally fits our plan--no problems at all. So if we were in chart[i], I'm going to put this new information in chart[i + 1] because, remember the number here in the chart corresponds to how many tokens we've seen. And we're only in this brave new world after we've seen the (c). The (c) was one token; previously we'd seen (i) tokens , so now we've seen [i + 1] tokens. This entire approach is called shifting. Let's test our knowledge of using shifting to fill out the parse table: the chart. Let's say that this is our grammar: P reduces to or can be rewritten as: open parenthesis P, closed parenthesis. or P can just disappear. Sometimes we write the epsilon and sometimes we don't--whatever we'd prefer. So chart state[0] includes the following parse states: (P goes to: here's right where I am, open P, close) or (P goes to: here's where I am and then there's nothing more), both coming from state[0]. What I'd like you to tell me is: What are we going to put in chart[1] if the input is ( ) because of shifting? What's shifting going to add to our parsing chart? In this multiple choice quiz--actually, there's only 1 right answer. Which one is it? Well let's go back and remember our rule for shifting. It only applies if we have a dot in front of a token, so we have sort of 2 possible worlds here: this has a dot in front of nothing, and this has a dot in front of a token. We are definitely going to use the dot in front of the token. And then we need to look at that token, and it better match the next part of the input. So we haven't seen anything yet--is the next token an open parenthesis? Oh, it is! We're so happy, this is going to work out perfectly. So then, conceptually, what I do is just shift my finger over one, just a step to the right. So let's go see which one of those that looks like. It should have this dot moved in, inside the parentheses. Well, this does not quite match. It doesn't have the parentheses at all--this represents using the wrong rule. Over here, we've got the right rule, but we didn't move the dot. This is just the parse state we started with previously. So that's not the result of shifting. This, however--this is looking very promising. We've moved the dot over one-- so now it's inside, and we haven't changed this starting offset. We're going to put this in chart[1], and this information assumes we started with zero tokens . Then we saw this left parenthesis and Here's where we are now. Finally, in this last one, We've mistakenly updated the starting position or the (from) information, and this would correspond to some other hypothetical input where we had already seen one token, and now we've seen one more open parenthesis and we're expecting to see a few more. That's not the input we're currently given. This doesn't match--there are no hidden tokens to the left that aren't shown in the rule. So now we really want to use the full power of our rewrite rules to help us complete the parsing chart. We've already seen 2 possible ways to do it. If the dot is right before a nonterminal, then we take the closure or predict what's going to happen, by bringing in and rewriting rules that start with a (c). If, on the other hand, the dot is right before a terminal, a token--a fixed part of the input-- we shift over it. We just move our finger to the right, assuming that this new token, (c), is exactly what we see in the input. But there is a third case--a "corner" case: 3 corners--that's hard to draw; actually, that's not hard to draw; something with 3 corners is a triangle-- in which there's nothing after the dot. What if there's no (c) and there's no (d), and we've reached the end? We've done a lot of shifting and our finger is already as far to the right as it can go. Well, now we're going to reduce-- by applying the rule: (x --> a b) in reverse. For example, let's say that the input was: <a b blah> and we were right here--we'd seen these 2 characters-- and one of the rules in our grammar was: (x --> a b). I match up this (a) with this one, this (a) with this one-- and I'm going to take my input and conceptually change it, removing the (a b) and replacing them with (x) as if I'm constructing the parse tree or applying the rewrite rules in reverse. We've seen before how one direction corresponds to string generation, and one direction corresponds to parsing. So once we've matched our predictions exactly, the input has corresponded to (a) and the input has corresponded to (b) and we have rewrite rule: (x --> a b), we're going to apply that rewrite rule in reverse to do parsing--removing (a) and (b) from the input--conceptually-- and replacing them with (x). This is called reduction. So to get a better feel for this last way to fill out the chart, I'm going to walk through a bit of a parse to show you how it goes. I've got the grammar here in the upper right and here's my input string, and I'm going to abuse notation a bit, by using this red dot again to mean: Where We Are. So, conceptually, one of the first things we'll do is shift. We saw the integer token, and we were expecting that because one of our parse states here was: (E --> red dot int) from zero. But now we want to turn this (int) into an (E) by using this rule, in reverse. And that's a bit magical for now, but we'll see why we want to do it, real shortly. Then we'll want to shift over the (+). It fits with our grammar and it's the input token we saw, and next, we'll want to shift over this (int). And now we'll want to replace this (int) with an (E), just like we did above. So this was another instance of magic or this third new rule that we're going to be talking about. And then, finally, now we've got an (E + E) and if we look up here in our grammar, (E) can be rewritten as (E + E). So we use magic once again, and the process will continue. Each of these times, when we've taken a token or a terminal in the input and replaced it with a nonterminal, has been an instance of reduction. And if we were to view this in the opposite order, we'd see it as a parse tree. At the end of the day, I'm going to ally it a lot of details. We'd end up with this; and the shrinking input, as I replace these terminals or tokens with nonterminals, sort of corresponds to how my tree edges in here--same sort of pattern. I have more and more Whitespace on the left, more and more Whitespace on the left. So the relationship between this magic step and parsing should be pretty clear, but I still need to tell you how to do it-- how do we actually perform reductions. Suppose we have the parsing state: (E --> to E + E), and we've seen it all. There's nothing more in the future to see for this particular rewrite rule. Coming from chart state [B], we've previously seen (B) hidden tokens that aren't shown here on the left and this is all in chart state [A]. I'm leaving (A) and (B) abstract so that we know how to write a general program that does this. We decided we wanted to look for (E --> E + E) all the way back in chart state [B]-- all the way back, after we'd seen B inputs. So if we view this as our input or sort of the bottom edge of our parse tree, as we're working on constructing it, these are some previous input tokens-- maybe previous ints, previous pluses, maybe parentheses--if we extend our grammar. And at this point, we decided: I think I'm going to see an (E + E) in the future. And now we have. We've seen all three parts of it. So conceptually, it's as if we've seen the (E) right here. Let me firm this up with a concrete example. Let's go back in time and look at where we came from. Suppose I extend our grammar so that is has both Addition and Subtraction--whoa, the power--let's not get drunk! And one of our previous states in chart [B] had been: (E --> to E), minus--this is where we were, and we were expecting an expression in (E). So by reduction--by prediction-- we would have added in expectations to see things like (E + E). And in fact, that's where we got this state--that's why it says "from B"-- we brought it in in chart state[B], based on doing the closure here. Well, now we seen enough input to actually make a single (E). We've seen (E + E); that reduces to (E). So it's as if we have this (E) in our input and we're going to shift over it. In some sense, this third approach--doing reduction-- is like a combination of the previous two. If I've computed the closure in the past, and now we've seen enough of the input to actually use a reduction rule, it's as if I put an (E) in the input and we're going to shift right over it. So I'm just going to shift my finger over one, shift it over this (E)--where did this (E) come from? It came from here. We'd finished seeing all of its subcomponents. We now have a big (E)--whoop! We're done with it. Here's the real trick: this is one of the tricky parts of doing these reductions-- note which chart state I added it to. We added it back to chart[A] because I don't want to forget that we've already seen a lot of these tokens. Remember the particular index we're using into our chart corresponds to how many of the input tokens we have to have seen so far. (A) was the farthest to the right, (B) over here. We definitely want to remember that we've seen all of these tokens in order to get to this point. This is the trickiest rule, so we'll do a worked example together, and then I'll ask for your input. Let's say we have the following grammar--if you look carefully at it, there's actually only one string in the language of this grammar: (a, bb, c). But I've added some extra nonterminals so that we'll get a chance to see how (bb) reduces to a bigger (B), by applying this rule in reverse, and then we keep going and do all the parsing. Unsurprisingly, the input will be: (a b b c). The only string in the language of the grammar, it's "bee-tastic". And now I'm going to work on making the chart. So let's say we haven't seen any of the input yet. We pick our starting nonterminal and, by convention, that's just the first one I mention. And actually, this is all there is; there's only one rule for the starting nonterminal. We haven't seen any of the input yet, and this red dot is not before a nonterminal so there's no closure operations to do. So we're totally fine--that's our entire parsing chart state. Now let's say we've seen one part of the input. We've seen the first token, (a). Well, that matches up exactly with the token we were expecting, to the right of the red dot, so we get to shift over it. And now I want to go back and make sure that we're recording all the right information. Officially, we need (from)-or position information-- for each one of these parsing states. So here, we came from zero--we hadn't seen any tokens yet. This rule, we brought over from the previous state by shifting. It's still (from) position zero. There's nothing in the input that's not already visible here on the right-hand side. But now I'm going to bring in the closure, and we decided to perform the closure in state[1]. So we write a (from1) here. Another way for you to think about this (from) or starting position is: there's really one more token--the (a)-- that would be here on the left, but I'm not including it. So that's the one token we're missing. Here, the next input token is a (b). So can we shift on any of these rules? Well, this has a dot before a nonterminal, so we can't do anything here. But this one has a dot before a token-- and it's the token we were expecting--we are so happy: (B goes to bb from 1) Now let's make the chart for 3 characters in the input. We've seen another (b)--so we go and look back previously. Are there any shifts we could do--oh--we could totally shift over that (b). All right. So here is the moment of truth for performing reductions We have the red dot at the end of a rule. There's nothing to the right of it, no more input to consume. So we're going to apply this (B --> bb) rule in reverse. So we're going to look back to state[1]. We're going to use this (from) information-- Where'd it come from? It came from state[1]-- and see: I could turn this (bb) in the input into a big (B), using this rule. Is there anyone who wants to see a big (B)? Back in state[1]? No--yes, there totally is! This rule here: (T) goes to (a) dot (Bc)-- it's really looking to see a big (B). But we just made one-- by reduction, by applying the rule in reverse. So, conceptually, you could go back and say: Oh--what if we'd seen this big (B) in the input? We've seen it right over here: (abb). Instead of seeing these two lower case (b)'s, we'd see the upper case (B). We'd take this rule-- and transplant it over to this state, being careful to retain the original (from) information. Now let's just interpret this (from) information. Starting from zero tokens, we've seen (abb) in chart state[3], and those are all represented-- they're all encoded in everything before the dot. In some sense, this lower case (a) has length1 and this upper case (B) had length2. Those two, together, add up to three. So I don't need any more hidden tokens to be in the third chart state. So this last part, where I--from here, Step 1-- went back over to here and found this rule, and then brought it back over here-- 1, 2, 3--this 3-step process-- is reduction. So let's say we have a slightly more complicated grammar. T is our start symbol; it goes to (p Q r) or (p Q s), so there are two strings in this grammar. It will 100 percent increase, over the previous grammar-- (p Q r) and (p Q s) are both there-- and the input is: (P q r)--wow, that's really lucky! That's one of the strings in the grammar. It's almost as if we planned these things in advance. So now we'll give you a chance to try this out. I have written down, here, five possible facts about the parsing chart for this grammar, on this 3-token input. Chart[1] has this, chart[1] has that. This is an element of chart[1], this is an element of chart[2]. And what I'd like you to do in this multiple multiple choice quiz is check all of the boxes that are correct. So if we do see: big (Q) goes to little (q) dot, from 1 in chart[2], check this box. Check all the boxes that apply. Well, if you'll permit me to doodle over our grammar, one way to get started with this is to think about what's in chart[0] These two are in chart[0]: (T --> dot p Q r) and (T --> dot p Q s), and we have seen anything yet. So if we start from that, in chart[0], the only operation we can do is to shift to get to chart position [1]. Shift over the input <p> if that's actually the first character of the input. Well, it totally is--that's super convenient. So we're going to move these dots over here and get: (T --> p dot Q r) and (T --> p dot Q s) from zero, in chart state[1]. Oh--so both of the first two are correct. Now we're going to have dots in front of the (Q). So we're going to bring in (Q --> dot q) from 1, in chart position 1. Now we're going to look at the input again and see that the next token is actually (q). So we're going to shift over this and put the result in chart[2]. So in fact, this one's correct as well--wow, we're on a roll! Now the last 2 involve doing reductions. We see: (Q --> q) and we've seen all the input we need by the time we're in chart state [2]. Zero, 1, 2. We've seen 2 characters for the input. So we're going to go back to states that had a dot in front of a big (Q) and say: we have found your big (Q) and we're done with it. So chart[1] had a dot in front of a big (Q). We'll conceptually shift over it and chart[2] will now have the dot after the big (Q). And another way to interpret this is: after seeing 2 characters in the input, we could be here. Well the first character is (p)--great. And the second character is little (q), which we reduce up to big (Q) so, yeah-- this is totally where we are; my finger is right there, starting from zero, with no more hidden tokens on the left. So, in fact, both of these are also right. We will do the reduction and do this sort of pretend shifting, for this first rule, and also for the second rule. In general, we do all the shifting, all the reductions, all the closures possible. Boy, it's a good thing we're going to have a computer program do this for us because doing it, by hand, is starting to get long. This was a particularly tricky quiz, so don't feel bad if you missed a few of these. In the end, though, all of them were right. This particular chart-based approach is due to Jay Earley, a computer scientist and psychologist. And now that we've seen all the theory behind it, we're going to code it up in Python together. Now one of the tricks that's different between this and Memo_Fibo is that our chart may have many things in it. One of the differences between this chart-based algorithm and our memoized Fibonacci is that our charts hold groups--lists, sets--of items. After we've seen one token of input, there's an entire collection of parse states that we could be in. So we're going to represent that by having our chart be a dictionary that maps from numbers to lists. But we're going to use those lists-- we don't really want any duplicates, Just like we saw with Memo_Fibo, we want to keep adding things to the chart until we're done. We want to be lazy and not do any extra work. So I don't want to add any duplicate entries to the chart because that'll just be more work for me to do later, and it may not settle down. So I'm going to write a special Add procedure, treating the right-hand side of the chart as if it were a set. And you may have seen sets in mathematics, but if you haven't a list can have elements repeated. I can have this list: [1, 2, 2, 3]. But in a set, each element can occur, at most, once. So if I were to put: {1, 2, 2, and 3} into this set, I would just get: {1, 2, 3} as the final result. When you're about to put something in, you check and see if it's already there, and if it's already there, you don't do anything. I'm going to have you implement that set for me. What I'd like you to do is write a Python procedure, using the Interpreter called: addtochart that takes 3 arguments: the chart, a Python dictionary, the index, a number, and the state--more on that later, but it could be anything-- and it ensures that if I go look at chart[index] later, it will return a list--it will evaluate to a list-- that contains state exactly once. So if state was already in chart[index], don't do anything. If it wasn't, you want to add it. addtochart should return true if something was actually added to chart[index], and return False otherwise-- False if if was already there. And we're going to us this so that we can tell if we actually updated the chart and then if we didn't update the chart,maybe we're closer to being done. To simplify this problem bit, you can assume that chart[index] is valid--that index is already in this mapping and that it returns a list. Let's say it's the Empty list, if we haven't gotten started yet. But it's, at least, going to be a list. Go forth! Let's write out one way to do it together. We're definitely going to need an if statement to tell the difference between whether state is already in chart sub index and whether it's not. Let me do the hard case first. I'll check to see if that state is in the list returned by chart bracket index. If it's not, we have to add it. One way to add an element to a list is to make a list out of it and use list concatenation or list append. Here, whatever chart[index] used to contain, we add that to the list containing just state, and we store the result. In this case we return true. Otherwise it's already there, so I should not do any updates. I'll just return false immediately. The key tricks--I have to check to see if state is in chart sub index, and if it's not, I have to make a bigger list that contains all the old stuff we used to have plus the new state we're being asked to add. We're going to use list comprehensions to help us write our parser. We were introduced to them earlier, and many computer scientists love list comprehensions because they allow you to state what must be true about a list and let the computer figure out how to get there. Just to remind you a bit of list comprehensions. We use the square bracket to say, "I'm making a list." but instead of listing all of the elements directly, I have some sort of formula. What I really want is to take all of the elements in 1, 2, 3, 4, 5-- let's call each of those x. I want my new list to be all of those squared, so x items x. So 1, 2, 3, 4, 5 should give us 1, 4, 9, 16, 25, and down here in the output it does. In list comprehensions we can also put little clauses or guards to only take some of the input list. Let's say that I only want to square those numbers that are odd. I write everything just the same as before, but at the end I put in this little guard that says "only yield this element if x modulo 2 is 1." That is, if x is odd, if the remainder when dividing x by 2 is 1. The second list only contains 1, 9, and 25 for the numbers 1, 3, and 5. We had our little refresher on list comprehensions. Now we want to parse a string according to a grammar. Let's say our grammar would look like this if we wrote it down on a piece of paper. We need to encode it in Python. Here is one way to do it. I'm going to take all of the left hand sides of all of the rules and write them out as the first part of a tuple. Then all of the right-hand sides, like open P close, becomes elements of a list-- open P close. Here my grammar had three rules, and here my grammar is a list of three elements. The second element corresponds to my second grammar rule-- P on the left-hand side, P in the 0th position, open P close on the right-hand side, open P close in a list on the first position. I'm going to need to do the same thing with parser states. Here is how I might draw on in color on a piece of paper, and here's how I'm going to encode it in Python. This is just one way to do it. We could pick a different way, but this is going to simplify our implementation. There are really four parts of our parsing state-- the left-hand side nonterminal, some list of terminals and nonterminals before the dot, some list after, and j. The right arrow, the dot, and the word "from"--we always have to write them, so I don't need to store them. I'm not going to write down "from" every time. We'll just remember it. I'm just going to make my state a 4-tuple, but instead of it being 1, 2, 3, 4, 1 will be the nonterminal on the left. This will be a list of a and b, and there might be more things here, or there might be nothing at which point it's the empty list. Three will be a list of things after the dot. There might be more things there, or again, there might be nothing, at which point probably we want to use reduction. Then j will just be some integer. Now you, via the interpreter, are going to write the first part of our parser. Our parser is just going to build up this big variable chart. We've already seen how to seed it with an initial value for chart state 0 and also how to see if a string is accepted by a grammar-- it's in the language of the grammar--by checking chart t if there are t tokens to see if it has the final state. Let's say we're deep in the middle of this. We're currently looking at chart sub i, and we see that x goes to ab dot cd from j. We're going to write the following code in our parser. We're going to call a special function called "closure" and pass it the grammar, just as we described before. I, which is going to be a number, that's the chart state we're looking at. X, that's going to be a single nonterminal. Ab, that's going to be this list here--could be empty, could have many things. And cd, that's this list here--could be empty, could have many thing. This closure function is going to return all the new parsing states that we want to add to chart position i. It's going to return a list of next states. For each one of those, we're going to add it to the chart. We've already written addtochart together, and we're going to figure out if there were any changes over all of the things you returned. For example, let's say you returned three things but two of them were already in the chart. Since at least one of those was a change, then we want any changes to be true. This blue code here, this is locked is stone. I'm definitely going to use this. But you can write any definition for closure that you like as long as it correctly implements how the closure is supposed to work. Go forth. This is relatively tricky, and here is my hint. If you're stuck, do a list comprehension over the grammar rules. Remember that you're trying to return states, and every state is pretty much like a grammar rule but with the addition of that red dot somewhere in the middle. Let's write out one way to do this together. I will assign the return value to this variable next_states, and then we'll just return next_states later on, but this will make it a little easier for me to think about it. The hint was definitely to do some sort of list comprehension over the rules in the grammar. That's going to look something like this. For every rule in the grammar put something in our output. Well, if there was something like E goes to xyz in our grammar, and we're bringing in the closure on E, the state we want is really just E goes to the red dot is all the way to the left, and everything that was the right-hand side of the rule comes to the right of the red dot. Remember that we're encoding parse states as simple tuples. The first part is this big nonterminal. Well, that's just the 0th part of the grammar rule. That's just E over here. Then the next part is what's before the red dot. When we're computing the closure there's nothing before the red dot. That's this white space right up here. Then there's what comes after the red dot. Well, that's xyz. That was just the second part of our grammar rule. Then finally we need to know what the current state is. For us, based on our definition of closure, and you can go back and take a look if it has slipped your mind, that's just i--the state we're currently looking at. When we're computing the closure, we add more information to the current chart state. This is pretty much two-thirds of the answer. The trick is there might be other rules in our grammar like T goes to abc, and we don't want to bring them in. We only wanted to compute this closure on E. We're going to need a little guard here in our list comprehension. I don't want to take every rule in the grammar and bring it in. I only want to bring in some of them. Well, what's the thing I'm supposed to be bringing in the closure for? It's based on cd. Cd is whatever we saw to the right of the dot. Remember that our current state is something like x goes to ab dot cd. First I have to check if cd is not empty. If it's not, then c is E, is the thing that we should be looking for. I only want to do this if cd is not empty and if this E, which was rule 0, matches the first part of cd. That is if this E is the same as c. If it is, we bring in the closure, and that's it. This is one of those examples that really shows off the power of list comprehensions. We want to take a bunch of grammar rules, slightly modify them into parsing states, and we only want to do that based on the rules of how the closure is supposed to work. Excellent work! You've just completed your first tough question on filling out the charts for parsing. Because parsing is everywhere in the computing world-- from HTML to E-mail, to languages like JavaScript or Python or C and C++-- this notion of memoizing-- writing down intermediate results so that we can refer to them-- is critical to performance; and because parsing happens all the time, this performance really matters. Now these are some of the first questions to really stretch our ability to do abstract reasoning, so don't worry if it's taken you a few more trials on these exercises than it may have in the past. On the other hand, we should definitely be excited about the goal that we're working towards. Very soon, we're going to have a complete parser for HTML and JavaScript. We've seen before that there are three ways to build up the chart. One is by calling the closure or predicting. The next is by shifting, and the third is by performing reductions. I'm going to have you do all three, and this is the second one--shifting. Let's say we're currently looking at chart sub i, and there is a state in there--x goes to ab dot cd from j. This time we're going to look at the input tokens, and they're in a list called just "tokens." I'm going to have the following code in our parser framework. We're going to figure out if there is a candidate next state by calling a special procedure "shift." Shift gets to see the tokens--the entire input, which token we're on, also which chart state we're on, x, ab, cd, and j, the current state we're considering. Based on that there may either be a possible shift or there might not be. Shift will either return None, at which point there is nothing to do, or it will return a single new parsing state that presumably involved shifting over the c if c matched up with the ith token. Then we'd add that to the chart in position i + 1, the correct place, and we'll keep track of whether there have been any changes. You should write shift. Now let's walk through how shift might work together. We can only shift if the next input token, the one we're currently looking at, exactly matches c, the next thing we expect to see. Now, you might have been tempted to have an i + 1 in here, but remember that in Python lists and strings are indexed from zero, so tokens bracket 0 is actually the first element of the input. One of the first thing we have to do is check and see is cd empty or is it something? Well, if cd is not empty, then we can take a look at its first element c, and we'll just check to see how that compares to tokens i. If they match exactly, then we can shift over that token. We're going to return a new parsing state that still has x at the front, but now instead of ab it should have abc, because we're shifting the red dot one. Remember that c was the 0th element of cd. We've shifted the red dot over one, and now instead of cd on the right it's just going to have d on the right. We want to peel off the first element of this list. We can use Python's range selection to peel off all but the 0th element. Let me just make my writing a bit more clear there. This was really from j, and we are also from j. If the stars did not align--either if cd was empty or it didn't match up the next token-- then we were supposed to return None. Now we are ready to finish off our parser. There were three ways to add to the chart, and you've already done one and two, computing the closure or predicting what's happening next and shifting. The last way is reductions. Let's say once again that we're looking at chart i, and one element of it is the state x goes to ab dot cd coming from j. I'm going to write this code. I'll lock it into our parser. Next_states equals reductions, a function that gets to look at the chart, i, x, ab, cd, and j. It's going to return a list of possible next states. For each one, we will add it to the chart and notice if anything changed. Reductions are relatively tricky, so my first hint for you is you only want to do reductions if cd is empty. Remember reductions only apply if the red dot is as far right as possible. My other hint for you is that you'll have to look back previously at the chart. Remember when we worked through examples together, we'd start over here, go back over the chart, and then go back to the right. You'll have to do the same sort of thing, so we're passing in the chart. Try it out. This one's a bit tricky. Let's go through one way to do this. Hopefully what we're currently looking at is x goes to ab dot nothing come from j. Hopefully then, if we look back to chart j where we originally came from, it will have some rule something go to blah, blah, blah dot x. This is the important part. We're reducing goes to ab, so I really hope somebody was looking for an x. If they were, then that can be one of our reductions. Once again, we're going to use the phenomenal cosmic power of Python list comprehensions. In general, we're going to take all of these states that were already in chart j and just modify them a bit. Let's call each one of those states in chart j jstate. Conceptually, what we're going to do is move the red dot over one. Our return value, the new state we're returning, is going to have this same y that we saw from jstate. Whatever that is that's still going to be our left-hand side. Then we want to take whatever jstate had before the dot, and that corresponds to all of this stuff that I've sort of left out here, but then add on x, because we're shifting over x, conceptually, as we do the reduction. Now we want to take everything jstate had after the dot, except we want to remove the x, because we shifted the red dot over it. Everything jstate had after the dot was j-state bracket 2. and we're going to do range selection on that to get rid of the first element. Then it looks like I can't preplan. Whatever this k value was, we're just going to leave it alone. Jstate 3 corresponds to k. However, we only want to do this if certain conditions hold. First, cd has to be the empty list which corresponds to this red dot being as far to the right as possible. The second thing we have to check for is that this x and that one match exactly. This x was the first element of jstate 0 1 2, so I'll check to make sure that jstate 2 is not empty. If this red dot were all the way to the right, there would be nothing there to check for. If it's not empty, I'm going to check its first character and make sure that matches up with our x. Those are all of the states we bring in as part of doing reductions. All right. Now that you've gone to the hard work of defining all of those procedures, let's see the big payoff as we use it to parse arbitrary strings in arbitrary context-free grammars. Here I've got the procedure addtochart that you wrote. We have the procedure closure that you wrote, once again defined using list comprehension. We've got shift, which either returns something or nothing. We've got reductions, which has a complicated return based on jstate in the chart. Way up at the top of this file, I've defined a particular grammar. It's that grammar of balanced parentheses. This is just our encoding of start symbol goes to P, P goes to open parentheses P, P goes to nothing, and then down here I've got a candidate input open open close close. That's in the language of the grammar, so I desperately hope that our procedure is going to find that out. Down here I have the parsing procedure skeleton that I wrote around your code that does the heavy lifting. One of the first things I do is take all the input tokens and add in a special endofinput marker. That's because sometimes we need to look ahead, for example, for shiting to see if the input token matches what's there, and I don't want us to walk off the end of a list. I'm just sort of padding out data structure by one. Here is the chart. It initially starts out totally empty. It's a Python dictionary with nothing in it. Our starting rule is just the first rule in the grammar. That's by total convention. We're going to start with S goes to P. I pre-initialize all of the elements of the chart with the empty list. Remember in that quiz I let you assume that it would always a well-defined list. I'm making that true here. Then our start state just works on this start rule. It uses this same symbol S. There is nothing before the red dot. Then we've got the red dot, then we've got the P, and that's started in state 0. Initially, the only thing in our chart is that at chart position zero we have this starting parsing state. What we're going to do is be super lazy and write ourselves a bunch of memos in this chart. Over and over again we're going to consider additional characters in the input and keep using your three procedures of closure, shifting, and reduction until there aren't any more changes. I is going to range over all of the possible tokens. Then until there are no more changes, we consider every state in the chart, and the state is something like x goes to ab dot cd from j. I just extract those into conveniently-named variables by pulling out the 0, 1, 2, 3rd element of this tuple. Now we're going to go through 3 options that correspond exactly to the work that you did. If the current state is a ab dot cd, we could compute the closure. If c is a nonterminal we look for each grammar rule c goes to pqr, we make a next state, blah, blah, blah. Here we're about to start parsing c, but c may be something like expression with its own production rules. We want to bring those in. Here is the code that I promised you in the quiz that I would write. Next_states is a called to closure. You implemented closure. Then we checked to see if there are any changes. In addition to the closure, there is also the possibility that we're going to do shifting. Ab dot cd, and if the tokens are c, if the next token is c, then we're totally going to shift. We're looking for parse token c, and the current token is exactly c. If that happens we are super lucky. We can parse over it and move on to j plus 1. Here is the code that I promised you in the quiz I would add, and there it is. Finally there is our third option for computing reductions. This one is the most complicated. If cd is empty we then we go back in time to chart j and bring something from it forward to this current location. You just finished implementing that. Down here we have the code that I promised that I would include in the parser that calls your function reductions. Then we're just going to keep repeating this until nothing changes. Remember that this was in a while true loop, so we're going to loop over and over and over again until there are no changes, and then we break out of the loop. Down here I have some purely debugging information. This is all just to print out the chart at the end so that we can take a look at it. We wouldn't actually need this if we were doing a parser. This is for explanatory purposes only. Then down here I've defined the accepting state. We reasoned to this earlier, which is basically the starting state, but with everything to the left of the red and nothing to the right of it, coming from state zero. If the accepting state is in the chart in position t when there were t tokens, then we parse the string successfully. Otherwise we do not. Down here, I'm checking to see what this value is. Is this string in the language of the grammar or not? We just print that out. In this particular example, the string is in the language of the grammar. Hopefully, that's what we'll see. Well, our output is quite voluminous. We see chart position 0, chart position 1, chart position 2. In fact, this was our starting state, S goes to dot P from 0. Then we brought in these other two from the closure. A good quiz question to ask yourself is why do we have this one--S goes to P dot from 0? My hint is P can go to nothing, so actually the empty string is accepted by this grammar. We end up filling in 0, 1, 2, 3, 4. This one actually corresponds to look ahead, that sort of end of input symbol that we saw there. Eventually we discover that wow, our string is in the language of this grammar. We're so happy. This is exactly what we wanted. If I were to change this a bit. I've been very minorly devious. Now, instead of having balanced parentheses, I have three open followed by one close. Now I've changed it so that the strings shouldn't be in the language of the grammar. We have three opens followed by one close. I click run. The chart is actually going to be very similar at the beginning, changing only near the end--possibly a little bit. But now we report that the string is not in the language of the grammar as expected. Now, one of the big draws of having a universal parser like this was that I could fill in any context-free grammar and check any string of tokens against it. For example, here I've defined a new grammar that accepts the word "prisoner" followed by a list of numbers. N is a list of numbers. It's at least 1, but you can have more. This is a recursive rule so we can have as many as we want, and I've gotten lazy. We only put in 0, 1, 2, 3, 4, 5, 6, but I could go all the way 7, 8, 9, 10. One of my favorite prisoners is number 6. Let's go see if this string, prisoner 6, is accepted by this grammar. Here the chart is a bit bigger, because we have sort of a separate state for each one of these. This makes us glad that the computer is doing the memorization instead of us doing it by hand. But down here at the end we accept. By contrast if I just have the word "prisoner," this shouldn't work, because this list requires 1 or more integers. And in fact down here we can see that it is not accepted. Let's do just one more of these. If there were another prisoner vying for the affection of my heart, I'd ask you to bring me prisoner 24601. Perhaps his time is up and his parole has begun.You know what that means. Let's check and see if the string is accepted by the language of the grammar. Here, all the way down at the end of the day, we see that prisoner 24601, famously Jean Valjean from Victor Hugo's Les Miserables, a nice piece of French literature, is accepted by the language of this grammar. But we have a large number of chart states--5, 4, 3, 2, 1, 0--to accept this string. Let's do one more of these just to show off our very arbitrary power. Now I've put in the B grammar from before. We know how this one is supposed to work because we did it out together on paper. The input string I've put in is abbc, and that string is in the language of the grammar. If I forget one of the b's, we expect it not to be. When I forget one of the b's it is not in the language of the grammar. The real trick is basically that you have done it. This is enough of a parser to be given a formal grammar for JavaScript or HTML and determine if a string, a webpage, a program is in that language. This is very exciting. So now we have all the machinery we need to tell if a string is valid. However, it's going to turn out that's not enough. Remember those upside down parse trees we talked about earlier? We really wanted those, as well, for our HTML and JavaScript programs in order to interpret them--to get at their meaning correctly. So here, I've written a pretty standard arithmetic expression grammar. An expression can be a number or an expression plus an expression or an expression minus an expression or maybe a negated expression, like negative 3. And we'll want to build up parse trees for this. Now this time, I've written the tokens as plus and minus and not instead of the symbols, + or -. That's our choice; we can do it either way we want. And the particular format I'm going to pick for our abstract syntax tree is nested tuples--or nested lists, in Python. So if we end up using this rule: expression goes to number, we're just going to return the tuple: ("number", 5)--if the input was 5. Similarly, if the input is something like: not 5, We'll end up returning: ("not", of the "number", 5). Note the nesting. So let's say I call this number: number 1. We really want to return this tuple: "number"--in quotes, just as a string, so we know what it is-- followed by the value of the token. If this was Thing Number 2 in our reduction rule-- not expression--I'd really want this to be filled with a 2. If over here, this was a 3, I would want to return "binop". That stands for Binary Operator, binary just meaning "two things". So things like: Plus, Minus, Times, and Divide-- those are arithmetic operations that take two arguments-- one on the left, and one on the right. We call those Binary Operators, as a class, just to save space. But whatever this third expression was, that's what I'd want this subtree-- this subpart of my tuple--to be. So just as we've seen before how we can encode token rules in Python and do some processing, like chopping off the quotes after we've specified how the token works, using regular expressions, it's going to turn out that there's a similar way for us to do that for grammar rules in Python. Now let me explain a little bit about what's going on. This format is totally arbitrary, but it's going to be very easy for us to use for assignments and to test your knowledge. For tokens, we used a "t_" to mean I'm defining a rule for a token. For parsing rules, we're going to use a "p_" to define the name of a parsing rule. And then here--just to help us out-- we're going to write down what the left-hand side of the rule is. This is how you parse an expression when that expression is a number. And just as out token rules were, in some sense, under-the-hood functions of this object, (t), our parsing rules are under-the-hood functions of this object, (p). And this is the parse tree-- or, more accurately, a number of parse trees. Here's our rule, written out, and this is very similar to: (exp --> number)--except that there's no great way to write the arrow, so instead, we'll just write a colon, by convention. But you should view this as the arrow. So this is: expression can be rewritten as NUMBER, and we just put it in quotes, like a string, and then down here we have to tell Python--or tell our parsing library-- how to build up the abstract syntax tree. p[0] is our returned parse tree. The numbering here is every one of these elements of our grammar rule-- except the colon gets a number. So the expression on the left is zero, This NUMBER over here is 1. So the parse tree I want associated with this expression, when we're all done, is a tuple that I make, by combining the word "number" with the value of this actual token. Let me show you another one of these, and then it'll be a little clearer. So here, once again, I start with the (p_). We're going to do that for all of our parsing rules. Here's what I'm telling you how to parse; I'm telling you how to parse an expression. There might be multiple different ways to parse an expression. It could be a number, it could be a (not) expression. So we use another underscore, in being a little more specific. And then down here I've written out my grammar rule in almost English--and again, this colon is like the arrow that we would normally draw. And then below that, I have written out how to construct the final abstract syntax tree. This expression is number zero, this (not) is number 1, This expression is number 2, so we want our parse tree for number zero to be the tuple I make, by putting the word "not"-- so that I know what it is--in front of the parse tree for number 2. If we were to see the input: NOT 5 executing these two rules, in the right order-- this one first, and then that one-- would give us this tree: "not", ("number", 5). Note the nesting. I could alternatively draw it as-- This is just a Python was of encoding this visual representation. So let's say that we've put in these 3 parsing rules into Python. We are trying to get back to parsing HTML. We want to understand how to parse Web pages and turn them into abstract syntax trees. And a Web page is just a list of elements. So it's either an element, followed by More or We're Done Now. And elements could be a number of things, like tags or maybe-- more simply, just words. Suppose our input is two words: Rama's Journey. What I'd like you to do, as a quiz, is submit, via the Interpreter: Define a variable that holds the final parse tree for this input. And again, the input is 2 words: Rama's Journey. Well, let's think it through together, and then write out the details. At a high level, this is going to be: an element , an element, and then Empty. So we're going to end up making a list that has element 1 in it and element 2 in it, and then nothing else-- based on this rule up here, where we just make a bigger and bigger list, out of the list containing the first element and everything else we've gathered up. So this will be the final value of our parse tree, corresponding to this more graphical parse tree-- really more of a list, but a lot of things in computer science are. Rama's Journey is more commonly known as the Ramayana. It's a Sanskrit epic that's a very important part of the Hindu canon and it explores human values and Dharma. If you haven't already had a chance to read it, I strongly encourage you to make a rendezvous with Rama. It's time well spent. Let's say we want to continue formalizing our HTML grammar in Python. One of the other types of elements in HTML, aside from bare words, is tag-decorated words. You might put <bold> or an <anchor> or even something more complicated, like this, that changes the color. So just to remind you of what these HTML tags look like, they start with this Left Angle, there's some name; they might have some arguments, there's a Right Angle; there can be any HTML in the middle; then there's this Left Angle Slash, another word, and a Right Angle. And here, I've just written out that grammar rule: this LANGLE corresponds to this part. this word goes here, tag arguments--color = "Red", Right Angle is that one, HTML is here, LANGLESLASH is these two, and so on. And, here, I'll build up my parse tree by using part[2]: zero, 1, 2, the word, like span or bold or underline; the tag arguments--if there are any, the body--the words that are being modified by bold or underline, and then, finally, the final word-- just to make sure, later on, that you've opened <span> and closed </span> or opened <bold> and closed </bold>. Remember, we want those parentheses to match. And our input text is: hello <baba> yaga, and we've got <baba> bolded. I'm going to ask you to take apart this concept and do it backwards. I have written out the parse tree, down here at the bottom, but I've left 3 blanks. I would like you to fill in the blanks with a single word that will make this parse tree correspond to what our parser will produce on this input. Well, let's go through it together--our parse tree is just going to be a list of elements, and here there are three: hello, the tag element, and yaga. And hello is just a simple Word_element so it fills in our first blank. Then we've got this tag_element and the trick to getting this question right is looking at the order in which we store them up here-- more or less in order of appearance. So since this is a <bold> tag, when this next part here is a (b), this empty list means there were no particular arguments to our <bold> tag. Here, I'm seeing arguments: color = "red". There's nothing like that down here. And then inside, we've got the Word_element, baba--and then we're done. Baba Yaga was a crone or a witch in Slavic folklore who was known for--among other things-- riding around in a house supported on chickens' legs--fun stuff! Take a bow--we are done parsing HTML! That was it; we've seen all of the relevant rules. Well, I haven't actually shown you the detail for handling tag arguments, but we'll get a chance to look into that later. For now, let's go on to JavaScript, which is actually going to have very similar rules to HTML. You may have already guessed that a lot of the options in JavaScript are very similar. We have a large number of binary operators: Plus, Minus, Times, Divide, Less Than, Greater Than-- and it turns out that there is a very convenient notation when we're programming grammars, for getting those all in. Rather than having to make a separate little parsing function-- or parsing rule--for each one, I can just write out multiple related parsing rules in the same string, and give one piece of code that applies uniformly to all of them. So we said before that this colon kind of meant the arrow. This vertical bar--it's as if we had written this same nonterminal (exp) one more time, and then another arrow: expression goes to expression times expression. This is just a concise notation for your benefit, so that we don't have to type out as much. And here, I'm showing how to make a abstract syntax tree, which, again, for us is just nested tuples for a JavaScript binary operator. And, in reality, we'd want to add in another rule for Divide, Less Than, Greater Than-- we might have ten of these at the end of the day. But it turns out that our old friend, Ambiguity, is going to rear its head. If my input is: (1 - 3 - 5) there are actually two ways we might interpret that-- or two parse trees we might end up with-- and, depending on which one we pick, we get a slightly different answer. This could mean: (1 - 3) - 5, at which point, we'll get (-7). Or it could mean: 1- (3 - 5), at which point, we'll get (3). We say that this first option is what is known as Left Associative because it puts the parentheses on the Left or the tree ends up being sort of unbalanced towards the Left. Similarly, this second option is Right Associative. Well, just to make sure that we're following along with this, a brief quiz: If subtraction is Left Associative, what is: 1 - 2 - 3 - 4? Fill in the blank--single numeric answer. Hmmm--it turns out the answer we're looking for is -8. And here's how to see it: If Subtraction is Left Associative, then we want to put as many of these parentheses as far to the left as possible. So we're going to do (1 - 2) first, and then subtract 3--and then subtract 4. So (1 - 2) is -1. (-1 - 3) is -4. (-4 - 4) is -8. And that's the answer we got. So by this point, we've totally conquered Ambiguity, right? Ah--not so right. Even if I know whether an operation is Left or Right Associative, I'm still not sure, when there are multiple operations, which one to do first. I could do the Multiplication first, and get: 8 + 6 is 14 or I could do the Addition first, and get: 2 * 10 is 20. This isn't the same problem as associativity because it's not about whether we're associating to the Left or the Right, it's about the--sort of the precedence of these Operators. which one is more important, which one should I deal with first-- which one binds more tightly. In Standard mathematics, we'd want to do the multiplication first. Multiplication has higher precedence than Addition. It gets serviced first. Just to make sure that we're all on the same page about Precedence and the difference between Precedence and Associativity, let's say that Multiplication and Division have higher Precedence-- that is, you should do them first-- compared to Addition and Subtraction--and this is how we normally do things. Then what is: 3 * 4 - 8/2? Fill in the blank for this quiz. Well, the answer we're looking for is: 8. We just multiply the (3 * 4) first--that's a 12. And the 8 over 2--that's a 4; we do that first. We have to do both of those things before we can do the Subtraction because they have higher precedence. So we end up with: (12 - 4) is 8. Precedence and associativity were not so tough, which is convenient because they're also super easy in Python. For our parser, in Python, we can just write out a table: a single variable, called Precedence, that lists lower precedence operators at the top and higher precedence operators at the bottom. And I know what you're thinking: this is totally reversed-- and you're exactly right, but it's not the first thing we've grown upside down in computer science programming languages. So lower precedence operators that bind very weakly--up here at the top; higher precedence operators that you have to do first--down here at the bottom. And we can also indicate their associativity at the same time. So we're going to have our precedence and associativity. This says that Times and Divide are both left-associative and they're very high precedence. Plus and Minus are both left-associative and they're lower precedence. And then our parser will automatically get rid of the ambiguity for us by using these rules. So we're going to test out that knowledge by having you submit via the interpreter, as a quiz-- some parsing rules that are going to handle a real part of JavaScript. Now, a lot like Python, JavaScript allows function calls-- you write out the name of your function and then you just pass in some number of arguments, possibly none. For that particular function, we would want the parse tree to be a tuple. That's how we're representing parse trees. The first part is "call"--telling us that it's a call expression. The next part is the name of the function, and then there's a list of all of the arguments. And this list may be empty if there are no arguments or it may contain expression parse trees. And, in fact, I'll do the first and second parts for you. Here's a rule for making expressions that are function calls: That's an identifier, like "myfun", followed by a Left parenthesis, followed by some optional arguments, followed by a Right parenthesis. And we just build up our parse tree out of a tuple--the word "call", the identifier--that's p[1]--zero, 1, 2, 3, 4-- and the optional arguments are position[3]-- I definitely need the (p) there--there we go: p[3]. Similarly, our rule for expressions that could be numbers, expression can become a number, at which point, I just make up this tuple, "number", followed by the actual value. and that's how we got things like this for ("number", 11). So here's the quiz: I'd like you to fill in the value for parsing optional arguments, and you may find that you have to define a few more of these parsing rules-- maybe some for there being no argument, some for there being at least one, and that kind of thing--try it out. All right. Let's go through it together--for optional arguments, there are two possibilities. The arguments could be: at least one--some real arguments-- or they could be Empty. The first two lines are going to look a bit like this. We have to call our nonterminal (optargs) because that's what I called it up here, and it has to match. I'm just going to make up this new nonterminal, (args), meaning "one or more". If we don't see any of them, we can return the Empty list. This means there's one or more arguments so I'll just pass the buck and assume that (args) is magically going to make, for me, the answer I want. And I'll just copy it from p[1] into p[0]. One of the real tricky parts of handling arguments is that they're separated by commas, rather than terminated by commas. So once you have your first argument-- if you're going to have a second, you need a comma but otherwise, you don't. This seems a little weird when we say it verbally, but if you look at it, it's more or less just what we expect. If there's only one argument, then it's just an expression--some number. But if there are more, then we put commas in between them. So here, for multiple arguments, we have an expression, a comma, and then any more arguments we like. And then, finally, we get to the last one, which is just an expression. For this one, we'll just make a Singleton list out of the only argument you gave me. So this would be the list, containing (1), for this example up here. And in this other case--myfun(2,3)-- we take this first part--just the (2)-- and we put it in a list by itself, and then we use (+) to get list concatenation-- list.append--to put this single element list together with all of the rest of the arguments we've gathered up. That's it for defining parsing functions for function calls and arguments. So now we've seen all the gory details in how to implement parsing for languages like HTML and JavaScript. Recall that parsing takes some tokens as input and produces a parse tree-- something like this, perhaps. In our next exciting episode we're going to learn how to interpret languages by walking over their parse trees. For example, maybe this is equal to 7. Let's find out. So one of the topics we're covering in this course is Memoization or caching, writing down values that we've already computed so that we can be lazy and not have to recompute them later. We've used this as one implementation of parsing but in the Real World, it might come up in many other places. Brendan, have you had a chance to use it at Mozilla or in your other projects? Not so much in parsing because we are in a tight competitive regime with other browsers, and you have to parse very efficiently and lex very efficiently. But in building a browser, you end up memoizing or caching a lot. You end up trying to remember decisions you made that were expensive, that can be preserved under some rules and reused. We also have a memory management system that's quite complex. We have a garbage collector for JavaScript, we have a reference counting system for our C++ code. The two have to meet, and it's possible to form cycles, which then have to be collected. We use an old David Bacon data programming trick. It's Bacon and Rajan PLDI 2001, I think. It's a cycle collector for reference code objects, and it buffers pointers that it suspects of forming cycles. And a pointer, in a reference kind of graph, can form a cycle. Every reference count is going down, from above 2 to 1 or above so that you may still have a stuck reference there, due to a circle. And so we use these techniques. We constrain a little bit in using C++ that has to run on Windows, Mac, and Linux. But in Python and JavaScript, people memoize all the time. And there's a craze now for PEGs-- Parser Expression Grammars? I think that's the acronym; I always mix it up with something else. But it's a parsing technique that can use memoization when it's backtracking and accord it Choice, so we're familiar with this, and we try to use memoization to a good effect. At Mozilla we have less use in parsing--more runtime, I'd say. You've just learned how to encode a grammar for HTML and JavaScript, and that is no mean feat. In fact, a number of years ago, for my research, I had to do something similar-- but for perhaps an evil or more production, more popular language--Java. We wanted to analyze Java programs, to look for particular errors and there weren't really any convenient parsers available at the time. So I was faced with a decision: Should I use a tool that didn't really fit the bill? Or should I try and write my own? And I thought, boy, Java's a Real World production language; it's got to be really hideous to write down a parser for it-- I'm sure its grammar is really hard to follow. So I figured I'd give myself a day to look at the official Java grammar and try to write a parser for it, using the same sorts of techniques we've covered in this class. Imagine my surprise, when it turns out that the official Java language specification actually uses the same sort of format-- the same sort of context-free grammar that we've been going over here. In fact, if you'll take a look, their handling of if-then-else statements or argument lists should look very familiar to you. It's, more or less, exactly what we covered for JavaScript. And I ended up writing a parser for Java 1.1 at the time-- this was many years ago--that worked for our research. I was able to make a tool that fit me, even though there was none available, using exactly the sort of techniques that you have just mastered through. In this unit, we're going to be covering what programs mean and especially what they mean in terms of their context, the environment in which they operate. This is called formal symantics, and while it may initially seem a bit dry, it's actually one of my favorite topics in computer science. In fact, before my research moved on to the greater glory of fixing bugs in programs, I started out trying to find bugs in programs, and one of the surprising lessons in finding bugs in programs is that both the program and our idea of what it should mean matter. All of you have probably had a bug in your code at some point or another, and officially a bug is really just an instance where the program's meaning is different from its specification. What it does do and what it should do don't agree. A, perhaps, surprising result is that in industrial practice a lot of the time the mistake is actually with the specification, and you've probably seen this in real life. A friend might've asked you to do something. You go and do it faithfully only to discover that that wasn't actually what the friend wanted to have happen. It's just what they told you to do. The same sort of thing comes up in bug finding and bug fixing research. Often the formal specification for a problem, this would never happen for the homework problems here, is vague or imprecise. Not enough to tell you exactly what's supposed to happen. Regardless of whether the problem is with the source code or the specification, understanding what code means in context is critical to figuring out if it's right or wrong, and that's what we're going to do in this unit. [Narrator] Welcome back to programming languages. It's an exciting time, and the story thus far we have already completed lexing and parsing, but remember that our goal was ultimately to make a web browser? Let's see how things are going towards that goal. We are going to start with your average web page, a string of HTML with some embedded Java script, and we wanted to break it down into tokens or words, and that process is called lexical analysis. Once we have a bunch of tokens, we were going to parse those into a tree like one of these trees, and that approach is called syntactic analysis or just parsing, and now we want to walk that tree and understand it, and do useful work, and this is called either symantics, a fancy word for meaning, or interpreting. We want to look at this abstract syntax tree that has 5 and 3 as a child of plus, and say that means 8. And we want to do this for web pages, and the meaning that we're going to extract from them is what they look like. [Narrator] Thus far, we've only looked at the form of an utterance or sentence, what words it has, whether they fit the subject, object, verb kind of ordering, but we haven't really looked at what they mean. It turns out that these 2 are not the same thing, and one of the most famous counter examples comes, again, from our man Noam Chomsky with the sentence, "Colorless green ideas sleep furiously." And this is a sentence that's syntactically well formed. Idea is the noun; sleep is the verb. This is an adverb. These are all modifiers that make it a noun phrase, but it's not clear what the meaning is. Actually, let me try to sketch it out. We've got some ideas, and I hear that one always represents ideas with old tiny lightbulbs, except that our ideas are colorless so let's ignore this yellow somehow, and simultaneously green. This--it's not obvious how to draw this, and then there's sleeping, and I think the universal symbol for that in English is a bunch of Zs. The sound that snoring makes in colloquial English, but they're sleeping furiously so Zzzzz, lots of Zs, and as my total difficulty to sketch this, I should point out, well, A: I'm bad at sketching, but B: it's really not clear what this means. What does it mean for an idea to sleep? I thought ideas were conceptions that people had; can ideas go to sleep? And people can try to put poetic interpretations on this. You can imagine a sort of a prose or poetic way of reading this, but in general I can sort of alter the sentence and make it still syntactically correct but symantically more and more contradictory. It's really not clear what this sentences means. Turns out that we have similar notions in computer programming languages. In python, you can write 1 + 1 or hello + world and get reasonable answers out, but what happens if I try to write 1 + hello? This does not really make sense. It's not clear what it means to add an integer to a string, and in general if you feed such a program fragment or expression to a python interpreter, it will give you some sort of run-time era which is the equivalent of throwing up its hands and saying, "I don't know." Just to review what it means for a program to lead to a run-time era or to describe something that doesn't make much symantic sense, here I've written 4 program fragments, and what I'd like you to do is check each one that would lead to some sort of run-time era, and you have to assume that each one is a complete program. What you see is what you get; there are no other hidden variables or imports declared earlier. Multiple multiple choice, try it out. [Narrator] 2 + 2, we're actually pretty sure this works out. There's no error for this one; it's going to evaluate to 4. Down here Mars=Earth + 1. There is actually going to be a problem here, and the problem relates to Earth, which is a variable that's used before it's being defined, and python's going to emit some sort of run-time error saying, "I don't know what Earth is so I don't know how to assign Earth + 1 to the variable Mars." This one will result in some sort of error. Over here, we assign Mars to be 4, and that's totally fine, and then we assign Mars to be Mars + 0 or another 4, so no errors here, but, finally, in this last one, we take a string, Mars, and we add an integer, 2, to it, and we don't expect addition to work on both strings and integers. This one also leads to an error. Mars is sometimes called the red planet, the fourth rock from the sun, and among other things, it features very prominently in Gustav Holst's 7 movement orchestral suite, The Planets, which was written in about 1915, worth giving a listen to if you haven't yet run into it. So because we're going to be writing an interpreter for JavaScript in HTML, we're only really going to be able to interpret good programs successfully. That means we want to recognize and rule out bad programs. So here you can conceptually imagine some sort of border patrol or gateway crossing where our diligent customs agent is going to keep out bad programs, like this "1"+2, while allowing in super-happy-fun programs like 1+2. The process of looking at a program's source code, looking at its text, looking at the letters that make it up, and trying to see if it's going to be well-behaved or not is known as type checking or semantic analysis. And as you may already guess, it's not going to be perfect but it's going to be pretty good. Type checking and semantic analysis. Semantic means "meaning." We're going to break a program down into its meaning. And I'm going to explain types in just a minute. [Narrator] A type is just a set of similar objects like numbers or strings with associated operations, and we've run into things like numbers in strings before, but there are more exotic types that also support operations, and as we can see even from this little doodle diagram sometimes there are operations like plus that apply to all of these things. I can add 2 numbers using arithmetic. I can concatenate 2 strings or I can append together 2 lists. They mean almost the same thing but not really. Arithmetic addition is not really the same as string concatenation. Similarly, both strings and lists support length. Here, it's the number of characters; here, it's the number of elements. Each one of these things, number, string, list, is a type, and what we basically want to do is make sure that we're not mistakenly combining elements from various types or unsafely calling non-associated operations. For example, 5 divided by 2 makes a lot of sense, but the string hello divided by the string 6, we have no idea what this means. Division isn't one of the operators for strings even though it is one of the operators for numbers. Let me give you another analogy of this that sort of bares reference to the real world. The word execute can mean many different things depending on what it's being applied to. A computer can execute a program which means to run it or to carry it out. There are some governments in the world that will execute their citizens, and this means to kill typically in a judicial context. These do not mean the same thing, but the word looks otherwise similar, and it falls in the same sort of grammatical pattern. They're both verbs being applied to objects. We're going to need to tell the difference. In fact, in English--and in fact, in Greek--there is a particular form of word play called syllepsis, based on exploiting this semantic incongruity. Let me give you an example of what it looks like in natural language, and then we'll bring it back to HTML. In this fragment: "she made no reply, up her mind, and a dash for the door" "made" is being applied to three different things--replies, make up a mind, and make a dash for some location. And it means something slightly different in each of these. Making a reply means to speak. Making up your mind means to decide something. And making a dash for the door means to run for the exit. But because we have this one function, if you'll permit me, being applied to these three different types of arguments, there's an incongruity which some may find humorous. Here's perhaps my favorite example from the same source. "She lowered her standards by raising her glass, her courage, her eyes, and his hopes." This is a very good but very disconcerting poem and a lovely example of syllepsis. Lowered is being applied to standards; that means to give up your ideals or try something worse. Raising her glass, as if in a toast. Raising her courage--to muster up her willpower. Raising her eyes to look up at someone. And raising his hopes because, well, nothing good happens in this poem. Similarly, there's an error in HTML known as mismatched tags. We talked about balanced parentheses in parsing-- the same number of As followed by the same number of Bs, or the same number of open parentheses followed by the same number of closed parentheses. Recall that that's not something we can do with regular languages or regular expressions, but we can capture it with a context-free grammar. However, we didn't handle it in our parser, so we must handle it now. This concept is not particularly tricky, but it does require a context-free grammar. So just to make sure that we're all on the same page, there's a bit of a quiz. I have written three HTML fragments, but I've left some things blank. What I would like you to do is fill in each blank with the word necessary for each fragment alone to be well-balanced HTML, to have its tags match up perfectly. Well, to have the tags match, we're beginning a bold here, so we'd have to end a bold there. This second example is a bit more complicated. We have to do these things from the inside out. We might look over and see, oh, we're ending an italics tag, so I should begin an italics tag here. But if we do that, things don't balance well. We look down and we see this bold later. Actually, this innermost tag--the i here has to balance with the closing i, meaning there's a b here--bold--that has to balance with the closing b. And then here we have an anchor tag beginning, so we need to have an anchor tag ending. Shaka was born in about 1787 and throughout his military and political career united quite a bit of the southern part of Africa, although these days his reign is viewed with some controversy. [Narrator] So here's a pictorial representation of a parse tree for HTML. Remember that all parse trees always grow upside down, and we have our actual tokens at the leaves at the bottom because this is a web page that just says, "Hello friends," with no tags, and it has a large number of intermittent nodes corresponding to non-terminals or rewrite rules in our grammar. We want to walk over this parse tree and decide based on all these intermediate nodes to print out to display on the screen as our web page Hello Friends. That process is known as interpreting. Walking over the tree to figure out what to do, and in some sense it's just like interpreting a sentence in English to figure out what it means or even translating a sentence from one language to another. Recall that our 2 major elements in our syntax tree are represented in python as tuples. Word elements just have 2 parts, the word word-hyphen element so that we know what's going on, and then the actual text from the user, and tag elements which start with tag elements. Again, to make it easier for us to interpret, we'll see that in just a minute. The beginning tag, the ending tag, and then down here a list of other elements. We also have a Java script element, which I haven't spent as much time talking about, but is our way of representing embedded Java script pieces of code in a web page. We're going to focus on these 2 for now. We're going to do that while we introduce graphics. Remember our goal is to render a webpage to make a picture that corresponds to a webpage. That means we need some way to make a picture, and it may not be obvious how we'll do that in Python. It turns out that just as we used a library for regular expressions and parsing and even timing procedures--if you remember that example from before-- we're going to use a library--someone else's code--to do graphics. This ability, by the way, to build on existing off-the-shelf components is one of the phenomenal advantages of computer science compared to other parts of engineering. It's very easy to copy someone else's library and build on top of it-- much harder to copy someone else's building without actually reconstructing it yourself. So there are 4 key functions in our graphics library that are worth knowing about. In graphics.word, you pass in a single word, and we'll draw it on the screen or on the picture we're making for you. Graphics.begtintag is a bit more complicated. You have to tell us both the type of the tag and also any arguments it might have. For example, suppose it's an anchor tag--a link in a webpage-- we need to know what the destination of the link is. I'll have you pass that in as a dictionary, mapping href to "google". Then after that you could call and display a bunch of other words and those would all be underlined or they would show up in blue or however we draw web links. Eventually, we can end the most recent tag, and there's also a way to display warnings, which is basically just for your benefit if you're trying this out in later assigments. This gives you a way of debugging. Maybe this will show up in some bold, red color or something like that so that you can't miss it. So let's imagine that we have the following webpage input. Nelson Mandela was elected democratically. I'm going to show you the sequence of calls to the graphics library that we would want. Well, conceptually, the first thing we're going to do is print out the word Nelson on the screen. Then we'll want to print out the word Mandela on the screen. Then we want to tell the graphics library that for while, subsequent words should be bolded. So we'll begin a bold tag. This bold tag doesn't have any arguments, so we'll just pass in the empty dictionary. That didn't actually draw anything on the screen. It's just a note to begin drawing in bold. You can imagine changing out your pen for something that draws in a different color. Now we instruct our graphics library to write the word "was," but it's going to be bolded. Now we write the world elected, and now we're done with things in bold, so we back out of our most recent tag. Finally, we'll add the word "democratically" and a period. This depends on how our lexer works, but remember that our definition for word was sort of anything that's not whitespace or angle brackets, so this period will be part of the same word. Then it will be the responsibility of our graphics library to do things like wrapping when we get to the end of the page to decide what bold looks like. And then to display the image back to you. So these 1, 2, 3, 4, 5, 6, 7 calls produce this image. That's how we're going to make our web browser. While we're here, Nelson Mandela was actually the first South African President in a fully representative democratic election, and he went on to win the 1993 Nobel Peace Prize, plus a host of other honors. So let's do it! We're just going to get started writing an interpreter together. I'm going to write the first half of it, and for this quiz, you're going to finish it off. We're going to write a recursive procedure called interpret that's going to walk over abstract syntax trees and figure out what they mean. What figure out what they mean is, calls the graphics library to render a webpage. That's the meaning of HTML. The reason why we're operating on trees instead of just 1, this is mostly just how I'm labeling it. But remember, that HTML can be a collection of elements rather than just 1. For example, you could write out a webpage that said, "Hello, Friend", and it would be a list of 2 elements. So I want to make sure that we're prepared to take a list instead of just a single thing. We'll immediately dispense with that however by considering them one at a time. So now, for example, we'll just do the "Hello". Remember for us though, it would look something like this. We've decided to represent our abstract syntax trees as tuples. So I'm going to need to pull out the 0th element of this tree to see what sort of thing it is. So I'm going to pull out the nodetype. In our running example, it's word-element, but it could be Javascript element, tag element--bunch of possibilities. If it is a word element, I know what to do. I'm going to call our graphics library and say print out a word, and the word that I want you to print out is the second child of the tree. So in this example, it's "Hello,". Another possibility is that someone has given us a tag element-- something like this--bold tag begins, some HTML in the center, bold tag ends. Well, we went to all the work to storing this information in our parser, so let's get it out now. The name of the tag we're entering is the first part of the abstract syntax tree. In this strong text example, it's just a b. There may well be some number of tag arguments. For the bold tag, no arguments, but for something like the anchor tag, there might be more. Then there's a list of HTML elements that we'll have to interpret later-- strong text, in this example, and then there's the closing tag name. Here's what I want you to do for the quiz-- 2 different things. I want you to check that the tags match and interpret the subtree. If the trees don't match, use graphics.warning to make that really obvious. Otherwise, interpret the subtree. Hint: call interpret recursively. Alright, let's go through his together. Checking whether or not the tags match is as simple as checking to see if the entry tag name matches the exit tag name or the beginning tag name matches the closed tag name. If they're not the same, then we'll indicate as much by calling graphics.warning. Otherwise, they are the same, so I just tell our graphics library that we're beginning this tag. It's a bold tag. There may be some arguments. In this case, there aren't. I call interpret on all the subtrees. It's convenient that we made interpret work on trees instead of single elements because now it's just 1 line to call it here. When I'm done, and this is critical, we have to call graphics.endtag. Otherwise, it would be run away bold. The whole rest of the webpage would be bold. We need to stop doing whatever this tag did. We only want to apply it over the span that it controls. [Narrator] Wow was that actually it for HTML? Actually, yes, remember we only have 3 types of HTML elements. The word element, which we just shot how to handle. We call graphics.word; the tag element, which we also saw how to handle. We check to make sure the tags match. We call graphics begin tag and graphics end tag, and the Java script element. Now, this is super tough, but it's not really HTML proper. Here's what we're going to do: step 1, we'll interpret the Java script until we get a string. Step 2, we'll just call graphics.word on that string. Whatever they want us to print out, we will. Now, we just need to know how to interpret Java script, and then we'll be done with our web browser. However, Java script is symantically richer than HTML, which means it will be harder to interpret. For example, Java script has arithmetic and HTML rarely has arithmetic. Java script also has variables. HTML rarely has variables, and we're going to have to deal with all of these things, but we have to start somewhere so let's just start with arithmetic. Suppose our input is 12 + 34. We'll be given a parse tree that looks mostly like this, but with some extra decorations. Remember that our parse tree is actually more--it will look more like this for the leaves. They're all tuples, but I'm abstracting away the tuples stuff just to show you the shape of it. What we're going to do is just write a procedure, again, called interpret or Java script interpret, that walks down the tree and computes values and returns them back up. How do I figure out what this plus means? Well, I'm going to call myself recursively. How do I figure out what this times means? Well, it's a binary operator so I'm going to figure out my left child. That's 1, and figure out my right child that's 2, so 1*2 is 2. I'll just bring that up, pass that up to my parent. Now, I'll call myself recursively over here. How do I figure out this times? Well, this is a 3, and that's a 4, so together they make 12, so this whole thing is 14. Our order was down this way, down that way, back up, down this way, all the way back up, and that's how we're going to figure out Java script arithmetic. Interpreting complicated languages in computer science is often called evaluation, which is abbreviated to eval in many instances. We're going to write an eval procedure for arithmetic expressions like this. It will therefore be called evaluate expression. So once again, as a quiz, we're going to build a lot of this interpreter, together. I will get started; you'll complete the rest. We're going to write an eval_exp procedure to interpret JavaScript arithmetic. We're only going to handle (+), (-), and numbers for now. Our procedure walks over a (tree) so it takes a single (tree) as argument. Note that this is a little different from our HTML interpreter, which took multiple (tree)s. Remember that our (tree)s typically look like these. It's either a tuple "number", followed by something like "5" or maybe something like "binop", for binary operator, with a left_child (tree), a right_child (tree), and something like (+) in the middle. This first part, here, is the nodetype. We're going to extract it, by getting the zeroth element of the (tree). If it's a "number", all I have to do is figure out the integer value of this string. Python allows me to do that, just by calling (int) as if it were a function-- to turn this string into an integer. Otherwise, for us, the node might be some binary operator. So we'll just pull out the left_child, the operator, and the right_child from the parts of the tuple that you already put there for us when you did all the hard work of making the parser. So here's what I want you to do for the quiz: You'll need to figure out the value of the left and the right_child-- and the big hint here is recursive function call. And then once you have those values, you should actually do the work. If this is a (+) binary operator, add them together. So let's see one way to do it, together. To get the value of the left_child, I'll just call eval_exp recursively. To get the value of the right_child, I'll do the same-- but for the right-hand side of the Abstract Syntax Tree. If the operator is (+), I'll just add them together-- returning the sum of the left_value and the right_value. Otherwise, if the operator is (-), I'll just subtract them--return the left_value minus the right_value. To some of you, this may seem a little weird. I'm defining (+) in terms of (+) in Python. That is, in order to explain how JavaScript works, I'm saying well, JavaScript asked you to do some Addition-- why don't you just do it in Python? But remember that an interpreter is really like a translator--so it should not be surprising. If you were teaching someone how to speak French and they ask you what does a French word mean-- what's the French word for "big" or how do I interpret the French word "grande"-- you might tell them: oh, it's just like the word "big" in the language that we speak. And this is that notion of their universal underlying concepts but we just have slightly different syntax for them. In this particular case, it looks a little weird because the JavaScript and the Python syntax for (+) are exactly the same. But you'll see slight differences later. Remember that, for example, in function declarations, JavaScript and Python do actually look different. So it should look very similar now because the translation is very direct. This is like Romance languages that share common Latin roots. So we just saw how to evaluate Arithmetic expressions, like (1 + 1) evaluates to 2. But we can also consider more complicated expressions, like (1 + 2) is equal to 3. We can imagine evaluating this part, recursively, and getting the answer, 3-- and then deciding that 3 is equal to 3, so this whole thing evaluates to True. And these may not seem like very complicated or powerful expressions yet. But these are really the building blocks that we're going to use to make a working Web browser. However, what if I give you an expression like this: We want to check and see if (x + 2) is equal to 3. What should this return? Actually, we're not certain. If (x) is currently equal to 1, then it should definitely return 3. But if (x) is something else, like negative 300, then this won't work out quite as well. We need to know the value of (x) to figure this out. And, in fact, we need to know the current value of (x) because a lot of variables change. In fact, we can see this same sort of thing in natural language. Here, I've written out a sentence, The king of France is bald, that is, syntactically, entirely valid. We can imagine trying to figure out if this sentence is True or False, but knowing what it means--whether it represents the world correctly or not-- depends on knowing the current state of the world. For example, as of the time of this recording, there is no king of France; France is not a monarchy. So it's not clear what it means to talk about the hair of the king of France when there is no king of France. Similarly, if you're writing a Python program and you write (x + 1) equals equals 2, and you haven't yet defined (x)-- if there is no king of France-- it's not clear what this means and the Python interpreter is going to give you a run time error, a run time error if (x) is not yet defined. That's not the only kind of run time error-- there are many ways things can go wrong-- but it's one of the most common. Now let's just briefly review evaluating expressions in context, in the form of a quiz. Try it out: I've written a 6-line Python program and I would really like it to print out True three times. So each of these print statements should have its argument evaluate to True. What I'd like you to do is fill in each blank so that that happens, but you can only fill in blanks with x, y, or z. This is kind of a puzzle-- can you solve constraints or do backwards reasoning to figure out how things would have to go. How do we even get started? One of the common tricks for a school or exam or test questions is to work from the bottom, up and see if there's extra information you can glean. (x + something) has to be equal to (z)--ah, not super handy yet. Something is exactly equal to "hello". Well, wait--right up here we assigned: y = "hello". So as long as I don't overwrite (y) with 2, this should totally work: y = "hello" because we just did the assignment a few lines up. All right. Now let's take a look at the rest of these. I need to add something to (x)--to get (z) that suggests that (x) is smaller than (z) because we don't have any negative numbers to play with in this example. So I'm going to have to add something like 1 or 2 or whatnot to (x) to get (z). Well, if I really think that (x) is less than (z), then this line is probably True. But in order for this to print out True and not give some sort of error, I'm going to have to assign to the value (x) and the value (z) before I get here. So one of these will have to be (x) and one of them will have to be (z). Since I want (x) to be smaller, let's try this out: (x) is 1; (z) is 2. All right. So then 1 is Less Than 2--that's going to be True. y = "hello"--that's going to be True. And now we have: print x + (something) is equal to z. Well, (x) is 1 and (z) is 2, so we'd really like to just write "1" in here-- but remember the rules of this puzzle-- we can only write x, y, or z so we'll write another (x). Since (x) is 1, (1 + 1) equals 2. So as that last quiz just showed us, in order to figure out whether an expression is True or not or what it evaluates to, we're going to need to keep track of the values of variables-- which might change with assignment statements. So we're going to track the current State of the World. Is (x) 1 or is (x) 2? We don't know yet. Is the King of France bald, or not? We're going to have to find out. It's a question that can be answered empirically, by looking at the state of things. So to figure out what an expression like (x + 2) means-- when we're doing our interpreting, when we're writing our Web browser, we're going to need to keep around some notion of the values of the variables--this State of the World. And we're going to do that with a mapping from variable names, like (x), to values. In Python dictionary-style, that might be something like: "x" currently has the value, 3. This mapping is called the State, and this is a super important concept in programming languages. It's kind of like asking: what's the current temperature? Depends on the current state of the world--and it may change, over time. We'll need a lot of bookkeeping to keep track of it. So as we hinted earlier, a fairly direct way to do this would be just to use a Python dictionary that maps strings--variable names--to values. If we had something like this, we could easily evaluate (x * y) in this context, in this state-- and determine that it's True for this state. Right now, "x" is 2; right now, "y" is 3; (2 * 3) is 6. So the value of this expression is True--if this is the State of the World. Now--later, we may want our environment to be a little more complicated than just a single Python mapping. So we're going to introduce an abstract function to query it. So we'll just make a promise to ourselves. We're going to write a function called environment_lookup, where you pass in an environment--probably a dictionary, but we may make it more complicated later-- and a variable_name, and you get the answer out. So if this is our environment, e, calling env_lookup of this environment, e, and asking for the variable, "y", gives us back the value, 3. So let's test out our knowledge of this with a quiz. We're going to go back to our JavaScript interpreter and add support for looking up variables like (x) and (y). The first change is that our recursive Evaluate_Expression procedure now takes 2 arguments: the Abstract Syntax Tree--and the environment because we've just established that the meaning of an expression depends on the context in the World--depends on the environment. We've already seen these 2 cases before. We peel apart our abstract syntax tree, which is just a bunch of nested tuples. We look in the zeroth component for the type. If it's a "number" node, then we just return the string value, converted to an integer. If it's a binary operator, like (+) or (-), we'll have to do the Addition or Subtraction. Here, I'm skipping a few steps, compared to last time. Last time, we assigned tree[1] to left_child and then called eval_exp on it. I'm going to do it all on one line now, just to say a little space. But notice that when I make my recursive calls to eval_exp, I have to pass in this environment in order to have my subchildren--the subparts of the AST-- know what the values of variables are. And since there haven't been any intervening assignment statements, the environment stays the same--whatever I was given is whatever I will pass on to my subtrees. So now I just check to see: if the operator is a JavaScript Plus, I evaluate it, using Python Plus. If the operator is JavaScript Minus, I evaluate it, using Python Minus. I translate these basic universal concepts, like Addition and Subtraction, from one language to another. I'm writing an interpreter. But what if, instead of being a "number" or a "binop" our nodetype = "identifier" is actually a reference to a variable? And just to remind you here, I've written out our Abstract Syntax Tree for (X) + 2. At the highest level, it's a binary operator where the left_child is the ("identifier", "x"), and the right_child is the ("number", "2"). So we started up here with "binop" but that involves calling ourselves, recursively, to evaluate our left_child. When we do, the nodetype for our left_child is "identifier" so we're going to have to figure out what the value of (x) is. So your mission is to complete the code for this case, by finding the identifier name, looking it up in the environment and returning it. Well, let's finish it off together. The variable_name or identifier name--they mean mostly the same thing-- is just the oneth component of this tuple. The zeroth part was "identifier", so the oneth part is "x". So to get out the final value, we're just going to call env_lookup, using our existing environment and the variable_name. And whatever that gives us back, we'll just return. And that's it. Now we can handle expressions like (X + 2), assuming that we know what the value of (x) is in our environment. So now we can handle expressions like (2 + 3) or (x + 1) but if you think about most of the Python programs you've written, they've got quite a bit more going on-- things like "if" statements or assignment statements that influence the state or change which parts of the program are executed. Formally, we say that statements or program parts, like "if" or "while" or "return" change the flow of control, and a potential reasonable analogy for control flow is a river. Here, I've written a relatively simple bit of Python code. But we could sort of trace through it, noting which lines get visited. We're definitely going to visit: x = 1. We'll take a look at this "if" because (x) is 1, it's less than 5 so we're going to curve in here and evaluate this "print". But then we're going to kind of skip over this whole "else" branch and rejoin things here--so you've got this flow that sometimes branches, seems to fork, rejoins at the end--Control Flow. Which part of the program do we execute? If I'm to keep my finger on the line that we're currently worried about, how does my finger move around? We're going to need to handle this sort of things if we're building an interpreter for JavaScript and HTML. So things like "if", "while", and "return" change the flow of control. These things are called "statements" to distinguish them from "expressions". Expressions are typically a bit simpler. They're more like noun phrases in a natural language. A statement is more like an entire sentence. It's going to contain a verb as well or some instruction, like change the value of (x) or jump over here. Statements often contain expressions but not the other way around. And you can think of this as being a bit of a hierarchy. This whole thing is a statement. The usual abbreviation for a statement is "stmt". But just this little part down here is an expression-- just like a whole sentence may contain one or two nouns. So let's say we have an environment that maps the variable, (x), to the value, 2-- and now I've written a JavaScript program below it that contains an if-then-else statement--it should remind you a lot of Python. If (x < 5), the variable, (y), is going to be assigned to "don"; otherwise, the variable, (y), is going to be assigned "quixote". In our environment, where (x) is 2, (x < 5) will be evaluated to True. So the flow of control will visit here and here, but will skip these two and rejoin us down here at the bottom. And hopefully, at the end of the day, we'll have a new environment where (x) maps to 2, and the variable (y) maps to "don". "Don Quixote" is a classic novel, written by Miguel de Cervantes around 1605. We get a number of expressions from it, like "Tilting at windmills" , in English; the protagonist believes a windmill to be a mortal foe, perhaps a dragon, and he charges up but gets knocked down by the whirling arms each time. These days, "tilting at windmills" means trying something over and over again, even though you know you're never going to succeed--an impossible task. So let's apply what we just learned to help complete our interpreter to fill out what it means to evaluate statements. Previously, we had an evaluate function expression. Now I'm going to make a new function for evaluating statements. It's going to take the abstract syntax tree and also the environment. We need to know the values of variables. As always by convention, we can get the type of the thing we're looking for from the 0th part of the tuple. We did all this work in the parser to record it. Let's totally take advantage of that. Well, 1 possibility is that it's an assignment statement. Those look something like this. Here's our statement type, assignment, and its first argument or the first part of its tuple is going to be some variable name that we're assigning to, and then the second part is going to be an arbitrary expression abstract syntax tree, so that corresponds to x becomes 3. So I'll just get out the variable name and get out the right_child abstract syntax tree. I'll figure out what the new value is by calling evaluate expression because this right-hand side part could be more complicated. For example, it could be a binop of a bunch of things, so we're going to need to walk down that tree and interpret it--translate it to figure out what it means. Now we've got the new value, and we'll just promise ourselves later on we're going to write some new function called environment update that changes the environment so that variable_name now points to new_value. This should remind you a lot of the chart update procedure that we wrote before. However, there are other types of statements. In addition to assignments, there are if-then-else. There are typically 3 parts of if-then-else. The conditional expression--suppose our if-then-else is if x 00:01:48,000 I haven't drawn in the curly braces to save space, but this is the general idea-- then our conditional expression is x 00:01:56,000 The then statements are A. The else statements are B. But before we go farther, there is 1 complicating factor. Remember that in JavaScript, you can have multiple statements inside this compound statement block. So really, we have then statement s and else statement s. Your mission is to complete this code, and you can assume that there's a procedure called eval_stmts that takes statements as an argument and an environment. So let's go over the answer to this or 1 possible answer together. We're trying to write a program to interpret if-then-else statements, and the big concept here about control flow is that we don't want to execute both the then branch and also the else branch. Instead, we'll have to pick one. So the first think I'm going to do is evaluate the conditional expression in the same environment in the same set of evaluations to variables that we currently have. If it comes out true, I'll want to execute the then statements. If it comes out false, I'll want to execute the else statements, and if you like, this if statement is the same as one where I checked to see if the result of evaluating the expression is equal to true, but if you have a little experience with propositional logic, that's actually the same as just checking the value of this variable directly. So if the conditional expression evaluates to true, I will evaluate all of the statements in the then branch. In our running example, that was A and B. In our current environment there haven't been any intervening assignment statements so the value of the variables hasn't changed. Otherwise, if the value of the conditional expression wasn't true, presumably it was false, we'll go over here to the else branch, evaluate the else statements in the same environment, and note that no matter what happens, we're either evaluating the then statements or the else statements, but not both, and that decision is made based on the value of the conditional expression, and that's it. These 4 lines suffice to evaluate an if-then-else statement in java script. Alright, so we've just seen, especially in that last quiz, how to evaluate an expression or a statement in in an environment, but we've been assuming that the environment, which I said is kind of like the world, comes pre-prepared, but what if we want to build a new world? What if we want to set the values of variables? What if I want to determine what the current temperature is? Here I've written 2 code snippets, 1 in Python and 1 in JavaScript that do the same thing, and both of them extend or create an environment. They make a bigger, richer world that has new bindings of values to variables. Here in Python, we assign the value zero to the variable x, and then we're going to print out x + 1, that'll be 1, and over here in JavaScript, we use a var statement to introduce the variable x and assign it the value zero, and then we write out onto the web page x + 1, which in an incredible surprise move will also be 1. We're going to want to handle statements like these in our JavaScript interpreter in order to build our web browser. So let's test our knowledge of assignment. statements with a brief quiz. So here I've written a fragment of Python code that's going to print out results to the screen based on these 2 print statements in myfun. What I would like you to do is to determine which of the following outputs could actually be produced by this program and try to work through it in your head, and this quiz is multiple, multiple choice. Check each box that corresponds to a string that could be printed out if you were to run this program in the Python interpreter. So the trick to understanding this quiz is noticing that myfun has a formal parameter named x, and when we're inside myfun, when we're inside the body, when control has reached these statements, we need x to refer to the actual argument and not the outside value. So when we get in here, myfun x = outside x. This can't happen because we've passed in os lusiadas. My Portuguese pronunciation needs work. Imagine I'm pronouncing that correctly, and that's going to shadow or replace the old value of x. However, there's only 1 variable here, x. So y never changes. So we will print out myfun y = outside y. Similarly, since we are passing in os lusiadas to myfun as x, we can print out myfun x is os luciadas, but there is never an assignment of y to os luciadas so we'll never end up printing out this variant. So again, the key concept, we can have multiple values of x in different contexts. Out here, x is outside x. In here, x is the value of the actual argument, os lusiandas, which we often--let's say aggressively pronounce in English as The Lusiads , a Portuguese epic poem in 1572, entirely worth checking out. This notion of variables having different values and different contexts is sometimes called scope. There's some sort of global scope that we start in where we're assigning values to variables, but then inside myfun, there's a new x that has a new value, and what this means is that our environment cannot be a flat mapping. We had hoped before that we'd be able to use a single Python dictionary, but this myfun example shows that that's really not going to cut it because in a single dictionary, you can only have x bind to 1 thing, and we need to know that x is sometimes outside x and sometimes os lasiandras. Let's get some practice with these concepts with another quiz. This one explicitly on scoping, and we'll do it together in the interpreter. So we have x gets outside x and y gets outside y just like before. So I've written out this program, and it's a little more complicated than last time. It has 2 functions, funone and funtwo, my phenomenal cosmic naming scheme, with a few printouts. X starts out as outside x. Y starts out as outside y. When we enter function 1, we print out current value of x in scope, the current value of y in scope, and then we call function 2. Function 2 also prints out its value of x and its value of y, and down here we get the ball rolling by calling function 1 on Hong Kong in 1997. So the quiz for you is to fill in these blanks, the 3 formal parameter declarations, 2 for funone and 1 for funtwo, but you can only use x, y, and z. So for each one of these blanks, fill it in with either x or y or z, and that's it. In order to make the output of this program, match exactly what we see down here, funone x Hong Kong, funone y outside y, funtwo x outside x, funtwo y funone y. This is a bit of a puzzle, try it out. Well, let's get started. Taking a look down here at the bottom, one of the first things we print out is funone x is Hong Kong. The only Hong Kong we ever see in the program is the first argument to funone so that means that this must be x. Funone y is outside y, which means that we can't have overwritten it here. If we put y in this box, we would mistakenly get out 1997, and we don't see that. So it can't be x because we just used x; it can't be y, so let's try z. If we pass in 1997 as z, then y will still refer to this old value of outside y, we'll get the printout that we expect. Then we call funtwo, and down here if we take a look at the printout, x remains unchanged. X is still outside x, but y is funone y. The place we see that is right here, it's the parameter being passed in. So in order from funone y to the flow here, we have to fill in this box with y. Note that the way scoping works, funone and funtwo are independent, so even though funone has overwritten x, funtwo still sees the old outside value. Well, let's test this answer and see if it's right. I will just add a little more information, and we get exactly the output we were expecting. Some actual information that Hong Kong is a special administrative region in China, was controlled by the UK until 1997, and then down here, just the output we had hoped to get for this puzzle. So we want to understand the relationship between Identifier or variable names (this means the same thing) and storage places, particular values as we're running our program; the state of the world. If I write something like this in Javascript, it's going to return 2. Conceptually, somewhere there's a box where we've made enough room to store the value 2, and we've labeled that with x. Since this is a place for storing a value, we might call it a storage location or storage place. If I write x=3, we need to go back to this box and update it with the new value, because x can only have 1 value at a time in the same context. So, if I declare another variable, it's going to make another box, another storage location. We'll need to use more memory in the computer to store this value. Let's see a more complete example. Here in this program we start off by initializing y to 2, we declare a myfun function of x, it prints out x and then it prints out y, and then we call a myfun of y plus 5. A little reasoning suggests that this is going to print out first the value of x, x is y plus 5, y is 2, so first we're going to print out 7, and then we're going to print out y which was 2, 7 and 2. So, initially maybe our world looks a bit like this. Y has the value of 2. But then when we call this function, we're moving into a slightly new context that has to have room for x, it's actual argument. The particular value we put in there is y plus 5, or 7, but we want to remember our roots. I defined this function here right next to the place where y was equal to 2, so when I'm in this context, printing out x and y, I can get the value of x right here, and I may have to look a little farther to get the value of y, but I can just trace the arrows and do it. Whenever we make a function call, it's going to get us a new box, new storage locations, and I'm going to firm up this intuition in just a bit. I realize it's very hand-wavy now. Here's the quiz. I've written a Python program that has 3 print statements. I'd like you to tell me what each one prints out. Fill in the blanks. Now let's work through it from the top. Initially x is 1, and then I define a new function tricky, but I haven't called it yet, so I'm not actually going to make any new variable spaces over here. And then I print out the value of x. Currently x is 1, and now I call tricky on x, and we noted before that whenever we make a function call we get a new box corresponding to that function call. This one knows who its parents are, and this new box is going to have room for all the formal parameters in tricky, also x, and this time we're passing in x. The current value of x is 1, huh, so we've got almost a duplicate sort of state. So now we're inside tricky, and we say x=x+5. The real question is: Which one do we change? The answer is this bottom, more specific one down here. This x has shadowed, has taken the place of in our hearts, the old one. So I change just this one to 6, so here, when I'm printing out the value of x, we look in this world, we see a 6, and we print it out. And now we return from tricky, and when we return from a function call, you can imagine we throw away all of its space, and we're back here in the normal world. Well, what's the value of x here? It's 1. So this assignment statement, x=x+5, changed the function's actual argument but did not change this more global value of x. We call these boxes that help us keep track of storage places for variables environments. Kind of like before, when we were talking about state being a bit like the world, you can view a particular environment like Central Asia or Western Europe or Antarctica as being a little region in the world that might have its own values for variables. If I want to know what the temperature is, well, it depends on the current environment. Are you in the Sahara desert or are you in Northern Sweden? The first environment, the one we start with, is special. We call it the global environment. By default everyone gets a chance to see it. Whenever we make a function call, we make a new environment that officially has a parent. This environment knows that it was created in, defined in this global environment. So when we're interpreting JavaScript, we're going to use this nested, or chained, notion of environments to keep track of the values of variables. An environment is just a mapping from variable names to values except environments may also have parent pointers. Every environment that's not the global one has a parent. Beyond having a parent pointer, environments just map variables to values. B is 555. X is 2. To give you another way to think about this notion of chained environments, we're going to reason by an analogy. Let's say that you're going on vacation. You leave your home and you go to stay at a hotel by the seashore. You don't bring everything in your home with you, but you bring a few things. And then eventually you're going to leave your hotel room and go out on the beach. Maybe you'll bring your swimming suit, pack a lunch, that sort of thing. You'll bring a few items with you, but not everything that was in your hotel room and certainly not everything that was in your home. Now let's say that you've forgotten your keys. Oh my gosh! Where are they? The first place to check might be in your pocket or around with you on the beach. Did I bring them all the way to the beach? If not, maybe they're back at the hotel. If they're not back in the hotel, maybe you left them at home. And if they're not at home, there isn't a whole lot of recourse. Maybe you can call a locksmith or do something else sort of generically. Hopefully you can get new keys. But ultimately, there is just nowhere else to check. So this is analogous of having a global environment--a big marketplace where you could buy new keys. And then some nested environments on top of it-- your home, your hotel, whatever you brought with you to the beach. So let's test our knowledge of this idyllic tropic scene with a quiz. Suppose you are currently in the hotel environment. We have A is 6 and B is 7. That points back to the home environment, where A is 44 and X is 55. And that points all the way to the global environment, where A is 1, B is 2, and C is 3. You're in the hotel, and you want to evaluate A, B, C, and X. What are the values of these variables? Fill in the blanks. Well, let's go through it together. We're right here in the hotel; we want to get the value of A. Oh, it's right here; it's 6. Similarly, if we're right here in the hotel and we want to get the value of B, we brought one with us; it's 7. But if we want to get the value of C, do we have it in the hotel? No. Okay, let's check back home. We also don't have it here. Okay, eventually we'll have to get it from the global environment. And then finally we want to get the value of X. Do we have it here in the hotel? No. Do we have it back at home? Yeah; it's 55. And in this example, we never actually got to Pebble Beach. It's a shame. Congratulations on mastering nested environment frames and variable lookups. While it might seem a bit foreign now, this notion of looking up a variable in an environment is very common in languages like PHP, Ruby, JavaScript, or Python. It's how it's done in the real world. Identifiers like home or friend may not mean the same thing in all contexts. My home may not be the same as your home. My friends may not be the same as your friends. But we both have homes, and we both have friends. This is an area where your intuition will really guide you to the right answer. So let's start building up these chained environments through a series of function calls. What will that look like? Well, at some point we declare or define the function--some fun, we'll call it-- and then later on we call it. We want to have some fun, and we're going to pass in as the actual arguments three different expressions. Here are the steps we go through. First, we create a new environment, and its parent pointer points to the current environment. This parent part is really essential. Next, in that new environment we create storage places for each formal parameter. Formal parameters, in this example, p1, p2, and p3. There are three formal parameters. Then you want to fill in those places with the values of the actual arguments. The actual arguments are e1, e2, and e3. Oh, no! There's a step 4. Then you actually just do it. You evaluate the function body in the new environment. That means it's going to be able to see the values of the actual arguments, which is just what we wanted. Let's try this out with a bit of a quiz. Here I've got a 5-line Python program. X gets 1; Y gets 2. I define a function, myfun, of formal parameters A, B, and X, prints out A + B + X. And then I make a call to myfun with actual arguments 1+2, 3+4, and 5+6. I'm definitely going to have a global environment, and when we call myfun, we want to make a new environment pointing back to the old one, which is going to have room for some new places. But I haven't quite filled everything out, and I'm hoping you will help me. We need to know the value of X and Y in the global environment and then fill in these three boxes down here in this child environment corresponding to the myfun function call. Fill in the blanks. Well, in the global environment x is 1 and y is 2. When we call myfun, the rules from before say that we should make storage spaces for all of the formal parameters: a, b, and x. Here's b, here's x, so this must be a. We fill them in with the values of the actual arguments. A was 1 plus 2, that's 3. Great, that was already done. B is 3 plus 4. This evaluates to 7, so b is 7, and x was 5 plus 6, so that's 11. So, at the end of the day, this is going to print out 21. Let's see a slightly more lively example. There's a lot going on in this example, and some of it you may not have seen before. I'm making a procedure called makegreeter that--and this is cute-- inside of it defines another procedure. If you haven't seen this before in Python, don't worry, but it is possible to make 1 function inside another. Here I'm making a function called greeter that takes a person to be talking to and prints out a particular greeting to that person. And then this makegreeter function returns greeter this function that I just defined in here. Wow! This is not obvious. So down here I'm making a variable sayhello, which is the result of making a greeter who always starts with "hello from uttar pradesh". And then I can ask that greeter to say hello to Gracie and also say hello to Lucknow. So sayhello points to or references a particular version of greeter where the greeting has been locked in to be hello from the UP. If you haven't been there, Uttar Pradesh is a region in India. Its capital city is Lucknow, known as The City of Nawabs. It's known for its manufacturing and retailing and possibly also silversmithing. Cool place. Very populous. So here I've recopied the same code from before. Nothing has changed except that I'm abbreviating Uttar Pradesh with u.p. And now over here on the right I'm drawing out the chained or nested environment frames as we're calling sayhello("gracie"). I'd like you to help me out with just the last part. Down here in this final environment frame there's a single variable bound to a value. I'd like you to fill in these 2 blanks so that this picture of the environment is complete. One way to think about this is to remember the rules for function calls. You take the function body and you evaluate it in the new argument. So the body of sayhello is print greeting + " " person, and we already know from seeing it in the interpreter what it's going to print out. It's going to print out "hello from u.p." "gracie". Currently I don't see gracie anywhere in this environment. That suggests that we're definitely going to need to add it. Another way to get to that is to remember the other rules for constructing environments. We definitely want to make space for the formal parameters, person, and put in the value of the actual argument, "gracie". So now when we go to evaluate greeting, we don't see it here but we'll go one up and get "hello from u.p." and we'll try to find person. We see it right here. We get "gracie". We'll compose them together and print out exactly the same behavior we saw on the interpreter. This quiz was pretty tricky. This notion of nested procedures does not come up very often in Python. But if we want a complete interpreter, one that understands all the nuances of a language, then we have to handle this. It's kind of like the subjunctive in a lot of romance languages. It doesn't come up very often in English; may come up more often than you'd think in other places. We've been talking about environments, and we've established that they need to do 2 different things: map variables to values and also point to the parent environment. So we're actually just going to represent environments as a tuple of the parent_pointer, or None if it's the global environment, and the dictionary, mapping variable names to values. That means that I can finally provide you with the definition of that environment lookup procedure we promised earlier. Remember that our procedure--check your pockets, check your hotel room, check your actual home. If that doesn't work, try to buy it on the Interwebs. Let's go see how this goes. We'll just look and see if this variable name is in our environment. But remember that our environment is actually a tuple of a parent in a dictionary, so we're going to have to select out the oneth element in order to check this out. If we have a binding for our variable name in the current environment, we just return that binding. We get out our dictionary, and we look up the value associated with vname in it. If we were the global environment and we didn't know the answer, then we'll just return None. We don't know what the deal is. We could try to do something else here like flag an error. For now let's just return some default value. But if we are not the global environment, if I don't have it in my pockets, I can check my hotel room and then my house, and I'll do that by getting my parent pointer out of position 0 and calling myself recursively. And the astute among you may notice that I was too lazy to actually call the formal parameter var_name, so let's just leave it at vname for variable name. So that's our lookup procedure. Step 1: Do we have it? Step 2: Are we the global environment? Step 3: If we're not the global environment, ask our parents. Similarly, we now know how to update an environment, or we could work our way through it. If we already have a binding for this variable name, then we'll just change that binding. This is a dictionary, and here I just updated the value that corresponds to vname in that dictionary. Otherwise, if I'm not the global environment, I can ask my parents to store the value for me. If I am the global environment and I didn't define your variable, then this is problematic. We should have allocated space earlier. So here I'm going to actually define some environments in Python rather than drawing pretty pictures of them, and we're going to run through some practice problems to make sure we understand this. This will be fill in the blanks. I'm going to call environment lookup of "x" in the new environment. What's that going to return? So then after we look up "y" in the global environment, we make a change. We assign "x" to be 55 in the new environment, and then we print out "x" in the new environment and the global one. How do these things turn out? Let's actually just draw the environments to make it a little easier. Here's our global environment. x is 11, y is 22. Here's our new environment. It points up here. x is 33, z is 44. A little abbreviated, but you get the idea. So if I look up x in the new environment, the answer is right here: 33. If I look up y in the global environment, the answer is similarly right there: 22. Now I'm going to update x in the new environment, and our procedure is, do we have a binding for x in the new environment? We do, so we update that one. Now when I go to look up x in the new environment, there's an answer right here: 55. When I go to look up x in the global environment, there's an answer right here: 11. Our newfound mastery of environments puts us in a perfect place to write interpreter code for declaring and calling functions. However, there's a lot more to functions than just environments. For example, someone could be a little mean and give us a procedure like this to try to interpret. Mean of x immediately returns x, but then after that it has written print "one thousand and one nights". We should never actually print out "one thousand and one nights" from this function definition. We should return first. That's a shame because One Thousand and One Nights is perhaps the best-known example of Arabic literature, a collection of Middle Eastern and South Asian stories. One of my particular favorite parts are the stories involving Sindbad the Sailor. Unfortunately, his luck fluctuates wildly. More on Sindbad perhaps later on. The meaning of this is we need a way to return without doing any more work. Let's get a better feel for this with a bit of a puzzle. Here I've written a bit of Python code, and I have 4 assignment statements involving x. What I'd like you to do is imagine that these assignment statements are not there. But you get to add one of them in, and your goal is to try to add in a statement that will prevent us from printing out "sindbad". So again, assume these statements aren't there, but which ones could you move in to prevent "sindbad" from being printed? Multiple multiple choice. Check all that apply. There's nothing particularly innocuous about this statement. X is already in scope. In fact, it's 3, so this is going to assign x to be 4. I don't think this will prevent us from printing "sindbad". This one, though, says x is x divided by 0. Division by 0 doesn't really make sense and will typically cause the Python interpreter to stop and say, "You are asking me to do impossible math," and thus not execute subsequent statements. Assigning x the string value "return" doesn't have the same effect as actually executing a return statement, so this won't help us. But x = y, well, if this is the entire program, then there is no y in scope, so Python will yell at us and say, "Oh, you're referencing an undefined variable." So just to make these examples clear, let's actually see it in the interpreter. This time I've left in x = x + 1, which should not prevent us from seeing Sindbad. And there he is. But if I print out x = x / 0, no, we don't get Sindbad and instead we get this error message from Python, "Blah, blah, blah, blah, blah"--the part here at the bottom is the most important-- "ZeroDivisionError: integer division or modulo by zero." Well, we did ask you to do that, so it's our own fault. Similarly, x = y we don't see Sindbad and instead we see "NameError: global name 'y' is not defined." So both of those 2 errors caused us not to see Sindbad. Sindbad certainly can't catch a break, but perhaps we can catch or notice errors in Python programs. If we are very wary and think that an error might happen, we can use the Python keywords try and except to guard critical code. This code is guarded. And if an error happens in here instead of aborting Python execution, it will go down to this except block and start executing there. This except block only runs if the guarded block has an error. So this code will print out "hello" and then we've seen before that when we try to do integer division by 0 that doesn't make much sense, so we'll jump down here and print out "didn't work" and then print out problem, which was our particular exception. And if you haven't run into it before, exception is just a special computer science keyword meaning an error in a program. It derives from exceptional situation and can refer to either something like you're out of space on your disk or memory card or a problem in your program like you're trying to divide by 0. However, it's also entirely possible to raise exceptions on our own. So here in this Python code fragment we're printing out "joseph heller" but in the middle we raise this exception with the value 22. And then down here we catch that exception, calling it the variable problem, and then we print out, oh, it "didn't work: we caught" problem, and this will end up printing out "joseph". We'll raise the exception, so we'll never actually print out "heller". We will print out it "didn't work: we caught" 22. And Catch-22 is a satirical novel by Joseph Heller. It's a bit absurd. The phrase "catch-22" has actually entered the popular English lexicon, meaning, approximately, "no win situation." We want to harness the power of exceptions just like you might harness a horse to a wagon. I assert that that's a horse and not, say, a giant, mutant, quadruped duck, which is what it might admittedly look a little bit more like to the untrained eye. We're going to use exceptions under the hood in our interpreter to simulate return statements. Remember that after a return statement we don't want to execute the statements that come after it; we want to jump back to the caller. We use exceptions to do that. Let's consider our code for evaluating statements in the context of an environment again. We get out the type of the statement, and if it is a return statement, we'll get out the associated expression. Remember you can write something like 1 + 2, so we're going to have to evaluate this expression's abstract syntax tree or parse tree to figure out what it means. So we'll evaluate that return expression in the environment and get a return value, which I'll abbreviate as retval, and then we'll just raise an exception with retval as its payload, just like 22 was the payload in the previous example. And we'll just have to trust ourselves to catch it later. In fact, that's what we'll do right now. We just saw how when evaluating statements like a return statement we could throw an exception. Now we're in a great position to code up function calls, which we'll have to set up a new environment and catch the return values. Once again we extract this statement type from our abstract syntax tree, and now we want to handle function calls. There are 2 parts to a function call abstract syntax tree: the name of the function, like absolute value or myfun or square root, and then the arguments. And because the function may have 1, 2, 3, or more arguments, we just have a list of expressions. Function name may mean different things in different contexts, just like any other variable, so we'll go look it up in the current environment. We're going to have to decide what it means for something to be a function. For something like an integer or a string, we can just use a Python integer or string. For a function, we're going to use a tuple where the first part is function so that we know one when we see it, then there's a list of formal parameters, then there's the body, and then there's the environment, and we'll see how that comes into play later. For now I'm just going to promise that this is how functions will turn out, and later, in the next step, we'll make that promise true by having function definitions produce these 4 tuple values. So we'll just pull out the function parameters, the function body, and the function environment. For example, if we're still calling square root, square root's official formal parameter name might be x when we passed in the particular actual argument 2. One of the goals in our interpreter is to rule out bad code. One easy mistake to make is to pass in the wrong number of arguments, to have a different number of actual arguments and formal parameters. We'll just check for that now. They're both lists. Compare their lengths. Otherwise, we have to make a new environment frame, which I'll leave for you to do, and then we want to evaluate the body in that new frame. We'll have to make a new environment frame and follow all of those steps-- make, potentially, spaces in the new frame for the formal parameters and assign to them the values of the actual arguments. So we have quite a bit to do in here. Then we want to evaluate the body in the new frame, and we're going to do that with exception handling. We'll try doing something--you tell me-- and ideally, we will get to the end and somewhere in the middle we'll have raised that special exception holding the return value. If that happens, we'll return the return value. Otherwise, the user wrote code without a return statement; we'll just return None. All the way up topside they're trying to call something like square root. Square root better be a function and not some string or some number. All the way down here we check for that. If we try to call something that was not a function, we'll just print out an error. Here's your quiz. Fill in these 2 pieces of code so that we correctly handle function calls. It's worth noting that this quiz is pretty tricky. This is a little more programming than we normally ask you to do. Let's go through it together. We need to make a new environment, and the parent pointer of that new environment should point to the environment the function was declared in. This is tricky, and it's easy to get this wrong. Don't use the environment we already have lying around; use the one we got out of the function. Currently it's empty. There is nothing in our mapping. So our next step is to evaluate the actual arguments and make room for them. The actual arguments may be as simple as the number 2, or they may be complicated mathematical expressions. We will go over each one in turn, and for that particular argument we will evaluate it in the current environment. Not in the function declaration environment; in the current one. We haven't really made this new one yet. And now we'll add to our environment. This line was particularly tricky because it requires you to remember what our environment really is. It's a tuple with 2 parts: a parent pointer and a dictionary. We want to get out the oneth part, the dictionary, and extend it so that when it refers to the ith formal parameter, that binds to the value of the ith actual argument. So in our example up here with calling the function square root on 2, the parameter name is x, the actual argument value is the number 2. X is now bound to 2. fparams[i]] is the variable name x, argval is the number 2. That's actually it for our new environment, so now we just want to evaluate the body in that environment. One line suffices. Remember that much like the if-then-else statement we've seen before with the curly braces in JavaScript, a function body may have many statements, so we'll use our eval-stmts procedure on the body in the new environment. This is critical. We don't want to use any of the old environments. We need the new ones where the formal parameters are bound to the actual arguments. And that's it. So now we know how to call functions and return from functions, and this makes me doubly happy. But both of those things assume we have a function somewhere, which we currently don't. We don't know how to make them. So right now, very soon, we're going to get into defining functions, making new functions out of nothing. Here I've defined the same function in Python on the left and JavaScript on the right. And while the syntax changes, we spell the words differently, all the key concepts are there. We have to list the name of the function, fname, we have to list the formal parameters, fparam in our previous example, and we have to give the body. And we said we'd just make a tuple, a for tuple that has the word "function" as a string. So if the user writes in code like this and we're making our JavaScript interpreter for our web browser, what should we turn it into? Well, a function value that has 4 parts: the word "function," telling us that it's something we can call; the list of parameters, x, maybe y and z; the body, a list of statements; the environment we were in when the function was defined. We don't need the function name because we'll be adding a mapping from the name to this value in the environment-- to the old environment, that is, not this new one. To the previous one. Let's try our hand at interpreting function definitions. I'll do the first part, you fill in the rest. In JavaScript, function definitions are top level elements of a JavaScript program. They're not statements and they're not expressions, so we're going to have a new evaluation function, evaluate elements. Here's the abstract syntax tree for the element, here's the current environment. As usual, we get the type of our tree node by looking at part 0. If it's a function definition, then we're going to pull out the function name, the function parameters, the function body, and then we're going to make up a function value out of that. It's going to be a for tuple, and then we're going to add that to the environment. Fill in each one of these 4 blanks so that the code works correctly, so that we return the right sort of function value and then add it to the environment. The first part is our little note to ourselves. This is a function value. Note that there's little repetition between the abstract syntax tree marker for this is a function element and also this is a function value. We could have made them different. It's our choice when we're writing the interpreter. The next thing to pass in is the parameters, the next thing is the body, and the last thing is the environment in which the function was defined. And we're done. This is how we do a function definition. So now we have the phenomenal cosmic power to define functions. Once we have them, we can call them with actual arguments, and then inside the function body we can return with the return value. Function bodies are statements which can contain expressions. So we'll be evaluating or interpreting quite a bit. And this is a lot of power. In fact, it's going to turn out that this is really all you need, pretty much, to be just as powerful as any other programming language. Recursive functions pack a wallop. There's a lot going on. And that means that this is actually a double-edged sword. With great power comes ... let's say lots of care that we have to take. We've been writing together in Python a program that simulates, interprets, evaluates JavaScript, and this means that anything that JavaScript could do we could also do in Python, because if for some reason we didn't really know how to write it in Python, we would just leave it in JavaScript and run our written in Python JavaScript interpreter. It's a bit like that MC Escher drawing where 1 hand is drawing another hand that's actually drawing the first in a bit of a recursive loop. We can use language A to simulate or interpret language B. So on the 1 hand, if you'll permit me, I can write a Python program that simulates any JavaScript program. That means that Python is at least as powerful as JavaScript. We'll abbreviate JavaScript with JS. It also turns out--not shown here, but it's actually very similar-- that I could write in JavaScript an interpreter for Python. So JavaScript is at least as powerful as Python. Both of these claims ignore speed because our interpreter or our web browser might be a little slower than just running the appropriate code natively, just as translating natural language text from Spanish into Mandarin Chinese takes some amount of time. But there's a strong sense in which these languages are equally expressive. Any computation I could carry out in Python I could also carry out in JavaScript. Any computation I could carry out in JavaScript I could also carry out in Python. I can be just as creative in either language. Now, one language may look prettier than another, one language may take a little less time to say a certain thought, to have a creative idea, but ultimately, I can express the same range of work, emotions, desires in Python and in JavaScript. This is pretty powerful stuff. We know from computer science theory from people like Alan Turing that languages like Python and JavaScript are equally powerful. You've seen half of that here when we wrote an interpreter for JavaScript in Python. We might wonder are natural languages equal? Spanish, Portuguese, Japanese, Mandarin, Hindi--are these languages all equal in every way? This idea is actually not universally accepted. Does every French utterance have an equivalent Japanese utterance? The Sapir Whorf hypothesis--or linguistic relativity hypothesis--in linguistics holds that the structure of a language influences the ways in which speakers reason about the way world. This is still hotly debated. Language is generally held to influence thought. For a chilling fictionalization, I encourage you back again to George Orwell's 1984. However, in computing in unnatural languages like Python and JavaScript, we can have definitive answers based on mathematical proofs. There is a very strong sense in which Python, JavaScript, C, C++, C-Sharp, and Java can all do exactly the same range of computations-- those that can be done on what's known as a "Turing machine," a mathematical model of computation. However we won't talk about Turing machines in detail in this class. [Complete and utter darkness] In the real world, it's entirely possible that language influences thought, and it may be that some things are easier in 1 language than another. In the world of computing, the languages that we are considering, like Python and JavaScript, are ultimately equally expressive in a strong formal sense. However, we often still think that some things are easier-- that is, maybe they take you a little less time to write or they're a little easier to read, they feel a little more natural--in 1 language than another. You may just prefer writing code in Python to writing code in JavaScript even though ultimately you could say all of the same things in JavaScript. One may feel a little easier to you even though the end results would be the same. So I assert that interpreting or translating between 2 systems of meaning is actually a very deep concept. And 1 interesting downside for us is that simulating a program, interpreting it, translating it often requires running it. Let's see how that plays out. Here I've written a simple Python program, the sort that we might want to translate or interpret into JavaScript and then back again, and what I'd like to know is, what does it do? Maybe it prints 0. I've listed a few options. I want you to think about this program in your head and tell me, what will happen if I run it? Check all that apply, bearing in mind that I am trying to trip you up. Let's go through the answer together. When I run this program, we start out with x being 0, and then this while loop says as long as True is true, keep incrementing x. So now x is 1, it's 2, it's 3, it's 4, it's 5, and we never actually get to this line about the print. So does this program print 0? Not so much. Control flow goes here, here, here, then back, and we stay in this while loop forever. It doesn't print out this huge number 4,294,967,296, which is, I think, pretty close to, let's say, 2 to the 32. This is a reasonable guess if you think, "Oh, the integer is going to max out at some value based on computer hardware." But no. There's a thought that it raises an exception. Some badly made Python interpreters might raise an exception on this, but it should not. If we had lots of computing resources, this would run forever. And similarly, it also never prints out -1. The correct answer is none of these things. It loops forever. All right. So if this program naturally loops forever and we're writing an interpreter that exactly simulates this program by following all of its steps, our interpreter is also going to loop forever. If someone had written this program in JavaScript and put it in the middle of a web page, our web browser would loop forever and never actually render the resulting web page. All right. Infinite loops, those are no fun at all. I want to see my web page. I don't want to wait an infinite number of seconds and then see my web page. That's pretty long. I would get hungry before that ran out. Wouldn't it be nice if we could just tell if a program was going to loop forever or not? And then if it's going to loop forever, I won't run it or I'll print a little warning on the web page, but I won't waste a lot of time on it. So what I'd really like to do is just look at the program source code as we got it from the Web, say, and just be able to tell if it loops forever in one of these infinite loops or if it halts, if it stops, if it settles down and returns an answer after some finite amount of time. This seems like a totally legitimate request. Unfortunately, it's not just difficult, it's actually impossible, provably impossible. Not really hard, we're too lazy, we couldn't figure it out, but we know you can't do it. You can't make this determination correctly every time. To see why this can't happen, let's assume we could solve it and see what bad things happen to the world. Let's assume that we have thought very hard about this and we have somehow implemented a magic procedure called halts which takes another procedure as an argument and returns True if that procedure halts and False if it loops forever. Now we'd know if it's safe to evaluate a web page. We just look at all the JavaScript on the web page, we call halts on it, if that returns True every time, we can totally render that web page. Let's test our understanding of this mythical halts procedure. Over here on the left I've written 4 bits of Python code: vladimir, nabokov, pale, and fire, and fire is in red because that's warm. One possibility is that we think vladimir halts; another possibility is that we think nabokov halts. What I'd like you to do is tell me which of these 4 statements-- there could be multiple--are actually true. Check each box that corresponds to a true fact. Going through it together, vladimir immediately returns 1, so it halts in pretty much 1 step. So yes, this does not loop forever. To figure out the value of nabokov, we call nabokov, which causes us to call nabokov, which causes us to call nabokov. This is one of those infinite loops. Not my most symmetric infinity symbol ever. We never actually get a value out of this. We call ourselves over and over again. This procedure does not halt. You might be thinking, "Oh, eventually we will run out of stack space," or more prosaic concerns like that, but remember here I want you to think in the abstract. We're assuming this mythical halts procedure. How about pale? X is 0, while True, x is x + 1. We actually looked at this before. This loop does not halt, does not terminate. How about fire? We start out with x is 0 and y is 1000, and as long as x is less than y, we add 2 to x and we add y to 1. After a little bit, this will be 2 and 1001, then this will be 4 and 1002, this will be 6 and 1003. And although it doesn't look like it now, eventually x will catch up to y because x is growing twice as fast. For example, after 1000 steps, x will be 2000 and y will also be 2000, at which point we'll break out of this loop. So fire does in fact halt. Pale Fire was a 1962 novel by Nabokov. He's perhaps more famous for Lolita. He was a Russian author who did a lot of writing in English. All right. We didn't see anything bad. That all looked fine. We could figure out just by staring at things whether they halted or not. Why am I predicting doom and gloom? We didn't have any problems. Here I've written just 1 last Python program. You've mastered all the others; this one should not be too tricky. I have this procedure, tsif, and if our magical procedure says that it halts, then we take this then branch. Otherwise, we take this else branch. 1, 2, 3, 4, 5, 6, 7 lines long. What I'd like you to do is check this box if halts (tsif) returns True and check this other box if halts (tsif) is False. Check all that are true. It should be relatively direct, a 50-50 chance even if you're guessing, right? Try it out. Give it some thought. Let's go through the possibilities. Let's imagine for now that halts (tsif) is true-- that tsif terminates. This means that after a finite number of steps, tsif must return a value. Well, let's go through and see what that value is. We go in here, and if halts (tsif), well actually, we were just assuming that was true, so we'll definitely take this then branch. Uh-oh, we loop forever. So we assumed that tsif halted, but now we seem to be looping forever. That is a contradiction, and it makes me super unhappy. By the way, cutely, sometimes people in mathematics-- rarely, but sometimes--draw crossed swords to show a contradiction. That's of course near and dear to my heart, so we'll use that. So when we thought the procedure halted, its source code made it loop forever. So if it's not one, it must be the other. Let's try the other approach. Let's say that we think that tsif does not halt, so it should loop forever. So let's run it and see it looping forever. We get in here, is halts (tsif) true? No, we just assumed it was false. Okay, so we go down to the else branch and we--oh--immediately return. That's kind of annoying because we were assuming that it doesn't halt--that it loops forever. Neither of those options are possible. This is also tricky. There is no possible value for halts that works out. No matter what you do, it ends up being wrong. And this is why we could never have a procedure like halts that worked in the real world. Even if you thought it worked on some cases, there's one evil case, at least, where it doesn't. tsif--This Sentence is False. It's a paradox, and the essence of a paradox like this is self reference. This sentence talks about itself. This sentence asserts its own falsehood. Similarly, the source code for tsif talks about whether or not tsif halts. This is the computer programming equivalent of a natural language paradox like this sentence is false. If I ask you, is this sentence true? Well, that can't be right because then it would truthfully be asserting that it's false, so that's a contradiction. If I ask you, is this sentence false? Well, then we'd invert it and have it be asserting that it was true. Oh, another contradiction--none of these work. It's the same problem in natural language or in computer science. You may have heard a similar version of this called the Barber Paradox, which is typically phrased as something like the barber cuts the hair of each person in this village who does not cuts its own hair. The question is does the barber do a self haircut or not? It's a lot like this sentence is false, but one level removed. You may also have heard Epimenides Paradox-- "All Cretans are liars. I'm a Cretan." Just like this sentence is false, but one step removed. So we've just finished learning about interpreters and formal semantics. We touched briefly on the halting problem. Surprisingly, although the halting problem officially is impossible to solve, it's actually one of my favorite areas in computer science. The halting problem and its cousin, Rice's Theorem, are sometimes informally known as the Law of Interpreter/Writer Employability. Because it's officially impossible to solve all these problems and get them right every time, there's always a market for people who can make closer approximations or be almost right, be right most of the time, be right with high probability. We know it's impossible to do absolutely correctly, but nothing stops us from being 99.999% correct. So we keep trying, with closer and closer approximations. In fact, a few years ago, with a student, I was trying to do just that. We wanted to look at a programmed source code and guess which lines were likely to be executed frequently without actually running the program. If we could solve this formally, we could definitely solve the halting problem. So we know it's impossible, but we can solve it before a subset of programs or be often right. You might imagine looking at the recursive definition for Fibonacci. If you're calling Fibonacci of ten, the recursive call happens much, much more frequently than the base case that just returns one. Is there some way we can look at how humans write programs and figure out what's common based on that? It turns out we were able to extract this sort of structural information or comments that are present in human written programs and figure out for them which lines are more or less likely to be executed, or executed more or less frequently at run time. So even though the problem is impossible to solve in practice, we actually view this as an opportunity. Because it's not possible to get it exactly right, we want to come as close as we can and reach for the stars. Welcome back. This is Unit 6 of Programming Languages. And the story, thus far, is that we started with a big Web page that might contain embedded JavaScript. And we did Lexing or Lexical Analysis to break it up into a list of tokens. And once we had that list of tokens, we did Parsing to check those tokens against a formal grammar and produce a Parse Tree. More recently, we've learned how to do Interpreting to walk up and down a parse tree-- with an environment--and figure out what the final result is supposed to be. We often call that Meaning or Semantics. In this Unit, we're going to put that all together to build a unified Web browser, and it's going to require all the tricks that we've learned, up to this point--including things like how to debug or what can go wrong if you interpret a program with an infinite loop. Let's talk about the Architecture for our Web browser. Just as engineers or architects that build buildings in the Real World like to have blueprints or plans--or some notion of how that design is going to come together-- we try to do the same thing in software engineering. We want to have a software architecture, a list of major components, and a design that incorporates all of them. Our first step is to find our Web page and lex it and parse it until we have an Abstract Syntax Tree. Most commonly, our HTML interpreter will walk over the Abstract Syntax Tree that we got from the parsing, and it may find elements in there that are embedded JavaScript. So then we'll have to call the JavaScript interpreter on them. In most cases, at some point the JavaScript code from the user will call "write" or "document_write", and that's that function that says: If I'm in JavaScript, display this on the resulting Web page. Because the meaning of a JavaScript program that calls "write" is that that text should be displayed, we'll definitely want to store all of the text from "write" so that we remember to include it in the Web page later. Eventually, the JavaScript fragments will be done executing and will be back to the HTML interpreter, which will have received all of those strings from "write", and it will take them-- plus all of the normal HTML elements-- and call the graphics library to make a pretty picture of them. Eventually, at the end of the day-- we end up with an image of the Web page, and that's what we wanted from our simple Web browser. Let's make sure that we all have the same idea about how that architecture is going to go--with a quiz. I'm going to write down candidate steps--or candidate parts-- of our algorithm's design, and you're going to tell me which parts are wrong or if there's a part that's shown in the wrong order. So here I've written 5 possible steps, in a particular order, that our Web browser might follow and I want you to put a check mark--in this multiple multiple choice quiz-- next to each step that's either erroneous or out of order. Let's go through it together--the Web page is broken down into words and trees. That's lexing and parsing, and we do that first. This is right; the Web page is then interpreted--that's True. Some of the fragments or elements that we come across might be JavaScript--embedded JavaScript-- so then we have to call the JavaScript interpreter. So thus far, the first 3 seem pretty good. Eventually, the user's JavaScript code on the Web page may call: write--at which point we'll have to store all of that output so that we can display it on the Web page. That's good. Ah! But then here we're suggesting that the JavaScript interpreter calls the graphics library. This is an erroneous step; in our particular architecture, the JavaScript interpreter returns all of the strings to the HTML interpreter and that interpreter, then, calls the graphics library. This is what's known as a Design Decision. For our particular Web browser, only the HTML interpreter is going to call the graphics library. That's not the only way to do it. Just like there's more than one way to build a house, there's more than one way to build or design a Web browser. We've just decided for this particular one, that only the HTML interpreter's going to call the graphics library. I claim that's going to simplify the amount of code we'd have to write. So we just said, in our particular architecture, that the HTML interpreter is going to call the JavaScript interpreter--but not the other way around. So they're kind of like two pieces to a puzzle that totally fit. These fit perfectly with the application of another jigsaw. I've labeled them as fitting so they fit now. Recall that we treat JavaScript as a single HTML token. And the reason for this is that things like (5 < 7) or (a > b)-- those can appear in JavaScript. But they would confuse us in HTML because we'd think the Less Than and Greater Than were part of tags. For example, this is totally Valid JavaScript. Assuming (a) and (b) are defined somewhere, this should either print out True or False. But if you look at it carefully, this (< b) is sort of indistinguishable from the (< b) that might come in legitimate HTML-- like: (<b> bold). So that's why we took all of this text and we didn't interpret it in our HTML parser. Instead, we saved it for later. Well--now's the time! Let me just remind you of how we defined our tokens related to JavaScript. Here I have our rule for beginning the tokenization of JavaScript. Remember, these backslashes are Escape sequences. You should read right over them. In some sense, the first character I want to match is this Less Than sign-- but just in case that has special meaning for regular expressions, I'm going to put a backslash before it to Escape it so that they know I mean exactly this backslash. Just like over here, I mean exactly this space, exactly this double quote, exactly this forward slash, exactly this double quote, and exactly this Great Than sign. So we're requiring JavaScript to start with: <script\ type=*text\/javascript\ and when it does, we move our lexer into a slightly different world. And we talked about this before; we just have multiple finite state machines and then-- whoop--we're down at the one at the bottom now. And then down here, I have my rule for ending JavaScript lexing. We're looking for this, but just in case any of these 3 special symbols have special meaning to regular expressions, I have put the backslash and Escape sequence in front of all of them. This is probably not actually necessary, but it's what's known as "defensive programming". It can't hurt, might help. I want the token.value to be all of the string data, all of the embedded JavaScript code. I'm going to use a variable we haven't told you about yet. It's possible to get the entire input string from the lexer in: (token.lexer.lexdata). Don't worry too much; I'm just going to assert that this works. This is the entire big string, and I'm going to get it, starting at the position we recorded earlier. Back up here--when we found the javascript(token) we wrote down the current lexer position and stored it in a little variable we made up called (code_start). So let's say 50 characters into the file we started the javascript. We'll just store that 50 right here in (code_start). That's going to let us pull out, starting at Character 50, up to where we currently are. Let's say that there are 100 characters of JavaScript-- now we'd be at 150--and I'm subtracting out 9. Why am I subtracting out 9? 1, 2, 3, 4, 5, 6, 7, 8, 9-- it's the size of this ending token. I don't want this (/script) to be in it. So I've set the value correctly. I say the type of this token is 'JAVASCRIPT'. For accurate debugging information, we want to keep track of which line we were on in case we want to report errors later. Here's a trick: the JavaScript embedded code probably had new lines in it. I want to make sure that all of those count, so I'm going to count up the total number of new lines--or character returns or whatnot-- found in the embedded JavaScript code and increment my own line count by that amount. And then we go back and move to the 'INITIAL' state of the lexer where we can get HTML tokens, like 'LANGLE', 'LANGLESLASH', 'RANGLE'. So this is just gathering up the raw string for embedded JavaScript, and storing it as a single HTML token. One last important thing to remind you of: Note that we stripped off the final \<\/script\> from the end. And because of the way lexpos works, it measures the value after we match the token. We actually end up stripping off the \<script\ type="text\/javascript\"\ from the beginning as well. So let's say that this is part of the Web page we receive. It's our HTML input and we're going to run our Lexer over it. Let's just make sure we understand how this embedded JavaScript is passed down the line, by having you tell me what token.value-- the string eventually associated with the token--will be? I've listed 4 possible options, but only 1 of them can be right. Check the one that you think corresponds to token.value for this HTML input. Well, we just saw the code for processing these tokens, and we know that it went to a bit of trouble to store the beginning position, lexps, and then the ending position, but then--phwoomp--subtract out 9. So this is way too much. We went to a lot of trouble to drop <script type"--blah, blah, blah--so this one doesn't match. Similarly, this one doesn't match. This one looks perfect! It has stripped out the tag at the beginning and the tag at the end. This one still has the tag at the end, so it's not right. In the particular example we're using, the Satasai or Bihari Satsai are 700 verses from the 17th century. They're written in Hindi and they cover topics from morality to devotion, to love. Good stuff! So we just learned how to do that JavaScript token in lexical analysis. Now we need to know how to handle that special JavaScript token.type when we're parsing. Just to review a bit, this is how we did basic HTML parsing or our basic HTML grammar. We say it's a parsing rule, with p_. This is the kind of thing we're trying to parse--an element-- and then we write down here, the rule from the grammar, and where we would normally write an arrow, they ask us to write a colon. So element can be rewritten to word. And then p[0] is the final parse tree. And p[1] is the child parse tree. And we build the final parse tree out of the child parse tree, growing a bigger tree, over time. Well--actually, our handling of JavaScript elements is very similar. We just indicate that an HTML element can consist of a JavaScript token, and we build up our parse tree by noting that it's a JavaScript token and then including the text. And you see this word here--JAVASCRIPT--in all capital letters. Back here, when we were lexing the JavaScript token, we said: token.type is JAVASCRIPT, in all capital letters. Those intentionally match. This is the linkage we're making between the lexer and the parser. In fact, they have to match; otherwise, it won't work. So let me show you a concrete example. Let's say my HTML input is: hello my and then there's some 'javascript' which says: document.write (99); and then "luft ballons". Let me show you what the Abstract Syntax Tree-- or what the parse tree--will look like for this. And we'll recall that HTML is a list of elements, and here we have 4 elements: 1, 2, 3, 4. The first is the word_element, hello. The next is the word_element, my. The next is the javascript_element containing only the important text-- not all of this tag stuff. And the last is the word_element, luftballons. This is the parse tree, a list of HTML elements. It just so happens that none of these are nested, but they could have been if there were some tags in here. And here: 99 luftballons is perhaps more commonly known as-- in English--as 99 Red Balloons. It was a protest song, in German, written around 1983. Here are, clearly, 99 entire balloons. It must be that the other 95 are just behind this one-- exactly covered by it. You believe me, don't you? You totally don't. So let's work together to extend our HTML Interpreter to handle these new JavaScript elements-- just like we saw a few seconds ago. Just like we saw in the last example, typically, the parse tree for HTML will be a list of elements. So we'll just run down and process each one, in turn. How we process it depends on its type. Is it a word, a tag, JavaScript? One of the easiest cases for us is if it's a word_element, we just call our graphics library and add that word to the final Web page. We've already seen what to do with <tag>_ elements in a previous quiz, so let's just do JavaScript now. We can get the text of the embedded JavaScript fragment out of the Abstract Syntax Tree. That's going to be something like: "document.write(55);"-- could be more complicated, calling Fibonacci functions-- doing arbitrary computation, in fact. Here "js" stands for JavaScript, and this is the text of the program. This next bit is a bit arbitrary. I'm going to walk through all the steps, but you should not worry about having to guess these. These come out of nowhere or come from library integration. Let's say that we've written down our JavaScript token definitions in some other file called: jstokens. I'm going to need to build a lexer to break this string down into tokens. Similarly, let's say I've put all of my JavaScript grammar rules somewhere else. I'm not showing them right here, but they're saved somewhere else on the disc, in a file called: jsgrammar. Once I break this text down into tokens, I'm going to need to check and see if it's valid JavaScript and build a parse tree. "lex" is the name of our library module for doing lexing. "yacc" is the name for our library module for doing parsing. "yacc" does not sound like it should be doing parsing. It stands for: Yet Another Compiler-Compiler, a tool for making compilers or interpreters. In fact, just like the JavaScript interpreter that we're making now. For now, this name is just a historical accident. Here's the real exciting part: I'm going to call our JavaScript parser and ask it to parse the text from the embedded JavaScript fragment, using the lexer--the token definitions--from jslexer. So jstree now holds a parse tree for JavaScript. And now the quiz for you is just to fill in these two blanks. I have this parse tree for JavaScript, and now I want to do--(something). I want to call our JavaScript interpreter and ask it to interpret (something--you tell me) and then, eventually, I want to call the graphics library and draw some word in the Web page. Which word should it be? Let's fill in the blanks. Well, we've seen that interpreters always work over Abstract Syntax Trees. My JavaScript interpreter should be called on our JavaScript parse tree-- our JavaScript Abstract Syntax Tree-- and it's going to arrange to return to us a string corresponding to what the user was going to print out as a result of calls to write, like this string containing (55). So that result is exactly what we want to display on the Web page. If this tripped you up because it was almost too simple, don't worry about it. Much of the detail in the integration is in knowing exactly the right way to call the lexar and the parser. But those aren't endearing concepts that I really want you to know after that class. Those are mere implementation details. Instead, the architecture-- the fact that we can only call interpreters on Abstract Syntax Trees and that we've decided to pass string results back and then display them, using our graphics library-- that's important; that's a design decision. This--this is a historical accident. That's why I gave all of you these, for free, and asked you to tell me about these conceptual bits. So we just filled out that previous code integrating our HTML interpreter with our JavaScript interpreter, assuming that our JavaScript interpreter returns a string. The basic idea is that if the embedded JavaScript code called document.write(x), we'd notice that x and save it and return it back to you. Unfortunately, there is an evil problem. This is a little more complicated than it looks. This is totally legitimate JavaScript code. Note that I have 1 call to document.write and then another call to document.write. Somehow I'm going to need to paste together "hello" and "world" and return both of them. So the basic problem here is that there may not be just 1 call to write. There may be many more or actually there may be 0, but we want to get out of this "hello-space-world!" So we have to store text printed by write, but we may find that as we execute or interpret the JavaScript program, the amount of output grows. Well, if we want to store values that may change-- boy, if only we already had some way to do that--oh wait! We totally do. We went to all that trouble to learn about how environments work in nested environments and variable updates. Let's reuse that. That was really powerful! So to make this work out, we'll just make a little contract with ourselves. Let's assume that when we're interpreting JavaScript and we come across a call to write we'll just figure out what the argument is--that will be some string-- and we'll append it to a special "javascript--space--output" variable that we'll store in the global environment. Global because you could call write from anywhere. Everyone has to be able to see it. So here is our glorious JavaScript interpreter, or at least the parts of it that you haven't already written. We're given the abstract syntax tree, which contains a list of JavaScript elements. The first thing we do is make a global environment. Global environments have no parent pointers. This would be a parent pointer, but instead it's none. We're going to start it out with the variable "javascript--space--output", mapping to the empty string. Then for every element in the embedded JavaScript code, we evaluate that element--you've already seen how to do that--in the global environment. This might make changes to it over time through calls to environment update. At the end of the day, the string we return is, well, we have the global environment right here. We get its 1th element, which is this mapping, and we get out the current value of "javascript output," which hopefully has changed. So it's quiz time. You've seen our assumption, and we've written out the code for the JavaScript interpreter, at least at the top level. Here I've written 3 sentences. We could rename "javascript--space--output" to anything as long as we're consistent. "Javascript--space--output" is a good choice because it has a space in it, and "javascript--space--output" starts empty, mapping to the empty string to support 0 calls to write. Multiple, multiple choice--check each one of these that's true. Well, let's go through them together. We could rename "javascript output" to anything as long as we're consistent. This is very tempting. Why don't I change this ugly space to an underscore. Well, the reason is that if the user knew that, in their embedded JavaScript fragment, they could assign to the variable "javascript_output" and because we're piggybacking on our environment, they'd find it, and they'd collide with it. So rather than printing out the right answer, we'd print out whatever the value was for this variable "javascript output." It's super unlikely, very unlikely that the user would happen to name a variable "javascript_output," but it's a security problem and officially there exists at least a few programs that won't compute the right answer if we change it to a variable that the user can collide with. So we can't actually rename it to anything. We have to be careful. When this feeds into the second one, "javascript output" is a good choice because it has a space in it--yes! If you think back to our lexer rule for identifiers, it looks something like this. Every javascript identifier contains upper or lowercase letters and possibly an underscore but can't contain a space. So this means there is no way for the user to have a variable name that has a space in it, so no way for them to collide with the rest of the environment. We could also have made a different design decision and had some global variable that's stored the "javascript output," but this approach, first, piggybacks on something you've already done, and second, illuminates cool issues like this. Finally, "javascript output" starts empty to support 0 calls to write. That does end up working out. Imagine that trees is the empty list. They just said begin Javascript, end JavaScript and didn't do any work. We would want to return a real value rather than having some sort of exception or look-up error problem. If I didn't initialize "javascript output" to the empty string, when we went to look it up here, there might not be anything there. Well, our previous approach only works if we treat calls to "write" specially, and we're careful to notice every call to "write" and append to this "javascript output" variable in the global environment. So let's work it out together. I'll do the first bit, and you'll finish it off. We're going to go back to our JavaScript interpreter and finish up our handling of "write," a special function call. Well, function calls are expressions, so we're in evaluating expression. Here's the abstract syntax tree or the parse tree for the expression. Here's the current environment. We need to figure out the type of the expression. We've already seen how to do binops, numbers, that sort of thing. So the one we really care about this time is function calls. So this is what we had before. A function call has a name and some actual arguments. Looks a bit like this. If the function call is myfun(a, 3+4), the function name is myfun, and the arguments are a list of expressions. We're going to go look up the function name in the environment. Now "write" is one of those special functions that users get to call, but they never actually provide a definition for. So we're not going to find it in the environment. Our environment lookup returns none if the function is "write," but it also returns none if the function is just unknown, so we'll check for "write" specially. If so, "write" should have a single argument, so we'll evaluate it. We'll get the current output that the user has written through previous calls to "write." I'm doing an environment lookup in the current environment instead of the global environment. Here's a trick though. Remember how environment lookups work. If I don't have it in my pockets, I check my hotel room. I check back home. I ask my parents. I look around on the web. I keep going back until eventually I hit the global environment. Because we've specially picked a variable name with a space in it, noone else can possibly make this variable. So even if I'm not in the global environment, I won't have it. My hotel room won't have it. My house won't have it. Eventually, I'll get back to the global environment, which we know has it because we were careful to put it in explicitly starting as the empty string last time. So the quiz for you is to fill in these 2 blanks. We figured out the output so far, and now we want to update the environment so that "javascript output" takes on a new value. What should go in here to make that work out? We want to concatenate everything the user has previously written, and then on the end of it, put the new current value. So I'm going to put all of the output we've gathered up so far from previous calls to document "write," and then just turn the value of the argument into a string and paste it on the end. And that's it. We handle calls to document "write" specially, and all of our previous code for function calls now goes else: if function name is not "write" then do whatever we had previously. So we've just seen how to integrate JavaScript and HTML in our interpreter in our web browser. Let me show you a more complicated example. We'll see how it plays out in real life. We often use this tag to begin a webpage. It's not strictly necessary, but it's very good practice. We're going to use this tag to begin a paragraph. Just to remind us, it's possible to have comments in HTML. The lexer strips them out, so we're not going to see them at the interpreter level. Here I've put in a list of word elements, This is a, and then here's a tag element, and inside it, nested are 3 more word elements and then the tag element ends. This is an anchor tag, making a link to Google. Let's say I want to write a webpage about John Searle's famous Chinese Room thought experiment, in which he argues against or at least puts forth positions that cause one to consider artificial intelligence. It's fun stuff. But I don't remember exactly when he made the experiment. I will in a totally contrived example. Super contrived. Use Javascript to compute this. So let's say I can't remember exactly when he came out with the Chinese Room thought experiment, but I do know that the date was equal to 1,260 + 6 factorial. If only there were some way I could carryout this computation on my webpage. Whoa is me! So I've written some Javascript to do just that. I compute 6 factorial + 1,260 and write it out and then we finish out with the rest of our webpage text. So this whole bit here is an embedded JavaScript fragment. Over here, we see the final result. This is a link to Google. John Searle's italicized Chinese Room thought experiment from 1980-- oh! that's when it was. How silly of me not to remember!-- argues against artificial intelligence. And you may notice that since there's some space here at the end of the script, this comma doesn't line up exactly with the 1980. Let's not worry about that for now. So now, there's a quiz. Our JavaScript interpreter is going to have to compute the value of 6 factorial, a function call within a function call within a function call. It's turtles all the way down. How many different environment frames will be created by the interpreter for factorial 6 above? Include the global frame in your answer. How many total environment frames will we be juggling at the same time? Fill in the blank. Question 2--In how many of those frames will n have the same value? So if you could find 3 frames where n was 77, then the answer here would be 3. It's going to turn out that there are 8. There's the global frame. There's our call factorial 6. There's factorial 5, 4......1, and in fact, if you look carefully--this was a bit of a trick-- at our termination condition for this recursive procedure, we actually call in here when n is 0. So that's 1, 2, 3, 4, 5, 6, 7, 8, if we include the global frame. And how many of those will n have the same value? None of them. It's 0, 1, 2, 3, 4, 5, 6, and undefined. It's never the same. We're honestly doing different computation going through different values. In a project as big as a JavaScript interpreter in a web browser, we will make mistakes. And in fact, even a single word flip can be deadly. Consider this hypothetical utterance from Joan of Arc: I would rather have a sandwich then be burned alive. Up here we've got the sandwich, here we've got the fire. The meaning of this single word really, really matters in this sentence. Then actually means "and subsequently." For most of us, I would rather have a sandwich and subsequently be burned alive is not actually what we would go for. So the difference between then and than--a single word in a natural language-- changes the meaning almost entirely. Joan of Arc was a French national heroine and martyr, and although it's easy to imagine these sorts of single word flips in natural languages, we're going to see the same problem in constructed languages like JavaScript or HTML. We're going to have to get every word right in order for the meaning to be correct, and this is a big project. That means we will need to focus some of our efforts on removing or finding mistakes, and that process is called debugging in computer science. For example, suppose when we were writing out the if-then-else part of our JavaScript interpreter we made a single mistake. We pull the conditional expression from the oneth element of the tree, we pull the then branch from the second element of the tree, and we pull the else branch from the third element of the tree. Then we evaluate the conditional expression in the environment, and if it's true, we execute the else statements, and if it's false, we execute the then branch statements. Did you catch the mistake? We've swapped these 2 lines. If the conditional comes out true, we will mistakenly go to the else branch. If the conditional comes out false, we'll mistakenly go to the then branch. We'll get almost every program incorrect. But not actually every program, and this is a skill in debugging. What we want to do is make a test case, a sample JavaScript programmer web page, that will show off this mistake, where the answer won't be what we expected. So here I've written down 4 candidate JavaScript programs that we might use as test cases to notice this mistake. In this multiple multiple choice quiz, what I would like you to do is select each test case that will actually show off the mistake. That is, imagine our interpreter has this bug in it and we feed it this input. Will we get the same answer we expect from reasoning in our minds, or will we get something different? If we get something different than what we expect, then we know there's a bug, and we can get started on fixing it. Which of these inputs will highlight this bug? Now let's go through each one of them. Writing "potato" may be fun, but it does not involve any sort of if-then-else processing, so it won't show off our defect. The expected answer is that the web page shows potato, and the answer we'll get is the web page shows potato. So this is not a good test case. Over here, if x is less than y write "tomato", else write "eggplant". We need a little more in this test case like values of x and y, but this is the right idea. Let's say that x is something like 0 and y is something like 1. We then expect it to print out "tomato" but because we've made this bug over here, it will print out "eggplant" instead. So the observed behavior will differ from our intuition or from our specification of what should really happen, so then we know there's a mistake. Over here return 2 + 3. Again there's no conditional control flow, so this is not a very good test for us. Finally, over here factorial does involve an if in determining whether or not the program terminates. This is a very good test because almost immediately, factorial of 5, we're going to see, oh, is 5 equal to 0? It's not. Bug. We'll return 1. We won't actually make any recursive calls. We'll get the wrong answer really fast. So this is a good test case for us. Testing just means checking a program to gain confidence that it's correct. More formally, in a software engineering class we'd say that we want to gain confidence that the implementation adheres to the specification as refined from the requirements. I'm not going to spend much time on these words in this class. You may have a chance to learn about them later. But the implementation is your source code and the specification and requirements come from the problem statements--whatever you were told to do in the quiz or in the homework or by your boss or some such. This is a bit of a personal aside, but in my mind, one of the most important things about testing is noticing that it only gains you confidence. It's not a proof. If you have a big program like a web browser and you try it on 10 web pages and it seems good, that is not a proof that it's always going to work perfectly in the future, but it does give you more confidence than only trying it on 1 web page. Probably. It depends on how cool that web page is. So typically, programs are very big and accept an infinite set of inputs. There are an infinite number of possible web pages out there. We know that because the grammar for web pages is recursive and allows for infinite creativity. We could write down any work of literature and have it be a web page. So we're not going to test them all in finite time; we're only going to gain confidence by testing a few. And because we can't test everything, we have to pick the things to test well. Just like in the previous quiz, we don't want to waste time on test cases that aren't going to get us a debug. In the real world, in commercial software engineering testing is a huge cost. In fact, maintenance often accounts for 90% of the life cycle cost of software. We spend very little time writing a program originally and a huge amount of time maintaining it, refactoring it, making it better in the face of changing ideas of what the users want, all that sort of thing. So testing is massive. Let's test our knowledge of testing--yes, all my puns are that bad--with a quiz. Mark all true statements. Part of testing a program feature is running the program in a way that exercises that feature--and then verifying the output. Testing can give us absolute certainty that our JavaScript interpreter is correct. One test input, or test case, is just as good as another. This first one, part of testing a program feature is running the program in a way that exercises that feature, that was the last quiz. Yes, that is part of testing. We have to exercise the feature and then compare the observed output to what we expected. And if they're different, that indicates a bug. Testing can give us absolute certainty. No. Testing can give us confidence that our JavaScript interpreter is correct. Because our JavaScript interpreter could potentially accept an infinite number of inputs-- there are an infinite number of possible JavaScript programs out there-- we don't have time to test them all. We can't be absolutely certain based on testing, but it can give us confidence. Finally, one test input is just as good as another. No. This was the previous quiz. We need a test input that exercises the feature. And if we have a bunch of features in our program, we would want a suite of test inputs that cover all those features. We've seen a little bit of testing, but let's look at testing from another angle. Let's say this is the program or the thing that we're considering testing. We want to test our JavaScript interpreter, and we're going to feed it this factorial definition and this call to document write. And by thinking hard about the problem, we know the answer we should get is 120. 5 times 4 times 3 times 2 times 1--5 factorial. Here's the quiz. Let's say this is our test case and that's the input we're comparing against. I want to know which parts of the program we gain confidence about. So here I've written 6 important parts of our JavaScript interpreter: handling function calls; handling environment lookups for variable values; handling string constants like hello; local variable declarations like var temp = 3; assignment statements like z = 2; and binary operations like addition. And what I want to know is, if this is our test input and we're comparing the answer to 120, which of these features in our interpreter will be tested? If something isn't tested, we can't hope to find a bug in it. As a hint, another way of looking at this problem is to imagine, let's say, that our code for function calls totally didn't work. Would we get 120? If the answer is no, then we're testing function calls. Let's go through our program and just notice everything we end up using. One of the first things we do is call the function write, and its argument is based on calling the function factorial of 5, so then we have to get up here and start determining if n is equal to 0. So function calls are definitely critical to getting the output to this test case correct. One of the first things we have to do is look up and see if n is equal to 0, and we'll change from 5 to 4 to 3 to 2 to 1 to 0 depending on which environment frame we're in. We will definitely end up doing environment lookups. If we can't do them, we don't know what the value of n is, so we're going to start getting this wrong. Eventually, as time goes by, we're comparing n to 0, we're multiplying n by the result of this function call, and we're subtracting 1 from n. Those are all binary operators. The equality check, the multiplication, and the subtraction-- those are all binary operator expressions. So we are testing at least some of our binary operators. But for the rest of these elements of our interpreter, we're not testing them explicitly. Even though we end up calling write, there are no string constants. The word here, constant, is very important, like "hello" in this program. You could argue that we're building up a dynamic string, 120, but that's not a string constant. There are also no local variable declarations. A local variable declaration is different from a function's formal parameter, and this matters because we're trying to find bugs in our interpreter code. Since we have different Python code to handle parameters than we do for local variable declarations, if we mistakenly think they're the same thing, we'll have more confidence in our program than we should. We might miss bugs. So we're not testing this sort of thing--var temp = 2. That's a local variable declaration. We don't see anything like that over here. Finally, assignment statements. There are no assignment statements in this program. Now, we'll end up associating with n the value 5 or 4 or 3 or 2 or 1, but that's handled by our function call code. We don't see anything like this--x = 2--in this input, so we're not testing it. So while this is a good test case and it checks many things, it does not give us confidence that we've exercised every feature of our interpreter. We'd need a few more test cases to do that. Let's continue our exploration of testing. As part of this class we're going to be working on a final project together-- for example, a web browser for HTML and JavaScript. You'll want to ensure that it's correct, that it does what it's supposed to do. One of the best ways to make that happen is to stop and think before you write anything and plan and reason about how the program will go. It's like designing a building before you set out to build it. If you have even the most rudimentary blueprints, your odds of success go up quite a bit. But often we don't spend the time we would like or we don't have the resources to plan everything in meticulous detail, so at some point we just go out and write the source code, at which point you want to test the implementation. Let me give you another example of mistakes in testing by imagining that I'm going to make a mistake when writing our code to look up a variable in the environment. Remember that our environment is a tuple of a parent pointer and then a Python dictionary that maps variable names like x or y to values like 22 or 33. So when it comes time to look up a variable in the environment, we check and see if the variable name is in the dictionary. That's the oneth component of this tuple. And if it is, we just return it. So there are 3 cases. One possibility is we have a value for the variable. Another possibility is we are the global environment-- our parent pointer is None--so if we don't have it, no one does. We'll just return None. There is no value. Otherwise, we call ourselves recursively and look up this same variable in our parent environment. So these lines represent the correct code, but let's say I make a mistake and I do the following implementation. When it comes time to look up a variable in the environment, if it's in my environment, I give you the answer. Otherwise, I return None. I never ask the parent. We know this is a bug because I'm making a big deal about it, but it's easy to make mistakes when you're writing the code on your own. Let's remember this mistake that I'm not going to look in my parent frame. Let's go through this program and get a feeling for what it should be in our mind. A is 1, and we call mistletoe with 5, so baldr has the value 5. Now I assign it, we look up the old value, 5 + 1 is 6, so now baldr is 6. A gets a + 2, so 1 + 2 is 3, so our variables are 6 and 3. Baldr gets 6 + 3, so baldr is 9. So the answer should be 9. However, with the bug we're going to get an error because at some point we'll try to look up this variable a, and it won't be in our current environment frame. Current environment frame only has baldr. And instead of looking it up in our parent frame, we'll just return None and then we'll try to add None to numbers and we'll get the wrong result. We will be super sad. Baldr was a god in Norse mythology-- so beautiful, so perfect that as a child his mother asked all of the other things in the world to promise not to hurt him. That's quite the protection deal. But she forgot to ask mistletoe, so everything in the world bounced off Baldr except for mistletoe. And in one of the stories in Norse mythology--it's variously told different ways-- Loki, the trickster god, convinced another god to throw mistletoe at Baldr. Actually, a common element in the story is that they were having fun by chucking things at him--throwing rocks. They'd just bounce off or whatnot. That's a little morbid, but I guess if you're invulnerable it could be fun. The person being asked to throw didn't understand the situation, threw the mistletoe at Baldr, killing Baldr--very sad. In fact, Baldr is sometimes compared and contrasted to Achilles in Greek mythology, who famously was invulnerable on all parts of his body except the heel. So anyway, this program should print 9, but instead it's going to raise an error. Let's say we don't know where the bug is. We don't know it's in environment lookup. What can we do to refine this test case so that it more closely points to exactly what's going on? A common approach is actually just to comment out lines in your test case and see if it still breaks. For example, if I comment out these 3 lines in my test case so that mistletoe just returns baldr, we expect to write 5, and we will. So now we know the bug is triggered or the problem lies in 1 of these 3 lines. This is sometimes called fault localization because we're trying to zoom in on--localize--where the problem is. So here's the quiz question for you to give you a little more practice with this sort of advanced testing and debugging. We've got these 4 boxes here. Each one corresponds to a single line. Which of these lines could I remove, comment out 1 at a time, and still see the exception? I know that if we remove all of them, we don't see the exception. So what I want to know is, which of these lines are essential to the bug? Which of these lines really show off the bug? Starting from the bottom, if I remove the last line, we never actually call mistletoe, so our program just declares a variable, declares a function, and then exits, so we don't see the exception. So we can't remove this line. Let's take a look up here. What if I comment out baldr is baldr + 1? Well, with our bug in environment lookup, this line a gets a + 2 will still cause us to die. So we can remove baldr is baldr + 1 and still see the exception. How about this one? If I remove a is a + 2, we'll still see the exception down here in baldr is baldr + a. We'll look up the value of a and not find it. So I can remove that line. Similarly, if I remove this third line, we can still die on line 2. So now, potentially, we have a lot of information available to us. We know that we need to make this call, we know that these 3 lines are important, and in a more fully formed integrated development environment or interpreter like the Python interpreter, we'd get an exception backtrace that would point us to this line or, if we've commented out that line, point us to the next one. So with all of this information, we get a better feel for what's actually required. Now that you've gotten a bit of a taste for this, let's check in with someone who toils in the trenches of the real world. I'm here at Mozilla with Steve Fink, and one of the topics that we cover in class is debugging or testing-- making small, convenient test cases that are going to lead us to a bug or a defect in our program. That's tricky even for small classroom examples. It can be really difficult in the real world. Steve, have you run into problems like this in your job? Sure, and in fact right now I'm dealing with a particular test program that went to a great deal of effort to kind of re-implement the algorithm that it's testing, which is great in terms of comparing the C++ implementation and this JavaScript test program and giving you a yes/no answer-- it works/it doesn't work. But if you actually do have a bug, it can be a bit of a pain tracking it down just because, okay, you have a failure somewhere in the test; now you have to figure out what the test program is actually doing to figure out why it made the particular invocations into the C++ engine that resulted in the behavior that it's actually testing. So in many cases, it's actually easier just to have a brain dead, simple series of call this, call this, call this, call this rather than for each of these items call this if this is true and expect this output if-- This is where the re-implementation of the algorithm comes. Let me give a specific example. This was a test of typed array code, and if you access outside of the bounds of a typed array, then it should give you a range error. An exception. Yeah, an exception, which of type range error. And so this test program just went through an array of different possible inputs and then said, "Well, based on this logic, if this index is higher than this number, "then expect range error; otherwise, expect this value that it pulled out of the array." So the actual test invocation right there is array element i should be retrieved from this typed array, and then you should get the result based on element j of this array. And it turns out, no, I didn't throw the right error. There was a problem. But figuring out, "Okay, so what exact element were you looking for "and what did you actually expect to find based on this other array?" was very indirect, very difficult. It would have been easier if it was just a dumb, simple series of statements saying, "Pull this element out, expect this error. Pull this element out, expect this value." And in fact, that's kind of what I plan to do is instrument the test case itself to generate a series of silly, stupid linear statements and generate a new test case out of that and then throw away the original because as clever and as easy to modify as it is, it's not actually helpful when you're trying to track down a particular bug. It's an excellent point. In one of the things we cover in class you'll notice that in class most of our test cases are relatively small and simple. And this is good advice. Sometimes it's better to have 2 test cases--1 for each feature-- than to try to combine them together and then have to tease apart an interaction later on. Yeah. It also makes it much easier to do, for example, binary search. You can whack off half of the test file if it is a very simple, straightforward test file. If it's all interrelated, then it's really hard to take off half at a time. Exactly. We'll get a chance to see in class commenting out parts of a test file to see if it still causes an error. In a linear test file or just a sequence of assignments, that's much easier to do than if there's a lot of complicated control flow. One of the cool features of our JavaScript interpreter is that it supports anonymous or nested functions. However, these features can be very hard to test, so let's try it out together. You'll recall this Python example from before where we had a nested function definition of greeter that we returned, and the final output of this program would be "hello" "gracie". I'm going to write this same program in JavaScript. Aside from some minor syntactic differences, the content is the same. We make a variable, greeting, initialize to "hola". Variable greeting is "hola". We're going to define this makegreeter function of 1 argument called greeting, define the makegreeter function of 1 argument called greeting. Then we're going to make this sort of nested function greeter that takes an argument, person, and here the local variable greeter is a function that takes an argument, person. So where in Python we used another def, in JavaScript we're using this function keyword. Argument person is the same. Instead of print we call write or document.write and we return the greeter. Sayhello is a variable of makegreeter("hello"), variable sayhello is the result of calling makegreeter on "hello" and then we do it at the end. So the real exciting part is here. In JavaScript you can use the word function to make a new function anywhere without really giving it a name, although we assigned it to the variable greeter almost immediately. So you can use it at the top level to make a function with a name, or you can use it lower down. See, here we just have function and then we're listing the arguments. We didn't put a name in here. This is sometimes called an anonymous function because it doesn't immediately have a name. So as a quiz, let's add support for those anonymous functions to our JavaScript interpreter. I'll write the first part, you fill in the key details. Anonymous functions are expressions. We know that since they can come on the right-hand side of something like this. Anything on the right-hand side of a var or an assignment statement is an expression. So there are a bunch of different types of expressions-- numbers, strings, binary operators. Let's just handle the function part for now. So as a running example, let's say we have a function of 2 variables, x and y, that's going to return their sum. The abstract syntax tree we get for that will have function in this sort of identifier position telling us what this sort of node is, then it will have a list of the parameters, and then it will have the body list of statements. And what I'd like you to do for this quiz is fill in these 4 blanks. We want to return a particular value-- value corresponding to a function. This is going to require you to think back to how we treated function definitions and function calls earlier in our interpreter. But here's a hint: A function was a for tuple containing the word function at the beginning and then also listing in some order the body, the environment, and the parameters. Fill it in. The first part of our return value is just the word function. This is to separate it from a number like 3 or 4 and to allow us to tell if the user mistakenly tries to call something that's not a function later. We then list the parameters which we got right from the abstract syntax tree, the body of the function, which we also got right from the abstract syntax tree, and the environment in which it was defined--this one, env. And we're passing in env here instead of some global environment or whatnot and this is what's going to allow local functions to see local variables. This is why things like makegreeter work. They can refer back to variables that were currently in scope when they were defined. Many of you may notice a striking similarity between this and our previous code for handling function declarations. In fact, our previous code just had 1 more step where we added this value to the environment. For an anonymous function, we don't add it to the environment unless the user assigns it. But this code should look really, really familiar. We have something almost exactly like it for handling functions at the top level as JavaScript elements. Well that time we got it right but suppose we made a mistake. Suppose we had access to the global environment so this is actually defined, and instead of passing in the current environment, whenever we make a function, we're going to pass in the global environment instead. This is a bug. This is not correct. Let's try to reason forward about what might go wrong, and how we could see this bug or how it would behave. I'm going to write some statements and you're going to tell me which ones are true. Here I've written four claims, and in this multiple choice test I'd like you to note which ones are true. The first, no test input with only one function can show the bug. The second, we need at least three variables in the global environment to see the bug. Here--see the bug, show the bug, expose the bug--all mean the same thing. We can show the bug with only two functions, each of which is separately declared at the top level, and finally, we can show the bug with one function nested inside another function. Well, let's take a look. The first one is actually true. With only one function in our program, we'll have our top level global environment and then the environment for our new function, and we're making its declaration, or its parent pointer, go back here to the global environment. That's where it should go, but that's also where the bug is putting it, so we won't be able to tell the difference. Now if this weren't an anonymous function but were instead a recursive function like factorial, we might be able to see the bug with only one. But with just one anonymous function, we can't quite see the bug. We need at least three variables in the global environment to see the bug. This isn't really true. One variable in the global environment--one local variable-- maybe even no variables in the global environment--should be totally fine. The only time the parent pointer matters is when we're looking up a variable in a child environment and we don't find it locally. So we should be able to construct a test case that has just one such variable, like the "a" in the Balder example we did earlier. We won't need three. We can show the bug with only two functions, each separately declared at the top level. If I have another function, function two, declared at the top level, its parent pointer should point back to global and because of the bug, it will point back to global anyway. So this won't let us see the bug. We can show the bug with one function nested inside another. This is the plan. Let's say we have function one with function two nested inside of it. The parent pointer for function one, or this pointer, should go back to global. The bug will make it go back to global. Function two should point back to function one but the bug will make it point to global. So all I have to do is put some variable "a" in here, and have function two refer to it. Then in my test case we won't find it and we'll get an error, but in the real world we should find it and that will allow me to pin down the defect. So here's that javascript code from before, with the anonymous function assigned to "greeter" nested inside "makegreeter." I'm going to draw the environment much more formally. In our global environment, "greeting" points to "hola." "Makegreeter" is a function with three other components that I'm not showing right now, and "sayhello"--well, to figure out its value, I'm going to have to call "makegreeter" on "hello." Whenever I call a function, I make a new frame with just enough room for all of the formal parameters. Then inside this frame I'm adding a new local variable, "greeter," which is a function with one parameter. And even with our environment bug, even with the bug that we've been considering, this is still going to point back to the global frame. So this value of "greeter"--this function defined here--will be copied back. And these things I've marked in green have the same value. This was the return value of "makegreeter," so it's what "sayhello" currently has. And now we're going to call "sayhello" on "gracie." So we're going to make a new frame where a person points to "gracie" pointing back to the global frame. And here's the question for you-- one of these arrows, or possibly both, is incorrect, if we have the bug we've currently been talking about. We have the bug. Check the arrow--check the parent pointer edge that would be different if we didn't have the bug. If we fixed the bug, how does the world change--quiz? The edge that should be different is the one on the left. Let's trace through it to see why. We know when we run this program that it should say "hello gracie." When we're running a function, our official rule is you take the function body--here's the function body-- "right greeting" plus "person"--and you evaluate it in that frame-- "right greeting" plus "spaces" plus "person." We go to look up "greeting." Do we have it? No. Let's go ask our parents. Oh, our parents do have a greeting--it's "hola." Look up "person"--do we have it? Yes, it's "gracie." With the bug, this program will mistakenly print out "hola gracie." That's not what we wanted. That doesn't match the semantics. If instead I erase this edge and draw it correctly, having this function point back to the environment in which it was defined, now when I try to write "greeting" plus "person," do I have "greeting?" No. How about my parent? Oh, my parent does, and it's "hello." How about "person," "gracie?" We'll write out "hello gracie." So with the bug we get "hola gracie." Without the bug we get, correctly, "hello gracie." So we've just had a chance to learn a bit about debugging, which is made up of testing and then trying to localize or isolate the fault and then fixing it. I actually had a chance to work at a lovely company in Santa Barbara, Green Hills Software, where my job was to do just that for just the sort of interpreter that you're writing. Every day I'd come in and there would be a stack of input programs on my desk, and our interpreter--or our compiler--was currently computing the wrong answers for them. And I would do this sort of hypothesis testing that we've been considering here. I'd say, oh; what if the bug is in the top half of the program? Then I can comment out the bottom half, and I should still see the bug. Oh, that didn't work. Maybe I'll hypothesize now that the bug is in the bottom half of the program. I'll comment out the top half and we'll still see the bug. And I could refine my way down--maybe it's in the top fourth, maybe it's in the top eighth, until eventually I had a very small input that still showed the bug. And then it was easy for me to localize the fault and fix it. The process was relatively lockstep, so lockstep in fact that a few years ago a researcher, Andreas Zeller, published a technique for automating it. His approach, called Delta Debugging, makes it systematic-- does this systematic hypothesis testing by dividing a program input in half and half again until it finds the smallest input that still reproduces the bug. In fact, looking back on it now, the job that I had is almost completely automated. When you run into defects or bugs in your code, and you probably will-- I certainly do all the time--I want you to apply that same level of formal reasoning. Think about where the bug might be. Make a test case that probes or falsifies that hypothesis. Localize the defect. And then move in to fix it. So now that we have a better understanding of how to check that our program is correct and test it to gain confidence, let's talk about optimization--making our program faster. Over on the right, I've doodled the tortoise and the hare. You can tell this is a hare and not, let's say, a mutated donkey because of the label; those labels are always correct. This bears reference to one of Aesop's fables--a Greek writer from times long ago-- in which the hare, although in some sense faster was relatively lazy and was eventually beaten out by the tortoise. In the real world, performance matters. We've heard, for example, that if you don't render a web page in 6 seconds or less shoppers will go to another website. For the vast majority of applications, things in this class: airline autopilots, banking transactions, things related to energy or power or transportation, performance matters less than correctness. Job one--test it, debug it, get the right answer. Job two--make it fast. In this sense, optimization refers to improving the performance of our code. Can we make our web browser take less time to render the same web pages? A lot of modern interpreters, from JavaScript interpreters to Python, use a technique known as Just-in-Time Improvement, which is sometimes abbreviated as JIT, to fix up or improve code right before they run it so that it's faster but gets the same output. So our basic optimization idea is going to be to replace the input webpage--the HTML or JavaScript fragment-- with one that takes less time to process but has--and this is super critical-- I cannot emphasize this enough--exactly the same meaning. We must produce the same output with optimizations on and with optimizations off, aside from the time it takes. We absolutely can't change the meaning. We have to be correct. In that sense, optimization for programming languages is somewhat similar to editing for conciseness in natural languages. If you say something redundant and it's possible to remove that redundancy without changing the meaning, you can strike it from written text. We're going to do the same thing with optimization. Here I've written JavaScript code to compute the factorial function, and this code is correct. Now, of course, as soon as I say that there's going to be one minor typo, but let's just assert that this code is correct. It actually computes factorial. But it's a little slower than it needs to be. You may have noticed that I wrote 1 times N times factorial of N minus 1 instead of just N times factorial of N minus 1. This is correct--multiplying something by 1 doesn't change its meaning-- but it's slower than necessary. If we're talking about arithmetic, whenever you see 1 times N, you could just replace it by N, and now you're saving time because we're removing notes from our abstract syntax tree. This means it takes less time to do our recursive walk and interpret it, and we have fewer multiplications. And multiplication is an arithmetic operation that this CPU has to perform; it takes some amount of time. In fact, especially in something like factorial, if I'm asking for the factorial of 10, we're going to call this function a large number of times. So even though it may not seem like I'm saving much, I save it every time we're in this loop. And this is why I suggested earlier that performing such a simplification or optimization is like editing someone's writing so that it's more concise. If I just edit that part away, this factorial is still correct; it just takes a little less time. [Which of the following could be simplified or removed without changing the result?] So you may already have a good intuition for these sorts of optimizations. Let me give you a chance to show that off. So here I've written a function in JavaScript called Plato's Republic. It's a function of 2 variables: A and B. A gets A times 1, B gets B + 0, A gets A + B, B gets B + 2, and then finally we return A. There are 5 possible statements here. Which of them can be simplified or removed without changing the result? And here I really want you to mostly focus on removing, and note that this is a little trickier than it looks. So give it some thought. [Which of the following could be simplified or removed without changing the result] [function platos_republic(a,b) {] Let's go through the lines 1 at a time. A times 1. This is the same as A=A because anything times 1 is just itself. So this assigns the new value of A to be equal to the old value of A. So this is actually equal to just doing nothing. So I could totally remove this line without changing the result of Plato's Republic. B gets B+0. This is the same sort of theory. This reduces to B gets B because adding 0 to something doesn't change its value. So I could just drop this statement entirely. A=A+B. That looks like something important might be going on. Let's hold on to that for a bit. In fact, let's go down here and see. Eventually we're returning A. I can't remove this line because we actually need to return A to have the same value. And if I'm going to return A, then I need to keep this line-- A gets A+B--so that I know what the right value of A is supposed to be. But--and this is the potentially tricky bit-- I can remove B=B+2. Even though there's no arithmetic simplification that I can perform, I just don't need the line! B isn't part of the return value. No one else can ever see it. We throw it away after this point. Formally in computer science we call this "dead code". It has no effect on the rest of the program. So I could drop these 3 lines, and all that Plato's Republic is really doing is summing its 2 variables together, returning the result. Plato's Republic is a dialogue written in about 380 BCE that talks about the definition of justice. The phrase "who watches the watchers" often comes up in discussions or criticisms of Plato's Republic. [How to implement optimizations] Okay, well that sounds great, so far. We have an idea of when we can possibly remove things based on mathematical truths. But how do we actually implement them in our JavaScript interpretor--in our web browser? Well, step 1 is to think of a big library of optimizations. For example, X times 1 is always equal to X, and X+0 is always equal to X. So if I see one of these expressions, I could just replace it with the simpler one on the right. And I'm going to do that by transforming the parse tree directly. But before we talk about transforming the parse tree, we're going to need to be certain about what sort of optimizations we want. Remember, we can only do optimizations that don't change the meaning of the program. We have to get the same answer, just in less time. So here I'm going to have you take a look and evaluate or tell me about some candidate optimizations. I want you to fill in each of these 4 blanks. [X1==_] [X0==_] [X*2==_] [X/X==_] Write the simplest expression you can to make the equality true. So can I replace X times 1 with something simple that fits in this box? Write the simplest expression you can that retains the meaning in all cases. This is a little trickier than it looks, so try it out. [QUIZ Fill in the blanks. Write the simplest expression to make the equality true.] Well, X times 1 is just equal to X regardless of the value of X. If X was 55, 55 times 1 is 55. If X was 0, 0 times 1 is 0. If X was negative 2, negative 2 times 1 is negative 2. Excellent. X times 0 is always equal to 0. This is one of those mathematical identities. 55 times 0 is 0. Negative 1 times 0 is 0. 0 times 0 is 0. It always works out. X times 2 can be rewritten as X + X. [strength reduction] This may not immediately seem like a useful optimization, Formally, we call it "strength reduction" in the sense that multiplication was a stronger, harder-to-compute operation than addition. On some CPUs or on some hardware platforms, it takes less time, fewer cycles, less energy to compute addition than it does to do multiplication. So even though both of these have 2 operands and they are both binary operators, this 1 might be faster on many platforms. Finally, we get to the last one and the one that probably is the most controversial: X divided by X cannot safely be replaced with anything smaller. You'd REALLY like it to just be 1. 1 is SO tempting! 5 divided by 5 equals 1. Negative 2 divided by negative 2 equals 1. Seems like it's always 1, except for this 1 corner case: 0 divided by 0 does not equal 1. [exception] 0 divided by 0 raises an exception. And the golden rule of Optimization Club is: "Always keep the same semantics." If there's a possibility that on some inputs we could raise an exception, we can't rule out that exception with our optimization. You'd think, "Why would anyone want to divide by 0?" You can't change the meaning of the program. You have to keep it exactly the same when you're doing optimizations. So 1 is very tempting, but it's too aggressive. There's a single case where it's wrong, so we can't use it for optimization. So one of the topics that we cover in this class is optimization, making a program faster but having it compute the same result, and I like optimization a lot. It is a lot of fun to think of cool ways to speed up the code, but it turns out that often getting the right answer or maintaining the code later, having the code be well documented, making it easy to debug the code, these things might all trump optimization. Steve, have you seen anything like that in Mozilla or other projects you've worked on? [Steve] Constantly. With the SpiderMonkey JavaScript engine these days, I kind of feel like we spend half of our time removing old optimizations to make way for refactoring; future engines. I think we've been hit particularly hard because we switched our JIT engines several times at this point. TraceMonkey was our original optimization-- well, our original JIT engine, which had a particular style of optimization that it covered, and we have since entirely removed the TraceMonkey JIT engine and replaced it with JägerMonkey, which is kind of the next generation JIT engine, except now, it's the previous generation JIT engine itself, and it is slated to be replaced by IonMonkey, we like monkeys. I was going to there is referring monkey theme. [Steve] Yes. And it turns out that the sorts of optimizations that are really helpful for a tracing style JIT are really obnoxious when you get into a different style of JIT, because they just get in the way, and it prevents you from--you know-- making a lot of code simplifications that makes it straight forward to do a JIT in a different style, and so there are many, many different optimizations that we've had to just rip out wholesale, and unfortunately, it's at least as much work to remove some of these--some of these optimizations as it was to make them in the first place, and really anytime you do an optimization, you have to be very aware of the cost of that optimization. You may be saving some runtime, but you are adding complexity to everybody who comes by and tries to read and understand that code. You are preventing some refactoring, some restructurings of that code because it would-- it would break the optimization--you know-- the optimization was made with certain assumptions, that's almost the definition of an optimization is that if we assume certain things, then we don't have to do some of these operations, and that's the way to make things faster is to not do some of the things that you were previously doing. And so there are all kinds of--you know-- hidden costs to an optimization, and it can actually be very damaging to put certain optimizations in the code because they're going to prevent other optimizations, they are going to prevent--you know-- simplifications of the code, they are going to prevent changing the semantics of what you've implemented because the optimization is based on certain assumptions that you may want to change in the future, and so we sent a lot of time--you know-- trying to find the right balance today, which is actually different from the balance yesterday, and so even if a previous optimization made total sense in the past world, it may actually get in the way in the current world. So yeah, we see a lot of this. Excellent, now you mentioned something that caught my ear, and I wonder if I might put you on the spot with a bit of a surprise question. You mentioned that you're looking over old code and refactoring it, and I'm just wondering throughout your average day, let's say you spend some amount of time reading code and some amount of time writing new code. What's that ratio or how many hours is fixing bugs and code, looking over old code, and how much is writing new code? [Steve] It varies a lot from day to day. Some days are actually spent 100% writing new code, and those days are happy days and rare days. The vast majority really is looking at existing code, sometimes code that I wrote, much more often code that other people wrote, and here at Mozilla, we have a rule that every line of code that goes into the tree must be reviewed by another person so-you know--in terms of you have a sealing of 50% of time is spent on new code because every line of new code is going to be viewed by at least one other person, and often you'll go through multiple rounds of review, and so--you know--multiple people or the same person are looking at that line of code several times, but even if you're going to write new code, you always have to understand the context in which you're placing that code, and so you really have to understand what comes before, and you will spend much, much of your time doing that, far more of your time doing that than kind of going into a green field and putting something brand new in place. And this idea that you have to understand the context in which your adding code is one of the reasons why understanding the meanings of programs, their semantics, is so important. So how are we going to fit optimization into our JavaScript interpreter? The basic plan is to change the parse tree before interpreting. That way we'll save time, especially if the optimization we made was in the inside recursive call of Fibonacci or factorial or something like that. So recall our general plan, the outline of our interpreter, we start with program text, which is a string, and we use lexical analysis to break it up into tokens, or important words. This is implemented with regular expressions. Then we use parsing based on context-free grammars and dynamic programming to check and see if those tokens are in the right order. Are they valid syntactically? Do they form a sentence? If so, we end up with a parse tree, also called an abstract syntax tree. And now--here's the new part--we're going to do optimization, which will also yield a parse tree but hopefully a simpler one. If all else fails, do no optimizations and return the same one. Then we do our interpreting, and that gives us the meaning of the program, the final result. So we're going to fit optimization in after parsing but before interpreting. Optimization is always optional. You don't have to do it, typically, unless you're in some sort of company where timing really, really matters, like, say, a car's anti-lock brake system, where you might have to respond within a certain number of milliseconds. But for the vast majority of applications, optimization is optional, so often we do it last. In fact, let me show you a simple Python example of how a JavaScript optimizer might go. For now I'll just optimize expression trees. We'll do these arithmetic optimizations we've been thinking of, and for now I'm going to focus on expressions that have expression type "binop"-- binary operator. For example, maybe it's something like A times 1 and I just want to replace that with A. Well, here's a real simple way to do that. I'll just check and see if the operation is star, and I'll check and see if the right-hand side is literally the number 1. If it is, then I can just return A; otherwise I'll return the original tree unchanged. Maybe it was something more complicated like 5 times 3 or 5 times X that we couldn't reason about. We could certainly put in more optimizations here, but now we have at least one. And the basic plan is right before we interpret an expression, we call optimize on it. Just to show this pictorially, let's say our input is 5 times 1. We're just going to replace that with 5. In our Python interpreter, that abstract syntax tree would show up as nested tuples: binop involving multiplication--oh, that's not exactly the order we used. There we go. A binop where the left child is a 5, there's some multiplication, and then the right child is 1. And if these two parts match a pattern we've already established, then we'll just hoist this part out and return it unchanged. So we've gone from 5 times 1 to just 5 by looking at our Python abstract syntax tree, checking to make sure the optimization is legal-- an optimization is only legal if it doesn't change the semantics of the program, doesn't change the meaning of the result-- and then once it is legal, we just replace the tree with a simpler tree. The way I've written it, we're officially returning a new tree. Potentially, if we wanted it to be a little more efficient, we could change it in place, but returning a new copy of the tree is fine for us. So let's go back to our simple optimizer. Currently, it only handles A times 1. The quiz for you is to add in support right about here for A times 0 and A + 0. Let's walk through a possibility together. Let's handle A times 0. In such a case, we want to return B or the number 0, whichever you prefer. Anything times 0 is 0. [return tree] And the other thing I am supposed to handle is A + 0, at which point I just return A. I could have been more complicated potentially and changed the if condition up here so that we're returning A in only 1 place, but for optimizations, readability is more important. because we really want to make sure we're getting the right answer. So we've added in support for 2 new optimizations. And presumably--now you can imagine how if we had a bunch of these we could just write them all out here, or maybe we could have a slightly more concise system for checking patterns and replacing them. [But does it work? Which of the following will our optimizer do?] So let's see how well you really understand the optimizer we just wrote. Here I've written out 5 candidate optimizations-- A times 1 gets replaced by A--and what I'd like you to do in this multiple-multiple choice quiz is check all of the ones that our optimizer, as we just wrote it, will perform. [QUIZ But does it work? Which of the following will our optimizer do?] We'll definitely replace A times 1 with A. We wrote the code for that. And we'll definitely replace A times [0] with 0. This next one--0 times A--looks super tempting but if you switch back for just a moment, you'll notice that our optimizer is not symmetric. We're only checking for the B--the right position-- to be the constant number. That means we will not perform this optimization. Similarly, A times 1 times 1 is going to depend a bit on what the input abstract syntax tree is, but at the end of the day, this will actually produce something like A times 1. We apply the rule once, but since we don't call ourselves recursively we're not going to notice that 1 times 1 is 1, and then also A times 1 is A. Currently, our optimizer can only do 1 optimization. Similarly, here we'd really like to reason that 5 times 0 is 0 so A + 0 should be A, but our optimizer only checks 1 thing at the top level so it won't notice that yet. Let's take a look at that last example in a little more detail. What we would really like to do is start at the top and call ourselves recursively to optimize both children. Once I figure out that 5 times 0 can be replaced by 0 and A can only be replaced by A I rebuild my abstract syntax tree and now I'm in a great position to rewrite this to be just A. So there's going to be Step 1: recursive calls. Step 2: Look for patterns. And then, finally, Step 3: We are done. In order for this to work out, our optimizer has to be recursive just like our evaluator and our interpretor. This is not a coincidence. Recursion--iteration--is really central to computer science. It's fundamental. All right, so for our final quiz in this unit, I want you to fix up this code so that it handles--it optimizes-- A plus 5 times 0 recursively. This change may be hard to think about, but it's relatively simple to implement. Our procedure was named "optimize." So now, instead of having A be just tree 1 and B be tree 3, we're going to call ourselves recursively on our subchildren, and then, only once they've both been optimized do we check for the pattern. This will correctly handle A plus 5 times 0. I may need 1 more return tree at the bottom, but that was assumed. So it was as simple as adding 2 recursive calls before we check for the pattern. So now our optimizer will correctly change this to ethos times zero plus zero, that's going to be zero, pathos times 1 times 1, that'll be pathos, and logus times 2 plus 5 will be logus times 2 plus 5, and you might have already spotted places where we could add other optimizations. For example, wouldn't it be nice to just replace this with 7 right now. So there's plenty of room for creativity in optimization. So we could do better with optimization, but it takes creativity because we need to know what we want to change and also when it's legal. So we've touched on Optimization-- the notion that you could take part of one Abstract Syntax Tree and replace it with something else, in order to make the program faster or use less power. The cardinal rule of Optimization was: You can't change the meaning of the program. You have to respect the formal semantics or at least, that's what I've always told you. But what if we break that law? What if we want to change the meaning of a program? For example, what if your program currently has a bug and I want to change it so that the bug isn't there? What if I want to fix your program-- Optimize it so that it is more correct, instead of being faster? I've worked on just this sort of research project. We call it Evolutionary Program Repair. It involves using genetic algorithms or genetic programming-- computational analogs of Real World biological processes, like Crossover and Mutation. We maintain a population of candidate programs that may fix your bug-- just like you can imagine a population of animals on an island and then survival of the fittest allows some of them to stay, and the rest to die out. If you're interested in this sort of research-- I affectionately call it Building Skynet because we're building a program that builds other programs-- there should be links below. But one of the things that I want you to take away is that the concepts that we're covering in this class-- notions like Abstract Syntax Trees or replacing one expression with another-- can be used in different contexts, to great effect. It just requires creativity to know when you can bend the rules without breaking them. That creativity is the essence of engineering. All right; let's wrap this up. Over the entire course, we've seen lexing, parsing; we just saw optimizing. We've seen interpreting. And just in case anything goes wrong, we know how to do debugging. Lexing was based on regular expressions. They specify sets of strings, and they can be implemented under the hood with finite state machines. Parsing uses context-free grammars, which can capture behavior like balanced parentheses that regular expressions can't. And we saw how to implement those with dynamic programming, that is, writing ourselves little memos in a chart, and parse states. Optimizations are great; they make the programs simpler and conserve some important resource like time or power or heat dissipation. But they're only valid if they retain the meaning. In general, interpreting refers to walking the abstract syntax tree recursively and computing the final value. In our particular web browser, our HTML interpreter calls the JavaScript interpreter, and our HTML interpreter calls the graphics interpreter. And in debugging and testing we can gain confidence that our program adheres to its specification by thinking very hard about which parts of the input or which parts of the program might be wrong and carefully crafting them, paying attention to all the information we have available. In the homework or the class final projects, you'll finish the browser, and unit 7 will be review for the final exam. Welcome back. We're about to start the final unit in this course. This time we're mostly going to focus on review and some practice problems to get you ready for the exam or at least to get you in the mood for the exam. But there may also be just a little bit of fun. You may get the chance to hear someone who is not Wes Weimer talking. I know, I know. Someone with real voice inflection? Be still, your beating heart. But before we get going with practice problems, let us make The List, a high level summary of everything you've learned thus far. We started off by introducing the concept of a language as a set of strings. Regular expressions, finite state machines, formal grammars-- these all denote or accept or correspond to sets of strings. In fact, the set of all valid JavaScript programs is just a set of really big strings. One of the first tools we introduced was regular expressions, which are just a concise notation for specifying some sets of strings. Those sets of strings are called regular languages. An incredible surprise move: regular expressions denote regular languages. And we learned a bunch of regular expressions--+, *, disjunctive choice, ranges of letters, 0 or 1 copies--and we ended up using these to specify tokens. More on that in just a bit. Then we learned about finite state machines, which are a cool way to draw regular expressions and also, it turns out, a way that we implement them under the hood. That's how Python actually does it. Here I've shown a finite state machine for ab*. Possible to have ambiguity or epsilon transitions in a finite state machine. That makes a finite state machine nondeterministic, because if you're trying to simulate it, you don't know exactly where to go at any given point. It turns out, however, that is not a problem at all. We can convert nondeterministic finite state machines down into deterministic finite state machines. They may get a little bit bigger, but it will totally work. Then we moved on to the more powerful context-free grammars, which are a concise notation for specifying some sets of strings. Wait! I thought that's what regular expressions were. Actually, they're both just concise notations for specifying possibly infinite sets of strings. And your typical context-free grammar is just a set of rewrite rules with a nonterminal symbol on the left, an arrow, and then some terminals and nonterminals on the right. Terminals are the same thing as tokens. They're the actual input that we're trying to match. There are some cool things that we can do with context-free grammars, like matching balanced parentheses, that we could not do-- we're certain we cannot do it, it is impossible to do correctly--with regular expressions. We often want to check and see if a string is in the language of a context-free grammar or matches that context-free grammar, can be derived or generated by that context-free grammar-- these are all the same question--and one way to do that was memoization, which for many years I always wanted to call "memorization," but it's just not. It's also called dynamic programming, which sounds really exciting, but in practice basically builds charts where we write down previously computed results so that we don't have to compute them again. This is called being lazy, and it's a phenomenal virtue when you're writing programs. We can combine context-free grammars and, potentially, memoization together to get parsing, which is the process of determining if a list of tokens is in the language of a context-free grammar. If so, we produce a parse tree. Where did we get that list of tokens, you ask? The process of lexing breaks a big string, like a web page, up into a list of tokens or important words. The tokens are specified using regular expressions, which means that a lexer is implemented using finite state machines. We do lexing first and then parsing. I have written them out of order to shake things up. Once we have our parse tree, we're getting closer and closer to the meaning of a program. One aspect of program semantics or program meanings is the notion of types--that we can classify objects or values like 1, 2, and 3 into groups and say, "Those are all numbers." So a type is just a set of values and some associated operations that you can apply. So the values might be things like all numbers, all strings, or all lists, and the operations might be things like + - / or length. I can apply length to a string or a list but not a number. I can add numbers, strings, and lists, but it means something different every time. I can divide numbers, but I can't really divide strings or lists, at least not using this division operator. Types are our first step along the road to meaning, and in computer science we formally call that semantics. By the way, if you've been wondering the whole time, semantics is a tricky word that essentially always ends in an S, even when we're using it in sort of a singular fashion. Semantics of a program: its meaning, what does it compute. A program may have type errors, like if you try to divide a string by an integer, or it may have any number of other exceptions. But in the general case, it produces a value. This means that we have computed something. That was the result. That's the meaning of our program, just like a sentence in English or French or Cantonese might have a meaning. Once we have a grip on semantics, we can introduce optimization, where we replace one program with another or, conceptually, one part of a program with another as long as the whole thing has the same semantics. This is the critical rule of optimization. You can't change the meaning of the program. If you can't change the meaning, what can you change? Typically, the new code you've brought in uses fewer resources-- less time, less memory, consumes less power-- and we've seen a bunch of examples of these. x * 1 could be replaced with just x, but x / x cannot be replaced with 1 because in the single case where x is 0, this changes the meaning of the program. After optimizing, or not--you never have to optimize--we can move on to interpretation. This is the fun part. We recursively walk over the parse tree, and the meaning of a program, the final result, the picture we should display for a web page, the result of a computation in a financial program, is computed from the meanings of its subexpressions. So if I'm in a state or environment where a maps to 5, I can compute the meaning of this abstract syntax tree expression. Well, we have times and plus. I'll go down here and figure out what a is. a is 5, 3 is 3. I multiply them together and I get 15. Over here, 1 and 2. I add them together and I get 3. The whole thing I get 18. Walk down the tree on both sides, and only as I'm coming back up do I compute the values. Typically, to perform interpretation we have to track state, like the values of variables which may change, in environments. And environments are often chained together, especially as you make function calls. Finally, we put all of that together to build our web browser. We followed a particular architecture. You could imagine doing another one, but this is the one we used for this class. We start by lexing and parsing HTML, treating any embedded JavaScript as a special token. Our HTML interpreter walks over the HTML parse tree, and whenever it gets to this special JavaScript token, it calls the JavaScript interpreter, which just returns a string. We got the string from a bunch of calls to document.write(). The HTML interpreter gathers up all the words--words in HTML or words computed by JavaScript--and just calls the graphics library to display them. Wow! And then we're done. That was a highlighted summary of a lot of the key concepts in the course, especially if you're taking notes at home. And now we're going to do a bunch of review questions. Many of them should seem very easy. That's intentional. We just want to go over the material and get it fresh in your mind, and the expectation is that you'll do harder studying on your own. Mastering the material involves personal responsibility. You're going to have to put extra time into it at the end. All right. First quiz: regular expressions. I have written a Python format regular expression here at the top of the slide, and what I'd like you to do is indicate which of the strings listed here match it exactly. Multiple multiple choice. List all that are correct. We see that this regular expression starts with an unmodified "a". So we can rule out immediately any of these strings at the bottom that start with a "b". They're not going to match it. The first letter has to be an "a". So we have an "a," and then remember that open parenthesis, question mark, colon, and close parenthesis are a Python syntax loosely just meaning open and close parentheses. So we've got an "a" followed by zero or more copies of "a? b*". "B*" can be no b's, and this " * " can be once, so this could be "a?" or just "aa," so yeah, we can match that. How about this, "aab"? Same strategy as before except that we make this "b*" be one "b". We can match this "abab"--"a", "b." We'll take one of these and then we'll repeat this whole group once. This time, we'll take the "a" that we really want and one more "b". Yeah, we can match this. "Abbabb", "a". We'll skip over this optional "a?". We will have this "*" be twice. We'll repeat the whole thing. We'll include the optional "a?". We will have this "*" be twice and now we're done. Yeah, we can match that. And then finally here, just like the previous string, but we want one more "a" at the end. Well, we'll take the outermost loop one more time. Take this. Not take the star. All right, next we have a bit of a trick question--I'm importing the regular expression library and then I'm calling "re.findall" on the regular expression [a-z] [a-z]+, and the haystack string "a quick brown". And that's going to return a list, and in these blanks, I want you to write the elements of that list. One of the strings inside "a quick brown" that are matched by this regular expression. Well, I did say this was a bit of a trick. If you look carefully at this regular expression, it requires words that are at least two letters long, a through z followed by one or more a through z at least two. So, we actually don't match a. We match quick and brown and then there's nothing in here. We just return a two-element list. We have questions like this, because I want you to be confident in your own answer and not necessarily trust the structure of the problem that's given to you. This particular phrase a quick brown comes from the sentence, "A quick brown fox jumps over the lazy dog," used commonly because it typically involves all of the letters in the English alphabet giving you a chance to see what each one looks like if you're testing out a font or what not. So here is my quick brown fox, and it's jumping over a lazy dog, and we will say that this sentence labels both of them. All right! This quiz is on finite state machines. I have drawn a super cool one here at the top and then down here at the bottom, I have four candidate regular expressions. What I'd like you to do is note each regular expression that has exactly the same language that accepts exactly the same strings as this finite state machine. That is what I want you to go backwards and find from this finite state machine best regular expression that matches it. Well, for a finite state machine and a regular expression to have the same language, they have to have exactly the same set of strings that they accept. Let's go try some of those out. In this particular regular expression, a is in the accepted set of strings. I need an a, but I could have zero b's and zero c's. However, this finite state machine does not allow us to accept on a single a. There's a string in here that's not up there, so this is not part of the answer. How about this one? Up here we can see that the string a b nothing is in the language of this finite state machine, but it's not in the language of this regular expression. This regular expression requires at least one c. There are no c's up here. This is also a bad call. Let's take a look at the last one in a bit of a leading ordering choice. This regular expression uses disjunction, and one possible choice here is a followed by nothing, followed by nothing, so a is in the language of this regular expression, but we've already seen that a is not accepted by this finite state machine, so this one is not quite correction. However, this one is. Now, this takes a little bit of reasoning. We can certainly start with an a. Then we have at least one b and possibly more. This looks a lot like a b +. Over here, we don't have the a. We just have a b followed by possibly more b's. So this is a lot like b+. I've got two branches--on that's ab+ and one that's just b+. That's an optional a followed by b+. After that point we have as many c's as we want, but possibly zero. That's c*, so yeah. This matches number 3. This time I’ve written a regular expression at the top in Python syntax and I’ve drawn four finite state machines. I would like you to check each finite state machine that accepts exactly the same language as it is regular expression. Let’s analyze them one by one. This requires at least 1C and then you can have zero or more As. This is CA star and we’re suppose to match optional CA star, so this isn’t quite right. A string that’s accepted up here A or even the empty string is not accepted down here. Down here this finite state machine would allow you to do A, C, A, C, A, C, to alternate between them because there is only one state. The regular expression up top does not. Over here this is looking relatively promising; if we have no C's we can have a star that’s pretty good and we can also have an optional C. But here is a string accepted by this first regular expression C, AA that is not accepted by this machine. C and then we would fall off. So this is not a good bat, so either I’m super evil or this last one is the winner and it turns out that the last one is the winner. And essentially up here we have A star and down here we have CA star. When I put these two paths together, I get optional C followed by A star. All right. Our penultimate question on regular expressions. Which of the following sentences are true? Check all that apply. Any regular expression written using + could be rewritten without + but match exactly the same set of strings. There is no regular expression that catches all strings that look like a^n. Remember this exponentiation here means copies so this would be a, aa, aaa. There's no regular expression that gets that whole infinite set. Here, there's no regular expression for a^n b^n, so this would be ab, aabb, aaabbb and then down here every regular expression has an associated finite state machine that recognizes the same strings. Let's go through it. If you had a regular expression like a+, I could rewrite that as aa*, so I never actually need plus. It's just convenient. There is no regular expression for a^n. There is. It is a+, and this recognizes a, aa, aaa, so this is misleading. However, for this one, there is no regular expression for a^n b^n. This is the same as the language of balanced parentheses except we're using a's in b's instead of open and close parenthesis. There is no such regular expression. We need a context-free grammar. Finally, every regular expression has an associated finite state machine that recognizes the same strings--yep--and we saw a little bit of how to do this. This is the Super Hard Quiz of Doom and our last question on finite state machines and regular languages and regular expressions. This requires quite a bit of abstract thinking so don't feel bad if this takes a number of tries. These questions are always, sometimes, and never. I've written out two claims, and what I want you to do is mark this box if the first claim is always true, mark this box if they're sometimes when it's true and sometime when it's false, and this box if it's never true. So here's the first claim. Suppose I have any finite state machine A. You draw it out for me. Can I then make a new finite state machine that accepts strings of the following form? For any string that's in yours, I then get another string that's in yours and I accept their concatenation when I glue them together. This is a little hard to get a feeling for but let's imagine my finite state machine A accepted ba ba ba, that sort of thing. Then I want to make a new finite state machine that accepts ba ba, ba ba, ba ba, doublings of the first finite state machine. Down here, I have a very similar claim but with one bit change. If I have a finite state machine B, can I make a new finite state machine that accepts strings of this form--x concatenated with x where x was a string accepted by B? So if you give me a finite statement machine that only recognizes hello, can I make a new finite machine that recognizes hello, hello? I don't know why you'd say that. Anyway, give this some thought. This may take some extra time. Well, let's try to reason these out since they're extra complicated. Suppose you give me your finite state machine A. Here I've drawn all these dots to mean it could be bigger in the middle. I don't get to know what it is. This is going to have to work for any finite state machine. But I do know that it has a start state and an end state--a final state. Here's what I'm going to do. I'm going to draw another copy of A on my paper. Then I'm going to go back to the first one and where it was a final state, I'm going to make it not a final state, so I change this part. Then I'm going to add an epsilon transition here, and I'm going to erase this other start state arrow. Now I have a new finite state machine that accepts strings of the following form-- there has to be some part x here that would've been accepted by A. Then there's some possibly different part y here that would be accepted by A again, so in general I accept x epsilon y or just xy. In fact, I can always do this. If you give me any finite state machine, I can always make a twice as big finite state machine that accepts one string from you followed by one independent, separate string from you. However, for this one it's going to be a little more complicated. It turns out that the answer is only sometimes. Let me give you an example for yes and an example for no. Let's say the finite state machine you give me for big B just has one string in it--lowercase b. I'll do the same trickery as before, and now I have a new finite state machine that accepts bb. Since there is only one string in the language, I've now doubled it. This works fine. I can do it at least once, but now here comes the evil part. This upper example--this blue example--of B totally worked. Now I'm going give you an example for B that does not. Here, B is a*x. This finite state machine accepts the regular expression a*x. Any number of a's, possibly zero, but then you need an x. Now, note the difference between this sentence and its earlier copy. This requires exactly the same string double. Let's imagine that I do complete this finite state machine construction-- the same sort of thing I've done before. Now I'm going to write out some of the strings that would be in a*x twice. Well, I could have no a's, so then I have no a's followed by an x. Or I could have one a--that's looking okay so far. Or I could have two a's, or I could have three a's. This pattern should be looking ominous. Or in general, if I were able to double this machine so that it accepted the same string both times rather than a new string each time, I would be recognizing (a^n)x(a^n)x. For the same reason that a^Nb^n can't be recognized--it's not regular--neither can this. Here we have one positive example and one negative example, so it only holds sometimes. This was super tricky. Do not feel bad if you didn't see this the first time. All right. This time I have written out a fragment of HTML. <font color = "red"> Richard Stallman launched the link GNU project for software freedom. Oh, we never closed the font. Bad HTML. There we go, and what I would like you to do is check each box that corresponds to a word that will be printed on the screen when we look at a in the web browser. So, if you think the word "Richard" will appear on the screen, check this box. If you think the word "red" will appear on the screen, check this box. Try your hand. Everything in the tag doesn't actually appear on the screen-- no font, no color, no red, yes Richard, yes Stallman launched the, none of this, none of this, none of this. You might see this link somewhere else in your browser, but it's not rendered as part of the webpage. GNU yes, project nope, yeah, yeah, yeah, no, no, no. Nothing inside the tags gets printed on the screen. [Blank screen of eternal darkness.] I'm here at Mozilla with Dave Herman a researcher at Mozilla Research who also sits on the standards committee for the governing body for JavaScript. I was wondering if you might tell us a bit about changes to the language over time or what's coming down the pike. Sure. JavaScript was initially invented by Brendan Eich in a great rush. He famously invented the first version of JavaScript in 10 days. The original goal of JavaScript was to create a little scripting language where people could to little things with webpages, and I think there were people even back then who had some visions of where it could go, but it really did start from pretty humble beginnings. At this point, JavaScript really is the language of the web, and the web has become note just a place for documents but a place for serious programs, for serious applications. As a result, the platform grows, the language grows, and the needs of the programmer grow with it. While JavaScript started out as a simple language, the needs of programmers aren't as simple as they used to be. That means that there's a lot of features that other programming languages have and JavaScript does not have that we've had to consider standardizing on. A big one is that as your programs start to get bigger, you have needs around organization of your programs that don't actually arise when your programs are smaller. You may have seen as you're working with Python that Python has a module system. It has the ability to define separate pieces of code that you put into modules, and then you can mix and match those modules and put together larger programs from smaller components. JavaScript doesn't have a module system at all. It's actually not that easy to create a library, create a piece of reusable code that you can share with other people. There are various idioms that people use within the language to sort of simulate a module system, but they don't get any support from the language directly. One of the biggest features that we've been working on for the next version of JavaScript is a module system in some ways similar to Python's module system, although JavaScript has some particular needs of its own. The web has some particular needs of its own. But it'll make it much easier for people to create reusable individual chunks of code that they can share with each other. One of the tasks in this course was to specify tokens like numbers in quoted strings. Here I'm giving you a slightly different kind of number--submit via the interpreter, define a variable regexp that matches numbers with one or more leading digits 1,2,3--1,1 and an optional dot followed by zero or more digits. Here's the dot and then here it has one digit, here it has zero digits after it. I need one or more leading digits, and then there's a sort of a compound optional part, so I'll use parenthesis. We may have a dot and to really mean the dot, I'm going to use the backslash to escape the dot because remember it has a special meaning in regular expressions, any character. And then I can have zero or more digits afterwards. And then that whole grouping is optional. Now you are going to play the role of a learner. I've given you three positive examples and three negative examples, and what I'd like you to do is craft a regular expression that accepts the three positive examples but rejects the three negative examples. Quite a bit of room for creativity here. Go try it out. Well, there are a number of ways to go about this-- actually, an infinite number of ways to go about this. An entirely legitimate strategy but one that might feel almost like cheating would be just to put these together. You could submit the Python code that corresponds to either this or this or this. Now you're guaranteed that it accepts the three strings on the left and nothing else. Now, you'd have to be careful about how you group things or whatnot, so that the or and the parentheses would bind correctly, but that's one way to do it. Let's go see if we can make a more natural feeling regular expression that actually does it though. It looks like we definitely have to start with an a. Now I have my choice of what I want to say the difference is between these other strings-- abb and here we've got aabbb. In some sense one of the key differences is the number of b's. Here's one regular expression that captures all the ones on the left and none of the ones on the right. It's an a*--so that gets this first one, and then after you're done with the a's, you may optionally have either bb or cc. Great. That gets 1, 2, and 3 but none of these to hers. This one is ruled because it's not bb cc with a's in front of it. These have too many b's. These have too many c's. But there are a large number of ways you could've done this. In fact, there is an area of study called learning theory that tries to make machines find patterns the same way that we can with our brain. There's a notion that you've really learned something when you've abstracted it to a small rule. The reason we're less happy with this answer up here is because its' over-fitting the data in some sense. It's just recording the yes instances. It's not really generalizing the pattern. We say that more learning is happening when we generalize a smaller pattern than just copying all of the available input, but that was by no means required for this problem. Here I've written down four claims. A context-free grammar always produces just a finite number of utterances. A context-free grammar can capture the language a^N and b^N, where N is the same. Context-free grammars are more powerful than regular expressions, and context-free grammars can tell if a program declares a variable before using it. Or equivalently, I could use a context-free grammar to determine if a program declares every variable before he uses it. Context-free grammars always produce a finite number of utterances. No. This one produces an infinite number of utterances. I can keep looping around rule one as many times as I want. And in fact, this is one of the glories of context-free grammars-- that they can often accept an infinite number strings, thus, giving you room for creativity based on just a finite grammar. Context-free grammars can capture a^N b^N. Yes. It looks like this. Just like the balanced parentheses one but with "ab" instead. So by "yes" I of course meant "Yes." Context-free grammars are more powerful than regular expressions. Yes. Here, more powerful or more expressive means that there are some languages-- remember, a language is set of string--that context-free grammars can recognize that regular expressions cannot. This is one of them, a^N b^N can't be captured by regular expressions, but it can be done by context-free grammars. Therefore, they are more powerful. Context-free grammars can tell if a program declares a variable before using it. No. If you think back to our grammars for JavaScript, we couldn't tell the difference between a variable that had been declared than one that had not been yet. That's a context-sensitive property. We won't be able to check it with context-free grammars. We could only notice that later when we are doing interpreting or in a statically typed language if we were type-checking things to make sure we are using integers and strings correctly. We might also check to see which variables were in scope. But in general, it's very hard to tell if a variable has already been used. That depends on the previous program. That previous program is the context. Context-free grammars don't get any context. All right! Now let's practice generating strings from a context-free grammar, or equivalently checking to see if the string is in a context-free grammar. Over here, I've written five strings and I'd like you to check each one that's in the language of this context-free grammar. The start symbol is S. It's the first one to appear in our grammar. One possibility is s goes to ee which goes to ei using rule 2 and rule 4 so this string is definitely in the language of our grammar. I could also have picked rule 2 followed by rule 3, and then eventually this will boil down to ei plus i. This string is also in the language of the grammar. Now, we have aib. Well, I can get the a and the b from this rule 1 here. But then if I don't want to make more a's and b's, I have to use this rule 2 to get rid of the s and that requires that I bring in this e, and there's no e in this string so that's not looking good. All right. How about this, aa, bb? I can get that by looping around the first rule twice and then ei. Yeah, this string is in language of the grammar. Over here, I've got the a and the b around it. We'll note that these a's and b's follows the same balanced parentheses pattern we've been doing a few times. The real question is whether ie plus can be generated from s. We can get the e, we can get the i, but if we use the plus rule it has to have an e on both sides so you know we really need another i in here but we don't have it so this string is not in language of the grammar. Let's take a break and talk a bit about computer security-- a topic we really haven't touched on much in this unit so far. Security can sometimes be defined as computing in the presence of an adversary-- someone else using a computer or a network or resources who means you hard or hopes to exploit or take advantage of resources resources that you've put out there. It just so happens--you'll be surprised to discover I am breaking this news-- that the internet is not secure. Malicious agents or adversaries can write malicious webpages or JavaScript fragments. The simplest way to do this would be to write a JavaScript fragment that loops forever-- some sort of version of Fibonacci that has no stopping condition that just keeps going and going and going. Then as soon as you've directed your browser to that page, it would stall, and you'd be denied some server. You wouldn't be able to use your computer. In practice, browsers often put some sort of timeout on script execution. I'll run your script for 3 or 4 seconds, and after that if it hasn't finished, I'd better stop. that's one of the reasons why optimization is so important, but it also has this security angle. If we make any mistakes when we're designing our web browser, then outside agents might break in to our computers and gain access to sensitive documents--our tax returns, our personal email, or whatnot. We want to make sure that that doesn't happen. Let's listen to someone who knows quite a bit more about security than I do talk about how this plays out in the real world with web browsers. The web can be a great place but it can also be a dangerous place. Nothing stops users from posting malicious code or websites or writing scripts that will trying to take advantage of your computer or your browser. There might be security holes or exploits, they're sometimes called, that allow this. I was wondering if you might talk a bit about security at the language or implementation level from the perspective of Mozilla. Absolutely. Security is a prevalent concern at Mozilla. When I was growing up, the idea of getting a piece of software was that you actually drove to a store and you looked at a shelf and you pulled a box off the shelf and you paid somebody and you took it home and that piece of software was sold to you by a company that you trusted, by a third party that you trusted, so you had some sense of this piece of software that I'm about to put on my computer is something that I can believe is going to do something on behalf, not something against me. The web doesn't work like that way at all. The way web applications work is you can go to any website anywhere in the world, and somebody you've never met and never seen and that nobody can vouch for you is going to run some of their code that they wrote on your computer. So that changes the game. That means that in order to build a serious platform where programs can do important things on your behalf, we need to make sure that they can't also do important things against you. The more people put valuable parts of their lives onto the web like their bank account, for example, the more we have important assets to defend. One of the concepts people talk about a lot in security is the notion of the trust computing base. When you download some code from some third party that you don't know, if we're being kind of maximally pessimistic we say, well, I don't trust this code completely. I'd like it to do something for me but I don't know for sure that it's not malicious. However, that code is running inside of a web browser like Firefox, and I do trust the code that was written by Mozilla. I do trust Firefox. In order to be able to say as much as we can about the security of a system, we'd like for the parts of the system that we need to trust the most to be as small as possible, so we talk about shrinking the trusted computing base, as being a goal of having the smallest possible amount of software where if it goes wrong disaster can ensue--like somebody can steal or credit card information or your bank account. All modern web browsers are implemented in C++. Now, C++ is a very powerful language. There are a lot of things that you can do with it. But it's also not a particularly safe language. It's a language where if you make one wrong move, if you make one little programming mistake, you can actually leave parts of your system open to malicious programs. For example, if you write a program in C++ and you have an array of data and you forget to make sure that the program doesn't go beyond the end of that array, in most programming languages you'll get a runtime error that says, "Oops. You tried to access beyond the end of the array." C++ doesn't give you that protection. What C++ does is it just keeps reading what ever happens to be in memory at the end of that array. Well, whatever happens to be in memory could actually be some part of the browser that has internal information like a password. It could also be some other program running on the system, and there are a lot of people out there who work on finding ways to exploit these kinds of bugs to use them to take control of your computer or to get access to your private data. The project of building a web browser that people can trust and building a web browser that operates on user's behalf is also one of building software that they can trust. In order to build software that they can trust, it needs to be built on top of programming technologies that we know we can work with effectively to build software that's not unsafe. We've been discussing malicious code like JavaScript written by evildoers that we would run in our interpreter. Running evil code seems really bad. Can't I just look at the source code and tell if it's bad before I run it and then not run the bad code? Why doesn't Mozilla do something like that. Unfortunately, it turns out that there's a lot of good theoretical computer science that shows us that that is a provably impossible problem. I don't know if you've discussed the halting program. We may have. It turns out that if I were able to prove that any particular piece of code was not malicious I would also be able to solve the halting problem, and we already know that that's an unsolvable problem in computer science. Looking at this maybe from a more positive side, that means that I'll always have a job. The law of compiler writer employability. Exactly. Here's a new quiz. The Great Grammar Fix-Up. It's a puzzle in which I've written a partial context-free grammar on the left with five holes, and over here on the right, I have five strings that I want to be in the language of the grammar. What I'd like you to do is fill in each hole with the single word like s, a, b, c, d lower case letter, that sort of thing, so that this grammar accepts these five strings. Now, the real challenge here is this partial structure that I've provided. If I covered this up and said you could write anything you want, it'd be pretty easy, but instead, you have to use this context that I've already given you and that's the challenge. The hint is that the naming is sometimes handy, but sometimes, it leads you astray. Be careful. Alright. We noticed that all of these strings start with a lowercase a and S starts with capital A. Why don't we have capital A goes to lowercase a just to get rid of this lowercase a at the beginning. So, we don't have to worry as much about it. Now, I noticed that there can be some number of b's: bb, bb, one b, so one or more b's here, and then sometimes, we've got c, and sometimes, we've got c d at the end. So, I'm going to make B C D be a list of one or more b's, and one way to do that is like this: B C D goes to b, B C D. So here in the middle, after the a, we could either have no b's or we could loop as many times as we want and pick up more b's, and now after that, it looks like we either need c, c d, or nothing. Well, we have c. We got nothing, so we could also have c d. All right. So, it's another one of these puzzle-like questions. This time, I've written out three context-free grammars, and then down here at the bottom, there are five strings that I want to be in the language of the grammar. Check all that apply. Which of these grammars can produce these five strings? Just to shake things up, let's get started on the right. Here our start symbol is S and it goes to PQR and there actually aren't that many choices. If we think about it, there are two strings in this grammar--PQR and PQ nothing. So this doesn't look like a good bet because it doesn't produce PQQ, or P, or PR. This is not a match. All right. What do we have over here? Well, every string is going to have to start with lowercase p and then Q, looks like I can have 0 or more Qs and then eventually we end with an R. This looks pretty good because it matches the first string and the string down here, but it doesn't get PQQ so I don't like this one. How about this grammar in the middle that uses ABC instead of Senatus Populus Que Romany in the name of the senate and the people of Rome--A, B and C? Well, we have two choices for our start symbol that definitely complicates things, but both of them start with a P--well that's convenient since all five of our strings starts with a P. Let's just go through the strings one at a time. Can I get P alone? Yes. A goes to PB. B goes to nothing--so I can get that one. How about PQQ? A goes to PB. B goes to Q and then Q again and then nothing. Yeah, I can get that one. How about PR? A goes to PBC. B goes to nothing. C goes to R. This is looking super promising. PQR--we use the first rule-PBC. We'll gather up one Q and then we'll have an R. Great! PQQR. We use the first rule--PBC. We'll go around this loop twice to get two Qs and then end with an R. Here once again, we're presenting familiar material in an unfamiliar way. This time, I'm going to give you the parse tree, and I want you to tell me what the grammar would have to be. Over here on the left, I have a parse tree for the string (int + int), and over here on the right, I have a grammar with three holes. I'd like you to fill in each blank with a single symbol and a word to make this grammar fit with this parse string. Now, let's just take a look at each of the steps one-by-one. This first step "E" can be rewritten by (E) corresponds to rule two. Must have used rule two to do that. Then here, I just changed the "E" to a "T" that's rule one. But then down here, I somehow changed this "T" to an "E + E". We only have two rules to play with, and only one of them starts with a "T". So, I must have used rule four to do this, and this tells me exactly what it has to be. "T" goes "E + E", so it must've been "E + E", and down here, the only thing I've changed is "E" goes to "int". That's not currently one of my grammar rules. It must have been rule three, "E" goes to "int". Remember, every step in the parse tree corresponds to taking some part of the current input and using one of the rewrite rules. Back to quizzes involving the interpreter. I'd like you to write me a short Python program that for all numbers x between 0 and 99 prints x cubed, that is x times x times x, but only if x itself is even and x cubed is less than 20. For example, 2 is even, and 2 times 2 is 4 times 2 again is 8, that's less than 20, so I would definitely want to print out 8 among potentially other numbers. And the hint is use a list comprehension. This can be done very concisely. Here is a candidate answer. Remember list comprehensions start and end with the square brackets that mean I'm making a list. I want to print out x cubed for every x in 0 to 99, but we can get that with range 100. But I only want to print it out if x is even, and to do that, I will compute the remainder when x is divided by 2 if that remainder is 0, then x was even, x cubed to be less than 20. In fact, there are only two of these 0 cubed and 2 cubed. As soon as we get up even to 4, 4 cubed is 64, which is already much higher than 20. A very short list comprehended down from a very large one. All right. Parsing States. Over here on the left I've drawn a grammar. "S" goes to "a s b". We can loop around here, and we can have a "c" in the middle if we like. Oh, it's just like balanced parentheses, but with central content. And our input is "a c b" but we've only seen the "a" and the "c" so far. I'd like to know which parsing states are in chart 2. Remember, chart 0 is "I haven't seen anything." Chart 1 is, "I've seen just the "a"." Chart 2 is, "I've seen the "a" and the "c", but I haven't yet seen the "b"." Check all that apply. Let's go through them. This one has the red dot right at the beginning, and it's coming from state 0. This is a state that will occur in our chart, but it occurs in chart state 0. Similarly, this one is coming from position 0. We've seen the a. We haven't seen the s or the b. This one will be there, but it's in chart 1, and we're looking for things in chart 2. S goes to nothing from 1, and I haven't quite seen it yet. This won't be in chart state 2 because only one input token is accounted for. This is still in chart state 1, but over here, this is looking very promising. This is saying we've just finished reducing s goes to c, and there's one more token before this that you haven't seen. Here, we're reducing s goes to c, and here's one token before this not currently shown. This will be in chart state 2. Now, these last two really test your memory of how we compute the parsing states, the charts, and how we keep track of this from information. This one looks very tempting. S goes to as.b, that's definitely where we are in the input. We're right before the b, but it says from 1. That means there has to be one more input character that we haven't seen, x a c, but that's not the input we're currently seeing. There's no other hidden character that's not shown here. Instead, the one we really want is as.b from 0. This is the beginning of the string. There's an a, s goes to c. This is where we are now. And we're hoping to see b. That's definitely in chart 2. Another quiz about parsing charts, although the hint for this one is to think about the closure. I've written a grammar on the left. It's like the E plus E E minus a grammar, but this time, we're using multiplication and division instead for no adequately explored reason. We're currently looking at a state in chart 2. Looks like this, E goes to E times, here's where we are, and then another E coming from chart state zero. What I'd like you to do is indicate which of these other states would have to be included in chart 2. That is, let's say we bring in closure from this parse state. What else we are going to bring in? Remember when one is computing the closure, you look for the red dot right in front of a nonterminal light key. Oh! We found one, this is super convenient. When you go back to the grammar and look for every rule that starts with "E" and you put a red dot right at the beginning of it, so we're expecting "E" goes to dot this, "E" goes to dot that, and "E" goes to dot end. And you put from the current state, state 2. So here, "E" goes to end becomes "E" goes to dot end from 2, that looks really good. Here's "E" times "E". Here's dot "E" times "E" from 2. That looks really good. Dot "E" times "E" from 0, this is not correct, so put in chart state 2, because it has forgotten about the previous 2 characters we've seen, and then over here, "E" goes to dot divided by "E". This looks good. The other 3 were distractors. All right, this review quiz is about precedence and associativity. Over here on the left, I've written out a grammar for list, and list selections in Python, which is kind of cool. An expression can be a list of integers separated by commas. You can have as many integers as you want, and let's imagine there is some other rule where int goes to [1, 2, 3] and we have tokens for that. You can take the length of the list, or if you're given a list, you can select off all but the last element. If you have the list [1, 2, 3], then you just get the list [1, 2]. Now I tell you as part of this problem that "len" associates to the "right" and it has low precedence, and selecting off all but the last element associates to the left and has high precedence. Just like we may have told you before that multiplication has high precedence, and addition has lower precedence. Then the input here is I want to compute the length of [1, 2, 3] with the last element selected off. The last element selected off. And then down here, I've parenthesized that input two different ways. What I want you to do is check the box that corresponds to what are parse 3 looks like. If we were to put this associativity and precedence declaration into our parser with this grammar, which one of these worlds would we end up in? This first option is the one that makes us happy. Higher precedence means it gets done first. It's on the inside of the parentheses, so I really need this part with the colon, -1--that has to be inside all the parentheses, and not len. This is the wrong approach. And then associates to the left means that we typically want our parentheses to look like this-- they're grouped off to the left as much as possible. So here we have 1, 2, 3--we remove one element, and then we remove one element from the rest of it, and then we compute the length. Here we are in the Python interpreter, and I'm just going to show you that this subrange operator actually does associate to the left in Python. Here I have more or less two versions of the same expression, where taking 1, 2, 3--chopping off all but the last element-- chopping off all but the last element again. So our list is going to go down from three elements to two elements to one. Here I have the original expression, and here I have the original expression with added parentheses, and we look down and see that they both get the same answer. Let's probe your knowledge of interpreting HTML and JavaScript and evaluating expressions. Here I've written four claims. We can interpret an expression by recursivly walking its abstract syntax tree. To interpret the HTML we covered in class, we need an environment. To interpret the JavaScript we covered in class, we need an environment. And finally, interpreting always produces a value or an error. Mark each one that's true. Well, I like this first one a lot. We can interpret an expression by walking its abstract syntax tree, or its parse tree, recursively. That's how we wrote eval-exp together. To interpret the HTML we covered in class, we need an environment. Actually no, the environment didn't come up until we got to JavaScript, which had variables. The HTML we covered in class does not have variables. So they don't change over time. So I don't need an environment. To interpret the JavaScript we covered in class, we need an environment. Totally. JavaScript does have variables. And since they can change value we are going to need to keep track of them. Interpreting always produces a value or an error. This was a trick, or at least it was very tricky. When interpreting returns it either produces a value, like 5, or an error, like type error-- you tried to add it into a string. But interpreting does not always return. It can loop forever. If I write a program while true do x becomes x + 1, that never returns with a value, and it may never raise an error. This is also known as The Halting Problem. Here's a fairly direct quiz to test your knowledge of environment lookups when we have nested, or chained, environments. So we have a global environment that maps a to 1, b to 2, c to 3, and three other environments. You are in the last one. And down here I have five questions. I want to know the value of a, b, c, d, and e as we would have computed it in our JavaScript interpreter. Fill in the blanks. Tell me what each one is. Well, we're going to follow the same recursive procedure to get every answer, check and see if we have it, and if not, call our parents. So, a--I don't know what it is. How about you? I don't know what it is. Oh, it's 99. B--I don't know what it is. Do you? Oh, it's 88. C--I don't know. Don't know. Don't know. Looks like it's 3. D--looks like it's 77. And this last one requires you to remember a bit about the corner case in our environment lookup. I don't know what it is. Do you? No, do you? No, do you? No, do you? And my parent pointer is none, so we'll just return none. We don't have a value for this variable. We could also have raised some sort of exception. Let's say I'd asked you to write the following procedure: Find last given a haystack and a needle, returns the index of the last instance of needle in haystack, or -1 if it's not present. For example, if we're trying to find the last o in philosophy, we're going to get this one 0,1,2,3,4,5,6 instead of this earlier 1,0,1,2,3,4 find the last occurence. Some of you may already be familiar with this procedure. You may have seen it in the previous class, but it doesn't matter--I'm going to write it for you. I've written find last for you but actually I've written a version that has a bug. This works pretty much correctly. What we're going to do is work our way backwards, but we're going to use two variables-- one to store where we're currently are and one to remember the last time we found something successful. Let's imagine we're looking in haystack for a, we're going to find this a first--gray and then we're going to go over and find this a--gray and then we're going to get -1 so we want to return this a. We're going to find the last one by repeatedly searching forward until we get -1 and then conceptually we'll back up one. Remember we get -1 because the find procedure in Python returns -1 if something isn't found. Forever, I'm going to start finding the needle in the haystack, find this a--great! If that didn't work, I return, otherwise, I look again until it doesn't work. Down here at the bottom, I have four possible inputs, findlast haystack a, findlast haystack z, findlast haystack empty string, findlast haystack empty string needle. Only some of these will actually show off the bug. The bug is that I am returning this pos instead of last pos. What I'd like you to do is check each box corresponding to an input that shows the bug. Remember what it means to show the bug--on the buggy code you get one answer but on the correct code and in our minds, you get another. Let's go run it and see. On the buggy code we get -1, -1, -1, -1. But if I fix the bug, then I get 5, -1, 8, -1. That means these first two-- "haystack", "a" and "haystack", "empty" show off the bug, and the last two do not. So the correct answer was, first one and this other one on the left, but not the ones on the right. You can also reason through the program qualitatively to get a handle on this. We're only going to see this difference if last_pos is not equal to this_pos. Remember, this was the bug, and this version is correct. So in order to see the bug, this_pos will have to be different from last_pos, which means we will have to have found the string at least once. We find the "a"--we find the other "a"--so this is a good example, and then in fact you have to know a bit about Python to know what it means to try to find the empty string in something. But Python always says the empty string is present-- present at offset zero--it's going to be present at offset 1--at offset 2-- just like epsilon, it fits anywhere. So there's more than one "a" in the string. There's more than one empty string in "haystack". So these are both good test inputs to show off this bug. Since there's no "z" in "haystack", last_pos and this_pos are both -1, so we can't tell the difference. And since there's no "needle" in the empty string, last_pos and this_pos are both -1, so we can't tell the difference. Testing is not easy. Now let's get a little more practice with debugging. Suppose someone asks you to write a sudoku checker. Sudoku is a common pencil and paper game, also often seen on the computer, in which you fill in grids with numbers according to certain rules. If you haven't seen Sudoku before, it doesn't matter. We're not going to do full Sudoku. We're going to do a very simple subset of it. People would normally write out these almost Tic-Tac-Toe-like board. We will represent that as a list of lists. Our first row is the list [1, 2, 3], our next row is the list [4, 5, 6], and our last row is [7, 8, 9]. What I want to do is just check that horizontally all the numbers are different. This is good, because 1 is different from 2 which is different from 3. This is good, 4, 5, and 6 are all not equal. This is good--7, 8, and 9 are all not equal. But this makes me super sad, because I've reused 1. This is our horizontal Sudoku checker. I'm going to write one with a bug, and you're going to help me fix it. Here I've written out our horizontal Sudoku checker, but I'm going to do it probably a little differently than you might have in the past. I'm going to use a more complicated algorithm to make it a little harder to debug to give you a feel for how this might go in the real world. I've written a helper procedure called count. Given a number and a row, a row is just a list. It returns the number of time that number appears--whoa, that's ambiguous! If, for example, you're asking for 5, it occurs once in [1, 2, 3, 4, 5], but it's count is now two in [1, 2, 3, 4, 5, 5]. I'm doing this using reduce from functional programming. I'm intentionally throwing in lambda, Python's equivalent of JavaScript's function expression. Reduce and map and list comprehension are aspects of functional programming used by companies like Google to make their search engines faster and more parallelizable. What this does is starting with the number zero, I'm going to go over every element in the row, and I'm going to call the current element this, and I'm going to call what I have so far the accumulator. If the current element is equal to the number that I want, I'll return 1+ the accumulator. Otherwise, I'll just return the accumulator. Let me walk you through it on checking the count of 5 in 1, 2, 3, 4, 5. The number that we want is 5. The current element starts out at 1, so I'm going leave the accumulator alone. Next, the current element is 2. That's not 5, so I leave the current accumulator alone. Next, the current element is 3. That's not still not 5, so I leave the accumulator alone. Next, the current element is 5. Still not 5, I leave the accumulator alone. Then, the current element is 5--whoa! Happy day in jubilation. I turn the accumulator into 1+ the accumulator, so just 1. Then in this particular list there is actually another 5 right after that. This is 5 again, so I'll have 1 + 1, which becomes 2. I'm walking down this list. How many 5s have I seen? Zero, zero, zero, zero, 1, 2, great. You could have written this with a simple for loop without using reduce, but often when you have to debug a program it's after you've been away for awhile, and it looks a bit unfamiliar. I'm intentionally giving you code that's not your usual style. I assert that there are no bugs in count. Count works correctly. However, there is a bug in my horizontal checker. Here's what we're going to do. We're going to figure out the number of rows in the board and store that in the variable size. For every row in 0 to size -1, I'm going to use functional programming again. Here's what I'm going to do to figure out if a number is unique or not. I'm going to use map to convert every element of the row into its count in that row. Let me show you how that would play out. Suppose our row is [5, 6, 6, 7]. After the map it's going to be [1, 2, 2, 1], because I've mapped every element of this list to its count in that same list. We've used map before to map strings to their lengths or map x to x^2, but you can use map to do more complicated calculations just like I'm doing here. I'm going to convert every one of these numbers--5, 6, and 7--to its count and then check and see if the count is less than or equal to 1. This will become True, False, False, True. What I really want is for every element in this list to be True. That would correspond to each element occurring having a count of at most 1. There is a Python procedure called all that given a list returns true if every element of that list is true. I'm using that to check that every element in my row had a count of 1 or less. I'm doing it all one two lines. This is pretty slick, but it's also pretty complicated. It's very concise code, but it might be harder to read, especially if you're not familiar with all or map or making functions in Python. We've had less experience with them in this class. This problem is intentionally difficult. So what I want to do is go over every row in the board and check to make sure that for every number in that row, it's count is less than or equal to 1 and then that's true for all the numbers on that board. If you were writing horizontal checker yourself, you might use a number of nested for loops, maybe even three nested for loops. I'm not writing as many for loops, because things like map and all and count do them for me. Anyway, if it's not the case that everything is true, then we return False. If I make it all the way through here, then we return True. I've even made some test cases. Down here I've got a good board--1, 2 ,3, 4, 5, 6, 7, 8, 9-- and a bad board--1, 1, 1, 4, 5, 6, 7, 8 ,9. And when I run my horizontal checker on them, the first one passes, because across every row all the elements are unique, but the second one fails. Over here--1, 1, 1, 1, 1, 1--we've got a lot of repetition there. That fails our checker. Unfortunately, my code has a bug. Here's a board that shows it off. I've already made the test case for you. [1, 2, 3]--that's looking good. Horizontally everything is unique. [4, 4, 4]--that's looking bad. This is not unique. We should be returning false. Then [7, 8, 9]--that's okay. We return true. We think that this board checks out, but it doesn't. What I would like you to do is define and submit via the interpreter your own version of horiz_checker that's very, very similar to mine, but just changes one or two words to fix it. Fix the bug, submit a new version of horiz_checker. It should still use all and map and lambda and all that good stuff. Let's get started on this by looking at the test cases instead of the code. Our buggy program worked fine when row 0 had the duplicates, but it didn't work well when row 1 had the duplicates. So, probably we're not handling the row correctly. Let's go up and see if that intuition pans out. In fact, it does. We're looping over all of the rows in range size. But if you look down in this code, although we introduced the variable row, we never really use it. Just use it over here. We're not using in all that much. Remember, I want to check to see that all of the numbers in these row are unique within that row. Conceptually, that's two references to row and I only see one over here. The bug in this code is that we're always checking the 0 true board. We should be checking the current row against itself, and that single word fix causes us to get the answers as we works on. All right. For our last big review question, Let's delve into Optimization, making programs faster. Remember that we can only apply an optimization-- that is, we can only replace one subtree of a program with another-- if we don't change the semantics, the meaning, the answer of the program. Here's another way to look at the challenge of optimization. What we really want to know for optimization is given two functions, F and G, do they both compute the same answer for all inputs. This may seem a little abstract, but let me firm it up with a concrete example. It might be that F is the original program, and G is the candidate optimized program. If they compute the same answer on all inputs a, then we can replace F with G wherever it occurs. We can imagine framing this as some hypothetical procedure--optimization okay. You just pass it in F and G and if F(a) = G(a) for all a, then you return True. Otherwise you return False. Now, this is clearly sketchy code. We sometimes call this psuedocode, because it wouldn't actually work in Python, but you can imagine what would go there. Somehow we're going to try this out--maybe we'll look at their source code. We apply these rules that we did previously. Maybe we test it out on a bunch of inputs. Somehow we come to the conclusion that F(a) is always equal to G(a). If so, we return True, and the optimization is okay. Otherwise, the optimization is not safe, so we don't apply it. Just to give one more concrete example, we expect optimization okay of F and G to return True, but optimization okay of X and Y down here where X is a/a and Y is 1. This should return False because remember if a equals 0 then this one is division by 0 exception, and this one is 1, and those aren't the same thing. All right. So here is the actual quiz. I've written four statements, four claims, that refer to that optimization okay phrasing or procedure from before. It's kind of like a specification. Here they are. We can implement optimization okay so that it returns a safe answer for optimization in all cases, for all possible programs. We cannot implement optimization okay that works precisely in all cases. It is undecidable like the Halting Problem. We cannot implement an optimization okay that works precisely for any case. It is undecidable like the Halting Problem. Then down here optimization of george f will and betty frieden implies optimization okay of betty frieden and george f will. Check all that are true. This was potentially a difficult quiz, requires you to think about outside the box of what I normally ask. We can implement optimization okay so that it returns a safe answer for optimization in all cases. Remember how are we using optimization okay? We consider a bunch of optimizations, and if this says True, then we swap out parts of the program. A safe answer is just to return false all the time, never do any optimization. That'll make for a slower programs, but it's safe because we'll always get the same answer. We're never changing the meaning of the program. Optimization is sometimes described as conservative because if you're not absolutely certain that an optimization is okay, just be conservative and don't do it, and you'll be fine. The program will be a little slower, but it'll always get the right answer. We cannot implement and optimization okay that works precisely in all cases. It is undecidable like the Halting Problem. This sadly is true. I'm going to sketch an answer for this. A formal proof that something is impossible, like the Halting Problem, is a little beyond the scope of most of this class. But let me show you how it would go. Suppose we could write optimization okay in a way that was precisely correct in all cases. I, the Great Wesini, shall solve the Halting Problem by telling you if an arbitrary program halts or not. You want to know if a program P halts or not. I'm going to tell you how to do it. Remember, we know this is impossible. Here's how we do it. Suppose you claim we've implemented optimization_ok. It always gets exactly the right answer. I'm going to use it to build a Halting Problem solver. You give me a program P and you want to know if it halts? I just make up a little program over here called "loops forever" or "loops." This procedure loops sets x to zero and while True, it increments x. We've seen before that this program never terminates, never returns a value. I can just check to see if your program ever halts by checking to see if it would be okay to replace it with loops forever. If your program gets the same answer on all inputs as loops forever, then your program loops forever on all inputs. Otherwise, your program halts. If optimization_ok could be written, then the Halting Problem could be written-- this Halting Problem decider. But this cannot be. We've seen before that there is no way to solve the Halting Problem. It's equivalent to figuring out if "this sentence is false" is true or false. It's a contradiction in the real world. So halts is impossible, but I could totally make halts if I had optimization_ok. That means optimization_ok must me impossible--impossible to solve every time precisely. We can solve it some of the time. We just can't solve it all of the time. Because if we could solve it all of the time, it'd be just like the Halting Problem. Then finally down here at the end-- optimization_ok of AB implies optimization_ok of BA. This is true because we're just checking equality. If A = B, then B = A. Now the two I've picked--George F Will, a Pulitzer Prize-winning conservative commentator, and Betty Frieden who wrote The Feminine Mystique and lead second-wave feminism in the United States-- they're unlikely to have exactly the same things to say. These two are unlikely to be equal, but if they were then you could reverse it, and they would match up. You never know. Check them both out. Let me ask you a leading question if I can, since I introduced our students very briefly to optimization at the JavaScript AST level. We might replace the subtrees like x * 1 with just x if we believed that that preserve semantics. I was wondering if you could just give me a hint without telling me any trade secrets about higher level optimizations that are important. What's the next step after replacing subtrees? In our JavaScript Engine, we've recently had a great boost from type inference. JavaScript is a very simply called untyped or dynamically type of language. It's important not to burn the programmers with writing down type decorations like in Java. That was never in the scope of JavaScript and rightly so, but the underlying runtime--the just-in-time compiling JavaScript Engine has to know the types to get very concrete and use the hardware well. We have a very adaptive sort of online-type inference algorithm. You can study the code and try to infer type,s and if some codes gets loaded or invalid, it can change its mind or it can conserve what is good and throw away what was invalidated. That's very important for performance. There are the traditional sort of loop invariant code motion optimizations that we're getting into more and more because before people are writing JavaScript that looks more like C or even Fortran in the old days. We see more graphics code. We see more numerical processing. Thank you for taking the time to tell us about it. Sure. My pleasure. It is time to declare moral victory. While there is much more to learn in computer science and the world, this about wraps it up for this class. You should celebrate. Here you can see happy people and clearly they're next to--let's call that a cake. At least one thing we can conclude is that while you've learned quite a bit about computer science, my sketching skills have not improved at all. This course was not easy. This course was not easy, and I fully acknowledge that. In fact, some of the material that it covers is similar to material covered in 400-level classes at universities like Cornell or Berkeley or the University of Virginia. There's a lot of deep stuff going on in here. You should really congratulate yourself on making through it alive. A legitimate question is what comes next? Well, there's likely to be a final for this course and perhaps some wrap-up surveys, but if you'll indulge me for just a moment here at the end of the class, let me make some recommendations for what you might do with your copious spare time. I personally recommend that you study--if you have the time-- philosophy until you've covered epistemology. What is true? How do we know things? Tricky. Free will--do we have it? So unclear. Logic, the philosophy of science, and what it is like to be a bat. And there's my bat, using echolocation and apparently with the wings of a condor. Similarly, I think there's a lot to be gained by studying cognitive psychology-- at least until you've covered perception, which is magical; consciousness, which is perhaps even more magical--bonus points if you know what it is and can tell me; and the Flynn effect--just when we thought we understood intelligence. Study speech or rhetoric until you've covered persuasion, and presumably made Captain Wentworth proud. Is all persuasion self-persuasion? You tell me. You should definitely investigate anthropology, possibly cultural anthropology, and gender studies until you've covered, say, Mead and Freeman-- Margaret Mead--and have a better feel for which behaviors are socially constructed and which may be essential. I think you may find that a larger fraction are socially constructed that you would have believed. You should follow along with statistics until you can avoid being fooled, either by others or by yourself. You should spend some time with religion and ethics until you've covered the relationship between unhappiness and unrealized desires. How do we become happy? Study physics and engineering until you can explain how a microphone, a radio, and a speaker--or a headset--all work. Spend some time studying government until you have an opinion about legislating morality and also the relative importance of freedom and equality. They are both virtues worth striving for. Ideally we'd like them both, but if you could only have one… Read history until you are not condemned to repeat the mistakes of the past, until you and Santana are friends. Finally, study life until you are happy. They say ignorance is bliss, but they are wrong all but finitely often. Wait, what was I saying earlier about statistics? Ah, never mind. Let me just conclude by saying that it has been an honest pleasure leading you during your discovery of this aspect of computer science. It's rare that I can do something like teaching this class that will leave such an impact on the world. Thank you for giving me this opportunity. Over the course of this class and in the forums, a number of you have asked me about research or what I do to nominally push forth the boundaries of human knowledge and make the world a better place. And now I'd like to give you the chance, the opportunity, to participate in just such a project. Oh, fellow travelers on this voyage of discovery, I stand before you, hat in hand--well, metaphorically, at any rate-- asking for your help, for your participation. Let me set the stage for you. Imagine that you have a job as a computer scientist and you have a program that you'd like to work on. It could be some Excel macros to make a better spreadsheet. It could be a game you've always wanted. It could be an assignment from your superior. Probably you will think hard about the problem-- that's what we hope everyone does--find examples online, write your code, debug it, and then, typically later, you may have to make some changes. All of these stages--except perhaps thinking about the problem--involve reading code. It turns out that in industrial practice, more time is spent reading code than on any other activity, especially writing it. By some estimates, up to 70% of time is spent just reading existing code. And as a result, the readability of code has a huge impact on productivity. Readable code doesn't just look good; it has an economic impact. That makes it unfortunate that we really do not understand code readability at all. We have some intuitions for natural language readability-- when something is at the 3rd grade level versus the 7th grade level-- but we'd really like to understand code readability more. I think that one way to do that is to ask people like you, ask people in the real world, "What do you think? Is this code readable or not?" and from that build a formal mechanical model that we can use to evaluate existing pieces of code and make representations. The largest existing study on code readability--more than 70% of the work of industrial software development--involves only 100 participants. I think that we, free online education, can do better, and I'm going to need your help. The survey we'd like you to participate in consists of a number of examples of snippets of code from real-world programs. The survey is completely voluntary and anonymous. We're not going to store any identifying information. Instead, we'll present you with a number of snippets of real-world programs written in either Python, Java, or CUDA. You're already familiar with Python, but you may be less familiar with Java or CUDA, a language for programming graphics cards. You don't need to be an expert. You don't need to be familiar with those languages. In fact, you don't even need to have heard of those languages. We're very interested in gathering your intuitive notions of software readability. So we'll show you a number of pieces of code, and after looking over each snippet, you'll rate it on a scale of 1 to 5, where 1 indicates less readable and 5 indicates more readable. The exact notion of readability we are leaving up to you. For example, perhaps you'll see a snippet like this and decide that it's a little less readable. Perhaps you'll see a snippet like this and decide that it's a little more readable. We're really interested in what you think about this subject. So the survey takes about 15 to 30 minutes, and it's totally anonymous and confidential. We're not going to store any important information that would help us trace these numbers back to you. It's not related to this Udacity class in any way. In fact, it's not worth extra credit. It doesn't influence your grade. It's solely to try to make the world a better place by increasing human knowledge, by helping us to understand when code is readable and when code isn't-- a really important part of software development. I realize that many of you are quite busy; you've got other things to do. Not a problem at all. But if you are interested, if you're not busy, if you have a few moments to spare, I would really personally appreciate it if you would take them and help us out. Even if you're not particularly comfortable or an expert with these languages, you're just as necessary. Those data points are critical. So if this isn't worth extra credit, why should you participate? A number of people on the forums have suggested that, based on my reasonable radio announcer voice, I should consider singing a bit more. These people are clearly doing their best to flatter me, because my singing is not all that and a bag of chips. But the graduate student who is leading this project, who is helping me out, is a pretty good singer. So what we have agreed to do or what I would be happy to do is if we're able to get the required number of participants-- if 1000 people help us out--we will happily sing the song of your choice. We have no shame if it will help us push forth the boundaries of human knowledge. So if you like Irish music, [singing voice] "Oh, it is the biggest mix-up "that you have ever seen. Holy mo, me father loves Nikita Kruschev. Holy moly me." If you like Bollywood musicals, [singing voice] "Pretty woman, dekho dekho na." If you like it un Francais, [singing in French]. If you prefer it in Spanish, [singing in Spanish]. If you like Japanese, [singing in Japanese]. Or if you just like more English or American folk music, [singing voice] "Lemon tree, very pretty." We'll do anything you want. Whether it be the theme to The Muppet Show or whether you'd like to hear me butcher romantic Mandarin songs, [singing in Mandarin], we will do it. Start a thread in the forum and vote for your favorite. Participate in the survey, and I will happily do almost anything in order to make the world a better place with future research. Please participate if you do have a few minutes, but it is by no means required. Thank you. Hi, I'm Peter Chapman, and welcome to the first Office Hours for CS 262 Building a Web Browser. I'm your assistant instructor, and I'm filling in for Professor Westley Weimer, who's currently at a conference. My name's Andy. I'm the assistant instructor for CS 212, which is Peter Norvig's class on the design of computer programs. And I'm going to be filling in the role of the student today and asking Peter here all of the questions that you came up with in the forums. So let's start off. The first question we had, Peter, was why are we learning regular expressions at all? Why is this useful for a class on programming languages? The class is structured around building a web browser, and our web browser needs to interpret html. The first step to do that is to identify the parts of html. We want to identify which part is the beginning of a tag, the end of a tag, what's a hyperlink, what's just text and words and whatnot. We want to do that very concisely with the powerful tool that is regular expressions. Regular expression just allows you to write some text, and it very precisely and easily identifies strings that can match, say, our tags or hyperlinks. Okay, and I've seen the beginning of Unit 2, and it seems like that gets reintroduced then. Yeah, we use it a lot throughout the course. And our second question comes from Hardy Martinez. He wants to know if the rules and format for regular expression that we're learning now--if they extend to other languages beyond Python, or if they are Python specific. In general, they use almost all the same notation, and that's partly because down underneath all the APIs that you see, all the functions that you are calling, they're using almost the same code. It's based on some--someone wrote it way back, and it seemed to work well, so people reuse it. There are some differences, depending on the language you're using and the library you're using, and that's just something you look up in the documentation. Python, for example, has a lot of documentation on what the symbols mean and whatnot. Sometimes they'll vary, especially when you're getting to the more obscure syntax features of regular expressions, which we don't cover in that class. Pretty much everything we talk about here is going to be the same throughout. Okay, so students that learn this will not be behind when they try to implement regular expressions? Yeah, and what matters is you know what the tools are. The specific character that means something, it doesn't make that much of a difference. The next question comes from Mark Sanders. Mark pointed out that regular expressions are very powerful and they are a useful tool, but they can quickly become really long and hard to read. He wants to know are there tools that we can use online that maybe would help us generate these longer regular expressions, and if there are, would they be useful? So there's a lot you can do with regular expressions, and I've seen regular expressions that are 2 or 3 lines of just non-stop characters and special symbols and whatnot. And at that point I have to say it's usually more useful that you break it up into smaller regular expressions that you connect together with code. There's not a whole lot of value, and it's very hard to debug regular expressions that are really long and do your entire program in one go. But there are tools that help you generate, but more importantly check, your regular expressions. There are tools that you just give it text, and you type in your regular expression, and it will highlight everything in that text that it matches. That's really useful for creating great expressions. I highly recommend them if you can find them. Okay, thank you. The last question we're going to talk about today came from Elise. And Elise got really excited by the discussion that Wes was having with the CTO of Mozilla. She wants to know how do you create a programming language? What goes into it? Well, the good news is that's what we're doing in this course. We just happen to be creating all the materials needed to interpret and run programming language that exists, and that is JavaScript, and interpret html, which is just how to display something. But that's how you build a programming language-- exactly what we're doing in this course. The only difference is that you would change the syntax and all the features to how you would want it in a language of your choosing. But this is the course, and I hope by the end you'll get a very clear picture of what would go into doing such a thing. All right, well, thank you for your answers, Peter. And thank you all for your questions. Thank you, as well. And thank you for being here, Andy. Thanks to everyone. Everyone gets thanks. See you next week. Welcome to the Unit 2 office hours. One of the first questions I'd like to address deals with the Ply library that we're using under the hood for this class to help us out with lexing and parsing. In the lectures we talked about how to write down a token definition. You define a function t_something--like a number-- and then you'd write out the regular expression--0 through 9-plus. Then you might do a little work modifying the token value-- maybe converting it from a string to an integer. Then eventually you return the token. The basic question from students is how does that work? What's going on? After you write down a number of these token definitions, there is a library behind the scenes--part of the grading scripts that we're using, but also available for you to download if you'd like to try it out on your own-- that gathers up all of your token definitions. One way to do this is using a technique called "reflection," which actually sounds very philosophical but is a way for a computer program to look at itself and all of it's own capabilities. In essence, our Python program asks, has anyone defined any functions recently that start with t_? If so, the next thing we have to do is get that regular expression out of them. It turns out that Python functions allow you to write documentation or a brief explanation at the beginning of any function. This is sometimes a good software engineering practice. Our Python parsing library and our Python lexing library reuse this power. We're writing down this regular expression, and the library is treating it as if it were documentation. We use that to get access to the regular expressions you've written down. So step one: you write down a bunch of these token definitions. Then we look--using reflection, for example--to find all of them. Step two: we go through all of them and ask, do they have any strings at the beginning- anything that looks like documentation. The answer is yes. But for us it's not documentation. It's a regular expression specification. The next thing to do is convert each of those regular expressions to a finite state machine. Now, I hinted at this in class. Didn't give a full, formal proof on how to do it. But it turns out that every one of the regular expressions--plus, star, disjunction, concatenation-- can be written out in a finite state machine. For every regular expression there is at least one--and in fact, typically, infinitely many-- finite state machines that accept exactly the same language. We'll just apply that conversion in the background. But if you have a bunch of different token definitions--one for number, one for string, one for some keywords in your language like "if," "then," or "else"-- we're going to end up with a bunch of different finite state machines. Now we have to combine them all together. If you're willing to humor me with nondeterministic finite state machines, we could actually do that just by putting a special state at the beginning-- a special new start state--and having an epsilon transition go to the beginning of each of our old states. We'll glue them all together into sort of a Frankenstein's monster-- an amalgamation of everything we've looked at. We're almost done except that it's not enough for a lexer to know this string is a token. You have to know which one it is. A real life lexer will have one more bit of information that we didn't talk about in class. A state isn't just an accepting state, it's an accepting state with a little label. If you accept, here it was a string. If you accept here in this over there, it was the token then. If you accept in this state down here, it's a number. Instead of just known what the accepting states are, we need to know what the accepting states are and what token each one corresponds to. All right. You did all your token definitions. We found them all. Each one had a regular expression. We found that. We converted each of those down into finite state machines. We joined them all together. We labeled all the accepting states. Now we represent that big finite state machine internally as edges. This is sometimes formally called a transition table, but it's just like the edges in coding that we used in class. Now when it comes time to actually do lexing--to break a string down into into important words and tokens--you just feed the characters of the string one at a time into that big finite state machine. It's exactly the same as the FSM sim procedure we went over in class. It's just that their finite state machine is much bigger. In fact, the FSM sim code that we wrote would work just as well, even on bigger finite state machines. I just didn't show it because they're harder to draw on screen. Under the hood, this library is basically just doing a bunch of grungy details, chores, busy work in the background. We did exercises with one or two regular expression definitions. The library gathers them all up together in one place. You're already familiar with all of the key concepts in making a lexical analysis library. The library just does a lot of the busy work for you. And that's the explanation. Another question on the forum related to the use of lexer states. A lexer state like I'm in a comment or I'm not is actually more of a convenience function for allowing us to have different rules depending on where we are. In normal code for HTML or JavaScript, we want to recognize things like angle brackets, because they might be a part of tags or they might be the less than or greater than sign in a JavaScript mathematical computation. But inside a comment, they don't mean anything special at all. You want to just skip over them, because that's some documentation the programmer wrote down for later maintenance. So we used exclusive states like I'm in a comment or I'm not to have different rules depending on where we are. A totally legitimate question is: Are we going to use these exclusive states to have one lexer for HTML and another for JavaScript when we write our final web browser? This is a great question. It's going to turn out that we're not going to use explicit states, but we are going to use exactly the same concept. If you think about it under the hood, lexer states are really just a cute way of giving you two different finite state machines-- two different sets of regular expressions-- one for in comments and one for not, for example. We will do the same thing just by writing two different sets of token definition files. Here's one for HTML, and here's another one for JavaScript. We'll start with the entire web page that we download from a web server somewhere, and we will feed that to our HTML lexer and parser. Some parts of the web page will be embedded JavaScript, and we'll see this in great detail in later units. We will gather up those strings and keep them safe. And when it comes time to interpret them, we will pass them to another lexer, this time a JavaScript lexer, that will interpret that substring as JavaScript. And this is one of the great joys, really, of computer science--turtles all the way down, or nested Russian dolls--once you've learned a particular concept, like how to make a lexer, you can often nest it or have multiple of them at the same time. Once we know how to make a lexer for HTML, nothing stops us from making a lexer for JavaScript and having them both running as part of the same program. And that's what we'll do. So officially we won't be using exclusive lexer states, but we will end up with multiple different finite state machines used for lexing under the hood. All right. The next question I would like to address deals with internationalization. In reality, web browsers like Firefox or Internet Explorer can handle words, strings, sentences in language other than English. The question from students is, basically, how does that work? What's up with that? To answer that fully, I need to take a little aside into how we even represent English characters. It turns out that it's totally arbitrary. We're essentially going to use numbers under the hood. Computers can already manipulate numbers. Let's say we believe that's possible. A computer file could just be a big list of numbers. Well, we're all going to agree on a standard that certain numbers stand for certain letters. This standard is totally arbitrary. For example, the decimal number 65 stands for uppercase English "A." The decimal number 66 is uppercase English "B." Why did we start at 65? Why not? This standard is called ASCII--the American Standard Code for Information Interchange. There are 256 possible number to letter conversions in it. We only need 52 of those for the alphabet--26 lowercase letters, 26 uppercase letters-- but there are also spaces, periods, parentheses, all of the number signs, multiplication, division, quotes, that sort of thing. Then the remainder is sort of filled out with special characters that aren't typically printed-- like new line character that we've been escape sequences for. Two hundred fifty six might seem like a lot of room, since we're really only using maybe 80 of them, but it is not enough to encode--for example--all Chinese characters or ideograms or all of the other scripts that exist in the world from Greek or Cyrillic or Tagalog, which I believe has a different alphabet. Someone will correct me on this one. Make it known in the forums. Anyway, there are a bunch of different scripts used in natural languages, and there are more than 256 characters in the entire world. The basic solution is we need more numbers. Rather than saying that numbers 1 through 256 correspond to letters, we'll just decide to use more room. We'll say numbers between 1 and 65,536 correspond to letters. Maybe the ones at the beginning correspond to English. Then there's some for Greek. Then there's some for Russian. It's just a bigger standard. Somehow we have to agree on the order in which they appear. You may have heard words like Unicode or UTF8 mentioned in this sort of discussion. Those are just standards for using bigger sequences of numbers to represent letters that occur in the natural languages throughout the world. All right. Let's get back now to the meat of the question. How does a web browser like Firefox handle words written in other languages, especially if you're doing token definitions or whatnot. Essentially, as a convenience feature for programmers like you, we've written out A through Z--or a through z, capital A through capital Z-- to mean I want this to be a word, but often there are special shortcuts, like \w, which you can write down--kind of like we might write down \n for new line, \w often means this is a word character. Someone else at the standards committee once and for all has written down all of the numbers corresponding to English letters, Cyrillic letters, Latin letters, Greek letters, all the way on down, including a bunch of Chinese, Japanese, Korean ideograms, or letters in their syllabaries, and listed all of the ones that don't correspond to space or punctuation in essentially a big lookup table. Then whenever you want to say I want to get a word in any language, you just refer to something like \w. You refer to this lookup table, often provided by a library for you, and it expands under the hood to actually thousands of individual characters or character ranges. In practice--one again, the answer to this is someone in one particular standards committee essentially enumerated every possible letter, every possible script sequence , in all of human natural languages--or at least all of the ones that we have thus far encountered or codified--and we've written down which of those correspond to word letters and which of them correspond to number. Then we provide special shortcuts that you can use to reference those sets. So when a Firefox developer is writing a regular expression, instead of using A through Z if they mean it's part of a word, they'll use something special like \w. The actual name for this escape sequence is different depending on which regular expression library you're using, but the basic concepts-- parenthesis grouping, plus, star--they stay the same for the Firefox developers even if you're supporting multiple international languages. Another question on the forums asked about the the length of writing down a bunch of regular expression rules, or tokens, for a language. The basic question was something like, this seems to go on forever! I can imagine having to write down so many token definition rules that I would expire of boredom before we ever finished. Is that what happens in the real world? What's it like? My answer to this is to some degree, there's no silver bullet. There's no single easy way to encode structured information to bring order from chaos. But what I can tell you is that it is a totally surmountable task for real world languages. I've been associated with a lexer and a parser, a frontend for the C-programming language. To handle this C-programming language, which has a lot of gory details, our list of token definitions was 600 lines long. That might seem like a lot if you're writing it out all at once, but in the grand scheme of things, a normal program like the Firefox web browser is multiple millions of lines long. So this list of regular expressions, this list of token definitions, is actually a very miniscule part of the entire software engineering effort. I was also involved in the creation of a lexer and parser, an interpreter for Java-- Java 1.1 at the time, and our list of tokens, our token definition file was 200 lines long. Java was more regular than C in that regard, didn't require the lexer act, which you can ask me about at some later point. 200 lines is even more reasonable. Finally, I think in one of the videos at some point, I mentioned in a particular Tetris game that I had the pleasure of working on, and there was a piece definition language that let me use the planner pentominoes instead of the normal 4-length tetris pieces. There the piece definition reader was more like 90 lines long, which is seeming even smaller and more attractible. But the way you really want to think about this is more like, say reasoning by analogy. Is it a lot of work to build a road? Is it a lot of work to build a sewer system? Is it a lot of work to paint a beautiful picture? Yes, but you do the work once, and then you advertise the cost for everyone who gets the chance to enjoy that construction. Yes, it takes a long time to pave a road, but after that, many people can drive over it. Often, language definitions like C or Java or C# or JavaScript-- they don't change very quickly, if they change at all. Once you have taken the time to write down all of your token definitions for JavaScript, even if it is a few hundred lines long, you look at it. You write some test cases. You feel good about it. You do a code walk through with someone else, and then you're done, and you can just build upon that, take advantage of it for the rest of your software development career. So it can be a bit arduous to write down a bunch of token definitions, especially since a lot of them seem the same. But you do it once, and then it's over. Another topic that I would like to address is malformed HTML. One of the questions on the forums was, are we going to talk about mistakes in web pages? What if a real web developer forgets to close off a tag or makes a sort of subtle mistake in punctuation? Are we going to talk about that in the web browser that we build for this class? And the answer is, yes! In fact, very prescient on your part. That's a very predictive question. We're going to get to it in unit 3, exactly the next unit. We're going to talk about recognizing malformed HTML and JavaScript. But in this class, we're mostly going to talk about recognizing them, and for the particular project that we work on for our simple web browser, if the HTML is malformed, we're not going to do anything about it. We just won't render that part of the web page. In practice, web browsers put a lot--a huge amount--of effort into being very forgiving. They want to render as much information as possible, even if the web page is out of date or written without knowledge of the standards or in any other way messed up. This approach of keeping going is sometimes known as error recovery or error tolerance or fault tolerance. In unit 3, we're going to talk about breaking up tokens and seeing if they match a particular structure, seeing if they're in the language of a formal grammar that describes all of JavaScript or all of web pages. You know in the real world, a lot of web pages are not. They don't match the formal idealized grammar I've written down on the walls of Plato's cave. Similarly, not every JavaScript program adheres to exactly the same idea of-- to pick a timely example--where the semicolons go after statements. So in practice, what you'll often want to do if you're doing commercial software if you want to make your customers as happy as possible by supporting everything that they've written, you'll write about your duplicate rules. For example, you might write one regular expression that accepts normal numbers, but if people make a common mistake when writing numbers, maybe they write multiple.multiple period signs or something like that, you might write another rule that accepts those, and maybe print out some warning but then does it's best to figure out what the value is and keeps going. Again, in real world industrial software development for a web browser, this sort of error recovery when you're doing lexical analysis or syntactic analysis is of critical importance because the vast majority of web pages are not standards compliant. In this class, we're going to tell you how to tell the difference between good HTML and bad, between well-formed JavaScript and malformed JavaScript. But I'm only going to require that you deal with well-formed strings. Once you know how to do it the good way though, you could do it for ill-formed strings. You'd have all the tools after finishing this class. It would just be more busy work, elbow grease. It would take additional time, and it wouldn't really teach you more concepts. That's why I'm not going to focus on it. At least 1 student asked, "At the end of this course, will we be able to write JavaScript programs?" This question sounds simple, but actually it's surprisingly complicated. Yes! By the end of this course, you will have written a few simple, but honest, JavaScript programs. Lke the implementation of Euclid's algorithm that you've already done, over the course of the next few units, you'll get 1 or 2 more chances to write JavaScript--simple JavaScript programs. But mostly, we'll be doing that to make sure that we understand the correspondents between JavaScript and Python. One of the things that we'll hint at as this course progresses is that those 2 languages are actually equivalent in a very strong theoretical sense. Anything you can do in Python, we could also do in JavaScript and vice versa. Now when people say, are you familiar with JavaScript? Have you written a long JavaScript program? They're probably talking about the way JavaScript interacts with a web page, uses the document-object model to draw flashy animations or change what's displayed to the user. We're not going to cover that in this class. That's more of a presentation or user-interface issue. In this class, we want to understand the theory--the nuts and bolts-- behind various programming languages. So we're not going to talk a lot about how to draw buttons or how to make special text effects, instead we're going to talk about how to interpret functions and integers and strings. What if the user's Java program is recursive? Could we still handle that? And once you can handle a language that has variables and recursion and rich control flow and a plethura of meanings, it turns out that all computer science formal languages that have that power-- they're all equivalent. Anything that you could do in C, you could do in C++ or Java or JavaScript or Python. So you could work your way up to writing the flashy buttons, but it's not a topic for this class. There was a very interesting and wide-reaching question on the forums about the uses of lexical analysis and regular expressions and this general sort of string processing outside of what we're doing in this class. The essence of the question was, what else is this good for in the real world? Is it used to do anything interesting? And the question is actually a resounding yes. There are a large number of great uses of regular expressions and lexical analysis beyond just building web browsers or writing language interpreters. One of the most basic is in electronic commerce. I hinted at this in the beginning of Unit 1, but things like phone numbers and credit card numbers are recognized and processed using regular expressions-- essentially using lexical analysis. Break down a big input string from the user into something that you want to deal with. For example, users often enter their phone numbers or credit card numbers with hyphens in the middle, but maybe you want to get rid of all of the hyphens so that you can just treat it as one big number and ask about it in your database. However, quite a few other things make use of lexical analysis. Let me give you one you probably haven't thought of: virus detection. These days there are a number of adversaries out there in the world of computing-- people who are interested in taking over your machine remotely, perhaps for economic reasons. Maybe they'd like to take over your machine and use it to send spam or do something else malicious--delete your files, something fun like that. It turns out that the virus software you probably have running on your computer now-- that is, the antivirus software, the good stuff designed to keep away the evil attackers-- is based on regular expressions and lexing. In essence, in order to be relatively interesting, a virus typically has to have some sort of important payload, a part where it replicates and takes over another program, writing out something to the disk or changing data structures in memory. A virus definition file, which you may have seen your antivirus software talk about updating, is actually just a big list of tokens. For every virus out there, we write a regular expression corresponding to the machine code, corresponding to this payload that it uses to take over or infect other files. And a virus scanner is actually just like a lexer except that if you match any of those tokens, it's a bad scene. A virus scanner runs all of those finite state machines over executable programs before you run them or attachments you download from the Internet. And if they find any of those patterns, they stop and say, "Oh, I think this file may be malicious. Let's do something special with it." So virus scanning or virus checking also uses regular expressions. Here's a third use. String matching in general is commonly used for dealing with computational biology like DNA sequencing or protein folding. When we get pieces of DNA from biological laboratories, you can view human DNA or animal DNA in the world as basically just a long string over a very simple alphabet of 4 characters--G, C, A, T-- corresponding to special objects or special structures in the world of biology and biochemistry. And everything about us, we believe, in the physical world is based on the interactions or the unrolling or instructions gleaned from DNA, perhaps through DNA or RNA transcription. I'm not much of a biologist, but I know that these days a lot of biology research is done with the aid of or enabled by computers. So for example, if I want to check to see if 2 particular DNA sources have a relatively high overlap but when they come out of the biology lab these strings are a bit scrambled because they've gone through a physical process, what I essentially want to do is say, "Oh, could this blob of text over here "match up with this DNA text from some other person?" "Can I find the best matching or the best alignment?" And that task uses exactly the same sort of lexical analysis string matching that we've talked about here. But I can take it 1 step further. You might have wondered at some point, "How do we come up with new drugs?" "How do I make a better aspirin? How does that sort of thing go?" And while there are definitely in-lab scientific techniques involved-- you might imagine, "Oh, maybe I take some sort of test subject, "I inject them with my candidate medicine and see if they get better"-- that sort of trial is very expensive. It would be really nice if we could use mathematical models to help narrow down the search space to help get an idea for how drugs might interact in your body, how they might behave. And it turns out that a lot of chemical interactions at that level are governed by protein folding-- how various proteins will sort of rub against each other and interact or not. We can use computers to simulate protein folding and thus get a better handle on candidate drugs we're designing. Maybe we can use the computers to simulate a bunch of possibilities, come up with the best 10, present those to the scientists, and then those are the ones that we try on live subjects. That sort of protein folding experiment involves a number of the same sort of techniques that we're learning about here in lexing-- go over strings, do comparisons, do big simulations. And in fact, if you're curious about this sort of genome sequence alignment, string matching, protein folding sort of world, you might want to check out BLAST--B-L-A-S-T, all capital letters-- which is a common software project for doing just that. It's not necessarily the fastest, but it is one of the most popular. And then the final thing I would mention is there are a lot of very high level readability metrics, both for software and also for natural language text, that are based on the sort of lexing or lexical analysis or token definition principles that we've come to know. For example, one of the least expensive ways of figuring out the appropriate grade level for a book is to measure very simple things like the number of words in a sentence and the number of syllables per word. Then through some division and multiplication you can arrive at whether that should be given to a 10-year-old child or a 14-year-old child or whatnot to read based on expected reading norms. That sort of readability metric can be easily computed using exactly the sort of break a string up into words kind of lexical analysis that we've been focusing on. And that segues into the final part of this question. Students were asking about natural language processing. With the lexing and parsing, the lexical analysis and syntactical analysis that we'll cover in this class, do they carry over to parsing real-world languages like Japanese or English or German? And the answer is, to some degree, yes. Linguists or computation linguists are often interested in modeling real-world natural languages using the same sorts of formal grammars that we're going to introduce in Unit 3. Stay tuned. Fun stuff. And this question of breaking a sentence up into words is legitimately tricky in languages other than English. I hinted at this in some of the lecture material. But in languages like Japanese or in Latin where spaces might not be written explicitly, we really have to think hard about how to break down an utterance into its substructures. However, natural language processing is actually, in some sense, significantly harder than the unnatural language processing that we do here. Real-world languages like English are not well behaved compared to JavaScript. JavaScript is very artificial, it's very regular. We know just how it will go, what the nouns are and what the verbs are. In a language like English, that's very hard to figure out. So natural language processing is currently, to some degree, still in its infancy. There are still a lot of tests or a lot of tasks that we would like to be able to carry out on natural language that are hard to do. If you're interested in natural language processing, writing computer programs that look at human written documents and do something with them, a common task to start with is document summarization. For example, you might go to a news aggregator site on the Web and there's a really long article. Wouldn't it be nice if you could say something like, "Summarize this for me." "What's the gist of this? Boil it down to just a few sentences." That's one of the common tasks that natural language processing researchers try to solve. And it turns out that that task is very difficult. Sort of a straw algorithm, a cheap way to do it might be to just take the topic sentence from each paragraph and put them together, counting on the human who wrote it to have used a special structure where each paragraph is introduced by a declarative topic sentence. It turns out that that simple approach is actually relatively hard to beat because understanding natural language requires your computer program to have, in some sense, a model of semantic meaning or the rest of the world. People will sometimes jokingly say that natural language processing is AI-complete where complete has a special mathematical meaning. We may get to deal with jokes and puns like that in a later class on theory. Suffice it to say for now, to some degree, I'm actually glad that I work in the easy world of unnatural language processing. It's significantly harder to deal with the utterances we use day to day when talking to other people. Welcome to office hours, week 3. The first question we have from the forums is are the tools Lex and YACC that we use throughout lecture and in the homeworks used outside of the classroom? That's a good question, Peter. Actually, the answer is a resounding yes. A number of times in the real world as well as in my research career I have used tools like the lexer and parser generators we're learning about in this class, Programming Languages. And it turns out that there's effectively a standard, this notion of making lexical analyzers or making parsers. It's so common, it's so popular that there is support for it for almost every language. The original tool for this was called Lex, a lexical analyzer generator, and the name in there, generator, is important. The idea was you would just write out some regular expressions, and this tool would automatically make the finite state machine, the lexical analyzer, for you, saving you a lot of time and grungy implementation work of converting regular expressions down to finite state machines. It was called a lexical analyzer generator, but it was proprietary software at the time and it only worked for C. Similarly, there were many attempts to make compilers or interpreters, so it was really important to be able to write down a context-free grammar and spit out a parser, something that would recognize the language and make an abstract syntax tree or a parse tree. So there were a number of so-called compiler compilers, tools that would allow you to write your own compiler, and one of the most famous was known as Yet Another Compiler Compiler, or YACC. Both Lex and YACC were proprietary software, so the GNU Project made free versions of them called Flex, a fast lexical analyzer generator, and Bison, Bison being a pun on YACC, which were then very widely used. Initially, they only supported the languages C and C++. But as time has gone by, you can find them for many other languages, so for example, Ruby, a scripting language a bit like Python, as Ruby-Lex and Ruby-YACC. Python has things like PLY. Java has similar tools. CUP is an example of 1 of them. OCaml, a language near and dear to my heart that you may know as Microsoft's F#, has ocamllex and ocamlyacc. So exactly the same sorts of ideas. You write out a regular expression and then some code to do. You write out a grammar and then for each rule you write out how to build up the abstract syntax tree. That's exactly the same format that are used in the lexical analyzer and parser generator tools for all of the other languages. So the techniques that you're learning in this class really carry over directly. The next time you want to make a little scripting language you can use exactly the same sorts of things we've learned here. So yes, I and the real world use, more or less, exactly these tools depending on exactly the language we're targeting. During lecture this week, we learned about context-free grammars and languages and about parsing them. But is there anything beyond that? Is there anything other than the context-free grammars and the regular languages that we've learned so far? Is there anything more powerful? That's an excellent question. It turns out that context-free grammars are not the end-all and be-all of interpreting languages like JavaScript or HTML. In fact, just as we saw that regular languages and regular expressions weren't powerful enough to do everything we needed-- they couldn't handle balanced parentheses, so we couldn't use them for parsing-- it's going to turn out that context-free languages and context-free grammars will only take us so far, and we're going to use additional techniques like interpretation or keeping track of local variables in order to find other things out. Here's a great example of what the "free" in context-free actually means. You might think, "Boy, is there a context-expensive grammar out there?" "What's the opposite of free?" It turns out in this domain the opposite of free is context-sensitive, and it's going to turn out that the meaning of a program depends on its context. For example, suppose I ask you what's X + 2? The meaning of that program depends a lot on the local value of X. So we're going to need something more than just parsing, more than context-free grammars, to reason about programs that include substrings like X + 2. If right above it I've written X = 4, then X = 4, X + 2 yields 6. But if right above it I've written X = 0, then we'd get a different answer. That line above it is the context. Our context-free grammar doesn't care about the line above it. You can write down X + 2 even if you've never assigned to X before. When we go to write our interpreter for JavaScript and our ability to render web pages by interpreting HTML, we're going to need to keep track of the context, the values, the variables, what has gone before, our history. All of that is going to matter for figuring out the true interpretations of programs. So again, just as regular expressions weren't powerful enough and we needed context-free grammars for parsing, we're going to need something else, context sensitivity, to make our final web server. And we're going to get to that in around Unit 5 in this class, so stay tuned. At the bottom of each homework problem there's a note encouraging students to write their own test cases. How does one write good test cases? That's a surprisingly difficult question. It turns out that there is an entire area of software engineering practice and research devoted to testing. Huge amounts of money are spent each year on software testing. It's an amazingly expensive prospect, and thus, coming up with good test cases is really both an art and a science. Formally, the basic idea behind testing is to make sure that a program implementation adheres to its specification-- that is, that what you've actually written down does what we think it should do or what you were required to do. So if the goal is to make a procedure that finds the biggest element in an array, good test cases or a good test suite would give us confidence that you've done just that. Now, unfortunately, for interesting programs there are an infinite number of possible test inputs. For example, even if you're just trying to write a program to sum the elements of a list, there are an infinite number of possible lists of numbers that you could pass in as input. We don't have time to run an infinite number of test cases, so often we write just a few and hope that they're indicative in some sense. Or maybe we hope that they would be very powerful and help us detect errors if there are errors or bugs in our programs. So one goal for writing a good test suite for making a bunch of test cases is to say, "Oh, if I run all of these test cases, I'll have confidence that there are no bugs." That's easier said than done. How do we actually do it? One hint that I would give is to think about corner cases, to play a little game in your mind. Imagine that someone else wrote the program and they're trying to be deceptive, they're trying to sneak it past you and find mistakes. It turns out that the human brain is actually very good in the same way that we're very good at vision at finding or detecting cheating or deception when we think someone is working against us. Take a step back if you can from the code, pretend it's not yours, take another look, a fresh look at the specification, the statement of the problem, and see what you might check. For example, for numbers be sure to hit all the corner cases. Try 0, try some negative numbers, try some positive numbers, try some primes, try some composites. For lists be sure to try the empty list, all the numbers in order, all the numbers in reverse order, all the numbers in a random order. If maybe the inputs are grammars or strings, try some short strings and some long strings, some grammars with and without recursion. This is really more of an art than a science, although you may be interested to learn that there are a bunch of great research efforts in automatically constructing test cases. The basic idea is this: You give me your program, and I'm going to write another program that stares at it and notices all the loops and all of the if statements, and I'm going to try to generate inputs, maybe at random, that will cause you to take all the possible branches in your program. So if you have an if statement that says if X is less than 10, I will generate 1 input where X is 9 and another where X is 11 to force you to go down both branches. That way if there's something wrong on one of the branches, like you use a variable that hasn't been previously initialized, you're more likely to find it. And that field is known as automated test input generation, and it is still in its infancy. We have not solved it in any way, and that means that there is room for creativity. One of the themes in this class is that whenever there are an infinite number of possibilities but that we can't use all of them, like in a grammar, there's room for creativity. We have to think of the best ones. We have to do design under constraint. And unfortunately, ultimately, that's the best answer I can give you here. Try to think adversarially. Think about all of the corner cases. Available now are some practice problems in which I go through-- essentially I pose homework problems to myself and solve them. You can find them in the list of videos. And in each one I inject a bug, a defect, I make a mistake, and I show how I would use testing and debugging, print statements and whatnot to narrow it down. If you're curious or you want a little more practice with testing and debugging, check those videos out. So in lecture, we spent a lot of time learning about context-free grammars and languages. Can context-free grammars be used to do anything other than parsing a programming language? That's a good point, Peter, and the answer is yes. In fact, there are a large number of applications for language formalisms or context-free grammars. I'll just list 4 or 5 of them. One of the first is security. We saw last time that regular expressions can be used in virus checkers. And in fact, that's how the vast majority of virus checkers work. They're like a big lexer. It turns out that these days the most common attacks or exploits or vulnerabilities reported involve cross-site scripting or SQL--database--code injection vulnerabilities. Both of these involve an application, a web application like Udacity's servers, reading in a string from the user and treating it as if it were part of another important language like HTML or SQL, the language of database queries. It turns out that there a number of techniques available for using context-free grammars to detect if a string from a user is normal or if it's trying to take advantage of some special system structure if it's one of these attacks. And essentially, the way to do that is we pretend to parse the final string given the context that the user has provided. And if the user's changes, the string provided by the user ends up influencing a large part of the parse tree, of the abstract syntax tree, in essence, if the high watermark of the changes or the tainted information from the user reaches very, very high, then we know it's a SQL code injection or cross-site scripting attack because those attacks are based on destroying or conflicting or deforming the essential structure of the output language. So 1 possible use for them is in security. Some of the best ways to figure out if something is SQL code injection or cross-site scripting, let's say, before you actually run it and find out, involve the use of grammars. Another is in the world of optimization. A production compiler or interpreter is often very interested in getting the same results but faster or using less memory or--and this is a big one these days-- using less power. If you're running a program on your smartphone or some other mobile device, you really want it to last as long as possible. Later on in the class, around Unit 6, we'll actually cover some basic optimizations. I'll teach some of them to you, and you'll get a chance to use them in your JavaScript interpreter for the web browser. But for now, just take my word for it. In order to do optimizations, we have to figure out what the values and variables are. For example, if I can figure out that X is always 0 and you have a line in your program that says Y gets Y + X, I don't have to bother interpreting that line because I know that adding 0 to something doesn't change its value. That sort of thing is called a data flow analysis or an optimization, because if I can reason about how numbers flow through your program, then I can make them faster, higher, stronger, use less power. It's a really nice idea. It's going to turn out that the best known research idea for figuring out values as they flow through various functions in your program is related to context-free grammars or, more formally, context-free language reachability. It turns out that interprocedural data flow analysis is the same problem as, in a theoretical sense, context-free language reachability, which is the same problem as could I generate a string in a context-free grammar. It turns out all of you are experts at figuring out if we could generate a string in the language of a context-free grammar, and exactly that sort of knowledge is one of the things program optimizers use to squeeze every last drop of goodness out of a program. Third possibility is in linguistics or computational linguistics. There are a number of references to these underneath the lecture videos, but it turns out that a lot of these notions of context-free grammars or generative grammars or universal grammars actually came out of psychology or linguistics or computational linguistics to help us understand human and natural language. And it's a really important use. But let me skip past that one since it's too easy in some sense. I'll give you 2 more. One more--near and dear to my heart--is specification mining. It turns out that often we want to figure out what a program should be doing just by looking at its source code. And this is super tricky. It's like trying to learn the rules of English grammar by reading a bunch of high school student essays and looking at what they get right and get wrong in common. As you can imagine, it's very difficult to get this perfectly because just because a number of students say something doesn't necessarily mean that they're following the rules. They might all get it wrong the same way. And if you've seen people post on forums, maybe not everyone has perfect grammar. So just taking samples might not be the right way to do it. It turns out that the output of specification mining often takes the form of a formal grammar or some sort of state machine: You should always call open and then you should call close. A lot of important security or software engineering policies can be described in terms of some sort of grammar. It turns out that learning grammars from examples is really, really difficult. Both that and this notion I mentioned earlier of interprocedural data flow analysis are the sorts of things that one might get into in a subsequent course after this one but where you'd build on the knowledge you learned here. Here's my last example, and this one is perhaps the farthest from the norm, but I think students may appreciate it. It turns out that if you're using a cellular phone, people might be able to intercept what you're saying if they just listen very hard. So these days, modern cell phones or mobile phones might try to encrypt the data packets that they send containing your vocal information so that, in theory, eavesdroppers can't figure out what's going on. However, if I've used a lot of that computational linguistic information, if I've studied the world, it turns out that in different spoken languages or with different accents we have different patterns of speech and then pauses. And some of the initial implementations of phone encryption tried to be smart and save power. They would only send information when you actually said something. So this meant that attackers could listen in and, using linguistic analysis information, even if they couldn't tell what you were saying, even if it was all scrambled, just by doing a statistical analysis of how long you said and then how long you paused and then how long you said again, we can reliably identify what language you're speaking and, worse than that, regional accents--say you're speaking English-- whether you're speaking with some sort of New York/Brooklyn accent or from the South or from California. We can tell based just on the patterns of how long you speak and how long the pauses are. That has very unfortunate Orwellian implications for some sort of surveillance state. Conveniently, it is more or less totally defeated by encrypting the silence as well-- using more power to just get rid of that side channel, prevent people from figuring out when you're speaking and when you're not. But that's an example of an application that also uses this sort of linguistic analysis-- perhaps a little less related to context-free grammars but still in the same vein. All in all, context-free grammars, context-free languages come up in significantly more of computer science than just parsing. Welcome to office hours for week 4. I noticed that Units 3 and 4 were quite abstract. Will the remaining units in the course be similarly abstract? That is a good question. Units 3 and 4 were relatively abstract-- to some degree, intentionally so. We wanted to cover the basics of grammars, context-free grammars, how we might parse them ourselves-- and we taught you a particular algorithm for that in class-- and then how to interface with a tool that uses a similar algorithm and then given a context-free grammar and a description of how to build a parse tree or an abstract syntax tree puts it all together. That was difficult material. And if you thought it seemed a little more abstract than the rest of the course, you are absolutely right. And part of that is that we want to challenge you. This is a world-class education, and these are the sort of concepts that we would go into at a top-tier university covering these topics. We want to make sure that you understand languages from the inside out and thus that you can manipulate in your mind grammar rules-- the backbones, the essential syntactic constructs of languages. We want you to know them, how to change them, how to implement them. That said, the course really does go up and then go back down a bit in terms of level of abstraction or difficulty. In Units 5 and 6, we're going to turn our attention to interpreting parse trees, interpreting abstract syntax trees. What comes next after a parser? Well, we try to figure out the meaning of a program. We'll look at interpreting HTML, interpreting JavaScript, as well as fun, off-to-the-side software engineering tasks like debugging programs and also optimizing them to make them go faster. I think you'll find that Units 5 and 6 will be significantly more concrete and grounded than Units 3 and 4 and possibly even a little easier. Why are we bothering to write an interpreter for JavaScript that just runs Python in the end anyway? Shouldn't we just write our code in Python directly and skip the middle step? That's an interesting idea and one that I think gets to the heart of language design. Programming languages, as we know them, are actually relatively old in the history of computer science. John Bacchus starting with speed coding, perhaps the first interpreted language, in 1953 and moved on to FORTRAN, which is still alive and going well, in around 1957. Around the same time Admiral Grace Hopper made the first compiler around 1952 and started really promulgating languages like FLOW-MATIC in 1957. Let's imagine that we transplant this question back in time. You're in the '60s saying, "You know? If I write this program in FORTRAN, ultimately it gets interpreted in assembly language and machine code. Why should I bother with FORTRAN? Why not write it all in assembly language?" Or these days more modern languages like Java were initially implemented in languages like C. Why bother with Java, if we could write everything in C? It turns out that all of the modern programming languages that we are considering-- Java, C++, C#, F# -- are all Turing completed, a term I won't define in this class explicitly, but it deals with Turing and models of computations--they're all equally powerful. Anything I could do in one language, I could do in another. Now it's a matter of choice and expediency. Some languages make it easier to write somethings or say some thoughts than others, and some make it easier to do it with fewer errors, and that's where I think the key motivations for modern languages really come from. I think in the future, we're going to see an explosion, a proliferation, a profusion of domain-specific languages--languages that aren't trying to be C or Java but are trying to solve a very particular problem and do it quite well. There are already a number of languages out there for dealing with mathematics, things like MATLAB or Maple or Mathematica. There are a number of ones out there for describing graphics. Game design actually has a history of using a number of domain-specific languages going all the way back to QuakeC from John Carmack. Even more modern at the time of this writing, modern games like Skyrim feature their own languages for describing events and quests-- Papyrus--check it out. Although they're based on relatively old programming language concepts. Another more modern example is there are a number of hardware definition languages-- VHDL and Veralog. Whenever Intel to some degree decides to design a new chip, they use a hardware definition language rather than C or Java or Python to describe it. These domain-specific languages hold out the promise of having higher-level operations and of helping you catch common mistakes. That's really important in economic terms for saving money in software engineering. I want to make it take less time for you to write the program, and I want to reduce the number of faults that we're going to find in it later. I think one of the advantages of more modern languages over something like C is that they feature higher order datatypes. In Python if you want a list or a dictionary it's easy to write it with just a little bit of syntax. In C you'd need to have those datatypes prepared or do all of the allocation yourself. It just takes longer, and it's easier for errors to creep in. I think one of the things that's been driving changes in programming languages over time is that we're recognizing that correctness is often more important than speed for many applications. Speed is still critical, but bugs can be really expensive. Especially in the financial district or in mission-critical applications. If you're making an airplane autopilot or an artificial heart pump. Languages where one line of code creates a dictionary and initializes it with some value save you a lot of work. You don't have to write out all of the lines to create that dictionary. As a result, you don't have to write out any lines with bugs in them. The fewer lines you can write, the more you can just declare your will and have the compiler fill it in, the happier I am. I think that there is a real reason to keep designing new languages, even if we bootstrap them on top of the old ones, because it might be easier or more concise to think a thought in the new language or because the new language might help us reduce errors or software engineering defects. Even thought our simple JavaScript interpreter is ultimately written in Python, webpages typically include JavaScript rather than Python, it's handy. People find it easier to write in one of these languages rather than the other, even though they're all Turing complete and can express the same computations. It's kind of a deep question and one that gets to personal choice and creativity. Sometimes we just prefer one language over another, even if they're all ultimately the same. In class we studied parsing using memoization, but I've heard in the real world many tools use techniques such as LALR(1). Why didn't we learn those? That is a good question, and actually there are a number of answers to it. I'll enumerate maybe five of them. One of the first is that this memoization or chart parsing technique that we learned is actually very similar to--almost isomorphic to-- some of the more advanced techniques used in practice. You can read up on or you may have heard of GLR--generalized LR parsing. That's commonly used in tools such as Oink--the real name for a software project, go check it out--which can be used to parse complicated languages like C++. It turns out that C++'s grammar doesn't really easily fit into these restrictive little cubbyholes that some of the faster tools prefer. It can really be a contortion that distorts meaning to try to get C++ to fit into one of these other tools. By teaching you a very general technique earl on that can handle any context-free grammar you know how parsing works even in these obscure corner cases, and I'm teaching you the approach that used in the more advanced tools. Another reason related to this is that all of these tools have the same interface. If you want to go try Oink out later on, it accepts this same sort of context-free grammar format that we're used to. So does Yacc. So does Bison. So does Ocamlyacc. So does Java CUP. So does RE Yacc, Ruby Yacc. I've taught you the way to phrase it, and then the particular tool under the hood can use whatever parsing algorithm it prefers. In the same way that we write regular expressions--ab+-- and then depending on whether we're writing a PERL program or a Python program or some other program, it might convert that regular expression into a finite state machine slightly differently, but we know what the final output is going to be. We know what strings are going to be matched. Similarly here, when you write your grammar, regardless of what parser-generating algorithm is eventually used, we know what the behavior is going to be. That's what we've covered in this class. There's a related argument. You might say, well, why are we using Python in this class when the real world uses C or Java or C++ or whichever language you think is commonly used in the real world--perhaps C#. That's the same argument here. Why are we using this chart parsing, when the real world uses these slightly different tools. This is a big question in education and pedagogy. I honestly believe as a practitioner and a researcher that there is a key difference between knowing how to program and knowing how to program in a particular language. The former is much more important. If you know how to program in Java, if you survived this class, you can pick up another language like Ruby, Java, Python, and do the same thing-- knowing how to program, thinking about recursion, thinking about laying out data, thinking about algorithms. That's much more important than knowing the particular syntax for any language. Similarly here, I believe that really understanding context-free grammars and parsing is more important than knowing which particular parser generator tool implementation is being used under the hood. You know one particular algorithm for creating parsers, and that may as well be the one that's used in practice. Another reason that I focused on this algorithm is that it is simple. It relates grammars to parsing, which is one of the concepts in this class. We lay out context-free grammars, but now we need to be able to tell if a string or an utterance is in the language of that grammar and build up its parse tree. It's only a few lines long, and it allows us to introduce lovely concepts like memoization or list comprehensions. A number of you might wonder, if we were to write our parser in another way, maybe you've heard of techniques like recursive dissent or even using LALR(1) grammars. Would it be just as convenient? I have done them all, and the answer is no. By no means is a recursive dissent parser or an LALR(1) grammar for the language fragment that we're considering here, as easy as the parsing algorithm that I showed you. Now, this is in fact the most elegant approach. Then finally a number of students were concerned about the time taken by our parser, which is cubic or runs in time proportional to the size times the size times the size of the input program, in the worst case for an ambiguous grammar. Now, this is bit beyond the scope of this course, but it's worth pointing out that these other tools that claim to be faster, it's not actually a fair comparison. The parsing algorithm I taught you handles any grammar. The tools that claim to be faster don't. They only handle special restricted grammars. An interesting note that I didn't cover in this course, but that's nonetheless true, is that the particular parsing algorithm that we covered also runs in linear time, is very fast for the same small class of grammars--LRK grammars they're called-- that are accepted by these faster tools. If you were the sort of person who would take all the work and time required to shoehorn your language's description into the particular straight jacket format favored by these other faster tools. The faster tools are actually just as slow or just as fast--your choice-- as the algorithm I taught you in the limit. Their asymptotic complexity is the same. They're both linear time. You don't loose anything in terms of time either. Again, getting back to the first point, I think it's more of an historical accident that most of these tools happen to use LALR(1) or other hacks for speed in practice. In the last few years--the last 10 years, say--research has focused increasingly on GLR parsing or this sort of chart parsing that I've shown you as a way of allowing people to write the grammars that they want, get linear time, super fast performance most of the time, pay a little bit when things are ambiguous, and then get on with their lives. If foresee that languages like C++ or Java or whatnot-- more complicated languages--will be analyzed using tools like that in the future. It's my honest believe as an educator that I'm teaching you the right approach, teaching something like LALR(1)--that information is really not necessary in the modern world, and it's log--those lectures feel like they go on forever. By contrast, this chart-based approach is elegant, simple, allows us to introduce fun concepts, handles all grammars, which the other approaches do not, fits in just a few slides, and is just as fast in the limit. What's not to like? I don't have any big questions left. Are there any smaller questions you'd like to address? All right, Peter. Since you phrase it so eloquently. Some students have wondered or they've heard acronyms like "LL," "LR," or "LALR" bandied about--perhaps on the forums or mentioned by other students who have taken similar topics, and you might wonder, what do those mean? Those acronyms are all subsets of context-free languages or context-free grammars. They're grammars that are written in a special way to make them easy to parse. The parsing approach that I've taught you in this class where we build up the chart of parsing states and memoized things can handle any of them. It handles LL. It handles LR. It handles LALR. And, in fact, it handles context-free grammars. I think a lot of those previous approaches--LALR in particular-- are really historical accidents. They were restricted classes of grammars that engineers made back in a time when computers were significantly slower, and we had to squeeze every drop of blood from the turnip that we could. We had to squeeze every ounce of performance that we could out of the hardware available. We said, oh, it's better if I, a human, spend a lot of time refactoring my grammer to make it easy for the parsing algorithm. These days I think your time, the human's time, is more important than the computers. I want to be able to write down the grammar naturally as a context-free grammar and have it parsed. In this course, we don't focus on LL, LR, LALR. Those are really historical accidents for performance that aren't relevant anymore in my opinion. We handle LL. We handle LR. We handle LALR. Everything works well in this class. A related question is in this class we covered a parsing approach where we kept a chart of parsing states and we memoized things. Some students have wondered, Wes, is that secretly dynamic programming? Now, some of you may not have heard the term dynamic programming before, and it sounds really exciting, like something out of a television commercial. I'm dynamic and I'm programming. How does that work out? Actually, it's an old term where program means more like table or chart. The way to think of this is imagine you're going to a parade or perhaps a symphony or a concert or whatnot, and there is a program written that says at 1 p.m. we'll do this and at 2 p.m. we'll play this other song and at 3 p.m. we'll do that. That's the program for a concert or the program for a schedule of events. That's the sort of program that we're talking about in dynamic programming. It just means a chart. Dynamic there means that it'd updated over time. Dynamic programming is then a special keyword used in computer science to mean I'm going to solve a problem by taking a big chart and writing down answers in it and adding to this chart over time. Dynamic programming is really useful when a problem exhibits what's known as the optimal substructure property. That is, when I can deal with one problem by solving smaller problems and then build the solution back up. Interesting examples of this in the real world are things like spell checkers, protein sequencers, or even trying to figure out the correct or in which to do matrix multiplication. It comes up a lot surprisingly. It turns out, yes, although I've been avoiding using the words in class, our memoization approach to parsing really is an instance of dynamic programming. You've learned your first steps about dynamic programming without it even being a big deal. Then finally in this grab bag, some students have wondered can we compile an interpreted language or interpret a compiled language? What do those even mean? Well, we've talked quite a bit about interpretation. We interpret HTML webpages and JavaScript on the fly. When we're running our web browser, we read in the input, think about what it means and spit out the answer immediately. In practice, it's possible to do some of that in advance-- to take your source code and build an executable program--some binary code on disk. That you can ship to someone else, and when they run it later, it will produce the same output but run really quickly. In some sense it's like thinking very hard about the problem, optimizing it once and for all, and then shipping it to all of your friends. Compiling is a lot like packing really well for a trip. You could just make a bunch of trips back and forth, carrying all your clothes, or you could spend a lot of time in your house beforehand packing a suitcase very carefully, cramming it in there, and then just make one trip. The question or the tradeoff is, well, how far are you going? If you're going across the street, it might actually be faster just to grab things and run back and forth across the street if the program is quick or whatnot. Conversely if you're going across the country, you probably want to pack things very carefully first because the round-trip cost is expensive. Compiled languages are very nice when you know that the program is going to take a while to run that you're going to ship it to other people. Interpreted languages like Python or JavaScript are really nice when you know it may only be run one or by one person looking at the answer and that rapid prototyping or rapid development is more important. You want to be able to try things out and have a lot of flexibility. Can you interpret a compiled language or compile and interpreted language? In fact, the distinction is really blurring all the time. Even Python, one of the languages we use in this course, nominally gets interpreted. You run things through a Python interpreter. It gives you the answer. But actually if you've tried running Python on your home computer, you may have noticed that it often creates a bunch of .pyc files. That's compiled Python byte code. Your Python interpreter will take a look at your human-readable English text source code, and if it has changed since last time, compiled it down into Python byte code, and then the byte code can be run quickly later. It's a lot like packing things into a suitcase. Java actually uses the same approach. Java source programs are compiled down into Java byte code, which is then interpreted by a Java virtual machine later on. Even a language like C--a classical compiled language--we compile it down into some machine code like X86 assembly or X86 machine code, but that's just interpreted by your processor's CPU later on. In some sense at the end of the day everything is interpreted. The question is just how much of this compilation we want to do beforehand. Again, optimization techniques like just-in-time translation or just-in-time compilation-- you may have heard this phrase JIT-- to blur the lines between these as time goes by. All of the techniques that I'm teaching you--lexing, parsing, looking for errors, optimization, interpreting, environments-- all of these are used in both compiled languages and interpreted languages. We'll get to all of those throughout this course, and then you'll be well-set to understand either of those two paradigms. Hello! Welcome to Unit 5 Office Hours. I'm Jonathan, an assistant instructor for an upcoming course. Peter is out of town this week, so I'll be handling the Unit 5 Office Hours this week. First question, how's that readability survey coming? It's a great question and relatively timely. It turns out that readability survey, the research project that we give everyone a chance to be involved in, is going really, really well. Over 6,000 people have started taking the survey, and over 2,000 people completed it all the way through, and the results are still coming in. Again, this is officially unrelated to Udacity or your grade. It's totally optional, although it would make me so happy if you would take the survey--still totally optional. We have a number of students with no experience taking the survey, which is great. We have a number of students with quite a bit of experience, and we even have interesting students who appear to posses the power of time travel or have made slight typos when filling it at the end how much experience they have. There are people who have more years of experience in Python than Python has actually been around--presumably Guido's father or something like that. We are pleased as punch with the current results of the survey, and I think it speaks to the charity and the kindness of students at Udacity and elsewhere who are interested in helping out with this sort of thing. My graduate student, Jonathan Dorn, and I will definitely be giving the song reward later on. However, since this is a family, show since anyone could be signing up for Udacity classes, a number of the more interesting suggestions for things that we will sing even though they're more humorous and outlandish may have to be pushed aside because we, in essence, want it to be rated G at the end. Still cast your votes for how you would like us to sing or otherwise reward you, and let me just once again thank everyone who took the time to participate. I know it did take time, and I know this sort of survey or research might seem hard to understand when you first get involved in it. Why is he asking me these questions? Why is he not showing me the entire context of a function? Why doesn't he define what readability is? All of those things that appear to be tricky about the survey or about the study were set up that way in order to help us scientifically isolate or control for various variables. It's tricky, and I'm glad you took the time to do it, and I think it will help us out a lot. We've had more than an order of magnitude more people participate in this survey than previous similar surveys in software engineering. It is a really exciting time and it seems that classes like the classes here at Udacity have the opportunity not just to transform education but to have an impact on research near and dear to my heart on both fronts. Why do you believe the future of programming language design lies in domain specific languages when we can just do operator overloading and APIs in a general language like C? Well, that’s a tough question and actually there is a bit of philosophy or opinion here. In class, we keep brushing against Turing completeness, and it turns out that languages like C++ or C# or Java or MATLAB are all going to allow us to express the same computations ultimately--that is, if it’s possible to do it in one language, it’s also possible to do it in the other, but that doesn’t say anything about how easy it is, how much help the language will give you about making mistakes, and how quick the final result will be. In my opinion, three important features that the domain specific language gives you over just coding up special types or operations in a general purpose language like C++ or C# are the conciseness of the representation, the ability to do type checking or run-time checking or otherwise have safety built-in, and the ability of the compiler or run-time system to do optimization. Let's take something like MATLAB, which is very good at doing mathematical operations or matrices or matrix multiply in a concise manner, and take it as sort of a running example. You could code up the same sorts of operations, matrix multiply, and language like C or C++ and C#, and you might start out by having them the functions that take a number of arguments in making your own data types. And to that, it’s relatively clear that languages like MATLAB, which just like to use the star to multiply two matrices, is going to be more concise. However, once you start adding operator overloading or feature of languages like C++ or C# that allows you to change the meaning of symbols like plus or stars that they, in essence, call functions you define. Then, the conciseness argument is more of a wash sort of a tie for both ends. However, the other two aspects, type safety or type checking and optimization, are still really critical. A language specifically designed to handle Mathematics or matrices something like MATLAB is going to be able to notice potentially more easily if you make mistakes related to that particular domain. For example, in C or C++, often a two-dimensional matrix in array is really just a single array carefully embedded. There's some sort of stride or approach where we reuse the elements of the indices in a very long one-dimensional array as if it were a two-dimensional array. And it is really easy to make mistakes to pass in arrays or matrices that have the wrong dimensions to matrix-matrix multiply, to confuse row major order and column major order, and language like C or C++ depending on which matrix implementation you're using won’t give you any support with that. It will silently let you shoot yourself in the foot. Compute the wrong answer. You might not even crash. You might just get something you’re not expecting. And that’s really problematic because these days the constraint is often programmer time rather than CPU time. I’d rather use a language where these things are built-in as first-class citizens, and there’s the possibility that it will alert me to error. Many of you may have a favorite C++ or C# or Java matrix library that would catch those errors. Again, ultimately, since these languages have equivalent expressive power, you can add that sort of error checking to any language or library. But often domain-specific languages do a better job at it. And the third example is then optimization. The higher-level instructions you give to a compiler or interpreter, the more scope it has for creativity, the more chances it has to reorder your statements or implement them in other way, the closer you can get to just being declarative. I want to multiply these matrices, and I don’t care how you do it. The more the compiler under the hood is able to take advantage of things like memory hierarchies, caches, special multimedia instructions you might have in order to get that sort of thing done well under the hood. If you actually write out your matrix-matrix multiply as three nested for loops, you’re forcing the compiler to generate code for that particular implementation. Often domain specific languages allow you to express things like matrix transposition or multiplication at a very high level. And thus, they actually end up generating better code for new target architectures than you might do if you were to code it up yourself. So you end up spending less time writing. It’s concise. You get guarantees, and it’s faster. And in fact, you can view the push to domain specific languages as just an extension of the push from assembly languages to high level languages. One of the first arguments made in favor of higher level languages were early studies in computer science that found that the number of lines of code that programmers could write per day essentially over the lifetime of a project was constant regardless of what language you are using. You could either pay your programmers and get ten lines of assembly or you could pay your programmers and get ten lines of C or ten lines of Python or some such. And if you have experience with multiple languages, typically you can get significantly more done in ten lines of Python than you can in ten lines of assembly because of built-in support for dictionaries or lambda, higher order data types, object-oriented programming, that sort of thing. Ultimately, you can get everything done with assembly, but it would take longer. The same argument here applies to domain specific languages. If I have a new more exotic domain-specific language, let’s pick MacroLab. That's a favorite one of mine for programming wireless sensor networks for moving data around and performing distributed computations. Let’s say for example that you want to keep track of people passing through your storefront advertising window to see if it’s actually working in attracting people. You might make up some sort of wireless sensor network to keeps track. You want to write programs for that. You could do them and see your assembly language or you could use this sort of domain specific language since it has notions of distributed computation where data lives, sending information back and forth, built-in as primitives. It’s able to check mistakes for you, generate good code for you, and in general, improve your productivity. Could you get all of that done with a well-crafted library? Yes. And in some sense, ultimately at the end of the day, maybe there is no difference between the well-crafted library and a domain specific language. But I think we'll see a lot of the initial effort or improvement common to domain specific language side and then the libraries will follow and catch up. In our JavaScript interpreter, we used exceptions ro implement return statements. Is this bad? Should we be using Python if we have to do this? Well, there is a lot of language-level exception handling in the real world. I don't think it's a reason to avoid Python or claim that one language is more dangerous than another. Language-level exception handling is super popular. It's actually goes back to Goodenough in 1975 who introduced a replacement model. That is an amazing family name. I wish I had that name. And since then, a number of languages have allowed you to deal with programmer errors and environmental concerns--both of which are often lump under the category of exceptions at the language level, and this actually is super handy because the previous approach involves sort of setting and checking global flags and programmers are very poor at remembering to do that consistently and correctly. Even with language level exception handling, it turns out that programmers make a lot of mistakes. One of the personal hypothesis is that this is because the control flow for exception handling isn't visible. When you're looking at the code, you can tell the control is going to flow down to the next line. if there's a statement in Python it's indented over. But exceptions really represent this sort of nonlocal jump to somewhere else and the indenting of the coder, the structure of the code may not make it clear. And if you're not aware that code can jump out of one line and go to another. You may forget to reestablish some in variant or close some important file or finalize a day of the structure by the end. And in fact, even a number of years ago, when I was doing my dissertation on the subject-- Oh, tragically boring--open source job of programmers tended to make on the order of 800 mistakes per 4 million lines of code related to exception handling alone. And in fact, exception handling is so prominent that if you look at an average program somewhere between 1% and 5% of the text of that program will literally be catch and finally blocks. That may actually seem low but typically a catcher or finally block, if it's not just empty will call some error handling routine and in large pieces of software, anywhere between 3 and 46% of the program is transitively reachable through methods calls or what not from catch and finally blocks. If you're interested in writing large robust pieces of software that get deployed in the real world, You will spend quite a bit of time dealing with handling errors. Language-level exception handling is at least for now much better than the alternative for that sort of thing. Is this a reason to avoid Python? We saw in class that we could use something like exception handling to deal with interpreting JavaScript return statements in our Python JavaScript interpreter? No, I wouldn't devoid Python as a result. In fact, even nominally friendlier languages like Java are potentially worse. You may not be aware of this Java actually still has GOTOs--go check it out. You can put in labels and then reuse the brake statement if you're given an argument to behave like GOTOs, so even though nominally more typed safe, more structured languages are supposed to avoid that sort of thing. In practice, a lot of real world languages be the Python or be the Java have their secret dark corners allowing you to write unstructured spaghetti code. This is nothing particularly bad about Python or particularly bad about JavaScript. It really gets back to this almost philosophical issue that sometimes when you detect an error, you don't have enough time, you don't have enough context to deal with it. That's really the motivation for exception handling. When I'm in the middle of some low level codes that fails to write something to the disc or fails to send something over the network, I don't know if should retry. Why not? Depends on the rest of the application semantics. If it's some sort of network maneuver may be I want to sleep for five seconds and try again, or if it's something like voice over IP like Skype may be I don't want to bother, may be I'll just wait for the next packet to arrive. I can't know unless I know more about the application semantics. So exceptions allow me to throw that notice of an error up and hopefully someone else who has more information will catch it--that's generic to the experience of programming. It's not particular to any one language so I wouldn't hold it against Python or Java or even JavaScript. How much more work would we have to do to turn our course projects into something more like the web browsers we use everyday? That is a nice question, and it's great to see students enthusiastic about extending the course project. To get the key ideas across in the amount of time given, we restricted attention in the course project to building a static web browser like the sort of web browser you'd see on an electronic book reader not particularly interactive, more concerns with downloading the web page and rendering it. Let say though that we wanted to work on the project in our spare time and extend it to become something a little more interactive. If you're interested in that, I would encourage you to look at two old-styled web browsers, Elinks and Mosaic, the precursor to Netscape or Firefox. Elinks is an old text-based web browser. Mosaic was one of the first visual web browsers. Take a look at those and see the sorts of user interface options that they offer to get an idea for what the bare minimum is for working web browser. Let say though that we want to do it together. In my mind, the first step would be to add the ability to have the user click on links. We can already read in a web page. We can already render it out to a nice image. Let's say, though, that we didn't worry about back buttons. We're not worrying about bookmarks. No cookies. Nothing fun like that. No foreign input. We just want the user to be able to navigate around the web by clicking on links. How do we do it? Well, right now our web browser is more of a batch processor. You give an input to web page, and it produces the image and then it's done. We want to add a little loop at the bottom that said "Wait for user input. Wait for the user to click on the screen." And let's imagine that through our GLE library or our graphics library or through talking to the operating system or the windowing system, we would receive some sort of notification whenever the user clicks in our window and probably we get information like the X and Y coordinate of the mouse click and whether or not it was a left or right click. So we need to build up some sort of mapping from locations on the screen to whether or not they correspond to href tags, links, the text displayed underneath them, and we could do that while we were displaying the text on the screen. If it's mostly images up here but then suddenly there is a link in the middle, we want to remember, by the way about half way down the page, if the user clicks there, it's a link, and we should know where to go next. How do we know where to go next? That's just the href argument from that particular tag. We already got that information at the lecture level. We passed it to the parser, and we have it when we're interpreting. We just stored in some sort of mapping off to the side. Let's imagine that the user clicks. We check our little page to link mapping. If the user is clicking in the margins or in the white space off to the side, we don't do anything. But if the user is clicking in an area corresponding to a link, we fetch the value of the target location. We say "Oh, it's something like http.google.com.index.html." And we open up a network connection in order to fetch that web page. If you took CS101 at Udacity, you may remember how to do that. But if not, it does not take that long to pick it up. And ultimately, we'd end up getting out a new string, a new file, corresponding to the contents of that web page, " Welcome to my web page", that sort of thing. Then we just call ourselves again and render that new web page and display it on the screen and then refresh our little mapping off to the side that maps screen coordinates to links. And if we have this kind of power, then the user could click and navigate their way through the web and then maybe eventually we want to add things like back button, which would just require us to store lists, even lists of strings, of places the user had visited previously. You can imagine starting to add abilities like clicking to navigate through the web, going backwards, going forwards again to the framework that we've already set up. And it would be pretty much as simple as adding a controlled loop to the bottom of our existing batch web browser. Now, let me give an idea of something a little more complicated under the hood The graphics library that we are using to lay out text actually does a pretty good job of-- if you're saying a lot of words, "Welcome to my web page," eventually will reach the end of the screen, and it will wrap over to the next line. Just like the word processor or a normal web browser. You might wonder, how do I do that? If I know the pages 18 inches wide, and I have a lot of text, and I know how big the font is. It's a 12 point font all of the letters to this wide. How do I figure out how many words to put on the first line? How many words to put on the second line? That sort of thing. That problem is called the word wrapping problem or perhaps more formerly the minimum ruggedness word wrapping problem. And it turns out that the human eye prefers column layouts that are not rugged on the side. You don't want it to be over or under--that kind of thing. Instead you want nice, even columns like a newspaper or like a magazine article that looks more pleasing to the eye. Well, in an incredible surprise move, it turns out that we can solve this problem using-- guess it--dynamic programming, memoization. There is a mathematical equation you can write down that sort of penalizes you for not having smooth columns and then we can try a bunch of different layouts--which words I put on which lines-- and just memorize their "badness" values, how ugly they would look to the human eye. And at the end of the day, we just take the one that looks the least ugly. And it turns out that that's actually how professional typesetting pieces of software like LaTeX or Microsoft Word solved this problem. We want to do some of those things under the hood to make our output look good, and we want to add support for things like clicking and following mouse clicks to navigate the web. But ultimately, we are pretty much there with having a web browser that similar to some of the earliest historical web browsers like ELinks and Mosaic. When we were writing our interpreter, we saw that JavaScript lets us modify global variables from within a function. Does this have security implications for our browser? Oh yes, there are very tragic--very problematic security implications of the ability to overwrite or even read from a variable that you're not expecting. Especially when you have a program written in JavaScript or something like PHP, another language commonly used to write web applications, that's outward facing--where adversaries can keep poking you until you fall over. One of the historically most common ways this came up-- and I'll use PHP as an example. In PHP--was known as registering or register global variables. Early on, PHP was commonly used to write code that would respond to web forms. Now if you're not familiar with web forms, just think about registering for an account online or maybe buying some food or buying a book. You often have to fill in things like this is my name, this is my address, this is my credit card number, here's how much I'm paying, here's how much I'm tipping. You write all of those things in text, and then some computer program on the other side is going to do calculations on them. For example, maybe it's going to add in sales tax, or calculate how much shipping is going to be, or figure out when to send you some email later based on the time and your zip code and the particular shipping company-- any sort of business logic in the middle. In order to do that, though, it needs to know what your zip code was when you entered it in the form field or how much money you said you were paying. So we need to get that information. In order to make it very simple for early PHP programmers, if you wrote your web page and said name here--this is the name field-- zip code here--this is the zip code field-- it might automatically make global variables in the middle of your PHP program called Name and Zip Code. Then you could just read out of them and get whatever the user had posted in the form. This was super convenient, but also super deadly. It is phenomenally easy to take over a web page or otherwise maliciously attack a web page or a web application that uses this sort of register global variables behavior. One easy way to think about this is, the values of these variable aren't set by the programmer, and they may not be validated. You can't trust people on the web to always put in an exact integer for their zip code. You can't trust them not to make up fake form fields that weren't really there that contain things like am I cleared or password credentials or how much money should I give this user or what's the sale or whatnot. In essence, any bit of business logic that you had in your program, they could fake up new values for it. You thought you were giving a 10% sale, suddenly you are giving a 110% sale--worst case sort of scenario. So this register global variables approach turned out to be a really poor design decision in early versions of PHP. These days, it's more or less off by default, but still it's what a lot of people think of when they think of global variables that we don't necessarily have control over where reading or writing them. But so is some adversary. Now this can definitely lead to security problems. Now these days, even if register global variables isn't a PHP feature, PHP programmers will still find fun ways to make the web insecure. Functions like Explode, which are very similar to things like String.Split in Python, are often used to assign to local variables, trusting the user or trusting the person on the other side of some sort of web interface to be well behaved. One of the big problems with computer security is that often the adversary is not well behaved. We have to pay attention and validate these sorts of strings. So this issue that you saw in class, relating to when can I change global variables, when are they in scope, am I going to get the value that I expect or make a new one. Now this can have unfortunate security implications. So it's worth understanding exactly how it works. Hello, I am Peter Chapman, your assistant instructor for this course on programming languages, "Building a Web Browser." You may have seen me on the forums and kind of managing the course in general, but one of the major things I do, helping you learn this material, is going over the homework answers. With that said, let's get started with the first problem on the first homework assignment, and that is a multiple choice question on general concepts covered in the first lecture. Statement 1 says, "Web pages can control their behavior and appearance through embedded JavaScript." This is definitely true. Almost any web page that you use on a daily basis has tons of JavaScript that make things nice and interactive and speedy. If you were to visit, say, our web site without JavaScript enabled, there would be almost nothing you can do. Nothing would load. Nothing would be interactive. And it's really not an overstatement that JavaScript is the basis for modern web applications. Statement 2, "While English sentences can be broken up into words, HTML and JavaScript cannot." This statement is false. Let's look at a piece of HTML to show you why. Here we can break up this sample bit of HTML into smaller pieces, namely the beginning of the bold tag, the actual text that says "Irvin," and the ending of the bold tag. Individually, each of these things has meaning in the same way that the sentence above, the word and, allows HTML and JavaScript to together be applied to the cannot. Some of these words have semantic meaning. Others are more syntactic structure. But nonetheless, they're words, just in a different language. Statement 3, "For every Python program that calls re.findall(), there is another Python program that does not call re.findall() but still obtains the same results." As it turns out, this statement is true. Before I deal with re.findall(), let's think of an alternative example and build up to that. Let's say instead of wanting to do find all, we just want to find one. That is, given a regular expression and an input text, we want to determine whether or not the text matches exactly the regular expression, and we can do this using the tools that we developed in lecture, particularly the procedure fsmsim. What we have to do is create a finite state machine representation for this regular expression, and that's pretty straightforward. We process the input text on this state machine using fsmsim, so you'd have to represent the state machine using the map that we described in lecture, and if the input text ends on an accepting state, then we can say we've found one match, so that's how we use fsmsim to find matches for the regular expression. But find all does something a little different. Let's say you had this code. This statement takes in a regular expression, the map numbers, and an input string that contains 2 numbers, 12 and 34. What find all is going to return looks like this. It's going to return 2 strings, 12 and 34, so we can use fsmsim to do kind of one matching. If we were just given the string 12, then we could do that, but we want to do a little different style of interpretation with find all, and we can still use fsmsim just with a little more effort. So let's say we have our black box fsmsim. And it has a representation for that regular expression. We also have our string that consists of 5 characters. What we're going to do is we're going to feed in the first character into our regular expression simulator. One matches the regular expression, so so far we have a match for 1. In order to match larger strings, we're going to try adding one more character, and we're going to feed in 12 to our regular expression simulator. 12 matches, so far, so good. Now we're going to try 12+. 12+ doesn't match, so we've realized that 12 is the largest possible prefix that will match this regular expression, and it's going to be one of the results. We're going to go back, and we're just going to try +. + doesn't work. We're going to try +3. That doesn't work either. That's not a number, and +34, which also doesn't work. We're going to give up on the +, and we're going to do the 3. 3 matches. Now we can try the 4. 34 matches, and since that's all the characters left in this string, we're done. And that's kind of how we can use fsmsim to simulate the same exact functionality of find all. Statement 4, "Every regular expression that involves neither + nor * matches a finite set of strings." This is true. In the regular expressions that we define in class, the only repetition is through + and *. We can do some fancy things still such as or or optional characters, but that doesn't even get us near the possibilities that these repeating operators can give us. I can enumerate a lot of different types in my regular expression, a lot of different strings, but it's never going to be infinite. And so if you don't have the + or the *, you're stuck with a finite set of strings. It may be a very large finite set, but it's still finite. In this summing numbers problem, we're given a string such as the one I have here, "hello 2 all of you 44." And we output the sum of all the integer numbers in the string. So here we have 2 and 44, and we're going to return the number 2 + 44, and with some advanced math, is 46. How are we going to solve this? Well, one way, using only the totals you had in CS101, might be to iterate through the string character by character, checking if the current character is a number and then continue concatenating that string of numbers until we don't reach a number, so we'd have 2, and then we'd hit a space, and then we add 2 to our total running sum. That isn't a very elegant way to do that. We'd rather use regular expressions to help us out, so to get us there, let's think of a regular expression that matches the numbers that we are looking for. Well, numbers range 0-9, and we want 1 or more of them, and that's it. We're going to use our friend re.findall with this regular expression in the input string, and for everything that's matched, we add it to our running sum. Let's write a bit of code to do just that. I remember to import the re library, and I've defined my procedure sumnums that takes in 1 parameter that is the sentence. I've now written the regular expression that we came up with previously, and I initialize my sum to 0. And now I'm going to run find all with this regular expression on the input sentence, and it's going to return a list of all the occurrences of that regular expression, in this case, a list of all the numbers. So found is going to equal one at a time all the numbers found in our input sentence, and remember from the hint given in the problem, the int procedure will turn a string into an integer if it so applies, and so we're going to update our sum with the integers that we find in the string, and once we're done, we're going to return the sum. In this problem, singly-hyphenated words, we're going to test our ability to use the or operator and the ability to group regular expressions. And here we're going to write a regular expression that matches 2 types of words, normal words, such as alice and bob, and also those with a single hyphen, such as super-irvin. We, however, won't perfectly match a string such as super-mega-irvin, so we need to write a regular expression that perfectly matches alice, bob, super-irvin but doesn't match super-mega-irvin. Well, one way to think about it is we have 2 types of regular expressions, one that matches normal words, or one that matches a word with a single hyphen. Let's do one at a time. First let's do the one that matches a normal word. This regular expression will match 1 or more occurrences of lower-case letters. Okay, let's move on to the single hyphenated words. A single hyphenated word has 3 parts, a word, a hyphen, and another word, so here I match a word, a hyphen, and then another word. Really I want to match either of these, and in order to do this, I'm going to have to group them, and in Python we group them using parentheses, and don't forget the silly question mark colon notation as well. And here we go as a regular expression. Notice that I listed the hyphenated words first because the way find all works is that it first checks to see if this matches the left side of the operator and then the right side. And if I'm running find all, I'd rather have it return the hyphenated word super-irvin instead of first checking if the word matches just super, then seeing that hyphen doesn't match anything, and then returning irvin. I'd rather get the whole thing, super-irvin. In this problem, we have been asked to complete a finite state machine so that it matches exactly the strings that this regular expression matches. Let's take a moment to look at what this regular expression does. The first part matches one or more a's or b's in any order. Then we match 0 or more c's, or together d and e, and lastly, we have an optional f that we match. Let's take it one part at a time while simultaneously trying to understand the finite state machine that we have partially built below. From the initial state, we go from 1 to 2 via b. Well, if we look at our regular expression, it's also valid that our first character is an a, so this probably means that this transaction is an a. And here at state 2, we repeat with an a, but we can also repeat with a b as well, and so far, we have the first part of our finite state machine in which we match one or more a's and b's. The next portion is the c, d, e business, and we see in our partially finished finite state machine we take an epsilon transition to 3. This is 0 or more matches, and the f is optional, so at this point, it is possible to finish in an accepting state. However, we can have as many c's as we want and then still finish, so this loop right here is probably a c. We still haven't dealt with the d and e. If we look at the d go down to state 4, in order to finish in an accepting state, we need to follow with an e, and the last part is the optional f. There's only 1 f, and if it does match, we still finish in an accepting state, which is exactly what happens when we go from state 3 to state 5, and so these are the portions of the finite state machine that we're missing that perfectly match the given regular expression. In this problem, we've been tasked with modifying code we built in lecture that simulates deterministic finite state machines to also simulate non-deterministic finite state machines, so as a quick review, what makes a non-deterministic finite state machine different than a deterministic one? One thing is that a non-deterministic state machine may have epsilon transitions, which means transitions that don't require any characters in the string and are taken automatically. The other difference is that a non-deterministic machine may have 2 output edges that correspond to the same letter, and this causes diverging states. Simulating a string on a machine, the machine can be in multiple states at the same time, and so that's really the key, what we're going to have to modify for this problem since we were told explicitly we do not have to worry about the epsilon transitions. The first thing we may want to go over is the notation in Python code for our machine. In the example, you were given a dictionary edges, so the keys in our dictionary indicates the state in our state machine, and the values are the other states to whom the key has an outgoing edge labeled with the second value in the tuple of the key. That may sound a bit confusing, so let's work through and draw a diagram for what this Python description represents. Let's say we always begin at state 1, which will hold true for the remainder of our examples. Here we begin at state 1. We then have 2 outgoing edges to states 2 and 3, and those are labeled with the letter a. From state 2, we have 1 outgoing edge to state 2 labeled with the letter a. From state 3, we have 2 outgoing edges to 3 and 4 labeled with the letter b, and from 4, we have 1 outgoing edge to state 5 labeled with the letter c. And lastly, we have our accepting states 2 and 5, so we'll use the notation of a double circle to indicate that it's an accepting state, and this is the finite state machine that this description represents. If you're a little rusty on your non-deterministic finite automata, let's go through an example string and see whether or not it's accepted. Let's say we have the string a, a, a. We start at state 1. From 1 we take the letter a to both 2 and 3. We're in two places at the same time. At 2, we take the letter a back to 2. At 3, there are no transitions for the letter a, so in this version of our simulation, this alternative dimension, however you want to think about it, the finite state machine has failed to accept the string. However, we still have the other version of the simulation. We take the last a back to 2, and from here we've succeeded, and by our definition of the non-determinism, if any path through this state machine results in an accepting state, then we say this machine accepts that string. Okay, let's do this once more. Here we have the string a, b, b, c. From a we go to 2 states, 2 and 3. Then we have the letter b. From state 2 there's nothing we can do. From state 3 we have 2 outgoing edges with b, so we're now at 3 and 4. Oh, and I forgot to include this last state transition, c, which will come up in a bit. From 3 we take another b to both 3 and 4, and from 4, there's nowhere to take this b to, so we've failed. And lastly we have a c. From state 3, there's nowhere to take this c, but from 4 we can take the c to 5, which is an accepting state. Now you hopefully feel pretty good with stepping through a non-deterministic finite state machine. Now we have to actually answer the question, and that is to simulate it. And what we're going to do is pretty much what we did by hand. We're going to do it recursively. We're going to start from the starting state, and we're going to take the first character in our string and recurse on this state that that edge leads to, so at 1 we're going to take the a and recurse onto 2 with the rest of the string and onto 3 for the rest of the string. And if any of those recursions, those recursive calls, come back true, then we say beginning at state 1, we return true, and it's going to go all the way back up. Let's try writing that. Here we have our procedure, the non-deterministic finite state machine simulator-- I know that's a mouthful--and we take in 4 parameters, the string on which we're simulating, the current state, the map of edges that represents the state machine, and lastly, a list of the accepting states. I mentioned before we're going to do this via recursion, and one of the first things you may want to think about when you're writing a recursive procedure is your base case. Our base case is going to happen when we have no more characters left in our string. So if I have no more characters, we're simply going to return whether or not we are currently in an accepting state, and thanks to the nice Python syntax, that translates almost exactly to the code. Otherwise we're going to look at the first character in our string. If the current state has an outgoing edge with a letter that's the first character in the string, we're going to do a recursive call for each edge. Here I've written the code that gets out the new state, and the last thing we need to decide is what to do with what the recursive call returns. And as I said earlier, we're going to return true if any of the recursive calls that we make return true. If we go through all of this mess, or if there wasn't an edge for the current letter at our present state, we're going to return false, and that's the code. In this problem, we're going to build a procedure that sees into the mind of a finite state machine. Given the definition for a non-deterministic finite state machine, we're going to use our crystal ball of Python code to read into the mind of the finite state machine and output any string if there exists one that is accepted by that finite state machine. This sounds like some pretty powerful stuff, but believe it or not, you have all the tools to do this. Here I have an outline for a finite state machine, and I didn't bother to label any of the edges, and let's just add a few more for fun. The strategy we're going to use is starting from the starting state, we're going to follow every edge, and as long as we don't visit a node that we've already visited, we're going to continue along until we reach an accepting state. We're then going to go back, building up a string that goes the other way, so the last character is going to be this edge. The second to last is going to be this one, and the third to last will be this one. Yeah, there are strings that would match if we went here and then looped at the 3 for a while. But the question only asks us to give one, and this is the best way to do it. We do have to take into account the issue of kind of an infinite loop. How do we know that we're never going to finish, never going to reach the accepting state? And I hinted at that earlier. We're just going to avoid revisiting the same node over and over again because all we care about is making forward progress. In this one I can follow the 1 over and over again, just looping around forever, but I'll never reach the accepting state 2, so what I'm going to say is if I follow the edge back to the 1, I haven't made any progress, so I'm going to stop following edges from the 1 along that path. If there so existed a second edge that led from the 1 and the 2, I would take that immediately and go right to the 2, so I can ignore the looping forever. Hopefully you're still with me. Now I'm going to walk you through--believe it or not-- the recursive solution to this problem. Here I have the declaration for my procedure. The inputs are the current state, the representation of our machine the accepting states, and the states that we visited so far, and as a reminder, what we're going to return is none if we reach a failure point. Otherwise we're going to start returning the edge that led us to this state, or more precisely, the next state, and build up the string as we go backwards from the accepting state. Okay, okay. Let's go right to the base case. If we've already visited this node, we're not making forward progress, and this isn't going to lead us to the accepting state, so we're going to return none. If we're currently in an accepting state, then we're going to return the empty string. We don't need to operate on any more edges to reach the accepting state. Here I'm adding the current state to what's going to be the new list of visited states. And here I'm looking up all the outgoing edges from the current state, and for each outgoing edge we find, we're going to recurse with the new state, and the new list of visited states, if following that path, eventually leads us back to something that we've already visited, or if there are no outgoing edges, basically if we failed, then foo will be none. If it's not none, that means we've found something. We found an accepting state, so we're going to start returning our string, and so the string I'm going to return is the character that I followed to the new state plus the string that was returned by our recursive call. This string represents all the characters that it took to get from newstate to the accepting state. This could be an empty string. It could be 100 different characters. It doesn't really matter. And in case there are no outgoing edges, as I mentioned before, we're going to return none as well. That's it. 13 lines of code to read the mind of a finite state machine. In this problem, we're going to modify the lexer to handle hexadecimal numbers. So what it is hexadecimal number? Well, more importantly, what is a decimal number? Let's go over this very quickly. If you have--let's say a number we write out--451--we consider this the ones place, the tens place, and the hundreds place. We do that because this is the 0th position, the 1th, and the 2nd, and 10 to the 0, 10 to the 1, and 10 to the 2. This is one, tens, hundreds. We calculate the value of this by multiplying the position of the digit by the value of the place. So this would yield 451. In computer science, we often use base 2. That's because the electronic circuits that we use in all of our fun little computers are most easily designed with 2 states--on and off. That's represented by a 1 or a 0. So the numbers that we often use are binary. Let's say we have this number--1101. In this case, it's not the ones place, the tens place, the hundreds place, and the thousands place. We've abstracted this idea of a base so that we have 2 to the 0, 2 to the 1, 2 to the 2, and 2 to the 3. If we multiply all of that out like we did with the decimal number, we get 13. So I still haven't answered what a hexadecimal number is. Hexadecimal is just base 16, and the reason we really like base 16-- it may seem odd to you at first--is that it's a very nice way of representing these base 2 numbers and handling them in a more concise manner. So 1, 1, 0, 1--I can write that with 1 hexadecimal number which happens to be d and convention dictates that whenever we write a hexadecimal number, we're going to put a 0 and an x in front of it. 0 and the x don't mean anything, except that it's a hexadecimal number that follows. So that's a hexadecimal, and for short, I'll say hex. So the goal of this problem is to modify the lexer to identify numbers written in hex and store the value of the number as what it equals. So we're going to identify the number using a regular expression, and then we're going to calculate the value using a formula much like this. So let's go straight to the IDE. So here I have the given code for this problem. Let's quickly run through it. Right here we have importing the lexer. Then we name the tokens that we want to have. Num stands for the hexadecimal numbers that we're going to identify, and ID is pretty much everything else, but the definition is described in the problem. We have 2 types of NUMs. One is a decimal number and the other is going to be the hexadecimal number, which we have to write. We ignore spaces, tabs, returns, etc., and we throw an error when there's something we don't understand. We have some code that runs our lexer for the sake of texting, and then we have some test cases. Let's fill in our code! Because it's easier, let's do the ID first. We have to come up with a regular expression. The definition for the ID is pretty simple. It's just a regular expression that matches sequences of characters with the letters a - z regardless of their capitalization, and then we just return it. So now we want to do the definition for hexadecimal numbers. The regular expression here is also not that bad. Here we have our definition for a hexadecimal number. We require that there's a 0 in x because that's what indicates that this is written in hex and not decimal. And then we have 1 or more numbers or letters a - f. In this line, I'm going to strip off the 0 and the x because that doesn't really help me calculate anything that has to do with the value of the number. Now I'm going to go through each digit of our number. For every digit that there is we're going to multiply our number by 16. That gives us the power of 16 for every digit that we've done so far. Here I want to check, if the digit we're at is between 0 and 9, so we don't have to do anything special with the fact that it's a letter, but we do have to do a bit of a conversion from the fact that it's a character and not a number. So one way to do this is take the numerical order value of our digit - data 0, and that's going to yield a number between 0 and 9 because they're all together in that. Also you could take--use INT--the INT function which will convert that string into an integer. Either way works. Here, I'm going to handle the case where the current digit is a letter a- f. I'm going to find out how many places away from a it is, and then I'm going to add 10, so a is going to equal 10. b is going to be some number - the value of a, which is going to give 1, so 1 + 10 + our number--we're going to add 11 to the number because b represents 11 and so on. I'm going to wrap up this function by setting the value of this token to the number and setting the type to NUM and returning the token itself. That's everything you have to do for this problem. So in this problem, we're going to build a bit of a spambot. Let's take an email address. Let's take my email address. Let's say I post this on the internet, but I don't want an automatic robot to go from every page, see my email address, and then start sending me SPAM. So I come up with a solution to insert the characters, NOSPAM, somewhere in my email address. Presumably, a crawling spambot won't be able to notice that this isn't actually part of my email address, and I put that in there just as a distraction. But a human will see my email address, realize that NOSPAM isn't actually part of my email address--who would really put that there?-- and just email to pchapman@udacity.com. Well, what we're going to do is build our lexer such that it matches email addresses, and the value of the token that it returns is going to remove NOSPAM from it. So what are we going to need? We're going to need to find our tokens and presumably, we're going to have 1 called email. Remember our tokens are going to use all capitalization, just as convention. Then we're going to want to define the function that matches that token. So now we have to write our regular expression that matches an email address. So the exact specifications for the email address are given in the problem specification. But to go over it briefly, we're going to have a sequence of letters with any capitalization, followed by an @ sign, and then we can have another sequence of letters followed by at least 1 dot and then more letters, possibly followed by another dot and more letters, but it doesn't end on a dot. You need to have some letters. So that's kind of the verbal walk through. Let's start writing it out. So we're going to match the letters before the @ sign. It's going to be this chunk right here. Then we're going to match the @ sign--this bit. So this part of a regular expression is going to match everything up to the last chunk of letters. This last chunk is called the top level domain--.com, .net, .edu--things like that. We're going to map with this regular expression everything before that. The specification for that is some letters followed by a period, and that whole thing can be repeated as many times as necessary, and at the end, we have our last bit of letters. For whatever this matches, we're going to remove the NOSPAM, and we're going to do that using the RE library, which you're hopefully pretty familiar with by now. This method in particular allows us to replace matching substrings with other substrings. In this case, we're going to replace all of the occurrences of NOSPAM with nothing. Also don't forget to define the error state where if it doesn't match anything, we're just going to skip it. The last thing we need to write is a code that builds the lexer and runs it on our given haystack--our given text of the webpage or whatnot of the email addresses. For that I'm going to go to the ID. Here I have the code I just wrote. I declare 1 token--that's the email. The definition matches our regular expression for email addresses and removes all of the occurrences of NOSPAM. I have something for when we hit an error, where nothing is matched. Now I just need to write the code that builds the lexer. So I'm going to basically follow what we did in lecture. This builds the lexer. Now we need to assign it the input. We're going to go through every token it matches and instill a list of results. I'm going to call that result. Here I go. For every token that we get, if I'm out of tokens, I'm going to break, but for all the ones that we do have, I'm going to append it to the result list and then return the result list. For this problem, we're going to write a lexer that's able to go through and create tokens for each of the JavaScript keywords and also ignore JavaScript comments, which are specified with little stars for long comments, just a slash and a star--this is a multi-line comment-- or just a slash, slash which comments everything for the rest of the line. So we've got 2 types of comments to handle. We did this 1 in class, but this one you're going to have to use some state variable like we did with HTML in class. So let's see how that's done. So here I have the solution. The first thing, which we gave you, was the long list of tokens-- the names and what they should match. So if I scroll down, I have them all defined. It's a little tedious, but it's what you have to do, and it's only a 1-time thing you have to do it. The only thing you really have to keep in mind is you have to escape characters that are particular to a regular expression. So freezing means you escape the parenthesis. We need to escape the pipes, plus, star-- things that have meaning in a regular expression. So the other major part of this problem was handling the comments. We have the end-of-line comment, which we did in lecture, and that's almost exactly the same. If you see 2 slashes, no matter what follows you simply pass by it. But what we're going to have to handle, just like we did with HTML, is if we're in a block comment--a multi-line comment, which is indicated by the slash, a star, blah, blah, blah, blah, and another star and a slash, we assign our states. We have a state called comment, and it's exclusive when you're in a comment, and you're not in anything else. A comment begins with the slash and the star, which is indicated right here. You have to escape both of them since they both have meaning. And then we begin the comment. We're done when we see the other star and then the slash. We increment our line count based on how many things we've passed by, and then we go back to the initial state. We need to remember an error for when something goes wrong, and then down here, I've defined what we want to ignore for the comment state, and it's the same exact stuff that we ignore when we're tokenizing the rest of it. In this problem, we're going to build on some of the JavaScript lesson we did in the previous one, and we're going to handle identifiers, numbers, and strings. Real quick, let's ask ourself, what are the differences between those? So we have an identifier, and as we talked about it in lecture, identifier is a name for something, usually a function or a variable. We then have numbers, and we're going to be able to handle numbers such as -1, 2., 3.5, etc. Then we have strings. This string contains the word, "Blah, an escaped quote--so the string contains this double quote, Blah, question mark--I don't know if you heard my raised pitch at the end. Blah?-- and then another double quote, and it ends. We indicate the end of the string with unescaped double quotes. So we want to write regular expressions to match these things because that's how we're going to write the functions that tell the lexer how to tokenize it. So let's do the identifier first. This one's pretty straight forward. We need at least 1 letter, and it can't be an underscore, but the casing doesn't matter. After that, it can be as long as we want, and it can have as many underscores as we want and then letters as well where the casing doesn't matter. So that's our regular expression for the identifier. For the number, it might be a little trickier. Let's say we have this number--542.555. We're going to write a regular expression to match this as well as all the other numbers, but this has all the pieces that we need to consider in a regular expression. The first thing is the minus sign. The minus sign can only occur at the beginning, and it's also optional. We then can match at least 1 but possibly more numbers up into a decimal point if it exists, but it also can just end there such as the -1 we have here. So the numbers [0 - 9], and it has to be 1 or more of them. This goes there. This matches that part. Now we're going to have a chunk that's optional. If we go down this route, we have to have a period, and we have to escape the period because it has meaning in a regular expression. But after the period, we can only have numbers, and there can be 0 or more of them. 0 for the case in where you just end in a period, which is often denoted to mean you want a floating point. But in this case, we're going to treat everything as a floating point. And then a star. So that's a regular expression. To go back, the dot goes here and these 5's go there. Now we just want to do strings. We have a regular expression. The first thing and the last thing we have to match are going to be the double quotes, and I use a single quote because I don't have to escape the double quotes in this, and that makes it nice. In between the double quotes, we can have 0 or more characters inside of them. Those characters can be in 2 groups. It's either escaped--like we have here--or it's just a character by itself--all the other letters. So let's do the not escaped first. That's going to be anything that's not a double quote or a backslash. We have to escape the backslash if we want to match that, so anything but those. So it's going to be everything here, all of this, but not these quotes right here because there's a backslash or a quote there. If we get any one of those, we're going to match a different rule where we have to have a backslash, but after that backslash, we can have any character, and that's what the period means. And I forgot to put my question mark. There we go. That's the regular expression that we're going to use. As you can see, as these regular expressions get more complicated, doing more complex things, they get messy. Messy--very, very quickly. Sometimes it's really conventient to write a regular expression like this. Sometimes you might just write a bit of code to do the same thing. But in this case, regular expressions are super powerful and super fun, and that's what we're doing here. Here I have my solution. I'm going to have 3 types of tokens-- the identifier, the number, and the string, which we went over. I have the identifier, which is exactly the regular expression we came up with. All we do is identify that type. For the number, when it matches, we're going to call float, which converts the string value that is in the token when we get it to an actual floating-point number. And then for the string case, we're going to strip off the quotes and just get the contents of the string itself-- that's what matters most-- ignore whitespace, have to deal with new lines and the errors as well. In this problem, we ask you to implement Euclid's algorithm using JavaScript. We're not expecting you to be a JavaScript guru, but it's useful to know the basic constructs when we're developing our interpreter for it. Perhaps, the best way to get familiar is by programming something. Euclid's algorithm is incredibly simple. It computes the GCD, or the greatest common divisor. Let's call our function gcd. It takes 2 inputst that are integers--a and b. If a = b, we're going to return a. If a > b, we're going to calculate the gcd of a - b and b. Taking a step back, this first one made sense. If you're given 2 numbers--36 and 36--it's pretty clear that the greatest common divisor is 36. So we're just going to pick 1. It could have been b, it doesn't really matter. This next one may not be as clear, but you probably have some intuition why it's true. We're going to reserve a proof for it for an algebra class that you might take in college or in high school. If a is less than b, we're going to calculate gcd of a and b - a. So looking at all of this together, it kind of looks like pseudocode, and actually it looks very close to the code that we're going to write be it in Python or JavaScript. So let's get right to it, and I'll go over some of the JavaScript notations and conventions as I code this up. But really this is it. So to declare a JavaScript function, we use the keyword function, and then the name of a function, which we call gcd. We're going to take in 2 inputs--a and b. Now we have our function body. Unlike Python where we can just use tabbing and whitespace to indicate what parts of the code are blocks or subparts of the rest of the code, we use braces, and forgive my poor bracing technique. I've never gotten very good at this. Now the first thing we're going to do is an if--if a = b, we're going to return a. If you haven't already figured it out, this is a recursive definition, and we're going to use it to write a recursive function. If a = b, we're going to return a, just like we've said. Oh yeah, and don't forget your semicolons just like I just did. Otherwise, else. If a > b, we're going to do gcd of a - b and b. Always add your semicolon. Finish your brace. We have 1 last case. Another else, and we're done. In this problem, we have a bit of a challenge, and I've accordingly labeled it with 2 gold stars, but what we want to do here, is optimize a finite state machine. So to go through an example, let's say we have this finite state machine. There's 1 accepting state at state 1, and then we have these few others. If you quickly look at it and think about what's going on, once you take a path down the b to state 2, you can never get to the accepting state. From state 2, 3, or 4, there's no way to get to state 1. So any string that goes down this path is always going to fail. This state machine is equivalent to the one that doesn't include any of these states. So we can make it a lot simpler. Why would we want to do this? Well, if you haven't noticed we've been using a lot of regular expressions in building our web browser. Those regular expressions are represented as finite state machines, and that's how they're processed. In order to make our web browser faster, it turns out we want as small finite state machines as possible. So what we're going to do is write code. Given a definition of finite state machine like the that we have here, we're going to identify states that don't matter towards the execution, and we call those dead states and remove them from the definition, while maintaining the exact same language, while recognizing the exact same strings that our finite state machine did before. So how are we going to this? Let's come up with a plan. So here we have "The Plan." Step 1--Let's find the live states and the dead states. We're going to do this by just finding the live states and assuming everything else is dead. So how are we going to do that? Well, we're going to find all the states, and we can do that by iterating through our dictionary, and with each state, we're going to run nfsmaccepts, which is from homework 1, and it's a procedure that given a definition for a finite state machine, a starting state, and the accepting states, it sees if it's possible to get from that state to any accepting state-- if it's possible to succeed from where we're at. So if I give this definition in state 3, it's going to tell me, no, we can't get to state 1 or any accepting state for that matter. If I give a 1, it's going to say, yep, this is all good. So that's actually going to be your definition for live versus dead. It can actually find a live state versus a dead state, which is awesome. Step 2--We're going to create a new finite state machine that doesn't have any of the dead states. In order to make it a really good, kind of clean, definition, we have to take some care. We don't want to include any transitions that lead to dead states. We want to remove all of the dead states, and we also want to remove states that no longer point to any live states. So here I have a bunch of little subparts. We're going to go through each edge state, each entry in our dictionary. If the current state is dead, we're not going to copy it into our new finite state machine. Otherwise, we're going to go through all of the destinations it had in the original finite state machine and prepare to copy over any that are still alive. If there are none that are still alive, we're going to remove that edge completely. We're not going to copy it into a new one. Once we have repeated that process in every state edge thing in the graph, we're going to update our accepting state list accordingly. We don't want to have any accepting states that are dead. So let's go to the solution. One of the first things I did is I copied in nondeterministic finite state machine accepts directly from unit 1 homework. It hasn't changed a bit. Now I'm going to do my trimming of my finite state machine. So like I said in my outline, I'm going to find all the states, just so I have a record of them, and it doesn't really matter if I have duplicates. It might slow down the trimming a bit, but I'm doing this to save time when I'm running the execution, not for the trimming so much. For each state, if it's live, I can tell by running nfsmaccepts, and if it is live, I'm going to add it to a list of live states. Now I'm going to create a new dictionary of edges--my new representation, and go through all of the old ones to see if they're still live and update them accordingly. So for each edge in the old dictionary, if that state is live, then I'm going to calculate the new destinations, meaning I'm going to remove the destinations that are now dead. So if that destination is live, I'm going to append it to the list. But I only want to set this new edge to my new finite state machine dictionary if the destinations are not empty. There's really no point in having an edge that goes to nowhere, that goes to fail. We just kind of always assume that if the edge doesn't exist, then we're going to fail. Lastly, I want to update my accepting states to only those that are live. I'm going to return the tuple of the new edges and the new accepting states. And that's it. Look! It's true! So much true! True means good. It means meaning and greatness. This first question asks us to make a few statements about formal grammars. Let's go over a little bit of vocabulary. A language is simply a set of strings. A regular language is a type of language. In particular, it's a set of strings that can be represented by a finite-state machine or a regular expression. A context-free language is also a set of strings but can be represented by context-free grammar, and what these 3 questions are asking us in this problem is to determine the relationship between a regular language and a context-free language, so let's say this bubble represents the set of regular languages. It's a set of sets of strings. And let's say this blob is the set of context-free languages. What we want to determine is how we can connect these two. Is it the case that no regular languages are context-free languages and vice versa? Or perhaps there are some regular languages that are not context-free. There are some context-free languages that are not regular, but there are some languages that are regular and context-free. And the last 2 possibilities are that all regular languages are context-free and vice versa. This kind of looks like a Pac-Man. Nom, nom. As it turns out, this diagram is the correct one. All regular languages are context-free, but not all context-free languages are regular. Briefly in lecture, Wes outlined the proof that all regular languages are context-free. The way the proof works is that you show that given an arbitrary finite-state machine, you can create a context-free grammar that embodies it, that represents the same functionality. Namely, it generates the same exact set of strings, and to show that there are some context-free languages that are not regular, we just have to come up with an example. An example of this is this set of matching parentheses. As it turns out--and I'm not going to prove it here--you can't represent this language with a regular expression. That's because you can't count how many times you see a left parentheses and then require that you see exactly that many right parentheses. There's just no form of counting in a regular expression. You can't hold that much state. Given that review, let's go over the actual questions. If a language is regular, than that language is also context-free. This is always true because we have our Pac-Man diagram here, and also because you can take any regular language and represent it with a context-free grammar. You can take any finite-state machine and represent it with a context-free grammar. If a language L is context-free, than that language L is also regular. This is sometimes true. If we have a regular language, that language is context-free, and, well, it's also regular. We have a case where sometimes a context-free language is regular. The question is is this always true, and the answer is no. If we have a context-free language such as the matching parentheses I went over before, this is a language that's context-free, but it's not regular. Sometimes this statement is true, and sometimes it's not. If 2 context-free grammars, G1 and G2, both accept an infinite number of strings, than they accept the same strings. This is sometimes true. Let's think of a couple examples. Well, there's a straightforward example that shows that this is a statement that can be true, and that is when G1 and G2 are the same grammar. Let's say we have the language ba* that Wes likes to use in the examples. We have baaa, baaaaa. All right, so we have ba*. Let's say we have the grammar G2. And you know what? Let's make it the same exact language. I have 2 grammars. Both accept an infinite number of strings. They happen to be the same strings, so this statement is sometimes true. We didn't say G1 and G2 had to be unique. You could also come up with examples where G1 and G2 are different, but they're the same exact string, so you could do baa*. And you'll also note I used a regular expression for my grammar, but all regular languages are context-free, so this is perfectly acceptable. Let's come up with a situation where this isn't true. Let's change G2 so that instead of ba* it's fa*, so we've got fa, faaa, and faa. I don't know, a lot of a's. These are both infinite, infinite grammars. They're regular expressions, therefore, they're context-free, but they don't accept the same strings, so we've come up with a case where this can be true, and we come up with a case where it can be false, so we're going to say it's sometimes true. In this problem we've been asked to define a function, cfgempty, which takes in a representation of a context-free grammar, a starting state, and a list of visited states and determines whether or not that context-free grammar is empty. Just like regular languages, we define an empty grammar as one that accepts no strings. Worded the other way, the set of strings that the grammar accepts is empty. So what's an example? Say we have the grammar with symbol S and S goes to S with the terminal a. In order for the grammar to make a string, we have to be able to replace all of the non-terminals with terminals. In this case, you can only replace S with itself and another terminal, but you're never going to get to the point where the string that you're building up, the substitutions you make, results in a string that's only terminals. So we say this grammar is empty. We want to write a program that does this for us because, well, it can get pretty complicated. As is the case with most of these examples, we're going to use a recursive strategy. As I said before, our procedure takes in 3 inputs: the grammar, the symbol that we're on, and the symbols that we've visited. This is important so that we don't loop forever. An empty language is going to be one where we keep visiting the same states over and over again without ever finishing. So this is really crucial to making this function work. We're going to go through the grammar, visiting all the rules that apply and doing the rewrite, and we're going to have 2 base cases. One is that we visited this before, and this means we're going in a loop and so this is a dead end. We're going to return something that shows that this wasn't true. We're going to return the value None. That says that this grammar is indeed empty. If the symbol is a terminal, then the grammar isn't empty, or at least the grammar so far isn't empty. We're just going to return the terminal because that's an example where if you start from a terminal you get a terminal. It's an example where the grammar finishes, it produces a string. Otherwise, we're going to go through all the matching symbols, all the rules that apply, do the substitutions, and recurse. And if the recursion returns a not null value, it returns a string of terminals, we're going to return the string back. And if the grammar does accept any string, we're going to build it up, going back up through the recursive calls and return a string that is a member of this language. Let's go to the IDE and write it out. Here I've defined my function. As we described earlier, we've taken a grammar which is represented as a list of rewrite rules, we have the symbol that we're currently on, and we have a list of symbols that we've visited. If we've currently visited the symbol that we're on, we're going to return None. We didn't find a string that's a member of this language, and this is going to avoid infinite loops so that our program terminates. So before I go on, you might have noticed I use the built-in function any, which was given as a hint in the problem. Let's briefly go over it. Any takes in a list, and if any value in this list is true, any returns True. It only returns False if all the values in this list are false. Let's go back to the code. Going back to our list comprehension, we're going to create a list of true and false values. We're going to create a true value if there's a rewrite rule that applies to the symbol-- in other words, if there's a rewrite rule where the left-hand side is the symbol that we're currently on. Otherwise, it's going to be false. This statement is essentially asking, "Is this symbol a terminal?" If no rewrite rules apply, we're going to say it's a terminal. And if it's a terminal, we're just going to return the current symbol we're on. That's the base case that we decided to do when we were sketching out this program. So those are our 2 base cases. Now we have to write the code that goes through the rewrite rules that apply to the non-terminal that we're on. We're going to update the list of visited symbols with the current visit symbol. Here we have a for loop that's going to go through every right-hand side of a rewrite rule that applies to the current symbol. This is going to give us every right-hand side where the left-hand side is the symbol. And the way it does that is it goes through the grammar, and if the left-hand side is our symbol, it's going to return the right-hand side. So this line asks the question, "Does every symbol in the right-hand side of our rule "result in a non-empty grammar?" And we determine that by calling cfgempty on every single symbol. We're using a list comprehension to create a list of true or false values that corresponds to whether the relative symbol is non-empty. It's true if it's non-empty. So if we're in the situation where we have a list of all true values, that means every symbol in the right-hand side is non-empty and the function all will return True in a similar way to any. But all, as opposed to any, returns True only if every element in the list is true. So if it's the case, we can get an example that proves that this context-free grammar isn't empty. So we create by going through each symbol in the right-hand side and building up our string and then returning it. If none of our rewrite rules terminated, then we're going to return None because we didn't find anything down this path. Here we have a grammar that represents some made-up language, kind of a cross between--I don't know--Python and JavaScript. It has a lot of keywords that are found in a lot of languages. Let's say we add a new rule. The question we need to answer is whether adding this new rule to this grammar creates an ambiguous grammar. As a reminder, an ambiguous grammar is one that given a string in that language, there are 2 parse trees, there are 2 ways to traverse the grammar and create that string. As we'll see later, this is really bad for languages that we want to interpret because it can result in the situation where 1 string, 1 program, 1 HTML document has 2 valid meanings. And so you can't really choose one, and that's not what we like. We use these precise languages such as HTML and JavaScript so that we know exactly what we want to be displayed or the exact actions that we want to be performed. We don't want ambiguity. Computers don't handle ambiguity very well. Their little brains explode. We can sit and stare and think about this for a while, but I'll just give you an example string that actually shows that adding this rule makes the grammar ambiguous. That gets us a check. Let's go over that. Here I have the string, and what we need to do is show that there's 2 ways using this grammar to generate the string. One way is using the if-then-else construct where this if, this then, and this else match here, here, and here. That means this part of the string corresponds to this C, this one goes here, and this one is from the E right there. That's 1 way to do it. The second way is using the if-then, do these 2 symbols, and then the if-then-else here, meaning that this corresponds to that S, this corresponds to that E, and then we have an if-then-else as that S. So here's 2 valid ways using this grammar to generate the same string. This shows that the grammar is ambiguous when we add this rule. Let's do another. Let's say we add this rule. B goes to a B and then a B. This is also ambiguous. Say we have print 4; print 4. So now we have 2 ways to create this. One way is to start with a B. From there we go to S and B. From here we can do print 4. We can replace the B--oh, I forgot to add that. We can replace the S with the print 4. An alternative way is basically do something very similar where we start with the B and we go to B B, but this time we replace each B with the S; That's our second way. Here there are 2 more rules. Neither of these rules makes the grammar ambiguous. When we add the keyword int, this is the only way to get an int. So there's not going to be a second way to generate strings with int. The same basic logic applies to the parentheses as well. This is the only way I have parentheses, and there's not going to be a second way there. All it does is add parentheses on the outside of a statement. And we can do it as many times as we want, but given x number of parentheses, you just apply this x number of times. Not a whole lot of fancy stuff going here. The fact that they match also is kind of a key contributor to this. If you had a parenthesis on 1 side and you had another rule with the other side, then you could maybe get some ambiguity depending on how you word it. But that's how this is. Let's go on to the last one. This should look familiar. I believe we went over this in lecture or something very similar to this, and this is definitely ambiguous. I'll come up with 1 example. Say we have 1 + 2 + 3. We can do this in 2 ways. We have E goes to E + E goes to 1, and this eventually goes to 2 + 3. An alternative way is that we have the 2 on the left-hand side and then we have the 3. Although the meaning of a plus, the associativity of addition allows us to do it in any order, from the perspective of a language of strings, perspective of determining whether or not the context-free grammar is ambiguous, the meaning of a plus is irrelevant here. In this problem we're tasked with creating a function that determines whether or not a context-free grammar is infinite. We say an infinite grammar is one that accepts an infinite number of strings. So let's come up with an example. Here is a grammar that accepts strings that spell out ba--different length of a, 3 a's-- and this can be possibly an infinite number of a's that follow the b. In an example of a finite grammar, I simply took the infinite grammar, removed the a right here, and this grammar only accepts the string b. Since the number of strings that this grammar accepts is finite--it's not infinite-- it's not an infinite grammar. So before I go on with how we're going to approach this problem, I'm going to go over one of the assumptions that you were given in the problem specification. That assumption is that for every non-terminal in the grammar, it derives at least 1 non-empty--that's critical--string. If you see S, you can assume that there's at least 1 non-empty string that S derives. So how does that help us? The way we're going to approach this problem is that we're going to try to see if we can rewrite Q where Q is any non-terminal in our grammar in the form of some terminal x, Q again, and some terminal y where either x or y is non-empty-- that is, the length of x and y together is greater than 0. So they both can't be empty because that's not a very helpful rule if Q goes to Q. That's not going to make us any progress. The reason that this is important is that if we have this rule or can rewrite Q in this form, we're back to the ba rule that we had originally. If we have this rule, we can build up an infinite string by simply repeating it over and over again and adding x's to the beginning or y's to the end. And so that's how we get an infinite grammar. The assumption comes in again because if we see this rule, we've assumed that Q can derive at least 1 non-empty string. We don't have to run what we wrote earlier in the homework, cfgempty, on Q; we can just assume it. So I don't actually even have to check if Q can eventually finish. If I find Q, I've found that the grammar is infinite as long as this property holds. So let's go over the game plan. I'm going to go through each non-terminal in the grammar because it doesn't really matter where I start. Any one of them is a valid way to generate an infinite grammar. Then I'm going to check for each of those non-terminals if it's possible to form something in the manner of this rewrite rule. So how do I do this part? I'm going to write a recursive helper function, and I'm going to check if that rule is of that form. If it's not, I'm going to recurse; if it is, I'm going to stop. Let's go to the code. Here I've declared my function, cfginfinite, where I take in a Python representation of the grammar. I'm going to go through every rule in the grammar-- that's what this list comprehension does-- and Q is going to be the left-hand side symbol in that rule. So this may be new to you. What I've done is I've declared a function within my function. The effect of this is that I can only call the helper function that I'm creating within the function cfginfinite. One advantage of doing this is that this function is not useful to any other code because I wrote it specifically for cfginfinite. So I can restrict access so that it's not misused in other places or depended on in other places. One disadvantage is that it kind of makes the code harder to read, and it makes it more difficult to understand where functions can be called and where they can't. Regardless, I'm using this helper function to determine whether or not the symbol Q can be rewritten in our form of x Q y where the length of x and y together is greater than 0. The 3 parameters are the current symbol we're at, the symbols we visited-- we don't want to loop around; otherwise, the helper function won't finish-- and the size of x and y in that case. It's this value. If I've looped around and I've already visited something, I'm going to return whether or not the size of x and y is greater than 0. If it is, we've found the rule that we're looking for and the helper will return True. If it's not, we're going to return False because we're not making the progress towards an infinite number of strings that we wanted to. Otherwise, we're going to have to parse through the rewrite rules that apply to that symbol current. I'm going to update my list of visited symbols, and then I'm going to go through each rewrite rule. So here, this for loop iterates through the right-hand sides of every rewrite rule that the current symbol applies to. Where the current symbol is equal to the left-hand side of that rule, it returns the right-hand side. Just another way to say it. I'm going to go through every symbol on the right-hand side, and I'm going to recurse on that symbol where the current of the recursive call is the symbol I'm on, updated symbols I've visited, and I'm updating the size of x and y that was passed in before with the length of the right-hand side minus 1. We do the minus 1 to exclude what we're recurring on, the Q. In this case, Q is symbol. When I do prove that Q can go back to Q, I can then check the size of everything else that I found before I found that loop. If helper is never true, then I'm just going to return False. So now that I've defined my helper function, I need to use it. For each symbol Q which this list comprehension returns, I'm going to try my helper function on that symbol. If that's ever true, I'm going to return True. If for every symbol I never find the helper function to be true, I'm going to return False. And I'm done. In this problem we've been asked to determine when given a grammar and a string if that string shows that this grammar is ambiguous. So how are we going to do that? The key here is going to be in writing out derivations of the string under that grammar. Let me show you an example. Here I've written out a grammar. For the sake of writing out the derivations, I'm going to label each rewrite rule with a number, just an identifier, so I can refer to this rule as rule 1. Let's say my given string is the string a and b. What are some ways I can derive ab given this grammar? Starting from s, I can take rule--let's do 0. That takes me to P. From P I can go to aT using rule 2. From aT I just need to get b. And fortunately, using rule 5, T goes to b. So there's 1 way to derive the string ab using this grammar. And later on when I do solve this problem, I'm going to refer to this derivation in the form of a list where I took rules 0, 2, and 5 to get ab. Now, to determine whether or not the grammar is ambiguous with regard to this string, I need to try and find another derivation. So if I take rule 1 instead of rule 0 starting from S, that gives me a and Q. From aQ I can take rule 4. Rule 4 goes to b, giving me ab. So the derivation is 1, 4. So I found 2 derivations--these are 2 very different derivations--for the string ab under this grammar starting from S. That's kind of a good example, but how does that help us solve the problem? So, just like an earlier problem in this homework assignment, we get to make an important assumption. The important assumption I'm making is that whatever grammars we feed into our function, they have a finite number of derivations. This actually means that there's a finite number of strings in the grammars. So they may not be all that interesting, but nonetheless, determining whether or not they're ambiguous is a very cool problem. So what does that allow us to do? It grants us the ability to get a very simple solution for detecting whether or not the grammar is ambiguous. What we're going to do is simply exhaustively enumerate all the derivations for that grammar. And the way we're going to do that is take the expand function that we wrote at the end of the lecture unit. Instead of enumerating just the strings, we're going to enumerate strings along with their derivation. Once we've enumerated all the derivations, we can check more than 1 derivation for that string. If we have found one, then the grammar is ambiguous. Otherwise, it's not. So if you're like me, you're eager to get right to the code. Let's do that. As the hint described, the first thing we're going to do is write our expand function. This is going to be taken almost right out of the lecture. If you don't remember or haven't seen this syntax before, this says I'm going to take the first and second values out of tokens and derivation and put them in the tuple (tokens, derivation). Here I have 2 loops that are going to enumerate each token in tokens and each rule in the grammar. I'm going to access them as I want given their position or index. So this gives me the rule out of the grammar. This says if the current token applies to this rule, it's on the left-hand side of this rule, then I'm going to do the following. I'm going to yield as part of this generator function a tuple where the first value in the tuple is the current state of the string. I'm going to make 1 substitution. That's what I'm doing here. I'm including everything to the left of the current token, making the 1 substitution, and then I'm including everything to the right of the token. And then I'm updating the derivation with the rule I used. So what does that look like? If I go back to the example I had here, let's say I pass in S. I am going to go through this list and see every rule that applies to S. Rule 0 and rule 1 both apply to S, so I'm going to yield 2 things. First one is going to be P because I'm substituting S for P, and then I'm going to return the derivation, which is using just rule 0. That's going to be the first thing I yield. The second thing I yield is going to be the substitution for the second rule, or rule 1. And so what I'm going to do in the body of is ambiguous now that I have the expand is I'm going to go back around and expand this expression even more. So when I expand this expression, I'm going to get 2 things. The first one is going to be using rule 2 to get aT, and the next one is going to be using rule 3 to just get c. So as you can see, I'm starting to build up all these derivations. So what I'm going to do in is ambiguous is I'm going to keep building up all these derivations until I can't expand anymore, and then I'm going to look at all the derivations that yield the string I was originally looking for, all the derivations once fully expanded yield ab, and then check to see if I got there the same way. If I got there in 2 different ways, then the grammar is ambiguous under the string I was looking for. Otherwise, it's not. So let's go write that function. I've declared my function. I've taken a grammar, a starting location, a starting symbol, and the utterance that I'm looking for. Enumerated is going to be all the possible strings in the grammar I've built up so far. Since I'm just going to start with start, the first value in the tuple is just going to be the string start or just the symbol start-- it's a 1-symbol string--and an empty derivation since I haven't done anything yet. So what do I have here? I'm going to take my enumerated list, try to enumerate it more, try to expand it using the expand function, and if it changes, then I'm making progress, I'm finding new strings, I'm expanding the derivations, and so I should keep going until I've gone through all the finite number of derivations. If this hasn't been updated, I haven't done anything new, the expand function didn't find anything new, I'm just going to break because I'm done. I found all the derivations I was looking for. So what I'm doing here is I'm going through each entry in my enumerated list. I'm going to try expanding that entry. If I found something new, then I'm going to add it to my new enumerated list. Otherwise, I'm not going to do anything. So what this is going to do is it's going to update new enumerated for every new thing expand finds. So once I've done all that, I'm going to count how many derivations I found for my utterance. And if I found more than 1, then I've shown the grammar to be ambiguous. I'm doing that by doing a list comprehension that essentially filters out everything that's not related to the utterance and then taking the length of that list. If it's greater than 1, then I've found 2 derivations. Otherwise, I haven't. So that's how you solve this problem. Welcome to the Homework 2 solutions. In this first question we're going to go over how to reason about the state of a chart when parsing a token in a given grammar. Right here I have a grammar that identifies JavaScript function calls. Let's say I have a function, pow, which computes the power of a number to another number--doesn't really matter. The idea is that this function computes 5 to the 6th. But what we care about is the tokens right here. And to show that this string is in this grammar, we're going to walk through it. Here I've written our first starting rule, which goes to id, some parentheses, and then optional arguments. So the id in this case is pow, and then we have 2 parentheses, and the optional arguments in the case of our example is 5 and 6. We don't have to have anything here. As the title implies, it's optional. It could go right to the empty string. But we do have arguments. In this case, we're going to have some kind of expression or an expression followed by a comma with more arguments. And in this case we have 2, so the optional arguments goes to arguments. It's not empty, so it's going to go to this rule. And then from arguments we're going to go to this rule where expression is going to be 5. We have the comma. That matches our comma. The rest of the rule is going to be ARGS, which goes to-- Since this is our last argument, it's just going to go straight to expression, which is 6. And we were able to match this string to the grammar using the set of replacement rules given. So I just went through that to demonstrate how this grammar matches JavaScript function calls. But that's not really what the question is asking. The question is asking about the chart. We're going to see what happens when we parse a certain set of tokens. Instead of writing the actual string, I just have the tokens that matter. And for the sake of parsing, that's all we care about. This can be matched by what I had before. But all we care about is the tokens. Now, when we parse this, what we want to ask is what is in Chart 2, the third entry in our chart? And so we're given a set of rules that may be in the chart. I'm just going to go through them real quick. So here are your choices. We're trying to figure out--as a reminder--what's in the second entry in our chart when we parse this list of tokens and this grammar. And since we're asking a question, we should remember question marks. So there's really 2 ways to solve this. The first is you work out the chart by hand. That's what we're going to do because it's easier to kind of explain what's going on. An alternative which is equally valid is to take the code that we wrote in lecture and modify it to print the chart at every given state. This is probably what you would want to do if you were asked this question more than once. But, like I said, for the sake of going over the answer, we're going to work it out by hand. Okay. Here's our input. Here is our grammar. We want to know what's in Chart 0. We haven't read anything in yet, so we're just going to be at the beginning of the start substitution rule. We introduced this in Chart State 0. So now we're on Chart 1 and we've read in 1 token, id. We're just going to shift on this rule because id is the first token in this rule. And this comes from 0 as well. So now the moment of truth, Chart 2. Let's see what we can do. We're going to see the token--that's the left parenthesis--and we're going to shift. So here there are 2 things that are possible. One is that optional arguments is empty. We don't know yet because we haven't seen the rest of the input token list. In that case, we're going to be past optional arguments. There's also the case where optional arguments isn't empty, which is actually what's going on with our input list. So let's write both those out. Here we've moved past optional arguments, presumably because it's empty by this rule right here. Then we have the other choice where optional arguments is not empty and we're going to be processing it. So regarding this first rule in our chart, we have the optional arguments being empty. So we need to make sure to add that. We introduced this in Chart State 2. We have the other case where optional arguments is not empty, and we're going to go through ARGS now. So I have written out both ARGS rules, and since we haven't read in this next token, we don't have anything to go further on in either rule, so at the beginning of each rule. And presumably, the next chart state we will shift over with the new expression. So now we have everything we need to answer the question. We're just going to check off the choices that were in our Chart State 2. So for this problem imagine you’re a criminal, specifically a bank robber. And from the bank you stole three things, a statue, a mask, and an erne. And I should probably got pictures to help you visualize this scenario. So now I’ve added pictures. Believe me you have no idea how long it took indiscernible and to make any scenario more realistic we’re going to add of course monetary and physical attributes to each of these items. And you want to steal weighs 15 kilograms and costs $30,000 and the scary mask weighs 9 kilograms and is worth $16,000 and lastly we have the erne. The erne weighs 8 kilograms and costs $15,000. So now I present to you a question. You didn’t go to the Jim enough and you can only carry 20 kilograms. So how would you solve this? One thing you might do, if you’re in a hurry and you’re about to be chased down by the police is take the one that weighs the least and try to get as many things as possible, hoping that you will make enough money from indiscernible Another opportunity might be to take the one that is worth the most, kind of ignoring what it weighs . Another choice would be to calculate the ratio between the weight and how much its worth. That way you chose items as long as you can carry them based on the cost per kilogram basically, the amount of money you’re making per weight. It turns out all three of those solution just don’t work for this problem. The last one will work, if you can take say half an erne , but for this you don’t really want to take half the erne. It’s worth nothing, unless it’s sold together and same for the mask and statue . So, you want to choose specifically which items to take. So taking the statue along doesn’t work. And it turns out the correct answer is to take the mask and the erne. So this is a surprisingly common problem in computer science and I suppose if you’re in a life of crime, it comes up often too. In computer science and economics this comes up when dealing with kind of resource obligation and making choices about which items to chose based on how much a cost function and how much they’re worth to you. So this is tricky to do quickly. And so when I’m going to ask you to do it, I mean, you can numerate all the possibilities, but that doesn’t really scale once you get to say, I don’t know, 15, 20 items. So we’re going to ask you to do is to write two functions that will help us to check whether given solution is correct. The first answer we’re going to write is called heist valid. And this is going to return true or false on whether or not the items you’re stealing is a valid thing to take away. We’re going to ask if everything you’re trying to steal is less than the total weight that you can carry and never going to think about heist total, which given a list of things you’re going to steal returns how much all those items are worth . So heist valid for the mask and the erne, that’s the correct answer. Nine plus eight is less than 20, so we’re going to return true . And the heist total we’re going to add 16 or 15 in return to that total, pretty straightforward. But we’re going to make it a little bit more tricky since we know how skilled you’re and require you to get off a one line solution . Hence this doesn’t really come off, up often when you’re in the real world programming , but we’re enforcing it here so that we encourage you to use these comprehensions and kind of think out of out of type the box . So what are inputs? We’re going to take in three things. A dictionary that essentially catalogues all the things that we’re able to steal. Each key in a dictionary is the name of the item that we can steal. And the value is a tuple where the first entry in the tuple is the weight of the item in kilograms and the second entry is the monetary value of the tuple in dollars. Although the units here don’t really matter as far as we’re consistent . We also have a limit to what we can carry . And lastly we have a list of strings corresponding to the heist here of what we’ve taken. So let’s do the first function. Since its we have to return something, its probably going to start with a return keyword . So what we’re going to do in this one line is add up the weight for each item that we’ve taken and see if its less than the limit. And because python is so awesome, this is pretty easy. So we’re going to take the sum of a list comprehension that generates a list of the weight of each item that we’ve taken. This is going to be the name of the item and that’s how we’re going to get the tuple out of the dictionary and we just care about the first item and that dictionary in for takings. So we’re going to go through each string and the taken list, look up the value in the dictionary corresponding to that item and take the first element in the tuple, which is the weight and we’re going to return that in our list. So when take the sum of that and we’re simply going to check, if it’s less than or equal to the limit. That’s a one line solution. Hurray! The next problem is going to have a very similar answer. In this case, we’re going to go through each item and take in get the tuple out of the available dictionary for that item and simply sum up the cost. Here is the key difference. So this list comprehension returns a list of all key values of each item and we’re going to take the sum of return. Those are one line solutions to each of those functions. For this problem we’ve been tasked with finding the longest common substring. The longest common substring is going to be the longest substring found in two or more given strings. Let’s go through an example and be pretty clear. So here referring two words that I’m not going to pronounce and if you look closely the longest sequence of characters that they’ve in common can be found right here APACH. There is no other substring longer than five characters found in both words. And in this problem we need to find the length of the longest common substring. So in this case it would be five . So when I ease solution to this problem, which should be really, really slow if we calculate every single possible substring in one word and check if its contained in the other word. So I would start with T, then I might do TA and then I might do AP, PA, AC, etcetera, etcetera and then I go to three letters and four letters and five letters and so on. And each time I would check if it’s in the other word. If it is in the other word, I would check to see if it’s the longest substring I’ve found so far. And I would update it. So this is pretty slow. We’re going to do something a little different. We’re going to write three functions. The first function C suffix, finds the longest common suffix . So given two words, like the ones we have here, the longest common suffix would be either the empty string or none. That mean there is no suffix they have in common. But if we ignored, the last few characters let’s say we had this, the longest common suffix is going to be APACH. So we’re going to find a function that finds a suffix, which is going to be a step in the direction of finding the more general longest common substring. The second function we are going to write creates a risk of all the prefixes for a given string. So if we take in a word say, CAT and calculate the prefixes of CAT, we will get a list exactly like this one. Notice that if there are three characters in the input string, the list is going to be of length three. And the last function is going to find the length of the longest common substring. The way we’re going to do that is by finding the largest common suffix of all the prefixes. So we’re going to go through each prefix, calculate the largest common suffix, and then keep track of the largest one we found and the length of the largest common suffix of all the prefixes quite an awful is going to be the longest common substring. So let’s get coding this. So ever in my function decoration for the common suffix. And one thing that was noted in a hint is that we’re probably going to want to cash the results of this function in a chart to save time and be more efficient. So let’s create that chart and then we’re going to check in the first line of our function whether or not we can reuse a value that we’ve already calculated. This is called memoisation. So here I make sure that X and Y are in the empty string and if they aren’t I’m going to check the C if the last value in each string is matching. If they do match, my total length of the common suffix is going to increase by one because the last characters match. And then I’m going to recursively call C suffix on everything, but the last character in the string. So five CAT and HAT, the first recursive call is going to check the T in CAT and the T in HAT. We’re going to see are they match at one and then recurse on CAT and HAT do the same thing? Recurse in C and H were not going to find a match, so we’re going to return the answer. And of course we have to remember to update our chart if we did find the answer. And that’s the common suffix. Lets move on to the next one and as spoiler each of the remaining functions is exactly one line long. So here is the code for a prefixes function . As a reminder, it takes in a string and outputs a list of all the prefixes for that string. So let’s take a look at this output. Given an input of CAT we have C, CA, CAT. If we are going to relate this to our code, CAT is X and we want to see what substring operations we can do on X to get these strings. So here we’re going to return everything from index 0, remember its 0-1-2 to 1, not including the 1. So it’s just going to be the first the 0 character. If we increment that by 1, we’re going to get the Increment by 1 again and we get the T . And so what this was comprehension does is it goes from 0 to the length of X, so its going to go from 0 to 2 and we’re going to take the substring from the beginning all the way to I plus 1, so its going to go to 1-2-3, just like we have here. Pretty simple. So given our two functions we’re going to rate L substring. And as I said before, this is going to be the maximum length of the common suffixes for all the prefixes both X and Y. If you didn’t follow along the code, it’s probably going to be clear. So here I’m taking the maximum of the list generated by this comprehension and what we’re going to do is find every combination to prefixes for X and Y together, find the common suffix of them and the maximum of that list is going to be the longest common substring of the entire word.And that is how you find the longest common substring. In this problem and the next we’re going to build a large portion of our javascript, parser. In particular, we’re first going to focus on javascript statements and then make it even easier really only go and consider six type statements. If then, so if you have an If statement basically, if then else, so here we’re going to handle a javascript statement, something like this and then also an else. Whereas this first type of statement is just this portion whereas the if and else handles all of this. We’re going to also do assignment, so variable X equals a five. Return statements, an example of that in javascript will look like this where we have the return keyword followed by an expression . Here I just have five. We have two ones left. One involving decoration namely using the var keyword, so this declares a variable X and so it’s a five versus just setting at the five later on. And the last type we’re going to handle in this portion is just the existence of an expression. You can have in your javascript an expression in the middle of your code . So instead of stuff here, we could just say five. This doesn’t do anything, but it’s a number five and its valid javascript. So this is pretty straightforward if you just follow the rules that were given at the top of the program and we’re going to go straight to the IDE and work through it one by one. So here I have my interpreter ready for us to get started with this question. So here I have the rule for a function and we’re going to write this out. Here I’m telling the parser that this is going to be a parser for the element non-terminal and I’m going to call this one the function parser. The first when to thing is going to be a string that tells a parser apply this rule. So here I say an element can go to the terminal function and identifier the some optional fantasies are right followed by a compound sequences statements. And once this has been matched, I’m going to apply it such that element is going to be the tuple with the world function. The name of the function , which is going to be identifier, the optional parameters which is number four and then six is going to be the compound statements. An can also just be a statement, which is going to be some sort of statement followed by a The two poles that it matches is going to be the word statement and the contents of that statement. Here I had my two rules for optional parameters and as the name implies the parameters can be optional, so our params can go to nothing or it can be a sequence of parameters. Now parameters can be some kind of identifier followed by a coma and more parameters or it can be one or the last parameter is just going to be an identifier. Notice how I put the identifier in a list because parameters are always a list even if there is just one thing in them. A compound statement is a sequence of statements in between a left brace and a right brace. the rules for statements, statements can be empty, so you can have nothing in your – between your left and right braces or it can be a single statement and a followed by more statements. So now we’re going to define the statements. Let’s start with F. If we do have an F statement, we’re going to put it in a tuple in our parse street where the first entry in the tuple is the string, if then it indicate that it’s an F statement. The second one is going to be the expression of the F statement and the last element of our tuple are going to be the compound statements that comprise the then. In the if then else , we have very similar structure except we’ve also added an else, which is going to be an additional entry in our tuple that is the sequence of statements that you do if the expression is not evaluated to be true. Here we have assignment. It’s going to an identifier. It’s a X equals the equal sign and then some expressions if I and then on parser you’re going to put a sign, the identifier and then expression to which the identifier is set. For return, we’re just going to do return and then the expression that we’re returning. We use the keyword bar to declare instead a variable, so we’re going to have the keywords bar followed by an identifier, the equal sign and expression we want to put bar, the identifier and expression. So make this a little more concrete, it would be as if we were doing this and the tuple that we put in our Pastry is going to be bar, X, five. And lastly we say a statement to an expression, which we haven’t defined yet and we’re saving for the next problem. Taken altogether we have much of our javascript parser. Well, at the least the part, that handles statements. In this problem we’re going to build the part of our javascript parser that handles javascript expressions. This is pretty straightforward, just like the last problem where we’re essentially numerating all the rules that we’ve predefined for our javascript language. So let’s go right through the I, the E. So here we have the supply code for the problem and if we look closely, we see that almost all the parse float are numerated to exactly what they should be. We have Identifier, numbers, strings, true and false, how to handle a not keyword do the opposite and then for expressions. We are also given an enumeration of the precedence and the associativity for each of these operations. So really we have everything we need in the problem description to do this problem. And as you can see here, I’ve already filled in the precedence ordering for the operations. And this has simply taken almost exactly right from the comment given in the problem where or is listed at the lowest precedence and we go all the way up to division, right here. I’ve also added not just to make it work. So let’s start filling in the rules. My first rule is going to handle. If we add a matching left and right parenthesis, the expression that is equal to is simply the contents of the parenthesis, pretty straightforward. And now I have four rules for some of our literal values. We have a number, we’re going to say number and then the contents of that string, just simply say the word string, we’ve matched true or false, we’re going to return the specified tuples. If we see a notch, then we simply have in our Pastry that we’re not and then the contents that are being. Afterwards, we have about a dozen or so binary rules. Addition, subtraction, times, modulus division etcetera, etcetera and to save some time I could enumerate each function, but I want to take a short cut. So here I’ve said if we match any of these things, I’m calling it a binary operation. For the first element is new left, upper end of the binary operation. The next entry in our tuple is going to be the operation being used and the last one its going to be the right upper hand of the binary operation. And now I have the expressions for function calls, not just decorations, which we had in the last problem. A function call is going to be identifier, with optional argument in between parenthesis. And the code for handling optional arguments is almost exactly the same as the code we use to handle, optional arguments in the function decoration. In fact, I think it is exactly the same. And with all that, we’ve done it. It’s about 50 lines a code and we are happy. So in the last problem of this homework assignment, we’re going to take a look at the complexity of parsing certain strings of input under certain grammars. Is it the case that certain grammars are more difficult to parse with the algorithms that we’ve given? Is it case that certain strings are more difficult to parse with the same algorithms? And just in case it wasn’t clear, this is definitely a challenge problem and very, very difficult. So please don’t be upset. If you want to able to get a good solution, if you dig your working solution I hope you shattered on the forms with your fellow students and discuss how you got there. So to recap, we’re trying to answer the question, how much work is it the parse? And before we answer that, we need to decide in someway to measure this work. We could take the time that it takes to run the parsing, maybe measure in seconds or minutes. We could take the energy when you have a web browser and something like my phone, then we need to decide whether or not our web browser is efficient enough not to drain my phone four hours into the day. I’m sure that happen to some of you before. So this might be measured in lots or some of the measurement of power. There is something wrong with each of these forms of measurements. And that is it doesn’t really get at the algorithm. If I buy a faster computer, does that mean my parser is better? No. if you build a more energy efficient phone, does that mean the parser is better? Not really. So measuring in such units would imply that our algorithms get better over time as the hardware does. But the truth is many algorithms haven’t gone better since when they were first developed and say the 70s. So we want a union of measurements that is independent on the hardware we’re running on. That way if I test my parser, I can compare it to your parser even though it’s very unlikely we’re running the exact same computer. Instead we’re going to find our own unit of measurement. For now let’s call it a work operation. We’re going to count the number of work operations it takes to parse, a given list of, a given string and our grammar. For this problem you were asked to give two things, a grammar and a list of tokens that takes at least two X, X, X work operations to parse where X is going to be defined as the maximum number of input tokens or the size of the largest grammar rule or the number of rules. So why is this definition special? It means that we can’t just give a really long list of tokens and expect to reach two times what is essentially x3 work operations. We have to find something that given the relative size of the grammar to tokens and the rules is more work to parse. The key to solving this problem is actually ambiguity. It turns out ambiguity really slows down the parsing process, given the set of rules that we’ve defined for parsing a given list of tokens. So let’s look at a really ambiguous grammar. This grammar matches a sequence of Xs, but because of this rule right here it’s very, very ambiguous. As it turns out that if you have the or more Xs in a row to actually break the two times x3 mark for parsing. But for the sake of demonstrating this, I’m going to just show you what the parse chart looks like with five Xs. So here I’ve taken the code given in the problem uncommented dissection that prints the chart and I’ve run the grammar that we had on a string of five tokens. The results, is as follows. Right from the get go there is a lot different rules that we can match. And with every step we keep getting more and more possibilities due to all the ambiguity. Everywhere that we could possibly have a P or putting in two more Ps and then from there even two more Ps. As it turns out for N characters we get about n2 possible Pastries. And that means the size of our chart alone includes a lot more than the possible Pastries and we do a lot more work operations as we try to go through that. So by the end, we’ve done 3,237 units of work. Now if we increase the number of tokens to something like 50, we get a very long parse chart. And that will just keep scrolling and so hit the bottom. Get some longer and longer and longer, and oh my gosh, does it end. Here we go. Yeah, it gets pretty big. One thing to note that I didn’t do in my examples was that the length of your input needed to be greater than 10 and less than 50. And by inputting mean the number X. So here I had Xs 50 and before I had a 5, but that’s why I neither of these were accepted. So if you did something say, 11 you will get a success that encourages you to copy and submit it. I hope you had fun doing this problem and it’s a bit more creative than what we’ve had in the past. And there is many, many right answers. I hope to see some of those answers on the form. Until then bye, bye. I will end with this manifest. Here I introduce to you to a web page rendered by the web browser we'll have built by the end of the class. In this problem, we asked you to generate the HTML that creates this page. A skill in becoming a computer scientist and a programer is the ability to look up information on your own. We ask you to look up a few of the tags that are used here and figure out how they apply in order to generate this page. I will briefly go over the tags that are used to generate various parts of the page, and then I'll quickly show you the HTML as a finished product. Every web page begins with and ends with HTML tags. To use the level 1 heading, we had H1 tags. We created paragraphs using the P tag and we had two paragraphs. We created this unordered list--unordered because each item in the list is just a bullet and not a number using the UL tag. Each item in the list begins with an LI tag--standing for list item. Within the list item, we can have another list, in this case it's an ordered list, which is define using the OL tag--standing for ordered list. In each item, like in the unordered list is defined with an LI tag. And now we have most of the structure for these webpage, I want to go back and highlight a few instances of tags that change how the page looks. For bold, we use B tags, for italics we use I, and there is also small and big tags that change how large or small the font size is. We can change how the font looks with TT tags. One last thing to note for changing how the text looks is the strong and emphasized tag elements. We use the strong instead of the bold when we want to describe the meaning of the text oppose to the formatting of the text. We went over how hyperlinks works in class but as a reminder we put the text of the link in between two anchor tags, and we set the target as the hyperlink reference. For an image, we use the IMG tag as the source of the image, as a URL, or relative pass to the image. In this case, we've defined cs26.png, the same directory as this page is being rendered. For details like that, we recommend that you check out Steve Hoffman's class cs253. Now, to look at the finish products, let's go quickly to the ID. Here I have the finished HTML and it should look strongly similar to what we worked out together with just the output. Keep in mind that the HTML that you created can look different in many, many ways for reasons such as different white space and things like new line spaces, etc. while the output of the HTML page looks the same. We've been tasked with adding a while loop to our JavaScript interpreter that works just as it does in Python. To get acquainted, here's some JavaScript code that writes out 0, 2 and 4. As you may have guessed, we test the expression if the expression, which is known as the condition, is true--then we evaluate the loop body. After evaluating the loop body, we test the conditional expression. Again, if it's still true, then we evaluate the loop body, and we continue this process until the conditional expression is false, at which point we continue on after the while loop. So a while loop is a type of statement that has the keyword while, an expression, and then a compound statement--a sequence of statements. In our parse tree, this is where we represented as a tuple, where the first element is the string while to indicate that this is a while loop. The second element is the expression--the condition that determines whether or not we execute the loop body. The last element of the tuple is the sequence of statements that comprise the loop body. So while tell you two ways to solve this--the first is going to re-use the Python while, and the second is going to implement the while loop recursively. Recall that in a programming language, you can have either a while loop or recursive calls and still be equally powerful. And so we're going to use that fact to implement our while with recursion. Here's one solution. The first two lines, extract the conditional expression and the loop body from the parse tree and then we simply plug in the conditional expression and the loop body into a Python while loop--so while the conditional expression is true we're going to execute the loop body--pretty straightforward. And here's my recursive solution--the first two lines are copied right out of the Python while implementation--where we extract the conditional expression and the loop body in the same way. We then evaluate the truthiness of our conditional expression. If our conditional expression is true, we execute the statements in the while loop and then recurs on eval while. Think about it for a moment, and we'll keep evaluating eval while until the conditional expression is false under this environment. When it is false or if it ever is false, we simply don't do anything which is exactly the same functionality we had with the while loop implementation. In this first problem, we asked you to evaluate a few statements on interpreters. The first statement reads every operation can be sensibly applied to every type of value. This is not true. Let's take a look at the plus operator. If you add two strings, it's sensible that it concats them and it's equally sensible that adding two numbers is equivalent to adding them under the plus operator. However, adding a string and a number is not a sensible operation. This doesn't really make sense--what we would do with this. Do we turn string into a number and add them arithmatically or do we concat "uda" with the 5 and get a new string? In most interpreters, this is a problem. The second statement reads--the meaning of an expression can depend on its context. This is true. At its core, this question is dealing with the notion of scope. Let me show you an example in Python. If I run this code, two values will be printed out--first 6 and then 5. Because within the function, we defined x to be 6 and then print it out the value 6, but outside of the function, the meaning of x is 5. This implies that x--the expression just x--can mean two different things and its value is dependent on the context it's in, whether it's in a function or outside a function or more precisely the scope of x. Statement 3 reads--we can use a single dictionary as an environment to track JavaScript variables--this is false. As we saw in lecture it's necessary to use different dictionaries for different levels of scope. Here you have a diagram of one possible environment. Within a function named fun, x can equal the string Andy, whereas in the global environment, x can be the outside x string. We generally represent each of these environments as a dictionary where the key is the name and the value, and the value of that entry in the dictionary is the value of the variable. Because the name can be repeated and because a dictionary has unique keys, we're going to have to have nested dictionaries or more than one dictionary to easily represent our environments. In theory, you could do it with a single dictionary, but also in theory you can only use a single flat list for every program you possibly want to write. But in practice you're going to need multiple dictionaries. The next statement reads our JavaScript interpreter always completes after recursively walking the parse tree--this is false. The easiest way to demonstrate this is a little bit of JavaScript. Here you have a little bit of JavaScript that never terminates. Although the parse tree for this JavaScript is finite, interpreting it is infinite. The way we interpret JavaScript is by running it, and in the process of running it, we're never going to exit this Y loop because the condition is true. You may ask yourself, can our JavaScript interpreter recognize that this Y loop will never finish and simply skip it or somehow move on from it or just terminate early. Well, although we can tell in this case that the Y loop is never going to exit because it's true and then nowhere inside the loop we change the control flow. In practice and in theory, doing this for the general case is impossible due to the halting problem which we discussed in lecture. The last statement states our HTML interpreter always completes after recursively walking the parse tree. This is true because no matter what tags we use, there is no notion of a loop like we have in JavaScript. There is no recursive calls that can cause the HTML interpretation to take an infinite amount of time and interpreting the HTML is going to be a direct function of the number of elements we have in our parse tree. Here, we test your knowledge of Java script environments and scope along with a little bit of info on Native North American peoples. As the text of the problem suggests, we're going to solve it by working out the nested environment diagrams. So let's start with the global environment. In the global environment, we define a function Apache, and the first thing we do is call it with the inputs 9 and 10. So this is going to create a new environment for that function call of Apache. The inputs were 9, which corresponds to Iroquois. And the second was 10, which corresponds to Ottawa. We then set Seneca to 1 and we declare and set Creek to 2. When we print out Seneca, we're going to look at the lowest environment, which is Apache. We see Seneca as 1. Iroquois is 9. Ottawa is 10. We now declare a function Cherokee, and we call it with the inputs 777 and 888. Since we're going into a new function, we create a new environment. 777 gets assigned to Seneca, which is a local variable, and Creek gets a value of 888. We print out Seneca, which at the closest scope is 777. We then print out Iroquois. It's not in the scope of Cherokee. So we go up to Apache and Iroquois is defined as 9. We now print out Ottawa. Ottawa is not defined here in Cherokee but it's defined in Apache as 10. And lastly, we're going to print out Creek. Same deal. Not defined in Cherokee but is in Apache. Now we do some modifications. We set Seneca to 33. We set Creek to 44. We set Iroquois to 55. It's not in Cherokee. So we're changing the value of Iroquois in the Apache environment. Then we set Ottawa. We leave this function and now we're printing out Seneca. Since we've left the Cherokee function, this environment no longer applies. And we're simply looking at what's in Apache. The value of Seneca is 1. The value of Iroquois if 55. The value of Ottawa is 66. The value of Creek is 2. Let’s say we have a list of numbers, and we wanted to find the odd numbers in that list. One way to do this is to use list comprehensions as we've learned earlier in the class. Here, the list of odds is only going to be the values of n, where n is an element in numbers and that n is odd, which is what this statement results in. We can also use the same construction to turn this list of numbers into a list of squares of each number. These types of operations are so common. In computer science, we give them a name. This is usually referred to as a filter, and there's a map. When we're filtering, we take in a list of numbers and some criteria and only return the numbers that satisfy that criteria. In a mapping, we take a list of elements and some operation and we perform that operation on each element. Python actually gives us built-in functions to do this. Another way to write odds is to use the built-in function filter where we give in two arguments. The first is a function that we've created anonymously using the lambda notation that return true or false. True if the n is odd, and false if n is even. The second parameter is the numbers, so filter is going to return all the numbers that when inputted into our first parameter, this function returns true. Here's how we generate the squares using the map operation. We pass in two parameters just like we did with filter where the first one is a function and the second one is a list, and map returns a new list that is the result of applying each element in numbers to the first parameter that we gave the function. This problem asks us to create what is known as a higher order of function that is we're going to create a function that generates a function that saves us time from having to repeat this first part of the filter and the map every time we want to use the same operation. Ideally, instead of writing filter of lambda n and mod 2 equals equal one. We're just going to create an odd filter. Here our filter maker creates a new function that takes in one parameter--numbers-- and applies filter in the same way as we have up here because we've already passed in to the filter maker the function the we wanted to use filter on. There are two ways you can solve this. The first, would be using the lambda notation. And the second is using inline function defines. Here, we're creating a function using lambda. That's what lambda does. It's a function that creates a function that is a list comprehension for every element in our list, which is the one parameter into our lambda function L. We're going to leave it in the new function created by this list comprehension if that element satisfies our function F. In this alternative solution, I am using a nested function declaration where we're creating a function that takes in the list and returns the result of filter of the original function that we used to create our special filter f in the list that we just passed into this function. So that's how we do this for filter. Let's do the same thing for mapping. And just like before, we can solve this in two ways. First, we'll go over how to do a lambda. And then we'll briefly go over how to do it with a function declaration. Here I am creating a function that is just a list comprehension that returns the result of applying each element in l to function f. In this alternative solution, we're defining a function yourmap that simply returns the result in using Phyton's built-in map with parameters f and the list that is passed in with applying yourmap. And the last line is returning the mapping function we created. Hey everyone. This is Shaun. I’m the assistant instructor for web applications engineering. Peter unfortunately couldn’t be here because he is off doing something silly like graduating. So you’re stuck with me. So let’s just jump right into the home work solutions. First question was about interpreting, testing, debugging. Actually all the homeworks are about that. And this question starts off with just a quiz, first off embedded JavaScript programs use functions like document.write to change the surrounding web page. Yes, this is true. We can take a quick look at something like this. So I’ve loaded up this HTML into a file and you can see there is a bit of java script in the script tag here, just a simple factorial function. And then it uses the document.write method to write out the factorial five, which is 120 and then write out the expression five is equal to five. So this should write out 120 and then true. So if we load this up in our web browser, we see that at the end of this, it has modified the web page to write 120 and true. Now we haven’t done any kind of styling to this, so it’s just running right into each other. But the point remains is that the document.write function is really how you modify on a basic level the overwriting HTML page. Next part, testing can prove that a web browser is correct. That is not true. So we can take a look at an example of that too. So let’s say I have a basic square function. Well actually not a basic square function, it’s much more complicated than it needs to be. But let’s see about if we can prove this is true with some test cases. So let’s print out some test cases say print square three and this if you run it, okay that brings out nine that makes sense. But then if we print out another test case and we see this is 9-2, which is what we expect. So I am just going to print out a few more test cases, okay. We’ve got a few more test cases here and we can already tell the square of 0 should be 0. And the square of two should be 4. So go ahead and run these and we get the expected output. Now are we done here, are we proved that this is correct? Obviously not because if you look at the code, this isn’t going to return the square of X for anything that is were mod two equals 0 and X is not two. Works fine for X as two. But when we print out square four which should be 16, but we instead get is 8, which is not at all what we want. So testing is great. Having simple small unit tests is a good habit to get into. But you can’t really test for every single possible input. It’s just not feasible. So you should be prepared for accepting that your code is probably right. But you can’t guarantee it with testing, okay. And the third part program should compute different answers before and after it has been optimized. Now this is definitely not true. Program should be correct. Now what correct is, it can vary depending on what your actual goals are, but the program should work as you intend it and once you start optimizing things that shouldn’t change. Now the final part of this quiz is making changes to a test case can help to localize a program bug. And yes, this is true. And we can see an example of this. This is actually fairly similar to what we were doing for. So you got an absolute value function and let’s say I’ve already told you that something is wrong with it. And I want you to find where the bug is. Well, where do we start? Well, let’s try printing out, the absolute value of one because we’re trying to break down on what part, what branch of this function, the bug that I’ve already you about is in. So we want to differentiate between positive values and negative values and zero, is that breaks it down to one of these two, statements. And we get out one which is the absolute value of one. So, okay that seems okay. Now let’s try and narrow it down a bit further from there. Okay, so let’s narrow it down a bit further and now let’s do the absolute value of 8, which is still right here. It’s still going to be in this else statement, but since it’s greater than two, it’s going to go into this internal if statement instead of this other else. So when we’re on this, we get 0, not 8. So we see that the bug is in this and its fairly clear that that’s where it is and most programs that you’re debugging this is not going to be this simple, but you can add additional test cases and use your test cases to narrow down on what part of your function, the errors are in. And that’s really the point of this, right here. Okay. For homework two, we asked you to modify the interpret function so that JavaScript elements are – the output of the JavaScript reinterpreted and run through the HTML interpreter. So instead of just basic JavaScript output, we can actually output further HTML making our JavaScript quite a bit more powerful. So how do we change this, so that we can do that? Well, first off we can see that we’re not really concerned with these two branches of this if statement. We’re not concerned with word elements or tag elements, we care about JavaScript elements. So we already know that we don’t really need to do anything right in here. We need to do something to modify how we interpret JavaScript. So we go down here and the two lines I added are right here. Now instead of just outputting the results of the JavaScript interpreter’s abstract syntax tree output. What I’m doing is I’m running the result of the JavaScript interpreter back through the HTML parser, the parse function. And outputting that abstract syntax for you, which this is HTML now and then we run that back through this function itself so that we can further interpret the syntax tree. Now after we’ve done that, we don’t really need this last graphics doubt word resolved. We don’t need to further interpret result. We’ve already done that. So we can just get rid of this and to check whether this works, we click run and we see below that we do indeed get our page output, but okay. So we’ve got this JavaScript output, but you can see that the odd numbers are bold and the even numbers are italicized which if you check, the web page that we gave you as an example, is exactly what we’ve done. We’ve wrapped the even and odd numbers or the odd and even numbers respectively in bold and italic text, which is what you see down here. So this gives us a lot more power in our JavaScript interpreter because we can use our JavaScript to now output further HTML that we can run on the fly. And that is going to be very, very important. So here we were given a version of a JavaScript interpreter that has a bug already in it. If we go down to the part of the JavaScript interpreter, that handles calling functions, we can run this sampler web page and discover that what the correct answer is, three and four has actually becomes 888 and 999. As it turns out, this very wrong answer is caused by a very simple bug. Hopefully you ran a few of your own text cases to narrow down the problem, but right here on this line is the culprit. Our new environment – the environment in which we evaluate the statements of the function body, is the ENV variable which comes from the call, ends the value passed into ENV is actually environment from which we call the function. If you recall the parsing for our JavaScript functions, the first element of the tuple is the strength function which says that this represents a function. The second is the parameters for the function. We then have the function body what is just a sequence of statements and then lastly we have the environment for the function. This is the parent from which the function was defined and it’s actually environment in which we’re supposed to executive the function. However, with this code that’s not the case. We’re executing the function; the environment from what we call it, not from what it was defined. So we need to fix that. So I’ve defined a variable function environment, which just grabs the fourth element or the third index out of the tuple and instead of creating the new environment as ENV, which is going to be the function environment that we want. And that’s it. The consequences of the bug are pretty severe, but it’s really just what do we change, 10 characters, I mean, that’s just how these bugs can be. It can be really hard to find that’s why finding bugs is time consuming, difficult and it’s a skill that you’re going to have to learn because its just part of programming, you’re going to make mistakes. In this homework assignment, we asked you to do a few optimizations. The very basic optimizations you can do are very, very simple optimizations on binary operations, on basic arithmetic, and the ones we specifically asked you to do are these right here as well as replacing expressions with constants when applicable. So we gave you this one right here and then, to add in the others, we just do this great big ‘else… if…’ statement. So the first one, we check that the operation is times, we check that A is a number and it’s a number equal to one. And if it is, well, one times anything is that second thing, is B. So we just returned B. We don’t have to wait and run this through once we’re interpreting. That would take more effort than we need to. Now we do the same thing with the next one if B is one and A is something else. We can just return A. Now we can do the same thing with addition and 0. We just check if the operation is equal to plus and that A is a number and it’s a number equal to 0, then we return B. If B is a number equal to zero, then we return A. And finally, the last one that we asked you to implement is a number minus itself is 0. So that’s fairly straightforward too. Check if the operation’s equal to minus and then if A equals B – and remember, you can do that because you can check if Python tuples are equal to each other, not just numbers – then we return a tuple of number and 0 to indicate the number 0 in our abstract syntax tree. Now the constant folding is a little bit more work, but really not too much. First, we check that the first element of the tuples A and B are number. Then if the operation is addition, if the operation equals plus, then we return number and second element of A and B added together. So that way, we don’t have to run that operation later on when we are actually running the program. And we can do the same thing if we check if the operation is minus, then we run – then we return tuple of number and the second element of A and B subtracted and similarly for multiplication. We can just do the same thing for the second elements of A and B, multiply together. And then once we have hoped that the operations have been optimized in some way, we wrap it back up in a binary operation and a tuple of BinOp, AOP and B, and return that. And if none of this worked, if we didn’t even get a BinOp to begin with, then we just return the expression because those are all the optimizations that we have done. So let’s try that with a few of these test cases and these are the test cases that we provided you with. So we have zero, one and two, numbers equal to 0.0, 1.0 and 2.0, and a few variables that are ancient kings and queens of Persia and Macedonia – Xerxes, Darius, Antiochus and Musa – and then we’re going to define a plus operation, just so we don’t have to keep writing this tuple out, and a minus operation and a times operation similarly, just to save some key strokes. And then we’re going to check whether an expression that we’ve said, which is times 2 and 0 is equal to 0. That is their optimization actually ran. We’re going to do the same thing with a minus operation and a slightly more complicated operation. Expression three is minus plus zero plus one plus two zero two. That was a quite a big mouthful, so let’s go through it just a bit more in-depth. Plus two and zero, so two plus zero and then we wrap it in this call to plus, so two plus zero plus one and we wrap it again in a plus zero, and then we wrap all of this up and subtract two from whatever this is. So this really should just be three minus two. Once you get past all of the massive amounts of parentheses. So we print out and make sure that that is indeed equal to one. We do the same thing for these expressions as well. So when we run this, we see that we pass all of our test cases. And this – our test cases involved a bunch of hand- checking, where we just made all these up and hand-checked that this is what they’re suppose to be and then verified that the optimization actually does what we think it’s going to do. This isn’t necessarily how you would normally do it, but it’s good enough to serve our purposes right now. For this homework, we asked you to remove dead code. That is code that could not have any effect on the final return result of the method we’re interested in. So, let’s go ahead and just dive right into this. We take a fragment; if you remember the fragments are of this shape where the first part of the tuple is the variable to be assigned to and then the next part of the tuple is the expression that is being assigned to it, in this case one is being assigned to A or A operational, one is being assigned to B, 2 is being assigned to C etcetera. Now we’re not really concerned with what specifically the operations are. We don’t care what operations are being done. We just care that something is being done to these variables, because if there is something being done, even if it ends up setting them to the exact same thing, we can’t necessarily know that ahead of time. So, if you have a fragment of this shape, then we store that as the old fragment, as the un-optimized fragment. And that’s the first argument to this method. And the return is the end return value; it’s the list of variables returned at the end of the fragment. And if they’re returned at the end of the fragment, they’re automatically live, as we said up here. Now we want to create a new optimized fragment of just the live variables. So we start off by initializing that to an empty list. And we set a variable called live equal to the returned live variables, because we know those are live. Now for every statement in the fragment starting from the back, so we’re working backwards from the return statement, back up to the top, we check if the first element of the tuple statement, that is the left hand side of the statement, is already in live. That is, it is one of the live variables currently. If it is, then we add that statement to the new optimized fragment. Otherwise we fall through and now we take the list of live variables and we remove the variables that we’re now assigning to. So we take all those out. From there, we update the live list with all the variables that are currently on the right hand side of statement. We run through the entire fragment doing that over and over until we get back to the top. Once we’re done with that, we check if the new fragment is equal to the old fragment. If it is, then we return the new fragment. We didn’t change anything. So we just return and stop and we’re done. If it isn’t, well, then we might have further optimizations as we discussed earlier. Then we return, removing dead of the new fragment in return. So we recursively call this until we don’t get any further changes, because hopefully we can optimize further. Now we’re going to check that removed dead gives us what we would expect if we ran through all the optimizations by hand, and I’m not going to bother going through all of these. You can read them fairly easily and when we do that, we see that we get true values for each of these. This is a fairly involved little bit of code. It takes a little bit to think about and this is a very useful optimization because we can potentially get rid of a lot of code doing this. In the last question in the last homework of the course, we were asked to just define a web page that uses some HTML and JavaScript. So if you ran it, you got this default, this comes in a placeholder text that we gave you and we invite you to use some creativity and have fun with your brother. Someone who knew just that. So I wasn’t very creative. I adapted the code from a website you may have heard of called searchwithpeter.info to match the context of our web browser and also to add a bit of JavaScript that will work in a JavaScript interpreter. And the result of that, I used a header, some paragraph tags, a link, an image, I used strong to make that bigger and this was generated by JavaScript execution, which isn’t very complicated. Udacity equals true if Udacity write it out and some of the P tags as we are going to interpret it which is what we did in question two. In this homework assignment, we asked you to write a function called auto debug, which takes a test piece of code, a test list and a test interesting, which checks if the code is interesting in some way. What we really mean is if there is some kind of bug that we know is going to happen. So we have this test specifically to check for it. In this case, the test is interesting if it contains A plus B on the same line, and variable A and variable B before that line. So how do we go about doing this? Well, we just – we first take the actual test list and the interesting test itself and if test itself is not interesting, then we return none. Because if it’s not interesting, none of its subsets are going to be interesting either. Otherwise we continue on and we set a size and a current test, best size and best test to be the length of the current test and test itself. Because we know those are interesting since we didn’t return and we want to hopefully find a smaller subset, so that we can narrow down where we are and where the bug we care about actually is. So we run through all the subsets of test and I will go through how we implemented that in a second. And for every element smaller in all the possible subsets of the test list, we check if first of all the length of the subset is less than the current best size – the current size of the – of an interesting test list and that this element is also interesting. If it is, then we reset the new best test to be this smaller subset and the current best size to be equal to the length of this smaller subset. And we keep running through this until we find hopefully the smaller subset or a smallest subset. We might have two interesting subsets that are the same size, that’s possible. And then once we’re all done with checking through all possible subsets, we just return the best test. Now to get all the subsets, which is something called a power set, if you’re familiar with set theory, we run it through this other function called ‘all subsets’ that takes a list, sets an element called ‘power set’ or ‘P set’ that is a list containing just the empty list, because the empty list is always a subset of everything because it’s nothing. And for every element in the list, we add two P set for all X that are currently in P set, that plus the element we’re talking about. And this is really something that you should probably play with and see how it acts, to really buy that this does what it says it does. It’s a really clever piece of code. And then we just return this. And this is just all the possible subsets, including the set itself. So what the all subsets method really does is it takes a list, let’s say list 1, 2, 3, and it returns all of the subsets of that list. So you would have the empty list and you would also have the subsets containing just one element and then all the subsets containing two elements or sub lists – I keep saying subsets; really these are lists and it’s not strictly the same thing, but we can treat them like that for now. And then all the subsets containing three elements, which is actually just the overarching list itself. And this is what the function of all subsets returns. Now to test this, we have a few test cases down here, and we already had the interesting test that we talked about earlier and we run test one through that and test one is this fragment of code up here. So variable X, variable Y, variable Z. X equals Y plus Z. Y equals Z and Z equals X plus X. So we run that through in – through auto debug and we should find that this is the smallest interesting fragment. And we see the first true statement, means that this is true. To find another interesting test, for this one, it’s just a list is interesting if it contains three numbers in strict sending order. And then we take some numbers here that we’ve generated somewhat randomly and we check auto debug against test two and interesting two. And just by hand-checking this, you should see that the length of the smallest interesting subset is three, which we can see; when it ran it, we got true, and indeed, if we check if the answer from this is itself interesting – if we run it back through interesting, we see that it is true. So our function for auto debugging or at least some auto debugging works fairly nicely. Welcome to bonus programming gem #1. This part is completely optional in that there are no quizzes. I'm going to lay out a programming problem and show you how I would approach it and debug it and give you some hints. If you already feel comfortable after seeing the problem, then you can skip it. Otherwise, follow along with me. At a high level, here's the problem description that we'll be tackling today. Given a list 'l' of arbitrary elements--could be strings, could be numbers, could be lists themselves--and a function 'f', return the element of 'l' that maximizes that function. So for example, if the function is square root and the list is 9, 16, 4, we'd want to return 16 because it has the highest square root. And we can assume that 'l' is not empty and that 'f' returns a number. Let's show an example. Let's say that the list is a list of strings--['Barbara', 'Kingsolver', 'wrote', 'the', 'Poisonwood', 'Bible'], and the function we're trying to maximize is len--the string length function. So among the 6 elements, 'Poinsonwood' has 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 letters. 'Kingsolver'--1, 2, 3, 4, 5, 6, 7, 8, 9, 10--also 10 letters, returning either one of those would be fine. What I encourage you to do at this point is, try it on your own! Go to the Python interpreter, make up some test cases, implement a function that does this, and then we'll all go through it together. So here, our goal is to find the element of the non-empty list "l" that maximizes the return value of f. and I'm just going to call this function findmax f of l. Conceptually, one way to do this is to keep track of the best thing you've seen so far, and then just walk over the list and notice if you ever see anything better. I'm going to make 2 descriptive variable names--the best element I've seen so far and the best f value I've seen so far, and then what I want to do is iterate over all the possible elements in the list without walking off the end, and I'll pull out that element and call the function f on it. If we either haven't seen anything good yet, or what we just saw is better than the best thing we've seen previously, congratulations! You, the current element, are promoted to the new champion, and then eventually when we're done, we just return the best element so far. Now I personally recommend making small test cases at the beginning, just so that we can get a feel for how it's going before we move to that big Barbara Kingsolver thing. Well, let's see if I managed to write this Python program without any mistakes. This is actually not obvious. Oh! There is a mistake. It returned bestelementsofar. Here's the error at the bottom--unindent does not match any outer indentation level. This is on line 13. Let's scroll back up and actually, I think, they are right. I needed 1 more space there. I don't know if you could see this before. For some reason, it hadn't tabbed over the whole way, but now I've made it tab over the whole way. So let's try again. Ah! And now it returns "quick," which is what we expected. That's the element of this list with the greatest length. Let's try another test. Try 5, -6, 3, and 2, and this time we want to find the element with the greatest absolute value. That should be -6. And it is! Wow! Looks like findmax is really working out well, except that it's totally not. There's actually a bug in this implementation. So the test that I've been making--they're all in sort of random order. You really want to try all the corner cases, and for something that takes a list as input, corner cases to consider are in order, in reverse order, and random. But we tried 2 tests, but they were both sort of in random order, and when you're testing a program that involves lists, you want to try in order, reverse order, and also random. So let's try this on reverse order, and see if it gets the right answer. Should be 4, and in fact, it is! Excellent. Now let's try it on in order and see if it gets the right answer. Should be -4--oh! It is -3. That's not the right answer. Hmm. What do we do? There's a bug in our code somewhere, and we may not know where. One of the first approaches to figuring out what's going on is called print statement debugging. So here what I'm doing is changing my program so that everytime we enter this loop, we print out what the value of "i" is just to make sure that things are on track. Here we're trying to print out the element and the f_value. Let's go see if I can even add print debugging without something going wrong. Alright, this looks pretty good. So we start out when i is 0 and the element there is 1 and the f_value is 1. Looking good. Then i is 1, the element is 2, f_value is 2. Good. And then i is 2, the element is 3, the f_value is 3. Well, this convinces me that we're actually calling the absolute value, but the thing I was expecting to see was -4, and we never seem to get there. So this suggests to me that i isn't getting high enough. Well, we know that i is going over every element in this range, so let's print that out to gain some understanding-- range(len(l)-1). So now here at the beginning, it tells us that i is only ranging over 0, 1, and 2, but we really want it to range over 0, 1, 2, 3, and in fact, we can make this even super obvious. Let's make an even simpler list that we're going to fail at. Now the list and the element indices are the same. We really want to get out the answer 3, but if we look down here, i only ranges over 0, 1, 2. 0, 0, 0. 1, 1, 1. 2, 2, 2. 2 is the best so we return it. So we're not getting to this last element. So there must be something wrong with this set, and I'm guessing, since we're missing the last element, that this -1--we don't really need to be subtracting 1. Now many people are often tempted to subtract 1 because Python lists start at 0, and you don't want to walk over the end. You will just print out range 4 to satisfy ourselves that it's 0, 1, 2, 3. Yep, so range(4)--0, 1, 2, 3. Now i ranges over 0, 1, 2, 3, and now we're getting the answer we expect. So now let's go back to the problem we were actually given, ["Barbara", "Kingsolver", "Wrote", "The", "Poisonwood", "Bible"], and hopefully, will get either Kingsolver or Poisonwood out, assuming I can count. Barbara is 7. Kingsolver is 10. Wrote is 5. The is 3. Poisonwood is 10. We end up with Kingsolver at the end of the day, which is a perfectly acceptable answer. But we've got all of this print debugging, and if the problem doesn't call for that, we should typically remove it before submitting, lest it be counted as part of our output and cause us to get the problem wrong. Now we just return Kingsolver. Here's an additional little nugget at the end. Let's make this function more complicated. Let's say that what I want to do is find the word that has an "l" closest to the end of it. So for example, here in "Bible" the "l" is in position 4. In "Kingsolver, it's in 0, 1, 2, 3, 4, 5, position something--I can't count. 0, 1, 2, 3, 4, 5--position 6. Alright, and for the others, it's -1. Well, we can do that with our find function. So we'll just pass in lpos, and this should work, right? Actually there may be a bug here. Let's see it in a minute. Ha! That didn't seem very good. We got "Bible" instead of "Kingsolver". What could go wrong? Well, now let's put back in some of our debugging, make sure all the steps along the way are working out. Oh! Look at this. The f_value is none every time. Why is that? I could have sworn I was writing a function that was returning--Oh! Oh! I forgot the word return. The default return value for a function is none if you don't say anything. So let's try running it again. And now, the return values are as expected and "Kingsolver," which has an "l" in position 6, beats out "Bible" with its "l" in position 3, and we return "Kingsolver." Now here, I had to add in 2 more lines just to make this simple function. It turns out that Python has a trick called lambda that let's you make a function in the middle of nowhere, and it looks something like this. Here, instead of making this function "l" position that returns word.find, I use lambda, which means make me a function. I don't have to call it anything because I'm only going to use it right here. Its argument is word, and its return value is word.find("l"). The word return is implicit when you use lambda. Just to make sure this is working, I will totally delete our definition of lpos, and add some new "Super Long This L Comes Last" word, and it should beat out all the others. Actually, it won't. Now it will. Case matters. Oh! And here's our answer. This function made with lambda--these are sometimes called anonymous functions-- had exactly the same semantics--exactly the same meaning as our previous lpos function, -1, 6, -1, -1, 3, but now "Super Long This L Comes Last" is 16. So it wins. So this time, we saw together how to write this function findmax. We also got a little experience with writing list test cases, where you typically want at least order, reverse, and random, and another good one is actually empty, but in this problem description, we were guaranteed nonempty. A bit about how to do print debugging. Everywhere there's something interesting in your code, you just print out some values and then you can look at them. And right at the end a little bit about lambda. Super productive! I hope you'll join me next time. We're about to begin another programming practice gem. This is optional material for students who would like to gain a little more practice programming and debugging. And what happens here will not influence your grade in any way. Today's problem: Given a list--could be empty, could be arbitrarily long-- print all sublists of that list. I'll give an example of what this means in just a second. If you prefer a more math-y explanation, for us this is the same problem as given a set, print all the subsets. For example, suppose the input is the 3-element list containing the strings LM, ECS, and SBA. Then we want the output to include the empty list--we don't have any of them-- all of the lists containing just 1 of them, all of the lists containing any pair of them, and then all of them. And one way to think about this is that you are throwing a party or perhaps hosting a dinner and you've invited your 3 friends: LM, ECS, and SBA. Who could show up? One possibility is that no one shows up and you eat alone. That would be super sad. Another possibility is that only your first friend shows up or only the second or only the third, and then you have a dinner for 2. It could be that any pair of them show up, you have a great time, or it could be that everyone shows up and everything works out just as you'd hoped. So you can think of this as a guest list for a party and you want to know what are all of the possible combinations of people who could actually attend. In this particular example, we started with 3 friends and ended up with 8 possibilities--1, 2, 3, 4, 5, 6, 7, 8. Totally optional quiz that does not count for your grade: If the input list had 5 entries, if you invited 5 friends to your dinner party, how many possible subsets or arrangements, ranging from no one shows up to everyone shows up, would there be? Fill in the blank. It turns out the answer is 32, which is pretty high. Here's 1 way to see it. Let's say that you had invited just 1 more person here, person X. Then either X shows up or X doesn't. We already had 8 possibilities with just these 3 friends, but now we have 8 more where X shows up. So there was the empty set, the empty list, but that also gives us the empty list plus person X. We had just LM, but now your friend X could show up as well. So if it used to be 8 and you add a new friend, X, now it's 16. And if you add another friend, Y, bringing you up to 5 friends, it goes from 16 to 32. In fact, in general, if you have N entries, there are 2 to the power of N possibilities. So there's going to be quite a lot of output. All right. So how should we solve it? My approach is going to be to use a tree. Or another way to think of this is to use recursion. Let's say that we start out with our possible guests remaining to be LM, ECS, and SBA, and the people who've showed up, let's say right now that's 0. I'm going to walk through and diagram a tree that shows all 8 possibilities. Say I start out with 3 guests to invite, and I'm going to pick the first one right now. One possibility is that LM shows up; another possibility is that LM does not. So now I have 2 other worlds to consider. In this first one, LM has showed up, and I still have to invite ECS and SBA and see what happens. Over here no one has showed up, but I still have to invite ECS and SBA. Let's work here on the left first. Now it's time to invite ECS. One possibility is that she shows up; another possibility is that she does not. But since LM showed up earlier, she's still here. In any event, I still have to invite or consider SBA. Let's say I do invite SBA. One possibility is that she shows up; another possibility is that she does not. Now I'm out of people to consider inviting, so we're done over here on the left. Back over here in this possible world, only LM has shown up so far. Let's go invite SBA. One possibility is that SBA shows up; another possibility is that she does not. And you can see how this pattern would repeat in the other side of the tree. I'll just do it here quickly. And now at the bottom of the tree you can see all 8 of our answers-- 1, 2, 3, 4, 5, 6, 7, 8--ranging from everyone shows up to no one shows up. In this tree, every time we go down a level, every time we consider another guest, we have 2 branches. So the size of the tree doubles each time, which is just what we reasoned about before. In this particular running example, my 3 friends that I invited for dinner, LM, ECS, and SBA, were Lucretia Mott, Elizabeth Cady Stanton, and Susan B. Anthony, 3 American abolitionists--that is, they opposed slavery-- who then went on to champion women's right to vote. All right. So how am I going to implement this? I'm going to make a recursive procedure that has 2 arguments: 1 corresponding to the remaining people to invite and another corresponding to who has showed up so far. Unlike many other recursive procedures, I'm going to call myself recursively twice: once in the case where the current person accepts, once in the case where they don't. So here we are in the interpreter, the integrated development environment. We're going to write a procedure that accepts a list as an argument and then prints out all the subsets of that list. I'm going to call my procedure sublists. We saw before when I drew it out that we wanted 2 arguments: the big list of people that I'm going to invite to my party and the people that I've selected so far. As we make recursive calls to sublists, the big list of people I've yet to invite will shrink, and then selected so far--the people who have showed up to my party-- may or may not grow. They may show up or not. So this is a recursive procedure, and every recursive procedure needs a base case or a stopping condition. If there's no one left to invite, then I'll just print out the people we've selected so far. Remember when I drew the tree at the bottom there were 8 answers? When I get down to the end, I want to print out each of those 8 answers. If the big list is not empty, then it has at least 1 element-- the current element, I'll call it--and then here I've just put the rest of the list, which is everything after the current element. May be empty; may have more things. In this recursive procedure, we're going to call ourselves 2 times. There's 1 case where the current person responds to our dinner invitation and ends up being one of the people we select, and there's another case where they do not. And that's actually it. Here's a test program. My dinner guests are Lucretia Mott, Elizabeth Cady Stanton, and Susan B. Anthony, and I'm going to call sublists, and the big list of people is dinner guests, and the people I've chosen so far is nothing. Let's see if this works. And in fact, we got just the answer we wanted. There's 1 world where everyone shows up, 1 world where no one shows up, 3 worlds with just 1 person, and 3 worlds with 2 people each, for a total of 8. But now let's get just a little more practice with debugging. Let's say that I make a mistake. There's a bug in my code, so I've introduced a bug in the code, and now let's rerun it. Uh-oh, this is tricky output. If you look here, there are still 1, 2, 3, 4, 5, 6, 7, 8 answers, but they're not the right ones, like this LM, ECS, SBA. It's mistakenly included twice, and it should only appear once as a possibility. SBA alone, once, twice, three times, four times, so here we're getting the wrong answer. How do we go about debugging it? One of the first steps is to make a test case that shows the problem, and we've made one, but it's kind of big. Let's see if we can see the problem with a smaller test input. How about just 2 people? There should be 4 possibilities, all different. Let's see what we get. We do get 4 possibilities, but they're not all different. I should get Lucretia and Elizabeth, just Lucretia, just Elizabeth, and no one. But instead I'm getting the same thing twice in a row, so even this smaller test case still shows the bug. Okay, maybe I can make a super small test case and still see the bug. How about just Lucretia? Oh, even this shows the bug because the 2 answers should be she shows up and she doesn't, but instead, both of the worlds I'm seeing are she shows up. Now we have a very small test case where the output we observe disagrees with our intuition or the problem specification. Now we're going to go try to localize the bug, like figure out which line the bug is on, and one way to do that is to add print statements. Here I've just added a print statement for big_list and a print statement for selectedsofar so that we can see what's going on with every recursive call. Here's a quick quiz for you. How many times do you think we'll see big_list printed out? I think it's going to be 3, once for the main call down here, and then we'll call ourselves recursively 2 more times, and then each one of those will stop. And in fact, that's what we get. 1, 2, 3, printings of big_list. Now let's trace through and see if this matches with our intuition. The big_list comes in holding Lucretia, and we haven't selected anything so far. That's good, and now we make 2 recursive calls. The big_list we've pulled off Lucretia. Okay, that part is correct, and selectedsofar we've selected Lucretia. Okay, that's possible. Remember, there are 2 worlds. One where she accepts our invitation and we select her, one where she doesn't. But then as I look down here, for this next recursive call the big_list is empty again. That's correct because with every recursive call, we have to pull something off it. But selectedsofar is Lucretia again so here--this is in both worlds--she's invited our invitation. That's really nice because we're super popular, but it's not the specification of the problem, so it tells me that for one of these recursive calls, selectedsofar is being set incorrectly. Now I know the problem is either here or here. I've narrowed it down to 2 expressions in 2 lines because I know that on the recursive call selectedsofar is being set incorrectly, and it's set based on the value of this second actual argument. All right, let's say I look at this and I think "Well, I should only be adding this current element 1 out of 2 times." In one world she accepts my invitation and in one she doesn't, so let's say over here I'm not supposed to include current_element, so let's see if removing it fixes the bug. Well, on this very simple test case, it now works. Our answer is sometimes Lucretia shows up, and sometimes she doesn't. We might be tempted to declare moral victory be carried through the streets in triumphal march, but let's go back to our other test cases and make sure that this bug really fixed the more complicated ones. Here I'm going to add in Lucretia Mott and Elizabeth Cady Stanton. To make the output easier to read, I'll just comment out this debugging, and now we can see that, oh, this wasn't quite the right answer. We didn't actually fix the problem. We should have both of them, Lucretia alone, Elizabeth alone, and none of them. We have both of them. We have Elizabeth alone, and we have none of them, but we don't have Lucretia alone, so this wasn't quite the right answer. And what do we do now? We put back in our print statement debugging and take a look and see what happens. We really want one of these to be either Lucretia alone or Elizabeth alone. Hmm, but this is a lot of debugging output, and it's hard to read. I don't like it. This is much too annoying. Now this is a time when you want to narrow things down and have more localized debugging. We already know that the problem is with one of these 2 expressions, and currently, we're not getting Lucretia and Elizabeth in sort of the right orders. I'll add some new print debugging here indicating what the current element I'm selecting is, so I'm changing the debugging information so that it's more localized to what I actually care about, and now, surprisingly, this actually gives us a better feel for the problem. When we come in at the beginning, Lucretia is our current element, so we expect our 2 recursive calls to have her and not have her. Our first recursive call is this part, and our second recursive call is this part. In the second recursive call where we don't select her, things are looking okay, but in the first recursive call where we do select her, somehow we're remembering her the first time but not the second time. Let me add just a little bit more debugging information to keep track of what's been selected so far, and now we can really see exactly what's going on. Our current element is Lucretia, so in some recursive calls, she should be one of the things we've selected so far, but we're not seeing that some of the time, and that points us exactly to this line in the code where we're not copying down what has been selected so far. I try making this change, comment out my print statement debugging, and rerun. Now we're getting the 4 elements we expect. Now let's try adding in Susan B. Anthony, and we do get the 8 answers we wanted, so we fixed the bug, but it involved print statement debugging at a high level and then at a more concentrated level to get a better feel for what was going on. Bonus, bonus. What if we want to return all the sublists in one big list instead of printing them out? Well, let's try something like this. Instead of printing out what we've selected so far, I will return it, and then down here when I make my 2 recursive calls, I'll make a list of the first one and add it to the list of the second one and see how that works, and to make it a little easier to evaluate the answer, we'll go back down to just 2 people, so we know there should be 4 options. When we stare at it a bit, this looks pretty good. Here's the answer with both of them. Here's one. Here's the other, and here's no one. But let's check and make sure that it's actually coming out equally. If it's coming out equally, I should be able to get these 4 elements out of the list independently, the 4 answers. Uh-oh. That didn't work. We can see that we haven't been building this up into sort of an evenly balanced list. There are too many opening square brackets here, not enough in other places. I could try returning this as a singleton list, but it doesn't make us any happier. But here, if I return the base case as a singleton list and then concatenate these 2 lists together, I get the 4 separate parts of the answers I was expecting. Just to review that, I'm going to go back to the wrong world. Here's the wrong world where in the leaf case I just returned the list of people selected so far. And then in the recursive case, I make a list of that and concatenate it with the list of the other. That actually doesn't work out. What I really want instead is to return a singleton list at every leaf and then just gather them up. They may seem very similar, but if the depth of the tree is more than 1, if this is a long tree that might have 8 things at the bottom, the wrong way ends up adding too many sort of nested levels of listing. This way adds exactly the right amount. Here let's just print out our answer. Now we can see that it's a list of 4 elements, both of them, just one, just the other, none of them, and if I add in Susan B. Anthony, a list of 8 elements. Nicely done. You followed along, got some practice with a brute-force procedure to enumerate all the sublists of a list and a little more experience with debugging. Welcome once again to another chance to practice your programming skills. Today we're going to take a look at a problem that's important for physical devices like yearbooks in a school or phone books or really any sorted index. The problem we're going to cover this time is how to organize and search through sorted information. The approach I want to take is to use a tree. We've seen trees before in some computer science programming. The particular kind of tree I'm going to focus on is one that has 2 branches at every level. Suppose I have a number of friends that I want to keep track of in my yearbook or in a telephone book. I could use a Python list to include all 4 of their names or all 4 of those elements. And I can check to see if an element is in a list in Python just by using the keyword "in"-- putting the element on the left and the list on the right. But we might wonder, "What is Python doing behind the scenes?" "How is this implemented in practice?" One way to do it--and the way we'll explore today-- is to build up a special kind of tree holding all of the information that I want to see. I'm going to start with the first element of my list and make it the root or the top of the tree. Let me sketch out the rest so the tree is easier to see. I've added the elements from my list--1, 2, 3 and 4--to this tree, and I've put them in a special order corresponding to how they'd fall in English alphabetical order. So since the J in Jacob comes before the M in Margaret, I've made Jacob the left child in Margaret. Since the N in Nelson comes after the M in Margaret--j, k, l, m, n, o, p; yes, I can remember the English alphabet--I've made it the right child. And the A in Alice follows all the way down here to the left. I'm going to construct a special tree to store information like this that has a number of properties. The first 2 just summarize or formalize this ordering intuition we had above. Everything to the left of Margaret and all the way down is less than or equal to--comes before in the alphabet, is a smaller number than if I'm storing phone numbers instead-- the information stored at Margaret's node. Jacob and Alice both come before Margaret in the alphabet, so they're both on the left. And similarly, right subtrees contain only information that's greater than or equal to-- larger, later in the alphabet. Nelson comes after Margaret, so it's here on the right. And then finally--and this is really important-- both the left and the right subtrees also follow rules I, II, and III. It is turtles all the way down. That makes this tree something special in computer science: a recursive data structure. We've already seen recursive functions that are defined in terms of themselves. Now I'm talking about a recursive way to lay out data that's defined in terms of itself. I'm going to draw a tree that's already mostly filled out. This tree uses numbers like 5 and 3 and 1, 6 and 8 and 13, but it follows the same principle we talked about before. For any particular node like 5, all of the children I can reach on the left are less than 5, and all of the children I can reach on the right--6, 8, and 13--are greater than 5. Now I want to add 7 to this tree, and you're going to help me out by telling me where it might go. I've drawn 7 boxes with sort of dotted edges, and these represent possible new nodes that I could add. What I'd like you to do is check all of the boxes where I could legitimately add a node for 7 to the sorts of trees that we've been talking about. Check all the boxes that apply. Let's answer this together. To answer it, I'm just going to review the 3 rules that talk about these trees. All of the left children of a node are less than or equal to it, all of the right children of a node are greater than or equal to it, and both of the children should follow rules I through III as well. This is a recursive data structure. Let's take a look at this first option here on the left. What could go in this box? Well, since it's a right child of this node labeled 1, by rule number II we know that it has to be greater than or equal to 1. And since it's eventually reachable on the left from 3, we know that it's less than or equal to 3. So the only things I could put in this box are 1, 2, or 3--not 7. It can't hold 7 because it has to be less than or equal to 3. So this one won't work out for us. By this same sort of reasoning--let's take a look at this box-- we know it has to be greater than or equal to 3 because it's to the right of this 3 node but less than or equal to 5. So 4 would be a great thing to put there, but 7 doesn't fit. Down here we're getting a little bit closer. This node has to be less than or equal to 6 but also greater than or equal to 5. This is a little harder to see in the picture, but starting from 5's right child I can eventually get down here. This is greater than or equal to 5. So maybe 5.5 could go in there but not 7. Over here--oh, I'm getting excited now-- since I can reach it going to the left of 8, I need something less than or equal to 8 and something greater than or equal to 6. 7 seems like a perfect thing to put here, so I could definitely add 7 to this part of my tree. Both of these would have to be greater than or equal to 8, so they're not good answers for 7. Now let's take a look at this evil box up here at the top. We've been describing trees with exactly 2 branches. We've been talking about the left child and the right child. I drew this mysterious third branch coming off of 5, and I drew it in the picture to the right, so you might be tempted to think, "Oh, this has to be a little better than 5 and a little less than 8, so 7 would be perfect." But in fact, the sort of recursive data structure we're describing allows exactly or up to 2 children. So it would be very tempting to put a 7 there, but that's not the kind of data structure we're describing. Now, don't feel bad if this one seemed very tempting to you. It's entirely possible to make trees like this that have 3 children every time or a variable number of children every time. But the practice problems I'm going to be going over require 1, 0, or 2. So now that we understand how these trees should work in theory, let's talk about how we might implement them in Python. Looking just at the top node of this tree, it has 3 important parts: the content--the number or name that I'm storing there-- and then the left and the right children coming out. However, we can also see that some nodes have no children, may not have a left or a right child. Let's use a very simple and direct approach for encoding these trees or representing them in Python. We'll use tuples. We'll have a 3 tuple where the 3 parts correspond exactly to my value-- the current content--the left child, and the right child. Some nodes have no children. We'll use None in Python to represent that. So this 7 node would look like this--a 7 with no left child and no right child-- and this complete tree will be a much bigger nested tuple. At the top level it's 1 tuple with 3 parts: a big left child, 5--my current value--and a big right child. And the left child and the right child also follow exactly the same layout. We had suggested earlier that in computer science this is often called a recursive data structure. My tree, this 5, is made up of or contains smaller instances of itself-- smaller instances that follow the same sort of pattern. So now let's get some concrete practice coding this up in Python. Let's try to write a procedure insert that takes 1 of these trees and a new element and returns a new tree including that element, just like you did in the quiz. I'll just set things up. Insert takes a tree and an element. This is going to be a recursive procedure. All the cool procedures are recursive. The base case is actually inserting into the empty tree. If you don't give me anything to work with, I'll just make a new singleton tree containing only this element. And that looks like this. A singleton tree, just a single branch, has no left child, no right child, and the element right in the center. If the tree is not None, then it has a left child, a current element, and a right child. And what we want to do is compare the element to be inserted against the element we found here, and that will tell us whether we should insert into the left or insert into the right. I'm going to do this in 2 steps. If the element to be inserted is less than or equal to what we're currently looking at, then we're going to call ourselves recursively going down and to the left. So I'm going to call insert on the left child and try to insert the same element into it. And that's going to return a new tree, a new--minor typo--left child. I'll just build up a new tree that has the new left child, this same element that was here already, and the old right child unchanged. We never even have to look in the right child. We can ignore that half of the tree. That's a phenomenal cosmic boost to speed. This is an efficient data structure when done well. Otherwise, we're going to do mostly the same thing on the right. So here's a quiz for you. What should go in this blank? This time we're going to leave the left child unchanged and build up a new tree based on this new right child. So now let's test it. I'm going to make a very simple tree that has midpoint right at the root, and let's say that I insert atwood, margaret into this tree. We think it should go on the left because atwood is less than midpoint. A comes before M. So let's try it out. And in fact, it did. Here's our answer. Here's our answer down here in Python tuple form, and here's the tree it corresponds to. Midpoint at the top with atwood, margaret as the left child. Midpoint at the top with atwood, margaret as the left child. No right child for midpoint, no children at all for atwood, margaret. Now let's try inserting zuma, jacob into this tree. Here is a pictorial representation of what we want to get out. Midpoint has only a right child. That right child is zuma, jacob--jacob, which I can't spell. Down here is the Python nested tuple interpretation. Midpoint has no left child, but it does have a right child: zuma, jacob. But reading this Python tuple stuff, that's really hard, so let's write a procedure to walk down one of these trees and print out everything in order. Again, this is a recursive procedure. If we've reached the end of the line, we don't do anything, but otherwise, here's what I'm going to do. Remember our rule for these trees. All of my left children are less than or equal to me. So I'll print them out first with a recursive call, then I'll print out myself, and then because all of my right children are greater than or equal to me, I'll print them out last. Now let's try this out with a little more complicated test case. I have taken a tree that has a midpoint, and then I'm inserting both Jacob Zuma and also Margaret Atwood into it. It would be a rare tree that would contain both the author of The Blind Assassin and also a South African president in 2009, but you never know. And now when we print out the tree, we get all of the elements in alphabetical order. Huh. Actually, if we didn't know any other way to sort things, this tree could be a way to put any arbitrary elements in ascending order. Now let's write one last procedure for these trees: contains. We want to see if a given tree contains an element. And the real trick with contains is that I don't have to look at the whole tree. If I'm given a very small element, I'll just go down the left path because I know it's not in the right path. Similarly, if I'm given a really huge element, I'll only go down the right path because I know it's not on the left. This is a recursive procedure, so it has a base case. If we're at the bottom of the tree and we haven't found it, then we return False. And now if this element is exactly the element we want, we found it. And then based on the dictionary ordering, we'll either call ourselves recursively on the left child only or on the right child only. Let's see if our third tree contains midpoint. It should. That's right at the top. Oh! Silly Python error. Else if is invalid syntax. Yep. They're exactly right and I'm wrong. I always get this wrong in Python. In Python, else if is written elif. Now let's try again. True. It does contain midpoint. Excellent. Let's see if it contains should not be there. Hint: The expected answer is False. And look, it is False. Unfortunately, there's actually a bug in our code. Let's see if we can find Jacob Zuma. He should totally be there but he's not. We still get False. Well, if there's a bug in our code, we have to find a test case that shows it. This is a test case that shows it. We tried a simpler one just looking for midpoint and that worked, so we'll just stick with this one for now. Our next step is to add print statement debugging until we've localized the fault. So here at the top of contains I'm just printing out the current tree and the element we're looking for. Let's go see what happens when we look for Jacob Zuma. First the tree is the entire huge tree with atwood, margaret, the midpoint, and then zuma, jacob, and the element we're looking for is zuma, jacob. So that's looking good so far. Then we call ourselves recursively and suddenly we're looking at the left child. Now we're looking inside the Margaret Atwood tree for zuma, jacob. That is not going to work. What this tells me is that we went left when we should have gone right. So somewhere up here there was some mistake involving one of these recursive calls. We went left but we should have gone right. Well, what's controlling this decision? It's the comparison between this_element and element. Here's another quiz for you. Fill in this blank with code that will make this work. The basic trick was that we had it reversed last time. We want to check and see if element is less than or equal to this_element, not the other way around. And now when we run it, we find the right answer. Here I'm making a significantly bigger tree as a kind of a final test case. We start out with an empty tree, but then we add 8, 6, 7, 5, 3, 0, 9 and then also pi, 3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5. And for each one of those we insert it into t1 and assign the result back to t1. So at the end of the day, t1 should have all of these. When we go print it out, they should be in order if our tree is working correctly. We should have gotten each one, and they should be in order. Let's go see if that works. Ah! 0, 1, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9. Excellent. This is a pretty good test case for us because it's long and it also has some duplicates, a bunch of duplicate numbers, to make sure we're handling less than or equal to or whatnot correctly. So now we have much more confidence in our tree insertion. When we were looking to see if our tree contained something, whenever we were looking something up in the tree, we could throw away half the tree from consideration at each step. If our target number was less, we could throw away the right tree--conceptually. We just forget about it for a while. This means that even if the tree is very large, we don't have to make very many recursive calls. That makes this tree a very efficient data structure. And in fact, one way for Python to implement things like dictionaries is using just this sort of tree.