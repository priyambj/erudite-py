{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%pylab notebook\n",
    "import sys\n",
    "import bs4 as bs\n",
    "import time\n",
    "import pandas as pd\n",
    "import dryscrape\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "if 'linux' in sys.platform:\n",
    "    # start xvfb in case no X is running. Make sure xvfb \n",
    "    # is installed, otherwise this won't work!\n",
    "    dryscrape.start_xvfb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_page_session(url, wait=2):\n",
    "    sess = dryscrape.Session()\n",
    "    sess.set_viewport_size(width=1024, height=800)\n",
    "    sess.visit(url)\n",
    "    time.sleep(5)\n",
    "    #sess.render('page.png')\n",
    "    return sess\n",
    "\n",
    "def click_buttons(sess, xpath):\n",
    "    for button in sess.xpath(xpath):\n",
    "        #print('click button')\n",
    "        try:\n",
    "            button.click()\n",
    "        except:\n",
    "            #print('\\tdone')\n",
    "            break    \n",
    "\n",
    "def get_specialization_df(url):\n",
    "    sess = get_page_session(url)\n",
    "    \n",
    "    #expand all syllabus details\n",
    "    click_buttons(sess, \"//div[contains(@class, 'course-show-syllabus-text')]\")\n",
    "    \n",
    "    time.sleep(1)\n",
    "    soup = bs.BeautifulSoup(sess.body(), \"lxml\")\n",
    "    courses = soup.find_all('div', attrs={'class': 'rc-SingleCourse'})\n",
    "    data = list()\n",
    "    titles = set()\n",
    "    for idx, c in enumerate(courses):\n",
    "        title = c.find('div', attrs={'class': 'course-title'}).getText(separator=u' ')\n",
    "        if title in titles:\n",
    "            continue\n",
    "        else:\n",
    "            titles.add(title)\n",
    "        print(title)\n",
    "        about = c.find('div', attrs={'class': 'course-about'}).getText(separator=u' ')\n",
    "        try:\n",
    "            syllabus = c.find('div', attrs={'class': 'rc-Syllabus'}).getText(separator=u' ')\n",
    "        except:\n",
    "            syllabus = ''\n",
    "        data.append((idx, title, about, syllabus))\n",
    "    sess.reset()\n",
    "    return pd.DataFrame(columns=['course_num', 'title', 'about', 'syllabus'], data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_specialization_links(url):\n",
    "    sess = get_page_session(url)\n",
    "    spec_pages = list()\n",
    "    current_idx = 0\n",
    "    while True:\n",
    "        for exp_idx, expand_button in enumerate(sess.xpath(\"//button[contains(@class, 'primary see-all-button')]\")):\n",
    "            if current_idx == exp_idx:\n",
    "                #print('click')\n",
    "                expand_button.click()\n",
    "                time.sleep(2)\n",
    "                spec_pages.append(sess.body())\n",
    "                current_idx += 1\n",
    "                sess = get_page_session(url)\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    spec_urls = set()\n",
    "    for sp in spec_pages:\n",
    "        sp = bs.BeautifulSoup(sp, \"lxml\")\n",
    "        js_obj = json.loads(sp.find('script', attrs={'type': 'application/ld+json'}).getText())\n",
    "        for item in  js_obj['itemListElement']:\n",
    "            url = item['url']\n",
    "            if url.startswith('https://www.coursera.org/specializations/'):\n",
    "                spec_urls.add(url)\n",
    "    return spec_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spec_links = get_specialization_links('https://www.coursera.org/browse/data-science')\n",
    "print(spec_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "courses = set()\n",
    "for l in tqdm(spec_links):\n",
    "    sys.stdout.flush()\n",
    "    name = l.rsplit('/', 1)[-1]    \n",
    "    print('process', name)\n",
    "    print('-' * 80)\n",
    "    df = get_specialization_df(l)\n",
    "    #print(df.head(2))\n",
    "    df.to_pickle('data/coursera/specializations/' + name + '.df')\n",
    "    df.to_csv('data/coursera/specializations/' + name + '.csv', encoding='utf-8', index=False)\n",
    "    courses.update(set(df['title']))\n",
    "    print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('num specializations:', len(spec_links))\n",
    "print('overall courses:', len(courses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
